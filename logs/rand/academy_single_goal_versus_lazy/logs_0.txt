Model: <class 'models.rand.RandomAgent'>, Dir: academy_single_goal_versus_lazy
num_envs: 1, state_size: (115,), action_size: [19], action_space: Discrete(19),

import math
import torch
import random
import numpy as np
import scipy.special as sps
from collections import deque
from operator import itemgetter

class BrownianNoise:
	def __init__(self, size, dt=0.02):
		self.size = size
		self.dt = dt
		self.reset()

	def reset(self):
		self.action = np.clip(np.random.randn(1, *self.size), -1, 1)
		self.daction_dt = np.random.randn(1, *self.size)

	def sample(self, state=None, scale=1):
		batch = [state.shape[0]] if state is not None and len(state.shape) in [2,4] else []
		self.daction_dt = np.random.randn(*batch, *self.size)
		self.action = self.action[0] if len(self.action) != batch else self.action
		self.action = np.clip(self.action + math.sqrt(self.dt) * self.daction_dt, -1, 1)
		return self.action * scale

class RandomAgent():
	def __init__(self, state_size, action_size, **kwargs):
		self.noise_process = BrownianNoise(action_size)
		self.eps = 1.0

	def get_action(self, state, eps=None, sample=True):
		action = self.noise_process.sample(state)
		return action

	def get_env_action(self, env, state=None, eps=None, sample=True):
		action = self.get_action(state, eps, sample)
		if hasattr(env.action_space, "n"): return np.argmax(action, -1), action
		action_range = env.action_space.high - env.action_space.low
		env_action = env.action_space.low + np.multiply((1+action)/2, action_range)
		return env_action, action

	def train(self, state, action, next_state, reward, done):
		if done[0]: self.noise_process.reset()

class ReplayBuffer():
	def __init__(self, maxlen=None):
		self.buffer = deque(maxlen=maxlen)
		
	def add(self, experience):
		self.buffer.append(experience)
		return self

	def extend(self, experiences, shuffle=False):
		if shuffle: random.shuffle(experiences)
		for exp in experiences:
			self.add(exp)
		return self

	def clear(self):
		self.buffer.clear()
		self.i_batch = 0
		return self
		
	def sample(self, batch_size, dtype=np.array, weights=None):
		sample_size = min(len(self.buffer), batch_size)
		sample_indices = random.choices(range(len(self.buffer)), k=sample_size, weights=weights)
		samples = itemgetter(*sample_indices)(self.buffer)
		sample_arrays = samples if dtype is None else map(dtype, zip(*samples))
		return sample_arrays, sample_indices, torch.Tensor([1])

	def next_batch(self, batch_size=1, dtype=np.array):
		if not hasattr(self, "i_batch"): self.i_batch = 0
		sample_indices = [i%len(self.buffer) for i in range(self.i_batch, self.i_batch+batch_size)]
		samples = itemgetter(*sample_indices)(self.buffer)
		self.i_batch = (self.i_batch+batch_size) % len(self.buffer)
		return map(dtype, zip(*samples))

	def update_priorities(self, indices, errors, offset=0.1):
		pass

	def reset_priorities(self):
		pass

	def __len__(self):
		return len(self.buffer)

class PrioritizedReplayBuffer(ReplayBuffer):
	def __init__(self, maxlen=None):
		super().__init__(maxlen)
		self.priorities = deque(maxlen=maxlen)
		
	def add(self, experience):
		super().add(experience)
		self.priorities.append(max(self.priorities, default=1))
		return self

	def clear(self):
		super().clear()
		self.priorities.clear()
		return self
		
	def get_probabilities(self, priority_scale):
		scaled_priorities = np.array(self.priorities) ** priority_scale
		sample_probabilities = scaled_priorities / sum(scaled_priorities)
		return sample_probabilities
	
	def get_importance(self, probabilities):
		importance = 1/len(self.buffer) * 1/probabilities
		importance_normalized = importance / max(importance)
		return importance_normalized[:,np.newaxis]
		
	def sample(self, batch_size, dtype=np.array, priority_scale=0.5):
		sample_probs = self.get_probabilities(priority_scale)
		samples, sample_indices, _ = super().sample(batch_size, None, sample_probs)
		importance = self.get_importance(sample_probs[sample_indices])
		return map(dtype, zip(*samples)), sample_indices, torch.Tensor(importance)
						
	def update_priorities(self, indices, errors, offset=0.1):
		for i,e in zip(indices, errors):
			self.priorities[i] = abs(e) + offset

	def reset_priorities(self):
		for i in range(len(self.priorities)):
			self.priorities[i] = 1
REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "1_vs_1_easy", "5_vs_5", "11_vs_11_stochastic"]
env_name = gfb_envs[4]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.unwrapped.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class AsyncAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000, checkpoint=False):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = AsyncAgent(envs.state_size, envs.action_size, num_envs, model)
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.stack.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0]:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 183, Reward: 0.0000 [0.00], Avg: 0.0000 (1.000)
Step: 538, Reward: 0.0000 [0.00], Avg: 0.0000 (1.000)
Step: 698, Reward: 0.0000 [0.00], Avg: 0.0000 (1.000)
Step: 832, Reward: 0.0000 [0.00], Avg: 0.0000 (1.000)
Step: 1149, Reward: 0.0000 [0.00], Avg: 0.0000 (1.000)
Step: 1382, Reward: 0.0000 [0.00], Avg: 0.0000 (1.000)
Step: 1604, Reward: -0.2000 [0.40], Avg: -0.0857 (1.000)
Step: 1643, Reward: 0.0000 [0.00], Avg: -0.0750 (1.000)
Step: 1775, Reward: 0.0000 [0.00], Avg: -0.0667 (1.000)
Step: 1801, Reward: 0.0000 [0.00], Avg: -0.0600 (1.000)
Step: 1946, Reward: 0.0000 [0.00], Avg: -0.0545 (1.000)
Step: 2290, Reward: 0.0000 [0.00], Avg: -0.0500 (1.000)
Step: 2530, Reward: 0.0000 [0.00], Avg: -0.0462 (1.000)
Step: 2573, Reward: -0.4000 [0.49], Avg: -0.1064 (1.000)
Step: 2726, Reward: 0.0000 [0.00], Avg: -0.0993 (1.000)
Step: 3211, Reward: 0.0000 [0.00], Avg: -0.0931 (1.000)
Step: 3337, Reward: 0.0000 [0.00], Avg: -0.0876 (1.000)
Step: 3451, Reward: 0.0000 [0.00], Avg: -0.0828 (1.000)
Step: 3641, Reward: 0.0000 [0.00], Avg: -0.0784 (1.000)
Step: 3846, Reward: -0.2000 [0.40], Avg: -0.1045 (1.000)
Step: 3900, Reward: 0.0000 [0.00], Avg: -0.0995 (1.000)
Step: 4176, Reward: 0.0000 [0.00], Avg: -0.0950 (1.000)
Step: 4723, Reward: 0.0000 [0.00], Avg: -0.0909 (1.000)
Step: 4814, Reward: 0.0000 [0.00], Avg: -0.0871 (1.000)
Step: 5287, Reward: 0.0000 [0.00], Avg: -0.0836 (1.000)
Step: 5684, Reward: 0.0000 [0.00], Avg: -0.0804 (1.000)
Step: 5940, Reward: 0.0000 [0.00], Avg: -0.0774 (1.000)
Step: 6127, Reward: 0.0000 [0.00], Avg: -0.0746 (1.000)
Step: 6235, Reward: 0.0000 [0.00], Avg: -0.0721 (1.000)
Step: 6457, Reward: 0.0000 [0.00], Avg: -0.0697 (1.000)
Step: 6691, Reward: 0.0000 [0.00], Avg: -0.0674 (1.000)
Step: 6776, Reward: 0.0000 [0.00], Avg: -0.0653 (1.000)
Step: 6972, Reward: 0.0000 [0.00], Avg: -0.0633 (1.000)
Step: 7098, Reward: 0.0000 [0.00], Avg: -0.0615 (1.000)
Step: 7175, Reward: -0.2000 [0.40], Avg: -0.0769 (1.000)
Step: 7410, Reward: 0.0000 [0.00], Avg: -0.0747 (1.000)
Step: 7696, Reward: 0.0000 [0.00], Avg: -0.0727 (1.000)
Step: 7909, Reward: -0.2000 [0.40], Avg: -0.0866 (1.000)
Step: 8348, Reward: 0.0000 [0.00], Avg: -0.0844 (1.000)
Step: 8559, Reward: 0.0000 [0.00], Avg: -0.0822 (1.000)
Step: 8771, Reward: -0.2000 [0.40], Avg: -0.0949 (1.000)
Step: 8980, Reward: 0.0000 [0.00], Avg: -0.0926 (1.000)
Step: 9403, Reward: 0.0000 [0.00], Avg: -0.0905 (1.000)
Step: 9512, Reward: 0.0000 [0.00], Avg: -0.0884 (1.000)
Step: 9752, Reward: 0.0000 [0.00], Avg: -0.0864 (1.000)
Step: 9909, Reward: 0.0000 [0.00], Avg: -0.0846 (1.000)
Step: 10068, Reward: -0.2000 [0.40], Avg: -0.0955 (1.000)
Step: 10269, Reward: 0.0000 [0.00], Avg: -0.0935 (1.000)
Step: 10334, Reward: 0.0000 [0.00], Avg: -0.0916 (1.000)
Step: 10589, Reward: 0.0000 [0.00], Avg: -0.0898 (1.000)
Step: 10996, Reward: 0.0000 [0.00], Avg: -0.0880 (1.000)
Step: 11085, Reward: 0.0000 [0.00], Avg: -0.0863 (1.000)
Step: 11277, Reward: 0.0000 [0.00], Avg: -0.0847 (1.000)
Step: 11326, Reward: 0.0000 [0.00], Avg: -0.0831 (1.000)
Step: 11758, Reward: 0.0000 [0.00], Avg: -0.0816 (1.000)
Step: 11890, Reward: 0.0000 [0.00], Avg: -0.0802 (1.000)
Step: 11926, Reward: 0.0000 [0.00], Avg: -0.0788 (1.000)
Step: 11995, Reward: 0.0000 [0.00], Avg: -0.0774 (1.000)
Step: 12069, Reward: 0.0000 [0.00], Avg: -0.0761 (1.000)
Step: 12330, Reward: 0.0000 [0.00], Avg: -0.0748 (1.000)
Step: 12418, Reward: 0.0000 [0.00], Avg: -0.0736 (1.000)
Step: 12573, Reward: 0.0000 [0.00], Avg: -0.0724 (1.000)
Step: 12908, Reward: 0.0000 [0.00], Avg: -0.0713 (1.000)
Step: 13106, Reward: 0.0000 [0.00], Avg: -0.0702 (1.000)
Step: 13206, Reward: 0.0000 [0.00], Avg: -0.0691 (1.000)
Step: 13796, Reward: 0.0000 [0.00], Avg: -0.0680 (1.000)
Step: 13838, Reward: 0.0000 [0.00], Avg: -0.0670 (1.000)
Step: 14473, Reward: 0.0000 [0.00], Avg: -0.0660 (1.000)
Step: 14755, Reward: 0.0000 [0.00], Avg: -0.0651 (1.000)
Step: 15040, Reward: 0.2000 [0.40], Avg: -0.0670 (1.000)
Step: 15237, Reward: -0.2000 [0.40], Avg: -0.0745 (1.000)
Step: 15280, Reward: -0.2000 [0.40], Avg: -0.0818 (1.000)
Step: 15331, Reward: 0.0000 [0.00], Avg: -0.0807 (1.000)
Step: 15370, Reward: 0.0000 [0.00], Avg: -0.0796 (1.000)
Step: 15417, Reward: 0.2000 [0.40], Avg: -0.0812 (1.000)
Step: 15641, Reward: -0.2000 [0.40], Avg: -0.0880 (1.000)
Step: 15863, Reward: 0.0000 [0.00], Avg: -0.0869 (1.000)
Step: 16250, Reward: -0.2000 [0.40], Avg: -0.0935 (1.000)
Step: 16545, Reward: 0.0000 [0.00], Avg: -0.0923 (1.000)
Step: 16599, Reward: 0.0000 [0.00], Avg: -0.0911 (1.000)
Step: 16748, Reward: -0.2000 [0.40], Avg: -0.0974 (1.000)
Step: 16812, Reward: 0.0000 [0.00], Avg: -0.0962 (1.000)
Step: 16922, Reward: 0.0000 [0.00], Avg: -0.0951 (1.000)
Step: 17111, Reward: 0.0000 [0.00], Avg: -0.0939 (1.000)
Step: 17237, Reward: 0.0000 [0.00], Avg: -0.0928 (1.000)
Step: 17382, Reward: 0.0000 [0.00], Avg: -0.0917 (1.000)
Step: 17463, Reward: 0.0000 [0.00], Avg: -0.0907 (1.000)
Step: 17668, Reward: 0.0000 [0.00], Avg: -0.0897 (1.000)
Step: 17848, Reward: 0.0000 [0.00], Avg: -0.0887 (1.000)
Step: 17933, Reward: 0.0000 [0.00], Avg: -0.0877 (1.000)
Step: 18015, Reward: 0.0000 [0.00], Avg: -0.0867 (1.000)
Step: 18162, Reward: 0.0000 [0.00], Avg: -0.0858 (1.000)
Step: 18340, Reward: 0.0000 [0.00], Avg: -0.0848 (1.000)
Step: 18521, Reward: 0.0000 [0.00], Avg: -0.0839 (1.000)
Step: 18622, Reward: 0.0000 [0.00], Avg: -0.0831 (1.000)
Step: 18783, Reward: 0.0000 [0.00], Avg: -0.0822 (1.000)
Step: 18989, Reward: 0.0000 [0.00], Avg: -0.0813 (1.000)
Step: 19459, Reward: 0.0000 [0.00], Avg: -0.0805 (1.000)
Step: 19804, Reward: 0.0000 [0.00], Avg: -0.0797 (1.000)
Step: 19893, Reward: -0.2000 [0.40], Avg: -0.0849 (1.000)
Step: 19980, Reward: -0.2000 [0.40], Avg: -0.0900 (1.000)
Step: 20115, Reward: 0.0000 [0.00], Avg: -0.0891 (1.000)
Step: 20229, Reward: 0.0000 [0.00], Avg: -0.0883 (1.000)
Step: 20348, Reward: 0.0000 [0.00], Avg: -0.0874 (1.000)
Step: 20506, Reward: 0.0000 [0.00], Avg: -0.0866 (1.000)
Step: 20533, Reward: 0.0000 [0.00], Avg: -0.0858 (1.000)
Step: 20721, Reward: 0.0000 [0.00], Avg: -0.0850 (1.000)
Step: 20791, Reward: 0.0000 [0.00], Avg: -0.0842 (1.000)
Step: 20991, Reward: 0.0000 [0.00], Avg: -0.0834 (1.000)
Step: 21192, Reward: 0.0000 [0.00], Avg: -0.0826 (1.000)
Step: 21312, Reward: 0.0000 [0.00], Avg: -0.0819 (1.000)
Step: 21712, Reward: 0.0000 [0.00], Avg: -0.0812 (1.000)
Step: 22004, Reward: 0.0000 [0.00], Avg: -0.0804 (1.000)
Step: 22056, Reward: 0.0000 [0.00], Avg: -0.0797 (1.000)
Step: 22312, Reward: 0.0000 [0.00], Avg: -0.0790 (1.000)
Step: 22557, Reward: -0.2000 [0.40], Avg: -0.0835 (1.000)
Step: 22738, Reward: 0.0000 [0.00], Avg: -0.0828 (1.000)
Step: 22821, Reward: 0.0000 [0.00], Avg: -0.0821 (1.000)
Step: 22865, Reward: 0.0000 [0.00], Avg: -0.0814 (1.000)
Step: 22916, Reward: 0.0000 [0.00], Avg: -0.0807 (1.000)
Step: 23147, Reward: 0.0000 [0.00], Avg: -0.0801 (1.000)
Step: 23319, Reward: 0.0000 [0.00], Avg: -0.0794 (1.000)
Step: 23477, Reward: 0.0000 [0.00], Avg: -0.0788 (1.000)
Step: 24082, Reward: 0.0000 [0.00], Avg: -0.0781 (1.000)
Step: 24269, Reward: 0.0000 [0.00], Avg: -0.0775 (1.000)
Step: 24593, Reward: 0.0000 [0.00], Avg: -0.0769 (1.000)
Step: 24756, Reward: 0.2000 [0.40], Avg: -0.0779 (1.000)
Step: 25117, Reward: 0.0000 [0.00], Avg: -0.0773 (1.000)
Step: 25236, Reward: -0.2000 [0.40], Avg: -0.0813 (1.000)
Step: 25346, Reward: 0.0000 [0.00], Avg: -0.0807 (1.000)
Step: 25426, Reward: 0.0000 [0.00], Avg: -0.0801 (1.000)
Step: 25667, Reward: 0.0000 [0.00], Avg: -0.0795 (1.000)
Step: 25996, Reward: -0.2000 [0.40], Avg: -0.0834 (1.000)
Step: 26205, Reward: 0.0000 [0.00], Avg: -0.0828 (1.000)
Step: 26792, Reward: 0.0000 [0.00], Avg: -0.0821 (1.000)
Step: 26856, Reward: -0.2000 [0.40], Avg: -0.0860 (1.000)
Step: 26929, Reward: 0.0000 [0.00], Avg: -0.0853 (1.000)
Step: 27486, Reward: 0.0000 [0.00], Avg: -0.0847 (1.000)
Step: 27705, Reward: 0.0000 [0.00], Avg: -0.0841 (1.000)
Step: 27855, Reward: 0.0000 [0.00], Avg: -0.0835 (1.000)
Step: 27912, Reward: 0.0000 [0.00], Avg: -0.0829 (1.000)
Step: 28052, Reward: 0.0000 [0.00], Avg: -0.0823 (1.000)
Step: 28092, Reward: 0.0000 [0.00], Avg: -0.0817 (1.000)
Step: 28307, Reward: 0.0000 [0.00], Avg: -0.0812 (1.000)
Step: 28563, Reward: 0.0000 [0.00], Avg: -0.0806 (1.000)
Step: 28783, Reward: 0.0000 [0.00], Avg: -0.0801 (1.000)
Step: 29086, Reward: -0.2000 [0.40], Avg: -0.0836 (1.000)
Step: 29291, Reward: 0.0000 [0.00], Avg: -0.0830 (1.000)
Step: 29387, Reward: 0.0000 [0.00], Avg: -0.0825 (1.000)
Step: 29550, Reward: -0.2000 [0.40], Avg: -0.0859 (1.000)
Step: 29632, Reward: 0.0000 [0.00], Avg: -0.0854 (1.000)
Step: 29752, Reward: 0.0000 [0.00], Avg: -0.0848 (1.000)
Step: 29804, Reward: 0.0000 [0.00], Avg: -0.0842 (1.000)
Step: 29880, Reward: -0.2000 [0.40], Avg: -0.0876 (1.000)
Step: 29927, Reward: 0.0000 [0.00], Avg: -0.0870 (1.000)
Step: 30195, Reward: 0.0000 [0.00], Avg: -0.0865 (1.000)
Step: 30419, Reward: 0.0000 [0.00], Avg: -0.0859 (1.000)
Step: 30532, Reward: 0.0000 [0.00], Avg: -0.0854 (1.000)
Step: 30662, Reward: 0.0000 [0.00], Avg: -0.0848 (1.000)
Step: 30789, Reward: 0.0000 [0.00], Avg: -0.0843 (1.000)
Step: 31115, Reward: 0.0000 [0.00], Avg: -0.0838 (1.000)
Step: 31245, Reward: 0.0000 [0.00], Avg: -0.0833 (1.000)
Step: 31441, Reward: 0.0000 [0.00], Avg: -0.0828 (1.000)
Step: 31990, Reward: 0.0000 [0.00], Avg: -0.0823 (1.000)
Step: 32329, Reward: 0.0000 [0.00], Avg: -0.0818 (1.000)
Step: 32406, Reward: -0.2000 [0.40], Avg: -0.0849 (1.000)
Step: 32482, Reward: 0.0000 [0.00], Avg: -0.0844 (1.000)
Step: 32722, Reward: 0.0000 [0.00], Avg: -0.0839 (1.000)
Step: 32789, Reward: 0.0000 [0.00], Avg: -0.0834 (1.000)
Step: 32965, Reward: 0.0000 [0.00], Avg: -0.0829 (1.000)
Step: 32999, Reward: 0.0000 [0.00], Avg: -0.0824 (1.000)
Step: 33075, Reward: 0.0000 [0.00], Avg: -0.0819 (1.000)
Step: 33993, Reward: 0.0000 [0.00], Avg: -0.0814 (1.000)
Step: 34072, Reward: 0.0000 [0.00], Avg: -0.0810 (1.000)
Step: 34229, Reward: 0.0000 [0.00], Avg: -0.0805 (1.000)
Step: 34438, Reward: 0.0000 [0.00], Avg: -0.0801 (1.000)
Step: 34716, Reward: 0.0000 [0.00], Avg: -0.0796 (1.000)
Step: 34895, Reward: 0.0000 [0.00], Avg: -0.0792 (1.000)
Step: 35062, Reward: 0.0000 [0.00], Avg: -0.0787 (1.000)
Step: 35355, Reward: 0.0000 [0.00], Avg: -0.0783 (1.000)
Step: 35424, Reward: 0.0000 [0.00], Avg: -0.0778 (1.000)
Step: 35743, Reward: 0.0000 [0.00], Avg: -0.0774 (1.000)
Step: 35950, Reward: -0.2000 [0.40], Avg: -0.0803 (1.000)
Step: 36038, Reward: -0.2000 [0.40], Avg: -0.0831 (1.000)
Step: 36206, Reward: -0.2000 [0.40], Avg: -0.0859 (1.000)
Step: 36498, Reward: 0.0000 [0.00], Avg: -0.0854 (1.000)
Step: 36594, Reward: -0.4000 [0.49], Avg: -0.0897 (1.000)
Step: 36780, Reward: 0.0000 [0.00], Avg: -0.0893 (1.000)
Step: 36908, Reward: -0.2000 [0.40], Avg: -0.0920 (1.000)
Step: 37035, Reward: 0.0000 [0.00], Avg: -0.0915 (1.000)
Step: 37442, Reward: 0.0000 [0.00], Avg: -0.0910 (1.000)
Step: 37578, Reward: 0.0000 [0.00], Avg: -0.0905 (1.000)
Step: 37724, Reward: 0.2000 [0.40], Avg: -0.0911 (1.000)
Step: 37761, Reward: 0.0000 [0.00], Avg: -0.0906 (1.000)
Step: 38223, Reward: 0.2000 [0.40], Avg: -0.0912 (1.000)
Step: 38588, Reward: -0.2000 [0.40], Avg: -0.0938 (1.000)
Step: 39128, Reward: 0.0000 [0.00], Avg: -0.0933 (1.000)
Step: 39421, Reward: 0.0000 [0.00], Avg: -0.0928 (1.000)
Step: 39593, Reward: 0.0000 [0.00], Avg: -0.0924 (1.000)
Step: 40028, Reward: -0.4000 [0.49], Avg: -0.0963 (1.000)
Step: 40084, Reward: 0.0000 [0.00], Avg: -0.0959 (1.000)
Step: 40179, Reward: 0.0000 [0.00], Avg: -0.0954 (1.000)
Step: 40262, Reward: 0.0000 [0.00], Avg: -0.0949 (1.000)
Step: 40813, Reward: 0.0000 [0.00], Avg: -0.0945 (1.000)
Step: 40889, Reward: 0.0000 [0.00], Avg: -0.0940 (1.000)
Step: 41026, Reward: -0.2000 [0.40], Avg: -0.0965 (1.000)
Step: 41115, Reward: 0.0000 [0.00], Avg: -0.0960 (1.000)
Step: 41363, Reward: -0.2000 [0.40], Avg: -0.0984 (1.000)
Step: 41469, Reward: -0.2000 [0.40], Avg: -0.1008 (1.000)
Step: 42143, Reward: 0.0000 [0.00], Avg: -0.1003 (1.000)
Step: 42412, Reward: 0.0000 [0.00], Avg: -0.0999 (1.000)
Step: 42598, Reward: -0.2000 [0.40], Avg: -0.1022 (1.000)
Step: 42907, Reward: 0.0000 [0.00], Avg: -0.1017 (1.000)
Step: 42940, Reward: 0.0000 [0.00], Avg: -0.1013 (1.000)
Step: 43080, Reward: 0.0000 [0.00], Avg: -0.1008 (1.000)
Step: 43196, Reward: 0.0000 [0.00], Avg: -0.1003 (1.000)
Step: 43251, Reward: 0.0000 [0.00], Avg: -0.0999 (1.000)
Step: 43390, Reward: -0.2000 [0.40], Avg: -0.1022 (1.000)
Step: 43433, Reward: -0.2000 [0.40], Avg: -0.1044 (1.000)
Step: 43803, Reward: 0.0000 [0.00], Avg: -0.1040 (1.000)
Step: 43938, Reward: 0.0000 [0.00], Avg: -0.1035 (1.000)
Step: 44121, Reward: -0.4000 [0.49], Avg: -0.1070 (1.000)
Step: 44367, Reward: 0.0000 [0.00], Avg: -0.1065 (1.000)
Step: 44590, Reward: 0.0000 [0.00], Avg: -0.1061 (1.000)
Step: 45008, Reward: 0.0000 [0.00], Avg: -0.1056 (1.000)
Step: 45091, Reward: 0.0000 [0.00], Avg: -0.1051 (1.000)
Step: 45221, Reward: -0.4000 [0.49], Avg: -0.1086 (1.000)
Step: 45607, Reward: 0.0000 [0.00], Avg: -0.1081 (1.000)
Step: 45680, Reward: 0.0000 [0.00], Avg: -0.1076 (1.000)
Step: 45763, Reward: 0.0000 [0.00], Avg: -0.1072 (1.000)
Step: 45918, Reward: -0.2000 [0.40], Avg: -0.1093 (1.000)
Step: 46043, Reward: -0.2000 [0.40], Avg: -0.1114 (1.000)
Step: 46221, Reward: 0.0000 [0.00], Avg: -0.1109 (1.000)
Step: 46401, Reward: -0.2000 [0.40], Avg: -0.1130 (1.000)
Step: 46515, Reward: -0.2000 [0.40], Avg: -0.1151 (1.000)
Step: 47095, Reward: 0.0000 [0.00], Avg: -0.1146 (1.000)
Step: 47178, Reward: 0.0000 [0.00], Avg: -0.1141 (1.000)
Step: 47317, Reward: -0.2000 [0.40], Avg: -0.1162 (1.000)
Step: 47794, Reward: 0.0000 [0.00], Avg: -0.1157 (1.000)
Step: 48015, Reward: 0.0000 [0.00], Avg: -0.1152 (1.000)
Step: 48212, Reward: -0.2000 [0.40], Avg: -0.1172 (1.000)
Step: 48288, Reward: 0.0000 [0.00], Avg: -0.1167 (1.000)
Step: 48365, Reward: 0.0000 [0.00], Avg: -0.1163 (1.000)
Step: 48658, Reward: 0.0000 [0.00], Avg: -0.1158 (1.000)
Step: 48702, Reward: 0.0000 [0.00], Avg: -0.1153 (1.000)
Step: 48767, Reward: -0.2000 [0.40], Avg: -0.1173 (1.000)
Step: 48928, Reward: 0.0000 [0.63], Avg: -0.1194 (1.000)
Step: 48969, Reward: 0.0000 [0.00], Avg: -0.1189 (1.000)
Step: 49158, Reward: 0.0000 [0.00], Avg: -0.1184 (1.000)
Step: 49241, Reward: 0.2000 [0.40], Avg: -0.1187 (1.000)
Step: 49460, Reward: 0.0000 [0.00], Avg: -0.1183 (1.000)
Step: 49519, Reward: 0.0000 [0.00], Avg: -0.1178 (1.000)
Step: 49557, Reward: 0.0000 [0.00], Avg: -0.1173 (1.000)
Step: 49589, Reward: 0.0000 [0.00], Avg: -0.1169 (1.000)
Step: 49763, Reward: 0.0000 [0.00], Avg: -0.1164 (1.000)
Step: 49916, Reward: 0.0000 [0.00], Avg: -0.1159 (1.000)
Step: 50189, Reward: 0.0000 [0.00], Avg: -0.1155 (1.000)
Step: 50389, Reward: 0.0000 [0.00], Avg: -0.1150 (1.000)
Step: 50448, Reward: 0.0000 [0.00], Avg: -0.1146 (1.000)
Step: 50595, Reward: 0.0000 [0.00], Avg: -0.1142 (1.000)
Step: 50906, Reward: 0.2000 [0.40], Avg: -0.1145 (1.000)
Step: 51066, Reward: 0.0000 [0.00], Avg: -0.1141 (1.000)
Step: 51334, Reward: -0.4000 [0.49], Avg: -0.1170 (1.000)
Step: 51405, Reward: 0.0000 [0.00], Avg: -0.1166 (1.000)
Step: 51588, Reward: 0.0000 [0.00], Avg: -0.1161 (1.000)
Step: 51673, Reward: 0.0000 [0.00], Avg: -0.1157 (1.000)
Step: 51744, Reward: 0.0000 [0.00], Avg: -0.1153 (1.000)
Step: 51940, Reward: 0.0000 [0.00], Avg: -0.1148 (1.000)
Step: 52012, Reward: -0.2000 [0.40], Avg: -0.1166 (1.000)
Step: 52170, Reward: -0.2000 [0.40], Avg: -0.1184 (1.000)
Step: 52212, Reward: 0.0000 [0.00], Avg: -0.1180 (1.000)
Step: 52375, Reward: 0.0000 [0.00], Avg: -0.1175 (1.000)
Step: 52435, Reward: -0.2000 [0.40], Avg: -0.1193 (1.000)
Step: 52499, Reward: 0.0000 [0.00], Avg: -0.1189 (1.000)
Step: 52727, Reward: -0.2000 [0.40], Avg: -0.1206 (1.000)
Step: 52978, Reward: 0.0000 [0.00], Avg: -0.1202 (1.000)
Step: 53067, Reward: 0.0000 [0.00], Avg: -0.1198 (1.000)
Step: 53393, Reward: -0.2000 [0.40], Avg: -0.1215 (1.000)
Step: 53582, Reward: 0.0000 [0.00], Avg: -0.1210 (1.000)
Step: 53667, Reward: 0.0000 [0.00], Avg: -0.1206 (1.000)
Step: 53997, Reward: -0.2000 [0.40], Avg: -0.1223 (1.000)
Step: 54344, Reward: 0.0000 [0.00], Avg: -0.1219 (1.000)
Step: 54585, Reward: 0.2000 [0.40], Avg: -0.1222 (1.000)
Step: 54705, Reward: 0.0000 [0.00], Avg: -0.1217 (1.000)
Step: 55055, Reward: -0.2000 [0.40], Avg: -0.1234 (1.000)
Step: 55123, Reward: 0.0000 [0.00], Avg: -0.1230 (1.000)
Step: 55353, Reward: 0.2000 [0.40], Avg: -0.1232 (1.000)
Step: 55909, Reward: -0.2000 [0.40], Avg: -0.1249 (1.000)
Step: 56021, Reward: 0.0000 [0.00], Avg: -0.1245 (1.000)
Step: 56363, Reward: 0.0000 [0.00], Avg: -0.1240 (1.000)
Step: 56674, Reward: 0.0000 [0.00], Avg: -0.1236 (1.000)
Step: 56923, Reward: 0.0000 [0.00], Avg: -0.1232 (1.000)
Step: 57158, Reward: 0.0000 [0.00], Avg: -0.1228 (1.000)
Step: 57371, Reward: 0.0000 [0.00], Avg: -0.1224 (1.000)
Step: 57523, Reward: 0.2000 [0.40], Avg: -0.1226 (1.000)
Step: 57740, Reward: 0.0000 [0.00], Avg: -0.1222 (1.000)
Step: 57797, Reward: 0.0000 [0.00], Avg: -0.1218 (1.000)
Step: 57831, Reward: 0.0000 [0.00], Avg: -0.1214 (1.000)
Step: 57889, Reward: -0.2000 [0.40], Avg: -0.1230 (1.000)
Step: 58014, Reward: 0.0000 [0.00], Avg: -0.1226 (1.000)
Step: 58375, Reward: 0.0000 [0.00], Avg: -0.1222 (1.000)
Step: 58447, Reward: 0.0000 [0.00], Avg: -0.1218 (1.000)
Step: 59195, Reward: 0.0000 [0.00], Avg: -0.1214 (1.000)
Step: 59370, Reward: 0.0000 [0.00], Avg: -0.1210 (1.000)
Step: 59628, Reward: -0.2000 [0.40], Avg: -0.1225 (1.000)
Step: 59659, Reward: 0.0000 [0.00], Avg: -0.1221 (1.000)
Step: 59968, Reward: 0.2000 [0.40], Avg: -0.1224 (1.000)
Step: 60113, Reward: 0.0000 [0.00], Avg: -0.1220 (1.000)
Step: 60283, Reward: 0.2000 [0.40], Avg: -0.1222 (1.000)
Step: 60381, Reward: 0.0000 [0.00], Avg: -0.1218 (1.000)
Step: 60441, Reward: 0.0000 [0.00], Avg: -0.1215 (1.000)
Step: 60738, Reward: -0.2000 [0.40], Avg: -0.1230 (1.000)
Step: 60942, Reward: 0.0000 [0.00], Avg: -0.1226 (1.000)
Step: 61002, Reward: 0.0000 [0.00], Avg: -0.1222 (1.000)
Step: 61159, Reward: 0.0000 [0.00], Avg: -0.1218 (1.000)
Step: 61335, Reward: 0.0000 [0.00], Avg: -0.1214 (1.000)
Step: 61533, Reward: 0.0000 [0.00], Avg: -0.1210 (1.000)
Step: 61992, Reward: 0.0000 [0.00], Avg: -0.1207 (1.000)
Step: 62220, Reward: 0.0000 [0.00], Avg: -0.1203 (1.000)
Step: 62308, Reward: 0.0000 [0.00], Avg: -0.1199 (1.000)
Step: 62428, Reward: -0.2000 [0.40], Avg: -0.1214 (1.000)
Step: 62511, Reward: 0.0000 [0.00], Avg: -0.1210 (1.000)
Step: 63206, Reward: 0.0000 [0.00], Avg: -0.1207 (1.000)
Step: 63402, Reward: -0.2000 [0.40], Avg: -0.1221 (1.000)
Step: 63764, Reward: 0.0000 [0.00], Avg: -0.1218 (1.000)
Step: 64249, Reward: 0.0000 [0.00], Avg: -0.1214 (1.000)
Step: 64429, Reward: 0.0000 [0.00], Avg: -0.1210 (1.000)
Step: 64497, Reward: 0.0000 [0.00], Avg: -0.1206 (1.000)
Step: 64861, Reward: 0.0000 [0.00], Avg: -0.1203 (1.000)
Step: 65092, Reward: -0.2000 [0.40], Avg: -0.1217 (1.000)
Step: 65208, Reward: 0.0000 [0.00], Avg: -0.1214 (1.000)
Step: 65542, Reward: 0.0000 [0.00], Avg: -0.1210 (1.000)
Step: 65878, Reward: 0.0000 [0.00], Avg: -0.1206 (1.000)
Step: 66355, Reward: -0.2000 [0.40], Avg: -0.1221 (1.000)
Step: 66432, Reward: -0.2000 [0.40], Avg: -0.1235 (1.000)
Step: 66779, Reward: 0.0000 [0.00], Avg: -0.1231 (1.000)
Step: 66911, Reward: 0.0000 [0.00], Avg: -0.1228 (1.000)
Step: 67010, Reward: 0.0000 [0.00], Avg: -0.1224 (1.000)
Step: 67213, Reward: 0.0000 [0.00], Avg: -0.1220 (1.000)
Step: 67308, Reward: 0.0000 [0.00], Avg: -0.1217 (1.000)
Step: 67405, Reward: 0.0000 [0.00], Avg: -0.1213 (1.000)
Step: 67554, Reward: -0.2000 [0.40], Avg: -0.1227 (1.000)
Step: 67631, Reward: -0.2000 [0.40], Avg: -0.1241 (1.000)
Step: 67831, Reward: 0.0000 [0.00], Avg: -0.1238 (1.000)
Step: 68030, Reward: -0.2000 [0.40], Avg: -0.1251 (1.000)
Step: 68342, Reward: -0.2000 [0.40], Avg: -0.1265 (1.000)
Step: 68470, Reward: 0.0000 [0.00], Avg: -0.1261 (1.000)
Step: 68602, Reward: 0.0000 [0.00], Avg: -0.1258 (1.000)
Step: 69435, Reward: 0.0000 [0.00], Avg: -0.1254 (1.000)
Step: 69511, Reward: 0.0000 [0.00], Avg: -0.1251 (1.000)
Step: 69737, Reward: 0.0000 [0.00], Avg: -0.1247 (1.000)
Step: 69865, Reward: 0.0000 [0.00], Avg: -0.1244 (1.000)
Step: 69994, Reward: 0.0000 [0.00], Avg: -0.1240 (1.000)
Step: 70028, Reward: 0.0000 [0.00], Avg: -0.1236 (1.000)
Step: 70193, Reward: 0.0000 [0.00], Avg: -0.1233 (1.000)
Step: 70522, Reward: 0.0000 [0.00], Avg: -0.1230 (1.000)
Step: 70562, Reward: 0.0000 [0.00], Avg: -0.1226 (1.000)
Step: 70951, Reward: 0.0000 [0.00], Avg: -0.1223 (1.000)
Step: 71259, Reward: 0.0000 [0.00], Avg: -0.1219 (1.000)
Step: 71638, Reward: 0.0000 [0.00], Avg: -0.1216 (1.000)
Step: 71686, Reward: 0.0000 [0.00], Avg: -0.1213 (1.000)
Step: 71928, Reward: 0.0000 [0.00], Avg: -0.1209 (1.000)
Step: 72066, Reward: 0.0000 [0.00], Avg: -0.1206 (1.000)
Step: 72136, Reward: 0.0000 [0.00], Avg: -0.1203 (1.000)
Step: 72219, Reward: 0.0000 [0.00], Avg: -0.1199 (1.000)
Step: 72458, Reward: 0.0000 [0.00], Avg: -0.1196 (1.000)
Step: 72538, Reward: 0.0000 [0.00], Avg: -0.1193 (1.000)
Step: 72611, Reward: -0.2000 [0.40], Avg: -0.1206 (1.000)
Step: 72797, Reward: 0.0000 [0.00], Avg: -0.1202 (1.000)
Step: 73133, Reward: 0.0000 [0.00], Avg: -0.1199 (1.000)
Step: 73421, Reward: 0.0000 [0.00], Avg: -0.1196 (1.000)
Step: 73457, Reward: -0.2000 [0.40], Avg: -0.1209 (1.000)
Step: 73510, Reward: 0.0000 [0.00], Avg: -0.1206 (1.000)
Step: 73641, Reward: 0.0000 [0.00], Avg: -0.1202 (1.000)
Step: 73813, Reward: -0.2000 [0.40], Avg: -0.1215 (1.000)
Step: 73957, Reward: 0.0000 [0.00], Avg: -0.1212 (1.000)
Step: 74243, Reward: -0.2000 [0.40], Avg: -0.1225 (1.000)
Step: 74406, Reward: -0.2000 [0.40], Avg: -0.1237 (1.000)
Step: 74718, Reward: 0.0000 [0.00], Avg: -0.1234 (1.000)
Step: 74774, Reward: 0.0000 [0.00], Avg: -0.1231 (1.000)
Step: 75153, Reward: 0.0000 [0.00], Avg: -0.1228 (1.000)
Step: 75374, Reward: 0.0000 [0.00], Avg: -0.1224 (1.000)
Step: 75662, Reward: 0.0000 [0.00], Avg: -0.1221 (1.000)
Step: 75745, Reward: 0.2000 [0.40], Avg: -0.1223 (1.000)
Step: 75818, Reward: 0.2000 [0.40], Avg: -0.1225 (1.000)
Step: 76467, Reward: 0.0000 [0.00], Avg: -0.1222 (1.000)
Step: 76783, Reward: 0.0000 [0.00], Avg: -0.1219 (1.000)
Step: 77278, Reward: 0.0000 [0.00], Avg: -0.1216 (1.000)
Step: 77353, Reward: 0.0000 [0.00], Avg: -0.1213 (1.000)
Step: 77656, Reward: 0.0000 [0.00], Avg: -0.1210 (1.000)
Step: 77888, Reward: 0.0000 [0.00], Avg: -0.1206 (1.000)
Step: 77975, Reward: 0.0000 [0.00], Avg: -0.1203 (1.000)
Step: 78474, Reward: 0.0000 [0.00], Avg: -0.1200 (1.000)
Step: 78698, Reward: 0.2000 [0.40], Avg: -0.1202 (1.000)
Step: 78850, Reward: 0.0000 [0.00], Avg: -0.1199 (1.000)
Step: 78901, Reward: 0.0000 [0.00], Avg: -0.1196 (1.000)
Step: 79029, Reward: 0.0000 [0.00], Avg: -0.1193 (1.000)
Step: 79420, Reward: -0.2000 [0.40], Avg: -0.1205 (1.000)
Step: 80098, Reward: -0.2000 [0.40], Avg: -0.1217 (1.000)
Step: 80259, Reward: 0.0000 [0.00], Avg: -0.1214 (1.000)
Step: 81050, Reward: -0.2000 [0.40], Avg: -0.1226 (1.000)
Step: 81342, Reward: 0.0000 [0.00], Avg: -0.1223 (1.000)
Step: 81441, Reward: 0.0000 [0.00], Avg: -0.1220 (1.000)
Step: 81636, Reward: 0.0000 [0.00], Avg: -0.1217 (1.000)
Step: 82105, Reward: -0.2000 [0.40], Avg: -0.1229 (1.000)
Step: 82221, Reward: 0.0000 [0.00], Avg: -0.1226 (1.000)
Step: 82487, Reward: 0.0000 [0.00], Avg: -0.1223 (1.000)
Step: 82564, Reward: -0.2000 [0.40], Avg: -0.1235 (1.000)
Step: 82692, Reward: 0.0000 [0.00], Avg: -0.1232 (1.000)
Step: 82778, Reward: 0.0000 [0.00], Avg: -0.1229 (1.000)
Step: 82932, Reward: 0.0000 [0.00], Avg: -0.1226 (1.000)
Step: 83019, Reward: -0.2000 [0.40], Avg: -0.1237 (1.000)
Step: 83198, Reward: -0.2000 [0.40], Avg: -0.1249 (1.000)
Step: 84137, Reward: 0.0000 [0.00], Avg: -0.1246 (1.000)
Step: 84264, Reward: 0.0000 [0.00], Avg: -0.1243 (1.000)
Step: 84341, Reward: 0.0000 [0.00], Avg: -0.1240 (1.000)
Step: 84513, Reward: -0.2000 [0.40], Avg: -0.1251 (1.000)
Step: 84912, Reward: 0.0000 [0.00], Avg: -0.1248 (1.000)
Step: 84942, Reward: 0.0000 [0.00], Avg: -0.1245 (1.000)
Step: 85093, Reward: 0.0000 [0.00], Avg: -0.1242 (1.000)
Step: 85332, Reward: -0.2000 [0.40], Avg: -0.1253 (1.000)
Step: 85421, Reward: 0.0000 [0.00], Avg: -0.1251 (1.000)
Step: 85485, Reward: 0.0000 [0.00], Avg: -0.1248 (1.000)
Step: 85606, Reward: 0.0000 [0.00], Avg: -0.1245 (1.000)
Step: 85879, Reward: 0.0000 [0.00], Avg: -0.1242 (1.000)
Step: 85921, Reward: 0.0000 [0.00], Avg: -0.1239 (1.000)
Step: 86142, Reward: -0.2000 [0.40], Avg: -0.1250 (1.000)
Step: 86173, Reward: 0.2000 [0.40], Avg: -0.1252 (1.000)
Step: 86438, Reward: 0.0000 [0.00], Avg: -0.1249 (1.000)
Step: 86920, Reward: -0.4000 [0.49], Avg: -0.1267 (1.000)
Step: 87092, Reward: 0.0000 [0.00], Avg: -0.1264 (1.000)
Step: 87154, Reward: 0.0000 [0.00], Avg: -0.1261 (1.000)
Step: 87184, Reward: -0.2000 [0.40], Avg: -0.1272 (1.000)
Step: 87318, Reward: 0.0000 [0.00], Avg: -0.1269 (1.000)
Step: 87649, Reward: 0.0000 [0.00], Avg: -0.1266 (1.000)
Step: 87849, Reward: -0.2000 [0.40], Avg: -0.1277 (1.000)
Step: 87905, Reward: 0.0000 [0.00], Avg: -0.1274 (1.000)
Step: 88122, Reward: 0.0000 [0.00], Avg: -0.1271 (1.000)
Step: 88407, Reward: 0.0000 [0.00], Avg: -0.1268 (1.000)
Step: 89576, Reward: 0.0000 [0.00], Avg: -0.1265 (1.000)
Step: 89802, Reward: 0.0000 [0.00], Avg: -0.1262 (1.000)
Step: 90036, Reward: 0.0000 [0.00], Avg: -0.1259 (1.000)
Step: 90565, Reward: 0.0000 [0.00], Avg: -0.1256 (1.000)
Step: 90640, Reward: -0.2000 [0.40], Avg: -0.1267 (1.000)
Step: 90780, Reward: 0.0000 [0.00], Avg: -0.1264 (1.000)
Step: 90921, Reward: 0.0000 [0.00], Avg: -0.1261 (1.000)
Step: 90959, Reward: 0.0000 [0.00], Avg: -0.1259 (1.000)
Step: 91019, Reward: 0.0000 [0.00], Avg: -0.1256 (1.000)
Step: 91082, Reward: 0.0000 [0.00], Avg: -0.1253 (1.000)
Step: 91134, Reward: 0.0000 [0.00], Avg: -0.1250 (1.000)
Step: 91229, Reward: 0.0000 [0.00], Avg: -0.1247 (1.000)
Step: 91634, Reward: -0.2000 [0.40], Avg: -0.1258 (1.000)
Step: 91906, Reward: 0.0000 [0.00], Avg: -0.1255 (1.000)
Step: 92111, Reward: 0.0000 [0.00], Avg: -0.1252 (1.000)
Step: 92199, Reward: 0.0000 [0.00], Avg: -0.1250 (1.000)
Step: 92566, Reward: -0.2000 [0.40], Avg: -0.1260 (1.000)
Step: 92704, Reward: 0.0000 [0.00], Avg: -0.1257 (1.000)
Step: 92891, Reward: 0.0000 [0.00], Avg: -0.1255 (1.000)
Step: 93110, Reward: -0.2000 [0.40], Avg: -0.1265 (1.000)
Step: 93185, Reward: 0.0000 [0.00], Avg: -0.1262 (1.000)
Step: 93354, Reward: 0.0000 [0.00], Avg: -0.1259 (1.000)
Step: 93560, Reward: 0.0000 [0.00], Avg: -0.1257 (1.000)
Step: 93636, Reward: 0.0000 [0.00], Avg: -0.1254 (1.000)
Step: 93726, Reward: 0.0000 [0.00], Avg: -0.1251 (1.000)
Step: 93850, Reward: 0.0000 [0.00], Avg: -0.1249 (1.000)
Step: 93922, Reward: -0.2000 [0.40], Avg: -0.1259 (1.000)
Step: 94010, Reward: 0.0000 [0.00], Avg: -0.1256 (1.000)
Step: 94223, Reward: 0.2000 [0.40], Avg: -0.1258 (1.000)
Step: 94270, Reward: -0.2000 [0.40], Avg: -0.1268 (1.000)
Step: 94305, Reward: 0.0000 [0.00], Avg: -0.1265 (1.000)
Step: 94608, Reward: 0.0000 [0.00], Avg: -0.1262 (1.000)
Step: 94918, Reward: 0.0000 [0.00], Avg: -0.1260 (1.000)
Step: 94989, Reward: -0.2000 [0.40], Avg: -0.1270 (1.000)
Step: 95214, Reward: 0.0000 [0.00], Avg: -0.1267 (1.000)
Step: 95678, Reward: 0.0000 [0.00], Avg: -0.1264 (1.000)
Step: 95970, Reward: -0.2000 [0.40], Avg: -0.1274 (1.000)
Step: 96032, Reward: 0.0000 [0.00], Avg: -0.1272 (1.000)
Step: 96419, Reward: 0.0000 [0.00], Avg: -0.1269 (1.000)
Step: 96929, Reward: 0.0000 [0.00], Avg: -0.1266 (1.000)
Step: 97106, Reward: 0.0000 [0.00], Avg: -0.1264 (1.000)
Step: 97253, Reward: 0.0000 [0.00], Avg: -0.1261 (1.000)
Step: 97356, Reward: -0.2000 [0.40], Avg: -0.1271 (1.000)
Step: 97589, Reward: 0.0000 [0.00], Avg: -0.1268 (1.000)
Step: 97906, Reward: -0.2000 [0.40], Avg: -0.1278 (1.000)
Step: 98218, Reward: 0.0000 [0.00], Avg: -0.1275 (1.000)
Step: 98744, Reward: -0.2000 [0.40], Avg: -0.1285 (1.000)
Step: 98980, Reward: 0.0000 [0.00], Avg: -0.1283 (1.000)
Step: 99084, Reward: 0.0000 [0.00], Avg: -0.1280 (1.000)
Step: 99552, Reward: 0.0000 [0.00], Avg: -0.1277 (1.000)
Step: 99871, Reward: 0.0000 [0.00], Avg: -0.1275 (1.000)
Step: 99945, Reward: 0.0000 [0.00], Avg: -0.1272 (1.000)
