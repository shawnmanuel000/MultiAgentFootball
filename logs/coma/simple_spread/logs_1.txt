Model: <class 'multiagent.coma.COMAAgent'>, Dir: simple_spread
num_envs: 1, state_size: [(1, 18), (1, 18), (1, 18)], action_size: [[1, 5], [1, 5], [1, 5]], action_space: [<gym.spaces.multi_discrete.MultiDiscrete object at 0x7feb5c6d7cc0>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7feb5c6d7d68>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7feb5c6d7dd8>],

import torch
import random
import numpy as np
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, one_hot

EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN

class COMAActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)!=3 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.recurrent = torch.nn.GRUCell(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_probs = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.init_hidden()

	def forward(self, state, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		if self.hidden.size(0) != state.size(0): self.init_hidden(state.size(0))
		self.hidden = self.recurrent(state, self.hidden)
		action_probs = self.action_probs(self.hidden).softmax(-1)
		action_probs = action_probs.view(*out_dims, -1)
		return action_probs

	def init_hidden(self, batch_size=1):
		self.hidden = torch.zeros([batch_size, ACTOR_HIDDEN])

class COMACritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)!=3 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.q_values = torch.nn.Linear(CRITIC_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		q_values = self.q_values(state)
		return q_values

class COMANetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(gpu=gpu)
		self.state_size = [state_size] if type(state_size[0]) in [int, np.int32] else state_size
		self.action_size = [action_size] if type(action_size[0]) in [int, np.int32] else action_size
		self.n_agents = lambda size: 1 if len(size)==1 else size[0]
		make_actor = lambda s_size,a_size: COMAActor([s_size[-1] + a_size[-1] + self.n_agents(s_size)], a_size)
		make_critic = lambda s_size,a_size: COMACritic([np.sum([np.prod(s) for s in self.state_size]) + 2*np.sum([np.prod(a) for a in self.action_size]) + s_size[-1] + self.n_agents(s_size)], a_size)
		self.models = [PTACNetwork(s_size, a_size, make_actor, make_critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		if load: self.load_model(load)
		
	def get_action_probs(self, state, sample=True, grad=True, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [model.actor_local(s.to(self.device), sample) for s,model in zip(state, self.models)]
			return [a.cpu().numpy().astype(np.float32) for a in action] if numpy else action

	def get_value(self, state, grad=True, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_values = [model.critic_local(s.to(self.device)) for s,model in zip(state, self.models)]
			return [q.cpu().numpy() for q in q_values] if numpy else q_values

	def optimize(self, actions, actor_inputs, critic_inputs, q_values, q_targets):
		for model,action,actor_input,critic_input,q_value,q_target in zip(self.models, actions, actor_inputs, critic_inputs, q_values, q_targets):
			for t in reversed(range(q_target.size(0))):
				q_value[t] = model.critic_local(critic_input[t])
				q_select = torch.gather(q_value[t], dim=-1, index=action[t].argmax(-1, keepdims=True)).squeeze(-1)
				critic_loss = (q_select - q_target[t].detach()).pow(2)
				model.step(model.critic_optimizer, critic_loss.mean(), retain=t>0)

			hidden = model.actor_local.hidden
			action_probs = torch.stack([model.actor_local(actor_input[t]) for t in range(q_target.size(0))], dim=0)
			baseline = (action_probs * q_value[:-1]).sum(-1, keepdims=True).detach()
			q_selected = torch.gather(q_value[:-1], dim=-1, index=action[:-1].argmax(-1, keepdims=True))
			log_probs = torch.gather(action_probs, dim=-1, index=action[:-1].argmax(-1, keepdims=True)).log()
			advantages = (q_selected - baseline).detach()
			actor_loss = (advantages * log_probs).sum()
			model.step(model.actor_optimizer, actor_loss.mean())
			model.actor_local.hidden = hidden

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("coma", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("coma", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class COMAAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, COMANetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True, numpy=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state)
		if not hasattr(self, "action"): self.action = [np.zeros_like(a) for a in action_random]
		actor_inputs = []
		state_list = self.to_tensor(state)
		state_list = [state_list] if type(state_list) != list else state_list
		for i,(state,last_a,s_size,a_size) in enumerate(zip(state_list, self.action, self.state_size, self.action_size)):
			n_agents = self.network.n_agents(s_size)
			last_action = last_a if len(state.shape)-len(s_size) == len(last_a.shape)-len(a_size) else np.zeros_like(action_random[i])
			agent_ids = np.eye(n_agents) if len(state.shape)==len(s_size) else np.repeat(np.expand_dims(np.eye(n_agents), 0), repeats=state.shape[0], axis=0)
			actor_input = torch.tensor(np.concatenate([state, last_action, agent_ids], axis=-1), device=self.network.device).float()
			actor_inputs.append(actor_input)
		action_greedy = self.network.get_action_probs(actor_inputs, sample=sample, grad=False, numpy=numpy)
		action = action_random if numpy and random.random() < eps else action_greedy
		if numpy: self.action = action
		return action

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.update_freq:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()

			n_agents = [self.network.n_agents(a_size) for a_size in self.action_size]
			states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, self.to_tensor(next_state))]
			actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.get_action(next_state, numpy=False))]
			states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			actions_one_hot = [one_hot(a) for a in actions]
			actions_one_hot_joint = torch.cat([a.view(*a.shape[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions_one_hot, self.action_size)], dim=-1)
			last_actions = [torch.cat([torch.zeros_like(a[0:1]), a[:-1]], dim=0) for a in actions_one_hot]
			last_actions_joint = torch.cat([a.view(*a.shape[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(last_actions, self.action_size)], dim=-1)
			agent_mask = [(1-torch.eye(n_agent)).view(-1, 1).repeat(1, a_size[-1]).view(n_agent, -1) for a_size,n_agent in zip(self.action_size, n_agents)]
			action_mask = torch.ones([1, 1, np.sum(n_agents), np.sum([n_agent*a_size[-1] for a_size,n_agent in zip(self.action_size, n_agents)])])
			cols, rows = [0, *np.cumsum(n_agents)], [0, *np.cumsum([n_agent*a_size[-1] for a_size,n_agent in zip(self.action_size, n_agents)])]
			for i,mask in enumerate(agent_mask): action_mask[...,cols[i]:cols[i+1], rows[i]:rows[i+1]] = mask

			states_joint, actions_joint, last_actions_joint = [x.unsqueeze(-2).repeat_interleave(action_mask.shape[-2], dim=-2) for x in [states_joint, actions_one_hot_joint, last_actions_joint]]
			joint_inputs = torch.cat([states_joint, actions_joint * action_mask, last_actions_joint], dim=-1).split(n_agents, dim=-2)
			agent_ids = [torch.eye(self.network.n_agents(a_size)).unsqueeze(0).unsqueeze(0).expand(*a.shape[:2], -1, -1) for a_size, a in zip(self.action_size, actions)]
			critic_inputs = [torch.cat([joint_input, state, agent_id], dim=-1) for joint_input,state,agent_id in zip(joint_inputs, states, agent_ids)]
			actor_inputs = [torch.cat([state, last_action, agent_id], dim=-1) for state,last_action,agent_id in zip(states, last_actions, agent_ids)]

			q_values = self.network.get_value(critic_inputs, grad=False)
			q_selecteds = [torch.gather(q_value, dim=-1, index=a.argmax(-1, keepdims=True)).squeeze(-1) for q_value,a in zip(q_values,actions)]
			q_targets = [self.compute_gae(q_selected[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_selected[:-1])[0] for q_selected,reward,done in zip(q_selecteds, rewards, dones)]
			self.network.optimize(actions, actor_inputs, critic_inputs, q_values, q_targets)
		if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.900             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)
# np.random.seed(1)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return gym.make(env_name)
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":0} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env)

def run(model, steps=10000, ports=16, env_name=env_name, eval_at=1000, checkpoint=False, save_best=False, log=True, render=True):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports, render=False, env_name=env_name)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, num_envs=num_envs, gpu=False, agent2=RandomAgent) 
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if np.any(dones[0]):
			rollouts = [rollout(envs.env, agent.reset(1), render=render) for _ in range(1)]
			test_reward = np.mean(rollouts, axis=0) - np.std(rollouts, axis=0)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if save_best and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts, axis=0)} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")
			agent.reset(num_envs)

def trial(model):
	envs = EnsembleEnv(make_env, 0, log=True, render=True)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, load=f"{env_name}")
	print(f"Reward: {rollout(envs.env, agent, eps=0.02, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[1], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="maddpg", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--test", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.test:
		trial(model)
	elif args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		run(model, args.steps, args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)

Step: 49, Reward: [-416.849 -416.849 -416.849] [0.0000], Avg: [-416.849 -416.849 -416.849] (0.995)
Step: 99, Reward: [-533.319 -533.319 -533.319] [0.0000], Avg: [-475.084 -475.084 -475.084] (0.990)
Step: 149, Reward: [-444.05 -444.05 -444.05] [0.0000], Avg: [-464.739 -464.739 -464.739] (0.985)
Step: 199, Reward: [-413.344 -413.344 -413.344] [0.0000], Avg: [-451.891 -451.891 -451.891] (0.980)
Step: 249, Reward: [-517.15 -517.15 -517.15] [0.0000], Avg: [-464.943 -464.943 -464.943] (0.975)
Step: 299, Reward: [-341.174 -341.174 -341.174] [0.0000], Avg: [-444.314 -444.314 -444.314] (0.970)
Step: 349, Reward: [-403.965 -403.965 -403.965] [0.0000], Avg: [-438.55 -438.55 -438.55] (0.966)
Step: 399, Reward: [-506.259 -506.259 -506.259] [0.0000], Avg: [-447.014 -447.014 -447.014] (0.961)
Step: 449, Reward: [-427.3 -427.3 -427.3] [0.0000], Avg: [-444.823 -444.823 -444.823] (0.956)
Step: 499, Reward: [-456.422 -456.422 -456.422] [0.0000], Avg: [-445.983 -445.983 -445.983] (0.951)
Step: 549, Reward: [-429.8 -429.8 -429.8] [0.0000], Avg: [-444.512 -444.512 -444.512] (0.946)
Step: 599, Reward: [-345.432 -345.432 -345.432] [0.0000], Avg: [-436.255 -436.255 -436.255] (0.942)
Step: 649, Reward: [-389.426 -389.426 -389.426] [0.0000], Avg: [-432.653 -432.653 -432.653] (0.937)
Step: 699, Reward: [-607.604 -607.604 -607.604] [0.0000], Avg: [-445.149 -445.149 -445.149] (0.932)
Step: 749, Reward: [-469.842 -469.842 -469.842] [0.0000], Avg: [-446.796 -446.796 -446.796] (0.928)
Step: 799, Reward: [-471.78 -471.78 -471.78] [0.0000], Avg: [-448.357 -448.357 -448.357] (0.923)
Step: 849, Reward: [-492.938 -492.938 -492.938] [0.0000], Avg: [-450.98 -450.98 -450.98] (0.918)
Step: 899, Reward: [-635.056 -635.056 -635.056] [0.0000], Avg: [-461.206 -461.206 -461.206] (0.914)
Step: 949, Reward: [-502.498 -502.498 -502.498] [0.0000], Avg: [-463.379 -463.379 -463.379] (0.909)
Step: 999, Reward: [-406.779 -406.779 -406.779] [0.0000], Avg: [-460.549 -460.549 -460.549] (0.905)
Step: 1049, Reward: [-877.698 -877.698 -877.698] [0.0000], Avg: [-480.413 -480.413 -480.413] (0.900)
Step: 1099, Reward: [-806.195 -806.195 -806.195] [0.0000], Avg: [-495.222 -495.222 -495.222] (0.896)
Step: 1149, Reward: [-580.463 -580.463 -580.463] [0.0000], Avg: [-498.928 -498.928 -498.928] (0.891)
Step: 1199, Reward: [-483.012 -483.012 -483.012] [0.0000], Avg: [-498.265 -498.265 -498.265] (0.887)
Step: 1249, Reward: [-436.734 -436.734 -436.734] [0.0000], Avg: [-495.803 -495.803 -495.803] (0.882)
Step: 1299, Reward: [-729.615 -729.615 -729.615] [0.0000], Avg: [-504.796 -504.796 -504.796] (0.878)
Step: 1349, Reward: [-459.642 -459.642 -459.642] [0.0000], Avg: [-503.124 -503.124 -503.124] (0.873)
Step: 1399, Reward: [-702.268 -702.268 -702.268] [0.0000], Avg: [-510.236 -510.236 -510.236] (0.869)
Step: 1449, Reward: [-597.187 -597.187 -597.187] [0.0000], Avg: [-513.234 -513.234 -513.234] (0.865)
Step: 1499, Reward: [-706.798 -706.798 -706.798] [0.0000], Avg: [-519.687 -519.687 -519.687] (0.860)
Step: 1549, Reward: [-543.562 -543.562 -543.562] [0.0000], Avg: [-520.457 -520.457 -520.457] (0.856)
Step: 1599, Reward: [-395.439 -395.439 -395.439] [0.0000], Avg: [-516.55 -516.55 -516.55] (0.852)
Step: 1649, Reward: [-522.831 -522.831 -522.831] [0.0000], Avg: [-516.74 -516.74 -516.74] (0.848)
Step: 1699, Reward: [-927.309 -927.309 -927.309] [0.0000], Avg: [-528.816 -528.816 -528.816] (0.843)
Step: 1749, Reward: [-508.594 -508.594 -508.594] [0.0000], Avg: [-528.238 -528.238 -528.238] (0.839)
Step: 1799, Reward: [-480.588 -480.588 -480.588] [0.0000], Avg: [-526.914 -526.914 -526.914] (0.835)
Step: 1849, Reward: [-693.597 -693.597 -693.597] [0.0000], Avg: [-531.419 -531.419 -531.419] (0.831)
Step: 1899, Reward: [-653.072 -653.072 -653.072] [0.0000], Avg: [-534.621 -534.621 -534.621] (0.827)
Step: 1949, Reward: [-494.368 -494.368 -494.368] [0.0000], Avg: [-533.589 -533.589 -533.589] (0.822)
Step: 1999, Reward: [-431.649 -431.649 -431.649] [0.0000], Avg: [-531.04 -531.04 -531.04] (0.818)
Step: 2049, Reward: [-474.626 -474.626 -474.626] [0.0000], Avg: [-529.664 -529.664 -529.664] (0.814)
Step: 2099, Reward: [-457.991 -457.991 -457.991] [0.0000], Avg: [-527.958 -527.958 -527.958] (0.810)
Step: 2149, Reward: [-741.977 -741.977 -741.977] [0.0000], Avg: [-532.935 -532.935 -532.935] (0.806)
Step: 2199, Reward: [-687.28 -687.28 -687.28] [0.0000], Avg: [-536.443 -536.443 -536.443] (0.802)
Step: 2249, Reward: [-605.913 -605.913 -605.913] [0.0000], Avg: [-537.987 -537.987 -537.987] (0.798)
Step: 2299, Reward: [-301.12 -301.12 -301.12] [0.0000], Avg: [-532.837 -532.837 -532.837] (0.794)
Step: 2349, Reward: [-462.981 -462.981 -462.981] [0.0000], Avg: [-531.351 -531.351 -531.351] (0.790)
Step: 2399, Reward: [-561.345 -561.345 -561.345] [0.0000], Avg: [-531.976 -531.976 -531.976] (0.786)
Step: 2449, Reward: [-651.221 -651.221 -651.221] [0.0000], Avg: [-534.409 -534.409 -534.409] (0.782)
Step: 2499, Reward: [-442.086 -442.086 -442.086] [0.0000], Avg: [-532.563 -532.563 -532.563] (0.778)
Step: 2549, Reward: [-544.396 -544.396 -544.396] [0.0000], Avg: [-532.795 -532.795 -532.795] (0.774)
Step: 2599, Reward: [-457.582 -457.582 -457.582] [0.0000], Avg: [-531.349 -531.349 -531.349] (0.771)
Step: 2649, Reward: [-462.736 -462.736 -462.736] [0.0000], Avg: [-530.054 -530.054 -530.054] (0.767)
Step: 2699, Reward: [-501.774 -501.774 -501.774] [0.0000], Avg: [-529.53 -529.53 -529.53] (0.763)
Step: 2749, Reward: [-400.876 -400.876 -400.876] [0.0000], Avg: [-527.191 -527.191 -527.191] (0.759)
Step: 2799, Reward: [-541.569 -541.569 -541.569] [0.0000], Avg: [-527.448 -527.448 -527.448] (0.755)
Step: 2849, Reward: [-397.541 -397.541 -397.541] [0.0000], Avg: [-525.169 -525.169 -525.169] (0.751)
Step: 2899, Reward: [-445.733 -445.733 -445.733] [0.0000], Avg: [-523.799 -523.799 -523.799] (0.748)
Step: 2949, Reward: [-523.762 -523.762 -523.762] [0.0000], Avg: [-523.799 -523.799 -523.799] (0.744)
Step: 2999, Reward: [-639.449 -639.449 -639.449] [0.0000], Avg: [-525.726 -525.726 -525.726] (0.740)
Step: 3049, Reward: [-582.693 -582.693 -582.693] [0.0000], Avg: [-526.66 -526.66 -526.66] (0.737)
Step: 3099, Reward: [-670.783 -670.783 -670.783] [0.0000], Avg: [-528.985 -528.985 -528.985] (0.733)
Step: 3149, Reward: [-488.468 -488.468 -488.468] [0.0000], Avg: [-528.341 -528.341 -528.341] (0.729)
Step: 3199, Reward: [-365.011 -365.011 -365.011] [0.0000], Avg: [-525.789 -525.789 -525.789] (0.726)
Step: 3249, Reward: [-480.129 -480.129 -480.129] [0.0000], Avg: [-525.087 -525.087 -525.087] (0.722)
Step: 3299, Reward: [-559.222 -559.222 -559.222] [0.0000], Avg: [-525.604 -525.604 -525.604] (0.718)
Step: 3349, Reward: [-412.329 -412.329 -412.329] [0.0000], Avg: [-523.914 -523.914 -523.914] (0.715)
Step: 3399, Reward: [-363.26 -363.26 -363.26] [0.0000], Avg: [-521.551 -521.551 -521.551] (0.711)
Step: 3449, Reward: [-631.347 -631.347 -631.347] [0.0000], Avg: [-523.142 -523.142 -523.142] (0.708)
Step: 3499, Reward: [-539.449 -539.449 -539.449] [0.0000], Avg: [-523.375 -523.375 -523.375] (0.704)
Step: 3549, Reward: [-440.264 -440.264 -440.264] [0.0000], Avg: [-522.205 -522.205 -522.205] (0.701)
Step: 3599, Reward: [-413.06 -413.06 -413.06] [0.0000], Avg: [-520.689 -520.689 -520.689] (0.697)
Step: 3649, Reward: [-381.993 -381.993 -381.993] [0.0000], Avg: [-518.789 -518.789 -518.789] (0.694)
Step: 3699, Reward: [-694.318 -694.318 -694.318] [0.0000], Avg: [-521.161 -521.161 -521.161] (0.690)
Step: 3749, Reward: [-550.485 -550.485 -550.485] [0.0000], Avg: [-521.552 -521.552 -521.552] (0.687)
Step: 3799, Reward: [-501.643 -501.643 -501.643] [0.0000], Avg: [-521.29 -521.29 -521.29] (0.683)
Step: 3849, Reward: [-325.237 -325.237 -325.237] [0.0000], Avg: [-518.744 -518.744 -518.744] (0.680)
Step: 3899, Reward: [-646.759 -646.759 -646.759] [0.0000], Avg: [-520.385 -520.385 -520.385] (0.676)
Step: 3949, Reward: [-454.168 -454.168 -454.168] [0.0000], Avg: [-519.547 -519.547 -519.547] (0.673)
Step: 3999, Reward: [-593.848 -593.848 -593.848] [0.0000], Avg: [-520.475 -520.475 -520.475] (0.670)
Step: 4049, Reward: [-475.864 -475.864 -475.864] [0.0000], Avg: [-519.925 -519.925 -519.925] (0.666)
Step: 4099, Reward: [-453.49 -453.49 -453.49] [0.0000], Avg: [-519.115 -519.115 -519.115] (0.663)
Step: 4149, Reward: [-430.66 -430.66 -430.66] [0.0000], Avg: [-518.049 -518.049 -518.049] (0.660)
Step: 4199, Reward: [-513.362 -513.362 -513.362] [0.0000], Avg: [-517.993 -517.993 -517.993] (0.656)
Step: 4249, Reward: [-604.88 -604.88 -604.88] [0.0000], Avg: [-519.015 -519.015 -519.015] (0.653)
Step: 4299, Reward: [-565.539 -565.539 -565.539] [0.0000], Avg: [-519.556 -519.556 -519.556] (0.650)
Step: 4349, Reward: [-433.359 -433.359 -433.359] [0.0000], Avg: [-518.565 -518.565 -518.565] (0.647)
Step: 4399, Reward: [-602.849 -602.849 -602.849] [0.0000], Avg: [-519.523 -519.523 -519.523] (0.643)
Step: 4449, Reward: [-380.902 -380.902 -380.902] [0.0000], Avg: [-517.966 -517.966 -517.966] (0.640)
Step: 4499, Reward: [-528.513 -528.513 -528.513] [0.0000], Avg: [-518.083 -518.083 -518.083] (0.637)
Step: 4549, Reward: [-458.151 -458.151 -458.151] [0.0000], Avg: [-517.424 -517.424 -517.424] (0.634)
Step: 4599, Reward: [-529.34 -529.34 -529.34] [0.0000], Avg: [-517.554 -517.554 -517.554] (0.631)
Step: 4649, Reward: [-446.257 -446.257 -446.257] [0.0000], Avg: [-516.787 -516.787 -516.787] (0.627)
Step: 4699, Reward: [-316.722 -316.722 -316.722] [0.0000], Avg: [-514.659 -514.659 -514.659] (0.624)
Step: 4749, Reward: [-567.534 -567.534 -567.534] [0.0000], Avg: [-515.215 -515.215 -515.215] (0.621)
Step: 4799, Reward: [-509.105 -509.105 -509.105] [0.0000], Avg: [-515.152 -515.152 -515.152] (0.618)
Step: 4849, Reward: [-559.55 -559.55 -559.55] [0.0000], Avg: [-515.609 -515.609 -515.609] (0.615)
Step: 4899, Reward: [-420.915 -420.915 -420.915] [0.0000], Avg: [-514.643 -514.643 -514.643] (0.612)
Step: 4949, Reward: [-610.505 -610.505 -610.505] [0.0000], Avg: [-515.611 -515.611 -515.611] (0.609)
Step: 4999, Reward: [-337.725 -337.725 -337.725] [0.0000], Avg: [-513.833 -513.833 -513.833] (0.606)
Step: 5049, Reward: [-378.367 -378.367 -378.367] [0.0000], Avg: [-512.491 -512.491 -512.491] (0.603)
Step: 5099, Reward: [-567.842 -567.842 -567.842] [0.0000], Avg: [-513.034 -513.034 -513.034] (0.600)
Step: 5149, Reward: [-517.749 -517.749 -517.749] [0.0000], Avg: [-513.08 -513.08 -513.08] (0.597)
Step: 5199, Reward: [-482.028 -482.028 -482.028] [0.0000], Avg: [-512.781 -512.781 -512.781] (0.594)
Step: 5249, Reward: [-394.455 -394.455 -394.455] [0.0000], Avg: [-511.654 -511.654 -511.654] (0.591)
Step: 5299, Reward: [-607.9 -607.9 -607.9] [0.0000], Avg: [-512.562 -512.562 -512.562] (0.588)
Step: 5349, Reward: [-441.443 -441.443 -441.443] [0.0000], Avg: [-511.898 -511.898 -511.898] (0.585)
Step: 5399, Reward: [-315.027 -315.027 -315.027] [0.0000], Avg: [-510.075 -510.075 -510.075] (0.582)
Step: 5449, Reward: [-376.398 -376.398 -376.398] [0.0000], Avg: [-508.848 -508.848 -508.848] (0.579)
Step: 5499, Reward: [-468.522 -468.522 -468.522] [0.0000], Avg: [-508.482 -508.482 -508.482] (0.576)
Step: 5549, Reward: [-405.5 -405.5 -405.5] [0.0000], Avg: [-507.554 -507.554 -507.554] (0.573)
Step: 5599, Reward: [-575.57 -575.57 -575.57] [0.0000], Avg: [-508.161 -508.161 -508.161] (0.570)
Step: 5649, Reward: [-477.38 -477.38 -477.38] [0.0000], Avg: [-507.889 -507.889 -507.889] (0.568)
Step: 5699, Reward: [-538.546 -538.546 -538.546] [0.0000], Avg: [-508.158 -508.158 -508.158] (0.565)
Step: 5749, Reward: [-516.108 -516.108 -516.108] [0.0000], Avg: [-508.227 -508.227 -508.227] (0.562)
Step: 5799, Reward: [-411.331 -411.331 -411.331] [0.0000], Avg: [-507.392 -507.392 -507.392] (0.559)
Step: 5849, Reward: [-472.021 -472.021 -472.021] [0.0000], Avg: [-507.089 -507.089 -507.089] (0.556)
Step: 5899, Reward: [-400.415 -400.415 -400.415] [0.0000], Avg: [-506.185 -506.185 -506.185] (0.554)
Step: 5949, Reward: [-389.473 -389.473 -389.473] [0.0000], Avg: [-505.204 -505.204 -505.204] (0.551)
Step: 5999, Reward: [-387.375 -387.375 -387.375] [0.0000], Avg: [-504.223 -504.223 -504.223] (0.548)
Step: 6049, Reward: [-533.617 -533.617 -533.617] [0.0000], Avg: [-504.466 -504.466 -504.466] (0.545)
Step: 6099, Reward: [-526.34 -526.34 -526.34] [0.0000], Avg: [-504.645 -504.645 -504.645] (0.543)
Step: 6149, Reward: [-572.247 -572.247 -572.247] [0.0000], Avg: [-505.194 -505.194 -505.194] (0.540)
Step: 6199, Reward: [-522.095 -522.095 -522.095] [0.0000], Avg: [-505.331 -505.331 -505.331] (0.537)
Step: 6249, Reward: [-576.738 -576.738 -576.738] [0.0000], Avg: [-505.902 -505.902 -505.902] (0.534)
Step: 6299, Reward: [-469.125 -469.125 -469.125] [0.0000], Avg: [-505.61 -505.61 -505.61] (0.532)
Step: 6349, Reward: [-526.305 -526.305 -526.305] [0.0000], Avg: [-505.773 -505.773 -505.773] (0.529)
Step: 6399, Reward: [-482.461 -482.461 -482.461] [0.0000], Avg: [-505.591 -505.591 -505.591] (0.526)
Step: 6449, Reward: [-493.739 -493.739 -493.739] [0.0000], Avg: [-505.499 -505.499 -505.499] (0.524)
Step: 6499, Reward: [-439.185 -439.185 -439.185] [0.0000], Avg: [-504.989 -504.989 -504.989] (0.521)
Step: 6549, Reward: [-566.429 -566.429 -566.429] [0.0000], Avg: [-505.458 -505.458 -505.458] (0.519)
Step: 6599, Reward: [-481.334 -481.334 -481.334] [0.0000], Avg: [-505.275 -505.275 -505.275] (0.516)
Step: 6649, Reward: [-468.946 -468.946 -468.946] [0.0000], Avg: [-505.002 -505.002 -505.002] (0.513)
Step: 6699, Reward: [-413.51 -413.51 -413.51] [0.0000], Avg: [-504.319 -504.319 -504.319] (0.511)
Step: 6749, Reward: [-425.817 -425.817 -425.817] [0.0000], Avg: [-503.738 -503.738 -503.738] (0.508)
Step: 6799, Reward: [-489.604 -489.604 -489.604] [0.0000], Avg: [-503.634 -503.634 -503.634] (0.506)
Step: 6849, Reward: [-590.466 -590.466 -590.466] [0.0000], Avg: [-504.268 -504.268 -504.268] (0.503)
Step: 6899, Reward: [-510.035 -510.035 -510.035] [0.0000], Avg: [-504.309 -504.309 -504.309] (0.501)
Step: 6949, Reward: [-386.878 -386.878 -386.878] [0.0000], Avg: [-503.465 -503.465 -503.465] (0.498)
Step: 6999, Reward: [-464.692 -464.692 -464.692] [0.0000], Avg: [-503.188 -503.188 -503.188] (0.496)
Step: 7049, Reward: [-513.892 -513.892 -513.892] [0.0000], Avg: [-503.264 -503.264 -503.264] (0.493)
Step: 7099, Reward: [-408.999 -408.999 -408.999] [0.0000], Avg: [-502.6 -502.6 -502.6] (0.491)
Step: 7149, Reward: [-465.304 -465.304 -465.304] [0.0000], Avg: [-502.339 -502.339 -502.339] (0.488)
Step: 7199, Reward: [-307.938 -307.938 -307.938] [0.0000], Avg: [-500.989 -500.989 -500.989] (0.486)
Step: 7249, Reward: [-455.507 -455.507 -455.507] [0.0000], Avg: [-500.675 -500.675 -500.675] (0.483)
Step: 7299, Reward: [-365.161 -365.161 -365.161] [0.0000], Avg: [-499.747 -499.747 -499.747] (0.481)
Step: 7349, Reward: [-364.767 -364.767 -364.767] [0.0000], Avg: [-498.829 -498.829 -498.829] (0.479)
Step: 7399, Reward: [-392.163 -392.163 -392.163] [0.0000], Avg: [-498.108 -498.108 -498.108] (0.476)
Step: 7449, Reward: [-381.379 -381.379 -381.379] [0.0000], Avg: [-497.325 -497.325 -497.325] (0.474)
Step: 7499, Reward: [-378.464 -378.464 -378.464] [0.0000], Avg: [-496.532 -496.532 -496.532] (0.471)
Step: 7549, Reward: [-406.76 -406.76 -406.76] [0.0000], Avg: [-495.938 -495.938 -495.938] (0.469)
Step: 7599, Reward: [-499.095 -499.095 -499.095] [0.0000], Avg: [-495.959 -495.959 -495.959] (0.467)
Step: 7649, Reward: [-417.606 -417.606 -417.606] [0.0000], Avg: [-495.446 -495.446 -495.446] (0.464)
Step: 7699, Reward: [-492.637 -492.637 -492.637] [0.0000], Avg: [-495.428 -495.428 -495.428] (0.462)
Step: 7749, Reward: [-460.201 -460.201 -460.201] [0.0000], Avg: [-495.201 -495.201 -495.201] (0.460)
Step: 7799, Reward: [-297.453 -297.453 -297.453] [0.0000], Avg: [-493.933 -493.933 -493.933] (0.458)
Step: 7849, Reward: [-519.698 -519.698 -519.698] [0.0000], Avg: [-494.097 -494.097 -494.097] (0.455)
Step: 7899, Reward: [-462.381 -462.381 -462.381] [0.0000], Avg: [-493.897 -493.897 -493.897] (0.453)
Step: 7949, Reward: [-490.219 -490.219 -490.219] [0.0000], Avg: [-493.874 -493.874 -493.874] (0.451)
Step: 7999, Reward: [-437.116 -437.116 -437.116] [0.0000], Avg: [-493.519 -493.519 -493.519] (0.448)
Step: 8049, Reward: [-542.852 -542.852 -542.852] [0.0000], Avg: [-493.825 -493.825 -493.825] (0.446)
Step: 8099, Reward: [-667.175 -667.175 -667.175] [0.0000], Avg: [-494.895 -494.895 -494.895] (0.444)
Step: 8149, Reward: [-693.991 -693.991 -693.991] [0.0000], Avg: [-496.117 -496.117 -496.117] (0.442)
Step: 8199, Reward: [-405.116 -405.116 -405.116] [0.0000], Avg: [-495.562 -495.562 -495.562] (0.440)
Step: 8249, Reward: [-435.634 -435.634 -435.634] [0.0000], Avg: [-495.199 -495.199 -495.199] (0.437)
Step: 8299, Reward: [-405.854 -405.854 -405.854] [0.0000], Avg: [-494.66 -494.66 -494.66] (0.435)
Step: 8349, Reward: [-410.709 -410.709 -410.709] [0.0000], Avg: [-494.158 -494.158 -494.158] (0.433)
Step: 8399, Reward: [-524.765 -524.765 -524.765] [0.0000], Avg: [-494.34 -494.34 -494.34] (0.431)
Step: 8449, Reward: [-449.22 -449.22 -449.22] [0.0000], Avg: [-494.073 -494.073 -494.073] (0.429)
Step: 8499, Reward: [-396.814 -396.814 -396.814] [0.0000], Avg: [-493.501 -493.501 -493.501] (0.427)
Step: 8549, Reward: [-400.174 -400.174 -400.174] [0.0000], Avg: [-492.955 -492.955 -492.955] (0.424)
Step: 8599, Reward: [-648.769 -648.769 -648.769] [0.0000], Avg: [-493.861 -493.861 -493.861] (0.422)
Step: 8649, Reward: [-684.211 -684.211 -684.211] [0.0000], Avg: [-494.961 -494.961 -494.961] (0.420)
Step: 8699, Reward: [-359.252 -359.252 -359.252] [0.0000], Avg: [-494.181 -494.181 -494.181] (0.418)
Step: 8749, Reward: [-460.525 -460.525 -460.525] [0.0000], Avg: [-493.989 -493.989 -493.989] (0.416)
Step: 8799, Reward: [-324.309 -324.309 -324.309] [0.0000], Avg: [-493.025 -493.025 -493.025] (0.414)
Step: 8849, Reward: [-706.556 -706.556 -706.556] [0.0000], Avg: [-494.231 -494.231 -494.231] (0.412)
Step: 8899, Reward: [-518.039 -518.039 -518.039] [0.0000], Avg: [-494.365 -494.365 -494.365] (0.410)
Step: 8949, Reward: [-425.567 -425.567 -425.567] [0.0000], Avg: [-493.981 -493.981 -493.981] (0.408)
Step: 8999, Reward: [-403.793 -403.793 -403.793] [0.0000], Avg: [-493.48 -493.48 -493.48] (0.406)
Step: 9049, Reward: [-369.427 -369.427 -369.427] [0.0000], Avg: [-492.794 -492.794 -492.794] (0.404)
Step: 9099, Reward: [-382.885 -382.885 -382.885] [0.0000], Avg: [-492.19 -492.19 -492.19] (0.402)
Step: 9149, Reward: [-439.707 -439.707 -439.707] [0.0000], Avg: [-491.904 -491.904 -491.904] (0.400)
Step: 9199, Reward: [-534.968 -534.968 -534.968] [0.0000], Avg: [-492.138 -492.138 -492.138] (0.398)
Step: 9249, Reward: [-339.879 -339.879 -339.879] [0.0000], Avg: [-491.315 -491.315 -491.315] (0.396)
Step: 9299, Reward: [-496.56 -496.56 -496.56] [0.0000], Avg: [-491.343 -491.343 -491.343] (0.394)
Step: 9349, Reward: [-610.901 -610.901 -610.901] [0.0000], Avg: [-491.982 -491.982 -491.982] (0.392)
Step: 9399, Reward: [-449.231 -449.231 -449.231] [0.0000], Avg: [-491.755 -491.755 -491.755] (0.390)
Step: 9449, Reward: [-481.811 -481.811 -481.811] [0.0000], Avg: [-491.702 -491.702 -491.702] (0.388)
Step: 9499, Reward: [-533.78 -533.78 -533.78] [0.0000], Avg: [-491.924 -491.924 -491.924] (0.386)
Step: 9549, Reward: [-682.36 -682.36 -682.36] [0.0000], Avg: [-492.921 -492.921 -492.921] (0.384)
Step: 9599, Reward: [-633.548 -633.548 -633.548] [0.0000], Avg: [-493.653 -493.653 -493.653] (0.382)
Step: 9649, Reward: [-347.642 -347.642 -347.642] [0.0000], Avg: [-492.897 -492.897 -492.897] (0.380)
Step: 9699, Reward: [-457.717 -457.717 -457.717] [0.0000], Avg: [-492.715 -492.715 -492.715] (0.378)
Step: 9749, Reward: [-561.414 -561.414 -561.414] [0.0000], Avg: [-493.068 -493.068 -493.068] (0.376)
Step: 9799, Reward: [-509.529 -509.529 -509.529] [0.0000], Avg: [-493.151 -493.151 -493.151] (0.374)
Step: 9849, Reward: [-547.066 -547.066 -547.066] [0.0000], Avg: [-493.425 -493.425 -493.425] (0.373)
Step: 9899, Reward: [-346.066 -346.066 -346.066] [0.0000], Avg: [-492.681 -492.681 -492.681] (0.371)
Step: 9949, Reward: [-397.734 -397.734 -397.734] [0.0000], Avg: [-492.204 -492.204 -492.204] (0.369)
Step: 9999, Reward: [-502.189 -502.189 -502.189] [0.0000], Avg: [-492.254 -492.254 -492.254] (0.367)
Step: 10049, Reward: [-539.247 -539.247 -539.247] [0.0000], Avg: [-492.488 -492.488 -492.488] (0.365)
Step: 10099, Reward: [-409.327 -409.327 -409.327] [0.0000], Avg: [-492.076 -492.076 -492.076] (0.363)
Step: 10149, Reward: [-295.201 -295.201 -295.201] [0.0000], Avg: [-491.106 -491.106 -491.106] (0.361)
Step: 10199, Reward: [-536.548 -536.548 -536.548] [0.0000], Avg: [-491.329 -491.329 -491.329] (0.360)
Step: 10249, Reward: [-457.747 -457.747 -457.747] [0.0000], Avg: [-491.165 -491.165 -491.165] (0.358)
Step: 10299, Reward: [-448.632 -448.632 -448.632] [0.0000], Avg: [-490.958 -490.958 -490.958] (0.356)
Step: 10349, Reward: [-611.794 -611.794 -611.794] [0.0000], Avg: [-491.542 -491.542 -491.542] (0.354)
Step: 10399, Reward: [-406.14 -406.14 -406.14] [0.0000], Avg: [-491.132 -491.132 -491.132] (0.353)
Step: 10449, Reward: [-405.674 -405.674 -405.674] [0.0000], Avg: [-490.723 -490.723 -490.723] (0.351)
Step: 10499, Reward: [-423.833 -423.833 -423.833] [0.0000], Avg: [-490.404 -490.404 -490.404] (0.349)
Step: 10549, Reward: [-362.232 -362.232 -362.232] [0.0000], Avg: [-489.797 -489.797 -489.797] (0.347)
Step: 10599, Reward: [-397.095 -397.095 -397.095] [0.0000], Avg: [-489.36 -489.36 -489.36] (0.346)
Step: 10649, Reward: [-456.635 -456.635 -456.635] [0.0000], Avg: [-489.206 -489.206 -489.206] (0.344)
Step: 10699, Reward: [-473.84 -473.84 -473.84] [0.0000], Avg: [-489.134 -489.134 -489.134] (0.342)
Step: 10749, Reward: [-401.388 -401.388 -401.388] [0.0000], Avg: [-488.726 -488.726 -488.726] (0.340)
Step: 10799, Reward: [-428.941 -428.941 -428.941] [0.0000], Avg: [-488.449 -488.449 -488.449] (0.339)
Step: 10849, Reward: [-614.362 -614.362 -614.362] [0.0000], Avg: [-489.029 -489.029 -489.029] (0.337)
Step: 10899, Reward: [-505.326 -505.326 -505.326] [0.0000], Avg: [-489.104 -489.104 -489.104] (0.335)
Step: 10949, Reward: [-574.161 -574.161 -574.161] [0.0000], Avg: [-489.493 -489.493 -489.493] (0.334)
Step: 10999, Reward: [-295.794 -295.794 -295.794] [0.0000], Avg: [-488.612 -488.612 -488.612] (0.332)
Step: 11049, Reward: [-431.898 -431.898 -431.898] [0.0000], Avg: [-488.355 -488.355 -488.355] (0.330)
Step: 11099, Reward: [-476.754 -476.754 -476.754] [0.0000], Avg: [-488.303 -488.303 -488.303] (0.329)
Step: 11149, Reward: [-445.788 -445.788 -445.788] [0.0000], Avg: [-488.113 -488.113 -488.113] (0.327)
Step: 11199, Reward: [-459.906 -459.906 -459.906] [0.0000], Avg: [-487.987 -487.987 -487.987] (0.325)
Step: 11249, Reward: [-450.506 -450.506 -450.506] [0.0000], Avg: [-487.82 -487.82 -487.82] (0.324)
Step: 11299, Reward: [-747.225 -747.225 -747.225] [0.0000], Avg: [-488.968 -488.968 -488.968] (0.322)
Step: 11349, Reward: [-367.175 -367.175 -367.175] [0.0000], Avg: [-488.431 -488.431 -488.431] (0.321)
Step: 11399, Reward: [-378.063 -378.063 -378.063] [0.0000], Avg: [-487.947 -487.947 -487.947] (0.319)
Step: 11449, Reward: [-446.885 -446.885 -446.885] [0.0000], Avg: [-487.768 -487.768 -487.768] (0.317)
Step: 11499, Reward: [-416.191 -416.191 -416.191] [0.0000], Avg: [-487.457 -487.457 -487.457] (0.316)
Step: 11549, Reward: [-405.243 -405.243 -405.243] [0.0000], Avg: [-487.101 -487.101 -487.101] (0.314)
Step: 11599, Reward: [-425.346 -425.346 -425.346] [0.0000], Avg: [-486.835 -486.835 -486.835] (0.313)
Step: 11649, Reward: [-286.525 -286.525 -286.525] [0.0000], Avg: [-485.975 -485.975 -485.975] (0.311)
Step: 11699, Reward: [-505.07 -505.07 -505.07] [0.0000], Avg: [-486.057 -486.057 -486.057] (0.309)
Step: 11749, Reward: [-408.573 -408.573 -408.573] [0.0000], Avg: [-485.727 -485.727 -485.727] (0.308)
Step: 11799, Reward: [-525.312 -525.312 -525.312] [0.0000], Avg: [-485.895 -485.895 -485.895] (0.306)
Step: 11849, Reward: [-471.202 -471.202 -471.202] [0.0000], Avg: [-485.833 -485.833 -485.833] (0.305)
Step: 11899, Reward: [-485.059 -485.059 -485.059] [0.0000], Avg: [-485.829 -485.829 -485.829] (0.303)
Step: 11949, Reward: [-569.219 -569.219 -569.219] [0.0000], Avg: [-486.178 -486.178 -486.178] (0.302)
Step: 11999, Reward: [-447.826 -447.826 -447.826] [0.0000], Avg: [-486.018 -486.018 -486.018] (0.300)
Step: 12049, Reward: [-416.321 -416.321 -416.321] [0.0000], Avg: [-485.729 -485.729 -485.729] (0.299)
Step: 12099, Reward: [-423.658 -423.658 -423.658] [0.0000], Avg: [-485.473 -485.473 -485.473] (0.297)
Step: 12149, Reward: [-466.39 -466.39 -466.39] [0.0000], Avg: [-485.394 -485.394 -485.394] (0.296)
Step: 12199, Reward: [-404.19 -404.19 -404.19] [0.0000], Avg: [-485.061 -485.061 -485.061] (0.294)
Step: 12249, Reward: [-542.179 -542.179 -542.179] [0.0000], Avg: [-485.295 -485.295 -485.295] (0.293)
Step: 12299, Reward: [-331.527 -331.527 -331.527] [0.0000], Avg: [-484.669 -484.669 -484.669] (0.291)
Step: 12349, Reward: [-458.252 -458.252 -458.252] [0.0000], Avg: [-484.563 -484.563 -484.563] (0.290)
Step: 12399, Reward: [-479.292 -479.292 -479.292] [0.0000], Avg: [-484.541 -484.541 -484.541] (0.288)
Step: 12449, Reward: [-457.27 -457.27 -457.27] [0.0000], Avg: [-484.432 -484.432 -484.432] (0.287)
Step: 12499, Reward: [-349.336 -349.336 -349.336] [0.0000], Avg: [-483.891 -483.891 -483.891] (0.286)
Step: 12549, Reward: [-394.34 -394.34 -394.34] [0.0000], Avg: [-483.535 -483.535 -483.535] (0.284)
Step: 12599, Reward: [-352.601 -352.601 -352.601] [0.0000], Avg: [-483.015 -483.015 -483.015] (0.283)
Step: 12649, Reward: [-434.574 -434.574 -434.574] [0.0000], Avg: [-482.824 -482.824 -482.824] (0.281)
Step: 12699, Reward: [-454.763 -454.763 -454.763] [0.0000], Avg: [-482.713 -482.713 -482.713] (0.280)
Step: 12749, Reward: [-319.523 -319.523 -319.523] [0.0000], Avg: [-482.073 -482.073 -482.073] (0.279)
Step: 12799, Reward: [-381.447 -381.447 -381.447] [0.0000], Avg: [-481.68 -481.68 -481.68] (0.277)
Step: 12849, Reward: [-439.712 -439.712 -439.712] [0.0000], Avg: [-481.517 -481.517 -481.517] (0.276)
Step: 12899, Reward: [-567.169 -567.169 -567.169] [0.0000], Avg: [-481.849 -481.849 -481.849] (0.274)
Step: 12949, Reward: [-321.718 -321.718 -321.718] [0.0000], Avg: [-481.23 -481.23 -481.23] (0.273)
Step: 12999, Reward: [-415.315 -415.315 -415.315] [0.0000], Avg: [-480.977 -480.977 -480.977] (0.272)
Step: 13049, Reward: [-629.335 -629.335 -629.335] [0.0000], Avg: [-481.545 -481.545 -481.545] (0.270)
Step: 13099, Reward: [-382.181 -382.181 -382.181] [0.0000], Avg: [-481.166 -481.166 -481.166] (0.269)
Step: 13149, Reward: [-454.323 -454.323 -454.323] [0.0000], Avg: [-481.064 -481.064 -481.064] (0.268)
Step: 13199, Reward: [-467.709 -467.709 -467.709] [0.0000], Avg: [-481.013 -481.013 -481.013] (0.266)
Step: 13249, Reward: [-466.278 -466.278 -466.278] [0.0000], Avg: [-480.958 -480.958 -480.958] (0.265)
Step: 13299, Reward: [-376.117 -376.117 -376.117] [0.0000], Avg: [-480.564 -480.564 -480.564] (0.264)
Step: 13349, Reward: [-460.806 -460.806 -460.806] [0.0000], Avg: [-480.49 -480.49 -480.49] (0.262)
Step: 13399, Reward: [-514.532 -514.532 -514.532] [0.0000], Avg: [-480.617 -480.617 -480.617] (0.261)
Step: 13449, Reward: [-306.203 -306.203 -306.203] [0.0000], Avg: [-479.968 -479.968 -479.968] (0.260)
Step: 13499, Reward: [-396.21 -396.21 -396.21] [0.0000], Avg: [-479.658 -479.658 -479.658] (0.258)
Step: 13549, Reward: [-378.559 -378.559 -378.559] [0.0000], Avg: [-479.285 -479.285 -479.285] (0.257)
Step: 13599, Reward: [-416.767 -416.767 -416.767] [0.0000], Avg: [-479.055 -479.055 -479.055] (0.256)
Step: 13649, Reward: [-508.311 -508.311 -508.311] [0.0000], Avg: [-479.162 -479.162 -479.162] (0.255)
Step: 13699, Reward: [-353.13 -353.13 -353.13] [0.0000], Avg: [-478.702 -478.702 -478.702] (0.253)
Step: 13749, Reward: [-483.624 -483.624 -483.624] [0.0000], Avg: [-478.72 -478.72 -478.72] (0.252)
Step: 13799, Reward: [-494.443 -494.443 -494.443] [0.0000], Avg: [-478.777 -478.777 -478.777] (0.251)
Step: 13849, Reward: [-474.898 -474.898 -474.898] [0.0000], Avg: [-478.763 -478.763 -478.763] (0.249)
Step: 13899, Reward: [-434.834 -434.834 -434.834] [0.0000], Avg: [-478.605 -478.605 -478.605] (0.248)
Step: 13949, Reward: [-418.756 -418.756 -418.756] [0.0000], Avg: [-478.391 -478.391 -478.391] (0.247)
Step: 13999, Reward: [-425.98 -425.98 -425.98] [0.0000], Avg: [-478.204 -478.204 -478.204] (0.246)
Step: 14049, Reward: [-354.136 -354.136 -354.136] [0.0000], Avg: [-477.762 -477.762 -477.762] (0.245)
Step: 14099, Reward: [-450.176 -450.176 -450.176] [0.0000], Avg: [-477.664 -477.664 -477.664] (0.243)
Step: 14149, Reward: [-578.469 -578.469 -578.469] [0.0000], Avg: [-478.02 -478.02 -478.02] (0.242)
Step: 14199, Reward: [-515.991 -515.991 -515.991] [0.0000], Avg: [-478.154 -478.154 -478.154] (0.241)
Step: 14249, Reward: [-592.649 -592.649 -592.649] [0.0000], Avg: [-478.556 -478.556 -478.556] (0.240)
Step: 14299, Reward: [-389.074 -389.074 -389.074] [0.0000], Avg: [-478.243 -478.243 -478.243] (0.238)
Step: 14349, Reward: [-505.931 -505.931 -505.931] [0.0000], Avg: [-478.339 -478.339 -478.339] (0.237)
Step: 14399, Reward: [-457.675 -457.675 -457.675] [0.0000], Avg: [-478.268 -478.268 -478.268] (0.236)
Step: 14449, Reward: [-550.078 -550.078 -550.078] [0.0000], Avg: [-478.516 -478.516 -478.516] (0.235)
Step: 14499, Reward: [-340.855 -340.855 -340.855] [0.0000], Avg: [-478.042 -478.042 -478.042] (0.234)
Step: 14549, Reward: [-555.711 -555.711 -555.711] [0.0000], Avg: [-478.308 -478.308 -478.308] (0.233)
Step: 14599, Reward: [-481.183 -481.183 -481.183] [0.0000], Avg: [-478.318 -478.318 -478.318] (0.231)
Step: 14649, Reward: [-426.651 -426.651 -426.651] [0.0000], Avg: [-478.142 -478.142 -478.142] (0.230)
Step: 14699, Reward: [-495.024 -495.024 -495.024] [0.0000], Avg: [-478.199 -478.199 -478.199] (0.229)
Step: 14749, Reward: [-717.804 -717.804 -717.804] [0.0000], Avg: [-479.012 -479.012 -479.012] (0.228)
Step: 14799, Reward: [-378.609 -378.609 -378.609] [0.0000], Avg: [-478.672 -478.672 -478.672] (0.227)
Step: 14849, Reward: [-421.807 -421.807 -421.807] [0.0000], Avg: [-478.481 -478.481 -478.481] (0.226)
Step: 14899, Reward: [-525.634 -525.634 -525.634] [0.0000], Avg: [-478.639 -478.639 -478.639] (0.225)
Step: 14949, Reward: [-542.182 -542.182 -542.182] [0.0000], Avg: [-478.852 -478.852 -478.852] (0.223)
Step: 14999, Reward: [-429.009 -429.009 -429.009] [0.0000], Avg: [-478.686 -478.686 -478.686] (0.222)
Step: 15049, Reward: [-441.982 -441.982 -441.982] [0.0000], Avg: [-478.564 -478.564 -478.564] (0.221)
Step: 15099, Reward: [-552.598 -552.598 -552.598] [0.0000], Avg: [-478.809 -478.809 -478.809] (0.220)
Step: 15149, Reward: [-534.065 -534.065 -534.065] [0.0000], Avg: [-478.991 -478.991 -478.991] (0.219)
Step: 15199, Reward: [-451.88 -451.88 -451.88] [0.0000], Avg: [-478.902 -478.902 -478.902] (0.218)
Step: 15249, Reward: [-550.54 -550.54 -550.54] [0.0000], Avg: [-479.137 -479.137 -479.137] (0.217)
Step: 15299, Reward: [-379.68 -379.68 -379.68] [0.0000], Avg: [-478.812 -478.812 -478.812] (0.216)
Step: 15349, Reward: [-416.157 -416.157 -416.157] [0.0000], Avg: [-478.608 -478.608 -478.608] (0.215)
Step: 15399, Reward: [-418.395 -418.395 -418.395] [0.0000], Avg: [-478.412 -478.412 -478.412] (0.214)
Step: 15449, Reward: [-397.773 -397.773 -397.773] [0.0000], Avg: [-478.151 -478.151 -478.151] (0.212)
Step: 15499, Reward: [-346.132 -346.132 -346.132] [0.0000], Avg: [-477.725 -477.725 -477.725] (0.211)
Step: 15549, Reward: [-402.91 -402.91 -402.91] [0.0000], Avg: [-477.485 -477.485 -477.485] (0.210)
Step: 15599, Reward: [-503.095 -503.095 -503.095] [0.0000], Avg: [-477.567 -477.567 -477.567] (0.209)
Step: 15649, Reward: [-321.103 -321.103 -321.103] [0.0000], Avg: [-477.067 -477.067 -477.067] (0.208)
Step: 15699, Reward: [-423.281 -423.281 -423.281] [0.0000], Avg: [-476.896 -476.896 -476.896] (0.207)
Step: 15749, Reward: [-371.157 -371.157 -371.157] [0.0000], Avg: [-476.56 -476.56 -476.56] (0.206)
Step: 15799, Reward: [-373.247 -373.247 -373.247] [0.0000], Avg: [-476.233 -476.233 -476.233] (0.205)
Step: 15849, Reward: [-398.401 -398.401 -398.401] [0.0000], Avg: [-475.988 -475.988 -475.988] (0.204)
Step: 15899, Reward: [-455.864 -455.864 -455.864] [0.0000], Avg: [-475.924 -475.924 -475.924] (0.203)
Step: 15949, Reward: [-370.534 -370.534 -370.534] [0.0000], Avg: [-475.594 -475.594 -475.594] (0.202)
Step: 15999, Reward: [-479.341 -479.341 -479.341] [0.0000], Avg: [-475.606 -475.606 -475.606] (0.201)
Step: 16049, Reward: [-387.163 -387.163 -387.163] [0.0000], Avg: [-475.33 -475.33 -475.33] (0.200)
Step: 16099, Reward: [-378.384 -378.384 -378.384] [0.0000], Avg: [-475.029 -475.029 -475.029] (0.199)
Step: 16149, Reward: [-505.218 -505.218 -505.218] [0.0000], Avg: [-475.122 -475.122 -475.122] (0.198)
Step: 16199, Reward: [-402.551 -402.551 -402.551] [0.0000], Avg: [-474.898 -474.898 -474.898] (0.197)
Step: 16249, Reward: [-456.669 -456.669 -456.669] [0.0000], Avg: [-474.842 -474.842 -474.842] (0.196)
Step: 16299, Reward: [-531.163 -531.163 -531.163] [0.0000], Avg: [-475.015 -475.015 -475.015] (0.195)
Step: 16349, Reward: [-401.059 -401.059 -401.059] [0.0000], Avg: [-474.789 -474.789 -474.789] (0.194)
Step: 16399, Reward: [-490.041 -490.041 -490.041] [0.0000], Avg: [-474.835 -474.835 -474.835] (0.193)
Step: 16449, Reward: [-350.84 -350.84 -350.84] [0.0000], Avg: [-474.459 -474.459 -474.459] (0.192)
Step: 16499, Reward: [-302.03 -302.03 -302.03] [0.0000], Avg: [-473.936 -473.936 -473.936] (0.191)
Step: 16549, Reward: [-419.588 -419.588 -419.588] [0.0000], Avg: [-473.772 -473.772 -473.772] (0.190)
Step: 16599, Reward: [-309.41 -309.41 -309.41] [0.0000], Avg: [-473.277 -473.277 -473.277] (0.189)
Step: 16649, Reward: [-548.754 -548.754 -548.754] [0.0000], Avg: [-473.503 -473.503 -473.503] (0.188)
Step: 16699, Reward: [-375.635 -375.635 -375.635] [0.0000], Avg: [-473.21 -473.21 -473.21] (0.187)
Step: 16749, Reward: [-410.827 -410.827 -410.827] [0.0000], Avg: [-473.024 -473.024 -473.024] (0.187)
Step: 16799, Reward: [-472.983 -472.983 -472.983] [0.0000], Avg: [-473.024 -473.024 -473.024] (0.186)
Step: 16849, Reward: [-378.487 -378.487 -378.487] [0.0000], Avg: [-472.744 -472.744 -472.744] (0.185)
Step: 16899, Reward: [-348.432 -348.432 -348.432] [0.0000], Avg: [-472.376 -472.376 -472.376] (0.184)
Step: 16949, Reward: [-531.14 -531.14 -531.14] [0.0000], Avg: [-472.549 -472.549 -472.549] (0.183)
Step: 16999, Reward: [-637.229 -637.229 -637.229] [0.0000], Avg: [-473.033 -473.033 -473.033] (0.182)
Step: 17049, Reward: [-312.048 -312.048 -312.048] [0.0000], Avg: [-472.561 -472.561 -472.561] (0.181)
Step: 17099, Reward: [-369.332 -369.332 -369.332] [0.0000], Avg: [-472.26 -472.26 -472.26] (0.180)
Step: 17149, Reward: [-422.123 -422.123 -422.123] [0.0000], Avg: [-472.113 -472.113 -472.113] (0.179)
Step: 17199, Reward: [-506.898 -506.898 -506.898] [0.0000], Avg: [-472.215 -472.215 -472.215] (0.178)
Step: 17249, Reward: [-359.062 -359.062 -359.062] [0.0000], Avg: [-471.887 -471.887 -471.887] (0.177)
Step: 17299, Reward: [-388.345 -388.345 -388.345] [0.0000], Avg: [-471.645 -471.645 -471.645] (0.177)
Step: 17349, Reward: [-346.072 -346.072 -346.072] [0.0000], Avg: [-471.283 -471.283 -471.283] (0.176)
Step: 17399, Reward: [-587.05 -587.05 -587.05] [0.0000], Avg: [-471.616 -471.616 -471.616] (0.175)
Step: 17449, Reward: [-376.396 -376.396 -376.396] [0.0000], Avg: [-471.343 -471.343 -471.343] (0.174)
Step: 17499, Reward: [-429.183 -429.183 -429.183] [0.0000], Avg: [-471.223 -471.223 -471.223] (0.173)
Step: 17549, Reward: [-479.37 -479.37 -479.37] [0.0000], Avg: [-471.246 -471.246 -471.246] (0.172)
Step: 17599, Reward: [-495.498 -495.498 -495.498] [0.0000], Avg: [-471.315 -471.315 -471.315] (0.171)
Step: 17649, Reward: [-432.113 -432.113 -432.113] [0.0000], Avg: [-471.204 -471.204 -471.204] (0.170)
Step: 17699, Reward: [-480.871 -480.871 -480.871] [0.0000], Avg: [-471.231 -471.231 -471.231] (0.170)
Step: 17749, Reward: [-514.012 -514.012 -514.012] [0.0000], Avg: [-471.351 -471.351 -471.351] (0.169)
Step: 17799, Reward: [-524.354 -524.354 -524.354] [0.0000], Avg: [-471.5 -471.5 -471.5] (0.168)
Step: 17849, Reward: [-300.26 -300.26 -300.26] [0.0000], Avg: [-471.021 -471.021 -471.021] (0.167)
Step: 17899, Reward: [-244.458 -244.458 -244.458] [0.0000], Avg: [-470.388 -470.388 -470.388] (0.166)
Step: 17949, Reward: [-413.668 -413.668 -413.668] [0.0000], Avg: [-470.23 -470.23 -470.23] (0.165)
Step: 17999, Reward: [-364.424 -364.424 -364.424] [0.0000], Avg: [-469.936 -469.936 -469.936] (0.165)
Step: 18049, Reward: [-481.748 -481.748 -481.748] [0.0000], Avg: [-469.969 -469.969 -469.969] (0.164)
Step: 18099, Reward: [-471.171 -471.171 -471.171] [0.0000], Avg: [-469.972 -469.972 -469.972] (0.163)
Step: 18149, Reward: [-412.122 -412.122 -412.122] [0.0000], Avg: [-469.813 -469.813 -469.813] (0.162)
Step: 18199, Reward: [-679.51 -679.51 -679.51] [0.0000], Avg: [-470.389 -470.389 -470.389] (0.161)
Step: 18249, Reward: [-457.864 -457.864 -457.864] [0.0000], Avg: [-470.354 -470.354 -470.354] (0.160)
Step: 18299, Reward: [-413.943 -413.943 -413.943] [0.0000], Avg: [-470.2 -470.2 -470.2] (0.160)
Step: 18349, Reward: [-357.295 -357.295 -357.295] [0.0000], Avg: [-469.893 -469.893 -469.893] (0.159)
Step: 18399, Reward: [-420.269 -420.269 -420.269] [0.0000], Avg: [-469.758 -469.758 -469.758] (0.158)
Step: 18449, Reward: [-413.504 -413.504 -413.504] [0.0000], Avg: [-469.605 -469.605 -469.605] (0.157)
Step: 18499, Reward: [-417.521 -417.521 -417.521] [0.0000], Avg: [-469.465 -469.465 -469.465] (0.157)
Step: 18549, Reward: [-453.361 -453.361 -453.361] [0.0000], Avg: [-469.421 -469.421 -469.421] (0.156)
Step: 18599, Reward: [-379.97 -379.97 -379.97] [0.0000], Avg: [-469.181 -469.181 -469.181] (0.155)
Step: 18649, Reward: [-523.655 -523.655 -523.655] [0.0000], Avg: [-469.327 -469.327 -469.327] (0.154)
Step: 18699, Reward: [-412.503 -412.503 -412.503] [0.0000], Avg: [-469.175 -469.175 -469.175] (0.153)
Step: 18749, Reward: [-458.047 -458.047 -458.047] [0.0000], Avg: [-469.145 -469.145 -469.145] (0.153)
Step: 18799, Reward: [-361.621 -361.621 -361.621] [0.0000], Avg: [-468.859 -468.859 -468.859] (0.152)
Step: 18849, Reward: [-361.655 -361.655 -361.655] [0.0000], Avg: [-468.575 -468.575 -468.575] (0.151)
Step: 18899, Reward: [-465.517 -465.517 -465.517] [0.0000], Avg: [-468.567 -468.567 -468.567] (0.150)
Step: 18949, Reward: [-234.902 -234.902 -234.902] [0.0000], Avg: [-467.95 -467.95 -467.95] (0.150)
Step: 18999, Reward: [-570.65 -570.65 -570.65] [0.0000], Avg: [-468.22 -468.22 -468.22] (0.149)
Step: 19049, Reward: [-501.083 -501.083 -501.083] [0.0000], Avg: [-468.307 -468.307 -468.307] (0.148)
Step: 19099, Reward: [-297.018 -297.018 -297.018] [0.0000], Avg: [-467.858 -467.858 -467.858] (0.147)
Step: 19149, Reward: [-454.015 -454.015 -454.015] [0.0000], Avg: [-467.822 -467.822 -467.822] (0.147)
Step: 19199, Reward: [-388.979 -388.979 -388.979] [0.0000], Avg: [-467.617 -467.617 -467.617] (0.146)
Step: 19249, Reward: [-498.014 -498.014 -498.014] [0.0000], Avg: [-467.696 -467.696 -467.696] (0.145)
Step: 19299, Reward: [-430.724 -430.724 -430.724] [0.0000], Avg: [-467.6 -467.6 -467.6] (0.144)
Step: 19349, Reward: [-574.981 -574.981 -574.981] [0.0000], Avg: [-467.877 -467.877 -467.877] (0.144)
Step: 19399, Reward: [-465.544 -465.544 -465.544] [0.0000], Avg: [-467.871 -467.871 -467.871] (0.143)
Step: 19449, Reward: [-404.512 -404.512 -404.512] [0.0000], Avg: [-467.709 -467.709 -467.709] (0.142)
Step: 19499, Reward: [-437.496 -437.496 -437.496] [0.0000], Avg: [-467.631 -467.631 -467.631] (0.142)
Step: 19549, Reward: [-380.378 -380.378 -380.378] [0.0000], Avg: [-467.408 -467.408 -467.408] (0.141)
Step: 19599, Reward: [-383.136 -383.136 -383.136] [0.0000], Avg: [-467.193 -467.193 -467.193] (0.140)
Step: 19649, Reward: [-495.987 -495.987 -495.987] [0.0000], Avg: [-467.266 -467.266 -467.266] (0.139)
Step: 19699, Reward: [-427.612 -427.612 -427.612] [0.0000], Avg: [-467.166 -467.166 -467.166] (0.139)
Step: 19749, Reward: [-534.074 -534.074 -534.074] [0.0000], Avg: [-467.335 -467.335 -467.335] (0.138)
Step: 19799, Reward: [-232.192 -232.192 -232.192] [0.0000], Avg: [-466.741 -466.741 -466.741] (0.137)
Step: 19849, Reward: [-383.056 -383.056 -383.056] [0.0000], Avg: [-466.53 -466.53 -466.53] (0.137)
Step: 19899, Reward: [-478.466 -478.466 -478.466] [0.0000], Avg: [-466.56 -466.56 -466.56] (0.136)
Step: 19949, Reward: [-517.815 -517.815 -517.815] [0.0000], Avg: [-466.689 -466.689 -466.689] (0.135)
Step: 19999, Reward: [-367.799 -367.799 -367.799] [0.0000], Avg: [-466.442 -466.442 -466.442] (0.135)
Step: 20049, Reward: [-361.235 -361.235 -361.235] [0.0000], Avg: [-466.179 -466.179 -466.179] (0.134)
Step: 20099, Reward: [-282.514 -282.514 -282.514] [0.0000], Avg: [-465.722 -465.722 -465.722] (0.133)
Step: 20149, Reward: [-564.604 -564.604 -564.604] [0.0000], Avg: [-465.968 -465.968 -465.968] (0.133)
Step: 20199, Reward: [-345.066 -345.066 -345.066] [0.0000], Avg: [-465.668 -465.668 -465.668] (0.132)
Step: 20249, Reward: [-369.122 -369.122 -369.122] [0.0000], Avg: [-465.43 -465.43 -465.43] (0.131)
Step: 20299, Reward: [-434.287 -434.287 -434.287] [0.0000], Avg: [-465.353 -465.353 -465.353] (0.131)
Step: 20349, Reward: [-453.905 -453.905 -453.905] [0.0000], Avg: [-465.325 -465.325 -465.325] (0.130)
Step: 20399, Reward: [-352.389 -352.389 -352.389] [0.0000], Avg: [-465.048 -465.048 -465.048] (0.129)
Step: 20449, Reward: [-532.836 -532.836 -532.836] [0.0000], Avg: [-465.214 -465.214 -465.214] (0.129)
Step: 20499, Reward: [-430.226 -430.226 -430.226] [0.0000], Avg: [-465.129 -465.129 -465.129] (0.128)
Step: 20549, Reward: [-448.065 -448.065 -448.065] [0.0000], Avg: [-465.087 -465.087 -465.087] (0.127)
Step: 20599, Reward: [-402.047 -402.047 -402.047] [0.0000], Avg: [-464.934 -464.934 -464.934] (0.127)
Step: 20649, Reward: [-369.867 -369.867 -369.867] [0.0000], Avg: [-464.704 -464.704 -464.704] (0.126)
Step: 20699, Reward: [-400.928 -400.928 -400.928] [0.0000], Avg: [-464.55 -464.55 -464.55] (0.126)
Step: 20749, Reward: [-428.436 -428.436 -428.436] [0.0000], Avg: [-464.463 -464.463 -464.463] (0.125)
Step: 20799, Reward: [-355.671 -355.671 -355.671] [0.0000], Avg: [-464.202 -464.202 -464.202] (0.124)
Step: 20849, Reward: [-288.5 -288.5 -288.5] [0.0000], Avg: [-463.78 -463.78 -463.78] (0.124)
Step: 20899, Reward: [-628.097 -628.097 -628.097] [0.0000], Avg: [-464.173 -464.173 -464.173] (0.123)
Step: 20949, Reward: [-574.791 -574.791 -574.791] [0.0000], Avg: [-464.437 -464.437 -464.437] (0.122)
Step: 20999, Reward: [-426.561 -426.561 -426.561] [0.0000], Avg: [-464.347 -464.347 -464.347] (0.122)
Step: 21049, Reward: [-328.18 -328.18 -328.18] [0.0000], Avg: [-464.024 -464.024 -464.024] (0.121)
Step: 21099, Reward: [-431.207 -431.207 -431.207] [0.0000], Avg: [-463.946 -463.946 -463.946] (0.121)
Step: 21149, Reward: [-344.26 -344.26 -344.26] [0.0000], Avg: [-463.663 -463.663 -463.663] (0.120)
Step: 21199, Reward: [-316.484 -316.484 -316.484] [0.0000], Avg: [-463.316 -463.316 -463.316] (0.119)
Step: 21249, Reward: [-490.933 -490.933 -490.933] [0.0000], Avg: [-463.381 -463.381 -463.381] (0.119)
Step: 21299, Reward: [-452.975 -452.975 -452.975] [0.0000], Avg: [-463.356 -463.356 -463.356] (0.118)
Step: 21349, Reward: [-392.648 -392.648 -392.648] [0.0000], Avg: [-463.191 -463.191 -463.191] (0.118)
Step: 21399, Reward: [-511.413 -511.413 -511.413] [0.0000], Avg: [-463.303 -463.303 -463.303] (0.117)
Step: 21449, Reward: [-546.037 -546.037 -546.037] [0.0000], Avg: [-463.496 -463.496 -463.496] (0.116)
Step: 21499, Reward: [-410.766 -410.766 -410.766] [0.0000], Avg: [-463.374 -463.374 -463.374] (0.116)
Step: 21549, Reward: [-572.269 -572.269 -572.269] [0.0000], Avg: [-463.626 -463.626 -463.626] (0.115)
Step: 21599, Reward: [-438.57 -438.57 -438.57] [0.0000], Avg: [-463.568 -463.568 -463.568] (0.115)
Step: 21649, Reward: [-410.019 -410.019 -410.019] [0.0000], Avg: [-463.445 -463.445 -463.445] (0.114)
Step: 21699, Reward: [-295.089 -295.089 -295.089] [0.0000], Avg: [-463.057 -463.057 -463.057] (0.114)
Step: 21749, Reward: [-365.382 -365.382 -365.382] [0.0000], Avg: [-462.832 -462.832 -462.832] (0.113)
Step: 21799, Reward: [-491.912 -491.912 -491.912] [0.0000], Avg: [-462.899 -462.899 -462.899] (0.112)
Step: 21849, Reward: [-511.886 -511.886 -511.886] [0.0000], Avg: [-463.011 -463.011 -463.011] (0.112)
Step: 21899, Reward: [-410.479 -410.479 -410.479] [0.0000], Avg: [-462.891 -462.891 -462.891] (0.111)
Step: 21949, Reward: [-371.055 -371.055 -371.055] [0.0000], Avg: [-462.682 -462.682 -462.682] (0.111)
Step: 21999, Reward: [-366.661 -366.661 -366.661] [0.0000], Avg: [-462.464 -462.464 -462.464] (0.110)
Step: 22049, Reward: [-369.656 -369.656 -369.656] [0.0000], Avg: [-462.253 -462.253 -462.253] (0.110)
Step: 22099, Reward: [-364.949 -364.949 -364.949] [0.0000], Avg: [-462.033 -462.033 -462.033] (0.109)
Step: 22149, Reward: [-364.583 -364.583 -364.583] [0.0000], Avg: [-461.813 -461.813 -461.813] (0.109)
Step: 22199, Reward: [-291.245 -291.245 -291.245] [0.0000], Avg: [-461.429 -461.429 -461.429] (0.108)
Step: 22249, Reward: [-374.727 -374.727 -374.727] [0.0000], Avg: [-461.234 -461.234 -461.234] (0.107)
Step: 22299, Reward: [-458.694 -458.694 -458.694] [0.0000], Avg: [-461.228 -461.228 -461.228] (0.107)
Step: 22349, Reward: [-356.476 -356.476 -356.476] [0.0000], Avg: [-460.994 -460.994 -460.994] (0.106)
Step: 22399, Reward: [-343.322 -343.322 -343.322] [0.0000], Avg: [-460.731 -460.731 -460.731] (0.106)
Step: 22449, Reward: [-589.658 -589.658 -589.658] [0.0000], Avg: [-461.019 -461.019 -461.019] (0.105)
Step: 22499, Reward: [-520.871 -520.871 -520.871] [0.0000], Avg: [-461.152 -461.152 -461.152] (0.105)
Step: 22549, Reward: [-550.097 -550.097 -550.097] [0.0000], Avg: [-461.349 -461.349 -461.349] (0.104)
Step: 22599, Reward: [-487.975 -487.975 -487.975] [0.0000], Avg: [-461.408 -461.408 -461.408] (0.104)
Step: 22649, Reward: [-600.326 -600.326 -600.326] [0.0000], Avg: [-461.714 -461.714 -461.714] (0.103)
Step: 22699, Reward: [-430.137 -430.137 -430.137] [0.0000], Avg: [-461.645 -461.645 -461.645] (0.103)
Step: 22749, Reward: [-353.787 -353.787 -353.787] [0.0000], Avg: [-461.408 -461.408 -461.408] (0.102)
Step: 22799, Reward: [-354.619 -354.619 -354.619] [0.0000], Avg: [-461.174 -461.174 -461.174] (0.102)
Step: 22849, Reward: [-378.145 -378.145 -378.145] [0.0000], Avg: [-460.992 -460.992 -460.992] (0.101)
Step: 22899, Reward: [-527.937 -527.937 -527.937] [0.0000], Avg: [-461.138 -461.138 -461.138] (0.101)
Step: 22949, Reward: [-396.735 -396.735 -396.735] [0.0000], Avg: [-460.998 -460.998 -460.998] (0.100)
Step: 22999, Reward: [-428.108 -428.108 -428.108] [0.0000], Avg: [-460.926 -460.926 -460.926] (0.100)
Step: 23049, Reward: [-407.635 -407.635 -407.635] [0.0000], Avg: [-460.811 -460.811 -460.811] (0.099)
Step: 23099, Reward: [-524.184 -524.184 -524.184] [0.0000], Avg: [-460.948 -460.948 -460.948] (0.099)
Step: 23149, Reward: [-455.471 -455.471 -455.471] [0.0000], Avg: [-460.936 -460.936 -460.936] (0.098)
Step: 23199, Reward: [-473.672 -473.672 -473.672] [0.0000], Avg: [-460.963 -460.963 -460.963] (0.098)
Step: 23249, Reward: [-513.982 -513.982 -513.982] [0.0000], Avg: [-461.077 -461.077 -461.077] (0.097)
Step: 23299, Reward: [-609.713 -609.713 -609.713] [0.0000], Avg: [-461.396 -461.396 -461.396] (0.097)
Step: 23349, Reward: [-361.516 -361.516 -361.516] [0.0000], Avg: [-461.182 -461.182 -461.182] (0.096)
Step: 23399, Reward: [-479.866 -479.866 -479.866] [0.0000], Avg: [-461.222 -461.222 -461.222] (0.096)
Step: 23449, Reward: [-446.918 -446.918 -446.918] [0.0000], Avg: [-461.192 -461.192 -461.192] (0.095)
Step: 23499, Reward: [-436.463 -436.463 -436.463] [0.0000], Avg: [-461.139 -461.139 -461.139] (0.095)
Step: 23549, Reward: [-510.098 -510.098 -510.098] [0.0000], Avg: [-461.243 -461.243 -461.243] (0.094)
Step: 23599, Reward: [-445.563 -445.563 -445.563] [0.0000], Avg: [-461.21 -461.21 -461.21] (0.094)
Step: 23649, Reward: [-566.578 -566.578 -566.578] [0.0000], Avg: [-461.433 -461.433 -461.433] (0.093)
Step: 23699, Reward: [-452.089 -452.089 -452.089] [0.0000], Avg: [-461.413 -461.413 -461.413] (0.093)
Step: 23749, Reward: [-297.282 -297.282 -297.282] [0.0000], Avg: [-461.068 -461.068 -461.068] (0.092)
Step: 23799, Reward: [-547.972 -547.972 -547.972] [0.0000], Avg: [-461.25 -461.25 -461.25] (0.092)
Step: 23849, Reward: [-458.425 -458.425 -458.425] [0.0000], Avg: [-461.244 -461.244 -461.244] (0.092)
Step: 23899, Reward: [-411.877 -411.877 -411.877] [0.0000], Avg: [-461.141 -461.141 -461.141] (0.091)
Step: 23949, Reward: [-407.167 -407.167 -407.167] [0.0000], Avg: [-461.028 -461.028 -461.028] (0.091)
Step: 23999, Reward: [-413.411 -413.411 -413.411] [0.0000], Avg: [-460.929 -460.929 -460.929] (0.090)
Step: 24049, Reward: [-586.069 -586.069 -586.069] [0.0000], Avg: [-461.189 -461.189 -461.189] (0.090)
Step: 24099, Reward: [-329.201 -329.201 -329.201] [0.0000], Avg: [-460.915 -460.915 -460.915] (0.089)
Step: 24149, Reward: [-564.669 -564.669 -564.669] [0.0000], Avg: [-461.13 -461.13 -461.13] (0.089)
Step: 24199, Reward: [-410.592 -410.592 -410.592] [0.0000], Avg: [-461.026 -461.026 -461.026] (0.088)
Step: 24249, Reward: [-661.014 -661.014 -661.014] [0.0000], Avg: [-461.438 -461.438 -461.438] (0.088)
Step: 24299, Reward: [-737.5 -737.5 -737.5] [0.0000], Avg: [-462.006 -462.006 -462.006] (0.088)
Step: 24349, Reward: [-457.518 -457.518 -457.518] [0.0000], Avg: [-461.997 -461.997 -461.997] (0.087)
Step: 24399, Reward: [-625.025 -625.025 -625.025] [0.0000], Avg: [-462.331 -462.331 -462.331] (0.087)
Step: 24449, Reward: [-508.315 -508.315 -508.315] [0.0000], Avg: [-462.425 -462.425 -462.425] (0.086)
Step: 24499, Reward: [-564.063 -564.063 -564.063] [0.0000], Avg: [-462.632 -462.632 -462.632] (0.086)
Step: 24549, Reward: [-399.592 -399.592 -399.592] [0.0000], Avg: [-462.504 -462.504 -462.504] (0.085)
Step: 24599, Reward: [-763.743 -763.743 -763.743] [0.0000], Avg: [-463.116 -463.116 -463.116] (0.085)
Step: 24649, Reward: [-440.18 -440.18 -440.18] [0.0000], Avg: [-463.07 -463.07 -463.07] (0.084)
Step: 24699, Reward: [-474.342 -474.342 -474.342] [0.0000], Avg: [-463.093 -463.093 -463.093] (0.084)
Step: 24749, Reward: [-403.321 -403.321 -403.321] [0.0000], Avg: [-462.972 -462.972 -462.972] (0.084)
Step: 24799, Reward: [-423.277 -423.277 -423.277] [0.0000], Avg: [-462.892 -462.892 -462.892] (0.083)
Step: 24849, Reward: [-397.35 -397.35 -397.35] [0.0000], Avg: [-462.76 -462.76 -462.76] (0.083)
Step: 24899, Reward: [-271.345 -271.345 -271.345] [0.0000], Avg: [-462.376 -462.376 -462.376] (0.082)
Step: 24949, Reward: [-447.032 -447.032 -447.032] [0.0000], Avg: [-462.345 -462.345 -462.345] (0.082)
Step: 24999, Reward: [-464.931 -464.931 -464.931] [0.0000], Avg: [-462.35 -462.35 -462.35] (0.082)
Step: 25049, Reward: [-346.319 -346.319 -346.319] [0.0000], Avg: [-462.118 -462.118 -462.118] (0.081)
Step: 25099, Reward: [-424.428 -424.428 -424.428] [0.0000], Avg: [-462.043 -462.043 -462.043] (0.081)
Step: 25149, Reward: [-386.086 -386.086 -386.086] [0.0000], Avg: [-461.892 -461.892 -461.892] (0.080)
Step: 25199, Reward: [-471.887 -471.887 -471.887] [0.0000], Avg: [-461.912 -461.912 -461.912] (0.080)
Step: 25249, Reward: [-522.913 -522.913 -522.913] [0.0000], Avg: [-462.033 -462.033 -462.033] (0.080)
Step: 25299, Reward: [-473.135 -473.135 -473.135] [0.0000], Avg: [-462.055 -462.055 -462.055] (0.079)
Step: 25349, Reward: [-425.234 -425.234 -425.234] [0.0000], Avg: [-461.982 -461.982 -461.982] (0.079)
Step: 25399, Reward: [-423.871 -423.871 -423.871] [0.0000], Avg: [-461.907 -461.907 -461.907] (0.078)
Step: 25449, Reward: [-318.675 -318.675 -318.675] [0.0000], Avg: [-461.626 -461.626 -461.626] (0.078)
Step: 25499, Reward: [-523.343 -523.343 -523.343] [0.0000], Avg: [-461.747 -461.747 -461.747] (0.078)
Step: 25549, Reward: [-517.242 -517.242 -517.242] [0.0000], Avg: [-461.855 -461.855 -461.855] (0.077)
Step: 25599, Reward: [-514.929 -514.929 -514.929] [0.0000], Avg: [-461.959 -461.959 -461.959] (0.077)
Step: 25649, Reward: [-321.014 -321.014 -321.014] [0.0000], Avg: [-461.684 -461.684 -461.684] (0.076)
Step: 25699, Reward: [-520.425 -520.425 -520.425] [0.0000], Avg: [-461.799 -461.799 -461.799] (0.076)
Step: 25749, Reward: [-683.514 -683.514 -683.514] [0.0000], Avg: [-462.229 -462.229 -462.229] (0.076)
Step: 25799, Reward: [-405.886 -405.886 -405.886] [0.0000], Avg: [-462.12 -462.12 -462.12] (0.075)
Step: 25849, Reward: [-358.061 -358.061 -358.061] [0.0000], Avg: [-461.919 -461.919 -461.919] (0.075)
Step: 25899, Reward: [-518.417 -518.417 -518.417] [0.0000], Avg: [-462.028 -462.028 -462.028] (0.075)
Step: 25949, Reward: [-407.688 -407.688 -407.688] [0.0000], Avg: [-461.923 -461.923 -461.923] (0.074)
Step: 25999, Reward: [-371.52 -371.52 -371.52] [0.0000], Avg: [-461.749 -461.749 -461.749] (0.074)
Step: 26049, Reward: [-448.685 -448.685 -448.685] [0.0000], Avg: [-461.724 -461.724 -461.724] (0.073)
Step: 26099, Reward: [-364.139 -364.139 -364.139] [0.0000], Avg: [-461.537 -461.537 -461.537] (0.073)
Step: 26149, Reward: [-548.822 -548.822 -548.822] [0.0000], Avg: [-461.704 -461.704 -461.704] (0.073)
Step: 26199, Reward: [-538.168 -538.168 -538.168] [0.0000], Avg: [-461.85 -461.85 -461.85] (0.072)
Step: 26249, Reward: [-652.911 -652.911 -652.911] [0.0000], Avg: [-462.214 -462.214 -462.214] (0.072)
Step: 26299, Reward: [-491.411 -491.411 -491.411] [0.0000], Avg: [-462.269 -462.269 -462.269] (0.072)
Step: 26349, Reward: [-430.087 -430.087 -430.087] [0.0000], Avg: [-462.208 -462.208 -462.208] (0.071)
Step: 26399, Reward: [-356.399 -356.399 -356.399] [0.0000], Avg: [-462.008 -462.008 -462.008] (0.071)
Step: 26449, Reward: [-527.761 -527.761 -527.761] [0.0000], Avg: [-462.132 -462.132 -462.132] (0.071)
Step: 26499, Reward: [-538.135 -538.135 -538.135] [0.0000], Avg: [-462.276 -462.276 -462.276] (0.070)
Step: 26549, Reward: [-430.341 -430.341 -430.341] [0.0000], Avg: [-462.216 -462.216 -462.216] (0.070)
Step: 26599, Reward: [-418.413 -418.413 -418.413] [0.0000], Avg: [-462.133 -462.133 -462.133] (0.069)
Step: 26649, Reward: [-719.29 -719.29 -719.29] [0.0000], Avg: [-462.616 -462.616 -462.616] (0.069)
Step: 26699, Reward: [-534.736 -534.736 -534.736] [0.0000], Avg: [-462.751 -462.751 -462.751] (0.069)
Step: 26749, Reward: [-409.003 -409.003 -409.003] [0.0000], Avg: [-462.65 -462.65 -462.65] (0.068)
Step: 26799, Reward: [-452.075 -452.075 -452.075] [0.0000], Avg: [-462.631 -462.631 -462.631] (0.068)
Step: 26849, Reward: [-476.171 -476.171 -476.171] [0.0000], Avg: [-462.656 -462.656 -462.656] (0.068)
Step: 26899, Reward: [-386.83 -386.83 -386.83] [0.0000], Avg: [-462.515 -462.515 -462.515] (0.067)
Step: 26949, Reward: [-351.774 -351.774 -351.774] [0.0000], Avg: [-462.309 -462.309 -462.309] (0.067)
