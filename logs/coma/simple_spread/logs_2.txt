Model: <class 'multiagent.coma.COMAAgent'>, Dir: simple_spread
num_envs: 1, state_size: [(1, 18), (1, 18), (1, 18)], action_size: [[1, 5], [1, 5], [1, 5]], action_space: [<gym.spaces.multi_discrete.MultiDiscrete object at 0x7f19eaa486a0>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f19eaa48748>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f19eaa487b8>],

import torch
import random
import numpy as np
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, one_hot, gumbel_softmax

EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64

class COMAActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)!=3 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.recurrent = torch.nn.GRUCell(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_probs = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.init_hidden()

	def forward(self, state, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		if self.hidden.size(0) != state.size(0): self.init_hidden(state.size(0))
		self.hidden = self.recurrent(state, self.hidden)
		action_probs = gumbel_softmax(self.action_probs(self.hidden))
		action_probs = action_probs.view(*out_dims, -1)
		return action_probs

	def init_hidden(self, batch_size=1):
		self.hidden = torch.zeros([batch_size, ACTOR_HIDDEN])

class COMACritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)!=3 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.q_values = torch.nn.Linear(CRITIC_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		q_values = self.q_values(state)
		return q_values

class COMANetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(gpu=gpu)
		self.state_size = [state_size] if type(state_size[0]) in [int, np.int32] else state_size
		self.action_size = [action_size] if type(action_size[0]) in [int, np.int32] else action_size
		self.n_agents = lambda size: 1 if len(size)==1 else size[0]
		make_actor = lambda s_size,a_size: COMAActor([s_size[-1] + a_size[-1] + self.n_agents(s_size)], a_size)
		make_critic = lambda s_size,a_size: COMACritic([np.sum([np.prod(s) for s in self.state_size]) + 2*np.sum([np.prod(a) for a in self.action_size]) + s_size[-1] + self.n_agents(s_size)], a_size)
		self.models = [PTACNetwork(s_size, a_size, make_actor, make_critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		if load: self.load_model(load)
		
	def get_action_probs(self, state, sample=True, grad=True, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [model.actor_local(s.to(self.device), sample) for s,model in zip(state, self.models)]
			return [a.cpu().numpy().astype(np.float32) for a in action] if numpy else action

	def get_value(self, state, grad=True, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_values = [model.critic_local(s.to(self.device)) for s,model in zip(state, self.models)]
			return [q.cpu().numpy() for q in q_values] if numpy else q_values

	def optimize(self, actions, actor_inputs, critic_inputs, q_values, q_targets):
		for model,action,actor_input,critic_input,q_value,q_target in zip(self.models, actions, actor_inputs, critic_inputs, q_values, q_targets):
			for t in reversed(range(q_target.size(0))):
				q_value[t] = model.critic_local(critic_input[t])
				q_select = torch.gather(q_value[t], dim=-1, index=action[t].argmax(-1, keepdims=True)).squeeze(-1)
				critic_loss = (q_select - q_target[t].detach()).pow(2)
				model.step(model.critic_optimizer, critic_loss.mean(), retain=t>0)

			hidden = model.actor_local.hidden
			action_probs = torch.stack([model.actor_local(actor_input[t]) for t in range(q_target.size(0))], dim=0)
			baseline = (action_probs * q_value[:-1]).sum(-1, keepdims=True).detach()
			q_selected = torch.gather(q_value[:-1], dim=-1, index=action[:-1].argmax(-1, keepdims=True))
			log_probs = torch.gather(action_probs, dim=-1, index=action[:-1].argmax(-1, keepdims=True)).log()
			advantages = (q_selected - baseline).detach()
			actor_loss = (advantages * log_probs).sum() + 0.001*action_probs.pow(2).mean()
			model.step(model.actor_optimizer, actor_loss.mean())
			model.actor_local.hidden = hidden

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("coma", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("coma", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class COMAAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, COMANetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True, numpy=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state)
		if not hasattr(self, "action"): self.action = [np.zeros_like(a) for a in action_random]
		actor_inputs = []
		state_list = self.to_tensor(state)
		state_list = [state_list] if type(state_list) != list else state_list
		for i,(state,last_a,s_size,a_size) in enumerate(zip(state_list, self.action, self.state_size, self.action_size)):
			n_agents = self.network.n_agents(s_size)
			last_action = last_a if len(state.shape)-len(s_size) == len(last_a.shape)-len(a_size) else np.zeros_like(action_random[i])
			agent_ids = np.eye(n_agents) if len(state.shape)==len(s_size) else np.repeat(np.expand_dims(np.eye(n_agents), 0), repeats=state.shape[0], axis=0)
			actor_input = torch.tensor(np.concatenate([state, last_action, agent_ids], axis=-1), device=self.network.device).float()
			actor_inputs.append(actor_input)
		action_greedy = self.network.get_action_probs(actor_inputs, sample=sample, grad=False, numpy=numpy)
		action = action_random if numpy and random.random() < eps else action_greedy
		if numpy: self.action = action
		return action

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.update_freq:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()

			n_agents = [self.network.n_agents(a_size) for a_size in self.action_size]
			states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, self.to_tensor(next_state))]
			actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.get_action(next_state, numpy=False))]
			states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			actions_one_hot = [one_hot(a) for a in actions]
			actions_one_hot_joint = torch.cat([a.view(*a.shape[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions_one_hot, self.action_size)], dim=-1)
			last_actions = [torch.cat([torch.zeros_like(a[0:1]), a[:-1]], dim=0) for a in actions_one_hot]
			last_actions_joint = torch.cat([a.view(*a.shape[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(last_actions, self.action_size)], dim=-1)
			agent_mask = [(1-torch.eye(n_agent)).view(-1, 1).repeat(1, a_size[-1]).view(n_agent, -1) for a_size,n_agent in zip(self.action_size, n_agents)]
			action_mask = torch.ones([1, 1, np.sum(n_agents), np.sum([n_agent*a_size[-1] for a_size,n_agent in zip(self.action_size, n_agents)])])
			cols, rows = [0, *np.cumsum(n_agents)], [0, *np.cumsum([n_agent*a_size[-1] for a_size,n_agent in zip(self.action_size, n_agents)])]
			for i,mask in enumerate(agent_mask): action_mask[...,cols[i]:cols[i+1], rows[i]:rows[i+1]] = mask

			states_joint, actions_joint, last_actions_joint = [x.unsqueeze(-2).repeat_interleave(action_mask.shape[-2], dim=-2) for x in [states_joint, actions_one_hot_joint, last_actions_joint]]
			joint_inputs = torch.cat([states_joint, actions_joint * action_mask, last_actions_joint], dim=-1).split(n_agents, dim=-2)
			agent_ids = [torch.eye(self.network.n_agents(a_size)).unsqueeze(0).unsqueeze(0).expand(*a.shape[:2], -1, -1) for a_size, a in zip(self.action_size, actions)]
			critic_inputs = [torch.cat([joint_input, state, agent_id], dim=-1) for joint_input,state,agent_id in zip(joint_inputs, states, agent_ids)]
			actor_inputs = [torch.cat([state, last_action, agent_id], dim=-1) for state,last_action,agent_id in zip(states, last_actions, agent_ids)]

			q_values = self.network.get_value(critic_inputs, grad=False)
			q_selecteds = [torch.gather(q_value, dim=-1, index=a.argmax(-1, keepdims=True)).squeeze(-1) for q_value,a in zip(q_values,actions)]
			q_targets = [self.compute_gae(q_selected[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_selected[:-1])[0] for q_selected,reward,done in zip(q_selecteds, rewards, dones)]
			self.network.optimize(actions, actor_inputs, critic_inputs, q_values, q_targets)
		if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.900             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)
# np.random.seed(1)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return gym.make(env_name)
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":0} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env)

def run(model, steps=10000, ports=16, env_name=env_name, eval_at=1000, checkpoint=False, save_best=False, log=True, render=True):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports, render=False, env_name=env_name)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, num_envs=num_envs, gpu=False, agent2=RandomAgent) 
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if np.any(dones[0]):
			rollouts = [rollout(envs.env, agent.reset(1), render=render) for _ in range(1)]
			test_reward = np.mean(rollouts, axis=0) - np.std(rollouts, axis=0)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if save_best and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts, axis=0)} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")
			agent.reset(num_envs)

def trial(model):
	envs = EnsembleEnv(make_env, 0, log=True, render=True)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, load=f"{env_name}")
	print(f"Reward: {rollout(envs.env, agent, eps=0.02, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[1], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="maddpg", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--test", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.test:
		trial(model)
	elif args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		run(model, args.steps, args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)

Step: 49, Reward: [-450.793 -450.793 -450.793] [0.0000], Avg: [-450.793 -450.793 -450.793] (0.995)
Step: 99, Reward: [-598.953 -598.953 -598.953] [0.0000], Avg: [-524.873 -524.873 -524.873] (0.990)
Step: 149, Reward: [-312.394 -312.394 -312.394] [0.0000], Avg: [-454.047 -454.047 -454.047] (0.985)
Step: 199, Reward: [-478.128 -478.128 -478.128] [0.0000], Avg: [-460.067 -460.067 -460.067] (0.980)
Step: 249, Reward: [-540.362 -540.362 -540.362] [0.0000], Avg: [-476.126 -476.126 -476.126] (0.975)
Step: 299, Reward: [-455.15 -455.15 -455.15] [0.0000], Avg: [-472.63 -472.63 -472.63] (0.970)
Step: 349, Reward: [-822.751 -822.751 -822.751] [0.0000], Avg: [-522.647 -522.647 -522.647] (0.966)
Step: 399, Reward: [-457.912 -457.912 -457.912] [0.0000], Avg: [-514.555 -514.555 -514.555] (0.961)
Step: 449, Reward: [-364.389 -364.389 -364.389] [0.0000], Avg: [-497.87 -497.87 -497.87] (0.956)
Step: 499, Reward: [-522.618 -522.618 -522.618] [0.0000], Avg: [-500.345 -500.345 -500.345] (0.951)
Step: 549, Reward: [-577.741 -577.741 -577.741] [0.0000], Avg: [-507.381 -507.381 -507.381] (0.946)
Step: 599, Reward: [-327.274 -327.274 -327.274] [0.0000], Avg: [-492.372 -492.372 -492.372] (0.942)
Step: 649, Reward: [-489.065 -489.065 -489.065] [0.0000], Avg: [-492.118 -492.118 -492.118] (0.937)
Step: 699, Reward: [-431.223 -431.223 -431.223] [0.0000], Avg: [-487.768 -487.768 -487.768] (0.932)
Step: 749, Reward: [-505.512 -505.512 -505.512] [0.0000], Avg: [-488.951 -488.951 -488.951] (0.928)
Step: 799, Reward: [-378.223 -378.223 -378.223] [0.0000], Avg: [-482.031 -482.031 -482.031] (0.923)
Step: 849, Reward: [-507.31 -507.31 -507.31] [0.0000], Avg: [-483.518 -483.518 -483.518] (0.918)
Step: 899, Reward: [-631.817 -631.817 -631.817] [0.0000], Avg: [-491.756 -491.756 -491.756] (0.914)
Step: 949, Reward: [-397.103 -397.103 -397.103] [0.0000], Avg: [-486.775 -486.775 -486.775] (0.909)
Step: 999, Reward: [-533.545 -533.545 -533.545] [0.0000], Avg: [-489.113 -489.113 -489.113] (0.905)
Step: 1049, Reward: [-511.359 -511.359 -511.359] [0.0000], Avg: [-490.173 -490.173 -490.173] (0.900)
Step: 1099, Reward: [-516.417 -516.417 -516.417] [0.0000], Avg: [-491.365 -491.365 -491.365] (0.896)
Step: 1149, Reward: [-353.062 -353.062 -353.062] [0.0000], Avg: [-485.352 -485.352 -485.352] (0.891)
Step: 1199, Reward: [-416.264 -416.264 -416.264] [0.0000], Avg: [-482.474 -482.474 -482.474] (0.887)
Step: 1249, Reward: [-477.485 -477.485 -477.485] [0.0000], Avg: [-482.274 -482.274 -482.274] (0.882)
Step: 1299, Reward: [-417.749 -417.749 -417.749] [0.0000], Avg: [-479.792 -479.792 -479.792] (0.878)
Step: 1349, Reward: [-568.171 -568.171 -568.171] [0.0000], Avg: [-483.066 -483.066 -483.066] (0.873)
Step: 1399, Reward: [-581.767 -581.767 -581.767] [0.0000], Avg: [-486.591 -486.591 -486.591] (0.869)
Step: 1449, Reward: [-380.301 -380.301 -380.301] [0.0000], Avg: [-482.926 -482.926 -482.926] (0.865)
Step: 1499, Reward: [-758.682 -758.682 -758.682] [0.0000], Avg: [-492.117 -492.117 -492.117] (0.860)
Step: 1549, Reward: [-498.335 -498.335 -498.335] [0.0000], Avg: [-492.318 -492.318 -492.318] (0.856)
Step: 1599, Reward: [-376.081 -376.081 -376.081] [0.0000], Avg: [-488.686 -488.686 -488.686] (0.852)
Step: 1649, Reward: [-413.874 -413.874 -413.874] [0.0000], Avg: [-486.419 -486.419 -486.419] (0.848)
Step: 1699, Reward: [-450.542 -450.542 -450.542] [0.0000], Avg: [-485.363 -485.363 -485.363] (0.843)
Step: 1749, Reward: [-532.945 -532.945 -532.945] [0.0000], Avg: [-486.723 -486.723 -486.723] (0.839)
Step: 1799, Reward: [-525.256 -525.256 -525.256] [0.0000], Avg: [-487.793 -487.793 -487.793] (0.835)
Step: 1849, Reward: [-446.824 -446.824 -446.824] [0.0000], Avg: [-486.686 -486.686 -486.686] (0.831)
Step: 1899, Reward: [-434.182 -434.182 -434.182] [0.0000], Avg: [-485.304 -485.304 -485.304] (0.827)
Step: 1949, Reward: [-432.274 -432.274 -432.274] [0.0000], Avg: [-483.944 -483.944 -483.944] (0.822)
Step: 1999, Reward: [-433.357 -433.357 -433.357] [0.0000], Avg: [-482.68 -482.68 -482.68] (0.818)
Step: 2049, Reward: [-430.459 -430.459 -430.459] [0.0000], Avg: [-481.406 -481.406 -481.406] (0.814)
Step: 2099, Reward: [-418.257 -418.257 -418.257] [0.0000], Avg: [-479.903 -479.903 -479.903] (0.810)
Step: 2149, Reward: [-535.868 -535.868 -535.868] [0.0000], Avg: [-481.204 -481.204 -481.204] (0.806)
Step: 2199, Reward: [-516.221 -516.221 -516.221] [0.0000], Avg: [-482. -482. -482.] (0.802)
Step: 2249, Reward: [-485.387 -485.387 -485.387] [0.0000], Avg: [-482.075 -482.075 -482.075] (0.798)
Step: 2299, Reward: [-576.864 -576.864 -576.864] [0.0000], Avg: [-484.136 -484.136 -484.136] (0.794)
Step: 2349, Reward: [-380.627 -380.627 -380.627] [0.0000], Avg: [-481.933 -481.933 -481.933] (0.790)
Step: 2399, Reward: [-453.077 -453.077 -453.077] [0.0000], Avg: [-481.332 -481.332 -481.332] (0.786)
Step: 2449, Reward: [-399.211 -399.211 -399.211] [0.0000], Avg: [-479.656 -479.656 -479.656] (0.782)
Step: 2499, Reward: [-378.225 -378.225 -378.225] [0.0000], Avg: [-477.628 -477.628 -477.628] (0.778)
Step: 2549, Reward: [-387.329 -387.329 -387.329] [0.0000], Avg: [-475.857 -475.857 -475.857] (0.774)
Step: 2599, Reward: [-450.197 -450.197 -450.197] [0.0000], Avg: [-475.364 -475.364 -475.364] (0.771)
Step: 2649, Reward: [-465.265 -465.265 -465.265] [0.0000], Avg: [-475.173 -475.173 -475.173] (0.767)
Step: 2699, Reward: [-571.218 -571.218 -571.218] [0.0000], Avg: [-476.952 -476.952 -476.952] (0.763)
Step: 2749, Reward: [-787.317 -787.317 -787.317] [0.0000], Avg: [-482.595 -482.595 -482.595] (0.759)
Step: 2799, Reward: [-702.002 -702.002 -702.002] [0.0000], Avg: [-486.513 -486.513 -486.513] (0.755)
Step: 2849, Reward: [-502.476 -502.476 -502.476] [0.0000], Avg: [-486.793 -486.793 -486.793] (0.751)
Step: 2899, Reward: [-426.44 -426.44 -426.44] [0.0000], Avg: [-485.752 -485.752 -485.752] (0.748)
Step: 2949, Reward: [-608.833 -608.833 -608.833] [0.0000], Avg: [-487.838 -487.838 -487.838] (0.744)
Step: 2999, Reward: [-386.91 -386.91 -386.91] [0.0000], Avg: [-486.156 -486.156 -486.156] (0.740)
Step: 3049, Reward: [-389.751 -389.751 -389.751] [0.0000], Avg: [-484.576 -484.576 -484.576] (0.737)
Step: 3099, Reward: [-617.854 -617.854 -617.854] [0.0000], Avg: [-486.725 -486.725 -486.725] (0.733)
Step: 3149, Reward: [-442.023 -442.023 -442.023] [0.0000], Avg: [-486.016 -486.016 -486.016] (0.729)
Step: 3199, Reward: [-494.644 -494.644 -494.644] [0.0000], Avg: [-486.151 -486.151 -486.151] (0.726)
Step: 3249, Reward: [-419.253 -419.253 -419.253] [0.0000], Avg: [-485.122 -485.122 -485.122] (0.722)
Step: 3299, Reward: [-465.988 -465.988 -465.988] [0.0000], Avg: [-484.832 -484.832 -484.832] (0.718)
Step: 3349, Reward: [-385.229 -385.229 -385.229] [0.0000], Avg: [-483.345 -483.345 -483.345] (0.715)
Step: 3399, Reward: [-407.12 -407.12 -407.12] [0.0000], Avg: [-482.224 -482.224 -482.224] (0.711)
Step: 3449, Reward: [-396.449 -396.449 -396.449] [0.0000], Avg: [-480.981 -480.981 -480.981] (0.708)
Step: 3499, Reward: [-401.027 -401.027 -401.027] [0.0000], Avg: [-479.839 -479.839 -479.839] (0.704)
Step: 3549, Reward: [-404.861 -404.861 -404.861] [0.0000], Avg: [-478.783 -478.783 -478.783] (0.701)
Step: 3599, Reward: [-406.231 -406.231 -406.231] [0.0000], Avg: [-477.775 -477.775 -477.775] (0.697)
Step: 3649, Reward: [-468.485 -468.485 -468.485] [0.0000], Avg: [-477.648 -477.648 -477.648] (0.694)
Step: 3699, Reward: [-592.947 -592.947 -592.947] [0.0000], Avg: [-479.206 -479.206 -479.206] (0.690)
Step: 3749, Reward: [-376.363 -376.363 -376.363] [0.0000], Avg: [-477.835 -477.835 -477.835] (0.687)
Step: 3799, Reward: [-483.139 -483.139 -483.139] [0.0000], Avg: [-477.904 -477.904 -477.904] (0.683)
Step: 3849, Reward: [-481.708 -481.708 -481.708] [0.0000], Avg: [-477.954 -477.954 -477.954] (0.680)
Step: 3899, Reward: [-583.414 -583.414 -583.414] [0.0000], Avg: [-479.306 -479.306 -479.306] (0.676)
Step: 3949, Reward: [-458.492 -458.492 -458.492] [0.0000], Avg: [-479.042 -479.042 -479.042] (0.673)
Step: 3999, Reward: [-387.208 -387.208 -387.208] [0.0000], Avg: [-477.895 -477.895 -477.895] (0.670)
Step: 4049, Reward: [-502.422 -502.422 -502.422] [0.0000], Avg: [-478.197 -478.197 -478.197] (0.666)
Step: 4099, Reward: [-459.083 -459.083 -459.083] [0.0000], Avg: [-477.964 -477.964 -477.964] (0.663)
Step: 4149, Reward: [-420.43 -420.43 -420.43] [0.0000], Avg: [-477.271 -477.271 -477.271] (0.660)
Step: 4199, Reward: [-862.843 -862.843 -862.843] [0.0000], Avg: [-481.861 -481.861 -481.861] (0.656)
Step: 4249, Reward: [-471.675 -471.675 -471.675] [0.0000], Avg: [-481.741 -481.741 -481.741] (0.653)
Step: 4299, Reward: [-516.673 -516.673 -516.673] [0.0000], Avg: [-482.148 -482.148 -482.148] (0.650)
Step: 4349, Reward: [-580.217 -580.217 -580.217] [0.0000], Avg: [-483.275 -483.275 -483.275] (0.647)
Step: 4399, Reward: [-485.856 -485.856 -485.856] [0.0000], Avg: [-483.304 -483.304 -483.304] (0.643)
Step: 4449, Reward: [-414.293 -414.293 -414.293] [0.0000], Avg: [-482.529 -482.529 -482.529] (0.640)
Step: 4499, Reward: [-452.218 -452.218 -452.218] [0.0000], Avg: [-482.192 -482.192 -482.192] (0.637)
Step: 4549, Reward: [-428.617 -428.617 -428.617] [0.0000], Avg: [-481.603 -481.603 -481.603] (0.634)
Step: 4599, Reward: [-397.826 -397.826 -397.826] [0.0000], Avg: [-480.693 -480.693 -480.693] (0.631)
Step: 4649, Reward: [-401.761 -401.761 -401.761] [0.0000], Avg: [-479.844 -479.844 -479.844] (0.627)
Step: 4699, Reward: [-432.471 -432.471 -432.471] [0.0000], Avg: [-479.34 -479.34 -479.34] (0.624)
Step: 4749, Reward: [-609.441 -609.441 -609.441] [0.0000], Avg: [-480.709 -480.709 -480.709] (0.621)
Step: 4799, Reward: [-445.234 -445.234 -445.234] [0.0000], Avg: [-480.34 -480.34 -480.34] (0.618)
Step: 4849, Reward: [-548.059 -548.059 -548.059] [0.0000], Avg: [-481.038 -481.038 -481.038] (0.615)
Step: 4899, Reward: [-621.791 -621.791 -621.791] [0.0000], Avg: [-482.474 -482.474 -482.474] (0.612)
Step: 4949, Reward: [-495.37 -495.37 -495.37] [0.0000], Avg: [-482.604 -482.604 -482.604] (0.609)
Step: 4999, Reward: [-389.41 -389.41 -389.41] [0.0000], Avg: [-481.673 -481.673 -481.673] (0.606)
Step: 5049, Reward: [-425.726 -425.726 -425.726] [0.0000], Avg: [-481.119 -481.119 -481.119] (0.603)
Step: 5099, Reward: [-391.937 -391.937 -391.937] [0.0000], Avg: [-480.244 -480.244 -480.244] (0.600)
Step: 5149, Reward: [-382.941 -382.941 -382.941] [0.0000], Avg: [-479.3 -479.3 -479.3] (0.597)
Step: 5199, Reward: [-369.676 -369.676 -369.676] [0.0000], Avg: [-478.245 -478.245 -478.245] (0.594)
Step: 5249, Reward: [-724.699 -724.699 -724.699] [0.0000], Avg: [-480.593 -480.593 -480.593] (0.591)
Step: 5299, Reward: [-529.904 -529.904 -529.904] [0.0000], Avg: [-481.058 -481.058 -481.058] (0.588)
Step: 5349, Reward: [-511.03 -511.03 -511.03] [0.0000], Avg: [-481.338 -481.338 -481.338] (0.585)
Step: 5399, Reward: [-365.565 -365.565 -365.565] [0.0000], Avg: [-480.266 -480.266 -480.266] (0.582)
Step: 5449, Reward: [-664.359 -664.359 -664.359] [0.0000], Avg: [-481.955 -481.955 -481.955] (0.579)
Step: 5499, Reward: [-369.977 -369.977 -369.977] [0.0000], Avg: [-480.937 -480.937 -480.937] (0.576)
Step: 5549, Reward: [-429.769 -429.769 -429.769] [0.0000], Avg: [-480.476 -480.476 -480.476] (0.573)
Step: 5599, Reward: [-351.866 -351.866 -351.866] [0.0000], Avg: [-479.328 -479.328 -479.328] (0.570)
Step: 5649, Reward: [-331.637 -331.637 -331.637] [0.0000], Avg: [-478.021 -478.021 -478.021] (0.568)
Step: 5699, Reward: [-503.281 -503.281 -503.281] [0.0000], Avg: [-478.242 -478.242 -478.242] (0.565)
Step: 5749, Reward: [-487.975 -487.975 -487.975] [0.0000], Avg: [-478.327 -478.327 -478.327] (0.562)
Step: 5799, Reward: [-410.508 -410.508 -410.508] [0.0000], Avg: [-477.742 -477.742 -477.742] (0.559)
Step: 5849, Reward: [-377.708 -377.708 -377.708] [0.0000], Avg: [-476.887 -476.887 -476.887] (0.556)
Step: 5899, Reward: [-397.401 -397.401 -397.401] [0.0000], Avg: [-476.214 -476.214 -476.214] (0.554)
Step: 5949, Reward: [-416.536 -416.536 -416.536] [0.0000], Avg: [-475.712 -475.712 -475.712] (0.551)
Step: 5999, Reward: [-464.706 -464.706 -464.706] [0.0000], Avg: [-475.62 -475.62 -475.62] (0.548)
Step: 6049, Reward: [-423.168 -423.168 -423.168] [0.0000], Avg: [-475.187 -475.187 -475.187] (0.545)
Step: 6099, Reward: [-479.804 -479.804 -479.804] [0.0000], Avg: [-475.225 -475.225 -475.225] (0.543)
Step: 6149, Reward: [-418.51 -418.51 -418.51] [0.0000], Avg: [-474.764 -474.764 -474.764] (0.540)
Step: 6199, Reward: [-542.56 -542.56 -542.56] [0.0000], Avg: [-475.31 -475.31 -475.31] (0.537)
Step: 6249, Reward: [-445.269 -445.269 -445.269] [0.0000], Avg: [-475.07 -475.07 -475.07] (0.534)
Step: 6299, Reward: [-385.72 -385.72 -385.72] [0.0000], Avg: [-474.361 -474.361 -474.361] (0.532)
Step: 6349, Reward: [-457.507 -457.507 -457.507] [0.0000], Avg: [-474.228 -474.228 -474.228] (0.529)
Step: 6399, Reward: [-508.815 -508.815 -508.815] [0.0000], Avg: [-474.498 -474.498 -474.498] (0.526)
Step: 6449, Reward: [-491.618 -491.618 -491.618] [0.0000], Avg: [-474.631 -474.631 -474.631] (0.524)
Step: 6499, Reward: [-554.112 -554.112 -554.112] [0.0000], Avg: [-475.243 -475.243 -475.243] (0.521)
Step: 6549, Reward: [-586.887 -586.887 -586.887] [0.0000], Avg: [-476.095 -476.095 -476.095] (0.519)
Step: 6599, Reward: [-472.42 -472.42 -472.42] [0.0000], Avg: [-476.067 -476.067 -476.067] (0.516)
Step: 6649, Reward: [-469.509 -469.509 -469.509] [0.0000], Avg: [-476.018 -476.018 -476.018] (0.513)
Step: 6699, Reward: [-383.628 -383.628 -383.628] [0.0000], Avg: [-475.328 -475.328 -475.328] (0.511)
Step: 6749, Reward: [-540.893 -540.893 -540.893] [0.0000], Avg: [-475.814 -475.814 -475.814] (0.508)
Step: 6799, Reward: [-448.206 -448.206 -448.206] [0.0000], Avg: [-475.611 -475.611 -475.611] (0.506)
Step: 6849, Reward: [-386.207 -386.207 -386.207] [0.0000], Avg: [-474.958 -474.958 -474.958] (0.503)
Step: 6899, Reward: [-402.399 -402.399 -402.399] [0.0000], Avg: [-474.432 -474.432 -474.432] (0.501)
Step: 6949, Reward: [-395.412 -395.412 -395.412] [0.0000], Avg: [-473.864 -473.864 -473.864] (0.498)
Step: 6999, Reward: [-340.847 -340.847 -340.847] [0.0000], Avg: [-472.914 -472.914 -472.914] (0.496)
Step: 7049, Reward: [-476.097 -476.097 -476.097] [0.0000], Avg: [-472.936 -472.936 -472.936] (0.493)
Step: 7099, Reward: [-392.2 -392.2 -392.2] [0.0000], Avg: [-472.368 -472.368 -472.368] (0.491)
Step: 7149, Reward: [-613.028 -613.028 -613.028] [0.0000], Avg: [-473.352 -473.352 -473.352] (0.488)
Step: 7199, Reward: [-570.401 -570.401 -570.401] [0.0000], Avg: [-474.025 -474.025 -474.025] (0.486)
Step: 7249, Reward: [-620.151 -620.151 -620.151] [0.0000], Avg: [-475.033 -475.033 -475.033] (0.483)
Step: 7299, Reward: [-538.49 -538.49 -538.49] [0.0000], Avg: [-475.468 -475.468 -475.468] (0.481)
Step: 7349, Reward: [-538.051 -538.051 -538.051] [0.0000], Avg: [-475.894 -475.894 -475.894] (0.479)
Step: 7399, Reward: [-503.295 -503.295 -503.295] [0.0000], Avg: [-476.079 -476.079 -476.079] (0.476)
Step: 7449, Reward: [-424.924 -424.924 -424.924] [0.0000], Avg: [-475.735 -475.735 -475.735] (0.474)
Step: 7499, Reward: [-495.15 -495.15 -495.15] [0.0000], Avg: [-475.865 -475.865 -475.865] (0.471)
Step: 7549, Reward: [-339.482 -339.482 -339.482] [0.0000], Avg: [-474.962 -474.962 -474.962] (0.469)
Step: 7599, Reward: [-405.744 -405.744 -405.744] [0.0000], Avg: [-474.506 -474.506 -474.506] (0.467)
Step: 7649, Reward: [-396.441 -396.441 -396.441] [0.0000], Avg: [-473.996 -473.996 -473.996] (0.464)
Step: 7699, Reward: [-443.526 -443.526 -443.526] [0.0000], Avg: [-473.798 -473.798 -473.798] (0.462)
Step: 7749, Reward: [-458.993 -458.993 -458.993] [0.0000], Avg: [-473.703 -473.703 -473.703] (0.460)
Step: 7799, Reward: [-365.752 -365.752 -365.752] [0.0000], Avg: [-473.011 -473.011 -473.011] (0.458)
Step: 7849, Reward: [-373.498 -373.498 -373.498] [0.0000], Avg: [-472.377 -472.377 -472.377] (0.455)
Step: 7899, Reward: [-552.824 -552.824 -552.824] [0.0000], Avg: [-472.886 -472.886 -472.886] (0.453)
Step: 7949, Reward: [-401.262 -401.262 -401.262] [0.0000], Avg: [-472.436 -472.436 -472.436] (0.451)
Step: 7999, Reward: [-457.87 -457.87 -457.87] [0.0000], Avg: [-472.345 -472.345 -472.345] (0.448)
Step: 8049, Reward: [-379.502 -379.502 -379.502] [0.0000], Avg: [-471.768 -471.768 -471.768] (0.446)
Step: 8099, Reward: [-605.754 -605.754 -605.754] [0.0000], Avg: [-472.595 -472.595 -472.595] (0.444)
Step: 8149, Reward: [-687.163 -687.163 -687.163] [0.0000], Avg: [-473.911 -473.911 -473.911] (0.442)
Step: 8199, Reward: [-377.282 -377.282 -377.282] [0.0000], Avg: [-473.322 -473.322 -473.322] (0.440)
Step: 8249, Reward: [-485.409 -485.409 -485.409] [0.0000], Avg: [-473.395 -473.395 -473.395] (0.437)
Step: 8299, Reward: [-446.829 -446.829 -446.829] [0.0000], Avg: [-473.235 -473.235 -473.235] (0.435)
Step: 8349, Reward: [-356.454 -356.454 -356.454] [0.0000], Avg: [-472.536 -472.536 -472.536] (0.433)
Step: 8399, Reward: [-492.471 -492.471 -492.471] [0.0000], Avg: [-472.655 -472.655 -472.655] (0.431)
Step: 8449, Reward: [-489.772 -489.772 -489.772] [0.0000], Avg: [-472.756 -472.756 -472.756] (0.429)
Step: 8499, Reward: [-409.08 -409.08 -409.08] [0.0000], Avg: [-472.381 -472.381 -472.381] (0.427)
Step: 8549, Reward: [-562.114 -562.114 -562.114] [0.0000], Avg: [-472.906 -472.906 -472.906] (0.424)
Step: 8599, Reward: [-556.876 -556.876 -556.876] [0.0000], Avg: [-473.394 -473.394 -473.394] (0.422)
Step: 8649, Reward: [-514.219 -514.219 -514.219] [0.0000], Avg: [-473.63 -473.63 -473.63] (0.420)
Step: 8699, Reward: [-548.882 -548.882 -548.882] [0.0000], Avg: [-474.063 -474.063 -474.063] (0.418)
Step: 8749, Reward: [-506.873 -506.873 -506.873] [0.0000], Avg: [-474.25 -474.25 -474.25] (0.416)
Step: 8799, Reward: [-426.296 -426.296 -426.296] [0.0000], Avg: [-473.978 -473.978 -473.978] (0.414)
Step: 8849, Reward: [-332.088 -332.088 -332.088] [0.0000], Avg: [-473.176 -473.176 -473.176] (0.412)
Step: 8899, Reward: [-414.041 -414.041 -414.041] [0.0000], Avg: [-472.844 -472.844 -472.844] (0.410)
Step: 8949, Reward: [-360.247 -360.247 -360.247] [0.0000], Avg: [-472.215 -472.215 -472.215] (0.408)
Step: 8999, Reward: [-535.427 -535.427 -535.427] [0.0000], Avg: [-472.566 -472.566 -472.566] (0.406)
Step: 9049, Reward: [-466.46 -466.46 -466.46] [0.0000], Avg: [-472.532 -472.532 -472.532] (0.404)
Step: 9099, Reward: [-625.279 -625.279 -625.279] [0.0000], Avg: [-473.372 -473.372 -473.372] (0.402)
Step: 9149, Reward: [-534.094 -534.094 -534.094] [0.0000], Avg: [-473.703 -473.703 -473.703] (0.400)
Step: 9199, Reward: [-611.684 -611.684 -611.684] [0.0000], Avg: [-474.453 -474.453 -474.453] (0.398)
Step: 9249, Reward: [-485.3 -485.3 -485.3] [0.0000], Avg: [-474.512 -474.512 -474.512] (0.396)
Step: 9299, Reward: [-348.254 -348.254 -348.254] [0.0000], Avg: [-473.833 -473.833 -473.833] (0.394)
Step: 9349, Reward: [-465.184 -465.184 -465.184] [0.0000], Avg: [-473.787 -473.787 -473.787] (0.392)
Step: 9399, Reward: [-432.323 -432.323 -432.323] [0.0000], Avg: [-473.566 -473.566 -473.566] (0.390)
Step: 9449, Reward: [-626.255 -626.255 -626.255] [0.0000], Avg: [-474.374 -474.374 -474.374] (0.388)
Step: 9499, Reward: [-488.513 -488.513 -488.513] [0.0000], Avg: [-474.449 -474.449 -474.449] (0.386)
Step: 9549, Reward: [-490.448 -490.448 -490.448] [0.0000], Avg: [-474.532 -474.532 -474.532] (0.384)
Step: 9599, Reward: [-489.711 -489.711 -489.711] [0.0000], Avg: [-474.611 -474.611 -474.611] (0.382)
Step: 9649, Reward: [-358.862 -358.862 -358.862] [0.0000], Avg: [-474.012 -474.012 -474.012] (0.380)
Step: 9699, Reward: [-422.364 -422.364 -422.364] [0.0000], Avg: [-473.746 -473.746 -473.746] (0.378)
Step: 9749, Reward: [-566.221 -566.221 -566.221] [0.0000], Avg: [-474.22 -474.22 -474.22] (0.376)
Step: 9799, Reward: [-386.424 -386.424 -386.424] [0.0000], Avg: [-473.772 -473.772 -473.772] (0.374)
Step: 9849, Reward: [-372.191 -372.191 -372.191] [0.0000], Avg: [-473.256 -473.256 -473.256] (0.373)
Step: 9899, Reward: [-362.525 -362.525 -362.525] [0.0000], Avg: [-472.697 -472.697 -472.697] (0.371)
Step: 9949, Reward: [-394.823 -394.823 -394.823] [0.0000], Avg: [-472.306 -472.306 -472.306] (0.369)
Step: 9999, Reward: [-478.93 -478.93 -478.93] [0.0000], Avg: [-472.339 -472.339 -472.339] (0.367)
Step: 10049, Reward: [-394.443 -394.443 -394.443] [0.0000], Avg: [-471.951 -471.951 -471.951] (0.365)
Step: 10099, Reward: [-318.352 -318.352 -318.352] [0.0000], Avg: [-471.191 -471.191 -471.191] (0.363)
Step: 10149, Reward: [-264.343 -264.343 -264.343] [0.0000], Avg: [-470.172 -470.172 -470.172] (0.361)
Step: 10199, Reward: [-505.592 -505.592 -505.592] [0.0000], Avg: [-470.345 -470.345 -470.345] (0.360)
Step: 10249, Reward: [-503.863 -503.863 -503.863] [0.0000], Avg: [-470.509 -470.509 -470.509] (0.358)
Step: 10299, Reward: [-507.224 -507.224 -507.224] [0.0000], Avg: [-470.687 -470.687 -470.687] (0.356)
Step: 10349, Reward: [-447.274 -447.274 -447.274] [0.0000], Avg: [-470.574 -470.574 -470.574] (0.354)
Step: 10399, Reward: [-571.925 -571.925 -571.925] [0.0000], Avg: [-471.061 -471.061 -471.061] (0.353)
Step: 10449, Reward: [-431.525 -431.525 -431.525] [0.0000], Avg: [-470.872 -470.872 -470.872] (0.351)
Step: 10499, Reward: [-741.256 -741.256 -741.256] [0.0000], Avg: [-472.16 -472.16 -472.16] (0.349)
Step: 10549, Reward: [-463.902 -463.902 -463.902] [0.0000], Avg: [-472.121 -472.121 -472.121] (0.347)
Step: 10599, Reward: [-556.154 -556.154 -556.154] [0.0000], Avg: [-472.517 -472.517 -472.517] (0.346)
Step: 10649, Reward: [-573.569 -573.569 -573.569] [0.0000], Avg: [-472.991 -472.991 -472.991] (0.344)
Step: 10699, Reward: [-454.955 -454.955 -454.955] [0.0000], Avg: [-472.907 -472.907 -472.907] (0.342)
Step: 10749, Reward: [-526.245 -526.245 -526.245] [0.0000], Avg: [-473.155 -473.155 -473.155] (0.340)
Step: 10799, Reward: [-383.785 -383.785 -383.785] [0.0000], Avg: [-472.741 -472.741 -472.741] (0.339)
Step: 10849, Reward: [-508.554 -508.554 -508.554] [0.0000], Avg: [-472.906 -472.906 -472.906] (0.337)
Step: 10899, Reward: [-419.524 -419.524 -419.524] [0.0000], Avg: [-472.662 -472.662 -472.662] (0.335)
Step: 10949, Reward: [-431.678 -431.678 -431.678] [0.0000], Avg: [-472.474 -472.474 -472.474] (0.334)
Step: 10999, Reward: [-616.339 -616.339 -616.339] [0.0000], Avg: [-473.128 -473.128 -473.128] (0.332)
Step: 11049, Reward: [-494.531 -494.531 -494.531] [0.0000], Avg: [-473.225 -473.225 -473.225] (0.330)
Step: 11099, Reward: [-583.57 -583.57 -583.57] [0.0000], Avg: [-473.722 -473.722 -473.722] (0.329)
Step: 11149, Reward: [-410.948 -410.948 -410.948] [0.0000], Avg: [-473.441 -473.441 -473.441] (0.327)
Step: 11199, Reward: [-640.303 -640.303 -640.303] [0.0000], Avg: [-474.186 -474.186 -474.186] (0.325)
Step: 11249, Reward: [-441.769 -441.769 -441.769] [0.0000], Avg: [-474.042 -474.042 -474.042] (0.324)
Step: 11299, Reward: [-408.56 -408.56 -408.56] [0.0000], Avg: [-473.752 -473.752 -473.752] (0.322)
Step: 11349, Reward: [-479.8 -479.8 -479.8] [0.0000], Avg: [-473.779 -473.779 -473.779] (0.321)
Step: 11399, Reward: [-452.647 -452.647 -452.647] [0.0000], Avg: [-473.686 -473.686 -473.686] (0.319)
Step: 11449, Reward: [-260.289 -260.289 -260.289] [0.0000], Avg: [-472.754 -472.754 -472.754] (0.317)
Step: 11499, Reward: [-474.428 -474.428 -474.428] [0.0000], Avg: [-472.761 -472.761 -472.761] (0.316)
Step: 11549, Reward: [-779.519 -779.519 -779.519] [0.0000], Avg: [-474.089 -474.089 -474.089] (0.314)
Step: 11599, Reward: [-429.959 -429.959 -429.959] [0.0000], Avg: [-473.899 -473.899 -473.899] (0.313)
Step: 11649, Reward: [-461.696 -461.696 -461.696] [0.0000], Avg: [-473.847 -473.847 -473.847] (0.311)
Step: 11699, Reward: [-313.704 -313.704 -313.704] [0.0000], Avg: [-473.162 -473.162 -473.162] (0.309)
Step: 11749, Reward: [-486.163 -486.163 -486.163] [0.0000], Avg: [-473.218 -473.218 -473.218] (0.308)
Step: 11799, Reward: [-308.79 -308.79 -308.79] [0.0000], Avg: [-472.521 -472.521 -472.521] (0.306)
Step: 11849, Reward: [-419.161 -419.161 -419.161] [0.0000], Avg: [-472.296 -472.296 -472.296] (0.305)
Step: 11899, Reward: [-434.172 -434.172 -434.172] [0.0000], Avg: [-472.136 -472.136 -472.136] (0.303)
Step: 11949, Reward: [-562.179 -562.179 -562.179] [0.0000], Avg: [-472.512 -472.512 -472.512] (0.302)
Step: 11999, Reward: [-386.557 -386.557 -386.557] [0.0000], Avg: [-472.154 -472.154 -472.154] (0.300)
Step: 12049, Reward: [-465.533 -465.533 -465.533] [0.0000], Avg: [-472.127 -472.127 -472.127] (0.299)
Step: 12099, Reward: [-423.842 -423.842 -423.842] [0.0000], Avg: [-471.927 -471.927 -471.927] (0.297)
Step: 12149, Reward: [-560.591 -560.591 -560.591] [0.0000], Avg: [-472.292 -472.292 -472.292] (0.296)
Step: 12199, Reward: [-387.076 -387.076 -387.076] [0.0000], Avg: [-471.943 -471.943 -471.943] (0.294)
Step: 12249, Reward: [-544.663 -544.663 -544.663] [0.0000], Avg: [-472.24 -472.24 -472.24] (0.293)
Step: 12299, Reward: [-477.128 -477.128 -477.128] [0.0000], Avg: [-472.259 -472.259 -472.259] (0.291)
Step: 12349, Reward: [-558.895 -558.895 -558.895] [0.0000], Avg: [-472.61 -472.61 -472.61] (0.290)
Step: 12399, Reward: [-539.628 -539.628 -539.628] [0.0000], Avg: [-472.88 -472.88 -472.88] (0.288)
Step: 12449, Reward: [-474.941 -474.941 -474.941] [0.0000], Avg: [-472.889 -472.889 -472.889] (0.287)
Step: 12499, Reward: [-394.446 -394.446 -394.446] [0.0000], Avg: [-472.575 -472.575 -472.575] (0.286)
Step: 12549, Reward: [-401.257 -401.257 -401.257] [0.0000], Avg: [-472.291 -472.291 -472.291] (0.284)
Step: 12599, Reward: [-617.323 -617.323 -617.323] [0.0000], Avg: [-472.866 -472.866 -472.866] (0.283)
Step: 12649, Reward: [-391.746 -391.746 -391.746] [0.0000], Avg: [-472.546 -472.546 -472.546] (0.281)
Step: 12699, Reward: [-447.656 -447.656 -447.656] [0.0000], Avg: [-472.448 -472.448 -472.448] (0.280)
Step: 12749, Reward: [-285.535 -285.535 -285.535] [0.0000], Avg: [-471.715 -471.715 -471.715] (0.279)
Step: 12799, Reward: [-442.66 -442.66 -442.66] [0.0000], Avg: [-471.601 -471.601 -471.601] (0.277)
Step: 12849, Reward: [-352.341 -352.341 -352.341] [0.0000], Avg: [-471.137 -471.137 -471.137] (0.276)
Step: 12899, Reward: [-518.863 -518.863 -518.863] [0.0000], Avg: [-471.322 -471.322 -471.322] (0.274)
Step: 12949, Reward: [-578.52 -578.52 -578.52] [0.0000], Avg: [-471.736 -471.736 -471.736] (0.273)
Step: 12999, Reward: [-456.942 -456.942 -456.942] [0.0000], Avg: [-471.679 -471.679 -471.679] (0.272)
Step: 13049, Reward: [-541.736 -541.736 -541.736] [0.0000], Avg: [-471.948 -471.948 -471.948] (0.270)
Step: 13099, Reward: [-385.477 -385.477 -385.477] [0.0000], Avg: [-471.618 -471.618 -471.618] (0.269)
Step: 13149, Reward: [-383.511 -383.511 -383.511] [0.0000], Avg: [-471.283 -471.283 -471.283] (0.268)
Step: 13199, Reward: [-478.585 -478.585 -478.585] [0.0000], Avg: [-471.31 -471.31 -471.31] (0.266)
Step: 13249, Reward: [-297.927 -297.927 -297.927] [0.0000], Avg: [-470.656 -470.656 -470.656] (0.265)
Step: 13299, Reward: [-442.856 -442.856 -442.856] [0.0000], Avg: [-470.551 -470.551 -470.551] (0.264)
Step: 13349, Reward: [-374.897 -374.897 -374.897] [0.0000], Avg: [-470.193 -470.193 -470.193] (0.262)
Step: 13399, Reward: [-686.064 -686.064 -686.064] [0.0000], Avg: [-470.999 -470.999 -470.999] (0.261)
Step: 13449, Reward: [-421.648 -421.648 -421.648] [0.0000], Avg: [-470.815 -470.815 -470.815] (0.260)
Step: 13499, Reward: [-524.525 -524.525 -524.525] [0.0000], Avg: [-471.014 -471.014 -471.014] (0.258)
Step: 13549, Reward: [-311.501 -311.501 -311.501] [0.0000], Avg: [-470.425 -470.425 -470.425] (0.257)
Step: 13599, Reward: [-398.761 -398.761 -398.761] [0.0000], Avg: [-470.162 -470.162 -470.162] (0.256)
Step: 13649, Reward: [-427.839 -427.839 -427.839] [0.0000], Avg: [-470.007 -470.007 -470.007] (0.255)
Step: 13699, Reward: [-453.704 -453.704 -453.704] [0.0000], Avg: [-469.947 -469.947 -469.947] (0.253)
Step: 13749, Reward: [-688.263 -688.263 -688.263] [0.0000], Avg: [-470.741 -470.741 -470.741] (0.252)
Step: 13799, Reward: [-665.867 -665.867 -665.867] [0.0000], Avg: [-471.448 -471.448 -471.448] (0.251)
Step: 13849, Reward: [-387.102 -387.102 -387.102] [0.0000], Avg: [-471.144 -471.144 -471.144] (0.249)
Step: 13899, Reward: [-513.844 -513.844 -513.844] [0.0000], Avg: [-471.297 -471.297 -471.297] (0.248)
Step: 13949, Reward: [-331.256 -331.256 -331.256] [0.0000], Avg: [-470.795 -470.795 -470.795] (0.247)
Step: 13999, Reward: [-614.037 -614.037 -614.037] [0.0000], Avg: [-471.307 -471.307 -471.307] (0.246)
Step: 14049, Reward: [-335.408 -335.408 -335.408] [0.0000], Avg: [-470.823 -470.823 -470.823] (0.245)
Step: 14099, Reward: [-373.299 -373.299 -373.299] [0.0000], Avg: [-470.478 -470.478 -470.478] (0.243)
Step: 14149, Reward: [-380.322 -380.322 -380.322] [0.0000], Avg: [-470.159 -470.159 -470.159] (0.242)
Step: 14199, Reward: [-422.204 -422.204 -422.204] [0.0000], Avg: [-469.99 -469.99 -469.99] (0.241)
Step: 14249, Reward: [-497.763 -497.763 -497.763] [0.0000], Avg: [-470.088 -470.088 -470.088] (0.240)
Step: 14299, Reward: [-331.746 -331.746 -331.746] [0.0000], Avg: [-469.604 -469.604 -469.604] (0.238)
Step: 14349, Reward: [-427.543 -427.543 -427.543] [0.0000], Avg: [-469.457 -469.457 -469.457] (0.237)
Step: 14399, Reward: [-417.185 -417.185 -417.185] [0.0000], Avg: [-469.276 -469.276 -469.276] (0.236)
Step: 14449, Reward: [-488.095 -488.095 -488.095] [0.0000], Avg: [-469.341 -469.341 -469.341] (0.235)
Step: 14499, Reward: [-372.589 -372.589 -372.589] [0.0000], Avg: [-469.007 -469.007 -469.007] (0.234)
Step: 14549, Reward: [-598.542 -598.542 -598.542] [0.0000], Avg: [-469.452 -469.452 -469.452] (0.233)
Step: 14599, Reward: [-305.898 -305.898 -305.898] [0.0000], Avg: [-468.892 -468.892 -468.892] (0.231)
Step: 14649, Reward: [-350.73 -350.73 -350.73] [0.0000], Avg: [-468.489 -468.489 -468.489] (0.230)
Step: 14699, Reward: [-460.519 -460.519 -460.519] [0.0000], Avg: [-468.462 -468.462 -468.462] (0.229)
Step: 14749, Reward: [-533.785 -533.785 -533.785] [0.0000], Avg: [-468.683 -468.683 -468.683] (0.228)
Step: 14799, Reward: [-432.061 -432.061 -432.061] [0.0000], Avg: [-468.56 -468.56 -468.56] (0.227)
Step: 14849, Reward: [-483.844 -483.844 -483.844] [0.0000], Avg: [-468.611 -468.611 -468.611] (0.226)
Step: 14899, Reward: [-684.667 -684.667 -684.667] [0.0000], Avg: [-469.336 -469.336 -469.336] (0.225)
Step: 14949, Reward: [-363.213 -363.213 -363.213] [0.0000], Avg: [-468.981 -468.981 -468.981] (0.223)
Step: 14999, Reward: [-509.452 -509.452 -509.452] [0.0000], Avg: [-469.116 -469.116 -469.116] (0.222)
Step: 15049, Reward: [-450.279 -450.279 -450.279] [0.0000], Avg: [-469.054 -469.054 -469.054] (0.221)
Step: 15099, Reward: [-551.245 -551.245 -551.245] [0.0000], Avg: [-469.326 -469.326 -469.326] (0.220)
Step: 15149, Reward: [-349.131 -349.131 -349.131] [0.0000], Avg: [-468.929 -468.929 -468.929] (0.219)
Step: 15199, Reward: [-418.824 -418.824 -418.824] [0.0000], Avg: [-468.764 -468.764 -468.764] (0.218)
Step: 15249, Reward: [-617.581 -617.581 -617.581] [0.0000], Avg: [-469.252 -469.252 -469.252] (0.217)
Step: 15299, Reward: [-433.116 -433.116 -433.116] [0.0000], Avg: [-469.134 -469.134 -469.134] (0.216)
Step: 15349, Reward: [-418.491 -418.491 -418.491] [0.0000], Avg: [-468.969 -468.969 -468.969] (0.215)
Step: 15399, Reward: [-540.47 -540.47 -540.47] [0.0000], Avg: [-469.201 -469.201 -469.201] (0.214)
Step: 15449, Reward: [-428.144 -428.144 -428.144] [0.0000], Avg: [-469.068 -469.068 -469.068] (0.212)
Step: 15499, Reward: [-460.255 -460.255 -460.255] [0.0000], Avg: [-469.04 -469.04 -469.04] (0.211)
Step: 15549, Reward: [-379.064 -379.064 -379.064] [0.0000], Avg: [-468.751 -468.751 -468.751] (0.210)
Step: 15599, Reward: [-498.156 -498.156 -498.156] [0.0000], Avg: [-468.845 -468.845 -468.845] (0.209)
Step: 15649, Reward: [-411.499 -411.499 -411.499] [0.0000], Avg: [-468.662 -468.662 -468.662] (0.208)
Step: 15699, Reward: [-554.647 -554.647 -554.647] [0.0000], Avg: [-468.935 -468.935 -468.935] (0.207)
Step: 15749, Reward: [-432.611 -432.611 -432.611] [0.0000], Avg: [-468.82 -468.82 -468.82] (0.206)
Step: 15799, Reward: [-504.842 -504.842 -504.842] [0.0000], Avg: [-468.934 -468.934 -468.934] (0.205)
Step: 15849, Reward: [-354.336 -354.336 -354.336] [0.0000], Avg: [-468.573 -468.573 -468.573] (0.204)
Step: 15899, Reward: [-438.704 -438.704 -438.704] [0.0000], Avg: [-468.479 -468.479 -468.479] (0.203)
Step: 15949, Reward: [-416.289 -416.289 -416.289] [0.0000], Avg: [-468.315 -468.315 -468.315] (0.202)
Step: 15999, Reward: [-411.224 -411.224 -411.224] [0.0000], Avg: [-468.137 -468.137 -468.137] (0.201)
Step: 16049, Reward: [-409.176 -409.176 -409.176] [0.0000], Avg: [-467.953 -467.953 -467.953] (0.200)
Step: 16099, Reward: [-392.734 -392.734 -392.734] [0.0000], Avg: [-467.719 -467.719 -467.719] (0.199)
Step: 16149, Reward: [-356.872 -356.872 -356.872] [0.0000], Avg: [-467.376 -467.376 -467.376] (0.198)
Step: 16199, Reward: [-410.471 -410.471 -410.471] [0.0000], Avg: [-467.201 -467.201 -467.201] (0.197)
Step: 16249, Reward: [-623.57 -623.57 -623.57] [0.0000], Avg: [-467.682 -467.682 -467.682] (0.196)
Step: 16299, Reward: [-382.291 -382.291 -382.291] [0.0000], Avg: [-467.42 -467.42 -467.42] (0.195)
Step: 16349, Reward: [-360.571 -360.571 -360.571] [0.0000], Avg: [-467.093 -467.093 -467.093] (0.194)
Step: 16399, Reward: [-374.36 -374.36 -374.36] [0.0000], Avg: [-466.81 -466.81 -466.81] (0.193)
Step: 16449, Reward: [-629.023 -629.023 -629.023] [0.0000], Avg: [-467.303 -467.303 -467.303] (0.192)
Step: 16499, Reward: [-314.809 -314.809 -314.809] [0.0000], Avg: [-466.841 -466.841 -466.841] (0.191)
Step: 16549, Reward: [-397.682 -397.682 -397.682] [0.0000], Avg: [-466.632 -466.632 -466.632] (0.190)
Step: 16599, Reward: [-418.029 -418.029 -418.029] [0.0000], Avg: [-466.486 -466.486 -466.486] (0.189)
Step: 16649, Reward: [-408.958 -408.958 -408.958] [0.0000], Avg: [-466.313 -466.313 -466.313] (0.188)
Step: 16699, Reward: [-357.432 -357.432 -357.432] [0.0000], Avg: [-465.987 -465.987 -465.987] (0.187)
Step: 16749, Reward: [-517.844 -517.844 -517.844] [0.0000], Avg: [-466.142 -466.142 -466.142] (0.187)
Step: 16799, Reward: [-458.603 -458.603 -458.603] [0.0000], Avg: [-466.12 -466.12 -466.12] (0.186)
Step: 16849, Reward: [-320.435 -320.435 -320.435] [0.0000], Avg: [-465.687 -465.687 -465.687] (0.185)
Step: 16899, Reward: [-284.401 -284.401 -284.401] [0.0000], Avg: [-465.151 -465.151 -465.151] (0.184)
Step: 16949, Reward: [-491.132 -491.132 -491.132] [0.0000], Avg: [-465.228 -465.228 -465.228] (0.183)
Step: 16999, Reward: [-326.396 -326.396 -326.396] [0.0000], Avg: [-464.819 -464.819 -464.819] (0.182)
Step: 17049, Reward: [-458.716 -458.716 -458.716] [0.0000], Avg: [-464.801 -464.801 -464.801] (0.181)
Step: 17099, Reward: [-431. -431. -431.] [0.0000], Avg: [-464.703 -464.703 -464.703] (0.180)
Step: 17149, Reward: [-336.891 -336.891 -336.891] [0.0000], Avg: [-464.33 -464.33 -464.33] (0.179)
Step: 17199, Reward: [-440.25 -440.25 -440.25] [0.0000], Avg: [-464.26 -464.26 -464.26] (0.178)
Step: 17249, Reward: [-455.419 -455.419 -455.419] [0.0000], Avg: [-464.234 -464.234 -464.234] (0.177)
Step: 17299, Reward: [-399.897 -399.897 -399.897] [0.0000], Avg: [-464.048 -464.048 -464.048] (0.177)
Step: 17349, Reward: [-462.832 -462.832 -462.832] [0.0000], Avg: [-464.045 -464.045 -464.045] (0.176)
Step: 17399, Reward: [-372.321 -372.321 -372.321] [0.0000], Avg: [-463.781 -463.781 -463.781] (0.175)
Step: 17449, Reward: [-545.387 -545.387 -545.387] [0.0000], Avg: [-464.015 -464.015 -464.015] (0.174)
Step: 17499, Reward: [-320.715 -320.715 -320.715] [0.0000], Avg: [-463.606 -463.606 -463.606] (0.173)
Step: 17549, Reward: [-413.824 -413.824 -413.824] [0.0000], Avg: [-463.464 -463.464 -463.464] (0.172)
Step: 17599, Reward: [-465.141 -465.141 -465.141] [0.0000], Avg: [-463.469 -463.469 -463.469] (0.171)
Step: 17649, Reward: [-620.834 -620.834 -620.834] [0.0000], Avg: [-463.914 -463.914 -463.914] (0.170)
Step: 17699, Reward: [-418.69 -418.69 -418.69] [0.0000], Avg: [-463.787 -463.787 -463.787] (0.170)
Step: 17749, Reward: [-433.429 -433.429 -433.429] [0.0000], Avg: [-463.701 -463.701 -463.701] (0.169)
Step: 17799, Reward: [-361.884 -361.884 -361.884] [0.0000], Avg: [-463.415 -463.415 -463.415] (0.168)
Step: 17849, Reward: [-452.432 -452.432 -452.432] [0.0000], Avg: [-463.384 -463.384 -463.384] (0.167)
Step: 17899, Reward: [-394.068 -394.068 -394.068] [0.0000], Avg: [-463.191 -463.191 -463.191] (0.166)
Step: 17949, Reward: [-454.316 -454.316 -454.316] [0.0000], Avg: [-463.166 -463.166 -463.166] (0.165)
Step: 17999, Reward: [-345.247 -345.247 -345.247] [0.0000], Avg: [-462.838 -462.838 -462.838] (0.165)
Step: 18049, Reward: [-343.8 -343.8 -343.8] [0.0000], Avg: [-462.509 -462.509 -462.509] (0.164)
Step: 18099, Reward: [-410.792 -410.792 -410.792] [0.0000], Avg: [-462.366 -462.366 -462.366] (0.163)
Step: 18149, Reward: [-462.88 -462.88 -462.88] [0.0000], Avg: [-462.367 -462.367 -462.367] (0.162)
Step: 18199, Reward: [-365.278 -365.278 -365.278] [0.0000], Avg: [-462.101 -462.101 -462.101] (0.161)
Step: 18249, Reward: [-471.669 -471.669 -471.669] [0.0000], Avg: [-462.127 -462.127 -462.127] (0.160)
Step: 18299, Reward: [-402.472 -402.472 -402.472] [0.0000], Avg: [-461.964 -461.964 -461.964] (0.160)
Step: 18349, Reward: [-575.177 -575.177 -575.177] [0.0000], Avg: [-462.272 -462.272 -462.272] (0.159)
Step: 18399, Reward: [-458.856 -458.856 -458.856] [0.0000], Avg: [-462.263 -462.263 -462.263] (0.158)
Step: 18449, Reward: [-469.163 -469.163 -469.163] [0.0000], Avg: [-462.282 -462.282 -462.282] (0.157)
Step: 18499, Reward: [-551.449 -551.449 -551.449] [0.0000], Avg: [-462.523 -462.523 -462.523] (0.157)
Step: 18549, Reward: [-308.951 -308.951 -308.951] [0.0000], Avg: [-462.109 -462.109 -462.109] (0.156)
Step: 18599, Reward: [-458.405 -458.405 -458.405] [0.0000], Avg: [-462.099 -462.099 -462.099] (0.155)
Step: 18649, Reward: [-416.871 -416.871 -416.871] [0.0000], Avg: [-461.977 -461.977 -461.977] (0.154)
Step: 18699, Reward: [-693.129 -693.129 -693.129] [0.0000], Avg: [-462.596 -462.596 -462.596] (0.153)
Step: 18749, Reward: [-501.369 -501.369 -501.369] [0.0000], Avg: [-462.699 -462.699 -462.699] (0.153)
Step: 18799, Reward: [-352.33 -352.33 -352.33] [0.0000], Avg: [-462.405 -462.405 -462.405] (0.152)
Step: 18849, Reward: [-482.353 -482.353 -482.353] [0.0000], Avg: [-462.458 -462.458 -462.458] (0.151)
Step: 18899, Reward: [-443.815 -443.815 -443.815] [0.0000], Avg: [-462.409 -462.409 -462.409] (0.150)
Step: 18949, Reward: [-561.795 -561.795 -561.795] [0.0000], Avg: [-462.671 -462.671 -462.671] (0.150)
Step: 18999, Reward: [-480.968 -480.968 -480.968] [0.0000], Avg: [-462.719 -462.719 -462.719] (0.149)
Step: 19049, Reward: [-472.112 -472.112 -472.112] [0.0000], Avg: [-462.744 -462.744 -462.744] (0.148)
Step: 19099, Reward: [-573.416 -573.416 -573.416] [0.0000], Avg: [-463.034 -463.034 -463.034] (0.147)
Step: 19149, Reward: [-418.853 -418.853 -418.853] [0.0000], Avg: [-462.918 -462.918 -462.918] (0.147)
Step: 19199, Reward: [-405.936 -405.936 -405.936] [0.0000], Avg: [-462.77 -462.77 -462.77] (0.146)
Step: 19249, Reward: [-507.837 -507.837 -507.837] [0.0000], Avg: [-462.887 -462.887 -462.887] (0.145)
Step: 19299, Reward: [-589.87 -589.87 -589.87] [0.0000], Avg: [-463.216 -463.216 -463.216] (0.144)
Step: 19349, Reward: [-455.939 -455.939 -455.939] [0.0000], Avg: [-463.197 -463.197 -463.197] (0.144)
Step: 19399, Reward: [-516.355 -516.355 -516.355] [0.0000], Avg: [-463.334 -463.334 -463.334] (0.143)
Step: 19449, Reward: [-447.263 -447.263 -447.263] [0.0000], Avg: [-463.293 -463.293 -463.293] (0.142)
Step: 19499, Reward: [-474.234 -474.234 -474.234] [0.0000], Avg: [-463.321 -463.321 -463.321] (0.142)
Step: 19549, Reward: [-484.51 -484.51 -484.51] [0.0000], Avg: [-463.375 -463.375 -463.375] (0.141)
Step: 19599, Reward: [-308.469 -308.469 -308.469] [0.0000], Avg: [-462.98 -462.98 -462.98] (0.140)
Step: 19649, Reward: [-525.628 -525.628 -525.628] [0.0000], Avg: [-463.139 -463.139 -463.139] (0.139)
Step: 19699, Reward: [-433.718 -433.718 -433.718] [0.0000], Avg: [-463.065 -463.065 -463.065] (0.139)
Step: 19749, Reward: [-343.17 -343.17 -343.17] [0.0000], Avg: [-462.761 -462.761 -462.761] (0.138)
Step: 19799, Reward: [-397.629 -397.629 -397.629] [0.0000], Avg: [-462.597 -462.597 -462.597] (0.137)
Step: 19849, Reward: [-396.805 -396.805 -396.805] [0.0000], Avg: [-462.431 -462.431 -462.431] (0.137)
Step: 19899, Reward: [-457.579 -457.579 -457.579] [0.0000], Avg: [-462.419 -462.419 -462.419] (0.136)
Step: 19949, Reward: [-493.6 -493.6 -493.6] [0.0000], Avg: [-462.497 -462.497 -462.497] (0.135)
Step: 19999, Reward: [-445.148 -445.148 -445.148] [0.0000], Avg: [-462.454 -462.454 -462.454] (0.135)
Step: 20049, Reward: [-695.407 -695.407 -695.407] [0.0000], Avg: [-463.035 -463.035 -463.035] (0.134)
Step: 20099, Reward: [-407.377 -407.377 -407.377] [0.0000], Avg: [-462.896 -462.896 -462.896] (0.133)
Step: 20149, Reward: [-398.966 -398.966 -398.966] [0.0000], Avg: [-462.737 -462.737 -462.737] (0.133)
Step: 20199, Reward: [-525.338 -525.338 -525.338] [0.0000], Avg: [-462.892 -462.892 -462.892] (0.132)
Step: 20249, Reward: [-326.366 -326.366 -326.366] [0.0000], Avg: [-462.555 -462.555 -462.555] (0.131)
Step: 20299, Reward: [-402.958 -402.958 -402.958] [0.0000], Avg: [-462.408 -462.408 -462.408] (0.131)
Step: 20349, Reward: [-715.211 -715.211 -715.211] [0.0000], Avg: [-463.03 -463.03 -463.03] (0.130)
Step: 20399, Reward: [-387.775 -387.775 -387.775] [0.0000], Avg: [-462.845 -462.845 -462.845] (0.129)
Step: 20449, Reward: [-477.718 -477.718 -477.718] [0.0000], Avg: [-462.882 -462.882 -462.882] (0.129)
Step: 20499, Reward: [-542.148 -542.148 -542.148] [0.0000], Avg: [-463.075 -463.075 -463.075] (0.128)
Step: 20549, Reward: [-435.723 -435.723 -435.723] [0.0000], Avg: [-463.008 -463.008 -463.008] (0.127)
Step: 20599, Reward: [-481.04 -481.04 -481.04] [0.0000], Avg: [-463.052 -463.052 -463.052] (0.127)
Step: 20649, Reward: [-391.579 -391.579 -391.579] [0.0000], Avg: [-462.879 -462.879 -462.879] (0.126)
Step: 20699, Reward: [-548.269 -548.269 -548.269] [0.0000], Avg: [-463.085 -463.085 -463.085] (0.126)
Step: 20749, Reward: [-376.361 -376.361 -376.361] [0.0000], Avg: [-462.876 -462.876 -462.876] (0.125)
Step: 20799, Reward: [-485.821 -485.821 -485.821] [0.0000], Avg: [-462.931 -462.931 -462.931] (0.124)
Step: 20849, Reward: [-434.555 -434.555 -434.555] [0.0000], Avg: [-462.863 -462.863 -462.863] (0.124)
Step: 20899, Reward: [-431.143 -431.143 -431.143] [0.0000], Avg: [-462.788 -462.788 -462.788] (0.123)
Step: 20949, Reward: [-477.581 -477.581 -477.581] [0.0000], Avg: [-462.823 -462.823 -462.823] (0.122)
Step: 20999, Reward: [-390.965 -390.965 -390.965] [0.0000], Avg: [-462.652 -462.652 -462.652] (0.122)
Step: 21049, Reward: [-619.618 -619.618 -619.618] [0.0000], Avg: [-463.025 -463.025 -463.025] (0.121)
Step: 21099, Reward: [-427.577 -427.577 -427.577] [0.0000], Avg: [-462.941 -462.941 -462.941] (0.121)
Step: 21149, Reward: [-408.507 -408.507 -408.507] [0.0000], Avg: [-462.812 -462.812 -462.812] (0.120)
Step: 21199, Reward: [-553.68 -553.68 -553.68] [0.0000], Avg: [-463.026 -463.026 -463.026] (0.119)
Step: 21249, Reward: [-389.431 -389.431 -389.431] [0.0000], Avg: [-462.853 -462.853 -462.853] (0.119)
Step: 21299, Reward: [-402.044 -402.044 -402.044] [0.0000], Avg: [-462.71 -462.71 -462.71] (0.118)
Step: 21349, Reward: [-470.545 -470.545 -470.545] [0.0000], Avg: [-462.729 -462.729 -462.729] (0.118)
Step: 21399, Reward: [-342.116 -342.116 -342.116] [0.0000], Avg: [-462.447 -462.447 -462.447] (0.117)
Step: 21449, Reward: [-857.137 -857.137 -857.137] [0.0000], Avg: [-463.367 -463.367 -463.367] (0.116)
Step: 21499, Reward: [-453.724 -453.724 -453.724] [0.0000], Avg: [-463.344 -463.344 -463.344] (0.116)
Step: 21549, Reward: [-337.786 -337.786 -337.786] [0.0000], Avg: [-463.053 -463.053 -463.053] (0.115)
Step: 21599, Reward: [-371.946 -371.946 -371.946] [0.0000], Avg: [-462.842 -462.842 -462.842] (0.115)
Step: 21649, Reward: [-535.365 -535.365 -535.365] [0.0000], Avg: [-463.01 -463.01 -463.01] (0.114)
Step: 21699, Reward: [-508.222 -508.222 -508.222] [0.0000], Avg: [-463.114 -463.114 -463.114] (0.114)
Step: 21749, Reward: [-481.202 -481.202 -481.202] [0.0000], Avg: [-463.155 -463.155 -463.155] (0.113)
Step: 21799, Reward: [-412.991 -412.991 -412.991] [0.0000], Avg: [-463.04 -463.04 -463.04] (0.112)
Step: 21849, Reward: [-585.112 -585.112 -585.112] [0.0000], Avg: [-463.32 -463.32 -463.32] (0.112)
Step: 21899, Reward: [-419.316 -419.316 -419.316] [0.0000], Avg: [-463.219 -463.219 -463.219] (0.111)
Step: 21949, Reward: [-406.622 -406.622 -406.622] [0.0000], Avg: [-463.09 -463.09 -463.09] (0.111)
Step: 21999, Reward: [-402.476 -402.476 -402.476] [0.0000], Avg: [-462.953 -462.953 -462.953] (0.110)
Step: 22049, Reward: [-348.44 -348.44 -348.44] [0.0000], Avg: [-462.693 -462.693 -462.693] (0.110)
Step: 22099, Reward: [-374. -374. -374.] [0.0000], Avg: [-462.492 -462.492 -462.492] (0.109)
Step: 22149, Reward: [-309.973 -309.973 -309.973] [0.0000], Avg: [-462.148 -462.148 -462.148] (0.109)
Step: 22199, Reward: [-426.705 -426.705 -426.705] [0.0000], Avg: [-462.068 -462.068 -462.068] (0.108)
Step: 22249, Reward: [-401.035 -401.035 -401.035] [0.0000], Avg: [-461.931 -461.931 -461.931] (0.107)
Step: 22299, Reward: [-772.564 -772.564 -772.564] [0.0000], Avg: [-462.628 -462.628 -462.628] (0.107)
Step: 22349, Reward: [-534.671 -534.671 -534.671] [0.0000], Avg: [-462.789 -462.789 -462.789] (0.106)
Step: 22399, Reward: [-456.59 -456.59 -456.59] [0.0000], Avg: [-462.775 -462.775 -462.775] (0.106)
Step: 22449, Reward: [-328.805 -328.805 -328.805] [0.0000], Avg: [-462.476 -462.476 -462.476] (0.105)
Step: 22499, Reward: [-389.605 -389.605 -389.605] [0.0000], Avg: [-462.315 -462.315 -462.315] (0.105)
Step: 22549, Reward: [-400.7 -400.7 -400.7] [0.0000], Avg: [-462.178 -462.178 -462.178] (0.104)
Step: 22599, Reward: [-391.814 -391.814 -391.814] [0.0000], Avg: [-462.022 -462.022 -462.022] (0.104)
Step: 22649, Reward: [-412.582 -412.582 -412.582] [0.0000], Avg: [-461.913 -461.913 -461.913] (0.103)
Step: 22699, Reward: [-389.013 -389.013 -389.013] [0.0000], Avg: [-461.753 -461.753 -461.753] (0.103)
Step: 22749, Reward: [-547.463 -547.463 -547.463] [0.0000], Avg: [-461.941 -461.941 -461.941] (0.102)
Step: 22799, Reward: [-565.521 -565.521 -565.521] [0.0000], Avg: [-462.168 -462.168 -462.168] (0.102)
Step: 22849, Reward: [-307.168 -307.168 -307.168] [0.0000], Avg: [-461.829 -461.829 -461.829] (0.101)
Step: 22899, Reward: [-420.368 -420.368 -420.368] [0.0000], Avg: [-461.738 -461.738 -461.738] (0.101)
Step: 22949, Reward: [-506.663 -506.663 -506.663] [0.0000], Avg: [-461.836 -461.836 -461.836] (0.100)
Step: 22999, Reward: [-412.501 -412.501 -412.501] [0.0000], Avg: [-461.729 -461.729 -461.729] (0.100)
Step: 23049, Reward: [-405.652 -405.652 -405.652] [0.0000], Avg: [-461.607 -461.607 -461.607] (0.099)
Step: 23099, Reward: [-321.784 -321.784 -321.784] [0.0000], Avg: [-461.305 -461.305 -461.305] (0.099)
Step: 23149, Reward: [-359.276 -359.276 -359.276] [0.0000], Avg: [-461.084 -461.084 -461.084] (0.098)
Step: 23199, Reward: [-373.654 -373.654 -373.654] [0.0000], Avg: [-460.896 -460.896 -460.896] (0.098)
Step: 23249, Reward: [-504.942 -504.942 -504.942] [0.0000], Avg: [-460.991 -460.991 -460.991] (0.097)
Step: 23299, Reward: [-362.821 -362.821 -362.821] [0.0000], Avg: [-460.78 -460.78 -460.78] (0.097)
Step: 23349, Reward: [-364.743 -364.743 -364.743] [0.0000], Avg: [-460.574 -460.574 -460.574] (0.096)
Step: 23399, Reward: [-507.433 -507.433 -507.433] [0.0000], Avg: [-460.674 -460.674 -460.674] (0.096)
Step: 23449, Reward: [-393.024 -393.024 -393.024] [0.0000], Avg: [-460.53 -460.53 -460.53] (0.095)
Step: 23499, Reward: [-451.438 -451.438 -451.438] [0.0000], Avg: [-460.511 -460.511 -460.511] (0.095)
Step: 23549, Reward: [-338.741 -338.741 -338.741] [0.0000], Avg: [-460.252 -460.252 -460.252] (0.094)
Step: 23599, Reward: [-435.038 -435.038 -435.038] [0.0000], Avg: [-460.199 -460.199 -460.199] (0.094)
Step: 23649, Reward: [-512.796 -512.796 -512.796] [0.0000], Avg: [-460.31 -460.31 -460.31] (0.093)
Step: 23699, Reward: [-481.351 -481.351 -481.351] [0.0000], Avg: [-460.354 -460.354 -460.354] (0.093)
Step: 23749, Reward: [-434.732 -434.732 -434.732] [0.0000], Avg: [-460.301 -460.301 -460.301] (0.092)
Step: 23799, Reward: [-407.205 -407.205 -407.205] [0.0000], Avg: [-460.189 -460.189 -460.189] (0.092)
Step: 23849, Reward: [-472.761 -472.761 -472.761] [0.0000], Avg: [-460.215 -460.215 -460.215] (0.092)
Step: 23899, Reward: [-535.771 -535.771 -535.771] [0.0000], Avg: [-460.373 -460.373 -460.373] (0.091)
Step: 23949, Reward: [-310.016 -310.016 -310.016] [0.0000], Avg: [-460.06 -460.06 -460.06] (0.091)
Step: 23999, Reward: [-496.659 -496.659 -496.659] [0.0000], Avg: [-460.136 -460.136 -460.136] (0.090)
Step: 24049, Reward: [-346.35 -346.35 -346.35] [0.0000], Avg: [-459.899 -459.899 -459.899] (0.090)
Step: 24099, Reward: [-333.342 -333.342 -333.342] [0.0000], Avg: [-459.637 -459.637 -459.637] (0.089)
Step: 24149, Reward: [-559.061 -559.061 -559.061] [0.0000], Avg: [-459.842 -459.842 -459.842] (0.089)
Step: 24199, Reward: [-498.492 -498.492 -498.492] [0.0000], Avg: [-459.922 -459.922 -459.922] (0.088)
Step: 24249, Reward: [-426.342 -426.342 -426.342] [0.0000], Avg: [-459.853 -459.853 -459.853] (0.088)
Step: 24299, Reward: [-408.641 -408.641 -408.641] [0.0000], Avg: [-459.748 -459.748 -459.748] (0.088)
Step: 24349, Reward: [-594.925 -594.925 -594.925] [0.0000], Avg: [-460.025 -460.025 -460.025] (0.087)
Step: 24399, Reward: [-445.873 -445.873 -445.873] [0.0000], Avg: [-459.996 -459.996 -459.996] (0.087)
Step: 24449, Reward: [-285.133 -285.133 -285.133] [0.0000], Avg: [-459.639 -459.639 -459.639] (0.086)
Step: 24499, Reward: [-579.111 -579.111 -579.111] [0.0000], Avg: [-459.883 -459.883 -459.883] (0.086)
Step: 24549, Reward: [-394.426 -394.426 -394.426] [0.0000], Avg: [-459.749 -459.749 -459.749] (0.085)
Step: 24599, Reward: [-634.394 -634.394 -634.394] [0.0000], Avg: [-460.104 -460.104 -460.104] (0.085)
Step: 24649, Reward: [-777.945 -777.945 -777.945] [0.0000], Avg: [-460.749 -460.749 -460.749] (0.084)
Step: 24699, Reward: [-344.146 -344.146 -344.146] [0.0000], Avg: [-460.513 -460.513 -460.513] (0.084)
Step: 24749, Reward: [-663.262 -663.262 -663.262] [0.0000], Avg: [-460.922 -460.922 -460.922] (0.084)
Step: 24799, Reward: [-451.283 -451.283 -451.283] [0.0000], Avg: [-460.903 -460.903 -460.903] (0.083)
Step: 24849, Reward: [-369.012 -369.012 -369.012] [0.0000], Avg: [-460.718 -460.718 -460.718] (0.083)
Step: 24899, Reward: [-631.522 -631.522 -631.522] [0.0000], Avg: [-461.061 -461.061 -461.061] (0.082)
Step: 24949, Reward: [-423.93 -423.93 -423.93] [0.0000], Avg: [-460.987 -460.987 -460.987] (0.082)
Step: 24999, Reward: [-425.708 -425.708 -425.708] [0.0000], Avg: [-460.916 -460.916 -460.916] (0.082)
Step: 25049, Reward: [-555.194 -555.194 -555.194] [0.0000], Avg: [-461.104 -461.104 -461.104] (0.081)
Step: 25099, Reward: [-382.222 -382.222 -382.222] [0.0000], Avg: [-460.947 -460.947 -460.947] (0.081)
Step: 25149, Reward: [-422.953 -422.953 -422.953] [0.0000], Avg: [-460.872 -460.872 -460.872] (0.080)
Step: 25199, Reward: [-341.381 -341.381 -341.381] [0.0000], Avg: [-460.635 -460.635 -460.635] (0.080)
Step: 25249, Reward: [-330.384 -330.384 -330.384] [0.0000], Avg: [-460.377 -460.377 -460.377] (0.080)
Step: 25299, Reward: [-426.719 -426.719 -426.719] [0.0000], Avg: [-460.31 -460.31 -460.31] (0.079)
Step: 25349, Reward: [-452.074 -452.074 -452.074] [0.0000], Avg: [-460.294 -460.294 -460.294] (0.079)
Step: 25399, Reward: [-422.878 -422.878 -422.878] [0.0000], Avg: [-460.22 -460.22 -460.22] (0.078)
Step: 25449, Reward: [-442.391 -442.391 -442.391] [0.0000], Avg: [-460.185 -460.185 -460.185] (0.078)
Step: 25499, Reward: [-671.566 -671.566 -671.566] [0.0000], Avg: [-460.6 -460.6 -460.6] (0.078)
Step: 25549, Reward: [-577.632 -577.632 -577.632] [0.0000], Avg: [-460.829 -460.829 -460.829] (0.077)
Step: 25599, Reward: [-511.484 -511.484 -511.484] [0.0000], Avg: [-460.928 -460.928 -460.928] (0.077)
Step: 25649, Reward: [-410.658 -410.658 -410.658] [0.0000], Avg: [-460.83 -460.83 -460.83] (0.076)
Step: 25699, Reward: [-435.317 -435.317 -435.317] [0.0000], Avg: [-460.78 -460.78 -460.78] (0.076)
Step: 25749, Reward: [-378.736 -378.736 -378.736] [0.0000], Avg: [-460.621 -460.621 -460.621] (0.076)
Step: 25799, Reward: [-438.935 -438.935 -438.935] [0.0000], Avg: [-460.579 -460.579 -460.579] (0.075)
Step: 25849, Reward: [-364.218 -364.218 -364.218] [0.0000], Avg: [-460.392 -460.392 -460.392] (0.075)
Step: 25899, Reward: [-525.208 -525.208 -525.208] [0.0000], Avg: [-460.517 -460.517 -460.517] (0.075)
Step: 25949, Reward: [-309.812 -309.812 -309.812] [0.0000], Avg: [-460.227 -460.227 -460.227] (0.074)
Step: 25999, Reward: [-490.935 -490.935 -490.935] [0.0000], Avg: [-460.286 -460.286 -460.286] (0.074)
Step: 26049, Reward: [-437.649 -437.649 -437.649] [0.0000], Avg: [-460.243 -460.243 -460.243] (0.073)
Step: 26099, Reward: [-519.115 -519.115 -519.115] [0.0000], Avg: [-460.355 -460.355 -460.355] (0.073)
Step: 26149, Reward: [-425.073 -425.073 -425.073] [0.0000], Avg: [-460.288 -460.288 -460.288] (0.073)
Step: 26199, Reward: [-454.114 -454.114 -454.114] [0.0000], Avg: [-460.276 -460.276 -460.276] (0.072)
Step: 26249, Reward: [-344.718 -344.718 -344.718] [0.0000], Avg: [-460.056 -460.056 -460.056] (0.072)
Step: 26299, Reward: [-378.842 -378.842 -378.842] [0.0000], Avg: [-459.902 -459.902 -459.902] (0.072)
Step: 26349, Reward: [-325.651 -325.651 -325.651] [0.0000], Avg: [-459.647 -459.647 -459.647] (0.071)
Step: 26399, Reward: [-390.053 -390.053 -390.053] [0.0000], Avg: [-459.515 -459.515 -459.515] (0.071)
Step: 26449, Reward: [-510.935 -510.935 -510.935] [0.0000], Avg: [-459.612 -459.612 -459.612] (0.071)
Step: 26499, Reward: [-428.384 -428.384 -428.384] [0.0000], Avg: [-459.553 -459.553 -459.553] (0.070)
Step: 26549, Reward: [-359.44 -359.44 -359.44] [0.0000], Avg: [-459.365 -459.365 -459.365] (0.070)
Step: 26599, Reward: [-360.118 -360.118 -360.118] [0.0000], Avg: [-459.178 -459.178 -459.178] (0.069)
Step: 26649, Reward: [-477.471 -477.471 -477.471] [0.0000], Avg: [-459.213 -459.213 -459.213] (0.069)
Step: 26699, Reward: [-546.07 -546.07 -546.07] [0.0000], Avg: [-459.375 -459.375 -459.375] (0.069)
Step: 26749, Reward: [-415.581 -415.581 -415.581] [0.0000], Avg: [-459.293 -459.293 -459.293] (0.068)
Step: 26799, Reward: [-601.069 -601.069 -601.069] [0.0000], Avg: [-459.558 -459.558 -459.558] (0.068)
Step: 26849, Reward: [-431.087 -431.087 -431.087] [0.0000], Avg: [-459.505 -459.505 -459.505] (0.068)
Step: 26899, Reward: [-567.989 -567.989 -567.989] [0.0000], Avg: [-459.707 -459.707 -459.707] (0.067)
Step: 26949, Reward: [-351.897 -351.897 -351.897] [0.0000], Avg: [-459.507 -459.507 -459.507] (0.067)
Step: 26999, Reward: [-376.513 -376.513 -376.513] [0.0000], Avg: [-459.353 -459.353 -459.353] (0.067)
Step: 27049, Reward: [-547.02 -547.02 -547.02] [0.0000], Avg: [-459.515 -459.515 -459.515] (0.066)
Step: 27099, Reward: [-625.101 -625.101 -625.101] [0.0000], Avg: [-459.82 -459.82 -459.82] (0.066)
Step: 27149, Reward: [-378.699 -378.699 -378.699] [0.0000], Avg: [-459.671 -459.671 -459.671] (0.066)
Step: 27199, Reward: [-519.057 -519.057 -519.057] [0.0000], Avg: [-459.78 -459.78 -459.78] (0.065)
Step: 27249, Reward: [-308.243 -308.243 -308.243] [0.0000], Avg: [-459.502 -459.502 -459.502] (0.065)
Step: 27299, Reward: [-444.889 -444.889 -444.889] [0.0000], Avg: [-459.475 -459.475 -459.475] (0.065)
