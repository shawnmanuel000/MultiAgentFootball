Model: <class 'multiagent.coma.COMAAgent'>, Dir: simple_spread
num_envs: 4,
state_size: [(1, 18), (1, 18), (1, 18)],
action_size: [[1, 5], [1, 5], [1, 5]],
action_space: [MultiDiscrete([5]), MultiDiscrete([5]), MultiDiscrete([5])],
envs: <class 'utils.envs.EnsembleEnv'>,
reward_shape: False,
icm: False,

import copy
import torch
import numpy as np
from utils.network import PTNetwork, PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, one_hot_from_indices

LEARNING_RATE = 0.001
ALPHA = 0.99
EPS = 0.00001
LAMBDA = 0.95
DISCOUNT_RATE = 0.99
GRAD_NORM = 10
TARGET_UPDATE = 200

HIDDEN_SIZE = 64
EPS_MAX = 0.5
EPS_MIN = 0.01
EPS_DECAY = 0.995
NUM_ENVS = 4
EPISODE_LIMIT = 50
REPLAY_BATCH_SIZE = 32

class COMAAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, lambda *args, **kwargs: None, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		del self.network
		n_agents = len(action_size)
		n_actions = action_size[0][-1]
		n_obs = state_size[0][-1]
		state_len = int(np.sum([np.prod(space) for space in state_size]))
		preprocess = {"actions": ("actions_onehot", [OneHot(out_dim=n_actions)])}
		groups = {"agents": n_agents}
		scheme = {
			"state": {"vshape": state_len},
			"obs": {"vshape": n_obs, "group": "agents"},
			"actions": {"vshape": (1,), "group": "agents", "dtype": torch.long},
			"reward": {"vshape": (1,)},
			"done": {"vshape": (1,), "dtype": torch.uint8},
		}
		
		self.device = torch.device('cuda' if gpu and torch.cuda.is_available() else 'cpu')
		self.replay_buffer = ReplayBuffer(scheme, groups, NUM_ENVS, EPISODE_LIMIT+1, preprocess=preprocess, device=self.device)
		self.mac = BasicMAC(self.replay_buffer.scheme, groups, n_agents, n_actions, device=self.device)
		self.learner = COMALearner(self.mac, self.replay_buffer.scheme, n_agents, n_actions, device=self.device)
		self.new_episode_batch = lambda batch_size: EpisodeBatch(scheme, groups, batch_size, EPISODE_LIMIT+1, preprocess=preprocess, device=self.device)
		self.episode_batch = self.new_episode_batch(NUM_ENVS)
		self.mac.init_hidden(batch_size=NUM_ENVS)
		self.num_envs = NUM_ENVS
		self.time = 0

	def get_action(self, state, eps=None, sample=True, numpy=True):
		self.num_envs = state[0].shape[0] if len(state[0].shape) > len(self.state_size[0]) else 1
		if np.prod(self.mac.hidden_states.shape[:-1]) != self.num_envs*len(self.action_size): self.mac.init_hidden(batch_size=self.num_envs)
		if self.episode_batch.batch_size != self.num_envs: self.episode_batch = self.new_episode_batch(self.num_envs)
		self.step = 0 if not hasattr(self, "step") else (self.step + 1)%self.replay_buffer.max_seq_length
		state_joint = np.concatenate(state, -1)
		obs = np.concatenate(state, -2)
		if not hasattr(self, "action"): self.action = np.zeros([*obs.shape[:-1], self.action_size[0][-1]])
		self.episode_batch.update({"state": [state_joint], "obs": [obs]}, ts=self.step)
		actions = self.mac.select_actions(self.episode_batch, t_ep=self.step, t_env=self.time, test_mode=False)
		actions = actions.view([*state[0].shape[:-len(self.state_size[0])], actions.shape[-1]])
		return np.split(one_hot_from_indices(actions, self.action_size[0][-1]).cpu().numpy(), actions.size(-1), axis=-2)

	def train(self, state, action, next_state, reward, done):
		action, reward, done = [list(zip(*x)) for x in [action, reward, done]]
		post_transition_data = {"actions": [np.argmax(a, -1) for a in action], "reward": [np.mean(reward, -1)], "done": [np.any(done, -1)]}
		self.episode_batch.update(post_transition_data, ts=self.step)
		if np.any(done[0]):
			self.episode_batch.update({"state": [np.concatenate(next_state, -1)], "obs": [np.concatenate(next_state, -2)]}, ts=self.step)
			actions = self.mac.select_actions(self.episode_batch, t_ep=self.step, t_env=self.time, test_mode=False)
			self.episode_batch.update({"actions": actions}, ts=self.step)
			self.replay_buffer.insert_episode_batch(self.episode_batch)
			if self.replay_buffer.can_sample(REPLAY_BATCH_SIZE):
				episode_sample = self.replay_buffer.sample(REPLAY_BATCH_SIZE)
				max_ep_t = episode_sample.max_t_filled()
				episode_sample = episode_sample[:, :max_ep_t]
				if episode_sample.device != self.device: episode_sample.to(self.device)
				self.learner.train(episode_sample)
			self.episode_batch = self.new_episode_batch(state[0].shape[0])
			self.mac.init_hidden(self.num_envs)
			self.time += self.step
			self.step = 0

class OneHot():
	def __init__(self, out_dim):
		self.out_dim = out_dim

	def transform(self, tensor):
		y_onehot = tensor.new(*tensor.shape[:-1], self.out_dim).zero_()
		y_onehot.scatter_(-1, tensor.long(), 1)
		return y_onehot.float()

	def infer_output_info(self, vshape_in, dtype_in):
		return (self.out_dim,), torch.float32

class COMALearner():
	def __init__(self, mac, scheme, n_agents, n_actions, device):
		self.device = device
		self.n_agents = n_agents
		self.n_actions = n_actions
		self.last_target_update_step = 0
		self.mac = mac
		self.critic_training_steps = 0
		self.critic = COMACritic(scheme, self.n_agents, self.n_actions).to(self.device)
		self.critic_params = list(self.critic.parameters())
		self.agent_params = list(mac.parameters())
		self.params = self.agent_params + self.critic_params
		self.target_critic = copy.deepcopy(self.critic)
		self.agent_optimiser = torch.optim.RMSprop(params=self.agent_params, lr=LEARNING_RATE, alpha=ALPHA, eps=EPS)
		self.critic_optimiser = torch.optim.RMSprop(params=self.critic_params, lr=LEARNING_RATE, alpha=ALPHA, eps=EPS)

	def train(self, batch):
		# Get the relevant quantities
		bs = batch.batch_size
		max_t = batch.max_seq_length
		rewards = batch["reward"][:, :-1]
		actions = batch["actions"][:, :]
		done = batch["done"][:, :-1].float()
		mask = batch["filled"][:, :-1].float()
		mask[:, 1:] = mask[:, 1:] * (1 - done[:, :-1])
		critic_mask = mask.clone()
		mask = mask.repeat(1, 1, self.n_agents).view(-1)
		q_vals = self._train_critic(batch, rewards, done, actions, critic_mask, bs, max_t)
		actions = actions[:,:-1]
		mac_out = []
		self.mac.init_hidden(batch.batch_size)
		for t in range(batch.max_seq_length - 1):
			agent_outs = self.mac.forward(batch, t=t)
			mac_out.append(agent_outs)
		mac_out = torch.stack(mac_out, dim=1)  # Concat over time
		# Mask out unavailable actions, renormalise (as in action selection)
		q_vals = q_vals.reshape(-1, self.n_actions)
		pi = mac_out.view(-1, self.n_actions)
		baseline = (pi * q_vals).sum(-1).detach()
		q_taken = torch.gather(q_vals, dim=1, index=actions.reshape(-1, 1)).squeeze(1)
		pi_taken = torch.gather(pi, dim=1, index=actions.reshape(-1, 1)).squeeze(1)
		pi_taken[mask == 0] = 1.0
		log_pi_taken = torch.log(pi_taken)
		advantages = (q_taken - baseline).detach()
		coma_loss = - ((advantages * log_pi_taken) * mask).sum() / mask.sum()
		self.agent_optimiser.zero_grad()
		coma_loss.backward()
		torch.nn.utils.clip_grad_norm_(self.agent_params, GRAD_NORM)
		self.agent_optimiser.step()
		if (self.critic_training_steps - self.last_target_update_step) / TARGET_UPDATE >= 1.0:
			self._update_targets()
			self.last_target_update_step = self.critic_training_steps

	def _train_critic(self, batch, rewards, done, actions, mask, bs, max_t):
		target_q_vals = self.target_critic(batch)[:, :]
		targets_taken = torch.gather(target_q_vals, dim=3, index=actions).squeeze(3)
		targets = build_td_lambda_targets(rewards, done, mask, targets_taken, self.n_agents)
		q_vals = torch.zeros_like(target_q_vals)[:, :-1]
		for t in reversed(range(rewards.size(1))):
			mask_t = mask[:, t].expand(-1, self.n_agents)
			if mask_t.sum() == 0:
				continue
			q_t = self.critic(batch, t)
			q_vals[:, t] = q_t.view(bs, self.n_agents, self.n_actions)
			q_taken = torch.gather(q_t, dim=3, index=actions[:, t:t+1]).squeeze(3).squeeze(1)
			targets_t = targets[:, t]
			td_error = (q_taken - targets_t.detach())
			# 0-out the targets that came from padded data
			masked_td_error = td_error * mask_t
			loss = (masked_td_error ** 2).sum() / mask_t.sum()
			self.critic_optimiser.zero_grad()
			loss.backward()
			torch.nn.utils.clip_grad_norm_(self.critic_params, GRAD_NORM)
			self.critic_optimiser.step()
			self.critic_training_steps += 1
		return q_vals

	def _update_targets(self):
		self.target_critic.load_state_dict(self.critic.state_dict())

	def cuda(self):
		self.mac.cuda()
		self.critic.cuda()
		self.target_critic.cuda()

def build_td_lambda_targets(rewards, done, mask, target_qs, n_agents, gamma=DISCOUNT_RATE, td_lambda=LAMBDA):
	# Assumes  <target_qs > in B*T*A and <reward >, <done >, <mask > in (at least) B*T-1*1
	# Initialise  last  lambda -return  for  not  done  episodes
	ret = target_qs.new_zeros(*target_qs.shape)
	ret[:, -1] = target_qs[:, -1] * (1 - torch.sum(done, dim=1))
	# Backwards  recursive  update  of the "forward  view"
	for t in range(ret.shape[1] - 2, -1,  -1):
		ret[:, t] = td_lambda * gamma * ret[:, t + 1] + mask[:, t]*(rewards[:, t] + (1 - td_lambda) * gamma * target_qs[:, t + 1] * (1 - done[:, t]))
	# Returns lambda-return from t=0 to t=T-1, i.e. in B*T-1*A
	return ret[:, 0:-1]

class COMACritic(torch.nn.Module):
	def __init__(self, scheme, n_agents, n_actions):
		super(COMACritic, self).__init__()
		self.n_actions = n_actions
		self.n_agents = n_agents
		input_shape = self._get_input_shape(scheme)
		self.output_type = "q"
		self.fc1 = torch.nn.Linear(input_shape, HIDDEN_SIZE)
		self.fc2 = torch.nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)
		self.fc3 = torch.nn.Linear(HIDDEN_SIZE, self.n_actions)

	def forward(self, batch, t=None):
		inputs = self._build_inputs(batch, t=t)
		x = torch.relu(self.fc1(inputs))
		x = torch.relu(self.fc2(x))
		q = self.fc3(x)
		return q

	def _build_inputs(self, batch, t=None):
		bs = batch.batch_size
		max_t = batch.max_seq_length if t is None else 1
		ts = slice(None) if t is None else slice(t, t+1)
		inputs = []
		inputs.append(batch["state"][:, ts].unsqueeze(2).repeat(1, 1, self.n_agents, 1))
		inputs.append(batch["obs"][:, ts])
		actions = batch["actions_onehot"][:, ts].view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1)
		agent_mask = (1 - torch.eye(self.n_agents, device=batch.device))
		agent_mask = agent_mask.view(-1, 1).repeat(1, self.n_actions).view(self.n_agents, -1)
		inputs.append(actions * agent_mask.unsqueeze(0).unsqueeze(0))
		# last actions
		if t == 0:
			inputs.append(torch.zeros_like(batch["actions_onehot"][:, 0:1]).view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1))
		elif isinstance(t, int):
			inputs.append(batch["actions_onehot"][:, slice(t-1, t)].view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1))
		else:
			last_actions = torch.cat([torch.zeros_like(batch["actions_onehot"][:, 0:1]), batch["actions_onehot"][:, :-1]], dim=1)
			last_actions = last_actions.view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1)
			inputs.append(last_actions)

		inputs.append(torch.eye(self.n_agents, device=batch.device).unsqueeze(0).unsqueeze(0).expand(bs, max_t, -1, -1))
		inputs = torch.cat([x.reshape(bs, max_t, self.n_agents, -1) for x in inputs], dim=-1)
		return inputs

	def _get_input_shape(self, scheme):
		input_shape = scheme["state"]["vshape"]
		input_shape += scheme["obs"]["vshape"]
		input_shape += scheme["actions_onehot"]["vshape"][0] * self.n_agents * 2
		input_shape += self.n_agents
		return input_shape

class BasicMAC:
	def __init__(self, scheme, groups, n_agents, n_actions, device):
		self.device = device
		self.n_agents = n_agents
		self.n_actions = n_actions
		self.agent = RNNAgent(self._get_input_shape(scheme), self.n_actions).to(self.device)
		self.action_selector = MultinomialActionSelector()
		self.hidden_states = None

	def select_actions(self, ep_batch, t_ep, t_env, bs=slice(None), test_mode=False):
		agent_outputs = self.forward(ep_batch, t_ep, test_mode=test_mode)
		chosen_actions = self.action_selector.select_action(agent_outputs[bs], t_env, test_mode=test_mode)
		return chosen_actions

	def forward(self, ep_batch, t, test_mode=False):
		inputs = 0
		agent_inputs = self._build_inputs(ep_batch, t)
		agent_outs = self.agent(agent_inputs, self.hidden_states)
		agent_outs = torch.nn.functional.softmax(agent_outs, dim=-1)
		if not test_mode:
			epsilon_action_num = agent_outs.size(-1)
			agent_outs = ((1 - self.action_selector.epsilon) * agent_outs + torch.ones_like(agent_outs).to(self.device) * self.action_selector.epsilon/epsilon_action_num)
		return agent_outs.view(ep_batch.batch_size, self.n_agents, -1)

	def init_hidden(self, batch_size):
		self.hidden_states = self.agent.init_hidden().unsqueeze(0).expand(batch_size, self.n_agents, -1)  # bav

	def parameters(self):
		return self.agent.parameters()

	def load_state(self, other_mac):
		self.agent.load_state_dict(other_mac.agent.state_dict())

	def cuda(self):
		self.agent.cuda()

	def save_models(self, path):
		torch.save(self.agent.state_dict(), "{}/agent.torch".format(path))

	def load_models(self, path):
		self.agent.load_state_dict(torch.load("{}/agent.torch".format(path), map_location=lambda storage, loc: storage))

	def _build_inputs(self, batch, t):
		bs = batch.batch_size
		inputs = []
		inputs.append(batch["obs"][:, t])  # b1av
		inputs.append(torch.zeros_like(batch["actions_onehot"][:, t]) if t==0 else batch["actions_onehot"][:, t-1])
		inputs.append(torch.eye(self.n_agents, device=batch.device).unsqueeze(0).expand(bs, -1, -1))
		inputs = torch.cat([x.reshape(bs*self.n_agents, -1) for x in inputs], dim=1)
		return inputs

	def _get_input_shape(self, scheme):
		input_shape = scheme["obs"]["vshape"]
		input_shape += scheme["actions_onehot"]["vshape"][0]
		input_shape += self.n_agents
		return input_shape

class RNNAgent(torch.nn.Module):
	def __init__(self, input_shape, output_shape):
		super(RNNAgent, self).__init__()
		self.fc1 = torch.nn.Linear(input_shape, HIDDEN_SIZE)
		# self.rnn = torch.nn.GRUCell(HIDDEN_SIZE, HIDDEN_SIZE)
		self.fc2 = torch.nn.Linear(HIDDEN_SIZE, output_shape)

	def init_hidden(self):
		return self.fc1.weight.new(1, HIDDEN_SIZE).zero_()

	def forward(self, inputs, hidden_state):
		x = torch.relu(self.fc1(inputs))
		# h_in = hidden_state.reshape(-1, HIDDEN_SIZE)
		# h = self.rnn(x, h_in)
		q = self.fc2(x)
		return q

class MultinomialActionSelector():
	def __init__(self, eps_start=EPS_MAX, eps_finish=EPS_MIN, eps_decay=EPS_DECAY):
		self.schedule = DecayThenFlatSchedule(eps_start, eps_finish, EPISODE_LIMIT/(1-eps_decay), decay="linear")
		self.epsilon = self.schedule.eval(0)

	def select_action(self, agent_inputs, t_env, test_mode=False):
		self.epsilon = self.schedule.eval(t_env)
		masked_policies = agent_inputs.clone()
		picked_actions = masked_policies.max(dim=2)[1] if test_mode else torch.distributions.Categorical(masked_policies).sample().long()
		return picked_actions

class DecayThenFlatSchedule():
	def __init__(self, start, finish, time_length, decay="exp"):
		self.start = start
		self.finish = finish
		self.time_length = time_length
		self.delta = (self.start - self.finish) / self.time_length
		self.decay = decay
		if self.decay in ["exp"]:
			self.exp_scaling = (-1) * self.time_length / np.log(self.finish) if self.finish > 0 else 1

	def eval(self, T):
		if self.decay in ["linear"]:
			return max(self.finish, self.start - self.delta * T)
		elif self.decay in ["exp"]:
			return min(self.start, max(self.finish, np.exp(- T / self.exp_scaling)))

from types import SimpleNamespace as SN

class EpisodeBatch():
	def __init__(self, scheme, groups, batch_size, max_seq_length, data=None, preprocess=None, device="cpu"):
		self.scheme = scheme.copy()
		self.groups = groups
		self.batch_size = batch_size
		self.max_seq_length = max_seq_length
		self.preprocess = {} if preprocess is None else preprocess
		self.device = device

		if data is not None:
			self.data = data
		else:
			self.data = SN()
			self.data.transition_data = {}
			self.data.episode_data = {}
			self._setup_data(self.scheme, self.groups, batch_size, max_seq_length, self.preprocess)

	def _setup_data(self, scheme, groups, batch_size, max_seq_length, preprocess):
		if preprocess is not None:
			for k in preprocess:
				assert k in scheme
				new_k = preprocess[k][0]
				transforms = preprocess[k][1]
				vshape = self.scheme[k]["vshape"]
				dtype = self.scheme[k]["dtype"]
				for transform in transforms:
					vshape, dtype = transform.infer_output_info(vshape, dtype)
				self.scheme[new_k] = {"vshape": vshape, "dtype": dtype}
				if "group" in self.scheme[k]:
					self.scheme[new_k]["group"] = self.scheme[k]["group"]
				if "episode_const" in self.scheme[k]:
					self.scheme[new_k]["episode_const"] = self.scheme[k]["episode_const"]

		assert "filled" not in scheme, '"filled" is a reserved key for masking.'
		scheme.update({"filled": {"vshape": (1,), "dtype": torch.long},})

		for field_key, field_info in scheme.items():
			assert "vshape" in field_info, "Scheme must define vshape for {}".format(field_key)
			vshape = field_info["vshape"]
			episode_const = field_info.get("episode_const", False)
			group = field_info.get("group", None)
			dtype = field_info.get("dtype", torch.float32)

			if isinstance(vshape, int):
				vshape = (vshape,)
			if group:
				assert group in groups, "Group {} must have its number of members defined in _groups_".format(group)
				shape = (groups[group], *vshape)
			else:
				shape = vshape
			if episode_const:
				self.data.episode_data[field_key] = torch.zeros((batch_size, *shape), dtype=dtype).to(self.device)
			else:
				self.data.transition_data[field_key] = torch.zeros((batch_size, max_seq_length, *shape), dtype=dtype).to(self.device)

	def extend(self, scheme, groups=None):
		self._setup_data(scheme, self.groups if groups is None else groups, self.batch_size, self.max_seq_length)

	def to(self, device):
		for k, v in self.data.transition_data.items():
			self.data.transition_data[k] = v.to(device)
		for k, v in self.data.episode_data.items():
			self.data.episode_data[k] = v.to(device)
		self.device = device

	def update(self, data, bs=slice(None), ts=slice(None), mark_filled=True):
		slices = self._parse_slices((bs, ts))
		for k, v in data.items():
			if k in self.data.transition_data:
				target = self.data.transition_data
				if mark_filled:
					target["filled"][slices] = 1
					mark_filled = False
				_slices = slices
			elif k in self.data.episode_data:
				target = self.data.episode_data
				_slices = slices[0]
			else:
				raise KeyError("{} not found in transition or episode data".format(k))

			dtype = self.scheme[k].get("dtype", torch.float32)
			v = v if isinstance(v, torch.Tensor) else torch.tensor(v, dtype=dtype, device=self.device)
			self._check_safe_view(v, target[k][_slices])
			target[k][_slices] = v.view_as(target[k][_slices])

			if k in self.preprocess:
				new_k = self.preprocess[k][0]
				v = target[k][_slices]
				for transform in self.preprocess[k][1]:
					v = transform.transform(v)
				target[new_k][_slices] = v.view_as(target[new_k][_slices])

	def _check_safe_view(self, v, dest):
		idx = len(v.shape) - 1
		for s in dest.shape[::-1]:
			if v.shape[idx] != s:
				if s != 1:
					raise ValueError("Unsafe reshape of {} to {}".format(v.shape, dest.shape))
			else:
				idx -= 1

	def __getitem__(self, item):
		if isinstance(item, str):
			if item in self.data.episode_data:
				return self.data.episode_data[item]
			elif item in self.data.transition_data:
				return self.data.transition_data[item]
			else:
				raise ValueError
		elif isinstance(item, tuple) and all([isinstance(it, str) for it in item]):
			new_data = self._new_data_sn()
			for key in item:
				if key in self.data.transition_data:
					new_data.transition_data[key] = self.data.transition_data[key]
				elif key in self.data.episode_data:
					new_data.episode_data[key] = self.data.episode_data[key]
				else:
					raise KeyError("Unrecognised key {}".format(key))

			# Update the scheme to only have the requested keys
			new_scheme = {key: self.scheme[key] for key in item}
			new_groups = {self.scheme[key]["group"]: self.groups[self.scheme[key]["group"]]
						for key in item if "group" in self.scheme[key]}
			ret = EpisodeBatch(new_scheme, new_groups, self.batch_size, self.max_seq_length, data=new_data, device=self.device)
			return ret
		else:
			item = self._parse_slices(item)
			new_data = self._new_data_sn()
			for k, v in self.data.transition_data.items():
				new_data.transition_data[k] = v[item]
			for k, v in self.data.episode_data.items():
				new_data.episode_data[k] = v[item[0]]

			ret_bs = self._get_num_items(item[0], self.batch_size)
			ret_max_t = self._get_num_items(item[1], self.max_seq_length)

			ret = EpisodeBatch(self.scheme, self.groups, ret_bs, ret_max_t, data=new_data, device=self.device)
			return ret

	def _get_num_items(self, indexing_item, max_size):
		if isinstance(indexing_item, list) or isinstance(indexing_item, np.ndarray):
			return len(indexing_item)
		elif isinstance(indexing_item, slice):
			_range = indexing_item.indices(max_size)
			return 1 + (_range[1] - _range[0] - 1)//_range[2]

	def _new_data_sn(self):
		new_data = SN()
		new_data.transition_data = {}
		new_data.episode_data = {}
		return new_data

	def _parse_slices(self, items):
		parsed = []
		# Only batch slice given, add full time slice
		if (isinstance(items, slice)  # slice a:b
			or isinstance(items, int)  # int i
			or (isinstance(items, (list, np.ndarray, torch.LongTensor, torch.cuda.LongTensor)))  # [a,b,c]
			):
			items = (items, slice(None))

		# Need the time indexing to be contiguous
		if isinstance(items[1], list):
			raise IndexError("Indexing across Time must be contiguous")

		for item in items:
			#TODO: stronger checks to ensure only supported options get through
			if isinstance(item, int):
				# Convert single indices to slices
				parsed.append(slice(item, item+1))
			else:
				# Leave slices and lists as is
				parsed.append(item)
		return parsed

	def max_t_filled(self):
		return torch.sum(self.data.transition_data["filled"], 1).max(0)[0]

class ReplayBuffer(EpisodeBatch):
	def __init__(self, scheme, groups, buffer_size, max_seq_length, preprocess=None, device="cpu"):
		super(ReplayBuffer, self).__init__(scheme, groups, buffer_size, max_seq_length, preprocess=preprocess, device=device)
		self.buffer_size = buffer_size  # same as self.batch_size but more explicit
		self.buffer_index = 0
		self.episodes_in_buffer = 0

	def insert_episode_batch(self, ep_batch):
		if self.buffer_index + ep_batch.batch_size <= self.buffer_size:
			self.update(ep_batch.data.transition_data, slice(self.buffer_index, self.buffer_index + ep_batch.batch_size), slice(0, ep_batch.max_seq_length), mark_filled=False)
			self.update(ep_batch.data.episode_data, slice(self.buffer_index, self.buffer_index + ep_batch.batch_size))
			self.buffer_index = (self.buffer_index + ep_batch.batch_size)
			self.episodes_in_buffer = max(self.episodes_in_buffer, self.buffer_index)
			self.buffer_index = self.buffer_index % self.buffer_size
			assert self.buffer_index < self.buffer_size
		else:
			buffer_left = self.buffer_size - self.buffer_index
			self.insert_episode_batch(ep_batch[0:buffer_left, :])
			self.insert_episode_batch(ep_batch[buffer_left:, :])

	def can_sample(self, batch_size):
		return self.episodes_in_buffer >= batch_size

	def sample(self, batch_size):
		assert self.can_sample(batch_size)
		if self.episodes_in_buffer == batch_size:
			return self[:batch_size]
		else:
			ep_ids = np.random.choice(self.episodes_in_buffer, batch_size, replace=False)
			return self[ep_ids]


# import torch
# import random
# import numpy as np
# from utils.wrappers import ParallelAgent
# from utils.network import PTNetwork, PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, one_hot, gsoftmax

# EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
# INPUT_LAYER = 64
# ACTOR_HIDDEN = 64
# CRITIC_HIDDEN = 64

# class COMAActor(torch.nn.Module):
# 	def __init__(self, state_size, action_size):
# 		super().__init__()
# 		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)!=3 else Conv(state_size, INPUT_LAYER)
# 		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
# 		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
# 		self.recurrent = torch.nn.GRUCell(ACTOR_HIDDEN, ACTOR_HIDDEN)
# 		self.action_probs = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
# 		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
# 		self.init_hidden()

# 	def forward(self, state, sample=True):
# 		state = self.layer1(state).relu()
# 		state = self.layer2(state).relu()
# 		state = self.layer3(state).relu()
# 		out_dims = state.size()[:-1]
# 		state = state.view(int(np.prod(out_dims)), -1)
# 		if self.hidden.size(0) != state.size(0): self.init_hidden(state.size(0))
# 		self.hidden = self.recurrent(state, self.hidden)
# 		action_probs = gsoftmax(self.action_probs(self.hidden), hard=False)
# 		action_probs = action_probs.view(*out_dims, -1)
# 		return action_probs

# 	def init_hidden(self, batch_size=1):
# 		self.hidden = torch.zeros([batch_size, ACTOR_HIDDEN])

# class COMACritic(torch.nn.Module):
# 	def __init__(self, state_size, action_size):
# 		super().__init__()
# 		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)!=3 else Conv(state_size, INPUT_LAYER)
# 		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
# 		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
# 		self.q_values = torch.nn.Linear(CRITIC_HIDDEN, action_size[-1])
# 		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

# 	def forward(self, state):
# 		state = self.layer1(state).relu()
# 		state = self.layer2(state).relu()
# 		state = self.layer3(state).relu()
# 		q_values = self.q_values(state)
# 		return q_values

# class COMANetwork(PTNetwork):
# 	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
# 		super().__init__(gpu=gpu)
# 		self.state_size = [state_size] if type(state_size[0]) in [int, np.int32] else state_size
# 		self.action_size = [action_size] if type(action_size[0]) in [int, np.int32] else action_size
# 		self.n_agents = lambda size: 1 if len(size)==1 else size[0]
# 		make_actor = lambda s_size,a_size: COMAActor([s_size[-1] + a_size[-1] + self.n_agents(s_size)], a_size)
# 		make_critic = lambda s_size,a_size: COMACritic([np.sum([np.prod(s) for s in self.state_size]) + 2*np.sum([np.prod(a) for a in self.action_size]) + s_size[-1] + self.n_agents(s_size)], a_size)
# 		self.models = [PTACNetwork(s_size, a_size, make_actor, make_critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
# 		if load: self.load_model(load)
		
# 	def get_action_probs(self, state, sample=True, grad=True, numpy=False):
# 		with torch.enable_grad() if grad else torch.no_grad():
# 			action = [model.actor_local(s.to(self.device), sample) for s,model in zip(state, self.models)]
# 			return [a.cpu().numpy().astype(np.float32) for a in action] if numpy else action

# 	def get_value(self, state, grad=True, numpy=False):
# 		with torch.enable_grad() if grad else torch.no_grad():
# 			q_values = [model.critic_local(s.to(self.device)) for s,model in zip(state, self.models)]
# 			return [q.cpu().numpy() for q in q_values] if numpy else q_values

# 	def optimize(self, actions, actor_inputs, critic_inputs, q_values, q_targets):
# 		for model,action,actor_input,critic_input,q_value,q_target in zip(self.models, actions, actor_inputs, critic_inputs, q_values, q_targets):
# 			for t in reversed(range(q_target.size(0))):
# 				q_value[t] = model.critic_local(critic_input[t])
# 				q_select = torch.gather(q_value[t], dim=-1, index=action[t].argmax(-1, keepdims=True)).squeeze(-1)
# 				critic_loss = (q_select - q_target[t].detach()).pow(2)
# 				model.step(model.critic_optimizer, critic_loss.mean(), retain=t>0)

# 			hidden = model.actor_local.hidden
# 			action_probs = torch.stack([model.actor_local(actor_input[t]) for t in range(q_target.size(0))], dim=0)
# 			baseline = (action_probs * q_value[:-1]).sum(-1, keepdims=True).detach()
# 			q_selected = torch.gather(q_value[:-1], dim=-1, index=action[:-1].argmax(-1, keepdims=True))
# 			log_probs = torch.gather(action_probs, dim=-1, index=action[:-1].argmax(-1, keepdims=True)).log()
# 			advantages = (q_selected - baseline).detach()
# 			actor_loss = (advantages * log_probs).sum() + 0.001*action_probs.pow(2).mean()
# 			model.step(model.actor_optimizer, actor_loss.mean())
# 			model.actor_local.hidden = hidden

# 	def save_model(self, dirname="pytorch", name="best"):
# 		[model.save_model("coma", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
# 	def load_model(self, dirname="pytorch", name="best"):
# 		[model.load_model("coma", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

# class COMAAgent(PTACAgent):
# 	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, decay=EPS_DECAY, gpu=True, load=None):
# 		super().__init__(state_size, action_size, COMANetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

# 	def get_action(self, state, eps=None, sample=True, numpy=True):
# 		eps = self.eps if eps is None else eps
# 		action_random = super().get_action(state)
# 		if not hasattr(self, "action"): self.action = [np.zeros_like(a) for a in action_random]
# 		actor_inputs = []
# 		state_list = self.to_tensor(state)
# 		state_list = [state_list] if type(state_list) != list else state_list
# 		for i,(state,last_a,s_size,a_size) in enumerate(zip(state_list, self.action, self.state_size, self.action_size)):
# 			n_agents = self.network.n_agents(s_size)
# 			last_action = last_a if len(state.shape)-len(s_size) == len(last_a.shape)-len(a_size) else np.zeros_like(action_random[i])
# 			agent_ids = np.eye(n_agents) if len(state.shape)==len(s_size) else np.repeat(np.expand_dims(np.eye(n_agents), 0), repeats=state.shape[0], axis=0)
# 			actor_input = torch.tensor(np.concatenate([state, last_action, agent_ids], axis=-1), device=self.network.device).float()
# 			actor_inputs.append(actor_input)
# 		action_greedy = self.network.get_action_probs(actor_inputs, sample=sample, grad=False, numpy=numpy)
# 		action = action_random if numpy and random.random() < eps else action_greedy
# 		if numpy: self.action = action
# 		return action

# 	def train(self, state, action, next_state, reward, done):
# 		self.buffer.append((state, action, reward, done))
# 		if np.any(done[0]) or len(self.buffer) >= self.update_freq:
# 			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
# 			self.buffer.clear()

# 			n_agents = [self.network.n_agents(a_size) for a_size in self.action_size]
# 			states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, self.to_tensor(next_state))]
# 			actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.get_action(next_state, numpy=False))]
# 			states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
# 			actions_one_hot = [one_hot(a) for a in actions]
# 			actions_one_hot_joint = torch.cat([a.view(*a.shape[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions_one_hot, self.action_size)], dim=-1)
# 			last_actions = [torch.cat([torch.zeros_like(a[0:1]), a[:-1]], dim=0) for a in actions_one_hot]
# 			last_actions_joint = torch.cat([a.view(*a.shape[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(last_actions, self.action_size)], dim=-1)
# 			agent_mask = [(1-torch.eye(n_agent)).view(-1, 1).repeat(1, a_size[-1]).view(n_agent, -1) for a_size,n_agent in zip(self.action_size, n_agents)]
# 			action_mask = torch.ones([1, 1, np.sum(n_agents), np.sum([n_agent*a_size[-1] for a_size,n_agent in zip(self.action_size, n_agents)])])
# 			cols, rows = [0, *np.cumsum(n_agents)], [0, *np.cumsum([n_agent*a_size[-1] for a_size,n_agent in zip(self.action_size, n_agents)])]
# 			for i,mask in enumerate(agent_mask): action_mask[...,cols[i]:cols[i+1], rows[i]:rows[i+1]] = mask

# 			states_joint, actions_joint, last_actions_joint = [x.unsqueeze(-2).repeat_interleave(action_mask.shape[-2], dim=-2) for x in [states_joint, actions_one_hot_joint, last_actions_joint]]
# 			joint_inputs = torch.cat([states_joint, actions_joint * action_mask, last_actions_joint], dim=-1).split(n_agents, dim=-2)
# 			agent_ids = [torch.eye(self.network.n_agents(a_size)).unsqueeze(0).unsqueeze(0).expand(*a.shape[:2], -1, -1) for a_size, a in zip(self.action_size, actions)]
# 			critic_inputs = [torch.cat([joint_input, state, agent_id], dim=-1) for joint_input,state,agent_id in zip(joint_inputs, states, agent_ids)]
# 			actor_inputs = [torch.cat([state, last_action, agent_id], dim=-1) for state,last_action,agent_id in zip(states, last_actions, agent_ids)]

# 			q_values = self.network.get_value(critic_inputs, grad=False)
# 			q_selecteds = [torch.gather(q_value, dim=-1, index=a.argmax(-1, keepdims=True)).squeeze(-1) for q_value,a in zip(q_values,actions)]
# 			q_targets = [self.compute_gae(q_selected[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_selected[:-1])[0] for q_selected,reward,done in zip(q_selecteds, rewards, dones)]
# 			self.network.optimize(actions, actor_inputs, critic_inputs, q_values, q_targets)
# 		if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0003           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.001   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 256				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 512				# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.998			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.001               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 1000000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.sac import SACAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, DoubleAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv, TrainEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, MPI_SIZE, MPI_RANK
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-3]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False, reward_shape=False):
	if env_name in gym_envs: return TrainEnv(gym.make(env_name))
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	ballr = lambda x,y: (np.maximum if x>0 else np.minimum)(x - np.abs(y)*np.sign(x), 0.5*x)
	reward_fn = lambda obs,reward: [(ballr(o[0,88], o[0,89]) + o[0,95]-o[0,96] + 2*r)/4 for o,r in zip(obs,reward)]
	return FootballTeamEnv(ggym, env_name, reward_fn if reward_shape else None)

def run(model, steps=10000, ports=16, env_name=env_name, trial_at=100, save_at=10, checkpoint=True, save_best=False, log=True, render=False, reward_shape=False, icm=False):
	envs = (EnvManager if type(ports) == list or MPI_SIZE > 1 else EnsembleEnv)(lambda: make_env(env_name, reward_shape=reward_shape), ports)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, envs.num_envs, load="", gpu=True, agent2=RandomAgent, save_dir=env_name, icm=icm) 
	logger = Logger(model, env_name, num_envs=envs.num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space, envs=type(envs), reward_shape=reward_shape, icm=icm)
	states = envs.reset(train=True)
	total_rewards = []
	for s in range(steps+1):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions, train=True)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if s%trial_at == 0:
			rollouts = rollout(envs, agent, render=render)
			total_rewards.append(np.mean(rollouts, axis=-1))
			if checkpoint and len(total_rewards) % save_at==0: agent.save_model(env_name, "checkpoint")
			if save_best and np.all(total_rewards[-1] >= np.max(total_rewards, axis=-1)): agent.save_model(env_name)
			if log: logger.log(f"Step: {s:7d}, Reward: {total_rewards[-1]} [{np.std(rollouts):4.3f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.eps:.4f})", agent.get_stats())

def trial(model, env_name, render):
	envs = EnsembleEnv(lambda: make_env(env_name, log=True, render=render), 0)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, gpu=False, load=f"{env_name}", agent2=RandomAgent, save_dir=env_name)
	print(f"Reward: {np.mean([rollout(envs.env, agent, eps=0.0, render=True) for _ in range(5)], axis=0)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[4], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="coma", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--reward_shape", action="store_true", help="Whether to shape rewards for football")
	parser.add_argument("--icm", action="store_true", help="Whether to use intrinsic motivation")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--trial", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "sac":SACAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent, "rand":RandomAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.trial:
		trial(model=model, env_name=env_name, render=args.render)
	elif args.selfport is not None or MPI_RANK>0 :
		EnvWorker(self_port=args.selfport, make_env=make_env).start()
	else:
		run(model=model, steps=args.steps, ports=args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render, reward_shape=args.reward_shape, icm=args.icm)


Step:       0, Reward: [-430.745 -430.745 -430.745] [32.842], Avg: [-430.745 -430.745 -430.745] (1.0000) ({r_i: None, r_t: [-9.664 -9.664 -9.664], eps: 1.0})
Step:     100, Reward: [-453.632 -453.632 -453.632] [121.480], Avg: [-442.188 -442.188 -442.188] (1.0000) ({r_i: None, r_t: [-1008.395 -1008.395 -1008.395], eps: 1.0})
Step:     200, Reward: [-532.643 -532.643 -532.643] [64.677], Avg: [-472.340 -472.340 -472.340] (1.0000) ({r_i: None, r_t: [-1002.273 -1002.273 -1002.273], eps: 1.0})
Step:     300, Reward: [-494.940 -494.940 -494.940] [28.933], Avg: [-477.990 -477.990 -477.990] (1.0000) ({r_i: None, r_t: [-1034.506 -1034.506 -1034.506], eps: 1.0})
Step:     400, Reward: [-651.535 -651.535 -651.535] [96.922], Avg: [-512.699 -512.699 -512.699] (1.0000) ({r_i: None, r_t: [-1005.880 -1005.880 -1005.880], eps: 1.0})
Step:     500, Reward: [-448.225 -448.225 -448.225] [79.770], Avg: [-501.953 -501.953 -501.953] (1.0000) ({r_i: None, r_t: [-980.544 -980.544 -980.544], eps: 1.0})
Step:     600, Reward: [-421.073 -421.073 -421.073] [49.103], Avg: [-490.399 -490.399 -490.399] (1.0000) ({r_i: None, r_t: [-981.276 -981.276 -981.276], eps: 1.0})
Step:     700, Reward: [-529.172 -529.172 -529.172] [129.162], Avg: [-495.246 -495.246 -495.246] (1.0000) ({r_i: None, r_t: [-1053.150 -1053.150 -1053.150], eps: 1.0})
Step:     800, Reward: [-518.421 -518.421 -518.421] [59.024], Avg: [-497.821 -497.821 -497.821] (1.0000) ({r_i: None, r_t: [-973.990 -973.990 -973.990], eps: 1.0})
Step:     900, Reward: [-533.536 -533.536 -533.536] [53.533], Avg: [-501.392 -501.392 -501.392] (1.0000) ({r_i: None, r_t: [-993.682 -993.682 -993.682], eps: 1.0})
Step:    1000, Reward: [-472.645 -472.645 -472.645] [67.017], Avg: [-498.779 -498.779 -498.779] (1.0000) ({r_i: None, r_t: [-1015.085 -1015.085 -1015.085], eps: 1.0})
Step:    1100, Reward: [-499.694 -499.694 -499.694] [47.633], Avg: [-498.855 -498.855 -498.855] (1.0000) ({r_i: None, r_t: [-885.552 -885.552 -885.552], eps: 1.0})
Step:    1200, Reward: [-520.910 -520.910 -520.910] [64.198], Avg: [-500.552 -500.552 -500.552] (1.0000) ({r_i: None, r_t: [-909.803 -909.803 -909.803], eps: 1.0})
Step:    1300, Reward: [-593.611 -593.611 -593.611] [129.302], Avg: [-507.199 -507.199 -507.199] (1.0000) ({r_i: None, r_t: [-929.960 -929.960 -929.960], eps: 1.0})
Step:    1400, Reward: [-464.240 -464.240 -464.240] [73.960], Avg: [-504.335 -504.335 -504.335] (1.0000) ({r_i: None, r_t: [-1019.087 -1019.087 -1019.087], eps: 1.0})
Step:    1500, Reward: [-547.204 -547.204 -547.204] [186.437], Avg: [-507.014 -507.014 -507.014] (1.0000) ({r_i: None, r_t: [-979.692 -979.692 -979.692], eps: 1.0})
Step:    1600, Reward: [-494.215 -494.215 -494.215] [66.458], Avg: [-506.261 -506.261 -506.261] (1.0000) ({r_i: None, r_t: [-1078.893 -1078.893 -1078.893], eps: 1.0})
Step:    1700, Reward: [-448.210 -448.210 -448.210] [63.841], Avg: [-503.036 -503.036 -503.036] (1.0000) ({r_i: None, r_t: [-902.394 -902.394 -902.394], eps: 1.0})
Step:    1800, Reward: [-638.800 -638.800 -638.800] [120.467], Avg: [-510.182 -510.182 -510.182] (1.0000) ({r_i: None, r_t: [-1001.090 -1001.090 -1001.090], eps: 1.0})
Step:    1900, Reward: [-464.619 -464.619 -464.619] [26.593], Avg: [-507.904 -507.904 -507.904] (1.0000) ({r_i: None, r_t: [-951.252 -951.252 -951.252], eps: 1.0})
Step:    2000, Reward: [-491.732 -491.732 -491.732] [49.782], Avg: [-507.133 -507.133 -507.133] (1.0000) ({r_i: None, r_t: [-959.060 -959.060 -959.060], eps: 1.0})
Step:    2100, Reward: [-456.853 -456.853 -456.853] [83.716], Avg: [-504.848 -504.848 -504.848] (1.0000) ({r_i: None, r_t: [-865.457 -865.457 -865.457], eps: 1.0})
Step:    2200, Reward: [-561.771 -561.771 -561.771] [76.493], Avg: [-507.323 -507.323 -507.323] (1.0000) ({r_i: None, r_t: [-1026.841 -1026.841 -1026.841], eps: 1.0})
Step:    2300, Reward: [-421.443 -421.443 -421.443] [46.807], Avg: [-503.745 -503.745 -503.745] (1.0000) ({r_i: None, r_t: [-966.593 -966.593 -966.593], eps: 1.0})
Step:    2400, Reward: [-569.881 -569.881 -569.881] [89.289], Avg: [-506.390 -506.390 -506.390] (1.0000) ({r_i: None, r_t: [-992.537 -992.537 -992.537], eps: 1.0})
Step:    2500, Reward: [-520.192 -520.192 -520.192] [71.238], Avg: [-506.921 -506.921 -506.921] (1.0000) ({r_i: None, r_t: [-1011.513 -1011.513 -1011.513], eps: 1.0})
Step:    2600, Reward: [-480.060 -480.060 -480.060] [51.348], Avg: [-505.926 -505.926 -505.926] (1.0000) ({r_i: None, r_t: [-886.398 -886.398 -886.398], eps: 1.0})
Step:    2700, Reward: [-531.743 -531.743 -531.743] [43.702], Avg: [-506.848 -506.848 -506.848] (1.0000) ({r_i: None, r_t: [-929.174 -929.174 -929.174], eps: 1.0})
Step:    2800, Reward: [-466.653 -466.653 -466.653] [32.977], Avg: [-505.462 -505.462 -505.462] (1.0000) ({r_i: None, r_t: [-907.907 -907.907 -907.907], eps: 1.0})
Step:    2900, Reward: [-462.993 -462.993 -462.993] [54.936], Avg: [-504.046 -504.046 -504.046] (1.0000) ({r_i: None, r_t: [-1013.063 -1013.063 -1013.063], eps: 1.0})
Step:    3000, Reward: [-577.355 -577.355 -577.355] [76.042], Avg: [-506.411 -506.411 -506.411] (1.0000) ({r_i: None, r_t: [-990.876 -990.876 -990.876], eps: 1.0})
Step:    3100, Reward: [-502.894 -502.894 -502.894] [72.598], Avg: [-506.301 -506.301 -506.301] (1.0000) ({r_i: None, r_t: [-1059.110 -1059.110 -1059.110], eps: 1.0})
Step:    3200, Reward: [-500.265 -500.265 -500.265] [90.611], Avg: [-506.118 -506.118 -506.118] (1.0000) ({r_i: None, r_t: [-1007.717 -1007.717 -1007.717], eps: 1.0})
Step:    3300, Reward: [-497.141 -497.141 -497.141] [90.428], Avg: [-505.854 -505.854 -505.854] (1.0000) ({r_i: None, r_t: [-933.088 -933.088 -933.088], eps: 1.0})
Step:    3400, Reward: [-647.990 -647.990 -647.990] [42.949], Avg: [-509.915 -509.915 -509.915] (1.0000) ({r_i: None, r_t: [-923.472 -923.472 -923.472], eps: 1.0})
Step:    3500, Reward: [-505.409 -505.409 -505.409] [80.039], Avg: [-509.790 -509.790 -509.790] (1.0000) ({r_i: None, r_t: [-920.352 -920.352 -920.352], eps: 1.0})
Step:    3600, Reward: [-427.964 -427.964 -427.964] [72.030], Avg: [-507.579 -507.579 -507.579] (1.0000) ({r_i: None, r_t: [-938.654 -938.654 -938.654], eps: 1.0})
Step:    3700, Reward: [-503.756 -503.756 -503.756] [141.541], Avg: [-507.478 -507.478 -507.478] (1.0000) ({r_i: None, r_t: [-995.404 -995.404 -995.404], eps: 1.0})
Step:    3800, Reward: [-486.475 -486.475 -486.475] [147.559], Avg: [-506.940 -506.940 -506.940] (1.0000) ({r_i: None, r_t: [-921.895 -921.895 -921.895], eps: 1.0})
Step:    3900, Reward: [-560.568 -560.568 -560.568] [111.518], Avg: [-508.280 -508.280 -508.280] (1.0000) ({r_i: None, r_t: [-993.956 -993.956 -993.956], eps: 1.0})
Step:    4000, Reward: [-514.982 -514.982 -514.982] [16.135], Avg: [-508.444 -508.444 -508.444] (1.0000) ({r_i: None, r_t: [-969.873 -969.873 -969.873], eps: 1.0})
Step:    4100, Reward: [-472.388 -472.388 -472.388] [81.048], Avg: [-507.585 -507.585 -507.585] (1.0000) ({r_i: None, r_t: [-958.290 -958.290 -958.290], eps: 1.0})
Step:    4200, Reward: [-536.818 -536.818 -536.818] [77.782], Avg: [-508.265 -508.265 -508.265] (1.0000) ({r_i: None, r_t: [-1185.024 -1185.024 -1185.024], eps: 1.0})
Step:    4300, Reward: [-412.262 -412.262 -412.262] [22.480], Avg: [-506.083 -506.083 -506.083] (1.0000) ({r_i: None, r_t: [-862.501 -862.501 -862.501], eps: 1.0})
Step:    4400, Reward: [-547.914 -547.914 -547.914] [13.159], Avg: [-507.013 -507.013 -507.013] (1.0000) ({r_i: None, r_t: [-926.783 -926.783 -926.783], eps: 1.0})
Step:    4500, Reward: [-437.987 -437.987 -437.987] [57.648], Avg: [-505.512 -505.512 -505.512] (1.0000) ({r_i: None, r_t: [-931.429 -931.429 -931.429], eps: 1.0})
Step:    4600, Reward: [-527.701 -527.701 -527.701] [82.645], Avg: [-505.984 -505.984 -505.984] (1.0000) ({r_i: None, r_t: [-996.136 -996.136 -996.136], eps: 1.0})
Step:    4700, Reward: [-483.143 -483.143 -483.143] [64.749], Avg: [-505.508 -505.508 -505.508] (1.0000) ({r_i: None, r_t: [-872.540 -872.540 -872.540], eps: 1.0})
Step:    4800, Reward: [-449.367 -449.367 -449.367] [28.677], Avg: [-504.363 -504.363 -504.363] (1.0000) ({r_i: None, r_t: [-909.162 -909.162 -909.162], eps: 1.0})
Step:    4900, Reward: [-503.518 -503.518 -503.518] [26.464], Avg: [-504.346 -504.346 -504.346] (1.0000) ({r_i: None, r_t: [-970.853 -970.853 -970.853], eps: 1.0})
Step:    5000, Reward: [-523.196 -523.196 -523.196] [75.713], Avg: [-504.715 -504.715 -504.715] (1.0000) ({r_i: None, r_t: [-852.543 -852.543 -852.543], eps: 1.0})
Step:    5100, Reward: [-484.817 -484.817 -484.817] [87.216], Avg: [-504.333 -504.333 -504.333] (1.0000) ({r_i: None, r_t: [-960.719 -960.719 -960.719], eps: 1.0})
Step:    5200, Reward: [-531.675 -531.675 -531.675] [154.334], Avg: [-504.849 -504.849 -504.849] (1.0000) ({r_i: None, r_t: [-1102.481 -1102.481 -1102.481], eps: 1.0})
Step:    5300, Reward: [-510.916 -510.916 -510.916] [80.314], Avg: [-504.961 -504.961 -504.961] (1.0000) ({r_i: None, r_t: [-1007.006 -1007.006 -1007.006], eps: 1.0})
Step:    5400, Reward: [-468.449 -468.449 -468.449] [57.571], Avg: [-504.297 -504.297 -504.297] (1.0000) ({r_i: None, r_t: [-987.500 -987.500 -987.500], eps: 1.0})
Step:    5500, Reward: [-533.427 -533.427 -533.427] [100.820], Avg: [-504.817 -504.817 -504.817] (1.0000) ({r_i: None, r_t: [-975.309 -975.309 -975.309], eps: 1.0})
Step:    5600, Reward: [-425.574 -425.574 -425.574] [49.386], Avg: [-503.427 -503.427 -503.427] (1.0000) ({r_i: None, r_t: [-878.499 -878.499 -878.499], eps: 1.0})
Step:    5700, Reward: [-576.869 -576.869 -576.869] [157.625], Avg: [-504.693 -504.693 -504.693] (1.0000) ({r_i: None, r_t: [-1019.781 -1019.781 -1019.781], eps: 1.0})
Step:    5800, Reward: [-475.570 -475.570 -475.570] [93.157], Avg: [-504.200 -504.200 -504.200] (1.0000) ({r_i: None, r_t: [-1001.806 -1001.806 -1001.806], eps: 1.0})
Step:    5900, Reward: [-428.432 -428.432 -428.432] [53.246], Avg: [-502.937 -502.937 -502.937] (1.0000) ({r_i: None, r_t: [-916.758 -916.758 -916.758], eps: 1.0})
Step:    6000, Reward: [-536.478 -536.478 -536.478] [181.146], Avg: [-503.487 -503.487 -503.487] (1.0000) ({r_i: None, r_t: [-932.258 -932.258 -932.258], eps: 1.0})
Step:    6100, Reward: [-491.204 -491.204 -491.204] [30.341], Avg: [-503.289 -503.289 -503.289] (1.0000) ({r_i: None, r_t: [-948.879 -948.879 -948.879], eps: 1.0})
Step:    6200, Reward: [-463.871 -463.871 -463.871] [47.757], Avg: [-502.663 -502.663 -502.663] (1.0000) ({r_i: None, r_t: [-975.746 -975.746 -975.746], eps: 1.0})
Step:    6300, Reward: [-444.760 -444.760 -444.760] [60.778], Avg: [-501.758 -501.758 -501.758] (1.0000) ({r_i: None, r_t: [-1033.878 -1033.878 -1033.878], eps: 1.0})
Step:    6400, Reward: [-530.146 -530.146 -530.146] [98.094], Avg: [-502.195 -502.195 -502.195] (1.0000) ({r_i: None, r_t: [-852.932 -852.932 -852.932], eps: 1.0})
Step:    6500, Reward: [-449.603 -449.603 -449.603] [52.520], Avg: [-501.398 -501.398 -501.398] (1.0000) ({r_i: None, r_t: [-1066.810 -1066.810 -1066.810], eps: 1.0})
Step:    6600, Reward: [-539.624 -539.624 -539.624] [84.179], Avg: [-501.969 -501.969 -501.969] (1.0000) ({r_i: None, r_t: [-908.719 -908.719 -908.719], eps: 1.0})
Step:    6700, Reward: [-539.487 -539.487 -539.487] [98.359], Avg: [-502.520 -502.520 -502.520] (1.0000) ({r_i: None, r_t: [-1136.973 -1136.973 -1136.973], eps: 1.0})
Step:    6800, Reward: [-473.155 -473.155 -473.155] [85.562], Avg: [-502.095 -502.095 -502.095] (1.0000) ({r_i: None, r_t: [-909.464 -909.464 -909.464], eps: 1.0})
Step:    6900, Reward: [-474.105 -474.105 -474.105] [36.026], Avg: [-501.695 -501.695 -501.695] (1.0000) ({r_i: None, r_t: [-1064.167 -1064.167 -1064.167], eps: 1.0})
Step:    7000, Reward: [-496.892 -496.892 -496.892] [99.277], Avg: [-501.627 -501.627 -501.627] (1.0000) ({r_i: None, r_t: [-975.582 -975.582 -975.582], eps: 1.0})
Step:    7100, Reward: [-544.683 -544.683 -544.683] [107.926], Avg: [-502.225 -502.225 -502.225] (1.0000) ({r_i: None, r_t: [-959.694 -959.694 -959.694], eps: 1.0})
Step:    7200, Reward: [-470.019 -470.019 -470.019] [86.509], Avg: [-501.784 -501.784 -501.784] (1.0000) ({r_i: None, r_t: [-1034.208 -1034.208 -1034.208], eps: 1.0})
Step:    7300, Reward: [-448.129 -448.129 -448.129] [45.210], Avg: [-501.059 -501.059 -501.059] (1.0000) ({r_i: None, r_t: [-911.714 -911.714 -911.714], eps: 1.0})
Step:    7400, Reward: [-512.488 -512.488 -512.488] [67.736], Avg: [-501.212 -501.212 -501.212] (1.0000) ({r_i: None, r_t: [-1024.676 -1024.676 -1024.676], eps: 1.0})
Step:    7500, Reward: [-455.766 -455.766 -455.766] [59.322], Avg: [-500.614 -500.614 -500.614] (1.0000) ({r_i: None, r_t: [-951.396 -951.396 -951.396], eps: 1.0})
Step:    7600, Reward: [-418.835 -418.835 -418.835] [26.628], Avg: [-499.551 -499.551 -499.551] (1.0000) ({r_i: None, r_t: [-1024.816 -1024.816 -1024.816], eps: 1.0})
Step:    7700, Reward: [-491.283 -491.283 -491.283] [58.400], Avg: [-499.445 -499.445 -499.445] (1.0000) ({r_i: None, r_t: [-1049.075 -1049.075 -1049.075], eps: 1.0})
Step:    7800, Reward: [-484.112 -484.112 -484.112] [97.934], Avg: [-499.251 -499.251 -499.251] (1.0000) ({r_i: None, r_t: [-931.714 -931.714 -931.714], eps: 1.0})
Step:    7900, Reward: [-453.237 -453.237 -453.237] [40.827], Avg: [-498.676 -498.676 -498.676] (1.0000) ({r_i: None, r_t: [-1118.718 -1118.718 -1118.718], eps: 1.0})
Step:    8000, Reward: [-495.419 -495.419 -495.419] [29.903], Avg: [-498.636 -498.636 -498.636] (1.0000) ({r_i: None, r_t: [-1004.188 -1004.188 -1004.188], eps: 1.0})
Step:    8100, Reward: [-540.335 -540.335 -540.335] [101.430], Avg: [-499.145 -499.145 -499.145] (1.0000) ({r_i: None, r_t: [-1042.306 -1042.306 -1042.306], eps: 1.0})
Step:    8200, Reward: [-503.916 -503.916 -503.916] [59.249], Avg: [-499.202 -499.202 -499.202] (1.0000) ({r_i: None, r_t: [-960.968 -960.968 -960.968], eps: 1.0})
Step:    8300, Reward: [-456.547 -456.547 -456.547] [48.997], Avg: [-498.694 -498.694 -498.694] (1.0000) ({r_i: None, r_t: [-972.333 -972.333 -972.333], eps: 1.0})
Step:    8400, Reward: [-582.632 -582.632 -582.632] [75.201], Avg: [-499.682 -499.682 -499.682] (1.0000) ({r_i: None, r_t: [-1129.115 -1129.115 -1129.115], eps: 1.0})
Step:    8500, Reward: [-553.129 -553.129 -553.129] [128.721], Avg: [-500.303 -500.303 -500.303] (1.0000) ({r_i: None, r_t: [-1030.081 -1030.081 -1030.081], eps: 1.0})
Step:    8600, Reward: [-436.275 -436.275 -436.275] [38.179], Avg: [-499.567 -499.567 -499.567] (1.0000) ({r_i: None, r_t: [-952.337 -952.337 -952.337], eps: 1.0})
Step:    8700, Reward: [-579.436 -579.436 -579.436] [147.224], Avg: [-500.475 -500.475 -500.475] (1.0000) ({r_i: None, r_t: [-1063.590 -1063.590 -1063.590], eps: 1.0})
Step:    8800, Reward: [-481.402 -481.402 -481.402] [124.021], Avg: [-500.261 -500.261 -500.261] (1.0000) ({r_i: None, r_t: [-976.212 -976.212 -976.212], eps: 1.0})
Step:    8900, Reward: [-453.707 -453.707 -453.707] [65.207], Avg: [-499.743 -499.743 -499.743] (1.0000) ({r_i: None, r_t: [-976.893 -976.893 -976.893], eps: 1.0})
Step:    9000, Reward: [-469.680 -469.680 -469.680] [58.515], Avg: [-499.413 -499.413 -499.413] (1.0000) ({r_i: None, r_t: [-975.120 -975.120 -975.120], eps: 1.0})
Step:    9100, Reward: [-473.711 -473.711 -473.711] [28.382], Avg: [-499.134 -499.134 -499.134] (1.0000) ({r_i: None, r_t: [-849.184 -849.184 -849.184], eps: 1.0})
Step:    9200, Reward: [-471.103 -471.103 -471.103] [32.163], Avg: [-498.832 -498.832 -498.832] (1.0000) ({r_i: None, r_t: [-1130.910 -1130.910 -1130.910], eps: 1.0})
Step:    9300, Reward: [-544.948 -544.948 -544.948] [125.402], Avg: [-499.323 -499.323 -499.323] (1.0000) ({r_i: None, r_t: [-1037.280 -1037.280 -1037.280], eps: 1.0})
Step:    9400, Reward: [-508.221 -508.221 -508.221] [81.000], Avg: [-499.416 -499.416 -499.416] (1.0000) ({r_i: None, r_t: [-1018.807 -1018.807 -1018.807], eps: 1.0})
Step:    9500, Reward: [-456.991 -456.991 -456.991] [80.080], Avg: [-498.974 -498.974 -498.974] (1.0000) ({r_i: None, r_t: [-1130.921 -1130.921 -1130.921], eps: 1.0})
Step:    9600, Reward: [-514.149 -514.149 -514.149] [107.694], Avg: [-499.131 -499.131 -499.131] (1.0000) ({r_i: None, r_t: [-1122.346 -1122.346 -1122.346], eps: 1.0})
Step:    9700, Reward: [-501.999 -501.999 -501.999] [104.833], Avg: [-499.160 -499.160 -499.160] (1.0000) ({r_i: None, r_t: [-1038.903 -1038.903 -1038.903], eps: 1.0})
Step:    9800, Reward: [-480.938 -480.938 -480.938] [111.014], Avg: [-498.976 -498.976 -498.976] (1.0000) ({r_i: None, r_t: [-995.951 -995.951 -995.951], eps: 1.0})
Step:    9900, Reward: [-445.270 -445.270 -445.270] [27.665], Avg: [-498.439 -498.439 -498.439] (1.0000) ({r_i: None, r_t: [-845.788 -845.788 -845.788], eps: 1.0})
Step:   10000, Reward: [-544.007 -544.007 -544.007] [89.839], Avg: [-498.890 -498.890 -498.890] (1.0000) ({r_i: None, r_t: [-1194.999 -1194.999 -1194.999], eps: 1.0})
Step:   10100, Reward: [-445.240 -445.240 -445.240] [15.370], Avg: [-498.364 -498.364 -498.364] (1.0000) ({r_i: None, r_t: [-967.737 -967.737 -967.737], eps: 1.0})
Step:   10200, Reward: [-464.219 -464.219 -464.219] [63.959], Avg: [-498.033 -498.033 -498.033] (1.0000) ({r_i: None, r_t: [-1032.451 -1032.451 -1032.451], eps: 1.0})
Step:   10300, Reward: [-481.482 -481.482 -481.482] [81.452], Avg: [-497.874 -497.874 -497.874] (1.0000) ({r_i: None, r_t: [-977.064 -977.064 -977.064], eps: 1.0})
Step:   10400, Reward: [-539.068 -539.068 -539.068] [99.479], Avg: [-498.266 -498.266 -498.266] (1.0000) ({r_i: None, r_t: [-1018.439 -1018.439 -1018.439], eps: 1.0})
Step:   10500, Reward: [-480.884 -480.884 -480.884] [41.222], Avg: [-498.102 -498.102 -498.102] (1.0000) ({r_i: None, r_t: [-1028.030 -1028.030 -1028.030], eps: 1.0})
Step:   10600, Reward: [-547.629 -547.629 -547.629] [87.882], Avg: [-498.565 -498.565 -498.565] (1.0000) ({r_i: None, r_t: [-1030.799 -1030.799 -1030.799], eps: 1.0})
Step:   10700, Reward: [-449.221 -449.221 -449.221] [51.306], Avg: [-498.108 -498.108 -498.108] (1.0000) ({r_i: None, r_t: [-884.963 -884.963 -884.963], eps: 1.0})
Step:   10800, Reward: [-622.998 -622.998 -622.998] [230.100], Avg: [-499.254 -499.254 -499.254] (1.0000) ({r_i: None, r_t: [-1006.685 -1006.685 -1006.685], eps: 1.0})
Step:   10900, Reward: [-450.328 -450.328 -450.328] [68.935], Avg: [-498.809 -498.809 -498.809] (1.0000) ({r_i: None, r_t: [-1064.871 -1064.871 -1064.871], eps: 1.0})
Step:   11000, Reward: [-432.912 -432.912 -432.912] [46.236], Avg: [-498.215 -498.215 -498.215] (1.0000) ({r_i: None, r_t: [-1159.293 -1159.293 -1159.293], eps: 1.0})
Step:   11100, Reward: [-543.630 -543.630 -543.630] [98.095], Avg: [-498.621 -498.621 -498.621] (1.0000) ({r_i: None, r_t: [-884.776 -884.776 -884.776], eps: 1.0})
Step:   11200, Reward: [-522.390 -522.390 -522.390] [86.806], Avg: [-498.831 -498.831 -498.831] (1.0000) ({r_i: None, r_t: [-940.705 -940.705 -940.705], eps: 1.0})
Step:   11300, Reward: [-646.160 -646.160 -646.160] [67.778], Avg: [-500.123 -500.123 -500.123] (1.0000) ({r_i: None, r_t: [-953.494 -953.494 -953.494], eps: 1.0})
Step:   11400, Reward: [-454.769 -454.769 -454.769] [53.759], Avg: [-499.729 -499.729 -499.729] (1.0000) ({r_i: None, r_t: [-1020.762 -1020.762 -1020.762], eps: 1.0})
Step:   11500, Reward: [-524.497 -524.497 -524.497] [62.410], Avg: [-499.943 -499.943 -499.943] (1.0000) ({r_i: None, r_t: [-949.424 -949.424 -949.424], eps: 1.0})
Step:   11600, Reward: [-443.083 -443.083 -443.083] [43.705], Avg: [-499.457 -499.457 -499.457] (1.0000) ({r_i: None, r_t: [-944.439 -944.439 -944.439], eps: 1.0})
Step:   11700, Reward: [-553.964 -553.964 -553.964] [162.170], Avg: [-499.919 -499.919 -499.919] (1.0000) ({r_i: None, r_t: [-1001.682 -1001.682 -1001.682], eps: 1.0})
Step:   11800, Reward: [-447.088 -447.088 -447.088] [59.240], Avg: [-499.475 -499.475 -499.475] (1.0000) ({r_i: None, r_t: [-852.310 -852.310 -852.310], eps: 1.0})
Step:   11900, Reward: [-486.461 -486.461 -486.461] [84.936], Avg: [-499.366 -499.366 -499.366] (1.0000) ({r_i: None, r_t: [-1027.929 -1027.929 -1027.929], eps: 1.0})
Step:   12000, Reward: [-452.157 -452.157 -452.157] [21.258], Avg: [-498.976 -498.976 -498.976] (1.0000) ({r_i: None, r_t: [-1036.086 -1036.086 -1036.086], eps: 1.0})
Step:   12100, Reward: [-518.738 -518.738 -518.738] [159.487], Avg: [-499.138 -499.138 -499.138] (1.0000) ({r_i: None, r_t: [-1107.803 -1107.803 -1107.803], eps: 1.0})
Step:   12200, Reward: [-492.595 -492.595 -492.595] [97.927], Avg: [-499.085 -499.085 -499.085] (1.0000) ({r_i: None, r_t: [-973.357 -973.357 -973.357], eps: 1.0})
Step:   12300, Reward: [-551.180 -551.180 -551.180] [129.993], Avg: [-499.505 -499.505 -499.505] (1.0000) ({r_i: None, r_t: [-1168.009 -1168.009 -1168.009], eps: 1.0})
Step:   12400, Reward: [-465.068 -465.068 -465.068] [90.064], Avg: [-499.229 -499.229 -499.229] (1.0000) ({r_i: None, r_t: [-871.109 -871.109 -871.109], eps: 1.0})
Step:   12500, Reward: [-482.448 -482.448 -482.448] [64.373], Avg: [-499.096 -499.096 -499.096] (1.0000) ({r_i: None, r_t: [-862.114 -862.114 -862.114], eps: 1.0})
Step:   12600, Reward: [-471.763 -471.763 -471.763] [55.269], Avg: [-498.881 -498.881 -498.881] (1.0000) ({r_i: None, r_t: [-888.887 -888.887 -888.887], eps: 1.0})
Step:   12700, Reward: [-524.654 -524.654 -524.654] [28.439], Avg: [-499.082 -499.082 -499.082] (1.0000) ({r_i: None, r_t: [-919.298 -919.298 -919.298], eps: 1.0})
Step:   12800, Reward: [-520.566 -520.566 -520.566] [106.576], Avg: [-499.249 -499.249 -499.249] (1.0000) ({r_i: None, r_t: [-926.948 -926.948 -926.948], eps: 1.0})
Step:   12900, Reward: [-501.767 -501.767 -501.767] [67.665], Avg: [-499.268 -499.268 -499.268] (1.0000) ({r_i: None, r_t: [-904.118 -904.118 -904.118], eps: 1.0})
Step:   13000, Reward: [-538.866 -538.866 -538.866] [83.736], Avg: [-499.571 -499.571 -499.571] (1.0000) ({r_i: None, r_t: [-1093.197 -1093.197 -1093.197], eps: 1.0})
Step:   13100, Reward: [-537.229 -537.229 -537.229] [79.738], Avg: [-499.856 -499.856 -499.856] (1.0000) ({r_i: None, r_t: [-978.932 -978.932 -978.932], eps: 1.0})
Step:   13200, Reward: [-499.323 -499.323 -499.323] [133.977], Avg: [-499.852 -499.852 -499.852] (1.0000) ({r_i: None, r_t: [-1129.759 -1129.759 -1129.759], eps: 1.0})
Step:   13300, Reward: [-503.668 -503.668 -503.668] [109.739], Avg: [-499.880 -499.880 -499.880] (1.0000) ({r_i: None, r_t: [-949.718 -949.718 -949.718], eps: 1.0})
Step:   13400, Reward: [-519.828 -519.828 -519.828] [34.525], Avg: [-500.028 -500.028 -500.028] (1.0000) ({r_i: None, r_t: [-1201.057 -1201.057 -1201.057], eps: 1.0})
Step:   13500, Reward: [-436.243 -436.243 -436.243] [15.287], Avg: [-499.559 -499.559 -499.559] (1.0000) ({r_i: None, r_t: [-970.745 -970.745 -970.745], eps: 1.0})
Step:   13600, Reward: [-471.769 -471.769 -471.769] [79.259], Avg: [-499.356 -499.356 -499.356] (1.0000) ({r_i: None, r_t: [-913.820 -913.820 -913.820], eps: 1.0})
Step:   13700, Reward: [-523.394 -523.394 -523.394] [46.312], Avg: [-499.530 -499.530 -499.530] (1.0000) ({r_i: None, r_t: [-1018.763 -1018.763 -1018.763], eps: 1.0})
Step:   13800, Reward: [-555.964 -555.964 -555.964] [65.579], Avg: [-499.936 -499.936 -499.936] (1.0000) ({r_i: None, r_t: [-997.283 -997.283 -997.283], eps: 1.0})
Step:   13900, Reward: [-482.821 -482.821 -482.821] [68.340], Avg: [-499.814 -499.814 -499.814] (1.0000) ({r_i: None, r_t: [-1003.171 -1003.171 -1003.171], eps: 1.0})
Step:   14000, Reward: [-448.579 -448.579 -448.579] [89.988], Avg: [-499.451 -499.451 -499.451] (1.0000) ({r_i: None, r_t: [-898.980 -898.980 -898.980], eps: 1.0})
Step:   14100, Reward: [-499.930 -499.930 -499.930] [139.585], Avg: [-499.454 -499.454 -499.454] (1.0000) ({r_i: None, r_t: [-1032.379 -1032.379 -1032.379], eps: 1.0})
Step:   14200, Reward: [-540.962 -540.962 -540.962] [49.193], Avg: [-499.744 -499.744 -499.744] (1.0000) ({r_i: None, r_t: [-1025.213 -1025.213 -1025.213], eps: 1.0})
Step:   14300, Reward: [-590.297 -590.297 -590.297] [101.955], Avg: [-500.373 -500.373 -500.373] (1.0000) ({r_i: None, r_t: [-941.703 -941.703 -941.703], eps: 1.0})
Step:   14400, Reward: [-469.014 -469.014 -469.014] [51.652], Avg: [-500.157 -500.157 -500.157] (1.0000) ({r_i: None, r_t: [-910.385 -910.385 -910.385], eps: 1.0})
Step:   14500, Reward: [-492.406 -492.406 -492.406] [54.752], Avg: [-500.104 -500.104 -500.104] (1.0000) ({r_i: None, r_t: [-1022.023 -1022.023 -1022.023], eps: 1.0})
Step:   14600, Reward: [-476.698 -476.698 -476.698] [148.084], Avg: [-499.945 -499.945 -499.945] (1.0000) ({r_i: None, r_t: [-1030.020 -1030.020 -1030.020], eps: 1.0})
Step:   14700, Reward: [-481.009 -481.009 -481.009] [64.438], Avg: [-499.817 -499.817 -499.817] (1.0000) ({r_i: None, r_t: [-1031.623 -1031.623 -1031.623], eps: 1.0})
Step:   14800, Reward: [-380.935 -380.935 -380.935] [43.333], Avg: [-499.019 -499.019 -499.019] (1.0000) ({r_i: None, r_t: [-1045.336 -1045.336 -1045.336], eps: 1.0})
Step:   14900, Reward: [-531.395 -531.395 -531.395] [73.718], Avg: [-499.235 -499.235 -499.235] (1.0000) ({r_i: None, r_t: [-1041.137 -1041.137 -1041.137], eps: 1.0})
Step:   15000, Reward: [-483.910 -483.910 -483.910] [71.259], Avg: [-499.133 -499.133 -499.133] (1.0000) ({r_i: None, r_t: [-1109.652 -1109.652 -1109.652], eps: 1.0})
Step:   15100, Reward: [-461.671 -461.671 -461.671] [89.815], Avg: [-498.887 -498.887 -498.887] (1.0000) ({r_i: None, r_t: [-913.914 -913.914 -913.914], eps: 1.0})
Step:   15200, Reward: [-509.922 -509.922 -509.922] [27.845], Avg: [-498.959 -498.959 -498.959] (1.0000) ({r_i: None, r_t: [-1046.872 -1046.872 -1046.872], eps: 1.0})
Step:   15300, Reward: [-553.569 -553.569 -553.569] [90.246], Avg: [-499.313 -499.313 -499.313] (1.0000) ({r_i: None, r_t: [-935.411 -935.411 -935.411], eps: 1.0})
Step:   15400, Reward: [-472.727 -472.727 -472.727] [99.176], Avg: [-499.142 -499.142 -499.142] (1.0000) ({r_i: None, r_t: [-1015.443 -1015.443 -1015.443], eps: 1.0})
Step:   15500, Reward: [-506.325 -506.325 -506.325] [74.412], Avg: [-499.188 -499.188 -499.188] (1.0000) ({r_i: None, r_t: [-991.314 -991.314 -991.314], eps: 1.0})
Step:   15600, Reward: [-466.466 -466.466 -466.466] [88.344], Avg: [-498.980 -498.980 -498.980] (1.0000) ({r_i: None, r_t: [-1013.413 -1013.413 -1013.413], eps: 1.0})
Step:   15700, Reward: [-599.143 -599.143 -599.143] [104.548], Avg: [-499.614 -499.614 -499.614] (1.0000) ({r_i: None, r_t: [-919.107 -919.107 -919.107], eps: 1.0})
Step:   15800, Reward: [-543.110 -543.110 -543.110] [34.053], Avg: [-499.887 -499.887 -499.887] (1.0000) ({r_i: None, r_t: [-1063.800 -1063.800 -1063.800], eps: 1.0})
Step:   15900, Reward: [-575.328 -575.328 -575.328] [108.041], Avg: [-500.359 -500.359 -500.359] (1.0000) ({r_i: None, r_t: [-1035.313 -1035.313 -1035.313], eps: 1.0})
Step:   16000, Reward: [-457.763 -457.763 -457.763] [34.628], Avg: [-500.094 -500.094 -500.094] (1.0000) ({r_i: None, r_t: [-1001.514 -1001.514 -1001.514], eps: 1.0})
Step:   16100, Reward: [-435.743 -435.743 -435.743] [61.396], Avg: [-499.697 -499.697 -499.697] (1.0000) ({r_i: None, r_t: [-1118.002 -1118.002 -1118.002], eps: 1.0})
Step:   16200, Reward: [-536.387 -536.387 -536.387] [136.063], Avg: [-499.922 -499.922 -499.922] (1.0000) ({r_i: None, r_t: [-1014.084 -1014.084 -1014.084], eps: 1.0})
Step:   16300, Reward: [-431.267 -431.267 -431.267] [40.605], Avg: [-499.503 -499.503 -499.503] (1.0000) ({r_i: None, r_t: [-972.722 -972.722 -972.722], eps: 1.0})
Step:   16400, Reward: [-479.294 -479.294 -479.294] [163.074], Avg: [-499.381 -499.381 -499.381] (1.0000) ({r_i: None, r_t: [-869.244 -869.244 -869.244], eps: 1.0})
Step:   16500, Reward: [-544.053 -544.053 -544.053] [100.181], Avg: [-499.650 -499.650 -499.650] (1.0000) ({r_i: None, r_t: [-1061.834 -1061.834 -1061.834], eps: 1.0})
Step:   16600, Reward: [-480.359 -480.359 -480.359] [70.526], Avg: [-499.534 -499.534 -499.534] (1.0000) ({r_i: None, r_t: [-980.521 -980.521 -980.521], eps: 1.0})
Step:   16700, Reward: [-480.428 -480.428 -480.428] [108.904], Avg: [-499.421 -499.421 -499.421] (1.0000) ({r_i: None, r_t: [-938.066 -938.066 -938.066], eps: 1.0})
Step:   16800, Reward: [-464.817 -464.817 -464.817] [85.614], Avg: [-499.216 -499.216 -499.216] (1.0000) ({r_i: None, r_t: [-939.734 -939.734 -939.734], eps: 1.0})
Step:   16900, Reward: [-468.790 -468.790 -468.790] [25.527], Avg: [-499.037 -499.037 -499.037] (1.0000) ({r_i: None, r_t: [-873.826 -873.826 -873.826], eps: 1.0})
Step:   17000, Reward: [-522.191 -522.191 -522.191] [82.262], Avg: [-499.172 -499.172 -499.172] (1.0000) ({r_i: None, r_t: [-989.710 -989.710 -989.710], eps: 1.0})
Step:   17100, Reward: [-431.130 -431.130 -431.130] [61.927], Avg: [-498.777 -498.777 -498.777] (1.0000) ({r_i: None, r_t: [-979.163 -979.163 -979.163], eps: 1.0})
Step:   17200, Reward: [-472.032 -472.032 -472.032] [57.923], Avg: [-498.622 -498.622 -498.622] (1.0000) ({r_i: None, r_t: [-1102.053 -1102.053 -1102.053], eps: 1.0})
Step:   17300, Reward: [-518.617 -518.617 -518.617] [130.744], Avg: [-498.737 -498.737 -498.737] (1.0000) ({r_i: None, r_t: [-912.186 -912.186 -912.186], eps: 1.0})
Step:   17400, Reward: [-516.606 -516.606 -516.606] [94.847], Avg: [-498.839 -498.839 -498.839] (1.0000) ({r_i: None, r_t: [-935.130 -935.130 -935.130], eps: 1.0})
Step:   17500, Reward: [-558.451 -558.451 -558.451] [210.383], Avg: [-499.178 -499.178 -499.178] (1.0000) ({r_i: None, r_t: [-941.719 -941.719 -941.719], eps: 1.0})
Step:   17600, Reward: [-489.503 -489.503 -489.503] [48.187], Avg: [-499.123 -499.123 -499.123] (1.0000) ({r_i: None, r_t: [-1036.912 -1036.912 -1036.912], eps: 1.0})
Step:   17700, Reward: [-458.116 -458.116 -458.116] [28.958], Avg: [-498.893 -498.893 -498.893] (1.0000) ({r_i: None, r_t: [-964.507 -964.507 -964.507], eps: 1.0})
Step:   17800, Reward: [-514.986 -514.986 -514.986] [61.211], Avg: [-498.983 -498.983 -498.983] (1.0000) ({r_i: None, r_t: [-986.883 -986.883 -986.883], eps: 1.0})
Step:   17900, Reward: [-497.608 -497.608 -497.608] [30.520], Avg: [-498.975 -498.975 -498.975] (1.0000) ({r_i: None, r_t: [-939.010 -939.010 -939.010], eps: 1.0})
Step:   18000, Reward: [-480.762 -480.762 -480.762] [121.116], Avg: [-498.874 -498.874 -498.874] (1.0000) ({r_i: None, r_t: [-899.414 -899.414 -899.414], eps: 1.0})
Step:   18100, Reward: [-621.455 -621.455 -621.455] [139.318], Avg: [-499.548 -499.548 -499.548] (1.0000) ({r_i: None, r_t: [-928.989 -928.989 -928.989], eps: 1.0})
Step:   18200, Reward: [-501.574 -501.574 -501.574] [82.198], Avg: [-499.559 -499.559 -499.559] (1.0000) ({r_i: None, r_t: [-905.725 -905.725 -905.725], eps: 1.0})
Step:   18300, Reward: [-483.536 -483.536 -483.536] [113.021], Avg: [-499.472 -499.472 -499.472] (1.0000) ({r_i: None, r_t: [-1130.239 -1130.239 -1130.239], eps: 1.0})
Step:   18400, Reward: [-535.516 -535.516 -535.516] [136.123], Avg: [-499.667 -499.667 -499.667] (1.0000) ({r_i: None, r_t: [-956.302 -956.302 -956.302], eps: 1.0})
Step:   18500, Reward: [-474.953 -474.953 -474.953] [73.317], Avg: [-499.534 -499.534 -499.534] (1.0000) ({r_i: None, r_t: [-977.127 -977.127 -977.127], eps: 1.0})
Step:   18600, Reward: [-516.630 -516.630 -516.630] [73.868], Avg: [-499.625 -499.625 -499.625] (1.0000) ({r_i: None, r_t: [-969.843 -969.843 -969.843], eps: 1.0})
Step:   18700, Reward: [-434.988 -434.988 -434.988] [14.310], Avg: [-499.282 -499.282 -499.282] (1.0000) ({r_i: None, r_t: [-865.162 -865.162 -865.162], eps: 1.0})
Step:   18800, Reward: [-507.534 -507.534 -507.534] [37.871], Avg: [-499.325 -499.325 -499.325] (1.0000) ({r_i: None, r_t: [-1087.873 -1087.873 -1087.873], eps: 1.0})
Step:   18900, Reward: [-495.636 -495.636 -495.636] [22.735], Avg: [-499.306 -499.306 -499.306] (1.0000) ({r_i: None, r_t: [-922.776 -922.776 -922.776], eps: 1.0})
Step:   19000, Reward: [-534.436 -534.436 -534.436] [129.700], Avg: [-499.490 -499.490 -499.490] (1.0000) ({r_i: None, r_t: [-985.628 -985.628 -985.628], eps: 1.0})
Step:   19100, Reward: [-413.170 -413.170 -413.170] [40.066], Avg: [-499.040 -499.040 -499.040] (1.0000) ({r_i: None, r_t: [-1034.642 -1034.642 -1034.642], eps: 1.0})
Step:   19200, Reward: [-539.965 -539.965 -539.965] [50.768], Avg: [-499.252 -499.252 -499.252] (1.0000) ({r_i: None, r_t: [-970.682 -970.682 -970.682], eps: 1.0})
Step:   19300, Reward: [-492.428 -492.428 -492.428] [57.739], Avg: [-499.217 -499.217 -499.217] (1.0000) ({r_i: None, r_t: [-939.493 -939.493 -939.493], eps: 1.0})
Step:   19400, Reward: [-498.431 -498.431 -498.431] [101.708], Avg: [-499.213 -499.213 -499.213] (1.0000) ({r_i: None, r_t: [-999.735 -999.735 -999.735], eps: 1.0})
Step:   19500, Reward: [-523.203 -523.203 -523.203] [153.963], Avg: [-499.335 -499.335 -499.335] (1.0000) ({r_i: None, r_t: [-1094.388 -1094.388 -1094.388], eps: 1.0})
Step:   19600, Reward: [-619.517 -619.517 -619.517] [110.353], Avg: [-499.945 -499.945 -499.945] (1.0000) ({r_i: None, r_t: [-1120.454 -1120.454 -1120.454], eps: 1.0})
Step:   19700, Reward: [-530.321 -530.321 -530.321] [136.487], Avg: [-500.099 -500.099 -500.099] (1.0000) ({r_i: None, r_t: [-927.436 -927.436 -927.436], eps: 1.0})
Step:   19800, Reward: [-423.621 -423.621 -423.621] [63.581], Avg: [-499.715 -499.715 -499.715] (1.0000) ({r_i: None, r_t: [-938.780 -938.780 -938.780], eps: 1.0})
Step:   19900, Reward: [-473.228 -473.228 -473.228] [3.537], Avg: [-499.582 -499.582 -499.582] (1.0000) ({r_i: None, r_t: [-1086.698 -1086.698 -1086.698], eps: 1.0})
Step:   20000, Reward: [-458.210 -458.210 -458.210] [25.606], Avg: [-499.376 -499.376 -499.376] (1.0000) ({r_i: None, r_t: [-1056.682 -1056.682 -1056.682], eps: 1.0})
Step:   20100, Reward: [-454.452 -454.452 -454.452] [74.607], Avg: [-499.154 -499.154 -499.154] (1.0000) ({r_i: None, r_t: [-939.562 -939.562 -939.562], eps: 1.0})
Step:   20200, Reward: [-512.343 -512.343 -512.343] [74.858], Avg: [-499.219 -499.219 -499.219] (1.0000) ({r_i: None, r_t: [-926.495 -926.495 -926.495], eps: 1.0})
Step:   20300, Reward: [-538.156 -538.156 -538.156] [53.968], Avg: [-499.410 -499.410 -499.410] (1.0000) ({r_i: None, r_t: [-962.752 -962.752 -962.752], eps: 1.0})
Step:   20400, Reward: [-489.174 -489.174 -489.174] [82.544], Avg: [-499.360 -499.360 -499.360] (1.0000) ({r_i: None, r_t: [-966.078 -966.078 -966.078], eps: 1.0})
Step:   20500, Reward: [-536.697 -536.697 -536.697] [147.486], Avg: [-499.541 -499.541 -499.541] (1.0000) ({r_i: None, r_t: [-1087.883 -1087.883 -1087.883], eps: 1.0})
Step:   20600, Reward: [-491.009 -491.009 -491.009] [101.366], Avg: [-499.500 -499.500 -499.500] (1.0000) ({r_i: None, r_t: [-989.656 -989.656 -989.656], eps: 1.0})
Step:   20700, Reward: [-535.056 -535.056 -535.056] [38.270], Avg: [-499.671 -499.671 -499.671] (1.0000) ({r_i: None, r_t: [-1080.830 -1080.830 -1080.830], eps: 1.0})
Step:   20800, Reward: [-489.848 -489.848 -489.848] [51.779], Avg: [-499.624 -499.624 -499.624] (1.0000) ({r_i: None, r_t: [-1015.810 -1015.810 -1015.810], eps: 1.0})
Step:   20900, Reward: [-460.836 -460.836 -460.836] [83.601], Avg: [-499.439 -499.439 -499.439] (1.0000) ({r_i: None, r_t: [-957.510 -957.510 -957.510], eps: 1.0})
Step:   21000, Reward: [-463.181 -463.181 -463.181] [56.197], Avg: [-499.267 -499.267 -499.267] (1.0000) ({r_i: None, r_t: [-937.562 -937.562 -937.562], eps: 1.0})
Step:   21100, Reward: [-661.193 -661.193 -661.193] [82.236], Avg: [-500.031 -500.031 -500.031] (1.0000) ({r_i: None, r_t: [-1021.791 -1021.791 -1021.791], eps: 1.0})
Step:   21200, Reward: [-492.174 -492.174 -492.174] [109.075], Avg: [-499.994 -499.994 -499.994] (1.0000) ({r_i: None, r_t: [-928.619 -928.619 -928.619], eps: 1.0})
Step:   21300, Reward: [-443.714 -443.714 -443.714] [50.302], Avg: [-499.731 -499.731 -499.731] (1.0000) ({r_i: None, r_t: [-1000.923 -1000.923 -1000.923], eps: 1.0})
Step:   21400, Reward: [-562.662 -562.662 -562.662] [100.411], Avg: [-500.024 -500.024 -500.024] (1.0000) ({r_i: None, r_t: [-1077.155 -1077.155 -1077.155], eps: 1.0})
Step:   21500, Reward: [-443.838 -443.838 -443.838] [29.423], Avg: [-499.764 -499.764 -499.764] (1.0000) ({r_i: None, r_t: [-1091.112 -1091.112 -1091.112], eps: 1.0})
Step:   21600, Reward: [-477.920 -477.920 -477.920] [49.485], Avg: [-499.663 -499.663 -499.663] (1.0000) ({r_i: None, r_t: [-1138.171 -1138.171 -1138.171], eps: 1.0})
Step:   21700, Reward: [-477.409 -477.409 -477.409] [69.114], Avg: [-499.561 -499.561 -499.561] (1.0000) ({r_i: None, r_t: [-1005.393 -1005.393 -1005.393], eps: 1.0})
Step:   21800, Reward: [-529.914 -529.914 -529.914] [99.451], Avg: [-499.700 -499.700 -499.700] (1.0000) ({r_i: None, r_t: [-959.332 -959.332 -959.332], eps: 1.0})
Step:   21900, Reward: [-508.247 -508.247 -508.247] [92.037], Avg: [-499.738 -499.738 -499.738] (1.0000) ({r_i: None, r_t: [-1028.002 -1028.002 -1028.002], eps: 1.0})
Step:   22000, Reward: [-488.243 -488.243 -488.243] [129.010], Avg: [-499.686 -499.686 -499.686] (1.0000) ({r_i: None, r_t: [-1138.963 -1138.963 -1138.963], eps: 1.0})
Step:   22100, Reward: [-478.635 -478.635 -478.635] [49.454], Avg: [-499.592 -499.592 -499.592] (1.0000) ({r_i: None, r_t: [-928.486 -928.486 -928.486], eps: 1.0})
Step:   22200, Reward: [-579.583 -579.583 -579.583] [76.030], Avg: [-499.950 -499.950 -499.950] (1.0000) ({r_i: None, r_t: [-897.556 -897.556 -897.556], eps: 1.0})
Step:   22300, Reward: [-508.155 -508.155 -508.155] [71.246], Avg: [-499.987 -499.987 -499.987] (1.0000) ({r_i: None, r_t: [-1033.554 -1033.554 -1033.554], eps: 1.0})
Step:   22400, Reward: [-483.066 -483.066 -483.066] [105.715], Avg: [-499.912 -499.912 -499.912] (1.0000) ({r_i: None, r_t: [-1020.551 -1020.551 -1020.551], eps: 1.0})
Step:   22500, Reward: [-583.833 -583.833 -583.833] [110.796], Avg: [-500.283 -500.283 -500.283] (1.0000) ({r_i: None, r_t: [-1004.440 -1004.440 -1004.440], eps: 1.0})
Step:   22600, Reward: [-528.992 -528.992 -528.992] [156.226], Avg: [-500.410 -500.410 -500.410] (1.0000) ({r_i: None, r_t: [-893.489 -893.489 -893.489], eps: 1.0})
Step:   22700, Reward: [-531.311 -531.311 -531.311] [38.724], Avg: [-500.545 -500.545 -500.545] (1.0000) ({r_i: None, r_t: [-897.444 -897.444 -897.444], eps: 1.0})
Step:   22800, Reward: [-468.320 -468.320 -468.320] [69.372], Avg: [-500.404 -500.404 -500.404] (1.0000) ({r_i: None, r_t: [-1057.598 -1057.598 -1057.598], eps: 1.0})
Step:   22900, Reward: [-499.518 -499.518 -499.518] [82.736], Avg: [-500.400 -500.400 -500.400] (1.0000) ({r_i: None, r_t: [-983.024 -983.024 -983.024], eps: 1.0})
Step:   23000, Reward: [-514.536 -514.536 -514.536] [49.237], Avg: [-500.462 -500.462 -500.462] (1.0000) ({r_i: None, r_t: [-1081.083 -1081.083 -1081.083], eps: 1.0})
Step:   23100, Reward: [-434.038 -434.038 -434.038] [49.721], Avg: [-500.175 -500.175 -500.175] (1.0000) ({r_i: None, r_t: [-973.569 -973.569 -973.569], eps: 1.0})
Step:   23200, Reward: [-546.131 -546.131 -546.131] [204.263], Avg: [-500.373 -500.373 -500.373] (1.0000) ({r_i: None, r_t: [-978.357 -978.357 -978.357], eps: 1.0})
Step:   23300, Reward: [-563.208 -563.208 -563.208] [115.314], Avg: [-500.641 -500.641 -500.641] (1.0000) ({r_i: None, r_t: [-1003.295 -1003.295 -1003.295], eps: 1.0})
Step:   23400, Reward: [-447.021 -447.021 -447.021] [48.515], Avg: [-500.413 -500.413 -500.413] (1.0000) ({r_i: None, r_t: [-915.276 -915.276 -915.276], eps: 1.0})
Step:   23500, Reward: [-475.020 -475.020 -475.020] [85.926], Avg: [-500.305 -500.305 -500.305] (1.0000) ({r_i: None, r_t: [-929.828 -929.828 -929.828], eps: 1.0})
Step:   23600, Reward: [-564.668 -564.668 -564.668] [78.276], Avg: [-500.577 -500.577 -500.577] (1.0000) ({r_i: None, r_t: [-975.373 -975.373 -975.373], eps: 1.0})
Step:   23700, Reward: [-451.210 -451.210 -451.210] [75.158], Avg: [-500.369 -500.369 -500.369] (1.0000) ({r_i: None, r_t: [-1014.214 -1014.214 -1014.214], eps: 1.0})
Step:   23800, Reward: [-471.727 -471.727 -471.727] [41.100], Avg: [-500.250 -500.250 -500.250] (1.0000) ({r_i: None, r_t: [-918.763 -918.763 -918.763], eps: 1.0})
Step:   23900, Reward: [-504.211 -504.211 -504.211] [89.350], Avg: [-500.266 -500.266 -500.266] (1.0000) ({r_i: None, r_t: [-960.230 -960.230 -960.230], eps: 1.0})
Step:   24000, Reward: [-451.791 -451.791 -451.791] [60.340], Avg: [-500.065 -500.065 -500.065] (1.0000) ({r_i: None, r_t: [-1131.638 -1131.638 -1131.638], eps: 1.0})
Step:   24100, Reward: [-483.240 -483.240 -483.240] [52.745], Avg: [-499.995 -499.995 -499.995] (1.0000) ({r_i: None, r_t: [-992.443 -992.443 -992.443], eps: 1.0})
Step:   24200, Reward: [-380.719 -380.719 -380.719] [43.291], Avg: [-499.505 -499.505 -499.505] (1.0000) ({r_i: None, r_t: [-930.703 -930.703 -930.703], eps: 1.0})
Step:   24300, Reward: [-478.971 -478.971 -478.971] [55.783], Avg: [-499.420 -499.420 -499.420] (1.0000) ({r_i: None, r_t: [-1028.119 -1028.119 -1028.119], eps: 1.0})
Step:   24400, Reward: [-506.574 -506.574 -506.574] [110.240], Avg: [-499.450 -499.450 -499.450] (1.0000) ({r_i: None, r_t: [-889.376 -889.376 -889.376], eps: 1.0})
Step:   24500, Reward: [-461.158 -461.158 -461.158] [47.501], Avg: [-499.294 -499.294 -499.294] (1.0000) ({r_i: None, r_t: [-1055.239 -1055.239 -1055.239], eps: 1.0})
Step:   24600, Reward: [-524.174 -524.174 -524.174] [136.722], Avg: [-499.395 -499.395 -499.395] (1.0000) ({r_i: None, r_t: [-1046.731 -1046.731 -1046.731], eps: 1.0})
Step:   24700, Reward: [-545.501 -545.501 -545.501] [103.127], Avg: [-499.581 -499.581 -499.581] (1.0000) ({r_i: None, r_t: [-1022.529 -1022.529 -1022.529], eps: 1.0})
Step:   24800, Reward: [-544.524 -544.524 -544.524] [142.857], Avg: [-499.761 -499.761 -499.761] (1.0000) ({r_i: None, r_t: [-938.945 -938.945 -938.945], eps: 1.0})
Step:   24900, Reward: [-464.122 -464.122 -464.122] [8.376], Avg: [-499.619 -499.619 -499.619] (1.0000) ({r_i: None, r_t: [-1052.250 -1052.250 -1052.250], eps: 1.0})
Step:   25000, Reward: [-467.005 -467.005 -467.005] [56.913], Avg: [-499.489 -499.489 -499.489] (1.0000) ({r_i: None, r_t: [-1048.110 -1048.110 -1048.110], eps: 1.0})
Step:   25100, Reward: [-379.387 -379.387 -379.387] [14.183], Avg: [-499.012 -499.012 -499.012] (1.0000) ({r_i: None, r_t: [-959.198 -959.198 -959.198], eps: 1.0})
Step:   25200, Reward: [-505.337 -505.337 -505.337] [203.686], Avg: [-499.037 -499.037 -499.037] (1.0000) ({r_i: None, r_t: [-1090.194 -1090.194 -1090.194], eps: 1.0})
Step:   25300, Reward: [-532.507 -532.507 -532.507] [63.042], Avg: [-499.169 -499.169 -499.169] (1.0000) ({r_i: None, r_t: [-935.865 -935.865 -935.865], eps: 1.0})
Step:   25400, Reward: [-561.064 -561.064 -561.064] [29.231], Avg: [-499.412 -499.412 -499.412] (1.0000) ({r_i: None, r_t: [-944.265 -944.265 -944.265], eps: 1.0})
Step:   25500, Reward: [-512.219 -512.219 -512.219] [145.572], Avg: [-499.462 -499.462 -499.462] (1.0000) ({r_i: None, r_t: [-977.339 -977.339 -977.339], eps: 1.0})
Step:   25600, Reward: [-468.013 -468.013 -468.013] [43.412], Avg: [-499.339 -499.339 -499.339] (1.0000) ({r_i: None, r_t: [-1009.138 -1009.138 -1009.138], eps: 1.0})
Step:   25700, Reward: [-540.812 -540.812 -540.812] [46.571], Avg: [-499.500 -499.500 -499.500] (1.0000) ({r_i: None, r_t: [-865.336 -865.336 -865.336], eps: 1.0})
Step:   25800, Reward: [-455.905 -455.905 -455.905] [29.106], Avg: [-499.332 -499.332 -499.332] (1.0000) ({r_i: None, r_t: [-898.089 -898.089 -898.089], eps: 1.0})
Step:   25900, Reward: [-481.318 -481.318 -481.318] [37.331], Avg: [-499.262 -499.262 -499.262] (1.0000) ({r_i: None, r_t: [-940.725 -940.725 -940.725], eps: 1.0})
Step:   26000, Reward: [-498.359 -498.359 -498.359] [66.728], Avg: [-499.259 -499.259 -499.259] (1.0000) ({r_i: None, r_t: [-1050.943 -1050.943 -1050.943], eps: 1.0})
Step:   26100, Reward: [-540.208 -540.208 -540.208] [116.321], Avg: [-499.415 -499.415 -499.415] (1.0000) ({r_i: None, r_t: [-950.555 -950.555 -950.555], eps: 1.0})
Step:   26200, Reward: [-557.245 -557.245 -557.245] [68.246], Avg: [-499.635 -499.635 -499.635] (1.0000) ({r_i: None, r_t: [-989.449 -989.449 -989.449], eps: 1.0})
Step:   26300, Reward: [-513.567 -513.567 -513.567] [68.989], Avg: [-499.688 -499.688 -499.688] (1.0000) ({r_i: None, r_t: [-962.221 -962.221 -962.221], eps: 1.0})
Step:   26400, Reward: [-471.585 -471.585 -471.585] [92.064], Avg: [-499.582 -499.582 -499.582] (1.0000) ({r_i: None, r_t: [-1050.420 -1050.420 -1050.420], eps: 1.0})
Step:   26500, Reward: [-482.554 -482.554 -482.554] [71.534], Avg: [-499.518 -499.518 -499.518] (1.0000) ({r_i: None, r_t: [-979.927 -979.927 -979.927], eps: 1.0})
Step:   26600, Reward: [-523.953 -523.953 -523.953] [11.933], Avg: [-499.609 -499.609 -499.609] (1.0000) ({r_i: None, r_t: [-984.956 -984.956 -984.956], eps: 1.0})
Step:   26700, Reward: [-473.465 -473.465 -473.465] [70.371], Avg: [-499.512 -499.512 -499.512] (1.0000) ({r_i: None, r_t: [-1001.303 -1001.303 -1001.303], eps: 1.0})
Step:   26800, Reward: [-452.374 -452.374 -452.374] [31.016], Avg: [-499.337 -499.337 -499.337] (1.0000) ({r_i: None, r_t: [-1043.989 -1043.989 -1043.989], eps: 1.0})
Step:   26900, Reward: [-465.448 -465.448 -465.448] [62.123], Avg: [-499.211 -499.211 -499.211] (1.0000) ({r_i: None, r_t: [-1021.365 -1021.365 -1021.365], eps: 1.0})
Step:   27000, Reward: [-484.663 -484.663 -484.663] [33.261], Avg: [-499.157 -499.157 -499.157] (1.0000) ({r_i: None, r_t: [-959.031 -959.031 -959.031], eps: 1.0})
Step:   27100, Reward: [-509.985 -509.985 -509.985] [98.492], Avg: [-499.197 -499.197 -499.197] (1.0000) ({r_i: None, r_t: [-928.539 -928.539 -928.539], eps: 1.0})
Step:   27200, Reward: [-496.909 -496.909 -496.909] [136.415], Avg: [-499.189 -499.189 -499.189] (1.0000) ({r_i: None, r_t: [-1018.625 -1018.625 -1018.625], eps: 1.0})
Step:   27300, Reward: [-596.248 -596.248 -596.248] [149.881], Avg: [-499.543 -499.543 -499.543] (1.0000) ({r_i: None, r_t: [-936.963 -936.963 -936.963], eps: 1.0})
Step:   27400, Reward: [-506.846 -506.846 -506.846] [41.385], Avg: [-499.570 -499.570 -499.570] (1.0000) ({r_i: None, r_t: [-898.902 -898.902 -898.902], eps: 1.0})
Step:   27500, Reward: [-469.498 -469.498 -469.498] [113.193], Avg: [-499.461 -499.461 -499.461] (1.0000) ({r_i: None, r_t: [-901.926 -901.926 -901.926], eps: 1.0})
Step:   27600, Reward: [-635.224 -635.224 -635.224] [162.305], Avg: [-499.951 -499.951 -499.951] (1.0000) ({r_i: None, r_t: [-900.303 -900.303 -900.303], eps: 1.0})
Step:   27700, Reward: [-408.402 -408.402 -408.402] [44.307], Avg: [-499.621 -499.621 -499.621] (1.0000) ({r_i: None, r_t: [-885.533 -885.533 -885.533], eps: 1.0})
Step:   27800, Reward: [-542.846 -542.846 -542.846] [60.635], Avg: [-499.776 -499.776 -499.776] (1.0000) ({r_i: None, r_t: [-996.521 -996.521 -996.521], eps: 1.0})
Step:   27900, Reward: [-470.321 -470.321 -470.321] [49.207], Avg: [-499.671 -499.671 -499.671] (1.0000) ({r_i: None, r_t: [-954.519 -954.519 -954.519], eps: 1.0})
Step:   28000, Reward: [-574.207 -574.207 -574.207] [214.258], Avg: [-499.936 -499.936 -499.936] (1.0000) ({r_i: None, r_t: [-1111.083 -1111.083 -1111.083], eps: 1.0})
Step:   28100, Reward: [-506.721 -506.721 -506.721] [8.326], Avg: [-499.960 -499.960 -499.960] (1.0000) ({r_i: None, r_t: [-942.648 -942.648 -942.648], eps: 1.0})
Step:   28200, Reward: [-569.973 -569.973 -569.973] [111.429], Avg: [-500.208 -500.208 -500.208] (1.0000) ({r_i: None, r_t: [-953.184 -953.184 -953.184], eps: 1.0})
Step:   28300, Reward: [-508.840 -508.840 -508.840] [79.280], Avg: [-500.238 -500.238 -500.238] (1.0000) ({r_i: None, r_t: [-958.874 -958.874 -958.874], eps: 1.0})
Step:   28400, Reward: [-578.764 -578.764 -578.764] [101.559], Avg: [-500.514 -500.514 -500.514] (1.0000) ({r_i: None, r_t: [-986.274 -986.274 -986.274], eps: 1.0})
Step:   28500, Reward: [-591.470 -591.470 -591.470] [115.591], Avg: [-500.832 -500.832 -500.832] (1.0000) ({r_i: None, r_t: [-1169.800 -1169.800 -1169.800], eps: 1.0})
Step:   28600, Reward: [-488.742 -488.742 -488.742] [88.774], Avg: [-500.790 -500.790 -500.790] (1.0000) ({r_i: None, r_t: [-780.279 -780.279 -780.279], eps: 1.0})
Step:   28700, Reward: [-521.971 -521.971 -521.971] [33.108], Avg: [-500.863 -500.863 -500.863] (1.0000) ({r_i: None, r_t: [-959.187 -959.187 -959.187], eps: 1.0})
Step:   28800, Reward: [-505.833 -505.833 -505.833] [34.449], Avg: [-500.880 -500.880 -500.880] (1.0000) ({r_i: None, r_t: [-919.903 -919.903 -919.903], eps: 1.0})
Step:   28900, Reward: [-503.833 -503.833 -503.833] [97.548], Avg: [-500.891 -500.891 -500.891] (1.0000) ({r_i: None, r_t: [-1012.732 -1012.732 -1012.732], eps: 1.0})
Step:   29000, Reward: [-440.797 -440.797 -440.797] [50.489], Avg: [-500.684 -500.684 -500.684] (1.0000) ({r_i: None, r_t: [-928.140 -928.140 -928.140], eps: 1.0})
Step:   29100, Reward: [-562.785 -562.785 -562.785] [116.995], Avg: [-500.897 -500.897 -500.897] (1.0000) ({r_i: None, r_t: [-965.033 -965.033 -965.033], eps: 1.0})
Step:   29200, Reward: [-639.317 -639.317 -639.317] [103.343], Avg: [-501.369 -501.369 -501.369] (1.0000) ({r_i: None, r_t: [-988.536 -988.536 -988.536], eps: 1.0})
Step:   29300, Reward: [-445.455 -445.455 -445.455] [30.213], Avg: [-501.179 -501.179 -501.179] (1.0000) ({r_i: None, r_t: [-902.634 -902.634 -902.634], eps: 1.0})
Step:   29400, Reward: [-602.302 -602.302 -602.302] [176.728], Avg: [-501.522 -501.522 -501.522] (1.0000) ({r_i: None, r_t: [-1016.626 -1016.626 -1016.626], eps: 1.0})
Step:   29500, Reward: [-511.179 -511.179 -511.179] [158.110], Avg: [-501.554 -501.554 -501.554] (1.0000) ({r_i: None, r_t: [-920.106 -920.106 -920.106], eps: 1.0})
Step:   29600, Reward: [-476.293 -476.293 -476.293] [55.605], Avg: [-501.469 -501.469 -501.469] (1.0000) ({r_i: None, r_t: [-1042.407 -1042.407 -1042.407], eps: 1.0})
Step:   29700, Reward: [-491.866 -491.866 -491.866] [104.320], Avg: [-501.437 -501.437 -501.437] (1.0000) ({r_i: None, r_t: [-1088.558 -1088.558 -1088.558], eps: 1.0})
Step:   29800, Reward: [-507.402 -507.402 -507.402] [185.398], Avg: [-501.457 -501.457 -501.457] (1.0000) ({r_i: None, r_t: [-1032.807 -1032.807 -1032.807], eps: 1.0})
Step:   29900, Reward: [-456.545 -456.545 -456.545] [48.241], Avg: [-501.307 -501.307 -501.307] (1.0000) ({r_i: None, r_t: [-875.283 -875.283 -875.283], eps: 1.0})
Step:   30000, Reward: [-533.012 -533.012 -533.012] [85.722], Avg: [-501.413 -501.413 -501.413] (1.0000) ({r_i: None, r_t: [-987.632 -987.632 -987.632], eps: 1.0})
Step:   30100, Reward: [-536.530 -536.530 -536.530] [71.193], Avg: [-501.529 -501.529 -501.529] (1.0000) ({r_i: None, r_t: [-893.233 -893.233 -893.233], eps: 1.0})
Step:   30200, Reward: [-547.525 -547.525 -547.525] [38.517], Avg: [-501.681 -501.681 -501.681] (1.0000) ({r_i: None, r_t: [-985.107 -985.107 -985.107], eps: 1.0})
Step:   30300, Reward: [-479.483 -479.483 -479.483] [118.417], Avg: [-501.608 -501.608 -501.608] (1.0000) ({r_i: None, r_t: [-1065.074 -1065.074 -1065.074], eps: 1.0})
Step:   30400, Reward: [-561.707 -561.707 -561.707] [64.925], Avg: [-501.805 -501.805 -501.805] (1.0000) ({r_i: None, r_t: [-1010.767 -1010.767 -1010.767], eps: 1.0})
Step:   30500, Reward: [-451.624 -451.624 -451.624] [53.034], Avg: [-501.641 -501.641 -501.641] (1.0000) ({r_i: None, r_t: [-948.546 -948.546 -948.546], eps: 1.0})
Step:   30600, Reward: [-450.393 -450.393 -450.393] [43.069], Avg: [-501.474 -501.474 -501.474] (1.0000) ({r_i: None, r_t: [-950.137 -950.137 -950.137], eps: 1.0})
Step:   30700, Reward: [-533.941 -533.941 -533.941] [65.283], Avg: [-501.579 -501.579 -501.579] (1.0000) ({r_i: None, r_t: [-1067.794 -1067.794 -1067.794], eps: 1.0})
Step:   30800, Reward: [-467.822 -467.822 -467.822] [35.584], Avg: [-501.470 -501.470 -501.470] (1.0000) ({r_i: None, r_t: [-993.941 -993.941 -993.941], eps: 1.0})
Step:   30900, Reward: [-484.409 -484.409 -484.409] [70.771], Avg: [-501.415 -501.415 -501.415] (1.0000) ({r_i: None, r_t: [-955.292 -955.292 -955.292], eps: 1.0})
Step:   31000, Reward: [-561.148 -561.148 -561.148] [43.701], Avg: [-501.607 -501.607 -501.607] (1.0000) ({r_i: None, r_t: [-1050.393 -1050.393 -1050.393], eps: 1.0})
Step:   31100, Reward: [-432.019 -432.019 -432.019] [61.021], Avg: [-501.384 -501.384 -501.384] (1.0000) ({r_i: None, r_t: [-976.953 -976.953 -976.953], eps: 1.0})
Step:   31200, Reward: [-630.810 -630.810 -630.810] [131.670], Avg: [-501.798 -501.798 -501.798] (1.0000) ({r_i: None, r_t: [-957.143 -957.143 -957.143], eps: 1.0})
Step:   31300, Reward: [-434.193 -434.193 -434.193] [28.093], Avg: [-501.582 -501.582 -501.582] (1.0000) ({r_i: None, r_t: [-961.431 -961.431 -961.431], eps: 1.0})
Step:   31400, Reward: [-465.936 -465.936 -465.936] [66.680], Avg: [-501.469 -501.469 -501.469] (1.0000) ({r_i: None, r_t: [-999.333 -999.333 -999.333], eps: 1.0})
Step:   31500, Reward: [-590.413 -590.413 -590.413] [87.967], Avg: [-501.751 -501.751 -501.751] (1.0000) ({r_i: None, r_t: [-904.295 -904.295 -904.295], eps: 1.0})
Step:   31600, Reward: [-387.236 -387.236 -387.236] [61.559], Avg: [-501.389 -501.389 -501.389] (1.0000) ({r_i: None, r_t: [-1107.734 -1107.734 -1107.734], eps: 1.0})
Step:   31700, Reward: [-540.707 -540.707 -540.707] [110.004], Avg: [-501.513 -501.513 -501.513] (1.0000) ({r_i: None, r_t: [-910.214 -910.214 -910.214], eps: 1.0})
Step:   31800, Reward: [-515.687 -515.687 -515.687] [28.113], Avg: [-501.557 -501.557 -501.557] (1.0000) ({r_i: None, r_t: [-975.820 -975.820 -975.820], eps: 1.0})
Step:   31900, Reward: [-475.381 -475.381 -475.381] [72.848], Avg: [-501.476 -501.476 -501.476] (1.0000) ({r_i: None, r_t: [-897.540 -897.540 -897.540], eps: 1.0})
Step:   32000, Reward: [-523.100 -523.100 -523.100] [79.807], Avg: [-501.543 -501.543 -501.543] (1.0000) ({r_i: None, r_t: [-1026.754 -1026.754 -1026.754], eps: 1.0})
Step:   32100, Reward: [-522.984 -522.984 -522.984] [82.711], Avg: [-501.610 -501.610 -501.610] (1.0000) ({r_i: None, r_t: [-992.502 -992.502 -992.502], eps: 1.0})
Step:   32200, Reward: [-538.117 -538.117 -538.117] [46.251], Avg: [-501.723 -501.723 -501.723] (1.0000) ({r_i: None, r_t: [-1003.231 -1003.231 -1003.231], eps: 1.0})
Step:   32300, Reward: [-462.155 -462.155 -462.155] [74.710], Avg: [-501.600 -501.600 -501.600] (1.0000) ({r_i: None, r_t: [-967.508 -967.508 -967.508], eps: 1.0})
Step:   32400, Reward: [-520.860 -520.860 -520.860] [95.644], Avg: [-501.660 -501.660 -501.660] (1.0000) ({r_i: None, r_t: [-1070.694 -1070.694 -1070.694], eps: 1.0})
Step:   32500, Reward: [-541.990 -541.990 -541.990] [111.540], Avg: [-501.783 -501.783 -501.783] (1.0000) ({r_i: None, r_t: [-914.126 -914.126 -914.126], eps: 1.0})
Step:   32600, Reward: [-503.769 -503.769 -503.769] [116.377], Avg: [-501.790 -501.790 -501.790] (1.0000) ({r_i: None, r_t: [-897.109 -897.109 -897.109], eps: 1.0})
Step:   32700, Reward: [-518.389 -518.389 -518.389] [143.272], Avg: [-501.840 -501.840 -501.840] (1.0000) ({r_i: None, r_t: [-999.518 -999.518 -999.518], eps: 1.0})
Step:   32800, Reward: [-562.006 -562.006 -562.006] [245.696], Avg: [-502.023 -502.023 -502.023] (1.0000) ({r_i: None, r_t: [-1005.719 -1005.719 -1005.719], eps: 1.0})
Step:   32900, Reward: [-569.721 -569.721 -569.721] [68.384], Avg: [-502.228 -502.228 -502.228] (1.0000) ({r_i: None, r_t: [-1006.148 -1006.148 -1006.148], eps: 1.0})
Step:   33000, Reward: [-492.775 -492.775 -492.775] [98.517], Avg: [-502.200 -502.200 -502.200] (1.0000) ({r_i: None, r_t: [-1022.284 -1022.284 -1022.284], eps: 1.0})
Step:   33100, Reward: [-573.941 -573.941 -573.941] [100.055], Avg: [-502.416 -502.416 -502.416] (1.0000) ({r_i: None, r_t: [-1038.608 -1038.608 -1038.608], eps: 1.0})
Step:   33200, Reward: [-547.365 -547.365 -547.365] [94.699], Avg: [-502.551 -502.551 -502.551] (1.0000) ({r_i: None, r_t: [-1049.839 -1049.839 -1049.839], eps: 1.0})
Step:   33300, Reward: [-391.572 -391.572 -391.572] [34.122], Avg: [-502.218 -502.218 -502.218] (1.0000) ({r_i: None, r_t: [-1077.023 -1077.023 -1077.023], eps: 1.0})
Step:   33400, Reward: [-516.632 -516.632 -516.632] [48.244], Avg: [-502.261 -502.261 -502.261] (1.0000) ({r_i: None, r_t: [-1112.330 -1112.330 -1112.330], eps: 1.0})
Step:   33500, Reward: [-449.183 -449.183 -449.183] [43.856], Avg: [-502.103 -502.103 -502.103] (1.0000) ({r_i: None, r_t: [-903.082 -903.082 -903.082], eps: 1.0})
Step:   33600, Reward: [-415.755 -415.755 -415.755] [45.222], Avg: [-501.847 -501.847 -501.847] (1.0000) ({r_i: None, r_t: [-1023.534 -1023.534 -1023.534], eps: 1.0})
Step:   33700, Reward: [-479.642 -479.642 -479.642] [99.322], Avg: [-501.782 -501.782 -501.782] (1.0000) ({r_i: None, r_t: [-1159.296 -1159.296 -1159.296], eps: 1.0})
Step:   33800, Reward: [-535.442 -535.442 -535.442] [131.219], Avg: [-501.881 -501.881 -501.881] (1.0000) ({r_i: None, r_t: [-1048.978 -1048.978 -1048.978], eps: 1.0})
Step:   33900, Reward: [-435.031 -435.031 -435.031] [77.843], Avg: [-501.684 -501.684 -501.684] (1.0000) ({r_i: None, r_t: [-1000.113 -1000.113 -1000.113], eps: 1.0})
Step:   34000, Reward: [-443.970 -443.970 -443.970] [39.057], Avg: [-501.515 -501.515 -501.515] (1.0000) ({r_i: None, r_t: [-1008.719 -1008.719 -1008.719], eps: 1.0})
Step:   34100, Reward: [-482.054 -482.054 -482.054] [131.292], Avg: [-501.458 -501.458 -501.458] (1.0000) ({r_i: None, r_t: [-1016.795 -1016.795 -1016.795], eps: 1.0})
Step:   34200, Reward: [-485.220 -485.220 -485.220] [77.969], Avg: [-501.411 -501.411 -501.411] (1.0000) ({r_i: None, r_t: [-1116.908 -1116.908 -1116.908], eps: 1.0})
Step:   34300, Reward: [-419.724 -419.724 -419.724] [69.383], Avg: [-501.173 -501.173 -501.173] (1.0000) ({r_i: None, r_t: [-959.711 -959.711 -959.711], eps: 1.0})
Step:   34400, Reward: [-630.030 -630.030 -630.030] [169.295], Avg: [-501.547 -501.547 -501.547] (1.0000) ({r_i: None, r_t: [-919.049 -919.049 -919.049], eps: 1.0})
Step:   34500, Reward: [-562.930 -562.930 -562.930] [47.621], Avg: [-501.724 -501.724 -501.724] (1.0000) ({r_i: None, r_t: [-929.416 -929.416 -929.416], eps: 1.0})
Step:   34600, Reward: [-468.300 -468.300 -468.300] [107.899], Avg: [-501.628 -501.628 -501.628] (1.0000) ({r_i: None, r_t: [-995.608 -995.608 -995.608], eps: 1.0})
Step:   34700, Reward: [-503.628 -503.628 -503.628] [39.602], Avg: [-501.634 -501.634 -501.634] (1.0000) ({r_i: None, r_t: [-988.122 -988.122 -988.122], eps: 1.0})
Step:   34800, Reward: [-534.957 -534.957 -534.957] [126.943], Avg: [-501.729 -501.729 -501.729] (1.0000) ({r_i: None, r_t: [-1101.914 -1101.914 -1101.914], eps: 1.0})
Step:   34900, Reward: [-462.015 -462.015 -462.015] [105.806], Avg: [-501.616 -501.616 -501.616] (1.0000) ({r_i: None, r_t: [-1128.769 -1128.769 -1128.769], eps: 1.0})
Step:   35000, Reward: [-500.856 -500.856 -500.856] [94.429], Avg: [-501.613 -501.613 -501.613] (1.0000) ({r_i: None, r_t: [-908.508 -908.508 -908.508], eps: 1.0})
Step:   35100, Reward: [-580.982 -580.982 -580.982] [86.538], Avg: [-501.839 -501.839 -501.839] (1.0000) ({r_i: None, r_t: [-1020.817 -1020.817 -1020.817], eps: 1.0})
Step:   35200, Reward: [-475.132 -475.132 -475.132] [20.869], Avg: [-501.763 -501.763 -501.763] (1.0000) ({r_i: None, r_t: [-958.320 -958.320 -958.320], eps: 1.0})
Step:   35300, Reward: [-484.704 -484.704 -484.704] [41.376], Avg: [-501.715 -501.715 -501.715] (1.0000) ({r_i: None, r_t: [-968.793 -968.793 -968.793], eps: 1.0})
Step:   35400, Reward: [-514.484 -514.484 -514.484] [73.277], Avg: [-501.751 -501.751 -501.751] (1.0000) ({r_i: None, r_t: [-1111.992 -1111.992 -1111.992], eps: 1.0})
Step:   35500, Reward: [-488.845 -488.845 -488.845] [65.273], Avg: [-501.715 -501.715 -501.715] (1.0000) ({r_i: None, r_t: [-1039.971 -1039.971 -1039.971], eps: 1.0})
Step:   35600, Reward: [-526.811 -526.811 -526.811] [106.450], Avg: [-501.785 -501.785 -501.785] (1.0000) ({r_i: None, r_t: [-1041.329 -1041.329 -1041.329], eps: 1.0})
Step:   35700, Reward: [-494.788 -494.788 -494.788] [106.913], Avg: [-501.766 -501.766 -501.766] (1.0000) ({r_i: None, r_t: [-1061.110 -1061.110 -1061.110], eps: 1.0})
Step:   35800, Reward: [-499.296 -499.296 -499.296] [65.485], Avg: [-501.759 -501.759 -501.759] (1.0000) ({r_i: None, r_t: [-1035.553 -1035.553 -1035.553], eps: 1.0})
Step:   35900, Reward: [-494.362 -494.362 -494.362] [127.113], Avg: [-501.738 -501.738 -501.738] (1.0000) ({r_i: None, r_t: [-1005.382 -1005.382 -1005.382], eps: 1.0})
Step:   36000, Reward: [-571.721 -571.721 -571.721] [160.905], Avg: [-501.932 -501.932 -501.932] (1.0000) ({r_i: None, r_t: [-1007.092 -1007.092 -1007.092], eps: 1.0})
Step:   36100, Reward: [-454.741 -454.741 -454.741] [34.828], Avg: [-501.802 -501.802 -501.802] (1.0000) ({r_i: None, r_t: [-976.526 -976.526 -976.526], eps: 1.0})
Step:   36200, Reward: [-457.822 -457.822 -457.822] [12.903], Avg: [-501.680 -501.680 -501.680] (1.0000) ({r_i: None, r_t: [-895.106 -895.106 -895.106], eps: 1.0})
Step:   36300, Reward: [-487.926 -487.926 -487.926] [91.838], Avg: [-501.643 -501.643 -501.643] (1.0000) ({r_i: None, r_t: [-1023.533 -1023.533 -1023.533], eps: 1.0})
Step:   36400, Reward: [-546.145 -546.145 -546.145] [52.082], Avg: [-501.765 -501.765 -501.765] (1.0000) ({r_i: None, r_t: [-962.798 -962.798 -962.798], eps: 1.0})
Step:   36500, Reward: [-429.032 -429.032 -429.032] [79.456], Avg: [-501.566 -501.566 -501.566] (1.0000) ({r_i: None, r_t: [-1048.412 -1048.412 -1048.412], eps: 1.0})
Step:   36600, Reward: [-550.698 -550.698 -550.698] [95.069], Avg: [-501.700 -501.700 -501.700] (1.0000) ({r_i: None, r_t: [-1096.270 -1096.270 -1096.270], eps: 1.0})
Step:   36700, Reward: [-458.959 -458.959 -458.959] [104.521], Avg: [-501.584 -501.584 -501.584] (1.0000) ({r_i: None, r_t: [-1048.910 -1048.910 -1048.910], eps: 1.0})
Step:   36800, Reward: [-498.520 -498.520 -498.520] [25.938], Avg: [-501.575 -501.575 -501.575] (1.0000) ({r_i: None, r_t: [-1045.615 -1045.615 -1045.615], eps: 1.0})
Step:   36900, Reward: [-473.648 -473.648 -473.648] [70.069], Avg: [-501.500 -501.500 -501.500] (1.0000) ({r_i: None, r_t: [-975.631 -975.631 -975.631], eps: 1.0})
Step:   37000, Reward: [-469.213 -469.213 -469.213] [65.305], Avg: [-501.413 -501.413 -501.413] (1.0000) ({r_i: None, r_t: [-1038.076 -1038.076 -1038.076], eps: 1.0})
Step:   37100, Reward: [-526.360 -526.360 -526.360] [159.614], Avg: [-501.480 -501.480 -501.480] (1.0000) ({r_i: None, r_t: [-967.613 -967.613 -967.613], eps: 1.0})
Step:   37200, Reward: [-450.454 -450.454 -450.454] [47.473], Avg: [-501.343 -501.343 -501.343] (1.0000) ({r_i: None, r_t: [-1015.755 -1015.755 -1015.755], eps: 1.0})
Step:   37300, Reward: [-502.148 -502.148 -502.148] [62.581], Avg: [-501.345 -501.345 -501.345] (1.0000) ({r_i: None, r_t: [-912.293 -912.293 -912.293], eps: 1.0})
Step:   37400, Reward: [-539.558 -539.558 -539.558] [109.773], Avg: [-501.447 -501.447 -501.447] (1.0000) ({r_i: None, r_t: [-979.147 -979.147 -979.147], eps: 1.0})
Step:   37500, Reward: [-530.686 -530.686 -530.686] [77.841], Avg: [-501.525 -501.525 -501.525] (1.0000) ({r_i: None, r_t: [-1019.089 -1019.089 -1019.089], eps: 1.0})
Step:   37600, Reward: [-527.295 -527.295 -527.295] [84.547], Avg: [-501.593 -501.593 -501.593] (1.0000) ({r_i: None, r_t: [-1036.402 -1036.402 -1036.402], eps: 1.0})
Step:   37700, Reward: [-476.133 -476.133 -476.133] [22.199], Avg: [-501.526 -501.526 -501.526] (1.0000) ({r_i: None, r_t: [-1006.991 -1006.991 -1006.991], eps: 1.0})
Step:   37800, Reward: [-467.867 -467.867 -467.867] [53.096], Avg: [-501.437 -501.437 -501.437] (1.0000) ({r_i: None, r_t: [-1021.183 -1021.183 -1021.183], eps: 1.0})
Step:   37900, Reward: [-522.242 -522.242 -522.242] [77.812], Avg: [-501.492 -501.492 -501.492] (1.0000) ({r_i: None, r_t: [-989.128 -989.128 -989.128], eps: 1.0})
Step:   38000, Reward: [-443.654 -443.654 -443.654] [21.929], Avg: [-501.340 -501.340 -501.340] (1.0000) ({r_i: None, r_t: [-976.296 -976.296 -976.296], eps: 1.0})
Step:   38100, Reward: [-461.799 -461.799 -461.799] [62.301], Avg: [-501.236 -501.236 -501.236] (1.0000) ({r_i: None, r_t: [-873.275 -873.275 -873.275], eps: 1.0})
Step:   38200, Reward: [-484.302 -484.302 -484.302] [66.853], Avg: [-501.192 -501.192 -501.192] (1.0000) ({r_i: None, r_t: [-943.883 -943.883 -943.883], eps: 1.0})
Step:   38300, Reward: [-477.552 -477.552 -477.552] [85.442], Avg: [-501.131 -501.131 -501.131] (1.0000) ({r_i: None, r_t: [-1035.289 -1035.289 -1035.289], eps: 1.0})
Step:   38400, Reward: [-433.185 -433.185 -433.185] [49.082], Avg: [-500.954 -500.954 -500.954] (1.0000) ({r_i: None, r_t: [-939.083 -939.083 -939.083], eps: 1.0})
Step:   38500, Reward: [-623.675 -623.675 -623.675] [129.550], Avg: [-501.272 -501.272 -501.272] (1.0000) ({r_i: None, r_t: [-955.042 -955.042 -955.042], eps: 1.0})
Step:   38600, Reward: [-456.118 -456.118 -456.118] [10.119], Avg: [-501.155 -501.155 -501.155] (1.0000) ({r_i: None, r_t: [-818.485 -818.485 -818.485], eps: 1.0})
Step:   38700, Reward: [-492.535 -492.535 -492.535] [39.746], Avg: [-501.133 -501.133 -501.133] (1.0000) ({r_i: None, r_t: [-925.297 -925.297 -925.297], eps: 1.0})
Step:   38800, Reward: [-531.201 -531.201 -531.201] [110.967], Avg: [-501.211 -501.211 -501.211] (1.0000) ({r_i: None, r_t: [-1068.268 -1068.268 -1068.268], eps: 1.0})
Step:   38900, Reward: [-507.248 -507.248 -507.248] [76.018], Avg: [-501.226 -501.226 -501.226] (1.0000) ({r_i: None, r_t: [-885.219 -885.219 -885.219], eps: 1.0})
Step:   39000, Reward: [-616.598 -616.598 -616.598] [67.559], Avg: [-501.521 -501.521 -501.521] (1.0000) ({r_i: None, r_t: [-1110.777 -1110.777 -1110.777], eps: 1.0})
Step:   39100, Reward: [-553.784 -553.784 -553.784] [136.459], Avg: [-501.654 -501.654 -501.654] (1.0000) ({r_i: None, r_t: [-972.711 -972.711 -972.711], eps: 1.0})
Step:   39200, Reward: [-558.082 -558.082 -558.082] [108.075], Avg: [-501.798 -501.798 -501.798] (1.0000) ({r_i: None, r_t: [-987.676 -987.676 -987.676], eps: 1.0})
Step:   39300, Reward: [-518.753 -518.753 -518.753] [112.935], Avg: [-501.841 -501.841 -501.841] (1.0000) ({r_i: None, r_t: [-1044.967 -1044.967 -1044.967], eps: 1.0})
Step:   39400, Reward: [-430.859 -430.859 -430.859] [72.743], Avg: [-501.661 -501.661 -501.661] (1.0000) ({r_i: None, r_t: [-878.173 -878.173 -878.173], eps: 1.0})
Step:   39500, Reward: [-515.547 -515.547 -515.547] [69.020], Avg: [-501.696 -501.696 -501.696] (1.0000) ({r_i: None, r_t: [-996.276 -996.276 -996.276], eps: 1.0})
Step:   39600, Reward: [-500.703 -500.703 -500.703] [84.361], Avg: [-501.694 -501.694 -501.694] (1.0000) ({r_i: None, r_t: [-888.735 -888.735 -888.735], eps: 1.0})
Step:   39700, Reward: [-483.536 -483.536 -483.536] [76.597], Avg: [-501.648 -501.648 -501.648] (1.0000) ({r_i: None, r_t: [-1079.765 -1079.765 -1079.765], eps: 1.0})
Step:   39800, Reward: [-569.909 -569.909 -569.909] [161.747], Avg: [-501.819 -501.819 -501.819] (1.0000) ({r_i: None, r_t: [-884.146 -884.146 -884.146], eps: 1.0})
Step:   39900, Reward: [-522.062 -522.062 -522.062] [26.752], Avg: [-501.870 -501.870 -501.870] (1.0000) ({r_i: None, r_t: [-905.284 -905.284 -905.284], eps: 1.0})
Step:   40000, Reward: [-505.994 -505.994 -505.994] [92.145], Avg: [-501.880 -501.880 -501.880] (1.0000) ({r_i: None, r_t: [-961.461 -961.461 -961.461], eps: 1.0})
Step:   40100, Reward: [-513.670 -513.670 -513.670] [41.628], Avg: [-501.910 -501.910 -501.910] (1.0000) ({r_i: None, r_t: [-1060.015 -1060.015 -1060.015], eps: 1.0})
Step:   40200, Reward: [-446.411 -446.411 -446.411] [78.068], Avg: [-501.772 -501.772 -501.772] (1.0000) ({r_i: None, r_t: [-1074.781 -1074.781 -1074.781], eps: 1.0})
Step:   40300, Reward: [-543.610 -543.610 -543.610] [81.226], Avg: [-501.875 -501.875 -501.875] (1.0000) ({r_i: None, r_t: [-1039.898 -1039.898 -1039.898], eps: 1.0})
Step:   40400, Reward: [-427.355 -427.355 -427.355] [72.600], Avg: [-501.691 -501.691 -501.691] (1.0000) ({r_i: None, r_t: [-980.302 -980.302 -980.302], eps: 1.0})
Step:   40500, Reward: [-459.383 -459.383 -459.383] [49.186], Avg: [-501.587 -501.587 -501.587] (1.0000) ({r_i: None, r_t: [-931.813 -931.813 -931.813], eps: 1.0})
Step:   40600, Reward: [-465.230 -465.230 -465.230] [43.478], Avg: [-501.498 -501.498 -501.498] (1.0000) ({r_i: None, r_t: [-981.616 -981.616 -981.616], eps: 1.0})
Step:   40700, Reward: [-559.967 -559.967 -559.967] [97.750], Avg: [-501.641 -501.641 -501.641] (1.0000) ({r_i: None, r_t: [-937.923 -937.923 -937.923], eps: 1.0})
Step:   40800, Reward: [-473.386 -473.386 -473.386] [124.865], Avg: [-501.572 -501.572 -501.572] (1.0000) ({r_i: None, r_t: [-863.075 -863.075 -863.075], eps: 1.0})
Step:   40900, Reward: [-562.520 -562.520 -562.520] [123.454], Avg: [-501.721 -501.721 -501.721] (1.0000) ({r_i: None, r_t: [-863.700 -863.700 -863.700], eps: 1.0})
Step:   41000, Reward: [-456.443 -456.443 -456.443] [119.978], Avg: [-501.611 -501.611 -501.611] (1.0000) ({r_i: None, r_t: [-880.922 -880.922 -880.922], eps: 1.0})
Step:   41100, Reward: [-431.500 -431.500 -431.500] [34.823], Avg: [-501.440 -501.440 -501.440] (1.0000) ({r_i: None, r_t: [-901.019 -901.019 -901.019], eps: 1.0})
Step:   41200, Reward: [-486.275 -486.275 -486.275] [58.984], Avg: [-501.404 -501.404 -501.404] (1.0000) ({r_i: None, r_t: [-963.749 -963.749 -963.749], eps: 1.0})
Step:   41300, Reward: [-475.558 -475.558 -475.558] [14.708], Avg: [-501.341 -501.341 -501.341] (1.0000) ({r_i: None, r_t: [-1113.378 -1113.378 -1113.378], eps: 1.0})
Step:   41400, Reward: [-509.941 -509.941 -509.941] [122.709], Avg: [-501.362 -501.362 -501.362] (1.0000) ({r_i: None, r_t: [-908.137 -908.137 -908.137], eps: 1.0})
Step:   41500, Reward: [-486.532 -486.532 -486.532] [79.052], Avg: [-501.326 -501.326 -501.326] (1.0000) ({r_i: None, r_t: [-959.512 -959.512 -959.512], eps: 1.0})
Step:   41600, Reward: [-569.040 -569.040 -569.040] [93.339], Avg: [-501.489 -501.489 -501.489] (1.0000) ({r_i: None, r_t: [-919.271 -919.271 -919.271], eps: 1.0})
Step:   41700, Reward: [-519.436 -519.436 -519.436] [47.855], Avg: [-501.532 -501.532 -501.532] (1.0000) ({r_i: None, r_t: [-1035.092 -1035.092 -1035.092], eps: 1.0})
Step:   41800, Reward: [-433.403 -433.403 -433.403] [32.041], Avg: [-501.369 -501.369 -501.369] (1.0000) ({r_i: None, r_t: [-1046.561 -1046.561 -1046.561], eps: 1.0})
Step:   41900, Reward: [-504.359 -504.359 -504.359] [49.033], Avg: [-501.376 -501.376 -501.376] (1.0000) ({r_i: None, r_t: [-1011.269 -1011.269 -1011.269], eps: 1.0})
Step:   42000, Reward: [-452.457 -452.457 -452.457] [44.634], Avg: [-501.260 -501.260 -501.260] (1.0000) ({r_i: None, r_t: [-1032.297 -1032.297 -1032.297], eps: 1.0})
Step:   42100, Reward: [-479.130 -479.130 -479.130] [69.047], Avg: [-501.208 -501.208 -501.208] (1.0000) ({r_i: None, r_t: [-1007.584 -1007.584 -1007.584], eps: 1.0})
Step:   42200, Reward: [-489.455 -489.455 -489.455] [151.901], Avg: [-501.180 -501.180 -501.180] (1.0000) ({r_i: None, r_t: [-968.690 -968.690 -968.690], eps: 1.0})
Step:   42300, Reward: [-525.491 -525.491 -525.491] [102.433], Avg: [-501.237 -501.237 -501.237] (1.0000) ({r_i: None, r_t: [-954.669 -954.669 -954.669], eps: 1.0})
Step:   42400, Reward: [-480.392 -480.392 -480.392] [74.581], Avg: [-501.188 -501.188 -501.188] (1.0000) ({r_i: None, r_t: [-943.954 -943.954 -943.954], eps: 1.0})
Step:   42500, Reward: [-536.591 -536.591 -536.591] [54.159], Avg: [-501.271 -501.271 -501.271] (1.0000) ({r_i: None, r_t: [-987.285 -987.285 -987.285], eps: 1.0})
Step:   42600, Reward: [-557.520 -557.520 -557.520] [130.731], Avg: [-501.403 -501.403 -501.403] (1.0000) ({r_i: None, r_t: [-1084.265 -1084.265 -1084.265], eps: 1.0})
Step:   42700, Reward: [-428.207 -428.207 -428.207] [58.637], Avg: [-501.232 -501.232 -501.232] (1.0000) ({r_i: None, r_t: [-936.166 -936.166 -936.166], eps: 1.0})
Step:   42800, Reward: [-528.269 -528.269 -528.269] [89.652], Avg: [-501.295 -501.295 -501.295] (1.0000) ({r_i: None, r_t: [-966.890 -966.890 -966.890], eps: 1.0})
Step:   42900, Reward: [-454.555 -454.555 -454.555] [57.096], Avg: [-501.186 -501.186 -501.186] (1.0000) ({r_i: None, r_t: [-1033.765 -1033.765 -1033.765], eps: 1.0})
Step:   43000, Reward: [-547.356 -547.356 -547.356] [51.458], Avg: [-501.293 -501.293 -501.293] (1.0000) ({r_i: None, r_t: [-1064.142 -1064.142 -1064.142], eps: 1.0})
Step:   43100, Reward: [-426.394 -426.394 -426.394] [43.544], Avg: [-501.120 -501.120 -501.120] (1.0000) ({r_i: None, r_t: [-946.367 -946.367 -946.367], eps: 1.0})
Step:   43200, Reward: [-511.925 -511.925 -511.925] [27.677], Avg: [-501.145 -501.145 -501.145] (1.0000) ({r_i: None, r_t: [-1018.928 -1018.928 -1018.928], eps: 1.0})
Step:   43300, Reward: [-518.437 -518.437 -518.437] [131.434], Avg: [-501.185 -501.185 -501.185] (1.0000) ({r_i: None, r_t: [-946.984 -946.984 -946.984], eps: 1.0})
Step:   43400, Reward: [-470.372 -470.372 -470.372] [65.424], Avg: [-501.114 -501.114 -501.114] (1.0000) ({r_i: None, r_t: [-1039.164 -1039.164 -1039.164], eps: 1.0})
Step:   43500, Reward: [-543.185 -543.185 -543.185] [54.280], Avg: [-501.210 -501.210 -501.210] (1.0000) ({r_i: None, r_t: [-869.095 -869.095 -869.095], eps: 1.0})
Step:   43600, Reward: [-472.151 -472.151 -472.151] [33.526], Avg: [-501.144 -501.144 -501.144] (1.0000) ({r_i: None, r_t: [-1013.489 -1013.489 -1013.489], eps: 1.0})
Step:   43700, Reward: [-461.043 -461.043 -461.043] [27.342], Avg: [-501.052 -501.052 -501.052] (1.0000) ({r_i: None, r_t: [-978.972 -978.972 -978.972], eps: 1.0})
Step:   43800, Reward: [-508.351 -508.351 -508.351] [121.837], Avg: [-501.069 -501.069 -501.069] (1.0000) ({r_i: None, r_t: [-902.654 -902.654 -902.654], eps: 1.0})
Step:   43900, Reward: [-494.449 -494.449 -494.449] [89.077], Avg: [-501.054 -501.054 -501.054] (1.0000) ({r_i: None, r_t: [-967.039 -967.039 -967.039], eps: 1.0})
Step:   44000, Reward: [-529.463 -529.463 -529.463] [130.166], Avg: [-501.118 -501.118 -501.118] (1.0000) ({r_i: None, r_t: [-942.152 -942.152 -942.152], eps: 1.0})
Step:   44100, Reward: [-557.860 -557.860 -557.860] [75.165], Avg: [-501.247 -501.247 -501.247] (1.0000) ({r_i: None, r_t: [-1089.226 -1089.226 -1089.226], eps: 1.0})
Step:   44200, Reward: [-498.385 -498.385 -498.385] [93.890], Avg: [-501.240 -501.240 -501.240] (1.0000) ({r_i: None, r_t: [-1097.691 -1097.691 -1097.691], eps: 1.0})
Step:   44300, Reward: [-471.798 -471.798 -471.798] [53.827], Avg: [-501.174 -501.174 -501.174] (1.0000) ({r_i: None, r_t: [-1032.284 -1032.284 -1032.284], eps: 1.0})
Step:   44400, Reward: [-559.389 -559.389 -559.389] [115.913], Avg: [-501.305 -501.305 -501.305] (1.0000) ({r_i: None, r_t: [-951.058 -951.058 -951.058], eps: 1.0})
Step:   44500, Reward: [-516.426 -516.426 -516.426] [29.062], Avg: [-501.339 -501.339 -501.339] (1.0000) ({r_i: None, r_t: [-1159.898 -1159.898 -1159.898], eps: 1.0})
Step:   44600, Reward: [-500.082 -500.082 -500.082] [65.652], Avg: [-501.336 -501.336 -501.336] (1.0000) ({r_i: None, r_t: [-1022.987 -1022.987 -1022.987], eps: 1.0})
Step:   44700, Reward: [-467.709 -467.709 -467.709] [63.621], Avg: [-501.261 -501.261 -501.261] (1.0000) ({r_i: None, r_t: [-914.494 -914.494 -914.494], eps: 1.0})
Step:   44800, Reward: [-519.525 -519.525 -519.525] [44.882], Avg: [-501.301 -501.301 -501.301] (1.0000) ({r_i: None, r_t: [-1097.572 -1097.572 -1097.572], eps: 1.0})
Step:   44900, Reward: [-468.244 -468.244 -468.244] [76.826], Avg: [-501.228 -501.228 -501.228] (1.0000) ({r_i: None, r_t: [-952.191 -952.191 -952.191], eps: 1.0})
Step:   45000, Reward: [-502.435 -502.435 -502.435] [84.244], Avg: [-501.231 -501.231 -501.231] (1.0000) ({r_i: None, r_t: [-1102.808 -1102.808 -1102.808], eps: 1.0})
Step:   45100, Reward: [-410.952 -410.952 -410.952] [81.471], Avg: [-501.031 -501.031 -501.031] (1.0000) ({r_i: None, r_t: [-1198.390 -1198.390 -1198.390], eps: 1.0})
Step:   45200, Reward: [-461.303 -461.303 -461.303] [72.011], Avg: [-500.943 -500.943 -500.943] (1.0000) ({r_i: None, r_t: [-861.168 -861.168 -861.168], eps: 1.0})
Step:   45300, Reward: [-584.848 -584.848 -584.848] [125.728], Avg: [-501.128 -501.128 -501.128] (1.0000) ({r_i: None, r_t: [-1100.918 -1100.918 -1100.918], eps: 1.0})
Step:   45400, Reward: [-523.740 -523.740 -523.740] [74.046], Avg: [-501.178 -501.178 -501.178] (1.0000) ({r_i: None, r_t: [-1002.460 -1002.460 -1002.460], eps: 1.0})
Step:   45500, Reward: [-496.911 -496.911 -496.911] [98.822], Avg: [-501.168 -501.168 -501.168] (1.0000) ({r_i: None, r_t: [-895.189 -895.189 -895.189], eps: 1.0})
Step:   45600, Reward: [-498.995 -498.995 -498.995] [110.385], Avg: [-501.164 -501.164 -501.164] (1.0000) ({r_i: None, r_t: [-1053.636 -1053.636 -1053.636], eps: 1.0})
Step:   45700, Reward: [-416.400 -416.400 -416.400] [64.904], Avg: [-500.979 -500.979 -500.979] (1.0000) ({r_i: None, r_t: [-936.749 -936.749 -936.749], eps: 1.0})
Step:   45800, Reward: [-616.994 -616.994 -616.994] [214.383], Avg: [-501.231 -501.231 -501.231] (1.0000) ({r_i: None, r_t: [-949.000 -949.000 -949.000], eps: 1.0})
Step:   45900, Reward: [-477.037 -477.037 -477.037] [103.013], Avg: [-501.179 -501.179 -501.179] (1.0000) ({r_i: None, r_t: [-886.568 -886.568 -886.568], eps: 1.0})
Step:   46000, Reward: [-518.397 -518.397 -518.397] [80.774], Avg: [-501.216 -501.216 -501.216] (1.0000) ({r_i: None, r_t: [-1093.406 -1093.406 -1093.406], eps: 1.0})
Step:   46100, Reward: [-485.354 -485.354 -485.354] [53.368], Avg: [-501.182 -501.182 -501.182] (1.0000) ({r_i: None, r_t: [-940.782 -940.782 -940.782], eps: 1.0})
Step:   46200, Reward: [-477.417 -477.417 -477.417] [130.209], Avg: [-501.130 -501.130 -501.130] (1.0000) ({r_i: None, r_t: [-1121.612 -1121.612 -1121.612], eps: 1.0})
Step:   46300, Reward: [-515.767 -515.767 -515.767] [44.475], Avg: [-501.162 -501.162 -501.162] (1.0000) ({r_i: None, r_t: [-932.519 -932.519 -932.519], eps: 1.0})
Step:   46400, Reward: [-457.649 -457.649 -457.649] [45.823], Avg: [-501.068 -501.068 -501.068] (1.0000) ({r_i: None, r_t: [-1007.011 -1007.011 -1007.011], eps: 1.0})
Step:   46500, Reward: [-509.176 -509.176 -509.176] [93.457], Avg: [-501.086 -501.086 -501.086] (1.0000) ({r_i: None, r_t: [-1017.786 -1017.786 -1017.786], eps: 1.0})
Step:   46600, Reward: [-465.045 -465.045 -465.045] [65.944], Avg: [-501.009 -501.009 -501.009] (1.0000) ({r_i: None, r_t: [-977.322 -977.322 -977.322], eps: 1.0})
Step:   46700, Reward: [-503.457 -503.457 -503.457] [68.524], Avg: [-501.014 -501.014 -501.014] (1.0000) ({r_i: None, r_t: [-997.200 -997.200 -997.200], eps: 1.0})
Step:   46800, Reward: [-563.595 -563.595 -563.595] [51.411], Avg: [-501.147 -501.147 -501.147] (1.0000) ({r_i: None, r_t: [-1014.086 -1014.086 -1014.086], eps: 1.0})
Step:   46900, Reward: [-570.864 -570.864 -570.864] [74.265], Avg: [-501.296 -501.296 -501.296] (1.0000) ({r_i: None, r_t: [-1075.730 -1075.730 -1075.730], eps: 1.0})
Step:   47000, Reward: [-519.770 -519.770 -519.770] [67.107], Avg: [-501.335 -501.335 -501.335] (1.0000) ({r_i: None, r_t: [-938.713 -938.713 -938.713], eps: 1.0})
Step:   47100, Reward: [-531.382 -531.382 -531.382] [95.323], Avg: [-501.399 -501.399 -501.399] (1.0000) ({r_i: None, r_t: [-1033.352 -1033.352 -1033.352], eps: 1.0})
Step:   47200, Reward: [-430.269 -430.269 -430.269] [64.489], Avg: [-501.248 -501.248 -501.248] (1.0000) ({r_i: None, r_t: [-1087.644 -1087.644 -1087.644], eps: 1.0})
Step:   47300, Reward: [-416.418 -416.418 -416.418] [24.346], Avg: [-501.069 -501.069 -501.069] (1.0000) ({r_i: None, r_t: [-984.228 -984.228 -984.228], eps: 1.0})
Step:   47400, Reward: [-660.423 -660.423 -660.423] [115.982], Avg: [-501.405 -501.405 -501.405] (1.0000) ({r_i: None, r_t: [-1029.244 -1029.244 -1029.244], eps: 1.0})
Step:   47500, Reward: [-477.249 -477.249 -477.249] [97.982], Avg: [-501.354 -501.354 -501.354] (1.0000) ({r_i: None, r_t: [-980.737 -980.737 -980.737], eps: 1.0})
Step:   47600, Reward: [-516.539 -516.539 -516.539] [39.357], Avg: [-501.386 -501.386 -501.386] (1.0000) ({r_i: None, r_t: [-940.956 -940.956 -940.956], eps: 1.0})
Step:   47700, Reward: [-510.669 -510.669 -510.669] [67.856], Avg: [-501.405 -501.405 -501.405] (1.0000) ({r_i: None, r_t: [-966.365 -966.365 -966.365], eps: 1.0})
Step:   47800, Reward: [-617.105 -617.105 -617.105] [124.145], Avg: [-501.647 -501.647 -501.647] (1.0000) ({r_i: None, r_t: [-1025.646 -1025.646 -1025.646], eps: 1.0})
Step:   47900, Reward: [-545.582 -545.582 -545.582] [89.063], Avg: [-501.738 -501.738 -501.738] (1.0000) ({r_i: None, r_t: [-920.270 -920.270 -920.270], eps: 1.0})
Step:   48000, Reward: [-446.397 -446.397 -446.397] [33.965], Avg: [-501.623 -501.623 -501.623] (1.0000) ({r_i: None, r_t: [-1075.861 -1075.861 -1075.861], eps: 1.0})
Step:   48100, Reward: [-522.338 -522.338 -522.338] [89.434], Avg: [-501.666 -501.666 -501.666] (1.0000) ({r_i: None, r_t: [-924.177 -924.177 -924.177], eps: 1.0})
Step:   48200, Reward: [-444.525 -444.525 -444.525] [73.537], Avg: [-501.548 -501.548 -501.548] (1.0000) ({r_i: None, r_t: [-946.633 -946.633 -946.633], eps: 1.0})
Step:   48300, Reward: [-541.192 -541.192 -541.192] [144.509], Avg: [-501.630 -501.630 -501.630] (1.0000) ({r_i: None, r_t: [-1022.320 -1022.320 -1022.320], eps: 1.0})
Step:   48400, Reward: [-588.524 -588.524 -588.524] [90.713], Avg: [-501.809 -501.809 -501.809] (1.0000) ({r_i: None, r_t: [-966.663 -966.663 -966.663], eps: 1.0})
Step:   48500, Reward: [-484.514 -484.514 -484.514] [98.364], Avg: [-501.773 -501.773 -501.773] (1.0000) ({r_i: None, r_t: [-850.530 -850.530 -850.530], eps: 1.0})
Step:   48600, Reward: [-547.886 -547.886 -547.886] [107.830], Avg: [-501.868 -501.868 -501.868] (1.0000) ({r_i: None, r_t: [-1081.217 -1081.217 -1081.217], eps: 1.0})
Step:   48700, Reward: [-476.934 -476.934 -476.934] [131.003], Avg: [-501.817 -501.817 -501.817] (1.0000) ({r_i: None, r_t: [-998.261 -998.261 -998.261], eps: 1.0})
Step:   48800, Reward: [-439.335 -439.335 -439.335] [51.861], Avg: [-501.689 -501.689 -501.689] (1.0000) ({r_i: None, r_t: [-1012.561 -1012.561 -1012.561], eps: 1.0})
Step:   48900, Reward: [-519.060 -519.060 -519.060] [50.662], Avg: [-501.725 -501.725 -501.725] (1.0000) ({r_i: None, r_t: [-1059.183 -1059.183 -1059.183], eps: 1.0})
Step:   49000, Reward: [-521.653 -521.653 -521.653] [86.387], Avg: [-501.765 -501.765 -501.765] (1.0000) ({r_i: None, r_t: [-938.900 -938.900 -938.900], eps: 1.0})
Step:   49100, Reward: [-544.471 -544.471 -544.471] [73.202], Avg: [-501.852 -501.852 -501.852] (1.0000) ({r_i: None, r_t: [-911.238 -911.238 -911.238], eps: 1.0})
Step:   49200, Reward: [-532.434 -532.434 -532.434] [92.012], Avg: [-501.914 -501.914 -501.914] (1.0000) ({r_i: None, r_t: [-1123.857 -1123.857 -1123.857], eps: 1.0})
Step:   49300, Reward: [-461.459 -461.459 -461.459] [41.455], Avg: [-501.832 -501.832 -501.832] (1.0000) ({r_i: None, r_t: [-1026.140 -1026.140 -1026.140], eps: 1.0})
Step:   49400, Reward: [-483.645 -483.645 -483.645] [25.651], Avg: [-501.795 -501.795 -501.795] (1.0000) ({r_i: None, r_t: [-1134.089 -1134.089 -1134.089], eps: 1.0})
Step:   49500, Reward: [-427.934 -427.934 -427.934] [31.164], Avg: [-501.646 -501.646 -501.646] (1.0000) ({r_i: None, r_t: [-996.015 -996.015 -996.015], eps: 1.0})
Step:   49600, Reward: [-481.539 -481.539 -481.539] [58.812], Avg: [-501.606 -501.606 -501.606] (1.0000) ({r_i: None, r_t: [-975.518 -975.518 -975.518], eps: 1.0})
Step:   49700, Reward: [-466.616 -466.616 -466.616] [102.784], Avg: [-501.536 -501.536 -501.536] (1.0000) ({r_i: None, r_t: [-1013.636 -1013.636 -1013.636], eps: 1.0})
Step:   49800, Reward: [-436.776 -436.776 -436.776] [94.198], Avg: [-501.406 -501.406 -501.406] (1.0000) ({r_i: None, r_t: [-996.316 -996.316 -996.316], eps: 1.0})
Step:   49900, Reward: [-480.356 -480.356 -480.356] [34.279], Avg: [-501.364 -501.364 -501.364] (1.0000) ({r_i: None, r_t: [-975.461 -975.461 -975.461], eps: 1.0})
Step:   50000, Reward: [-443.911 -443.911 -443.911] [44.043], Avg: [-501.249 -501.249 -501.249] (1.0000) ({r_i: None, r_t: [-1020.825 -1020.825 -1020.825], eps: 1.0})
Step:   50100, Reward: [-532.089 -532.089 -532.089] [105.353], Avg: [-501.311 -501.311 -501.311] (1.0000) ({r_i: None, r_t: [-889.219 -889.219 -889.219], eps: 1.0})
Step:   50200, Reward: [-557.347 -557.347 -557.347] [106.356], Avg: [-501.422 -501.422 -501.422] (1.0000) ({r_i: None, r_t: [-1060.302 -1060.302 -1060.302], eps: 1.0})
Step:   50300, Reward: [-502.926 -502.926 -502.926] [41.036], Avg: [-501.425 -501.425 -501.425] (1.0000) ({r_i: None, r_t: [-962.158 -962.158 -962.158], eps: 1.0})
Step:   50400, Reward: [-524.698 -524.698 -524.698] [57.239], Avg: [-501.471 -501.471 -501.471] (1.0000) ({r_i: None, r_t: [-925.352 -925.352 -925.352], eps: 1.0})
Step:   50500, Reward: [-504.887 -504.887 -504.887] [64.259], Avg: [-501.478 -501.478 -501.478] (1.0000) ({r_i: None, r_t: [-954.392 -954.392 -954.392], eps: 1.0})
Step:   50600, Reward: [-471.388 -471.388 -471.388] [51.099], Avg: [-501.419 -501.419 -501.419] (1.0000) ({r_i: None, r_t: [-1154.171 -1154.171 -1154.171], eps: 1.0})
Step:   50700, Reward: [-517.115 -517.115 -517.115] [138.388], Avg: [-501.449 -501.449 -501.449] (1.0000) ({r_i: None, r_t: [-1031.174 -1031.174 -1031.174], eps: 1.0})
Step:   50800, Reward: [-444.413 -444.413 -444.413] [66.802], Avg: [-501.337 -501.337 -501.337] (1.0000) ({r_i: None, r_t: [-939.969 -939.969 -939.969], eps: 1.0})
Step:   50900, Reward: [-432.870 -432.870 -432.870] [16.933], Avg: [-501.203 -501.203 -501.203] (1.0000) ({r_i: None, r_t: [-991.658 -991.658 -991.658], eps: 1.0})
Step:   51000, Reward: [-370.693 -370.693 -370.693] [32.804], Avg: [-500.948 -500.948 -500.948] (1.0000) ({r_i: None, r_t: [-1096.595 -1096.595 -1096.595], eps: 1.0})
Step:   51100, Reward: [-475.813 -475.813 -475.813] [136.790], Avg: [-500.899 -500.899 -500.899] (1.0000) ({r_i: None, r_t: [-916.913 -916.913 -916.913], eps: 1.0})
Step:   51200, Reward: [-523.476 -523.476 -523.476] [179.841], Avg: [-500.943 -500.943 -500.943] (1.0000) ({r_i: None, r_t: [-940.082 -940.082 -940.082], eps: 1.0})
Step:   51300, Reward: [-492.178 -492.178 -492.178] [53.377], Avg: [-500.926 -500.926 -500.926] (1.0000) ({r_i: None, r_t: [-1129.687 -1129.687 -1129.687], eps: 1.0})
Step:   51400, Reward: [-460.493 -460.493 -460.493] [61.418], Avg: [-500.847 -500.847 -500.847] (1.0000) ({r_i: None, r_t: [-908.265 -908.265 -908.265], eps: 1.0})
Step:   51500, Reward: [-472.015 -472.015 -472.015] [107.067], Avg: [-500.791 -500.791 -500.791] (1.0000) ({r_i: None, r_t: [-1038.023 -1038.023 -1038.023], eps: 1.0})
Step:   51600, Reward: [-481.713 -481.713 -481.713] [39.777], Avg: [-500.754 -500.754 -500.754] (1.0000) ({r_i: None, r_t: [-934.155 -934.155 -934.155], eps: 1.0})
Step:   51700, Reward: [-553.592 -553.592 -553.592] [99.581], Avg: [-500.856 -500.856 -500.856] (1.0000) ({r_i: None, r_t: [-1033.731 -1033.731 -1033.731], eps: 1.0})
Step:   51800, Reward: [-549.043 -549.043 -549.043] [86.653], Avg: [-500.949 -500.949 -500.949] (1.0000) ({r_i: None, r_t: [-884.042 -884.042 -884.042], eps: 1.0})
Step:   51900, Reward: [-593.629 -593.629 -593.629] [139.700], Avg: [-501.127 -501.127 -501.127] (1.0000) ({r_i: None, r_t: [-1032.346 -1032.346 -1032.346], eps: 1.0})
Step:   52000, Reward: [-483.547 -483.547 -483.547] [93.618], Avg: [-501.094 -501.094 -501.094] (1.0000) ({r_i: None, r_t: [-1006.036 -1006.036 -1006.036], eps: 1.0})
Step:   52100, Reward: [-465.541 -465.541 -465.541] [62.240], Avg: [-501.026 -501.026 -501.026] (1.0000) ({r_i: None, r_t: [-977.210 -977.210 -977.210], eps: 1.0})
Step:   52200, Reward: [-472.814 -472.814 -472.814] [109.262], Avg: [-500.972 -500.972 -500.972] (1.0000) ({r_i: None, r_t: [-1033.585 -1033.585 -1033.585], eps: 1.0})
Step:   52300, Reward: [-445.383 -445.383 -445.383] [56.514], Avg: [-500.865 -500.865 -500.865] (1.0000) ({r_i: None, r_t: [-975.784 -975.784 -975.784], eps: 1.0})
Step:   52400, Reward: [-454.701 -454.701 -454.701] [32.365], Avg: [-500.778 -500.778 -500.778] (1.0000) ({r_i: None, r_t: [-1025.449 -1025.449 -1025.449], eps: 1.0})
Step:   52500, Reward: [-487.658 -487.658 -487.658] [64.232], Avg: [-500.753 -500.753 -500.753] (1.0000) ({r_i: None, r_t: [-1045.680 -1045.680 -1045.680], eps: 1.0})
Step:   52600, Reward: [-510.693 -510.693 -510.693] [73.572], Avg: [-500.771 -500.771 -500.771] (1.0000) ({r_i: None, r_t: [-1053.921 -1053.921 -1053.921], eps: 1.0})
Step:   52700, Reward: [-449.957 -449.957 -449.957] [72.970], Avg: [-500.675 -500.675 -500.675] (1.0000) ({r_i: None, r_t: [-935.572 -935.572 -935.572], eps: 1.0})
Step:   52800, Reward: [-501.021 -501.021 -501.021] [9.195], Avg: [-500.676 -500.676 -500.676] (1.0000) ({r_i: None, r_t: [-1047.374 -1047.374 -1047.374], eps: 1.0})
Step:   52900, Reward: [-473.522 -473.522 -473.522] [109.677], Avg: [-500.625 -500.625 -500.625] (1.0000) ({r_i: None, r_t: [-974.041 -974.041 -974.041], eps: 1.0})
Step:   53000, Reward: [-443.253 -443.253 -443.253] [67.742], Avg: [-500.517 -500.517 -500.517] (1.0000) ({r_i: None, r_t: [-872.211 -872.211 -872.211], eps: 1.0})
Step:   53100, Reward: [-413.910 -413.910 -413.910] [87.182], Avg: [-500.354 -500.354 -500.354] (1.0000) ({r_i: None, r_t: [-971.711 -971.711 -971.711], eps: 1.0})
Step:   53200, Reward: [-567.526 -567.526 -567.526] [88.685], Avg: [-500.480 -500.480 -500.480] (1.0000) ({r_i: None, r_t: [-1070.931 -1070.931 -1070.931], eps: 1.0})
Step:   53300, Reward: [-504.156 -504.156 -504.156] [180.658], Avg: [-500.487 -500.487 -500.487] (1.0000) ({r_i: None, r_t: [-1064.792 -1064.792 -1064.792], eps: 1.0})
Step:   53400, Reward: [-526.600 -526.600 -526.600] [120.497], Avg: [-500.536 -500.536 -500.536] (1.0000) ({r_i: None, r_t: [-1157.718 -1157.718 -1157.718], eps: 1.0})
Step:   53500, Reward: [-407.897 -407.897 -407.897] [66.512], Avg: [-500.363 -500.363 -500.363] (1.0000) ({r_i: None, r_t: [-903.102 -903.102 -903.102], eps: 1.0})
Step:   53600, Reward: [-505.604 -505.604 -505.604] [147.154], Avg: [-500.372 -500.372 -500.372] (1.0000) ({r_i: None, r_t: [-1220.591 -1220.591 -1220.591], eps: 1.0})
Step:   53700, Reward: [-494.363 -494.363 -494.363] [122.912], Avg: [-500.361 -500.361 -500.361] (1.0000) ({r_i: None, r_t: [-846.900 -846.900 -846.900], eps: 1.0})
Step:   53800, Reward: [-506.454 -506.454 -506.454] [152.832], Avg: [-500.373 -500.373 -500.373] (1.0000) ({r_i: None, r_t: [-1011.436 -1011.436 -1011.436], eps: 1.0})
Step:   53900, Reward: [-444.532 -444.532 -444.532] [72.640], Avg: [-500.269 -500.269 -500.269] (1.0000) ({r_i: None, r_t: [-951.138 -951.138 -951.138], eps: 1.0})
Step:   54000, Reward: [-466.813 -466.813 -466.813] [43.735], Avg: [-500.207 -500.207 -500.207] (1.0000) ({r_i: None, r_t: [-912.032 -912.032 -912.032], eps: 1.0})
Step:   54100, Reward: [-491.805 -491.805 -491.805] [78.580], Avg: [-500.192 -500.192 -500.192] (1.0000) ({r_i: None, r_t: [-927.741 -927.741 -927.741], eps: 1.0})
Step:   54200, Reward: [-505.567 -505.567 -505.567] [29.255], Avg: [-500.202 -500.202 -500.202] (1.0000) ({r_i: None, r_t: [-971.334 -971.334 -971.334], eps: 1.0})
Step:   54300, Reward: [-507.910 -507.910 -507.910] [64.497], Avg: [-500.216 -500.216 -500.216] (1.0000) ({r_i: None, r_t: [-1185.144 -1185.144 -1185.144], eps: 1.0})
Step:   54400, Reward: [-484.896 -484.896 -484.896] [114.110], Avg: [-500.188 -500.188 -500.188] (1.0000) ({r_i: None, r_t: [-1075.139 -1075.139 -1075.139], eps: 1.0})
Step:   54500, Reward: [-557.217 -557.217 -557.217] [173.699], Avg: [-500.292 -500.292 -500.292] (1.0000) ({r_i: None, r_t: [-955.112 -955.112 -955.112], eps: 1.0})
Step:   54600, Reward: [-464.744 -464.744 -464.744] [67.505], Avg: [-500.227 -500.227 -500.227] (1.0000) ({r_i: None, r_t: [-957.741 -957.741 -957.741], eps: 1.0})
Step:   54700, Reward: [-659.697 -659.697 -659.697] [154.360], Avg: [-500.518 -500.518 -500.518] (1.0000) ({r_i: None, r_t: [-947.782 -947.782 -947.782], eps: 1.0})
Step:   54800, Reward: [-525.957 -525.957 -525.957] [128.415], Avg: [-500.565 -500.565 -500.565] (1.0000) ({r_i: None, r_t: [-956.891 -956.891 -956.891], eps: 1.0})
Step:   54900, Reward: [-499.487 -499.487 -499.487] [45.341], Avg: [-500.563 -500.563 -500.563] (1.0000) ({r_i: None, r_t: [-908.388 -908.388 -908.388], eps: 1.0})
Step:   55000, Reward: [-502.516 -502.516 -502.516] [80.591], Avg: [-500.566 -500.566 -500.566] (1.0000) ({r_i: None, r_t: [-936.017 -936.017 -936.017], eps: 1.0})
Step:   55100, Reward: [-577.341 -577.341 -577.341] [128.765], Avg: [-500.705 -500.705 -500.705] (1.0000) ({r_i: None, r_t: [-985.592 -985.592 -985.592], eps: 1.0})
Step:   55200, Reward: [-453.527 -453.527 -453.527] [71.204], Avg: [-500.620 -500.620 -500.620] (1.0000) ({r_i: None, r_t: [-1047.334 -1047.334 -1047.334], eps: 1.0})
Step:   55300, Reward: [-447.963 -447.963 -447.963] [79.554], Avg: [-500.525 -500.525 -500.525] (1.0000) ({r_i: None, r_t: [-906.102 -906.102 -906.102], eps: 1.0})
Step:   55400, Reward: [-458.797 -458.797 -458.797] [39.606], Avg: [-500.450 -500.450 -500.450] (1.0000) ({r_i: None, r_t: [-996.145 -996.145 -996.145], eps: 1.0})
Step:   55500, Reward: [-456.133 -456.133 -456.133] [27.992], Avg: [-500.370 -500.370 -500.370] (1.0000) ({r_i: None, r_t: [-1101.427 -1101.427 -1101.427], eps: 1.0})
Step:   55600, Reward: [-441.496 -441.496 -441.496] [41.491], Avg: [-500.264 -500.264 -500.264] (1.0000) ({r_i: None, r_t: [-949.040 -949.040 -949.040], eps: 1.0})
Step:   55700, Reward: [-518.356 -518.356 -518.356] [159.924], Avg: [-500.297 -500.297 -500.297] (1.0000) ({r_i: None, r_t: [-1039.435 -1039.435 -1039.435], eps: 1.0})
Step:   55800, Reward: [-529.218 -529.218 -529.218] [41.182], Avg: [-500.348 -500.348 -500.348] (1.0000) ({r_i: None, r_t: [-966.650 -966.650 -966.650], eps: 1.0})
Step:   55900, Reward: [-509.817 -509.817 -509.817] [167.996], Avg: [-500.365 -500.365 -500.365] (1.0000) ({r_i: None, r_t: [-860.554 -860.554 -860.554], eps: 1.0})
Step:   56000, Reward: [-522.046 -522.046 -522.046] [74.904], Avg: [-500.404 -500.404 -500.404] (1.0000) ({r_i: None, r_t: [-1047.081 -1047.081 -1047.081], eps: 1.0})
Step:   56100, Reward: [-503.823 -503.823 -503.823] [168.438], Avg: [-500.410 -500.410 -500.410] (1.0000) ({r_i: None, r_t: [-1126.498 -1126.498 -1126.498], eps: 1.0})
Step:   56200, Reward: [-429.202 -429.202 -429.202] [59.230], Avg: [-500.284 -500.284 -500.284] (1.0000) ({r_i: None, r_t: [-949.269 -949.269 -949.269], eps: 1.0})
Step:   56300, Reward: [-519.288 -519.288 -519.288] [27.462], Avg: [-500.317 -500.317 -500.317] (1.0000) ({r_i: None, r_t: [-1121.232 -1121.232 -1121.232], eps: 1.0})
Step:   56400, Reward: [-553.072 -553.072 -553.072] [58.279], Avg: [-500.411 -500.411 -500.411] (1.0000) ({r_i: None, r_t: [-944.683 -944.683 -944.683], eps: 1.0})
Step:   56500, Reward: [-508.141 -508.141 -508.141] [45.006], Avg: [-500.424 -500.424 -500.424] (1.0000) ({r_i: None, r_t: [-915.727 -915.727 -915.727], eps: 1.0})
Step:   56600, Reward: [-524.140 -524.140 -524.140] [21.332], Avg: [-500.466 -500.466 -500.466] (1.0000) ({r_i: None, r_t: [-1026.732 -1026.732 -1026.732], eps: 1.0})
Step:   56700, Reward: [-462.903 -462.903 -462.903] [63.194], Avg: [-500.400 -500.400 -500.400] (1.0000) ({r_i: None, r_t: [-993.165 -993.165 -993.165], eps: 1.0})
Step:   56800, Reward: [-466.035 -466.035 -466.035] [71.100], Avg: [-500.340 -500.340 -500.340] (1.0000) ({r_i: None, r_t: [-946.296 -946.296 -946.296], eps: 1.0})
Step:   56900, Reward: [-542.013 -542.013 -542.013] [61.803], Avg: [-500.413 -500.413 -500.413] (1.0000) ({r_i: None, r_t: [-1131.182 -1131.182 -1131.182], eps: 1.0})
Step:   57000, Reward: [-473.169 -473.169 -473.169] [115.450], Avg: [-500.365 -500.365 -500.365] (1.0000) ({r_i: None, r_t: [-1119.210 -1119.210 -1119.210], eps: 1.0})
Step:   57100, Reward: [-524.398 -524.398 -524.398] [121.549], Avg: [-500.407 -500.407 -500.407] (1.0000) ({r_i: None, r_t: [-1056.412 -1056.412 -1056.412], eps: 1.0})
Step:   57200, Reward: [-417.976 -417.976 -417.976] [78.643], Avg: [-500.263 -500.263 -500.263] (1.0000) ({r_i: None, r_t: [-1003.759 -1003.759 -1003.759], eps: 1.0})
Step:   57300, Reward: [-507.507 -507.507 -507.507] [93.607], Avg: [-500.276 -500.276 -500.276] (1.0000) ({r_i: None, r_t: [-1020.406 -1020.406 -1020.406], eps: 1.0})
Step:   57400, Reward: [-484.235 -484.235 -484.235] [48.321], Avg: [-500.248 -500.248 -500.248] (1.0000) ({r_i: None, r_t: [-1138.906 -1138.906 -1138.906], eps: 1.0})
Step:   57500, Reward: [-485.154 -485.154 -485.154] [69.771], Avg: [-500.222 -500.222 -500.222] (1.0000) ({r_i: None, r_t: [-1080.429 -1080.429 -1080.429], eps: 1.0})
Step:   57600, Reward: [-470.810 -470.810 -470.810] [54.661], Avg: [-500.171 -500.171 -500.171] (1.0000) ({r_i: None, r_t: [-966.340 -966.340 -966.340], eps: 1.0})
Step:   57700, Reward: [-473.185 -473.185 -473.185] [121.995], Avg: [-500.124 -500.124 -500.124] (1.0000) ({r_i: None, r_t: [-940.266 -940.266 -940.266], eps: 1.0})
Step:   57800, Reward: [-504.038 -504.038 -504.038] [35.698], Avg: [-500.131 -500.131 -500.131] (1.0000) ({r_i: None, r_t: [-999.822 -999.822 -999.822], eps: 1.0})
Step:   57900, Reward: [-413.812 -413.812 -413.812] [58.547], Avg: [-499.982 -499.982 -499.982] (1.0000) ({r_i: None, r_t: [-1052.241 -1052.241 -1052.241], eps: 1.0})
Step:   58000, Reward: [-521.265 -521.265 -521.265] [111.602], Avg: [-500.019 -500.019 -500.019] (1.0000) ({r_i: None, r_t: [-958.405 -958.405 -958.405], eps: 1.0})
Step:   58100, Reward: [-431.761 -431.761 -431.761] [55.900], Avg: [-499.901 -499.901 -499.901] (1.0000) ({r_i: None, r_t: [-1085.302 -1085.302 -1085.302], eps: 1.0})
Step:   58200, Reward: [-443.190 -443.190 -443.190] [66.154], Avg: [-499.804 -499.804 -499.804] (1.0000) ({r_i: None, r_t: [-907.577 -907.577 -907.577], eps: 1.0})
Step:   58300, Reward: [-493.349 -493.349 -493.349] [65.113], Avg: [-499.793 -499.793 -499.793] (1.0000) ({r_i: None, r_t: [-984.545 -984.545 -984.545], eps: 1.0})
Step:   58400, Reward: [-453.144 -453.144 -453.144] [66.227], Avg: [-499.713 -499.713 -499.713] (1.0000) ({r_i: None, r_t: [-975.581 -975.581 -975.581], eps: 1.0})
Step:   58500, Reward: [-529.882 -529.882 -529.882] [68.732], Avg: [-499.765 -499.765 -499.765] (1.0000) ({r_i: None, r_t: [-1078.288 -1078.288 -1078.288], eps: 1.0})
Step:   58600, Reward: [-441.696 -441.696 -441.696] [69.650], Avg: [-499.666 -499.666 -499.666] (1.0000) ({r_i: None, r_t: [-918.370 -918.370 -918.370], eps: 1.0})
Step:   58700, Reward: [-472.107 -472.107 -472.107] [25.304], Avg: [-499.619 -499.619 -499.619] (1.0000) ({r_i: None, r_t: [-948.933 -948.933 -948.933], eps: 1.0})
Step:   58800, Reward: [-480.695 -480.695 -480.695] [59.093], Avg: [-499.587 -499.587 -499.587] (1.0000) ({r_i: None, r_t: [-961.282 -961.282 -961.282], eps: 1.0})
Step:   58900, Reward: [-523.045 -523.045 -523.045] [101.793], Avg: [-499.627 -499.627 -499.627] (1.0000) ({r_i: None, r_t: [-1031.341 -1031.341 -1031.341], eps: 1.0})
Step:   59000, Reward: [-501.319 -501.319 -501.319] [77.847], Avg: [-499.629 -499.629 -499.629] (1.0000) ({r_i: None, r_t: [-960.248 -960.248 -960.248], eps: 1.0})
Step:   59100, Reward: [-514.607 -514.607 -514.607] [88.271], Avg: [-499.655 -499.655 -499.655] (1.0000) ({r_i: None, r_t: [-937.846 -937.846 -937.846], eps: 1.0})
Step:   59200, Reward: [-487.815 -487.815 -487.815] [56.909], Avg: [-499.635 -499.635 -499.635] (1.0000) ({r_i: None, r_t: [-1049.797 -1049.797 -1049.797], eps: 1.0})
Step:   59300, Reward: [-495.646 -495.646 -495.646] [72.130], Avg: [-499.628 -499.628 -499.628] (1.0000) ({r_i: None, r_t: [-1015.741 -1015.741 -1015.741], eps: 1.0})
Step:   59400, Reward: [-534.529 -534.529 -534.529] [90.640], Avg: [-499.687 -499.687 -499.687] (1.0000) ({r_i: None, r_t: [-940.967 -940.967 -940.967], eps: 1.0})
Step:   59500, Reward: [-474.697 -474.697 -474.697] [46.141], Avg: [-499.645 -499.645 -499.645] (1.0000) ({r_i: None, r_t: [-1021.336 -1021.336 -1021.336], eps: 1.0})
Step:   59600, Reward: [-409.710 -409.710 -409.710] [15.009], Avg: [-499.494 -499.494 -499.494] (1.0000) ({r_i: None, r_t: [-957.927 -957.927 -957.927], eps: 1.0})
Step:   59700, Reward: [-511.287 -511.287 -511.287] [102.107], Avg: [-499.514 -499.514 -499.514] (1.0000) ({r_i: None, r_t: [-1066.210 -1066.210 -1066.210], eps: 1.0})
Step:   59800, Reward: [-550.532 -550.532 -550.532] [38.067], Avg: [-499.599 -499.599 -499.599] (1.0000) ({r_i: None, r_t: [-982.044 -982.044 -982.044], eps: 1.0})
Step:   59900, Reward: [-544.176 -544.176 -544.176] [43.759], Avg: [-499.673 -499.673 -499.673] (1.0000) ({r_i: None, r_t: [-947.867 -947.867 -947.867], eps: 1.0})
Step:   60000, Reward: [-513.147 -513.147 -513.147] [109.430], Avg: [-499.696 -499.696 -499.696] (1.0000) ({r_i: None, r_t: [-1157.869 -1157.869 -1157.869], eps: 1.0})
Step:   60100, Reward: [-430.187 -430.187 -430.187] [79.572], Avg: [-499.580 -499.580 -499.580] (1.0000) ({r_i: None, r_t: [-913.469 -913.469 -913.469], eps: 1.0})
Step:   60200, Reward: [-479.079 -479.079 -479.079] [106.551], Avg: [-499.546 -499.546 -499.546] (1.0000) ({r_i: None, r_t: [-1162.552 -1162.552 -1162.552], eps: 1.0})
Step:   60300, Reward: [-449.028 -449.028 -449.028] [103.236], Avg: [-499.463 -499.463 -499.463] (1.0000) ({r_i: None, r_t: [-1094.398 -1094.398 -1094.398], eps: 1.0})
Step:   60400, Reward: [-530.913 -530.913 -530.913] [114.735], Avg: [-499.515 -499.515 -499.515] (1.0000) ({r_i: None, r_t: [-1044.835 -1044.835 -1044.835], eps: 1.0})
Step:   60500, Reward: [-410.323 -410.323 -410.323] [52.497], Avg: [-499.367 -499.367 -499.367] (1.0000) ({r_i: None, r_t: [-930.455 -930.455 -930.455], eps: 1.0})
Step:   60600, Reward: [-452.692 -452.692 -452.692] [81.589], Avg: [-499.291 -499.291 -499.291] (1.0000) ({r_i: None, r_t: [-1071.176 -1071.176 -1071.176], eps: 1.0})
Step:   60700, Reward: [-611.313 -611.313 -611.313] [261.767], Avg: [-499.475 -499.475 -499.475] (1.0000) ({r_i: None, r_t: [-875.013 -875.013 -875.013], eps: 1.0})
Step:   60800, Reward: [-460.105 -460.105 -460.105] [68.531], Avg: [-499.410 -499.410 -499.410] (1.0000) ({r_i: None, r_t: [-879.581 -879.581 -879.581], eps: 1.0})
Step:   60900, Reward: [-567.884 -567.884 -567.884] [121.144], Avg: [-499.522 -499.522 -499.522] (1.0000) ({r_i: None, r_t: [-1086.504 -1086.504 -1086.504], eps: 1.0})
Step:   61000, Reward: [-572.977 -572.977 -572.977] [72.882], Avg: [-499.643 -499.643 -499.643] (1.0000) ({r_i: None, r_t: [-1047.890 -1047.890 -1047.890], eps: 1.0})
Step:   61100, Reward: [-537.083 -537.083 -537.083] [75.285], Avg: [-499.704 -499.704 -499.704] (1.0000) ({r_i: None, r_t: [-887.005 -887.005 -887.005], eps: 1.0})
Step:   61200, Reward: [-384.430 -384.430 -384.430] [35.531], Avg: [-499.516 -499.516 -499.516] (1.0000) ({r_i: None, r_t: [-1019.666 -1019.666 -1019.666], eps: 1.0})
Step:   61300, Reward: [-456.421 -456.421 -456.421] [39.737], Avg: [-499.446 -499.446 -499.446] (1.0000) ({r_i: None, r_t: [-1040.493 -1040.493 -1040.493], eps: 1.0})
Step:   61400, Reward: [-504.417 -504.417 -504.417] [144.911], Avg: [-499.454 -499.454 -499.454] (1.0000) ({r_i: None, r_t: [-1009.932 -1009.932 -1009.932], eps: 1.0})
Step:   61500, Reward: [-531.259 -531.259 -531.259] [91.006], Avg: [-499.505 -499.505 -499.505] (1.0000) ({r_i: None, r_t: [-967.451 -967.451 -967.451], eps: 1.0})
Step:   61600, Reward: [-514.660 -514.660 -514.660] [91.089], Avg: [-499.530 -499.530 -499.530] (1.0000) ({r_i: None, r_t: [-996.437 -996.437 -996.437], eps: 1.0})
Step:   61700, Reward: [-492.653 -492.653 -492.653] [89.363], Avg: [-499.519 -499.519 -499.519] (1.0000) ({r_i: None, r_t: [-989.487 -989.487 -989.487], eps: 1.0})
Step:   61800, Reward: [-471.462 -471.462 -471.462] [79.949], Avg: [-499.473 -499.473 -499.473] (1.0000) ({r_i: None, r_t: [-892.817 -892.817 -892.817], eps: 1.0})
Step:   61900, Reward: [-431.076 -431.076 -431.076] [51.490], Avg: [-499.363 -499.363 -499.363] (1.0000) ({r_i: None, r_t: [-876.629 -876.629 -876.629], eps: 1.0})
Step:   62000, Reward: [-432.433 -432.433 -432.433] [36.164], Avg: [-499.255 -499.255 -499.255] (1.0000) ({r_i: None, r_t: [-1034.495 -1034.495 -1034.495], eps: 1.0})
Step:   62100, Reward: [-441.179 -441.179 -441.179] [60.737], Avg: [-499.162 -499.162 -499.162] (1.0000) ({r_i: None, r_t: [-987.365 -987.365 -987.365], eps: 1.0})
Step:   62200, Reward: [-482.680 -482.680 -482.680] [70.940], Avg: [-499.135 -499.135 -499.135] (1.0000) ({r_i: None, r_t: [-919.739 -919.739 -919.739], eps: 1.0})
Step:   62300, Reward: [-515.013 -515.013 -515.013] [78.042], Avg: [-499.161 -499.161 -499.161] (1.0000) ({r_i: None, r_t: [-997.374 -997.374 -997.374], eps: 1.0})
Step:   62400, Reward: [-415.122 -415.122 -415.122] [19.989], Avg: [-499.026 -499.026 -499.026] (1.0000) ({r_i: None, r_t: [-1018.539 -1018.539 -1018.539], eps: 1.0})
Step:   62500, Reward: [-463.886 -463.886 -463.886] [55.330], Avg: [-498.970 -498.970 -498.970] (1.0000) ({r_i: None, r_t: [-1057.798 -1057.798 -1057.798], eps: 1.0})
Step:   62600, Reward: [-537.093 -537.093 -537.093] [93.866], Avg: [-499.031 -499.031 -499.031] (1.0000) ({r_i: None, r_t: [-1068.106 -1068.106 -1068.106], eps: 1.0})
Step:   62700, Reward: [-541.886 -541.886 -541.886] [69.922], Avg: [-499.099 -499.099 -499.099] (1.0000) ({r_i: None, r_t: [-975.463 -975.463 -975.463], eps: 1.0})
Step:   62800, Reward: [-490.473 -490.473 -490.473] [98.376], Avg: [-499.086 -499.086 -499.086] (1.0000) ({r_i: None, r_t: [-894.077 -894.077 -894.077], eps: 1.0})
Step:   62900, Reward: [-451.158 -451.158 -451.158] [36.380], Avg: [-499.010 -499.010 -499.010] (1.0000) ({r_i: None, r_t: [-1016.078 -1016.078 -1016.078], eps: 1.0})
Step:   63000, Reward: [-580.296 -580.296 -580.296] [80.409], Avg: [-499.138 -499.138 -499.138] (1.0000) ({r_i: None, r_t: [-1034.239 -1034.239 -1034.239], eps: 1.0})
Step:   63100, Reward: [-480.311 -480.311 -480.311] [92.260], Avg: [-499.109 -499.109 -499.109] (1.0000) ({r_i: None, r_t: [-962.022 -962.022 -962.022], eps: 1.0})
Step:   63200, Reward: [-528.621 -528.621 -528.621] [80.714], Avg: [-499.155 -499.155 -499.155] (1.0000) ({r_i: None, r_t: [-1021.186 -1021.186 -1021.186], eps: 1.0})
Step:   63300, Reward: [-569.636 -569.636 -569.636] [129.531], Avg: [-499.266 -499.266 -499.266] (1.0000) ({r_i: None, r_t: [-905.745 -905.745 -905.745], eps: 1.0})
Step:   63400, Reward: [-442.203 -442.203 -442.203] [28.114], Avg: [-499.177 -499.177 -499.177] (1.0000) ({r_i: None, r_t: [-1000.801 -1000.801 -1000.801], eps: 1.0})
Step:   63500, Reward: [-486.360 -486.360 -486.360] [57.129], Avg: [-499.156 -499.156 -499.156] (1.0000) ({r_i: None, r_t: [-1011.035 -1011.035 -1011.035], eps: 1.0})
Step:   63600, Reward: [-427.071 -427.071 -427.071] [52.009], Avg: [-499.043 -499.043 -499.043] (1.0000) ({r_i: None, r_t: [-1108.104 -1108.104 -1108.104], eps: 1.0})
Step:   63700, Reward: [-464.260 -464.260 -464.260] [76.180], Avg: [-498.989 -498.989 -498.989] (1.0000) ({r_i: None, r_t: [-929.277 -929.277 -929.277], eps: 1.0})
Step:   63800, Reward: [-385.089 -385.089 -385.089] [48.976], Avg: [-498.810 -498.810 -498.810] (1.0000) ({r_i: None, r_t: [-1054.288 -1054.288 -1054.288], eps: 1.0})
Step:   63900, Reward: [-512.734 -512.734 -512.734] [98.418], Avg: [-498.832 -498.832 -498.832] (1.0000) ({r_i: None, r_t: [-973.299 -973.299 -973.299], eps: 1.0})
Step:   64000, Reward: [-460.932 -460.932 -460.932] [83.607], Avg: [-498.773 -498.773 -498.773] (1.0000) ({r_i: None, r_t: [-1071.982 -1071.982 -1071.982], eps: 1.0})
Step:   64100, Reward: [-534.795 -534.795 -534.795] [85.810], Avg: [-498.829 -498.829 -498.829] (1.0000) ({r_i: None, r_t: [-1065.978 -1065.978 -1065.978], eps: 1.0})
Step:   64200, Reward: [-463.351 -463.351 -463.351] [127.712], Avg: [-498.774 -498.774 -498.774] (1.0000) ({r_i: None, r_t: [-1079.392 -1079.392 -1079.392], eps: 1.0})
Step:   64300, Reward: [-549.409 -549.409 -549.409] [160.473], Avg: [-498.853 -498.853 -498.853] (1.0000) ({r_i: None, r_t: [-929.320 -929.320 -929.320], eps: 1.0})
Step:   64400, Reward: [-492.571 -492.571 -492.571] [32.418], Avg: [-498.843 -498.843 -498.843] (1.0000) ({r_i: None, r_t: [-929.745 -929.745 -929.745], eps: 1.0})
Step:   64500, Reward: [-431.354 -431.354 -431.354] [34.953], Avg: [-498.738 -498.738 -498.738] (1.0000) ({r_i: None, r_t: [-919.911 -919.911 -919.911], eps: 1.0})
Step:   64600, Reward: [-530.566 -530.566 -530.566] [99.107], Avg: [-498.788 -498.788 -498.788] (1.0000) ({r_i: None, r_t: [-1013.252 -1013.252 -1013.252], eps: 1.0})
Step:   64700, Reward: [-452.094 -452.094 -452.094] [90.122], Avg: [-498.716 -498.716 -498.716] (1.0000) ({r_i: None, r_t: [-976.971 -976.971 -976.971], eps: 1.0})
Step:   64800, Reward: [-504.088 -504.088 -504.088] [49.799], Avg: [-498.724 -498.724 -498.724] (1.0000) ({r_i: None, r_t: [-921.001 -921.001 -921.001], eps: 1.0})
Step:   64900, Reward: [-475.769 -475.769 -475.769] [64.682], Avg: [-498.689 -498.689 -498.689] (1.0000) ({r_i: None, r_t: [-1042.557 -1042.557 -1042.557], eps: 1.0})
Step:   65000, Reward: [-542.081 -542.081 -542.081] [114.341], Avg: [-498.755 -498.755 -498.755] (1.0000) ({r_i: None, r_t: [-937.317 -937.317 -937.317], eps: 1.0})
Step:   65100, Reward: [-522.172 -522.172 -522.172] [96.076], Avg: [-498.791 -498.791 -498.791] (1.0000) ({r_i: None, r_t: [-1163.131 -1163.131 -1163.131], eps: 1.0})
Step:   65200, Reward: [-593.733 -593.733 -593.733] [226.222], Avg: [-498.937 -498.937 -498.937] (1.0000) ({r_i: None, r_t: [-1027.674 -1027.674 -1027.674], eps: 1.0})
Step:   65300, Reward: [-451.548 -451.548 -451.548] [80.788], Avg: [-498.864 -498.864 -498.864] (1.0000) ({r_i: None, r_t: [-988.466 -988.466 -988.466], eps: 1.0})
Step:   65400, Reward: [-439.614 -439.614 -439.614] [20.620], Avg: [-498.774 -498.774 -498.774] (1.0000) ({r_i: None, r_t: [-1022.534 -1022.534 -1022.534], eps: 1.0})
Step:   65500, Reward: [-501.489 -501.489 -501.489] [77.993], Avg: [-498.778 -498.778 -498.778] (1.0000) ({r_i: None, r_t: [-946.662 -946.662 -946.662], eps: 1.0})
Step:   65600, Reward: [-606.428 -606.428 -606.428] [86.492], Avg: [-498.942 -498.942 -498.942] (1.0000) ({r_i: None, r_t: [-961.990 -961.990 -961.990], eps: 1.0})
Step:   65700, Reward: [-464.831 -464.831 -464.831] [56.982], Avg: [-498.890 -498.890 -498.890] (1.0000) ({r_i: None, r_t: [-978.547 -978.547 -978.547], eps: 1.0})
Step:   65800, Reward: [-563.727 -563.727 -563.727] [83.170], Avg: [-498.988 -498.988 -498.988] (1.0000) ({r_i: None, r_t: [-1118.627 -1118.627 -1118.627], eps: 1.0})
Step:   65900, Reward: [-480.852 -480.852 -480.852] [89.860], Avg: [-498.961 -498.961 -498.961] (1.0000) ({r_i: None, r_t: [-917.955 -917.955 -917.955], eps: 1.0})
Step:   66000, Reward: [-515.965 -515.965 -515.965] [66.952], Avg: [-498.986 -498.986 -498.986] (1.0000) ({r_i: None, r_t: [-969.044 -969.044 -969.044], eps: 1.0})
Step:   66100, Reward: [-443.022 -443.022 -443.022] [44.514], Avg: [-498.902 -498.902 -498.902] (1.0000) ({r_i: None, r_t: [-993.690 -993.690 -993.690], eps: 1.0})
Step:   66200, Reward: [-583.097 -583.097 -583.097] [110.987], Avg: [-499.029 -499.029 -499.029] (1.0000) ({r_i: None, r_t: [-880.024 -880.024 -880.024], eps: 1.0})
Step:   66300, Reward: [-480.129 -480.129 -480.129] [56.094], Avg: [-499.000 -499.000 -499.000] (1.0000) ({r_i: None, r_t: [-1045.911 -1045.911 -1045.911], eps: 1.0})
Step:   66400, Reward: [-534.227 -534.227 -534.227] [102.031], Avg: [-499.053 -499.053 -499.053] (1.0000) ({r_i: None, r_t: [-954.938 -954.938 -954.938], eps: 1.0})
Step:   66500, Reward: [-443.004 -443.004 -443.004] [10.095], Avg: [-498.969 -498.969 -498.969] (1.0000) ({r_i: None, r_t: [-966.025 -966.025 -966.025], eps: 1.0})
Step:   66600, Reward: [-475.569 -475.569 -475.569] [48.996], Avg: [-498.934 -498.934 -498.934] (1.0000) ({r_i: None, r_t: [-949.288 -949.288 -949.288], eps: 1.0})
Step:   66700, Reward: [-511.700 -511.700 -511.700] [90.100], Avg: [-498.953 -498.953 -498.953] (1.0000) ({r_i: None, r_t: [-995.032 -995.032 -995.032], eps: 1.0})
Step:   66800, Reward: [-450.301 -450.301 -450.301] [34.221], Avg: [-498.880 -498.880 -498.880] (1.0000) ({r_i: None, r_t: [-970.355 -970.355 -970.355], eps: 1.0})
Step:   66900, Reward: [-500.981 -500.981 -500.981] [73.708], Avg: [-498.884 -498.884 -498.884] (1.0000) ({r_i: None, r_t: [-981.805 -981.805 -981.805], eps: 1.0})
Step:   67000, Reward: [-554.931 -554.931 -554.931] [87.684], Avg: [-498.967 -498.967 -498.967] (1.0000) ({r_i: None, r_t: [-941.555 -941.555 -941.555], eps: 1.0})
Step:   67100, Reward: [-498.550 -498.550 -498.550] [106.591], Avg: [-498.967 -498.967 -498.967] (1.0000) ({r_i: None, r_t: [-989.014 -989.014 -989.014], eps: 1.0})
Step:   67200, Reward: [-525.413 -525.413 -525.413] [127.117], Avg: [-499.006 -499.006 -499.006] (1.0000) ({r_i: None, r_t: [-934.651 -934.651 -934.651], eps: 1.0})
Step:   67300, Reward: [-457.482 -457.482 -457.482] [21.935], Avg: [-498.944 -498.944 -498.944] (1.0000) ({r_i: None, r_t: [-1091.517 -1091.517 -1091.517], eps: 1.0})
Step:   67400, Reward: [-469.546 -469.546 -469.546] [45.788], Avg: [-498.901 -498.901 -498.901] (1.0000) ({r_i: None, r_t: [-1016.394 -1016.394 -1016.394], eps: 1.0})
Step:   67500, Reward: [-514.478 -514.478 -514.478] [69.221], Avg: [-498.924 -498.924 -498.924] (1.0000) ({r_i: None, r_t: [-987.643 -987.643 -987.643], eps: 1.0})
Step:   67600, Reward: [-460.991 -460.991 -460.991] [95.429], Avg: [-498.868 -498.868 -498.868] (1.0000) ({r_i: None, r_t: [-1071.539 -1071.539 -1071.539], eps: 1.0})
Step:   67700, Reward: [-500.687 -500.687 -500.687] [25.223], Avg: [-498.870 -498.870 -498.870] (1.0000) ({r_i: None, r_t: [-1047.030 -1047.030 -1047.030], eps: 1.0})
Step:   67800, Reward: [-497.393 -497.393 -497.393] [135.037], Avg: [-498.868 -498.868 -498.868] (1.0000) ({r_i: None, r_t: [-936.185 -936.185 -936.185], eps: 1.0})
Step:   67900, Reward: [-430.934 -430.934 -430.934] [35.700], Avg: [-498.768 -498.768 -498.768] (1.0000) ({r_i: None, r_t: [-949.072 -949.072 -949.072], eps: 1.0})
Step:   68000, Reward: [-494.504 -494.504 -494.504] [101.580], Avg: [-498.762 -498.762 -498.762] (1.0000) ({r_i: None, r_t: [-1041.738 -1041.738 -1041.738], eps: 1.0})
Step:   68100, Reward: [-492.320 -492.320 -492.320] [47.108], Avg: [-498.753 -498.753 -498.753] (1.0000) ({r_i: None, r_t: [-1038.472 -1038.472 -1038.472], eps: 1.0})
Step:   68200, Reward: [-423.432 -423.432 -423.432] [93.929], Avg: [-498.642 -498.642 -498.642] (1.0000) ({r_i: None, r_t: [-922.852 -922.852 -922.852], eps: 1.0})
Step:   68300, Reward: [-431.046 -431.046 -431.046] [43.853], Avg: [-498.543 -498.543 -498.543] (1.0000) ({r_i: None, r_t: [-1000.109 -1000.109 -1000.109], eps: 1.0})
Step:   68400, Reward: [-595.416 -595.416 -595.416] [89.111], Avg: [-498.685 -498.685 -498.685] (1.0000) ({r_i: None, r_t: [-926.314 -926.314 -926.314], eps: 1.0})
Step:   68500, Reward: [-524.920 -524.920 -524.920] [38.428], Avg: [-498.723 -498.723 -498.723] (1.0000) ({r_i: None, r_t: [-994.875 -994.875 -994.875], eps: 1.0})
Step:   68600, Reward: [-511.041 -511.041 -511.041] [65.605], Avg: [-498.741 -498.741 -498.741] (1.0000) ({r_i: None, r_t: [-933.935 -933.935 -933.935], eps: 1.0})
Step:   68700, Reward: [-447.082 -447.082 -447.082] [86.987], Avg: [-498.666 -498.666 -498.666] (1.0000) ({r_i: None, r_t: [-1063.067 -1063.067 -1063.067], eps: 1.0})
Step:   68800, Reward: [-450.085 -450.085 -450.085] [71.893], Avg: [-498.595 -498.595 -498.595] (1.0000) ({r_i: None, r_t: [-960.448 -960.448 -960.448], eps: 1.0})
Step:   68900, Reward: [-513.776 -513.776 -513.776] [76.149], Avg: [-498.617 -498.617 -498.617] (1.0000) ({r_i: None, r_t: [-941.865 -941.865 -941.865], eps: 1.0})
Step:   69000, Reward: [-491.406 -491.406 -491.406] [71.499], Avg: [-498.607 -498.607 -498.607] (1.0000) ({r_i: None, r_t: [-957.287 -957.287 -957.287], eps: 1.0})
Step:   69100, Reward: [-478.417 -478.417 -478.417] [98.796], Avg: [-498.578 -498.578 -498.578] (1.0000) ({r_i: None, r_t: [-1019.289 -1019.289 -1019.289], eps: 1.0})
Step:   69200, Reward: [-529.674 -529.674 -529.674] [21.940], Avg: [-498.623 -498.623 -498.623] (1.0000) ({r_i: None, r_t: [-988.511 -988.511 -988.511], eps: 1.0})
Step:   69300, Reward: [-466.367 -466.367 -466.367] [44.319], Avg: [-498.576 -498.576 -498.576] (1.0000) ({r_i: None, r_t: [-939.940 -939.940 -939.940], eps: 1.0})
Step:   69400, Reward: [-544.772 -544.772 -544.772] [62.103], Avg: [-498.643 -498.643 -498.643] (1.0000) ({r_i: None, r_t: [-1102.964 -1102.964 -1102.964], eps: 1.0})
Step:   69500, Reward: [-437.926 -437.926 -437.926] [70.971], Avg: [-498.555 -498.555 -498.555] (1.0000) ({r_i: None, r_t: [-969.109 -969.109 -969.109], eps: 1.0})
Step:   69600, Reward: [-450.145 -450.145 -450.145] [42.248], Avg: [-498.486 -498.486 -498.486] (1.0000) ({r_i: None, r_t: [-940.175 -940.175 -940.175], eps: 1.0})
Step:   69700, Reward: [-574.534 -574.534 -574.534] [107.365], Avg: [-498.595 -498.595 -498.595] (1.0000) ({r_i: None, r_t: [-940.212 -940.212 -940.212], eps: 1.0})
Step:   69800, Reward: [-514.480 -514.480 -514.480] [102.699], Avg: [-498.618 -498.618 -498.618] (1.0000) ({r_i: None, r_t: [-1040.269 -1040.269 -1040.269], eps: 1.0})
Step:   69900, Reward: [-565.761 -565.761 -565.761] [109.014], Avg: [-498.714 -498.714 -498.714] (1.0000) ({r_i: None, r_t: [-976.631 -976.631 -976.631], eps: 1.0})
Step:   70000, Reward: [-439.721 -439.721 -439.721] [82.055], Avg: [-498.629 -498.629 -498.629] (1.0000) ({r_i: None, r_t: [-1048.687 -1048.687 -1048.687], eps: 1.0})
Step:   70100, Reward: [-479.532 -479.532 -479.532] [39.009], Avg: [-498.602 -498.602 -498.602] (1.0000) ({r_i: None, r_t: [-1041.825 -1041.825 -1041.825], eps: 1.0})
Step:   70200, Reward: [-531.130 -531.130 -531.130] [65.229], Avg: [-498.649 -498.649 -498.649] (1.0000) ({r_i: None, r_t: [-951.850 -951.850 -951.850], eps: 1.0})
Step:   70300, Reward: [-487.462 -487.462 -487.462] [55.248], Avg: [-498.633 -498.633 -498.633] (1.0000) ({r_i: None, r_t: [-1116.594 -1116.594 -1116.594], eps: 1.0})
Step:   70400, Reward: [-504.134 -504.134 -504.134] [98.217], Avg: [-498.640 -498.640 -498.640] (1.0000) ({r_i: None, r_t: [-965.073 -965.073 -965.073], eps: 1.0})
Step:   70500, Reward: [-514.942 -514.942 -514.942] [77.936], Avg: [-498.664 -498.664 -498.664] (1.0000) ({r_i: None, r_t: [-1029.665 -1029.665 -1029.665], eps: 1.0})
Step:   70600, Reward: [-504.925 -504.925 -504.925] [59.782], Avg: [-498.672 -498.672 -498.672] (1.0000) ({r_i: None, r_t: [-905.468 -905.468 -905.468], eps: 1.0})
Step:   70700, Reward: [-482.002 -482.002 -482.002] [94.271], Avg: [-498.649 -498.649 -498.649] (1.0000) ({r_i: None, r_t: [-941.665 -941.665 -941.665], eps: 1.0})
Step:   70800, Reward: [-473.240 -473.240 -473.240] [24.475], Avg: [-498.613 -498.613 -498.613] (1.0000) ({r_i: None, r_t: [-993.513 -993.513 -993.513], eps: 1.0})
Step:   70900, Reward: [-445.446 -445.446 -445.446] [83.850], Avg: [-498.538 -498.538 -498.538] (1.0000) ({r_i: None, r_t: [-927.818 -927.818 -927.818], eps: 1.0})
Step:   71000, Reward: [-553.243 -553.243 -553.243] [109.375], Avg: [-498.615 -498.615 -498.615] (1.0000) ({r_i: None, r_t: [-842.873 -842.873 -842.873], eps: 1.0})
Step:   71100, Reward: [-520.644 -520.644 -520.644] [52.729], Avg: [-498.646 -498.646 -498.646] (1.0000) ({r_i: None, r_t: [-1101.536 -1101.536 -1101.536], eps: 1.0})
Step:   71200, Reward: [-483.670 -483.670 -483.670] [91.233], Avg: [-498.625 -498.625 -498.625] (1.0000) ({r_i: None, r_t: [-980.835 -980.835 -980.835], eps: 1.0})
Step:   71300, Reward: [-477.745 -477.745 -477.745] [43.086], Avg: [-498.596 -498.596 -498.596] (1.0000) ({r_i: None, r_t: [-1085.338 -1085.338 -1085.338], eps: 1.0})
Step:   71400, Reward: [-569.597 -569.597 -569.597] [136.175], Avg: [-498.695 -498.695 -498.695] (1.0000) ({r_i: None, r_t: [-947.672 -947.672 -947.672], eps: 1.0})
Step:   71500, Reward: [-456.523 -456.523 -456.523] [83.211], Avg: [-498.636 -498.636 -498.636] (1.0000) ({r_i: None, r_t: [-976.642 -976.642 -976.642], eps: 1.0})
Step:   71600, Reward: [-571.898 -571.898 -571.898] [137.681], Avg: [-498.738 -498.738 -498.738] (1.0000) ({r_i: None, r_t: [-909.259 -909.259 -909.259], eps: 1.0})
Step:   71700, Reward: [-502.218 -502.218 -502.218] [61.671], Avg: [-498.743 -498.743 -498.743] (1.0000) ({r_i: None, r_t: [-818.653 -818.653 -818.653], eps: 1.0})
Step:   71800, Reward: [-481.682 -481.682 -481.682] [74.348], Avg: [-498.719 -498.719 -498.719] (1.0000) ({r_i: None, r_t: [-887.008 -887.008 -887.008], eps: 1.0})
Step:   71900, Reward: [-532.500 -532.500 -532.500] [119.160], Avg: [-498.766 -498.766 -498.766] (1.0000) ({r_i: None, r_t: [-1036.060 -1036.060 -1036.060], eps: 1.0})
Step:   72000, Reward: [-495.141 -495.141 -495.141] [70.016], Avg: [-498.761 -498.761 -498.761] (1.0000) ({r_i: None, r_t: [-855.024 -855.024 -855.024], eps: 1.0})
Step:   72100, Reward: [-433.507 -433.507 -433.507] [80.962], Avg: [-498.671 -498.671 -498.671] (1.0000) ({r_i: None, r_t: [-915.838 -915.838 -915.838], eps: 1.0})
Step:   72200, Reward: [-461.852 -461.852 -461.852] [100.392], Avg: [-498.620 -498.620 -498.620] (1.0000) ({r_i: None, r_t: [-999.815 -999.815 -999.815], eps: 1.0})
Step:   72300, Reward: [-515.677 -515.677 -515.677] [97.977], Avg: [-498.644 -498.644 -498.644] (1.0000) ({r_i: None, r_t: [-954.401 -954.401 -954.401], eps: 1.0})
Step:   72400, Reward: [-415.631 -415.631 -415.631] [29.772], Avg: [-498.529 -498.529 -498.529] (1.0000) ({r_i: None, r_t: [-996.538 -996.538 -996.538], eps: 1.0})
Step:   72500, Reward: [-486.626 -486.626 -486.626] [69.810], Avg: [-498.513 -498.513 -498.513] (1.0000) ({r_i: None, r_t: [-1032.356 -1032.356 -1032.356], eps: 1.0})
Step:   72600, Reward: [-527.477 -527.477 -527.477] [95.173], Avg: [-498.553 -498.553 -498.553] (1.0000) ({r_i: None, r_t: [-939.873 -939.873 -939.873], eps: 1.0})
Step:   72700, Reward: [-469.349 -469.349 -469.349] [31.876], Avg: [-498.512 -498.512 -498.512] (1.0000) ({r_i: None, r_t: [-1066.536 -1066.536 -1066.536], eps: 1.0})
Step:   72800, Reward: [-429.137 -429.137 -429.137] [58.796], Avg: [-498.417 -498.417 -498.417] (1.0000) ({r_i: None, r_t: [-1058.388 -1058.388 -1058.388], eps: 1.0})
Step:   72900, Reward: [-463.986 -463.986 -463.986] [71.667], Avg: [-498.370 -498.370 -498.370] (1.0000) ({r_i: None, r_t: [-982.012 -982.012 -982.012], eps: 1.0})
Step:   73000, Reward: [-506.433 -506.433 -506.433] [89.726], Avg: [-498.381 -498.381 -498.381] (1.0000) ({r_i: None, r_t: [-851.842 -851.842 -851.842], eps: 1.0})
Step:   73100, Reward: [-502.711 -502.711 -502.711] [86.029], Avg: [-498.387 -498.387 -498.387] (1.0000) ({r_i: None, r_t: [-996.592 -996.592 -996.592], eps: 1.0})
Step:   73200, Reward: [-452.541 -452.541 -452.541] [86.432], Avg: [-498.324 -498.324 -498.324] (1.0000) ({r_i: None, r_t: [-977.101 -977.101 -977.101], eps: 1.0})
Step:   73300, Reward: [-554.202 -554.202 -554.202] [165.386], Avg: [-498.401 -498.401 -498.401] (1.0000) ({r_i: None, r_t: [-989.216 -989.216 -989.216], eps: 1.0})
Step:   73400, Reward: [-506.957 -506.957 -506.957] [65.992], Avg: [-498.412 -498.412 -498.412] (1.0000) ({r_i: None, r_t: [-989.499 -989.499 -989.499], eps: 1.0})
Step:   73500, Reward: [-522.241 -522.241 -522.241] [90.921], Avg: [-498.445 -498.445 -498.445] (1.0000) ({r_i: None, r_t: [-1050.550 -1050.550 -1050.550], eps: 1.0})
Step:   73600, Reward: [-539.198 -539.198 -539.198] [47.273], Avg: [-498.500 -498.500 -498.500] (1.0000) ({r_i: None, r_t: [-899.657 -899.657 -899.657], eps: 1.0})
Step:   73700, Reward: [-457.247 -457.247 -457.247] [78.955], Avg: [-498.444 -498.444 -498.444] (1.0000) ({r_i: None, r_t: [-1043.621 -1043.621 -1043.621], eps: 1.0})
Step:   73800, Reward: [-517.149 -517.149 -517.149] [44.644], Avg: [-498.469 -498.469 -498.469] (1.0000) ({r_i: None, r_t: [-1036.321 -1036.321 -1036.321], eps: 1.0})
Step:   73900, Reward: [-451.765 -451.765 -451.765] [76.436], Avg: [-498.406 -498.406 -498.406] (1.0000) ({r_i: None, r_t: [-1020.095 -1020.095 -1020.095], eps: 1.0})
Step:   74000, Reward: [-465.293 -465.293 -465.293] [49.713], Avg: [-498.362 -498.362 -498.362] (1.0000) ({r_i: None, r_t: [-1039.330 -1039.330 -1039.330], eps: 1.0})
Step:   74100, Reward: [-514.107 -514.107 -514.107] [70.019], Avg: [-498.383 -498.383 -498.383] (1.0000) ({r_i: None, r_t: [-938.154 -938.154 -938.154], eps: 1.0})
Step:   74200, Reward: [-548.927 -548.927 -548.927] [62.734], Avg: [-498.451 -498.451 -498.451] (1.0000) ({r_i: None, r_t: [-1112.943 -1112.943 -1112.943], eps: 1.0})
Step:   74300, Reward: [-436.885 -436.885 -436.885] [12.945], Avg: [-498.368 -498.368 -498.368] (1.0000) ({r_i: None, r_t: [-1070.496 -1070.496 -1070.496], eps: 1.0})
Step:   74400, Reward: [-458.605 -458.605 -458.605] [24.644], Avg: [-498.315 -498.315 -498.315] (1.0000) ({r_i: None, r_t: [-1033.516 -1033.516 -1033.516], eps: 1.0})
Step:   74500, Reward: [-465.983 -465.983 -465.983] [37.610], Avg: [-498.271 -498.271 -498.271] (1.0000) ({r_i: None, r_t: [-948.137 -948.137 -948.137], eps: 1.0})
Step:   74600, Reward: [-500.737 -500.737 -500.737] [109.222], Avg: [-498.275 -498.275 -498.275] (1.0000) ({r_i: None, r_t: [-1077.160 -1077.160 -1077.160], eps: 1.0})
Step:   74700, Reward: [-538.233 -538.233 -538.233] [60.524], Avg: [-498.328 -498.328 -498.328] (1.0000) ({r_i: None, r_t: [-895.571 -895.571 -895.571], eps: 1.0})
Step:   74800, Reward: [-438.968 -438.968 -438.968] [30.058], Avg: [-498.249 -498.249 -498.249] (1.0000) ({r_i: None, r_t: [-977.528 -977.528 -977.528], eps: 1.0})
Step:   74900, Reward: [-536.609 -536.609 -536.609] [92.740], Avg: [-498.300 -498.300 -498.300] (1.0000) ({r_i: None, r_t: [-1021.420 -1021.420 -1021.420], eps: 1.0})
Step:   75000, Reward: [-524.542 -524.542 -524.542] [128.010], Avg: [-498.335 -498.335 -498.335] (1.0000) ({r_i: None, r_t: [-1027.552 -1027.552 -1027.552], eps: 1.0})
Step:   75100, Reward: [-468.639 -468.639 -468.639] [34.772], Avg: [-498.295 -498.295 -498.295] (1.0000) ({r_i: None, r_t: [-916.378 -916.378 -916.378], eps: 1.0})
Step:   75200, Reward: [-602.492 -602.492 -602.492] [97.540], Avg: [-498.434 -498.434 -498.434] (1.0000) ({r_i: None, r_t: [-1176.790 -1176.790 -1176.790], eps: 1.0})
Step:   75300, Reward: [-399.354 -399.354 -399.354] [35.360], Avg: [-498.302 -498.302 -498.302] (1.0000) ({r_i: None, r_t: [-1003.493 -1003.493 -1003.493], eps: 1.0})
Step:   75400, Reward: [-444.186 -444.186 -444.186] [60.947], Avg: [-498.231 -498.231 -498.231] (1.0000) ({r_i: None, r_t: [-944.577 -944.577 -944.577], eps: 1.0})
Step:   75500, Reward: [-533.280 -533.280 -533.280] [172.678], Avg: [-498.277 -498.277 -498.277] (1.0000) ({r_i: None, r_t: [-1098.732 -1098.732 -1098.732], eps: 1.0})
Step:   75600, Reward: [-527.267 -527.267 -527.267] [36.905], Avg: [-498.315 -498.315 -498.315] (1.0000) ({r_i: None, r_t: [-912.148 -912.148 -912.148], eps: 1.0})
Step:   75700, Reward: [-479.547 -479.547 -479.547] [86.799], Avg: [-498.291 -498.291 -498.291] (1.0000) ({r_i: None, r_t: [-994.685 -994.685 -994.685], eps: 1.0})
Step:   75800, Reward: [-525.896 -525.896 -525.896] [95.337], Avg: [-498.327 -498.327 -498.327] (1.0000) ({r_i: None, r_t: [-936.514 -936.514 -936.514], eps: 1.0})
Step:   75900, Reward: [-503.995 -503.995 -503.995] [58.077], Avg: [-498.334 -498.334 -498.334] (1.0000) ({r_i: None, r_t: [-969.442 -969.442 -969.442], eps: 1.0})
Step:   76000, Reward: [-475.588 -475.588 -475.588] [67.885], Avg: [-498.305 -498.305 -498.305] (1.0000) ({r_i: None, r_t: [-982.794 -982.794 -982.794], eps: 1.0})
Step:   76100, Reward: [-466.825 -466.825 -466.825] [61.589], Avg: [-498.263 -498.263 -498.263] (1.0000) ({r_i: None, r_t: [-1122.108 -1122.108 -1122.108], eps: 1.0})
Step:   76200, Reward: [-468.877 -468.877 -468.877] [57.061], Avg: [-498.225 -498.225 -498.225] (1.0000) ({r_i: None, r_t: [-1044.604 -1044.604 -1044.604], eps: 1.0})
Step:   76300, Reward: [-510.990 -510.990 -510.990] [56.567], Avg: [-498.241 -498.241 -498.241] (1.0000) ({r_i: None, r_t: [-966.402 -966.402 -966.402], eps: 1.0})
Step:   76400, Reward: [-414.723 -414.723 -414.723] [95.104], Avg: [-498.132 -498.132 -498.132] (1.0000) ({r_i: None, r_t: [-1011.822 -1011.822 -1011.822], eps: 1.0})
Step:   76500, Reward: [-520.167 -520.167 -520.167] [89.680], Avg: [-498.161 -498.161 -498.161] (1.0000) ({r_i: None, r_t: [-923.012 -923.012 -923.012], eps: 1.0})
Step:   76600, Reward: [-489.838 -489.838 -489.838] [63.428], Avg: [-498.150 -498.150 -498.150] (1.0000) ({r_i: None, r_t: [-923.424 -923.424 -923.424], eps: 1.0})
Step:   76700, Reward: [-451.288 -451.288 -451.288] [52.902], Avg: [-498.089 -498.089 -498.089] (1.0000) ({r_i: None, r_t: [-1037.331 -1037.331 -1037.331], eps: 1.0})
Step:   76800, Reward: [-479.913 -479.913 -479.913] [71.376], Avg: [-498.065 -498.065 -498.065] (1.0000) ({r_i: None, r_t: [-956.649 -956.649 -956.649], eps: 1.0})
Step:   76900, Reward: [-440.374 -440.374 -440.374] [41.909], Avg: [-497.991 -497.991 -497.991] (1.0000) ({r_i: None, r_t: [-949.916 -949.916 -949.916], eps: 1.0})
Step:   77000, Reward: [-488.766 -488.766 -488.766] [36.674], Avg: [-497.979 -497.979 -497.979] (1.0000) ({r_i: None, r_t: [-943.804 -943.804 -943.804], eps: 1.0})
Step:   77100, Reward: [-555.491 -555.491 -555.491] [113.820], Avg: [-498.053 -498.053 -498.053] (1.0000) ({r_i: None, r_t: [-944.846 -944.846 -944.846], eps: 1.0})
Step:   77200, Reward: [-505.492 -505.492 -505.492] [94.329], Avg: [-498.063 -498.063 -498.063] (1.0000) ({r_i: None, r_t: [-950.158 -950.158 -950.158], eps: 1.0})
Step:   77300, Reward: [-578.010 -578.010 -578.010] [147.253], Avg: [-498.166 -498.166 -498.166] (1.0000) ({r_i: None, r_t: [-988.367 -988.367 -988.367], eps: 1.0})
Step:   77400, Reward: [-459.478 -459.478 -459.478] [36.513], Avg: [-498.116 -498.116 -498.116] (1.0000) ({r_i: None, r_t: [-1017.945 -1017.945 -1017.945], eps: 1.0})
Step:   77500, Reward: [-489.501 -489.501 -489.501] [18.620], Avg: [-498.105 -498.105 -498.105] (1.0000) ({r_i: None, r_t: [-975.014 -975.014 -975.014], eps: 1.0})
Step:   77600, Reward: [-476.224 -476.224 -476.224] [58.647], Avg: [-498.077 -498.077 -498.077] (1.0000) ({r_i: None, r_t: [-986.279 -986.279 -986.279], eps: 1.0})
Step:   77700, Reward: [-426.612 -426.612 -426.612] [36.891], Avg: [-497.985 -497.985 -497.985] (1.0000) ({r_i: None, r_t: [-1064.144 -1064.144 -1064.144], eps: 1.0})
Step:   77800, Reward: [-499.203 -499.203 -499.203] [32.482], Avg: [-497.987 -497.987 -497.987] (1.0000) ({r_i: None, r_t: [-1051.022 -1051.022 -1051.022], eps: 1.0})
Step:   77900, Reward: [-452.906 -452.906 -452.906] [89.309], Avg: [-497.929 -497.929 -497.929] (1.0000) ({r_i: None, r_t: [-987.247 -987.247 -987.247], eps: 1.0})
Step:   78000, Reward: [-560.054 -560.054 -560.054] [111.012], Avg: [-498.008 -498.008 -498.008] (1.0000) ({r_i: None, r_t: [-1069.414 -1069.414 -1069.414], eps: 1.0})
Step:   78100, Reward: [-594.403 -594.403 -594.403] [163.210], Avg: [-498.132 -498.132 -498.132] (1.0000) ({r_i: None, r_t: [-928.160 -928.160 -928.160], eps: 1.0})
Step:   78200, Reward: [-594.931 -594.931 -594.931] [155.347], Avg: [-498.255 -498.255 -498.255] (1.0000) ({r_i: None, r_t: [-938.668 -938.668 -938.668], eps: 1.0})
Step:   78300, Reward: [-471.195 -471.195 -471.195] [95.390], Avg: [-498.221 -498.221 -498.221] (1.0000) ({r_i: None, r_t: [-894.809 -894.809 -894.809], eps: 1.0})
Step:   78400, Reward: [-523.672 -523.672 -523.672] [67.889], Avg: [-498.253 -498.253 -498.253] (1.0000) ({r_i: None, r_t: [-1048.845 -1048.845 -1048.845], eps: 1.0})
Step:   78500, Reward: [-486.469 -486.469 -486.469] [111.277], Avg: [-498.238 -498.238 -498.238] (1.0000) ({r_i: None, r_t: [-1051.438 -1051.438 -1051.438], eps: 1.0})
Step:   78600, Reward: [-584.362 -584.362 -584.362] [77.345], Avg: [-498.348 -498.348 -498.348] (1.0000) ({r_i: None, r_t: [-843.185 -843.185 -843.185], eps: 1.0})
Step:   78700, Reward: [-382.569 -382.569 -382.569] [28.036], Avg: [-498.201 -498.201 -498.201] (1.0000) ({r_i: None, r_t: [-888.730 -888.730 -888.730], eps: 1.0})
Step:   78800, Reward: [-469.241 -469.241 -469.241] [67.004], Avg: [-498.164 -498.164 -498.164] (1.0000) ({r_i: None, r_t: [-1057.224 -1057.224 -1057.224], eps: 1.0})
Step:   78900, Reward: [-465.361 -465.361 -465.361] [112.809], Avg: [-498.122 -498.122 -498.122] (1.0000) ({r_i: None, r_t: [-984.113 -984.113 -984.113], eps: 1.0})
Step:   79000, Reward: [-436.438 -436.438 -436.438] [61.558], Avg: [-498.044 -498.044 -498.044] (1.0000) ({r_i: None, r_t: [-1098.195 -1098.195 -1098.195], eps: 1.0})
Step:   79100, Reward: [-491.871 -491.871 -491.871] [96.807], Avg: [-498.037 -498.037 -498.037] (1.0000) ({r_i: None, r_t: [-1068.563 -1068.563 -1068.563], eps: 1.0})
Step:   79200, Reward: [-562.639 -562.639 -562.639] [131.668], Avg: [-498.118 -498.118 -498.118] (1.0000) ({r_i: None, r_t: [-862.396 -862.396 -862.396], eps: 1.0})
Step:   79300, Reward: [-486.235 -486.235 -486.235] [104.803], Avg: [-498.103 -498.103 -498.103] (1.0000) ({r_i: None, r_t: [-968.779 -968.779 -968.779], eps: 1.0})
Step:   79400, Reward: [-479.363 -479.363 -479.363] [65.389], Avg: [-498.080 -498.080 -498.080] (1.0000) ({r_i: None, r_t: [-977.491 -977.491 -977.491], eps: 1.0})
Step:   79500, Reward: [-496.681 -496.681 -496.681] [77.382], Avg: [-498.078 -498.078 -498.078] (1.0000) ({r_i: None, r_t: [-950.599 -950.599 -950.599], eps: 1.0})
Step:   79600, Reward: [-429.294 -429.294 -429.294] [38.837], Avg: [-497.991 -497.991 -497.991] (1.0000) ({r_i: None, r_t: [-1084.870 -1084.870 -1084.870], eps: 1.0})
Step:   79700, Reward: [-428.516 -428.516 -428.516] [42.103], Avg: [-497.904 -497.904 -497.904] (1.0000) ({r_i: None, r_t: [-1042.357 -1042.357 -1042.357], eps: 1.0})
Step:   79800, Reward: [-565.879 -565.879 -565.879] [171.077], Avg: [-497.989 -497.989 -497.989] (1.0000) ({r_i: None, r_t: [-828.609 -828.609 -828.609], eps: 1.0})
Step:   79900, Reward: [-520.999 -520.999 -520.999] [20.962], Avg: [-498.018 -498.018 -498.018] (1.0000) ({r_i: None, r_t: [-1046.198 -1046.198 -1046.198], eps: 1.0})
Step:   80000, Reward: [-558.880 -558.880 -558.880] [58.354], Avg: [-498.094 -498.094 -498.094] (1.0000) ({r_i: None, r_t: [-929.421 -929.421 -929.421], eps: 1.0})
Step:   80100, Reward: [-430.337 -430.337 -430.337] [33.074], Avg: [-498.010 -498.010 -498.010] (1.0000) ({r_i: None, r_t: [-1035.495 -1035.495 -1035.495], eps: 1.0})
Step:   80200, Reward: [-482.773 -482.773 -482.773] [101.634], Avg: [-497.991 -497.991 -497.991] (1.0000) ({r_i: None, r_t: [-968.286 -968.286 -968.286], eps: 1.0})
Step:   80300, Reward: [-578.474 -578.474 -578.474] [138.852], Avg: [-498.091 -498.091 -498.091] (1.0000) ({r_i: None, r_t: [-974.126 -974.126 -974.126], eps: 1.0})
Step:   80400, Reward: [-470.418 -470.418 -470.418] [34.863], Avg: [-498.056 -498.056 -498.056] (1.0000) ({r_i: None, r_t: [-1036.600 -1036.600 -1036.600], eps: 1.0})
Step:   80500, Reward: [-459.839 -459.839 -459.839] [21.733], Avg: [-498.009 -498.009 -498.009] (1.0000) ({r_i: None, r_t: [-1030.369 -1030.369 -1030.369], eps: 1.0})
Step:   80600, Reward: [-549.969 -549.969 -549.969] [139.492], Avg: [-498.073 -498.073 -498.073] (1.0000) ({r_i: None, r_t: [-1010.221 -1010.221 -1010.221], eps: 1.0})
Step:   80700, Reward: [-462.895 -462.895 -462.895] [17.619], Avg: [-498.030 -498.030 -498.030] (1.0000) ({r_i: None, r_t: [-992.767 -992.767 -992.767], eps: 1.0})
Step:   80800, Reward: [-461.405 -461.405 -461.405] [55.896], Avg: [-497.985 -497.985 -497.985] (1.0000) ({r_i: None, r_t: [-1024.333 -1024.333 -1024.333], eps: 1.0})
Step:   80900, Reward: [-459.426 -459.426 -459.426] [47.528], Avg: [-497.937 -497.937 -497.937] (1.0000) ({r_i: None, r_t: [-1071.474 -1071.474 -1071.474], eps: 1.0})
Step:   81000, Reward: [-487.581 -487.581 -487.581] [149.154], Avg: [-497.924 -497.924 -497.924] (1.0000) ({r_i: None, r_t: [-913.810 -913.810 -913.810], eps: 1.0})
Step:   81100, Reward: [-449.394 -449.394 -449.394] [57.877], Avg: [-497.865 -497.865 -497.865] (1.0000) ({r_i: None, r_t: [-926.513 -926.513 -926.513], eps: 1.0})
Step:   81200, Reward: [-441.906 -441.906 -441.906] [48.000], Avg: [-497.796 -497.796 -497.796] (1.0000) ({r_i: None, r_t: [-1026.168 -1026.168 -1026.168], eps: 1.0})
Step:   81300, Reward: [-601.945 -601.945 -601.945] [108.525], Avg: [-497.924 -497.924 -497.924] (1.0000) ({r_i: None, r_t: [-1002.666 -1002.666 -1002.666], eps: 1.0})
Step:   81400, Reward: [-576.802 -576.802 -576.802] [105.438], Avg: [-498.020 -498.020 -498.020] (1.0000) ({r_i: None, r_t: [-1074.953 -1074.953 -1074.953], eps: 1.0})
Step:   81500, Reward: [-472.690 -472.690 -472.690] [120.004], Avg: [-497.989 -497.989 -497.989] (1.0000) ({r_i: None, r_t: [-900.195 -900.195 -900.195], eps: 1.0})
Step:   81600, Reward: [-492.400 -492.400 -492.400] [83.590], Avg: [-497.983 -497.983 -497.983] (1.0000) ({r_i: None, r_t: [-912.318 -912.318 -912.318], eps: 1.0})
Step:   81700, Reward: [-558.809 -558.809 -558.809] [55.742], Avg: [-498.057 -498.057 -498.057] (1.0000) ({r_i: None, r_t: [-1113.056 -1113.056 -1113.056], eps: 1.0})
Step:   81800, Reward: [-426.316 -426.316 -426.316] [27.695], Avg: [-497.969 -497.969 -497.969] (1.0000) ({r_i: None, r_t: [-1007.367 -1007.367 -1007.367], eps: 1.0})
Step:   81900, Reward: [-435.108 -435.108 -435.108] [29.812], Avg: [-497.893 -497.893 -497.893] (1.0000) ({r_i: None, r_t: [-982.649 -982.649 -982.649], eps: 1.0})
Step:   82000, Reward: [-453.424 -453.424 -453.424] [107.912], Avg: [-497.838 -497.838 -497.838] (1.0000) ({r_i: None, r_t: [-980.937 -980.937 -980.937], eps: 1.0})
Step:   82100, Reward: [-455.708 -455.708 -455.708] [39.667], Avg: [-497.787 -497.787 -497.787] (1.0000) ({r_i: None, r_t: [-1003.979 -1003.979 -1003.979], eps: 1.0})
Step:   82200, Reward: [-427.625 -427.625 -427.625] [50.672], Avg: [-497.702 -497.702 -497.702] (1.0000) ({r_i: None, r_t: [-989.466 -989.466 -989.466], eps: 1.0})
Step:   82300, Reward: [-420.865 -420.865 -420.865] [98.849], Avg: [-497.609 -497.609 -497.609] (1.0000) ({r_i: None, r_t: [-973.564 -973.564 -973.564], eps: 1.0})
Step:   82400, Reward: [-592.924 -592.924 -592.924] [66.869], Avg: [-497.724 -497.724 -497.724] (1.0000) ({r_i: None, r_t: [-1156.559 -1156.559 -1156.559], eps: 1.0})
Step:   82500, Reward: [-540.689 -540.689 -540.689] [55.672], Avg: [-497.776 -497.776 -497.776] (1.0000) ({r_i: None, r_t: [-1054.913 -1054.913 -1054.913], eps: 1.0})
Step:   82600, Reward: [-488.914 -488.914 -488.914] [60.263], Avg: [-497.766 -497.766 -497.766] (1.0000) ({r_i: None, r_t: [-1009.129 -1009.129 -1009.129], eps: 1.0})
Step:   82700, Reward: [-391.216 -391.216 -391.216] [48.430], Avg: [-497.637 -497.637 -497.637] (1.0000) ({r_i: None, r_t: [-1167.510 -1167.510 -1167.510], eps: 1.0})
Step:   82800, Reward: [-462.624 -462.624 -462.624] [101.257], Avg: [-497.595 -497.595 -497.595] (1.0000) ({r_i: None, r_t: [-1059.395 -1059.395 -1059.395], eps: 1.0})
Step:   82900, Reward: [-474.298 -474.298 -474.298] [92.398], Avg: [-497.567 -497.567 -497.567] (1.0000) ({r_i: None, r_t: [-935.537 -935.537 -935.537], eps: 1.0})
Step:   83000, Reward: [-521.291 -521.291 -521.291] [100.248], Avg: [-497.595 -497.595 -497.595] (1.0000) ({r_i: None, r_t: [-961.757 -961.757 -961.757], eps: 1.0})
Step:   83100, Reward: [-521.039 -521.039 -521.039] [69.279], Avg: [-497.623 -497.623 -497.623] (1.0000) ({r_i: None, r_t: [-1007.407 -1007.407 -1007.407], eps: 1.0})
Step:   83200, Reward: [-502.060 -502.060 -502.060] [52.111], Avg: [-497.629 -497.629 -497.629] (1.0000) ({r_i: None, r_t: [-940.072 -940.072 -940.072], eps: 1.0})
Step:   83300, Reward: [-526.417 -526.417 -526.417] [65.884], Avg: [-497.663 -497.663 -497.663] (1.0000) ({r_i: None, r_t: [-1025.764 -1025.764 -1025.764], eps: 1.0})
Step:   83400, Reward: [-645.171 -645.171 -645.171] [90.105], Avg: [-497.840 -497.840 -497.840] (1.0000) ({r_i: None, r_t: [-913.620 -913.620 -913.620], eps: 1.0})
Step:   83500, Reward: [-467.325 -467.325 -467.325] [93.445], Avg: [-497.803 -497.803 -497.803] (1.0000) ({r_i: None, r_t: [-1011.551 -1011.551 -1011.551], eps: 1.0})
Step:   83600, Reward: [-563.241 -563.241 -563.241] [31.593], Avg: [-497.881 -497.881 -497.881] (1.0000) ({r_i: None, r_t: [-1006.407 -1006.407 -1006.407], eps: 1.0})
Step:   83700, Reward: [-551.116 -551.116 -551.116] [127.221], Avg: [-497.945 -497.945 -497.945] (1.0000) ({r_i: None, r_t: [-927.181 -927.181 -927.181], eps: 1.0})
Step:   83800, Reward: [-470.943 -470.943 -470.943] [65.633], Avg: [-497.913 -497.913 -497.913] (1.0000) ({r_i: None, r_t: [-960.433 -960.433 -960.433], eps: 1.0})
Step:   83900, Reward: [-493.174 -493.174 -493.174] [55.644], Avg: [-497.907 -497.907 -497.907] (1.0000) ({r_i: None, r_t: [-1070.328 -1070.328 -1070.328], eps: 1.0})
Step:   84000, Reward: [-444.980 -444.980 -444.980] [53.357], Avg: [-497.844 -497.844 -497.844] (1.0000) ({r_i: None, r_t: [-1081.836 -1081.836 -1081.836], eps: 1.0})
Step:   84100, Reward: [-539.457 -539.457 -539.457] [73.750], Avg: [-497.894 -497.894 -497.894] (1.0000) ({r_i: None, r_t: [-876.545 -876.545 -876.545], eps: 1.0})
Step:   84200, Reward: [-503.690 -503.690 -503.690] [20.245], Avg: [-497.901 -497.901 -497.901] (1.0000) ({r_i: None, r_t: [-1120.021 -1120.021 -1120.021], eps: 1.0})
Step:   84300, Reward: [-478.181 -478.181 -478.181] [48.133], Avg: [-497.877 -497.877 -497.877] (1.0000) ({r_i: None, r_t: [-1037.647 -1037.647 -1037.647], eps: 1.0})
Step:   84400, Reward: [-440.848 -440.848 -440.848] [15.806], Avg: [-497.810 -497.810 -497.810] (1.0000) ({r_i: None, r_t: [-1018.410 -1018.410 -1018.410], eps: 1.0})
Step:   84500, Reward: [-500.541 -500.541 -500.541] [65.902], Avg: [-497.813 -497.813 -497.813] (1.0000) ({r_i: None, r_t: [-1020.198 -1020.198 -1020.198], eps: 1.0})
Step:   84600, Reward: [-443.690 -443.690 -443.690] [89.440], Avg: [-497.749 -497.749 -497.749] (1.0000) ({r_i: None, r_t: [-1046.922 -1046.922 -1046.922], eps: 1.0})
Step:   84700, Reward: [-513.486 -513.486 -513.486] [60.109], Avg: [-497.768 -497.768 -497.768] (1.0000) ({r_i: None, r_t: [-1036.225 -1036.225 -1036.225], eps: 1.0})
Step:   84800, Reward: [-585.692 -585.692 -585.692] [55.328], Avg: [-497.871 -497.871 -497.871] (1.0000) ({r_i: None, r_t: [-1057.682 -1057.682 -1057.682], eps: 1.0})
Step:   84900, Reward: [-560.576 -560.576 -560.576] [143.847], Avg: [-497.945 -497.945 -497.945] (1.0000) ({r_i: None, r_t: [-920.783 -920.783 -920.783], eps: 1.0})
Step:   85000, Reward: [-474.532 -474.532 -474.532] [95.893], Avg: [-497.917 -497.917 -497.917] (1.0000) ({r_i: None, r_t: [-940.719 -940.719 -940.719], eps: 1.0})
Step:   85100, Reward: [-498.841 -498.841 -498.841] [23.259], Avg: [-497.918 -497.918 -497.918] (1.0000) ({r_i: None, r_t: [-829.059 -829.059 -829.059], eps: 1.0})
Step:   85200, Reward: [-435.626 -435.626 -435.626] [72.738], Avg: [-497.845 -497.845 -497.845] (1.0000) ({r_i: None, r_t: [-878.150 -878.150 -878.150], eps: 1.0})
Step:   85300, Reward: [-593.141 -593.141 -593.141] [79.840], Avg: [-497.957 -497.957 -497.957] (1.0000) ({r_i: None, r_t: [-1036.048 -1036.048 -1036.048], eps: 1.0})
Step:   85400, Reward: [-552.608 -552.608 -552.608] [49.299], Avg: [-498.021 -498.021 -498.021] (1.0000) ({r_i: None, r_t: [-1023.972 -1023.972 -1023.972], eps: 1.0})
Step:   85500, Reward: [-525.184 -525.184 -525.184] [111.359], Avg: [-498.053 -498.053 -498.053] (1.0000) ({r_i: None, r_t: [-1069.420 -1069.420 -1069.420], eps: 1.0})
Step:   85600, Reward: [-391.531 -391.531 -391.531] [10.234], Avg: [-497.928 -497.928 -497.928] (1.0000) ({r_i: None, r_t: [-985.566 -985.566 -985.566], eps: 1.0})
Step:   85700, Reward: [-507.602 -507.602 -507.602] [75.407], Avg: [-497.940 -497.940 -497.940] (1.0000) ({r_i: None, r_t: [-948.712 -948.712 -948.712], eps: 1.0})
Step:   85800, Reward: [-462.458 -462.458 -462.458] [80.096], Avg: [-497.898 -497.898 -497.898] (1.0000) ({r_i: None, r_t: [-942.196 -942.196 -942.196], eps: 1.0})
Step:   85900, Reward: [-495.151 -495.151 -495.151] [56.117], Avg: [-497.895 -497.895 -497.895] (1.0000) ({r_i: None, r_t: [-1052.461 -1052.461 -1052.461], eps: 1.0})
Step:   86000, Reward: [-441.846 -441.846 -441.846] [75.680], Avg: [-497.830 -497.830 -497.830] (1.0000) ({r_i: None, r_t: [-972.280 -972.280 -972.280], eps: 1.0})
Step:   86100, Reward: [-581.199 -581.199 -581.199] [117.713], Avg: [-497.927 -497.927 -497.927] (1.0000) ({r_i: None, r_t: [-1196.456 -1196.456 -1196.456], eps: 1.0})
Step:   86200, Reward: [-573.959 -573.959 -573.959] [216.104], Avg: [-498.015 -498.015 -498.015] (1.0000) ({r_i: None, r_t: [-1045.783 -1045.783 -1045.783], eps: 1.0})
Step:   86300, Reward: [-520.908 -520.908 -520.908] [121.705], Avg: [-498.041 -498.041 -498.041] (1.0000) ({r_i: None, r_t: [-942.543 -942.543 -942.543], eps: 1.0})
Step:   86400, Reward: [-507.471 -507.471 -507.471] [67.126], Avg: [-498.052 -498.052 -498.052] (1.0000) ({r_i: None, r_t: [-966.641 -966.641 -966.641], eps: 1.0})
Step:   86500, Reward: [-501.681 -501.681 -501.681] [72.650], Avg: [-498.056 -498.056 -498.056] (1.0000) ({r_i: None, r_t: [-977.430 -977.430 -977.430], eps: 1.0})
Step:   86600, Reward: [-522.515 -522.515 -522.515] [85.401], Avg: [-498.085 -498.085 -498.085] (1.0000) ({r_i: None, r_t: [-969.556 -969.556 -969.556], eps: 1.0})
Step:   86700, Reward: [-494.399 -494.399 -494.399] [77.771], Avg: [-498.080 -498.080 -498.080] (1.0000) ({r_i: None, r_t: [-922.719 -922.719 -922.719], eps: 1.0})
Step:   86800, Reward: [-470.937 -470.937 -470.937] [43.335], Avg: [-498.049 -498.049 -498.049] (1.0000) ({r_i: None, r_t: [-1067.245 -1067.245 -1067.245], eps: 1.0})
Step:   86900, Reward: [-439.498 -439.498 -439.498] [46.184], Avg: [-497.982 -497.982 -497.982] (1.0000) ({r_i: None, r_t: [-1046.551 -1046.551 -1046.551], eps: 1.0})
Step:   87000, Reward: [-490.059 -490.059 -490.059] [126.220], Avg: [-497.973 -497.973 -497.973] (1.0000) ({r_i: None, r_t: [-1080.551 -1080.551 -1080.551], eps: 1.0})
Step:   87100, Reward: [-504.995 -504.995 -504.995] [32.813], Avg: [-497.981 -497.981 -497.981] (1.0000) ({r_i: None, r_t: [-1094.064 -1094.064 -1094.064], eps: 1.0})
Step:   87200, Reward: [-480.225 -480.225 -480.225] [48.682], Avg: [-497.961 -497.961 -497.961] (1.0000) ({r_i: None, r_t: [-1005.503 -1005.503 -1005.503], eps: 1.0})
Step:   87300, Reward: [-557.514 -557.514 -557.514] [88.238], Avg: [-498.029 -498.029 -498.029] (1.0000) ({r_i: None, r_t: [-890.768 -890.768 -890.768], eps: 1.0})
Step:   87400, Reward: [-503.777 -503.777 -503.777] [34.479], Avg: [-498.035 -498.035 -498.035] (1.0000) ({r_i: None, r_t: [-1048.787 -1048.787 -1048.787], eps: 1.0})
Step:   87500, Reward: [-494.075 -494.075 -494.075] [68.772], Avg: [-498.031 -498.031 -498.031] (1.0000) ({r_i: None, r_t: [-965.651 -965.651 -965.651], eps: 1.0})
Step:   87600, Reward: [-486.754 -486.754 -486.754] [121.728], Avg: [-498.018 -498.018 -498.018] (1.0000) ({r_i: None, r_t: [-855.196 -855.196 -855.196], eps: 1.0})
Step:   87700, Reward: [-494.319 -494.319 -494.319] [99.741], Avg: [-498.014 -498.014 -498.014] (1.0000) ({r_i: None, r_t: [-958.147 -958.147 -958.147], eps: 1.0})
Step:   87800, Reward: [-488.772 -488.772 -488.772] [91.741], Avg: [-498.003 -498.003 -498.003] (1.0000) ({r_i: None, r_t: [-967.542 -967.542 -967.542], eps: 1.0})
Step:   87900, Reward: [-548.434 -548.434 -548.434] [71.215], Avg: [-498.060 -498.060 -498.060] (1.0000) ({r_i: None, r_t: [-1122.002 -1122.002 -1122.002], eps: 1.0})
Step:   88000, Reward: [-529.506 -529.506 -529.506] [122.565], Avg: [-498.096 -498.096 -498.096] (1.0000) ({r_i: None, r_t: [-862.330 -862.330 -862.330], eps: 1.0})
Step:   88100, Reward: [-445.096 -445.096 -445.096] [50.949], Avg: [-498.036 -498.036 -498.036] (1.0000) ({r_i: None, r_t: [-890.286 -890.286 -890.286], eps: 1.0})
Step:   88200, Reward: [-489.325 -489.325 -489.325] [78.242], Avg: [-498.026 -498.026 -498.026] (1.0000) ({r_i: None, r_t: [-986.972 -986.972 -986.972], eps: 1.0})
Step:   88300, Reward: [-491.037 -491.037 -491.037] [99.011], Avg: [-498.018 -498.018 -498.018] (1.0000) ({r_i: None, r_t: [-945.023 -945.023 -945.023], eps: 1.0})
Step:   88400, Reward: [-463.755 -463.755 -463.755] [88.340], Avg: [-497.980 -497.980 -497.980] (1.0000) ({r_i: None, r_t: [-1022.272 -1022.272 -1022.272], eps: 1.0})
Step:   88500, Reward: [-437.467 -437.467 -437.467] [15.964], Avg: [-497.911 -497.911 -497.911] (1.0000) ({r_i: None, r_t: [-1131.063 -1131.063 -1131.063], eps: 1.0})
Step:   88600, Reward: [-473.000 -473.000 -473.000] [130.972], Avg: [-497.883 -497.883 -497.883] (1.0000) ({r_i: None, r_t: [-1064.617 -1064.617 -1064.617], eps: 1.0})
Step:   88700, Reward: [-469.381 -469.381 -469.381] [38.470], Avg: [-497.851 -497.851 -497.851] (1.0000) ({r_i: None, r_t: [-931.334 -931.334 -931.334], eps: 1.0})
Step:   88800, Reward: [-606.012 -606.012 -606.012] [184.208], Avg: [-497.973 -497.973 -497.973] (1.0000) ({r_i: None, r_t: [-918.445 -918.445 -918.445], eps: 1.0})
Step:   88900, Reward: [-525.643 -525.643 -525.643] [36.680], Avg: [-498.004 -498.004 -498.004] (1.0000) ({r_i: None, r_t: [-912.865 -912.865 -912.865], eps: 1.0})
Step:   89000, Reward: [-605.222 -605.222 -605.222] [146.627], Avg: [-498.124 -498.124 -498.124] (1.0000) ({r_i: None, r_t: [-1028.794 -1028.794 -1028.794], eps: 1.0})
Step:   89100, Reward: [-493.044 -493.044 -493.044] [44.514], Avg: [-498.118 -498.118 -498.118] (1.0000) ({r_i: None, r_t: [-986.444 -986.444 -986.444], eps: 1.0})
Step:   89200, Reward: [-602.917 -602.917 -602.917] [80.799], Avg: [-498.236 -498.236 -498.236] (1.0000) ({r_i: None, r_t: [-861.154 -861.154 -861.154], eps: 1.0})
Step:   89300, Reward: [-541.381 -541.381 -541.381] [77.014], Avg: [-498.284 -498.284 -498.284] (1.0000) ({r_i: None, r_t: [-1093.573 -1093.573 -1093.573], eps: 1.0})
Step:   89400, Reward: [-420.443 -420.443 -420.443] [48.086], Avg: [-498.197 -498.197 -498.197] (1.0000) ({r_i: None, r_t: [-1192.052 -1192.052 -1192.052], eps: 1.0})
Step:   89500, Reward: [-484.060 -484.060 -484.060] [56.192], Avg: [-498.181 -498.181 -498.181] (1.0000) ({r_i: None, r_t: [-1021.471 -1021.471 -1021.471], eps: 1.0})
Step:   89600, Reward: [-504.948 -504.948 -504.948] [165.338], Avg: [-498.189 -498.189 -498.189] (1.0000) ({r_i: None, r_t: [-1156.136 -1156.136 -1156.136], eps: 1.0})
Step:   89700, Reward: [-405.361 -405.361 -405.361] [43.327], Avg: [-498.085 -498.085 -498.085] (1.0000) ({r_i: None, r_t: [-925.987 -925.987 -925.987], eps: 1.0})
Step:   89800, Reward: [-464.362 -464.362 -464.362] [131.511], Avg: [-498.048 -498.048 -498.048] (1.0000) ({r_i: None, r_t: [-865.605 -865.605 -865.605], eps: 1.0})
Step:   89900, Reward: [-447.765 -447.765 -447.765] [35.997], Avg: [-497.992 -497.992 -497.992] (1.0000) ({r_i: None, r_t: [-881.297 -881.297 -881.297], eps: 1.0})
Step:   90000, Reward: [-531.590 -531.590 -531.590] [85.587], Avg: [-498.029 -498.029 -498.029] (1.0000) ({r_i: None, r_t: [-1014.148 -1014.148 -1014.148], eps: 1.0})
Step:   90100, Reward: [-506.898 -506.898 -506.898] [103.479], Avg: [-498.039 -498.039 -498.039] (1.0000) ({r_i: None, r_t: [-1018.698 -1018.698 -1018.698], eps: 1.0})
Step:   90200, Reward: [-462.327 -462.327 -462.327] [35.360], Avg: [-498.000 -498.000 -498.000] (1.0000) ({r_i: None, r_t: [-964.251 -964.251 -964.251], eps: 1.0})
Step:   90300, Reward: [-425.038 -425.038 -425.038] [53.708], Avg: [-497.919 -497.919 -497.919] (1.0000) ({r_i: None, r_t: [-999.673 -999.673 -999.673], eps: 1.0})
Step:   90400, Reward: [-450.752 -450.752 -450.752] [79.064], Avg: [-497.867 -497.867 -497.867] (1.0000) ({r_i: None, r_t: [-1142.918 -1142.918 -1142.918], eps: 1.0})
Step:   90500, Reward: [-560.457 -560.457 -560.457] [157.726], Avg: [-497.936 -497.936 -497.936] (1.0000) ({r_i: None, r_t: [-1044.836 -1044.836 -1044.836], eps: 1.0})
Step:   90600, Reward: [-501.436 -501.436 -501.436] [111.960], Avg: [-497.940 -497.940 -497.940] (1.0000) ({r_i: None, r_t: [-985.482 -985.482 -985.482], eps: 1.0})
Step:   90700, Reward: [-491.341 -491.341 -491.341] [159.214], Avg: [-497.933 -497.933 -497.933] (1.0000) ({r_i: None, r_t: [-999.465 -999.465 -999.465], eps: 1.0})
Step:   90800, Reward: [-425.174 -425.174 -425.174] [16.086], Avg: [-497.852 -497.852 -497.852] (1.0000) ({r_i: None, r_t: [-906.539 -906.539 -906.539], eps: 1.0})
Step:   90900, Reward: [-506.204 -506.204 -506.204] [53.212], Avg: [-497.862 -497.862 -497.862] (1.0000) ({r_i: None, r_t: [-812.853 -812.853 -812.853], eps: 1.0})
Step:   91000, Reward: [-573.552 -573.552 -573.552] [100.027], Avg: [-497.945 -497.945 -497.945] (1.0000) ({r_i: None, r_t: [-1014.925 -1014.925 -1014.925], eps: 1.0})
Step:   91100, Reward: [-507.166 -507.166 -507.166] [67.136], Avg: [-497.955 -497.955 -497.955] (1.0000) ({r_i: None, r_t: [-907.534 -907.534 -907.534], eps: 1.0})
Step:   91200, Reward: [-577.551 -577.551 -577.551] [103.650], Avg: [-498.042 -498.042 -498.042] (1.0000) ({r_i: None, r_t: [-946.950 -946.950 -946.950], eps: 1.0})
Step:   91300, Reward: [-484.228 -484.228 -484.228] [59.024], Avg: [-498.027 -498.027 -498.027] (1.0000) ({r_i: None, r_t: [-1085.629 -1085.629 -1085.629], eps: 1.0})
Step:   91400, Reward: [-447.748 -447.748 -447.748] [84.636], Avg: [-497.972 -497.972 -497.972] (1.0000) ({r_i: None, r_t: [-961.293 -961.293 -961.293], eps: 1.0})
Step:   91500, Reward: [-430.192 -430.192 -430.192] [43.988], Avg: [-497.898 -497.898 -497.898] (1.0000) ({r_i: None, r_t: [-1006.411 -1006.411 -1006.411], eps: 1.0})
Step:   91600, Reward: [-473.028 -473.028 -473.028] [63.636], Avg: [-497.871 -497.871 -497.871] (1.0000) ({r_i: None, r_t: [-939.524 -939.524 -939.524], eps: 1.0})
Step:   91700, Reward: [-505.521 -505.521 -505.521] [47.742], Avg: [-497.879 -497.879 -497.879] (1.0000) ({r_i: None, r_t: [-954.505 -954.505 -954.505], eps: 1.0})
Step:   91800, Reward: [-483.854 -483.854 -483.854] [44.620], Avg: [-497.864 -497.864 -497.864] (1.0000) ({r_i: None, r_t: [-1066.680 -1066.680 -1066.680], eps: 1.0})
Step:   91900, Reward: [-540.342 -540.342 -540.342] [80.618], Avg: [-497.910 -497.910 -497.910] (1.0000) ({r_i: None, r_t: [-825.269 -825.269 -825.269], eps: 1.0})
Step:   92000, Reward: [-457.715 -457.715 -457.715] [106.229], Avg: [-497.866 -497.866 -497.866] (1.0000) ({r_i: None, r_t: [-1004.930 -1004.930 -1004.930], eps: 1.0})
Step:   92100, Reward: [-518.495 -518.495 -518.495] [75.533], Avg: [-497.889 -497.889 -497.889] (1.0000) ({r_i: None, r_t: [-953.422 -953.422 -953.422], eps: 1.0})
Step:   92200, Reward: [-403.791 -403.791 -403.791] [16.606], Avg: [-497.787 -497.787 -497.787] (1.0000) ({r_i: None, r_t: [-1019.275 -1019.275 -1019.275], eps: 1.0})
Step:   92300, Reward: [-489.233 -489.233 -489.233] [83.303], Avg: [-497.778 -497.778 -497.778] (1.0000) ({r_i: None, r_t: [-1046.890 -1046.890 -1046.890], eps: 1.0})
Step:   92400, Reward: [-499.119 -499.119 -499.119] [87.116], Avg: [-497.779 -497.779 -497.779] (1.0000) ({r_i: None, r_t: [-1030.605 -1030.605 -1030.605], eps: 1.0})
Step:   92500, Reward: [-453.371 -453.371 -453.371] [50.862], Avg: [-497.731 -497.731 -497.731] (1.0000) ({r_i: None, r_t: [-1059.990 -1059.990 -1059.990], eps: 1.0})
Step:   92600, Reward: [-446.197 -446.197 -446.197] [76.858], Avg: [-497.676 -497.676 -497.676] (1.0000) ({r_i: None, r_t: [-1023.722 -1023.722 -1023.722], eps: 1.0})
Step:   92700, Reward: [-464.321 -464.321 -464.321] [52.301], Avg: [-497.640 -497.640 -497.640] (1.0000) ({r_i: None, r_t: [-1014.932 -1014.932 -1014.932], eps: 1.0})
Step:   92800, Reward: [-486.116 -486.116 -486.116] [40.218], Avg: [-497.627 -497.627 -497.627] (1.0000) ({r_i: None, r_t: [-1088.409 -1088.409 -1088.409], eps: 1.0})
Step:   92900, Reward: [-590.243 -590.243 -590.243] [126.730], Avg: [-497.727 -497.727 -497.727] (1.0000) ({r_i: None, r_t: [-1014.565 -1014.565 -1014.565], eps: 1.0})
Step:   93000, Reward: [-417.772 -417.772 -417.772] [60.147], Avg: [-497.641 -497.641 -497.641] (1.0000) ({r_i: None, r_t: [-943.008 -943.008 -943.008], eps: 1.0})
Step:   93100, Reward: [-592.801 -592.801 -592.801] [86.870], Avg: [-497.743 -497.743 -497.743] (1.0000) ({r_i: None, r_t: [-1014.361 -1014.361 -1014.361], eps: 1.0})
Step:   93200, Reward: [-539.018 -539.018 -539.018] [83.712], Avg: [-497.787 -497.787 -497.787] (1.0000) ({r_i: None, r_t: [-984.872 -984.872 -984.872], eps: 1.0})
Step:   93300, Reward: [-626.302 -626.302 -626.302] [113.857], Avg: [-497.925 -497.925 -497.925] (1.0000) ({r_i: None, r_t: [-983.893 -983.893 -983.893], eps: 1.0})
Step:   93400, Reward: [-543.949 -543.949 -543.949] [51.847], Avg: [-497.974 -497.974 -497.974] (1.0000) ({r_i: None, r_t: [-928.897 -928.897 -928.897], eps: 1.0})
Step:   93500, Reward: [-476.572 -476.572 -476.572] [77.095], Avg: [-497.951 -497.951 -497.951] (1.0000) ({r_i: None, r_t: [-1052.155 -1052.155 -1052.155], eps: 1.0})
Step:   93600, Reward: [-433.561 -433.561 -433.561] [56.734], Avg: [-497.882 -497.882 -497.882] (1.0000) ({r_i: None, r_t: [-1057.072 -1057.072 -1057.072], eps: 1.0})
Step:   93700, Reward: [-503.814 -503.814 -503.814] [54.169], Avg: [-497.889 -497.889 -497.889] (1.0000) ({r_i: None, r_t: [-1010.573 -1010.573 -1010.573], eps: 1.0})
Step:   93800, Reward: [-538.981 -538.981 -538.981] [120.167], Avg: [-497.933 -497.933 -497.933] (1.0000) ({r_i: None, r_t: [-977.335 -977.335 -977.335], eps: 1.0})
Step:   93900, Reward: [-470.558 -470.558 -470.558] [30.839], Avg: [-497.903 -497.903 -497.903] (1.0000) ({r_i: None, r_t: [-1032.865 -1032.865 -1032.865], eps: 1.0})
Step:   94000, Reward: [-448.748 -448.748 -448.748] [57.529], Avg: [-497.851 -497.851 -497.851] (1.0000) ({r_i: None, r_t: [-898.122 -898.122 -898.122], eps: 1.0})
Step:   94100, Reward: [-439.768 -439.768 -439.768] [70.645], Avg: [-497.790 -497.790 -497.790] (1.0000) ({r_i: None, r_t: [-988.875 -988.875 -988.875], eps: 1.0})
Step:   94200, Reward: [-493.515 -493.515 -493.515] [38.656], Avg: [-497.785 -497.785 -497.785] (1.0000) ({r_i: None, r_t: [-941.014 -941.014 -941.014], eps: 1.0})
Step:   94300, Reward: [-548.790 -548.790 -548.790] [52.938], Avg: [-497.839 -497.839 -497.839] (1.0000) ({r_i: None, r_t: [-1018.188 -1018.188 -1018.188], eps: 1.0})
Step:   94400, Reward: [-445.308 -445.308 -445.308] [54.771], Avg: [-497.783 -497.783 -497.783] (1.0000) ({r_i: None, r_t: [-1060.346 -1060.346 -1060.346], eps: 1.0})
Step:   94500, Reward: [-483.762 -483.762 -483.762] [69.483], Avg: [-497.769 -497.769 -497.769] (1.0000) ({r_i: None, r_t: [-992.760 -992.760 -992.760], eps: 1.0})
Step:   94600, Reward: [-619.048 -619.048 -619.048] [138.597], Avg: [-497.897 -497.897 -497.897] (1.0000) ({r_i: None, r_t: [-995.863 -995.863 -995.863], eps: 1.0})
Step:   94700, Reward: [-523.717 -523.717 -523.717] [85.801], Avg: [-497.924 -497.924 -497.924] (1.0000) ({r_i: None, r_t: [-976.906 -976.906 -976.906], eps: 1.0})
Step:   94800, Reward: [-459.184 -459.184 -459.184] [48.564], Avg: [-497.883 -497.883 -497.883] (1.0000) ({r_i: None, r_t: [-880.366 -880.366 -880.366], eps: 1.0})
Step:   94900, Reward: [-490.243 -490.243 -490.243] [39.943], Avg: [-497.875 -497.875 -497.875] (1.0000) ({r_i: None, r_t: [-977.992 -977.992 -977.992], eps: 1.0})
Step:   95000, Reward: [-490.774 -490.774 -490.774] [101.399], Avg: [-497.868 -497.868 -497.868] (1.0000) ({r_i: None, r_t: [-977.066 -977.066 -977.066], eps: 1.0})
Step:   95100, Reward: [-481.468 -481.468 -481.468] [35.352], Avg: [-497.850 -497.850 -497.850] (1.0000) ({r_i: None, r_t: [-1025.625 -1025.625 -1025.625], eps: 1.0})
Step:   95200, Reward: [-520.615 -520.615 -520.615] [116.172], Avg: [-497.874 -497.874 -497.874] (1.0000) ({r_i: None, r_t: [-1028.955 -1028.955 -1028.955], eps: 1.0})
Step:   95300, Reward: [-556.328 -556.328 -556.328] [57.585], Avg: [-497.936 -497.936 -497.936] (1.0000) ({r_i: None, r_t: [-1018.278 -1018.278 -1018.278], eps: 1.0})
Step:   95400, Reward: [-437.457 -437.457 -437.457] [30.735], Avg: [-497.872 -497.872 -497.872] (1.0000) ({r_i: None, r_t: [-992.730 -992.730 -992.730], eps: 1.0})
Step:   95500, Reward: [-455.808 -455.808 -455.808] [85.866], Avg: [-497.828 -497.828 -497.828] (1.0000) ({r_i: None, r_t: [-1020.607 -1020.607 -1020.607], eps: 1.0})
Step:   95600, Reward: [-470.002 -470.002 -470.002] [131.419], Avg: [-497.799 -497.799 -497.799] (1.0000) ({r_i: None, r_t: [-1001.420 -1001.420 -1001.420], eps: 1.0})
Step:   95700, Reward: [-568.740 -568.740 -568.740] [111.357], Avg: [-497.873 -497.873 -497.873] (1.0000) ({r_i: None, r_t: [-881.487 -881.487 -881.487], eps: 1.0})
Step:   95800, Reward: [-437.102 -437.102 -437.102] [6.172], Avg: [-497.810 -497.810 -497.810] (1.0000) ({r_i: None, r_t: [-915.179 -915.179 -915.179], eps: 1.0})
Step:   95900, Reward: [-578.885 -578.885 -578.885] [171.556], Avg: [-497.894 -497.894 -497.894] (1.0000) ({r_i: None, r_t: [-965.720 -965.720 -965.720], eps: 1.0})
Step:   96000, Reward: [-562.468 -562.468 -562.468] [155.470], Avg: [-497.961 -497.961 -497.961] (1.0000) ({r_i: None, r_t: [-1038.349 -1038.349 -1038.349], eps: 1.0})
Step:   96100, Reward: [-489.193 -489.193 -489.193] [126.643], Avg: [-497.952 -497.952 -497.952] (1.0000) ({r_i: None, r_t: [-1002.650 -1002.650 -1002.650], eps: 1.0})
Step:   96200, Reward: [-461.686 -461.686 -461.686] [19.863], Avg: [-497.915 -497.915 -497.915] (1.0000) ({r_i: None, r_t: [-1007.915 -1007.915 -1007.915], eps: 1.0})
Step:   96300, Reward: [-527.145 -527.145 -527.145] [69.386], Avg: [-497.945 -497.945 -497.945] (1.0000) ({r_i: None, r_t: [-1034.329 -1034.329 -1034.329], eps: 1.0})
Step:   96400, Reward: [-478.488 -478.488 -478.488] [23.560], Avg: [-497.925 -497.925 -497.925] (1.0000) ({r_i: None, r_t: [-1053.045 -1053.045 -1053.045], eps: 1.0})
Step:   96500, Reward: [-468.202 -468.202 -468.202] [66.042], Avg: [-497.894 -497.894 -497.894] (1.0000) ({r_i: None, r_t: [-962.354 -962.354 -962.354], eps: 1.0})
Step:   96600, Reward: [-504.540 -504.540 -504.540] [31.278], Avg: [-497.901 -497.901 -497.901] (1.0000) ({r_i: None, r_t: [-1061.811 -1061.811 -1061.811], eps: 1.0})
Step:   96700, Reward: [-444.543 -444.543 -444.543] [56.210], Avg: [-497.846 -497.846 -497.846] (1.0000) ({r_i: None, r_t: [-1072.184 -1072.184 -1072.184], eps: 1.0})
Step:   96800, Reward: [-485.231 -485.231 -485.231] [109.312], Avg: [-497.833 -497.833 -497.833] (1.0000) ({r_i: None, r_t: [-968.219 -968.219 -968.219], eps: 1.0})
Step:   96900, Reward: [-565.369 -565.369 -565.369] [68.430], Avg: [-497.902 -497.902 -497.902] (1.0000) ({r_i: None, r_t: [-1051.687 -1051.687 -1051.687], eps: 1.0})
Step:   97000, Reward: [-499.842 -499.842 -499.842] [83.986], Avg: [-497.904 -497.904 -497.904] (1.0000) ({r_i: None, r_t: [-993.915 -993.915 -993.915], eps: 1.0})
Step:   97100, Reward: [-495.436 -495.436 -495.436] [118.321], Avg: [-497.902 -497.902 -497.902] (1.0000) ({r_i: None, r_t: [-1090.440 -1090.440 -1090.440], eps: 1.0})
Step:   97200, Reward: [-467.647 -467.647 -467.647] [141.515], Avg: [-497.871 -497.871 -497.871] (1.0000) ({r_i: None, r_t: [-1017.056 -1017.056 -1017.056], eps: 1.0})
Step:   97300, Reward: [-550.806 -550.806 -550.806] [59.598], Avg: [-497.925 -497.925 -497.925] (1.0000) ({r_i: None, r_t: [-900.652 -900.652 -900.652], eps: 1.0})
Step:   97400, Reward: [-464.590 -464.590 -464.590] [38.848], Avg: [-497.891 -497.891 -497.891] (1.0000) ({r_i: None, r_t: [-948.443 -948.443 -948.443], eps: 1.0})
Step:   97500, Reward: [-411.171 -411.171 -411.171] [51.906], Avg: [-497.802 -497.802 -497.802] (1.0000) ({r_i: None, r_t: [-1014.701 -1014.701 -1014.701], eps: 1.0})
Step:   97600, Reward: [-503.264 -503.264 -503.264] [125.802], Avg: [-497.808 -497.808 -497.808] (1.0000) ({r_i: None, r_t: [-1061.625 -1061.625 -1061.625], eps: 1.0})
Step:   97700, Reward: [-471.944 -471.944 -471.944] [74.737], Avg: [-497.781 -497.781 -497.781] (1.0000) ({r_i: None, r_t: [-892.372 -892.372 -892.372], eps: 1.0})
Step:   97800, Reward: [-468.675 -468.675 -468.675] [97.108], Avg: [-497.752 -497.752 -497.752] (1.0000) ({r_i: None, r_t: [-991.865 -991.865 -991.865], eps: 1.0})
Step:   97900, Reward: [-524.467 -524.467 -524.467] [46.514], Avg: [-497.779 -497.779 -497.779] (1.0000) ({r_i: None, r_t: [-980.452 -980.452 -980.452], eps: 1.0})
Step:   98000, Reward: [-587.670 -587.670 -587.670] [112.891], Avg: [-497.870 -497.870 -497.870] (1.0000) ({r_i: None, r_t: [-934.946 -934.946 -934.946], eps: 1.0})
Step:   98100, Reward: [-561.365 -561.365 -561.365] [119.712], Avg: [-497.935 -497.935 -497.935] (1.0000) ({r_i: None, r_t: [-1073.610 -1073.610 -1073.610], eps: 1.0})
Step:   98200, Reward: [-422.303 -422.303 -422.303] [66.194], Avg: [-497.858 -497.858 -497.858] (1.0000) ({r_i: None, r_t: [-993.940 -993.940 -993.940], eps: 1.0})
Step:   98300, Reward: [-582.727 -582.727 -582.727] [76.731], Avg: [-497.944 -497.944 -497.944] (1.0000) ({r_i: None, r_t: [-932.844 -932.844 -932.844], eps: 1.0})
Step:   98400, Reward: [-487.670 -487.670 -487.670] [76.868], Avg: [-497.934 -497.934 -497.934] (1.0000) ({r_i: None, r_t: [-1041.821 -1041.821 -1041.821], eps: 1.0})
Step:   98500, Reward: [-474.760 -474.760 -474.760] [36.858], Avg: [-497.910 -497.910 -497.910] (1.0000) ({r_i: None, r_t: [-938.880 -938.880 -938.880], eps: 1.0})
Step:   98600, Reward: [-492.302 -492.302 -492.302] [164.682], Avg: [-497.905 -497.905 -497.905] (1.0000) ({r_i: None, r_t: [-958.344 -958.344 -958.344], eps: 1.0})
Step:   98700, Reward: [-428.362 -428.362 -428.362] [37.970], Avg: [-497.834 -497.834 -497.834] (1.0000) ({r_i: None, r_t: [-1065.307 -1065.307 -1065.307], eps: 1.0})
Step:   98800, Reward: [-456.211 -456.211 -456.211] [61.276], Avg: [-497.792 -497.792 -497.792] (1.0000) ({r_i: None, r_t: [-936.167 -936.167 -936.167], eps: 1.0})
Step:   98900, Reward: [-495.361 -495.361 -495.361] [104.162], Avg: [-497.790 -497.790 -497.790] (1.0000) ({r_i: None, r_t: [-965.445 -965.445 -965.445], eps: 1.0})
Step:   99000, Reward: [-391.114 -391.114 -391.114] [23.958], Avg: [-497.682 -497.682 -497.682] (1.0000) ({r_i: None, r_t: [-954.205 -954.205 -954.205], eps: 1.0})
Step:   99100, Reward: [-431.414 -431.414 -431.414] [42.707], Avg: [-497.615 -497.615 -497.615] (1.0000) ({r_i: None, r_t: [-1022.654 -1022.654 -1022.654], eps: 1.0})
Step:   99200, Reward: [-486.767 -486.767 -486.767] [65.071], Avg: [-497.604 -497.604 -497.604] (1.0000) ({r_i: None, r_t: [-974.207 -974.207 -974.207], eps: 1.0})
Step:   99300, Reward: [-510.053 -510.053 -510.053] [158.886], Avg: [-497.617 -497.617 -497.617] (1.0000) ({r_i: None, r_t: [-1042.312 -1042.312 -1042.312], eps: 1.0})
Step:   99400, Reward: [-494.731 -494.731 -494.731] [41.280], Avg: [-497.614 -497.614 -497.614] (1.0000) ({r_i: None, r_t: [-1032.939 -1032.939 -1032.939], eps: 1.0})
Step:   99500, Reward: [-479.226 -479.226 -479.226] [82.171], Avg: [-497.596 -497.596 -497.596] (1.0000) ({r_i: None, r_t: [-963.635 -963.635 -963.635], eps: 1.0})
Step:   99600, Reward: [-552.558 -552.558 -552.558] [59.981], Avg: [-497.651 -497.651 -497.651] (1.0000) ({r_i: None, r_t: [-1092.465 -1092.465 -1092.465], eps: 1.0})
Step:   99700, Reward: [-437.945 -437.945 -437.945] [38.142], Avg: [-497.591 -497.591 -497.591] (1.0000) ({r_i: None, r_t: [-910.945 -910.945 -910.945], eps: 1.0})
Step:   99800, Reward: [-416.722 -416.722 -416.722] [56.447], Avg: [-497.510 -497.510 -497.510] (1.0000) ({r_i: None, r_t: [-1068.639 -1068.639 -1068.639], eps: 1.0})
Step:   99900, Reward: [-460.630 -460.630 -460.630] [107.353], Avg: [-497.473 -497.473 -497.473] (1.0000) ({r_i: None, r_t: [-1062.448 -1062.448 -1062.448], eps: 1.0})
Step:  100000, Reward: [-566.786 -566.786 -566.786] [141.436], Avg: [-497.542 -497.542 -497.542] (1.0000) ({r_i: None, r_t: [-1000.008 -1000.008 -1000.008], eps: 1.0})
