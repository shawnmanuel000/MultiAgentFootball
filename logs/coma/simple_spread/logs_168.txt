Model: <class 'multiagent.coma.COMAAgent'>, Dir: simple_spread, Date: 13/03/2020 16:05:27
num_envs: 16,
state_size: [(1, 18), (1, 18), (1, 18)],
action_size: [[1, 5], [1, 5], [1, 5]],
action_space: [MultiDiscrete([5]), MultiDiscrete([5]), MultiDiscrete([5])],
envs: <class 'utils.envs.EnsembleEnv'>,
reward_shape: False,
icm: False,

import torch
import numpy as np
from models.rand import MultiagentReplayBuffer3
from utils.network import PTACNetwork, PTACAgent, PTCritic, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, TARGET_UPDATE_RATE, one_hot_from_indices

EPS_MIN = 0.1               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.99             	# The rate at which eps decays from EPS_MAX to EPS_MIN
REPLAY_BATCH_SIZE = 10			# Number of episodes to train on for each train step
EPISODE_BUFFER = 64				# Sets the maximum length of the replay buffer
TIME_BATCHES = 100				# The number of batches of time steps to train critic in reverse time sequence
NUM_STEPS = 50					# The number of steps to collect experience in sequence for each GAE calculation

class COMAActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_probs = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, eps):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		action_probs = self.action_probs(state).softmax(-1)
		action_probs = ((1 - eps) * action_probs + torch.ones_like(action_probs).to(state.device) * eps/action_probs.size(-1))
		action = torch.distributions.Categorical(action_probs).sample().long()
		return one_hot_from_indices(action, action_probs.size(-1)), action_probs

class COMANetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=True, load=""):
		self.actor = COMAActor([state_size[0][-1] + action_size[0][-1] + len(state_size)], action_size[0])
		self.critic = lambda s,a: PTCritic([np.sum([np.prod(s) for s in state_size]) + 2*np.sum([np.prod(a) for a in action_size]) + state_size[0][-1] + len(state_size)], action_size[0])
		super().__init__(state_size, action_size, actor=lambda s,a: self.actor, critic=self.critic, lr=lr, gpu=gpu, load=load, name="coma")

	def get_action_probs(self, inputs, eps, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			action, action_probs = self.actor_local(inputs, eps)
			return [x.cpu().numpy() if numpy else x for x in [action, action_probs]]

	def optimize(self, actions, critic_inputs, actor_inputs, rewards, dones, eps):
		critic_losses = []
		q_next_value = self.critic_target(critic_inputs)
		q_next_taken = torch.gather(q_next_value, dim=-1, index=actions.argmax(-1, keepdims=True)).squeeze(-1)
		q_next_taken = torch.cat([q_next_taken, torch.zeros_like(q_next_taken[:,-1]).unsqueeze(1)], dim=1)
		q_target = PTACAgent.compute_ma_gae(rewards.unsqueeze(-1), dones.unsqueeze(-1), q_next_taken)
		q_value = torch.zeros_like(q_next_value)
		t_batch = max(rewards.size(1)//TIME_BATCHES, 1)
		for t in reversed(range(0,min(rewards.size(1), t_batch*TIME_BATCHES),t_batch)):
			q_value[:,t:t+t_batch] = self.critic_local(critic_inputs[:,t:t+t_batch])
			q_taken = torch.gather(q_value[:,t:t+t_batch], dim=-1, index=actions[:,t:t+t_batch].argmax(-1, keepdims=True)).squeeze(-1)
			critic_error = (q_taken - q_target[:,t:t+t_batch].detach())
			critic_loss = critic_error.pow(2).mean()
			critic_losses.append(critic_loss.detach().cpu().numpy())
			self.step(self.critic_optimizer, critic_loss, self.critic_local.parameters(), retain=t>0)
		self.soft_copy(self.critic_local, self.critic_target)

		action_probs = self.get_action_probs(actor_inputs, eps, grad=True)[1]
		q_value = q_value.reshape(-1, action_probs.shape[-1])
		pi = action_probs.view(-1, action_probs.shape[-1])
		baseline = (pi * q_value).sum(-1).detach()
		q_taken = torch.gather(q_value, dim=1, index=actions.argmax(-1).reshape(-1, 1)).squeeze(1)
		pi_taken = torch.gather(pi, dim=1, index=actions.argmax(-1).reshape(-1, 1)).squeeze(1)
		advantages = (q_taken - baseline).detach()
		actor_loss = - (advantages * pi_taken.log()).mean()
		self.step(self.actor_optimizer, actor_loss, self.actor_local.parameters())
		return [np.mean(critic_losses), np.mean(actor_loss.detach().cpu().numpy())]

class COMAAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, COMANetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.replay_buffer = MultiagentReplayBuffer3(EPISODE_BUFFER, state_size, action_size)
		self.n_agents = len(action_size)
		self.stats = []

	def get_action(self, state, eps=None, sample=True, numpy=True):
		eps = self.eps if eps is None else eps
		obs = np.concatenate(state, -2)
		if not hasattr(self, "action"): self.action = np.zeros([*obs.shape[:-1], self.action_size[0][-1]])
		agent_ids = np.repeat(np.expand_dims(np.eye(self.n_agents), 0), repeats=obs.shape[0], axis=0)
		inputs = torch.from_numpy(np.concatenate([obs, self.action, agent_ids], -1)).float().to(self.network.device)
		self.action = self.network.get_action_probs(inputs, eps=self.eps, numpy=True)[0]
		return np.split(self.action, len(self.action_size), axis=-2)

	def train(self, state, action, next_state, reward, done):
		self.step = 0 if not hasattr(self, "step") else self.step + 1
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]):
			states, actions, rewards, dones = map(lambda x: torch.stack(self.to_tensor(x),2), zip(*self.buffer))
			obs, actions = [x.squeeze(-2) for x in [states, actions]]
			state = states.repeat(1,1,1,self.n_agents,1).view(*states.shape[:3],-1)
			actions_joint = actions.view(*actions.shape[:2],1,-1).repeat(1,1,self.n_agents,1)
			agent_mask = (1-torch.eye(self.n_agents, device=self.network.device))
			agent_mask = agent_mask.view(-1, 1).repeat(1, self.action_size[0][-1]).view(self.n_agents, -1).unsqueeze(0).unsqueeze(0)
			last_actions = torch.cat([torch.zeros_like(actions[:, 0:1]), actions[:, :-1]], dim=1)
			last_actions_joint = last_actions.view(*last_actions.shape[:2],1,-1).repeat(1,1,self.n_agents,1)
			agent_inds = torch.eye(self.n_agents, device=self.network.device).unsqueeze(0).unsqueeze(0).expand(*obs.shape[:2],-1,-1)
			critic_inputs = torch.cat([state, obs, actions_joint * agent_mask, last_actions_joint, agent_inds], dim=-1)
			actor_inputs = torch.cat([obs, last_actions, agent_inds], dim=-1)
			self.replay_buffer.add([self.to_numpy([x.transpose(0,1)]) for x in (actions, critic_inputs, actor_inputs, rewards, dones)])
			self.buffer.clear()
		if (self.step % self.update_freq)==0 and len(self.replay_buffer) >= REPLAY_BATCH_SIZE:
			actions, critic_inputs, actor_inputs, rewards, dones = [x[0] for x in self.replay_buffer.sample(REPLAY_BATCH_SIZE, lambda x: torch.Tensor(x).to(self.network.device))]
			self.stats.append(self.network.optimize(actions, critic_inputs, actor_inputs, rewards.mean(-1), dones.mean(-1), self.eps))
		if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)

	def get_stats(self):
		stats = {k:v for k,v in zip(["critic_loss", "actor_loss"], np.mean(self.stats, axis=0))} if len(self.stats)>0 else {}
		self.stats = []
		return {**stats, **super().get_stats()}

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0003           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.001   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 256				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 512				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.998			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.001               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 1000000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.sac import SACAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, DoubleAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv, TrainEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, MPI_SIZE, MPI_RANK
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-3]
# env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False, reward_shape=False):
	if env_name in gym_envs: return TrainEnv(gym.make(env_name))
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	ballr = lambda x,y: (np.maximum if x>0 else np.minimum)(x - np.abs(y)*np.sign(x), 0.5*x)
	reward_fn = lambda obs,reward,eps: [0.1*(ballr(o[0,88], o[0,89])) + r for o,r in zip(obs,reward)]
	return FootballTeamEnv(ggym, env_name, reward_fn if reward_shape else None)

def train(model, steps=10000, ports=16, env_name=env_name, trial_at=500, save_at=10, checkpoint=True, save_best=False, log=True, render=False, reward_shape=False, icm=False):
	envs = (EnvManager if type(ports) == list or MPI_SIZE > 1 else EnsembleEnv)(lambda: make_env(env_name, reward_shape=reward_shape), ports)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, envs.num_envs, load="", gpu=True, agent2=RandomAgent, save_dir=env_name, icm=icm) 
	logger = Logger(model, env_name, num_envs=envs.num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space, envs=type(envs), reward_shape=reward_shape, icm=icm)
	states = envs.reset(train=True)
	total_rewards = []
	for s in range(steps+1):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions, train=True)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if s%trial_at == 0:
			rollouts = rollout(envs, agent, render=render)
			total_rewards.append(np.mean(rollouts, axis=-1))
			if save_best and np.all(total_rewards[-1] >= np.max(total_rewards, axis=-1)): agent.save_model(env_name)
			if checkpoint and len(total_rewards) % save_at==0: agent.save_model(env_name, f"checkpoint{'_rs' if reward_shape else ''}{'_icm' if icm else ''}")
			if log: logger.log(f"Step: {s:7d}, Reward: {total_rewards[-1]} [{np.std(rollouts):4.3f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.eps:.4f})", agent.get_stats())

def trial(model, env_name, render):
	envs = EnsembleEnv(lambda: make_env(env_name, log=True, render=render), 0)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, gpu=False, load=f"{env_name}", agent2=RandomAgent, save_dir=env_name)
	print(f"Reward: {np.mean([rollout(envs.env, agent, eps=0.0, render=True) for _ in range(5)], axis=0)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="coma", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=200000, help="Number of steps to train the agent")
	parser.add_argument("--reward_shape", action="store_true", help="Whether to shape rewards for football")
	parser.add_argument("--icm", action="store_true", help="Whether to use intrinsic motivation")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--trial", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "sac":SACAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent, "rand":RandomAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.selfport is not None or MPI_RANK>0:
		EnvWorker(self_port=args.selfport, make_env=make_env).start()
	elif args.trial:
		trial(model=model, env_name=env_name, render=args.render)
	else:
		train(model=model, steps=args.steps, ports=args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render, reward_shape=args.reward_shape, icm=args.icm)


Step:       0, Reward: [-478.301 -478.301 -478.301] [81.535], Avg: [-478.301 -478.301 -478.301] (1.0000) <00:00:00> ({r_i: None, r_t: [-9.162 -9.162 -9.162], eps: 1.0})
Step:     500, Reward: [-466.502 -466.502 -466.502] [91.829], Avg: [-472.402 -472.402 -472.402] (0.9044) <00:00:13> ({r_i: None, r_t: [-4914.692 -4914.692 -4914.692], critic_loss: 6932.60009765625, actor_loss: -0.03500000014901161, eps: 0.904})
Step:    1000, Reward: [-484.004 -484.004 -484.004] [96.558], Avg: [-476.269 -476.269 -476.269] (0.8179) <00:00:26> ({r_i: None, r_t: [-4666.272 -4666.272 -4666.272], critic_loss: 5671.02783203125, actor_loss: -0.04500000178813934, eps: 0.818})
Step:    1500, Reward: [-463.364 -463.364 -463.364] [49.162], Avg: [-473.043 -473.043 -473.043] (0.7397) <00:00:39> ({r_i: None, r_t: [-4636.335 -4636.335 -4636.335], critic_loss: 5449.53076171875, actor_loss: 0.0729999989271164, eps: 0.74})
Step:    2000, Reward: [-510.824 -510.824 -510.824] [88.841], Avg: [-480.599 -480.599 -480.599] (0.6690) <00:00:52> ({r_i: None, r_t: [-4743.698 -4743.698 -4743.698], critic_loss: 5729.7958984375, actor_loss: -0.13300000131130219, eps: 0.669})
Step:    2500, Reward: [-451.565 -451.565 -451.565] [75.981], Avg: [-475.760 -475.760 -475.760] (0.6050) <00:01:04> ({r_i: None, r_t: [-4605.678 -4605.678 -4605.678], critic_loss: 4238.78515625, actor_loss: -0.16899999976158142, eps: 0.605})
Step:    3000, Reward: [-438.867 -438.867 -438.867] [71.165], Avg: [-470.490 -470.490 -470.490] (0.5472) <00:01:17> ({r_i: None, r_t: [-4682.619 -4682.619 -4682.619], critic_loss: 4632.9189453125, actor_loss: -0.6660000085830688, eps: 0.547})
Step:    3500, Reward: [-486.154 -486.154 -486.154] [80.695], Avg: [-472.448 -472.448 -472.448] (0.4948) <00:01:30> ({r_i: None, r_t: [-4493.763 -4493.763 -4493.763], critic_loss: 3954.136962890625, actor_loss: -0.7149999737739563, eps: 0.495})
Step:    4000, Reward: [-437.620 -437.620 -437.620] [63.922], Avg: [-468.578 -468.578 -468.578] (0.4475) <00:01:43> ({r_i: None, r_t: [-4573.197 -4573.197 -4573.197], critic_loss: 4775.0849609375, actor_loss: -0.45399999618530273, eps: 0.448})
Step:    4500, Reward: [-442.025 -442.025 -442.025] [53.267], Avg: [-465.923 -465.923 -465.923] (0.4047) <00:01:57> ({r_i: None, r_t: [-4603.231 -4603.231 -4603.231], critic_loss: 5855.6240234375, actor_loss: 0.4180000126361847, eps: 0.405})
Step:    5000, Reward: [-462.937 -462.937 -462.937] [113.322], Avg: [-465.651 -465.651 -465.651] (0.3660) <00:02:10> ({r_i: None, r_t: [-4501.625 -4501.625 -4501.625], critic_loss: 4930.43212890625, actor_loss: -0.08299999684095383, eps: 0.366})
Step:    5500, Reward: [-483.276 -483.276 -483.276] [70.819], Avg: [-467.120 -467.120 -467.120] (0.3310) <00:02:23> ({r_i: None, r_t: [-4438.138 -4438.138 -4438.138], critic_loss: 4259.6240234375, actor_loss: -0.06599999964237213, eps: 0.331})
Step:    6000, Reward: [-458.079 -458.079 -458.079] [90.443], Avg: [-466.425 -466.425 -466.425] (0.2994) <00:02:36> ({r_i: None, r_t: [-4437.438 -4437.438 -4437.438], critic_loss: 4650.3232421875, actor_loss: 0.054999999701976776, eps: 0.299})
Step:    6500, Reward: [-485.666 -485.666 -485.666] [80.481], Avg: [-467.799 -467.799 -467.799] (0.2708) <00:02:49> ({r_i: None, r_t: [-4588.722 -4588.722 -4588.722], critic_loss: 5198.6279296875, actor_loss: 0.5120000243186951, eps: 0.271})
Step:    7000, Reward: [-416.066 -416.066 -416.066] [73.612], Avg: [-464.350 -464.350 -464.350] (0.2449) <00:03:03> ({r_i: None, r_t: [-4431.426 -4431.426 -4431.426], critic_loss: 4563.52197265625, actor_loss: 0.02199999988079071, eps: 0.245})
Step:    7500, Reward: [-454.762 -454.762 -454.762] [76.346], Avg: [-463.751 -463.751 -463.751] (0.2215) <00:03:15> ({r_i: None, r_t: [-4425.388 -4425.388 -4425.388], critic_loss: 4003.319091796875, actor_loss: -0.13300000131130219, eps: 0.221})
Step:    8000, Reward: [-458.249 -458.249 -458.249] [88.983], Avg: [-463.427 -463.427 -463.427] (0.2003) <00:03:28> ({r_i: None, r_t: [-4468.311 -4468.311 -4468.311], critic_loss: 4058.660888671875, actor_loss: -0.12200000137090683, eps: 0.2})
Step:    8500, Reward: [-446.318 -446.318 -446.318] [82.863], Avg: [-462.477 -462.477 -462.477] (0.1811) <00:03:41> ({r_i: None, r_t: [-4459.417 -4459.417 -4459.417], critic_loss: 4355.35009765625, actor_loss: 0.14100000262260437, eps: 0.181})
Step:    9000, Reward: [-445.396 -445.396 -445.396] [80.568], Avg: [-461.578 -461.578 -461.578] (0.1638) <00:03:55> ({r_i: None, r_t: [-4350.683 -4350.683 -4350.683], critic_loss: 3904.927978515625, actor_loss: 0.41600000858306885, eps: 0.164})
Step:    9500, Reward: [-416.070 -416.070 -416.070] [102.574], Avg: [-459.302 -459.302 -459.302] (0.1481) <00:04:08> ({r_i: None, r_t: [-4185.168 -4185.168 -4185.168], critic_loss: 3539.7080078125, actor_loss: 0.4959999918937683, eps: 0.148})
Step:   10000, Reward: [-404.226 -404.226 -404.226] [65.346], Avg: [-456.680 -456.680 -456.680] (0.1340) <00:04:21> ({r_i: None, r_t: [-4153.527 -4153.527 -4153.527], critic_loss: 3378.85498046875, actor_loss: -0.3930000066757202, eps: 0.134})
Step:   10500, Reward: [-419.483 -419.483 -419.483] [67.025], Avg: [-454.989 -454.989 -454.989] (0.1212) <00:04:34> ({r_i: None, r_t: [-4149.203 -4149.203 -4149.203], critic_loss: 3112.91796875, actor_loss: 0.019999999552965164, eps: 0.121})
Step:   11000, Reward: [-406.002 -406.002 -406.002] [76.518], Avg: [-452.859 -452.859 -452.859] (0.1096) <00:04:48> ({r_i: None, r_t: [-4154.369 -4154.369 -4154.369], critic_loss: 3088.30810546875, actor_loss: 0.08799999952316284, eps: 0.11})
Step:   11500, Reward: [-459.587 -459.587 -459.587] [76.215], Avg: [-453.139 -453.139 -453.139] (0.1000) <00:05:01> ({r_i: None, r_t: [-4246.366 -4246.366 -4246.366], critic_loss: 3181.93603515625, actor_loss: -0.22599999606609344, eps: 0.1})
Step:   12000, Reward: [-427.651 -427.651 -427.651] [73.106], Avg: [-452.120 -452.120 -452.120] (0.1000) <00:05:14> ({r_i: None, r_t: [-4167.244 -4167.244 -4167.244], critic_loss: 3269.947021484375, actor_loss: -0.09300000220537186, eps: 0.1})
Step:   12500, Reward: [-407.985 -407.985 -407.985] [91.616], Avg: [-450.422 -450.422 -450.422] (0.1000) <00:05:27> ({r_i: None, r_t: [-4172.344 -4172.344 -4172.344], critic_loss: 3087.741943359375, actor_loss: -0.4099999964237213, eps: 0.1})
Step:   13000, Reward: [-393.523 -393.523 -393.523] [81.385], Avg: [-448.315 -448.315 -448.315] (0.1000) <00:05:40> ({r_i: None, r_t: [-4102.003 -4102.003 -4102.003], critic_loss: 2823.10107421875, actor_loss: 0.4390000104904175, eps: 0.1})
Step:   13500, Reward: [-431.048 -431.048 -431.048] [75.954], Avg: [-447.698 -447.698 -447.698] (0.1000) <00:05:53> ({r_i: None, r_t: [-4143.743 -4143.743 -4143.743], critic_loss: 2602.89404296875, actor_loss: -0.32499998807907104, eps: 0.1})
Step:   14000, Reward: [-407.056 -407.056 -407.056] [53.017], Avg: [-446.297 -446.297 -446.297] (0.1000) <00:06:06> ({r_i: None, r_t: [-4113.585 -4113.585 -4113.585], critic_loss: 2912.51806640625, actor_loss: 0.20200000703334808, eps: 0.1})
Step:   14500, Reward: [-412.107 -412.107 -412.107] [55.048], Avg: [-445.157 -445.157 -445.157] (0.1000) <00:06:20> ({r_i: None, r_t: [-4162.281 -4162.281 -4162.281], critic_loss: 2667.635986328125, actor_loss: 0.4099999964237213, eps: 0.1})
Step:   15000, Reward: [-395.488 -395.488 -395.488] [78.155], Avg: [-443.555 -443.555 -443.555] (0.1000) <00:06:33> ({r_i: None, r_t: [-4338.552 -4338.552 -4338.552], critic_loss: 3255.905029296875, actor_loss: 0.26100000739097595, eps: 0.1})
Step:   15500, Reward: [-425.094 -425.094 -425.094] [65.364], Avg: [-442.978 -442.978 -442.978] (0.1000) <00:06:46> ({r_i: None, r_t: [-4244.521 -4244.521 -4244.521], critic_loss: 3484.781982421875, actor_loss: -0.3610000014305115, eps: 0.1})
Step:   16000, Reward: [-422.397 -422.397 -422.397] [46.126], Avg: [-442.354 -442.354 -442.354] (0.1000) <00:07:00> ({r_i: None, r_t: [-4198.663 -4198.663 -4198.663], critic_loss: 2896.180908203125, actor_loss: -0.07900000363588333, eps: 0.1})
Step:   16500, Reward: [-395.885 -395.885 -395.885] [68.002], Avg: [-440.988 -440.988 -440.988] (0.1000) <00:07:13> ({r_i: None, r_t: [-4097.169 -4097.169 -4097.169], critic_loss: 2797.050048828125, actor_loss: -0.00800000037997961, eps: 0.1})
Step:   17000, Reward: [-427.075 -427.075 -427.075] [65.305], Avg: [-440.590 -440.590 -440.590] (0.1000) <00:07:26> ({r_i: None, r_t: [-4141.066 -4141.066 -4141.066], critic_loss: 2781.742919921875, actor_loss: -0.2370000034570694, eps: 0.1})
Step:   17500, Reward: [-396.616 -396.616 -396.616] [78.224], Avg: [-439.369 -439.369 -439.369] (0.1000) <00:07:38> ({r_i: None, r_t: [-4109.018 -4109.018 -4109.018], critic_loss: 2536.367919921875, actor_loss: 0.19300000369548798, eps: 0.1})
Step:   18000, Reward: [-410.513 -410.513 -410.513] [60.850], Avg: [-438.589 -438.589 -438.589] (0.1000) <00:07:52> ({r_i: None, r_t: [-4205.876 -4205.876 -4205.876], critic_loss: 2971.529052734375, actor_loss: -0.006000000052154064, eps: 0.1})
Step:   18500, Reward: [-420.692 -420.692 -420.692] [77.561], Avg: [-438.118 -438.118 -438.118] (0.1000) <00:08:05> ({r_i: None, r_t: [-4136.083 -4136.083 -4136.083], critic_loss: 2881.679931640625, actor_loss: 0.05400000140070915, eps: 0.1})
Step:   19000, Reward: [-409.431 -409.431 -409.431] [63.927], Avg: [-437.382 -437.382 -437.382] (0.1000) <00:08:18> ({r_i: None, r_t: [-4049.128 -4049.128 -4049.128], critic_loss: 2488.76611328125, actor_loss: -0.2529999911785126, eps: 0.1})
Step:   19500, Reward: [-392.273 -392.273 -392.273] [77.253], Avg: [-436.254 -436.254 -436.254] (0.1000) <00:08:31> ({r_i: None, r_t: [-4082.741 -4082.741 -4082.741], critic_loss: 2539.9189453125, actor_loss: 0.2849999964237213, eps: 0.1})
Step:   20000, Reward: [-402.253 -402.253 -402.253] [69.088], Avg: [-435.425 -435.425 -435.425] (0.1000) <00:08:44> ({r_i: None, r_t: [-4070.453 -4070.453 -4070.453], critic_loss: 2389.81103515625, actor_loss: 0.10700000077486038, eps: 0.1})
Step:   20500, Reward: [-415.397 -415.397 -415.397] [80.743], Avg: [-434.948 -434.948 -434.948] (0.1000) <00:08:57> ({r_i: None, r_t: [-4093.459 -4093.459 -4093.459], critic_loss: 2934.998046875, actor_loss: -0.05999999865889549, eps: 0.1})
Step:   21000, Reward: [-394.047 -394.047 -394.047] [40.741], Avg: [-433.997 -433.997 -433.997] (0.1000) <00:09:10> ({r_i: None, r_t: [-4160.561 -4160.561 -4160.561], critic_loss: 2695.1689453125, actor_loss: -0.1459999978542328, eps: 0.1})
Step:   21500, Reward: [-400.434 -400.434 -400.434] [69.750], Avg: [-433.234 -433.234 -433.234] (0.1000) <00:09:23> ({r_i: None, r_t: [-4091.012 -4091.012 -4091.012], critic_loss: 2910.882080078125, actor_loss: 0.15600000321865082, eps: 0.1})
Step:   22000, Reward: [-404.833 -404.833 -404.833] [70.457], Avg: [-432.603 -432.603 -432.603] (0.1000) <00:09:37> ({r_i: None, r_t: [-4064.432 -4064.432 -4064.432], critic_loss: 2820.5, actor_loss: -0.30799999833106995, eps: 0.1})
Step:   22500, Reward: [-368.581 -368.581 -368.581] [38.525], Avg: [-431.211 -431.211 -431.211] (0.1000) <00:09:49> ({r_i: None, r_t: [-3950.230 -3950.230 -3950.230], critic_loss: 2578.404052734375, actor_loss: -0.06199999898672104, eps: 0.1})
Step:   23000, Reward: [-411.921 -411.921 -411.921] [81.287], Avg: [-430.801 -430.801 -430.801] (0.1000) <00:10:02> ({r_i: None, r_t: [-4049.608 -4049.608 -4049.608], critic_loss: 2530.73388671875, actor_loss: 0.0560000017285347, eps: 0.1})
Step:   23500, Reward: [-402.140 -402.140 -402.140] [63.432], Avg: [-430.204 -430.204 -430.204] (0.1000) <00:10:15> ({r_i: None, r_t: [-4056.016 -4056.016 -4056.016], critic_loss: 2819.43603515625, actor_loss: 0.012000000104308128, eps: 0.1})
Step:   24000, Reward: [-382.707 -382.707 -382.707] [71.355], Avg: [-429.234 -429.234 -429.234] (0.1000) <00:10:28> ({r_i: None, r_t: [-4196.511 -4196.511 -4196.511], critic_loss: 2773.181884765625, actor_loss: 0.2160000056028366, eps: 0.1})
Step:   24500, Reward: [-394.943 -394.943 -394.943] [65.323], Avg: [-428.549 -428.549 -428.549] (0.1000) <00:10:41> ({r_i: None, r_t: [-4106.856 -4106.856 -4106.856], critic_loss: 2779.654052734375, actor_loss: 0.032999999821186066, eps: 0.1})
Step:   25000, Reward: [-414.960 -414.960 -414.960] [77.038], Avg: [-428.282 -428.282 -428.282] (0.1000) <00:10:54> ({r_i: None, r_t: [-3983.456 -3983.456 -3983.456], critic_loss: 2489.4560546875, actor_loss: -0.008999999612569809, eps: 0.1})
Step:   25500, Reward: [-421.249 -421.249 -421.249] [64.304], Avg: [-428.147 -428.147 -428.147] (0.1000) <00:11:07> ({r_i: None, r_t: [-3970.652 -3970.652 -3970.652], critic_loss: 2479.660888671875, actor_loss: -0.18199999630451202, eps: 0.1})
Step:   26000, Reward: [-420.632 -420.632 -420.632] [93.054], Avg: [-428.005 -428.005 -428.005] (0.1000) <00:11:21> ({r_i: None, r_t: [-4024.600 -4024.600 -4024.600], critic_loss: 2494.74609375, actor_loss: 0.04399999976158142, eps: 0.1})
Step:   26500, Reward: [-399.129 -399.129 -399.129] [79.552], Avg: [-427.470 -427.470 -427.470] (0.1000) <00:11:34> ({r_i: None, r_t: [-4013.813 -4013.813 -4013.813], critic_loss: 2391.469970703125, actor_loss: -0.17100000381469727, eps: 0.1})
Step:   27000, Reward: [-395.996 -395.996 -395.996] [76.801], Avg: [-426.898 -426.898 -426.898] (0.1000) <00:11:47> ({r_i: None, r_t: [-4081.786 -4081.786 -4081.786], critic_loss: 2821.635986328125, actor_loss: -0.1850000023841858, eps: 0.1})
Step:   27500, Reward: [-391.971 -391.971 -391.971] [43.862], Avg: [-426.274 -426.274 -426.274] (0.1000) <00:12:00> ({r_i: None, r_t: [-4061.271 -4061.271 -4061.271], critic_loss: 2489.05908203125, actor_loss: -0.13899999856948853, eps: 0.1})
Step:   28000, Reward: [-381.315 -381.315 -381.315] [71.054], Avg: [-425.486 -425.486 -425.486] (0.1000) <00:12:13> ({r_i: None, r_t: [-3969.522 -3969.522 -3969.522], critic_loss: 2364.906982421875, actor_loss: -0.09099999815225601, eps: 0.1})
Step:   28500, Reward: [-395.221 -395.221 -395.221] [69.502], Avg: [-424.964 -424.964 -424.964] (0.1000) <00:12:27> ({r_i: None, r_t: [-4040.647 -4040.647 -4040.647], critic_loss: 2522.7041015625, actor_loss: 0.18000000715255737, eps: 0.1})
Step:   29000, Reward: [-401.017 -401.017 -401.017] [75.685], Avg: [-424.558 -424.558 -424.558] (0.1000) <00:12:40> ({r_i: None, r_t: [-3986.426 -3986.426 -3986.426], critic_loss: 2347.946044921875, actor_loss: 0.19300000369548798, eps: 0.1})
Step:   29500, Reward: [-381.544 -381.544 -381.544] [57.420], Avg: [-423.841 -423.841 -423.841] (0.1000) <00:12:53> ({r_i: None, r_t: [-4118.278 -4118.278 -4118.278], critic_loss: 2741.2529296875, actor_loss: -0.20399999618530273, eps: 0.1})
Step:   30000, Reward: [-412.072 -412.072 -412.072] [70.773], Avg: [-423.648 -423.648 -423.648] (0.1000) <00:13:05> ({r_i: None, r_t: [-4100.541 -4100.541 -4100.541], critic_loss: 2581.672119140625, actor_loss: 0.11999999731779099, eps: 0.1})
Step:   30500, Reward: [-419.879 -419.879 -419.879] [89.797], Avg: [-423.587 -423.587 -423.587] (0.1000) <00:13:19> ({r_i: None, r_t: [-3949.538 -3949.538 -3949.538], critic_loss: 2273.64111328125, actor_loss: -0.25200000405311584, eps: 0.1})
Step:   31000, Reward: [-430.570 -430.570 -430.570] [70.002], Avg: [-423.698 -423.698 -423.698] (0.1000) <00:13:32> ({r_i: None, r_t: [-4078.864 -4078.864 -4078.864], critic_loss: 2225.052978515625, actor_loss: -0.17399999499320984, eps: 0.1})
Step:   31500, Reward: [-432.308 -432.308 -432.308] [64.944], Avg: [-423.833 -423.833 -423.833] (0.1000) <00:13:45> ({r_i: None, r_t: [-4071.641 -4071.641 -4071.641], critic_loss: 2515.7939453125, actor_loss: -0.06300000101327896, eps: 0.1})
Step:   32000, Reward: [-410.735 -410.735 -410.735] [58.479], Avg: [-423.631 -423.631 -423.631] (0.1000) <00:13:58> ({r_i: None, r_t: [-4143.106 -4143.106 -4143.106], critic_loss: 2830.237060546875, actor_loss: -0.020999999716877937, eps: 0.1})
Step:   32500, Reward: [-402.940 -402.940 -402.940] [75.058], Avg: [-423.318 -423.318 -423.318] (0.1000) <00:14:10> ({r_i: None, r_t: [-4128.918 -4128.918 -4128.918], critic_loss: 2709.805908203125, actor_loss: 0.054999999701976776, eps: 0.1})
Step:   33000, Reward: [-425.588 -425.588 -425.588] [59.363], Avg: [-423.352 -423.352 -423.352] (0.1000) <00:14:24> ({r_i: None, r_t: [-3974.705 -3974.705 -3974.705], critic_loss: 2325.2109375, actor_loss: 0.37400001287460327, eps: 0.1})
Step:   33500, Reward: [-416.402 -416.402 -416.402] [91.772], Avg: [-423.249 -423.249 -423.249] (0.1000) <00:14:37> ({r_i: None, r_t: [-4140.707 -4140.707 -4140.707], critic_loss: 2383.673095703125, actor_loss: -0.0430000014603138, eps: 0.1})
Step:   34000, Reward: [-380.507 -380.507 -380.507] [40.782], Avg: [-422.630 -422.630 -422.630] (0.1000) <00:14:50> ({r_i: None, r_t: [-3948.503 -3948.503 -3948.503], critic_loss: 2431.9541015625, actor_loss: -0.2160000056028366, eps: 0.1})
Step:   34500, Reward: [-369.726 -369.726 -369.726] [52.044], Avg: [-421.874 -421.874 -421.874] (0.1000) <00:15:03> ({r_i: None, r_t: [-4088.100 -4088.100 -4088.100], critic_loss: 2736.117919921875, actor_loss: -0.33899998664855957, eps: 0.1})
Step:   35000, Reward: [-387.890 -387.890 -387.890] [70.135], Avg: [-421.396 -421.396 -421.396] (0.1000) <00:15:16> ({r_i: None, r_t: [-4054.413 -4054.413 -4054.413], critic_loss: 2540.052001953125, actor_loss: -0.23600000143051147, eps: 0.1})
Step:   35500, Reward: [-384.079 -384.079 -384.079] [43.636], Avg: [-420.877 -420.877 -420.877] (0.1000) <00:15:29> ({r_i: None, r_t: [-4118.009 -4118.009 -4118.009], critic_loss: 2852.945068359375, actor_loss: 0.27399998903274536, eps: 0.1})
Step:   36000, Reward: [-381.918 -381.918 -381.918] [75.799], Avg: [-420.344 -420.344 -420.344] (0.1000) <00:15:42> ({r_i: None, r_t: [-4098.694 -4098.694 -4098.694], critic_loss: 2764.89990234375, actor_loss: 0.03799999877810478, eps: 0.1})
Step:   36500, Reward: [-399.782 -399.782 -399.782] [69.123], Avg: [-420.066 -420.066 -420.066] (0.1000) <00:15:55> ({r_i: None, r_t: [-4101.274 -4101.274 -4101.274], critic_loss: 2595.988037109375, actor_loss: 0.6779999732971191, eps: 0.1})
Step:   37000, Reward: [-414.686 -414.686 -414.686] [98.265], Avg: [-419.994 -419.994 -419.994] (0.1000) <00:16:09> ({r_i: None, r_t: [-3978.368 -3978.368 -3978.368], critic_loss: 2461.285888671875, actor_loss: 0.10400000214576721, eps: 0.1})
Step:   37500, Reward: [-381.377 -381.377 -381.377] [68.325], Avg: [-419.486 -419.486 -419.486] (0.1000) <00:16:22> ({r_i: None, r_t: [-3996.863 -3996.863 -3996.863], critic_loss: 2447.27392578125, actor_loss: 0.210999995470047, eps: 0.1})
Step:   38000, Reward: [-408.635 -408.635 -408.635] [75.320], Avg: [-419.345 -419.345 -419.345] (0.1000) <00:16:35> ({r_i: None, r_t: [-3975.686 -3975.686 -3975.686], critic_loss: 2374.693115234375, actor_loss: 0.05400000140070915, eps: 0.1})
Step:   38500, Reward: [-415.409 -415.409 -415.409] [86.198], Avg: [-419.294 -419.294 -419.294] (0.1000) <00:16:48> ({r_i: None, r_t: [-4044.121 -4044.121 -4044.121], critic_loss: 2589.528076171875, actor_loss: -0.03099999949336052, eps: 0.1})
Step:   39000, Reward: [-431.403 -431.403 -431.403] [92.424], Avg: [-419.448 -419.448 -419.448] (0.1000) <00:17:02> ({r_i: None, r_t: [-3997.102 -3997.102 -3997.102], critic_loss: 2333.820068359375, actor_loss: 0.06499999761581421, eps: 0.1})
Step:   39500, Reward: [-373.561 -373.561 -373.561] [75.942], Avg: [-418.874 -418.874 -418.874] (0.1000) <00:17:15> ({r_i: None, r_t: [-4121.793 -4121.793 -4121.793], critic_loss: 2448.548095703125, actor_loss: 0.09000000357627869, eps: 0.1})
Step:   40000, Reward: [-412.622 -412.622 -412.622] [56.575], Avg: [-418.797 -418.797 -418.797] (0.1000) <00:17:28> ({r_i: None, r_t: [-4045.813 -4045.813 -4045.813], critic_loss: 2733.134033203125, actor_loss: 0.22100000083446503, eps: 0.1})
Step:   40500, Reward: [-408.010 -408.010 -408.010] [77.273], Avg: [-418.665 -418.665 -418.665] (0.1000) <00:17:41> ({r_i: None, r_t: [-3927.763 -3927.763 -3927.763], critic_loss: 2563.2490234375, actor_loss: -0.050999999046325684, eps: 0.1})
Step:   41000, Reward: [-399.794 -399.794 -399.794] [55.385], Avg: [-418.438 -418.438 -418.438] (0.1000) <00:17:54> ({r_i: None, r_t: [-4078.193 -4078.193 -4078.193], critic_loss: 2580.85400390625, actor_loss: -0.07599999755620956, eps: 0.1})
Step:   41500, Reward: [-421.410 -421.410 -421.410] [69.732], Avg: [-418.473 -418.473 -418.473] (0.1000) <00:18:08> ({r_i: None, r_t: [-4081.109 -4081.109 -4081.109], critic_loss: 2547.468994140625, actor_loss: -0.03200000151991844, eps: 0.1})
Step:   42000, Reward: [-389.637 -389.637 -389.637] [79.984], Avg: [-418.134 -418.134 -418.134] (0.1000) <00:18:21> ({r_i: None, r_t: [-4024.044 -4024.044 -4024.044], critic_loss: 2313.407958984375, actor_loss: 0.023000000044703484, eps: 0.1})
Step:   42500, Reward: [-409.417 -409.417 -409.417] [87.506], Avg: [-418.033 -418.033 -418.033] (0.1000) <00:18:34> ({r_i: None, r_t: [-3965.163 -3965.163 -3965.163], critic_loss: 2416.64990234375, actor_loss: -0.13300000131130219, eps: 0.1})
Step:   43000, Reward: [-405.031 -405.031 -405.031] [58.017], Avg: [-417.883 -417.883 -417.883] (0.1000) <00:18:47> ({r_i: None, r_t: [-4123.534 -4123.534 -4123.534], critic_loss: 2649.89794921875, actor_loss: -0.14499999582767487, eps: 0.1})
Step:   43500, Reward: [-388.916 -388.916 -388.916] [70.216], Avg: [-417.554 -417.554 -417.554] (0.1000) <00:19:00> ({r_i: None, r_t: [-4039.812 -4039.812 -4039.812], critic_loss: 2732.6689453125, actor_loss: -0.20499999821186066, eps: 0.1})
Step:   44000, Reward: [-378.719 -378.719 -378.719] [54.240], Avg: [-417.118 -417.118 -417.118] (0.1000) <00:19:13> ({r_i: None, r_t: [-4008.085 -4008.085 -4008.085], critic_loss: 2708.951904296875, actor_loss: -0.35600000619888306, eps: 0.1})
Step:   44500, Reward: [-382.292 -382.292 -382.292] [76.635], Avg: [-416.731 -416.731 -416.731] (0.1000) <00:19:26> ({r_i: None, r_t: [-3950.442 -3950.442 -3950.442], critic_loss: 2482.8701171875, actor_loss: -0.07999999821186066, eps: 0.1})
Step:   45000, Reward: [-407.497 -407.497 -407.497] [80.552], Avg: [-416.629 -416.629 -416.629] (0.1000) <00:19:39> ({r_i: None, r_t: [-4118.135 -4118.135 -4118.135], critic_loss: 2668.79296875, actor_loss: -0.07599999755620956, eps: 0.1})
Step:   45500, Reward: [-398.407 -398.407 -398.407] [83.164], Avg: [-416.431 -416.431 -416.431] (0.1000) <00:19:53> ({r_i: None, r_t: [-4111.789 -4111.789 -4111.789], critic_loss: 2813.64404296875, actor_loss: 0.30000001192092896, eps: 0.1})
Step:   46000, Reward: [-406.736 -406.736 -406.736] [63.030], Avg: [-416.327 -416.327 -416.327] (0.1000) <00:20:06> ({r_i: None, r_t: [-4085.801 -4085.801 -4085.801], critic_loss: 2614.342041015625, actor_loss: 0.19900000095367432, eps: 0.1})
Step:   46500, Reward: [-406.841 -406.841 -406.841] [76.096], Avg: [-416.226 -416.226 -416.226] (0.1000) <00:20:19> ({r_i: None, r_t: [-3991.180 -3991.180 -3991.180], critic_loss: 2758.739013671875, actor_loss: -0.0020000000949949026, eps: 0.1})
Step:   47000, Reward: [-401.670 -401.670 -401.670] [64.073], Avg: [-416.073 -416.073 -416.073] (0.1000) <00:20:32> ({r_i: None, r_t: [-4059.366 -4059.366 -4059.366], critic_loss: 2836.75390625, actor_loss: -0.3179999887943268, eps: 0.1})
Step:   47500, Reward: [-411.958 -411.958 -411.958] [58.013], Avg: [-416.030 -416.030 -416.030] (0.1000) <00:20:45> ({r_i: None, r_t: [-4018.181 -4018.181 -4018.181], critic_loss: 2381.679931640625, actor_loss: -0.03799999877810478, eps: 0.1})
Step:   48000, Reward: [-379.675 -379.675 -379.675] [42.982], Avg: [-415.655 -415.655 -415.655] (0.1000) <00:20:59> ({r_i: None, r_t: [-3995.200 -3995.200 -3995.200], critic_loss: 2697.60693359375, actor_loss: -0.382999986410141, eps: 0.1})
Step:   48500, Reward: [-405.547 -405.547 -405.547] [85.242], Avg: [-415.552 -415.552 -415.552] (0.1000) <00:21:12> ({r_i: None, r_t: [-4145.137 -4145.137 -4145.137], critic_loss: 2983.751953125, actor_loss: -0.7310000061988831, eps: 0.1})
Step:   49000, Reward: [-415.829 -415.829 -415.829] [49.393], Avg: [-415.555 -415.555 -415.555] (0.1000) <00:21:25> ({r_i: None, r_t: [-4086.245 -4086.245 -4086.245], critic_loss: 2727.597900390625, actor_loss: -0.13699999451637268, eps: 0.1})
Step:   49500, Reward: [-431.000 -431.000 -431.000] [89.631], Avg: [-415.709 -415.709 -415.709] (0.1000) <00:21:38> ({r_i: None, r_t: [-4081.334 -4081.334 -4081.334], critic_loss: 2987.535888671875, actor_loss: 0.3490000069141388, eps: 0.1})
Step:   50000, Reward: [-409.097 -409.097 -409.097] [78.993], Avg: [-415.644 -415.644 -415.644] (0.1000) <00:21:51> ({r_i: None, r_t: [-4190.012 -4190.012 -4190.012], critic_loss: 3003.19189453125, actor_loss: 0.012000000104308128, eps: 0.1})
Step:   50500, Reward: [-397.955 -397.955 -397.955] [62.380], Avg: [-415.471 -415.471 -415.471] (0.1000) <00:22:04> ({r_i: None, r_t: [-4019.197 -4019.197 -4019.197], critic_loss: 2694.764892578125, actor_loss: -0.15600000321865082, eps: 0.1})
Step:   51000, Reward: [-403.247 -403.247 -403.247] [52.122], Avg: [-415.352 -415.352 -415.352] (0.1000) <00:22:17> ({r_i: None, r_t: [-4178.162 -4178.162 -4178.162], critic_loss: 2646.68603515625, actor_loss: -0.057999998331069946, eps: 0.1})
Step:   51500, Reward: [-416.885 -416.885 -416.885] [69.558], Avg: [-415.367 -415.367 -415.367] (0.1000) <00:22:31> ({r_i: None, r_t: [-4073.930 -4073.930 -4073.930], critic_loss: 2807.5, actor_loss: 0.2529999911785126, eps: 0.1})
Step:   52000, Reward: [-395.820 -395.820 -395.820] [49.161], Avg: [-415.180 -415.180 -415.180] (0.1000) <00:22:43> ({r_i: None, r_t: [-4019.958 -4019.958 -4019.958], critic_loss: 2677.095947265625, actor_loss: -0.33399999141693115, eps: 0.1})
Step:   52500, Reward: [-371.586 -371.586 -371.586] [54.760], Avg: [-414.769 -414.769 -414.769] (0.1000) <00:22:57> ({r_i: None, r_t: [-4066.584 -4066.584 -4066.584], critic_loss: 3045.35302734375, actor_loss: 0.5410000085830688, eps: 0.1})
Step:   53000, Reward: [-392.823 -392.823 -392.823] [50.896], Avg: [-414.564 -414.564 -414.564] (0.1000) <00:23:10> ({r_i: None, r_t: [-3974.764 -3974.764 -3974.764], critic_loss: 2568.486083984375, actor_loss: -0.04699999839067459, eps: 0.1})
Step:   53500, Reward: [-402.626 -402.626 -402.626] [63.526], Avg: [-414.454 -414.454 -414.454] (0.1000) <00:23:23> ({r_i: None, r_t: [-4027.509 -4027.509 -4027.509], critic_loss: 2790.341064453125, actor_loss: -0.03099999949336052, eps: 0.1})
Step:   54000, Reward: [-386.019 -386.019 -386.019] [79.149], Avg: [-414.193 -414.193 -414.193] (0.1000) <00:23:37> ({r_i: None, r_t: [-4176.595 -4176.595 -4176.595], critic_loss: 2986.697998046875, actor_loss: -0.1940000057220459, eps: 0.1})
Step:   54500, Reward: [-386.781 -386.781 -386.781] [84.922], Avg: [-413.943 -413.943 -413.943] (0.1000) <00:23:50> ({r_i: None, r_t: [-4033.966 -4033.966 -4033.966], critic_loss: 2757.300048828125, actor_loss: -0.10199999809265137, eps: 0.1})
Step:   55000, Reward: [-438.176 -438.176 -438.176] [99.938], Avg: [-414.162 -414.162 -414.162] (0.1000) <00:24:02> ({r_i: None, r_t: [-3840.191 -3840.191 -3840.191], critic_loss: 2505.35400390625, actor_loss: -0.35499998927116394, eps: 0.1})
Step:   55500, Reward: [-393.069 -393.069 -393.069] [83.124], Avg: [-413.973 -413.973 -413.973] (0.1000) <00:24:15> ({r_i: None, r_t: [-3954.519 -3954.519 -3954.519], critic_loss: 2551.260009765625, actor_loss: -0.2809999883174896, eps: 0.1})
Step:   56000, Reward: [-399.165 -399.165 -399.165] [74.773], Avg: [-413.842 -413.842 -413.842] (0.1000) <00:24:28> ({r_i: None, r_t: [-3961.664 -3961.664 -3961.664], critic_loss: 2679.177001953125, actor_loss: -0.6060000061988831, eps: 0.1})
Step:   56500, Reward: [-452.430 -452.430 -452.430] [86.992], Avg: [-414.181 -414.181 -414.181] (0.1000) <00:24:41> ({r_i: None, r_t: [-4226.114 -4226.114 -4226.114], critic_loss: 2711.2119140625, actor_loss: -0.30300000309944153, eps: 0.1})
Step:   57000, Reward: [-458.357 -458.357 -458.357] [95.279], Avg: [-414.565 -414.565 -414.565] (0.1000) <00:24:55> ({r_i: None, r_t: [-4299.345 -4299.345 -4299.345], critic_loss: 3348.281982421875, actor_loss: -0.25999999046325684, eps: 0.1})
Step:   57500, Reward: [-416.907 -416.907 -416.907] [75.352], Avg: [-414.585 -414.585 -414.585] (0.1000) <00:25:07> ({r_i: None, r_t: [-4360.306 -4360.306 -4360.306], critic_loss: 3958.00390625, actor_loss: 0.024000000208616257, eps: 0.1})
Step:   58000, Reward: [-474.924 -474.924 -474.924] [116.421], Avg: [-415.101 -415.101 -415.101] (0.1000) <00:25:20> ({r_i: None, r_t: [-4261.804 -4261.804 -4261.804], critic_loss: 4025.56689453125, actor_loss: -0.21199999749660492, eps: 0.1})
Step:   58500, Reward: [-453.305 -453.305 -453.305] [86.173], Avg: [-415.425 -415.425 -415.425] (0.1000) <00:25:33> ({r_i: None, r_t: [-4440.036 -4440.036 -4440.036], critic_loss: 3864.031005859375, actor_loss: 0.25999999046325684, eps: 0.1})
Step:   59000, Reward: [-420.520 -420.520 -420.520] [71.002], Avg: [-415.468 -415.468 -415.468] (0.1000) <00:25:46> ({r_i: None, r_t: [-4342.824 -4342.824 -4342.824], critic_loss: 4047.89990234375, actor_loss: 0.17000000178813934, eps: 0.1})
Step:   59500, Reward: [-454.813 -454.813 -454.813] [99.431], Avg: [-415.795 -415.795 -415.795] (0.1000) <00:26:00> ({r_i: None, r_t: [-4157.249 -4157.249 -4157.249], critic_loss: 3917.248046875, actor_loss: 0.5619999766349792, eps: 0.1})
Step:   60000, Reward: [-439.201 -439.201 -439.201] [71.830], Avg: [-415.989 -415.989 -415.989] (0.1000) <00:26:13> ({r_i: None, r_t: [-4188.416 -4188.416 -4188.416], critic_loss: 3807.58203125, actor_loss: -0.07000000029802322, eps: 0.1})
Step:   60500, Reward: [-440.741 -440.741 -440.741] [97.320], Avg: [-416.192 -416.192 -416.192] (0.1000) <00:26:26> ({r_i: None, r_t: [-4217.259 -4217.259 -4217.259], critic_loss: 3318.071044921875, actor_loss: -0.11999999731779099, eps: 0.1})
Step:   61000, Reward: [-405.361 -405.361 -405.361] [52.936], Avg: [-416.104 -416.104 -416.104] (0.1000) <00:26:39> ({r_i: None, r_t: [-4393.987 -4393.987 -4393.987], critic_loss: 3817.5859375, actor_loss: 0.25099998712539673, eps: 0.1})
Step:   61500, Reward: [-419.644 -419.644 -419.644] [79.534], Avg: [-416.132 -416.132 -416.132] (0.1000) <00:26:53> ({r_i: None, r_t: [-4355.306 -4355.306 -4355.306], critic_loss: 4219.86376953125, actor_loss: -0.36899998784065247, eps: 0.1})
Step:   62000, Reward: [-460.840 -460.840 -460.840] [85.311], Avg: [-416.490 -416.490 -416.490] (0.1000) <00:27:05> ({r_i: None, r_t: [-4312.804 -4312.804 -4312.804], critic_loss: 3903.510986328125, actor_loss: 0.2669999897480011, eps: 0.1})
Step:   62500, Reward: [-444.943 -444.943 -444.943] [89.172], Avg: [-416.716 -416.716 -416.716] (0.1000) <00:27:19> ({r_i: None, r_t: [-4325.186 -4325.186 -4325.186], critic_loss: 3971.467041015625, actor_loss: 0.2720000147819519, eps: 0.1})
Step:   63000, Reward: [-439.835 -439.835 -439.835] [99.358], Avg: [-416.898 -416.898 -416.898] (0.1000) <00:27:32> ({r_i: None, r_t: [-4356.948 -4356.948 -4356.948], critic_loss: 4125.6279296875, actor_loss: -0.2409999966621399, eps: 0.1})
Step:   63500, Reward: [-447.921 -447.921 -447.921] [91.063], Avg: [-417.140 -417.140 -417.140] (0.1000) <00:27:45> ({r_i: None, r_t: [-4325.706 -4325.706 -4325.706], critic_loss: 4176.18017578125, actor_loss: 0.03400000184774399, eps: 0.1})
Step:   64000, Reward: [-467.259 -467.259 -467.259] [72.330], Avg: [-417.529 -417.529 -417.529] (0.1000) <00:27:58> ({r_i: None, r_t: [-4430.095 -4430.095 -4430.095], critic_loss: 3848.675048828125, actor_loss: 0.6060000061988831, eps: 0.1})
Step:   64500, Reward: [-412.593 -412.593 -412.593] [63.812], Avg: [-417.491 -417.491 -417.491] (0.1000) <00:28:11> ({r_i: None, r_t: [-4293.468 -4293.468 -4293.468], critic_loss: 4311.73779296875, actor_loss: 0.27799999713897705, eps: 0.1})
Step:   65000, Reward: [-430.382 -430.382 -430.382] [94.045], Avg: [-417.589 -417.589 -417.589] (0.1000) <00:28:24> ({r_i: None, r_t: [-4484.028 -4484.028 -4484.028], critic_loss: 4047.257080078125, actor_loss: 0.25200000405311584, eps: 0.1})
Step:   65500, Reward: [-452.596 -452.596 -452.596] [82.735], Avg: [-417.854 -417.854 -417.854] (0.1000) <00:28:37> ({r_i: None, r_t: [-4286.968 -4286.968 -4286.968], critic_loss: 4198.18603515625, actor_loss: -0.382999986410141, eps: 0.1})
Step:   66000, Reward: [-444.763 -444.763 -444.763] [100.762], Avg: [-418.057 -418.057 -418.057] (0.1000) <00:28:50> ({r_i: None, r_t: [-4288.545 -4288.545 -4288.545], critic_loss: 3776.111083984375, actor_loss: -0.08500000089406967, eps: 0.1})
Step:   66500, Reward: [-436.681 -436.681 -436.681] [66.276], Avg: [-418.196 -418.196 -418.196] (0.1000) <00:29:03> ({r_i: None, r_t: [-4284.573 -4284.573 -4284.573], critic_loss: 3975.675048828125, actor_loss: 0.734000027179718, eps: 0.1})
Step:   67000, Reward: [-419.482 -419.482 -419.482] [62.349], Avg: [-418.205 -418.205 -418.205] (0.1000) <00:29:16> ({r_i: None, r_t: [-4234.585 -4234.585 -4234.585], critic_loss: 3808.922119140625, actor_loss: 0.039000000804662704, eps: 0.1})
Step:   67500, Reward: [-410.230 -410.230 -410.230] [86.090], Avg: [-418.146 -418.146 -418.146] (0.1000) <00:29:29> ({r_i: None, r_t: [-4265.286 -4265.286 -4265.286], critic_loss: 3851.654052734375, actor_loss: 0.004999999888241291, eps: 0.1})
Step:   68000, Reward: [-432.300 -432.300 -432.300] [58.400], Avg: [-418.250 -418.250 -418.250] (0.1000) <00:29:42> ({r_i: None, r_t: [-4282.628 -4282.628 -4282.628], critic_loss: 3856.84912109375, actor_loss: 0.008999999612569809, eps: 0.1})
Step:   68500, Reward: [-444.892 -444.892 -444.892] [93.436], Avg: [-418.443 -418.443 -418.443] (0.1000) <00:29:55> ({r_i: None, r_t: [-4405.010 -4405.010 -4405.010], critic_loss: 4166.953125, actor_loss: 0.07500000298023224, eps: 0.1})
Step:   69000, Reward: [-430.999 -430.999 -430.999] [102.726], Avg: [-418.533 -418.533 -418.533] (0.1000) <00:30:08> ({r_i: None, r_t: [-4290.553 -4290.553 -4290.553], critic_loss: 4337.31982421875, actor_loss: 0.27799999713897705, eps: 0.1})
Step:   69500, Reward: [-417.907 -417.907 -417.907] [75.649], Avg: [-418.529 -418.529 -418.529] (0.1000) <00:30:22> ({r_i: None, r_t: [-4413.786 -4413.786 -4413.786], critic_loss: 4236.6201171875, actor_loss: 0.18000000715255737, eps: 0.1})
Step:   70000, Reward: [-501.024 -501.024 -501.024] [116.137], Avg: [-419.114 -419.114 -419.114] (0.1000) <00:30:35> ({r_i: None, r_t: [-4274.870 -4274.870 -4274.870], critic_loss: 4113.10498046875, actor_loss: 0.18000000715255737, eps: 0.1})
Step:   70500, Reward: [-425.190 -425.190 -425.190] [94.128], Avg: [-419.157 -419.157 -419.157] (0.1000) <00:30:48> ({r_i: None, r_t: [-4421.423 -4421.423 -4421.423], critic_loss: 4485.6669921875, actor_loss: 0.003000000026077032, eps: 0.1})
Step:   71000, Reward: [-451.834 -451.834 -451.834] [127.257], Avg: [-419.385 -419.385 -419.385] (0.1000) <00:31:01> ({r_i: None, r_t: [-4383.589 -4383.589 -4383.589], critic_loss: 4818.76806640625, actor_loss: 0.17800000309944153, eps: 0.1})
Step:   71500, Reward: [-424.893 -424.893 -424.893] [77.086], Avg: [-419.423 -419.423 -419.423] (0.1000) <00:31:14> ({r_i: None, r_t: [-4341.703 -4341.703 -4341.703], critic_loss: 4363.51220703125, actor_loss: -0.27399998903274536, eps: 0.1})
Step:   72000, Reward: [-488.420 -488.420 -488.420] [134.883], Avg: [-419.899 -419.899 -419.899] (0.1000) <00:31:27> ({r_i: None, r_t: [-4307.339 -4307.339 -4307.339], critic_loss: 4650.14404296875, actor_loss: -0.6320000290870667, eps: 0.1})
Step:   72500, Reward: [-426.576 -426.576 -426.576] [131.750], Avg: [-419.945 -419.945 -419.945] (0.1000) <00:31:40> ({r_i: None, r_t: [-4432.249 -4432.249 -4432.249], critic_loss: 4647.7451171875, actor_loss: 0.19499999284744263, eps: 0.1})
Step:   73000, Reward: [-448.178 -448.178 -448.178] [80.007], Avg: [-420.137 -420.137 -420.137] (0.1000) <00:31:53> ({r_i: None, r_t: [-4582.669 -4582.669 -4582.669], critic_loss: 4793.0859375, actor_loss: 0.0729999989271164, eps: 0.1})
Step:   73500, Reward: [-417.234 -417.234 -417.234] [49.546], Avg: [-420.117 -420.117 -420.117] (0.1000) <00:32:06> ({r_i: None, r_t: [-4501.677 -4501.677 -4501.677], critic_loss: 5112.25, actor_loss: -0.5180000066757202, eps: 0.1})
Step:   74000, Reward: [-443.253 -443.253 -443.253] [82.106], Avg: [-420.273 -420.273 -420.273] (0.1000) <00:32:19> ({r_i: None, r_t: [-4316.547 -4316.547 -4316.547], critic_loss: 4773.64794921875, actor_loss: -0.041999999433755875, eps: 0.1})
Step:   74500, Reward: [-478.749 -478.749 -478.749] [104.818], Avg: [-420.662 -420.662 -420.662] (0.1000) <00:32:32> ({r_i: None, r_t: [-4412.486 -4412.486 -4412.486], critic_loss: 4479.16796875, actor_loss: 0.421999990940094, eps: 0.1})
Step:   75000, Reward: [-471.014 -471.014 -471.014] [81.867], Avg: [-420.996 -420.996 -420.996] (0.1000) <00:32:45> ({r_i: None, r_t: [-4333.936 -4333.936 -4333.936], critic_loss: 4574.5380859375, actor_loss: -0.14499999582767487, eps: 0.1})
Step:   75500, Reward: [-435.716 -435.716 -435.716] [92.970], Avg: [-421.093 -421.093 -421.093] (0.1000) <00:32:58> ({r_i: None, r_t: [-4424.943 -4424.943 -4424.943], critic_loss: 4561.14794921875, actor_loss: 0.4230000078678131, eps: 0.1})
Step:   76000, Reward: [-466.644 -466.644 -466.644] [115.596], Avg: [-421.390 -421.390 -421.390] (0.1000) <00:33:11> ({r_i: None, r_t: [-4439.841 -4439.841 -4439.841], critic_loss: 4611.23779296875, actor_loss: 0.7289999723434448, eps: 0.1})
Step:   76500, Reward: [-429.510 -429.510 -429.510] [96.575], Avg: [-421.443 -421.443 -421.443] (0.1000) <00:33:24> ({r_i: None, r_t: [-4336.403 -4336.403 -4336.403], critic_loss: 4508.35400390625, actor_loss: 0.17599999904632568, eps: 0.1})
Step:   77000, Reward: [-468.206 -468.206 -468.206] [113.037], Avg: [-421.745 -421.745 -421.745] (0.1000) <00:33:37> ({r_i: None, r_t: [-4315.294 -4315.294 -4315.294], critic_loss: 4557.2548828125, actor_loss: 0.4230000078678131, eps: 0.1})
Step:   77500, Reward: [-434.467 -434.467 -434.467] [81.598], Avg: [-421.826 -421.826 -421.826] (0.1000) <00:33:50> ({r_i: None, r_t: [-4571.095 -4571.095 -4571.095], critic_loss: 4998.5361328125, actor_loss: 0.26600000262260437, eps: 0.1})
Step:   78000, Reward: [-440.765 -440.765 -440.765] [90.537], Avg: [-421.947 -421.947 -421.947] (0.1000) <00:34:03> ({r_i: None, r_t: [-4356.961 -4356.961 -4356.961], critic_loss: 4612.43212890625, actor_loss: -0.050999999046325684, eps: 0.1})
Step:   78500, Reward: [-416.376 -416.376 -416.376] [77.669], Avg: [-421.912 -421.912 -421.912] (0.1000) <00:34:16> ({r_i: None, r_t: [-4429.127 -4429.127 -4429.127], critic_loss: 5017.8232421875, actor_loss: 0.2809999883174896, eps: 0.1})
Step:   79000, Reward: [-452.429 -452.429 -452.429] [71.415], Avg: [-422.104 -422.104 -422.104] (0.1000) <00:34:29> ({r_i: None, r_t: [-4355.280 -4355.280 -4355.280], critic_loss: 4887.3681640625, actor_loss: -0.07400000095367432, eps: 0.1})
Step:   79500, Reward: [-473.802 -473.802 -473.802] [116.309], Avg: [-422.427 -422.427 -422.427] (0.1000) <00:34:42> ({r_i: None, r_t: [-4431.807 -4431.807 -4431.807], critic_loss: 4809.06396484375, actor_loss: 0.10100000351667404, eps: 0.1})
Step:   80000, Reward: [-479.410 -479.410 -479.410] [102.967], Avg: [-422.781 -422.781 -422.781] (0.1000) <00:34:55> ({r_i: None, r_t: [-4430.478 -4430.478 -4430.478], critic_loss: 4893.60791015625, actor_loss: 0.09399999678134918, eps: 0.1})
Step:   80500, Reward: [-418.250 -418.250 -418.250] [78.494], Avg: [-422.753 -422.753 -422.753] (0.1000) <00:35:09> ({r_i: None, r_t: [-4164.739 -4164.739 -4164.739], critic_loss: 4103.9541015625, actor_loss: 0.3630000054836273, eps: 0.1})
Step:   81000, Reward: [-428.700 -428.700 -428.700] [111.160], Avg: [-422.789 -422.789 -422.789] (0.1000) <00:35:22> ({r_i: None, r_t: [-4302.008 -4302.008 -4302.008], critic_loss: 3932.593994140625, actor_loss: 0.421999990940094, eps: 0.1})
Step:   81500, Reward: [-381.395 -381.395 -381.395] [62.319], Avg: [-422.537 -422.537 -422.537] (0.1000) <00:35:35> ({r_i: None, r_t: [-4163.133 -4163.133 -4163.133], critic_loss: 4415.51220703125, actor_loss: 0.34200000762939453, eps: 0.1})
Step:   82000, Reward: [-404.300 -404.300 -404.300] [77.246], Avg: [-422.426 -422.426 -422.426] (0.1000) <00:35:47> ({r_i: None, r_t: [-4141.339 -4141.339 -4141.339], critic_loss: 3971.39306640625, actor_loss: 0.10100000351667404, eps: 0.1})
Step:   82500, Reward: [-439.302 -439.302 -439.302] [100.686], Avg: [-422.528 -422.528 -422.528] (0.1000) <00:36:01> ({r_i: None, r_t: [-4122.584 -4122.584 -4122.584], critic_loss: 3831.375, actor_loss: 0.0729999989271164, eps: 0.1})
Step:   83000, Reward: [-405.842 -405.842 -405.842] [93.809], Avg: [-422.428 -422.428 -422.428] (0.1000) <00:36:14> ({r_i: None, r_t: [-4105.703 -4105.703 -4105.703], critic_loss: 3701.81201171875, actor_loss: 0.734000027179718, eps: 0.1})
Step:   83500, Reward: [-393.697 -393.697 -393.697] [63.383], Avg: [-422.257 -422.257 -422.257] (0.1000) <00:36:27> ({r_i: None, r_t: [-4080.651 -4080.651 -4080.651], critic_loss: 4152.2861328125, actor_loss: -0.5099999904632568, eps: 0.1})
Step:   84000, Reward: [-445.945 -445.945 -445.945] [83.128], Avg: [-422.397 -422.397 -422.397] (0.1000) <00:36:40> ({r_i: None, r_t: [-4125.960 -4125.960 -4125.960], critic_loss: 4043.756103515625, actor_loss: -0.22300000488758087, eps: 0.1})
Step:   84500, Reward: [-421.649 -421.649 -421.649] [48.233], Avg: [-422.393 -422.393 -422.393] (0.1000) <00:36:52> ({r_i: None, r_t: [-4174.183 -4174.183 -4174.183], critic_loss: 3973.14306640625, actor_loss: -0.5109999775886536, eps: 0.1})
Step:   85000, Reward: [-440.662 -440.662 -440.662] [83.154], Avg: [-422.500 -422.500 -422.500] (0.1000) <00:37:05> ({r_i: None, r_t: [-4145.738 -4145.738 -4145.738], critic_loss: 4392.60888671875, actor_loss: -0.02199999988079071, eps: 0.1})
Step:   85500, Reward: [-417.734 -417.734 -417.734] [62.773], Avg: [-422.472 -422.472 -422.472] (0.1000) <00:37:18> ({r_i: None, r_t: [-4225.648 -4225.648 -4225.648], critic_loss: 4337.662109375, actor_loss: -0.5889999866485596, eps: 0.1})
Step:   86000, Reward: [-440.004 -440.004 -440.004] [71.358], Avg: [-422.573 -422.573 -422.573] (0.1000) <00:37:31> ({r_i: None, r_t: [-4241.935 -4241.935 -4241.935], critic_loss: 4686.47607421875, actor_loss: -0.009999999776482582, eps: 0.1})
Step:   86500, Reward: [-427.493 -427.493 -427.493] [109.509], Avg: [-422.602 -422.602 -422.602] (0.1000) <00:37:45> ({r_i: None, r_t: [-4511.145 -4511.145 -4511.145], critic_loss: 5037.0517578125, actor_loss: 0.2770000100135803, eps: 0.1})
Step:   87000, Reward: [-425.116 -425.116 -425.116] [73.321], Avg: [-422.616 -422.616 -422.616] (0.1000) <00:37:57> ({r_i: None, r_t: [-4375.427 -4375.427 -4375.427], critic_loss: 4930.255859375, actor_loss: -0.39100000262260437, eps: 0.1})
Step:   87500, Reward: [-441.250 -441.250 -441.250] [83.749], Avg: [-422.722 -422.722 -422.722] (0.1000) <00:38:10> ({r_i: None, r_t: [-4282.189 -4282.189 -4282.189], critic_loss: 4703.89990234375, actor_loss: -0.02199999988079071, eps: 0.1})
Step:   88000, Reward: [-437.198 -437.198 -437.198] [83.317], Avg: [-422.804 -422.804 -422.804] (0.1000) <00:38:23> ({r_i: None, r_t: [-4334.353 -4334.353 -4334.353], critic_loss: 5008.10205078125, actor_loss: -0.10599999874830246, eps: 0.1})
Step:   88500, Reward: [-428.691 -428.691 -428.691] [84.472], Avg: [-422.837 -422.837 -422.837] (0.1000) <00:38:36> ({r_i: None, r_t: [-4392.139 -4392.139 -4392.139], critic_loss: 4940.68115234375, actor_loss: 0.8109999895095825, eps: 0.1})
Step:   89000, Reward: [-476.512 -476.512 -476.512] [83.847], Avg: [-423.137 -423.137 -423.137] (0.1000) <00:38:49> ({r_i: None, r_t: [-4187.414 -4187.414 -4187.414], critic_loss: 4509.39794921875, actor_loss: 0.46700000762939453, eps: 0.1})
Step:   89500, Reward: [-405.355 -405.355 -405.355] [68.775], Avg: [-423.038 -423.038 -423.038] (0.1000) <00:39:01> ({r_i: None, r_t: [-4305.236 -4305.236 -4305.236], critic_loss: 4962.9931640625, actor_loss: 0.4860000014305115, eps: 0.1})
Step:   90000, Reward: [-428.728 -428.728 -428.728] [81.639], Avg: [-423.069 -423.069 -423.069] (0.1000) <00:39:15> ({r_i: None, r_t: [-4158.382 -4158.382 -4158.382], critic_loss: 4744.255859375, actor_loss: -0.14100000262260437, eps: 0.1})
Step:   90500, Reward: [-406.620 -406.620 -406.620] [80.372], Avg: [-422.979 -422.979 -422.979] (0.1000) <00:39:28> ({r_i: None, r_t: [-4379.541 -4379.541 -4379.541], critic_loss: 4834.7978515625, actor_loss: 0.23800000548362732, eps: 0.1})
Step:   91000, Reward: [-453.489 -453.489 -453.489] [65.702], Avg: [-423.146 -423.146 -423.146] (0.1000) <00:39:41> ({r_i: None, r_t: [-4337.615 -4337.615 -4337.615], critic_loss: 4925.7099609375, actor_loss: 0.1459999978542328, eps: 0.1})
Step:   91500, Reward: [-458.653 -458.653 -458.653] [102.508], Avg: [-423.339 -423.339 -423.339] (0.1000) <00:39:54> ({r_i: None, r_t: [-4227.199 -4227.199 -4227.199], critic_loss: 4966.169921875, actor_loss: 0.14900000393390656, eps: 0.1})
Step:   92000, Reward: [-408.626 -408.626 -408.626] [92.489], Avg: [-423.259 -423.259 -423.259] (0.1000) <00:40:07> ({r_i: None, r_t: [-4225.942 -4225.942 -4225.942], critic_loss: 4775.630859375, actor_loss: -0.12800000607967377, eps: 0.1})
Step:   92500, Reward: [-415.580 -415.580 -415.580] [93.844], Avg: [-423.218 -423.218 -423.218] (0.1000) <00:40:20> ({r_i: None, r_t: [-4274.772 -4274.772 -4274.772], critic_loss: 5045.0322265625, actor_loss: -0.003000000026077032, eps: 0.1})
Step:   93000, Reward: [-438.205 -438.205 -438.205] [105.754], Avg: [-423.298 -423.298 -423.298] (0.1000) <00:40:33> ({r_i: None, r_t: [-4243.767 -4243.767 -4243.767], critic_loss: 4537.2822265625, actor_loss: 0.10300000011920929, eps: 0.1})
Step:   93500, Reward: [-411.141 -411.141 -411.141] [62.923], Avg: [-423.233 -423.233 -423.233] (0.1000) <00:40:46> ({r_i: None, r_t: [-4241.330 -4241.330 -4241.330], critic_loss: 5133.7998046875, actor_loss: -0.04699999839067459, eps: 0.1})
Step:   94000, Reward: [-404.799 -404.799 -404.799] [83.579], Avg: [-423.136 -423.136 -423.136] (0.1000) <00:40:59> ({r_i: None, r_t: [-4244.798 -4244.798 -4244.798], critic_loss: 5008.01220703125, actor_loss: 0.29899999499320984, eps: 0.1})
Step:   94500, Reward: [-437.411 -437.411 -437.411] [89.442], Avg: [-423.211 -423.211 -423.211] (0.1000) <00:41:12> ({r_i: None, r_t: [-4121.477 -4121.477 -4121.477], critic_loss: 4668.26611328125, actor_loss: 0.2460000067949295, eps: 0.1})
Step:   95000, Reward: [-418.944 -418.944 -418.944] [57.250], Avg: [-423.188 -423.188 -423.188] (0.1000) <00:41:25> ({r_i: None, r_t: [-4131.222 -4131.222 -4131.222], critic_loss: 4585.98583984375, actor_loss: -0.014999999664723873, eps: 0.1})
Step:   95500, Reward: [-409.963 -409.963 -409.963] [71.768], Avg: [-423.120 -423.120 -423.120] (0.1000) <00:41:38> ({r_i: None, r_t: [-4140.619 -4140.619 -4140.619], critic_loss: 4467.5869140625, actor_loss: -0.032999999821186066, eps: 0.1})
Step:   96000, Reward: [-411.809 -411.809 -411.809] [86.168], Avg: [-423.061 -423.061 -423.061] (0.1000) <00:41:51> ({r_i: None, r_t: [-4157.854 -4157.854 -4157.854], critic_loss: 4578.2880859375, actor_loss: -0.492000013589859, eps: 0.1})
Step:   96500, Reward: [-430.188 -430.188 -430.188] [89.831], Avg: [-423.098 -423.098 -423.098] (0.1000) <00:42:03> ({r_i: None, r_t: [-4172.096 -4172.096 -4172.096], critic_loss: 4697.158203125, actor_loss: 0.3409999907016754, eps: 0.1})
Step:   97000, Reward: [-404.569 -404.569 -404.569] [61.187], Avg: [-423.003 -423.003 -423.003] (0.1000) <00:42:16> ({r_i: None, r_t: [-4182.850 -4182.850 -4182.850], critic_loss: 4691.23876953125, actor_loss: -0.16099999845027924, eps: 0.1})
Step:   97500, Reward: [-442.868 -442.868 -442.868] [75.540], Avg: [-423.104 -423.104 -423.104] (0.1000) <00:42:30> ({r_i: None, r_t: [-4124.858 -4124.858 -4124.858], critic_loss: 4756.7900390625, actor_loss: 0.5220000147819519, eps: 0.1})
Step:   98000, Reward: [-430.071 -430.071 -430.071] [96.527], Avg: [-423.139 -423.139 -423.139] (0.1000) <00:42:43> ({r_i: None, r_t: [-4037.355 -4037.355 -4037.355], critic_loss: 4538.2841796875, actor_loss: -0.1080000028014183, eps: 0.1})
Step:   98500, Reward: [-412.037 -412.037 -412.037] [73.059], Avg: [-423.083 -423.083 -423.083] (0.1000) <00:42:56> ({r_i: None, r_t: [-4185.329 -4185.329 -4185.329], critic_loss: 4887.4638671875, actor_loss: 0.07900000363588333, eps: 0.1})
Step:   99000, Reward: [-432.048 -432.048 -432.048] [71.284], Avg: [-423.128 -423.128 -423.128] (0.1000) <00:43:08> ({r_i: None, r_t: [-4157.233 -4157.233 -4157.233], critic_loss: 4876.18212890625, actor_loss: 0.22599999606609344, eps: 0.1})
Step:   99500, Reward: [-464.669 -464.669 -464.669] [70.577], Avg: [-423.336 -423.336 -423.336] (0.1000) <00:43:21> ({r_i: None, r_t: [-4334.797 -4334.797 -4334.797], critic_loss: 5618.64990234375, actor_loss: 0.0949999988079071, eps: 0.1})
Step:  100000, Reward: [-418.361 -418.361 -418.361] [76.095], Avg: [-423.311 -423.311 -423.311] (0.1000) <00:43:35> ({r_i: None, r_t: [-4207.914 -4207.914 -4207.914], critic_loss: 5396.59619140625, actor_loss: 0.3230000138282776, eps: 0.1})
Step:  100500, Reward: [-393.424 -393.424 -393.424] [83.870], Avg: [-423.163 -423.163 -423.163] (0.1000) <00:43:48> ({r_i: None, r_t: [-3996.891 -3996.891 -3996.891], critic_loss: 4591.7021484375, actor_loss: 0.07800000160932541, eps: 0.1})
Step:  101000, Reward: [-418.976 -418.976 -418.976] [81.478], Avg: [-423.143 -423.143 -423.143] (0.1000) <00:44:01> ({r_i: None, r_t: [-4091.338 -4091.338 -4091.338], critic_loss: 4243.71923828125, actor_loss: 0.35499998927116394, eps: 0.1})
Step:  101500, Reward: [-393.206 -393.206 -393.206] [81.802], Avg: [-422.996 -422.996 -422.996] (0.1000) <00:44:14> ({r_i: None, r_t: [-3977.597 -3977.597 -3977.597], critic_loss: 4471.8828125, actor_loss: 0.3240000009536743, eps: 0.1})
Step:  102000, Reward: [-388.738 -388.738 -388.738] [49.311], Avg: [-422.829 -422.829 -422.829] (0.1000) <00:44:27> ({r_i: None, r_t: [-4021.055 -4021.055 -4021.055], critic_loss: 4393.43212890625, actor_loss: 0.11699999868869781, eps: 0.1})
Step:  102500, Reward: [-395.624 -395.624 -395.624] [68.987], Avg: [-422.697 -422.697 -422.697] (0.1000) <00:44:40> ({r_i: None, r_t: [-4011.560 -4011.560 -4011.560], critic_loss: 4103.73681640625, actor_loss: -0.13500000536441803, eps: 0.1})
Step:  103000, Reward: [-406.576 -406.576 -406.576] [82.543], Avg: [-422.619 -422.619 -422.619] (0.1000) <00:44:53> ({r_i: None, r_t: [-3971.696 -3971.696 -3971.696], critic_loss: 4153.05712890625, actor_loss: -0.11800000071525574, eps: 0.1})
Step:  103500, Reward: [-391.647 -391.647 -391.647] [59.137], Avg: [-422.470 -422.470 -422.470] (0.1000) <00:45:06> ({r_i: None, r_t: [-4087.229 -4087.229 -4087.229], critic_loss: 4407.130859375, actor_loss: 0.1589999943971634, eps: 0.1})
Step:  104000, Reward: [-456.079 -456.079 -456.079] [62.970], Avg: [-422.631 -422.631 -422.631] (0.1000) <00:45:19> ({r_i: None, r_t: [-4035.382 -4035.382 -4035.382], critic_loss: 4251.60986328125, actor_loss: -0.07500000298023224, eps: 0.1})
Step:  104500, Reward: [-453.517 -453.517 -453.517] [70.864], Avg: [-422.778 -422.778 -422.778] (0.1000) <00:45:32> ({r_i: None, r_t: [-4084.990 -4084.990 -4084.990], critic_loss: 4454.51220703125, actor_loss: 0.2770000100135803, eps: 0.1})
Step:  105000, Reward: [-397.403 -397.403 -397.403] [44.099], Avg: [-422.658 -422.658 -422.658] (0.1000) <00:45:45> ({r_i: None, r_t: [-4071.448 -4071.448 -4071.448], critic_loss: 5410.67919921875, actor_loss: 0.07599999755620956, eps: 0.1})
Step:  105500, Reward: [-388.218 -388.218 -388.218] [41.681], Avg: [-422.495 -422.495 -422.495] (0.1000) <00:45:58> ({r_i: None, r_t: [-4049.121 -4049.121 -4049.121], critic_loss: 4909.9921875, actor_loss: -0.2919999957084656, eps: 0.1})
Step:  106000, Reward: [-408.081 -408.081 -408.081] [88.042], Avg: [-422.428 -422.428 -422.428] (0.1000) <00:46:11> ({r_i: None, r_t: [-4022.999 -4022.999 -4022.999], critic_loss: 4500.43017578125, actor_loss: -0.05400000140070915, eps: 0.1})
Step:  106500, Reward: [-372.785 -372.785 -372.785] [53.059], Avg: [-422.196 -422.196 -422.196] (0.1000) <00:46:23> ({r_i: None, r_t: [-4041.205 -4041.205 -4041.205], critic_loss: 4682.77880859375, actor_loss: 0.0949999988079071, eps: 0.1})
Step:  107000, Reward: [-427.201 -427.201 -427.201] [58.373], Avg: [-422.219 -422.219 -422.219] (0.1000) <00:46:36> ({r_i: None, r_t: [-4171.130 -4171.130 -4171.130], critic_loss: 5382.8720703125, actor_loss: 0.492000013589859, eps: 0.1})
Step:  107500, Reward: [-376.087 -376.087 -376.087] [45.507], Avg: [-422.005 -422.005 -422.005] (0.1000) <00:46:49> ({r_i: None, r_t: [-4029.020 -4029.020 -4029.020], critic_loss: 4375.6162109375, actor_loss: -0.1589999943971634, eps: 0.1})
Step:  108000, Reward: [-380.434 -380.434 -380.434] [72.172], Avg: [-421.814 -421.814 -421.814] (0.1000) <00:47:02> ({r_i: None, r_t: [-3987.686 -3987.686 -3987.686], critic_loss: 4304.5029296875, actor_loss: -0.6800000071525574, eps: 0.1})
Step:  108500, Reward: [-393.010 -393.010 -393.010] [76.406], Avg: [-421.682 -421.682 -421.682] (0.1000) <00:47:16> ({r_i: None, r_t: [-4057.359 -4057.359 -4057.359], critic_loss: 4554.44287109375, actor_loss: -0.34700000286102295, eps: 0.1})
Step:  109000, Reward: [-457.555 -457.555 -457.555] [65.791], Avg: [-421.845 -421.845 -421.845] (0.1000) <00:47:28> ({r_i: None, r_t: [-4127.902 -4127.902 -4127.902], critic_loss: 4987.34814453125, actor_loss: -0.3100000023841858, eps: 0.1})
Step:  109500, Reward: [-384.556 -384.556 -384.556] [52.266], Avg: [-421.676 -421.676 -421.676] (0.1000) <00:47:41> ({r_i: None, r_t: [-4152.593 -4152.593 -4152.593], critic_loss: 5110.580078125, actor_loss: -0.10899999737739563, eps: 0.1})
Step:  110000, Reward: [-403.759 -403.759 -403.759] [60.319], Avg: [-421.595 -421.595 -421.595] (0.1000) <00:47:54> ({r_i: None, r_t: [-4210.526 -4210.526 -4210.526], critic_loss: 5322.6240234375, actor_loss: 0.32499998807907104, eps: 0.1})
Step:  110500, Reward: [-428.633 -428.633 -428.633] [63.992], Avg: [-421.627 -421.627 -421.627] (0.1000) <00:48:07> ({r_i: None, r_t: [-4127.979 -4127.979 -4127.979], critic_loss: 5064.64208984375, actor_loss: -0.16300000250339508, eps: 0.1})
Step:  111000, Reward: [-396.654 -396.654 -396.654] [80.462], Avg: [-421.515 -421.515 -421.515] (0.1000) <00:48:20> ({r_i: None, r_t: [-4143.642 -4143.642 -4143.642], critic_loss: 4812.23681640625, actor_loss: 0.5370000004768372, eps: 0.1})
Step:  111500, Reward: [-388.300 -388.300 -388.300] [64.977], Avg: [-421.366 -421.366 -421.366] (0.1000) <00:48:33> ({r_i: None, r_t: [-4075.591 -4075.591 -4075.591], critic_loss: 5338.759765625, actor_loss: 0.6200000047683716, eps: 0.1})
Step:  112000, Reward: [-382.726 -382.726 -382.726] [61.576], Avg: [-421.195 -421.195 -421.195] (0.1000) <00:48:47> ({r_i: None, r_t: [-3987.220 -3987.220 -3987.220], critic_loss: 4720.43408203125, actor_loss: 0.39100000262260437, eps: 0.1})
Step:  112500, Reward: [-419.954 -419.954 -419.954] [73.839], Avg: [-421.189 -421.189 -421.189] (0.1000) <00:49:00> ({r_i: None, r_t: [-3959.500 -3959.500 -3959.500], critic_loss: 4185.90283203125, actor_loss: -0.4350000023841858, eps: 0.1})
Step:  113000, Reward: [-424.864 -424.864 -424.864] [61.007], Avg: [-421.205 -421.205 -421.205] (0.1000) <00:49:14> ({r_i: None, r_t: [-3906.241 -3906.241 -3906.241], critic_loss: 4652.23583984375, actor_loss: -0.07699999958276749, eps: 0.1})
Step:  113500, Reward: [-419.238 -419.238 -419.238] [59.428], Avg: [-421.197 -421.197 -421.197] (0.1000) <00:49:27> ({r_i: None, r_t: [-4081.748 -4081.748 -4081.748], critic_loss: 4824.7490234375, actor_loss: -0.050999999046325684, eps: 0.1})
Step:  114000, Reward: [-390.356 -390.356 -390.356] [63.403], Avg: [-421.062 -421.062 -421.062] (0.1000) <00:49:40> ({r_i: None, r_t: [-3988.322 -3988.322 -3988.322], critic_loss: 4479.8720703125, actor_loss: -0.14000000059604645, eps: 0.1})
Step:  114500, Reward: [-405.559 -405.559 -405.559] [68.362], Avg: [-420.995 -420.995 -420.995] (0.1000) <00:49:53> ({r_i: None, r_t: [-3910.139 -3910.139 -3910.139], critic_loss: 4490.60400390625, actor_loss: -0.36500000953674316, eps: 0.1})
Step:  115000, Reward: [-418.163 -418.163 -418.163] [93.115], Avg: [-420.982 -420.982 -420.982] (0.1000) <00:50:06> ({r_i: None, r_t: [-4065.501 -4065.501 -4065.501], critic_loss: 4745.2822265625, actor_loss: -0.20399999618530273, eps: 0.1})
Step:  115500, Reward: [-418.772 -418.772 -418.772] [57.311], Avg: [-420.973 -420.973 -420.973] (0.1000) <00:50:20> ({r_i: None, r_t: [-4041.982 -4041.982 -4041.982], critic_loss: 4713.55615234375, actor_loss: -0.6200000047683716, eps: 0.1})
Step:  116000, Reward: [-417.750 -417.750 -417.750] [83.622], Avg: [-420.959 -420.959 -420.959] (0.1000) <00:50:33> ({r_i: None, r_t: [-4092.583 -4092.583 -4092.583], critic_loss: 5337.24609375, actor_loss: -0.11800000071525574, eps: 0.1})
Step:  116500, Reward: [-383.508 -383.508 -383.508] [33.988], Avg: [-420.799 -420.799 -420.799] (0.1000) <00:50:45> ({r_i: None, r_t: [-4043.009 -4043.009 -4043.009], critic_loss: 4989.60009765625, actor_loss: -0.29499998688697815, eps: 0.1})
Step:  117000, Reward: [-410.165 -410.165 -410.165] [67.364], Avg: [-420.754 -420.754 -420.754] (0.1000) <00:50:58> ({r_i: None, r_t: [-4170.798 -4170.798 -4170.798], critic_loss: 5535.3017578125, actor_loss: -0.1469999998807907, eps: 0.1})
Step:  117500, Reward: [-464.639 -464.639 -464.639] [82.646], Avg: [-420.940 -420.940 -420.940] (0.1000) <00:51:12> ({r_i: None, r_t: [-4124.081 -4124.081 -4124.081], critic_loss: 5761.35791015625, actor_loss: -0.35499998927116394, eps: 0.1})
Step:  118000, Reward: [-426.436 -426.436 -426.436] [105.882], Avg: [-420.963 -420.963 -420.963] (0.1000) <00:51:25> ({r_i: None, r_t: [-4101.105 -4101.105 -4101.105], critic_loss: 5471.2470703125, actor_loss: 0.2800000011920929, eps: 0.1})
Step:  118500, Reward: [-389.030 -389.030 -389.030] [65.834], Avg: [-420.829 -420.829 -420.829] (0.1000) <00:51:38> ({r_i: None, r_t: [-4186.284 -4186.284 -4186.284], critic_loss: 5944.11181640625, actor_loss: 0.4320000112056732, eps: 0.1})
Step:  119000, Reward: [-414.975 -414.975 -414.975] [80.922], Avg: [-420.804 -420.804 -420.804] (0.1000) <00:51:50> ({r_i: None, r_t: [-4144.865 -4144.865 -4144.865], critic_loss: 5668.47314453125, actor_loss: 0.35899999737739563, eps: 0.1})
Step:  119500, Reward: [-425.119 -425.119 -425.119] [57.200], Avg: [-420.822 -420.822 -420.822] (0.1000) <00:52:04> ({r_i: None, r_t: [-4206.428 -4206.428 -4206.428], critic_loss: 6096.923828125, actor_loss: -0.13199999928474426, eps: 0.1})
Step:  120000, Reward: [-383.524 -383.524 -383.524] [86.281], Avg: [-420.667 -420.667 -420.667] (0.1000) <00:52:17> ({r_i: None, r_t: [-4158.016 -4158.016 -4158.016], critic_loss: 5930.0458984375, actor_loss: -0.11999999731779099, eps: 0.1})
Step:  120500, Reward: [-395.237 -395.237 -395.237] [57.443], Avg: [-420.562 -420.562 -420.562] (0.1000) <00:52:30> ({r_i: None, r_t: [-4278.900 -4278.900 -4278.900], critic_loss: 5987.97216796875, actor_loss: 0.6700000166893005, eps: 0.1})
Step:  121000, Reward: [-410.374 -410.374 -410.374] [66.254], Avg: [-420.520 -420.520 -420.520] (0.1000) <00:52:43> ({r_i: None, r_t: [-3969.174 -3969.174 -3969.174], critic_loss: 5637.5, actor_loss: -0.07000000029802322, eps: 0.1})
Step:  121500, Reward: [-397.904 -397.904 -397.904] [80.149], Avg: [-420.428 -420.428 -420.428] (0.1000) <00:52:55> ({r_i: None, r_t: [-3925.550 -3925.550 -3925.550], critic_loss: 5178.11376953125, actor_loss: -0.1899999976158142, eps: 0.1})
Step:  122000, Reward: [-434.297 -434.297 -434.297] [61.031], Avg: [-420.484 -420.484 -420.484] (0.1000) <00:53:09> ({r_i: None, r_t: [-3981.394 -3981.394 -3981.394], critic_loss: 5158.7490234375, actor_loss: 0.14000000059604645, eps: 0.1})
Step:  122500, Reward: [-367.980 -367.980 -367.980] [67.078], Avg: [-420.271 -420.271 -420.271] (0.1000) <00:53:22> ({r_i: None, r_t: [-3983.577 -3983.577 -3983.577], critic_loss: 5293.02392578125, actor_loss: -0.009999999776482582, eps: 0.1})
Step:  123000, Reward: [-404.351 -404.351 -404.351] [79.551], Avg: [-420.206 -420.206 -420.206] (0.1000) <00:53:35> ({r_i: None, r_t: [-4084.994 -4084.994 -4084.994], critic_loss: 5147.23779296875, actor_loss: -0.07100000232458115, eps: 0.1})
Step:  123500, Reward: [-410.389 -410.389 -410.389] [88.137], Avg: [-420.167 -420.167 -420.167] (0.1000) <00:53:48> ({r_i: None, r_t: [-4041.427 -4041.427 -4041.427], critic_loss: 5527.126953125, actor_loss: -0.3370000123977661, eps: 0.1})
Step:  124000, Reward: [-424.542 -424.542 -424.542] [45.488], Avg: [-420.184 -420.184 -420.184] (0.1000) <00:54:02> ({r_i: None, r_t: [-4078.303 -4078.303 -4078.303], critic_loss: 5489.52978515625, actor_loss: 0.12700000405311584, eps: 0.1})
Step:  124500, Reward: [-390.028 -390.028 -390.028] [60.132], Avg: [-420.064 -420.064 -420.064] (0.1000) <00:54:15> ({r_i: None, r_t: [-4025.446 -4025.446 -4025.446], critic_loss: 5287.31005859375, actor_loss: -0.04800000041723251, eps: 0.1})
Step:  125000, Reward: [-398.486 -398.486 -398.486] [46.209], Avg: [-419.978 -419.978 -419.978] (0.1000) <00:54:28> ({r_i: None, r_t: [-4098.275 -4098.275 -4098.275], critic_loss: 5290.7958984375, actor_loss: 0.04600000008940697, eps: 0.1})
Step:  125500, Reward: [-394.364 -394.364 -394.364] [61.444], Avg: [-419.876 -419.876 -419.876] (0.1000) <00:54:41> ({r_i: None, r_t: [-4094.240 -4094.240 -4094.240], critic_loss: 5552.23193359375, actor_loss: -0.38499999046325684, eps: 0.1})
Step:  126000, Reward: [-405.320 -405.320 -405.320] [40.260], Avg: [-419.819 -419.819 -419.819] (0.1000) <00:54:54> ({r_i: None, r_t: [-4193.044 -4193.044 -4193.044], critic_loss: 5340.64013671875, actor_loss: -0.15700000524520874, eps: 0.1})
Step:  126500, Reward: [-394.310 -394.310 -394.310] [44.339], Avg: [-419.718 -419.718 -419.718] (0.1000) <00:55:07> ({r_i: None, r_t: [-4165.535 -4165.535 -4165.535], critic_loss: 5931.66796875, actor_loss: -0.2720000147819519, eps: 0.1})
Step:  127000, Reward: [-415.528 -415.528 -415.528] [87.547], Avg: [-419.702 -419.702 -419.702] (0.1000) <00:55:20> ({r_i: None, r_t: [-4000.652 -4000.652 -4000.652], critic_loss: 5414.912109375, actor_loss: -0.2540000081062317, eps: 0.1})
Step:  127500, Reward: [-418.243 -418.243 -418.243] [50.235], Avg: [-419.696 -419.696 -419.696] (0.1000) <00:55:33> ({r_i: None, r_t: [-4113.274 -4113.274 -4113.274], critic_loss: 5867.96923828125, actor_loss: -0.36800000071525574, eps: 0.1})
Step:  128000, Reward: [-427.129 -427.129 -427.129] [64.226], Avg: [-419.725 -419.725 -419.725] (0.1000) <00:55:46> ({r_i: None, r_t: [-4157.582 -4157.582 -4157.582], critic_loss: 6379.86181640625, actor_loss: -0.15299999713897705, eps: 0.1})
Step:  128500, Reward: [-461.005 -461.005 -461.005] [89.123], Avg: [-419.885 -419.885 -419.885] (0.1000) <00:55:59> ({r_i: None, r_t: [-4261.744 -4261.744 -4261.744], critic_loss: 6599.77099609375, actor_loss: 0.3580000102519989, eps: 0.1})
Step:  129000, Reward: [-452.579 -452.579 -452.579] [71.253], Avg: [-420.011 -420.011 -420.011] (0.1000) <00:56:11> ({r_i: None, r_t: [-4274.942 -4274.942 -4274.942], critic_loss: 5972.07421875, actor_loss: -0.10199999809265137, eps: 0.1})
Step:  129500, Reward: [-405.589 -405.589 -405.589] [70.572], Avg: [-419.956 -419.956 -419.956] (0.1000) <00:56:25> ({r_i: None, r_t: [-4178.876 -4178.876 -4178.876], critic_loss: 6402.18115234375, actor_loss: -0.07900000363588333, eps: 0.1})
Step:  130000, Reward: [-408.704 -408.704 -408.704] [59.774], Avg: [-419.913 -419.913 -419.913] (0.1000) <00:56:38> ({r_i: None, r_t: [-4193.311 -4193.311 -4193.311], critic_loss: 6159.1318359375, actor_loss: 0.25600001215934753, eps: 0.1})
Step:  130500, Reward: [-398.151 -398.151 -398.151] [62.113], Avg: [-419.830 -419.830 -419.830] (0.1000) <00:56:52> ({r_i: None, r_t: [-4158.834 -4158.834 -4158.834], critic_loss: 6527.48388671875, actor_loss: -0.328000009059906, eps: 0.1})
Step:  131000, Reward: [-395.769 -395.769 -395.769] [62.035], Avg: [-419.738 -419.738 -419.738] (0.1000) <00:57:05> ({r_i: None, r_t: [-4050.311 -4050.311 -4050.311], critic_loss: 5624.1318359375, actor_loss: -0.17599999904632568, eps: 0.1})
Step:  131500, Reward: [-464.317 -464.317 -464.317] [96.065], Avg: [-419.907 -419.907 -419.907] (0.1000) <00:57:17> ({r_i: None, r_t: [-4226.517 -4226.517 -4226.517], critic_loss: 6556.2177734375, actor_loss: 0.03400000184774399, eps: 0.1})
Step:  132000, Reward: [-462.553 -462.553 -462.553] [119.308], Avg: [-420.068 -420.068 -420.068] (0.1000) <00:57:30> ({r_i: None, r_t: [-4224.357 -4224.357 -4224.357], critic_loss: 6725.72802734375, actor_loss: -0.503000020980835, eps: 0.1})
Step:  132500, Reward: [-499.180 -499.180 -499.180] [82.101], Avg: [-420.365 -420.365 -420.365] (0.1000) <00:57:44> ({r_i: None, r_t: [-4308.340 -4308.340 -4308.340], critic_loss: 7383.759765625, actor_loss: -0.9079999923706055, eps: 0.1})
Step:  133000, Reward: [-386.826 -386.826 -386.826] [60.014], Avg: [-420.240 -420.240 -420.240] (0.1000) <00:57:57> ({r_i: None, r_t: [-4246.387 -4246.387 -4246.387], critic_loss: 7234.80615234375, actor_loss: -0.029999999329447746, eps: 0.1})
Step:  133500, Reward: [-409.615 -409.615 -409.615] [71.236], Avg: [-420.200 -420.200 -420.200] (0.1000) <00:58:10> ({r_i: None, r_t: [-4397.989 -4397.989 -4397.989], critic_loss: 8627.0380859375, actor_loss: -0.460999995470047, eps: 0.1})
Step:  134000, Reward: [-474.724 -474.724 -474.724] [118.910], Avg: [-420.403 -420.403 -420.403] (0.1000) <00:58:24> ({r_i: None, r_t: [-4334.667 -4334.667 -4334.667], critic_loss: 7591.7939453125, actor_loss: 0.5630000233650208, eps: 0.1})
Step:  134500, Reward: [-430.623 -430.623 -430.623] [83.001], Avg: [-420.441 -420.441 -420.441] (0.1000) <00:58:37> ({r_i: None, r_t: [-4407.691 -4407.691 -4407.691], critic_loss: 8052.68798828125, actor_loss: 0.10100000351667404, eps: 0.1})
Step:  135000, Reward: [-439.870 -439.870 -439.870] [75.726], Avg: [-420.512 -420.512 -420.512] (0.1000) <00:58:50> ({r_i: None, r_t: [-4441.867 -4441.867 -4441.867], critic_loss: 8076.5458984375, actor_loss: 0.2160000056028366, eps: 0.1})
Step:  135500, Reward: [-414.668 -414.668 -414.668] [64.545], Avg: [-420.491 -420.491 -420.491] (0.1000) <00:59:03> ({r_i: None, r_t: [-4224.063 -4224.063 -4224.063], critic_loss: 7607.26708984375, actor_loss: -0.6299999952316284, eps: 0.1})
Step:  136000, Reward: [-436.448 -436.448 -436.448] [77.679], Avg: [-420.549 -420.549 -420.549] (0.1000) <00:59:16> ({r_i: None, r_t: [-4337.014 -4337.014 -4337.014], critic_loss: 7083.0869140625, actor_loss: -0.06199999898672104, eps: 0.1})
Step:  136500, Reward: [-431.942 -431.942 -431.942] [96.232], Avg: [-420.591 -420.591 -420.591] (0.1000) <00:59:29> ({r_i: None, r_t: [-4312.606 -4312.606 -4312.606], critic_loss: 7755.583984375, actor_loss: 0.4429999887943268, eps: 0.1})
Step:  137000, Reward: [-438.668 -438.668 -438.668] [84.078], Avg: [-420.657 -420.657 -420.657] (0.1000) <00:59:43> ({r_i: None, r_t: [-4320.505 -4320.505 -4320.505], critic_loss: 8215.1982421875, actor_loss: 0.23499999940395355, eps: 0.1})
Step:  137500, Reward: [-412.469 -412.469 -412.469] [54.687], Avg: [-420.627 -420.627 -420.627] (0.1000) <00:59:56> ({r_i: None, r_t: [-4432.770 -4432.770 -4432.770], critic_loss: 8488.5029296875, actor_loss: 0.33399999141693115, eps: 0.1})
Step:  138000, Reward: [-419.822 -419.822 -419.822] [74.556], Avg: [-420.624 -420.624 -420.624] (0.1000) <01:00:09> ({r_i: None, r_t: [-4280.491 -4280.491 -4280.491], critic_loss: 7762.15087890625, actor_loss: 0.2460000067949295, eps: 0.1})
Step:  138500, Reward: [-412.209 -412.209 -412.209] [61.380], Avg: [-420.594 -420.594 -420.594] (0.1000) <01:00:22> ({r_i: None, r_t: [-4257.033 -4257.033 -4257.033], critic_loss: 7648.22607421875, actor_loss: -0.2409999966621399, eps: 0.1})
Step:  139000, Reward: [-428.728 -428.728 -428.728] [67.764], Avg: [-420.623 -420.623 -420.623] (0.1000) <01:00:35> ({r_i: None, r_t: [-4286.334 -4286.334 -4286.334], critic_loss: 7322.10986328125, actor_loss: 0.21299999952316284, eps: 0.1})
Step:  139500, Reward: [-423.155 -423.155 -423.155] [71.758], Avg: [-420.632 -420.632 -420.632] (0.1000) <01:00:48> ({r_i: None, r_t: [-4256.962 -4256.962 -4256.962], critic_loss: 7585.9921875, actor_loss: 0.03200000151991844, eps: 0.1})
Step:  140000, Reward: [-420.960 -420.960 -420.960] [76.121], Avg: [-420.633 -420.633 -420.633] (0.1000) <01:01:01> ({r_i: None, r_t: [-4246.663 -4246.663 -4246.663], critic_loss: 7394.546875, actor_loss: 0.024000000208616257, eps: 0.1})
Step:  140500, Reward: [-408.221 -408.221 -408.221] [54.161], Avg: [-420.589 -420.589 -420.589] (0.1000) <01:01:14> ({r_i: None, r_t: [-4235.411 -4235.411 -4235.411], critic_loss: 7527.39404296875, actor_loss: 0.10300000011920929, eps: 0.1})
Step:  141000, Reward: [-392.559 -392.559 -392.559] [68.527], Avg: [-420.490 -420.490 -420.490] (0.1000) <01:01:27> ({r_i: None, r_t: [-4155.189 -4155.189 -4155.189], critic_loss: 6414.93408203125, actor_loss: -0.05700000002980232, eps: 0.1})
Step:  141500, Reward: [-394.153 -394.153 -394.153] [57.770], Avg: [-420.397 -420.397 -420.397] (0.1000) <01:01:40> ({r_i: None, r_t: [-4152.767 -4152.767 -4152.767], critic_loss: 7058.84619140625, actor_loss: 0.2639999985694885, eps: 0.1})
Step:  142000, Reward: [-403.529 -403.529 -403.529] [66.949], Avg: [-420.338 -420.338 -420.338] (0.1000) <01:01:53> ({r_i: None, r_t: [-4105.892 -4105.892 -4105.892], critic_loss: 6560.59423828125, actor_loss: -0.42899999022483826, eps: 0.1})
Step:  142500, Reward: [-414.452 -414.452 -414.452] [68.182], Avg: [-420.317 -420.317 -420.317] (0.1000) <01:02:06> ({r_i: None, r_t: [-4223.795 -4223.795 -4223.795], critic_loss: 7360.5908203125, actor_loss: -0.4569999873638153, eps: 0.1})
Step:  143000, Reward: [-361.873 -361.873 -361.873] [53.415], Avg: [-420.114 -420.114 -420.114] (0.1000) <01:02:20> ({r_i: None, r_t: [-4175.352 -4175.352 -4175.352], critic_loss: 7036.85986328125, actor_loss: -0.5899999737739563, eps: 0.1})
Step:  143500, Reward: [-416.238 -416.238 -416.238] [73.033], Avg: [-420.100 -420.100 -420.100] (0.1000) <01:02:33> ({r_i: None, r_t: [-4163.117 -4163.117 -4163.117], critic_loss: 7702.416015625, actor_loss: -0.5929999947547913, eps: 0.1})
Step:  144000, Reward: [-426.576 -426.576 -426.576] [66.206], Avg: [-420.123 -420.123 -420.123] (0.1000) <01:02:46> ({r_i: None, r_t: [-4277.292 -4277.292 -4277.292], critic_loss: 7794.56005859375, actor_loss: -0.12700000405311584, eps: 0.1})
Step:  144500, Reward: [-403.460 -403.460 -403.460] [79.388], Avg: [-420.065 -420.065 -420.065] (0.1000) <01:03:00> ({r_i: None, r_t: [-4269.863 -4269.863 -4269.863], critic_loss: 8415.759765625, actor_loss: -0.30799999833106995, eps: 0.1})
Step:  145000, Reward: [-451.680 -451.680 -451.680] [103.743], Avg: [-420.174 -420.174 -420.174] (0.1000) <01:03:13> ({r_i: None, r_t: [-4380.186 -4380.186 -4380.186], critic_loss: 8624.41015625, actor_loss: 0.22200000286102295, eps: 0.1})
Step:  145500, Reward: [-443.359 -443.359 -443.359] [82.456], Avg: [-420.253 -420.253 -420.253] (0.1000) <01:03:26> ({r_i: None, r_t: [-4276.423 -4276.423 -4276.423], critic_loss: 8440.5029296875, actor_loss: 0.9710000157356262, eps: 0.1})
Step:  146000, Reward: [-426.177 -426.177 -426.177] [92.452], Avg: [-420.274 -420.274 -420.274] (0.1000) <01:03:39> ({r_i: None, r_t: [-4209.359 -4209.359 -4209.359], critic_loss: 7999.02978515625, actor_loss: 0.41499999165534973, eps: 0.1})
Step:  146500, Reward: [-413.239 -413.239 -413.239] [63.201], Avg: [-420.250 -420.250 -420.250] (0.1000) <01:03:52> ({r_i: None, r_t: [-4310.431 -4310.431 -4310.431], critic_loss: 8153.33203125, actor_loss: 0.5709999799728394, eps: 0.1})
Step:  147000, Reward: [-420.044 -420.044 -420.044] [76.200], Avg: [-420.249 -420.249 -420.249] (0.1000) <01:04:05> ({r_i: None, r_t: [-4283.556 -4283.556 -4283.556], critic_loss: 7514.4677734375, actor_loss: 0.3970000147819519, eps: 0.1})
Step:  147500, Reward: [-455.828 -455.828 -455.828] [103.851], Avg: [-420.369 -420.369 -420.369] (0.1000) <01:04:18> ({r_i: None, r_t: [-4089.977 -4089.977 -4089.977], critic_loss: 7363.23779296875, actor_loss: 0.1720000058412552, eps: 0.1})
Step:  148000, Reward: [-409.454 -409.454 -409.454] [69.636], Avg: [-420.332 -420.332 -420.332] (0.1000) <01:04:31> ({r_i: None, r_t: [-4073.210 -4073.210 -4073.210], critic_loss: 6978.8779296875, actor_loss: -0.41200000047683716, eps: 0.1})
Step:  148500, Reward: [-401.808 -401.808 -401.808] [84.335], Avg: [-420.270 -420.270 -420.270] (0.1000) <01:04:44> ({r_i: None, r_t: [-4066.275 -4066.275 -4066.275], critic_loss: 7309.60986328125, actor_loss: -0.41499999165534973, eps: 0.1})
Step:  149000, Reward: [-427.303 -427.303 -427.303] [60.522], Avg: [-420.294 -420.294 -420.294] (0.1000) <01:04:57> ({r_i: None, r_t: [-4152.686 -4152.686 -4152.686], critic_loss: 7569.97412109375, actor_loss: 0.13899999856948853, eps: 0.1})
Step:  149500, Reward: [-414.662 -414.662 -414.662] [81.486], Avg: [-420.275 -420.275 -420.275] (0.1000) <01:05:10> ({r_i: None, r_t: [-4159.977 -4159.977 -4159.977], critic_loss: 6880.1201171875, actor_loss: -0.5299999713897705, eps: 0.1})
Step:  150000, Reward: [-431.294 -431.294 -431.294] [64.912], Avg: [-420.312 -420.312 -420.312] (0.1000) <01:05:23> ({r_i: None, r_t: [-4094.631 -4094.631 -4094.631], critic_loss: 7122.255859375, actor_loss: 0.05700000002980232, eps: 0.1})
Step:  150500, Reward: [-420.542 -420.542 -420.542] [69.077], Avg: [-420.312 -420.312 -420.312] (0.1000) <01:05:36> ({r_i: None, r_t: [-4115.088 -4115.088 -4115.088], critic_loss: 7118.01708984375, actor_loss: 0.12099999934434891, eps: 0.1})
Step:  151000, Reward: [-441.585 -441.585 -441.585] [65.475], Avg: [-420.383 -420.383 -420.383] (0.1000) <01:05:49> ({r_i: None, r_t: [-4120.485 -4120.485 -4120.485], critic_loss: 7611.02587890625, actor_loss: 0.027000000700354576, eps: 0.1})
Step:  151500, Reward: [-398.196 -398.196 -398.196] [71.296], Avg: [-420.310 -420.310 -420.310] (0.1000) <01:06:02> ({r_i: None, r_t: [-4164.958 -4164.958 -4164.958], critic_loss: 7611.6337890625, actor_loss: 0.30000001192092896, eps: 0.1})
Step:  152000, Reward: [-411.597 -411.597 -411.597] [64.328], Avg: [-420.281 -420.281 -420.281] (0.1000) <01:06:15> ({r_i: None, r_t: [-4117.341 -4117.341 -4117.341], critic_loss: 8035.009765625, actor_loss: 0.10000000149011612, eps: 0.1})
Step:  152500, Reward: [-399.314 -399.314 -399.314] [67.013], Avg: [-420.212 -420.212 -420.212] (0.1000) <01:06:28> ({r_i: None, r_t: [-4149.491 -4149.491 -4149.491], critic_loss: 7102.2158203125, actor_loss: -0.5299999713897705, eps: 0.1})
Step:  153000, Reward: [-402.972 -402.972 -402.972] [54.315], Avg: [-420.156 -420.156 -420.156] (0.1000) <01:06:41> ({r_i: None, r_t: [-4194.166 -4194.166 -4194.166], critic_loss: 7125.1279296875, actor_loss: 0.4490000009536743, eps: 0.1})
Step:  153500, Reward: [-397.014 -397.014 -397.014] [50.603], Avg: [-420.081 -420.081 -420.081] (0.1000) <01:06:54> ({r_i: None, r_t: [-4091.868 -4091.868 -4091.868], critic_loss: 6960.2177734375, actor_loss: 0.24500000476837158, eps: 0.1})
Step:  154000, Reward: [-398.868 -398.868 -398.868] [57.403], Avg: [-420.013 -420.013 -420.013] (0.1000) <01:07:07> ({r_i: None, r_t: [-4124.006 -4124.006 -4124.006], critic_loss: 7763.52197265625, actor_loss: -0.6010000109672546, eps: 0.1})
Step:  154500, Reward: [-412.365 -412.365 -412.365] [67.569], Avg: [-419.988 -419.988 -419.988] (0.1000) <01:07:21> ({r_i: None, r_t: [-4095.640 -4095.640 -4095.640], critic_loss: 7745.59912109375, actor_loss: 0.2280000001192093, eps: 0.1})
Step:  155000, Reward: [-394.730 -394.730 -394.730] [72.511], Avg: [-419.907 -419.907 -419.907] (0.1000) <01:07:34> ({r_i: None, r_t: [-4181.575 -4181.575 -4181.575], critic_loss: 8714.8994140625, actor_loss: -0.3630000054836273, eps: 0.1})
Step:  155500, Reward: [-396.680 -396.680 -396.680] [102.336], Avg: [-419.832 -419.832 -419.832] (0.1000) <01:07:47> ({r_i: None, r_t: [-4103.567 -4103.567 -4103.567], critic_loss: 7029.87890625, actor_loss: 0.28999999165534973, eps: 0.1})
Step:  156000, Reward: [-403.313 -403.313 -403.313] [62.163], Avg: [-419.779 -419.779 -419.779] (0.1000) <01:08:01> ({r_i: None, r_t: [-4203.875 -4203.875 -4203.875], critic_loss: 7106.1259765625, actor_loss: 0.03799999877810478, eps: 0.1})
Step:  156500, Reward: [-385.872 -385.872 -385.872] [71.678], Avg: [-419.671 -419.671 -419.671] (0.1000) <01:08:14> ({r_i: None, r_t: [-4124.712 -4124.712 -4124.712], critic_loss: 7260.94921875, actor_loss: 0.21400000154972076, eps: 0.1})
Step:  157000, Reward: [-384.187 -384.187 -384.187] [56.227], Avg: [-419.559 -419.559 -419.559] (0.1000) <01:08:27> ({r_i: None, r_t: [-4087.872 -4087.872 -4087.872], critic_loss: 7624.2919921875, actor_loss: -0.2630000114440918, eps: 0.1})
Step:  157500, Reward: [-422.215 -422.215 -422.215] [45.940], Avg: [-419.567 -419.567 -419.567] (0.1000) <01:08:40> ({r_i: None, r_t: [-4190.197 -4190.197 -4190.197], critic_loss: 7079.18115234375, actor_loss: -0.11999999731779099, eps: 0.1})
Step:  158000, Reward: [-420.191 -420.191 -420.191] [57.094], Avg: [-419.569 -419.569 -419.569] (0.1000) <01:08:53> ({r_i: None, r_t: [-4186.617 -4186.617 -4186.617], critic_loss: 7558.40576171875, actor_loss: -0.12600000202655792, eps: 0.1})
Step:  158500, Reward: [-399.881 -399.881 -399.881] [53.694], Avg: [-419.507 -419.507 -419.507] (0.1000) <01:09:06> ({r_i: None, r_t: [-4101.562 -4101.562 -4101.562], critic_loss: 7396.02197265625, actor_loss: -0.057999998331069946, eps: 0.1})
Step:  159000, Reward: [-437.166 -437.166 -437.166] [85.778], Avg: [-419.563 -419.563 -419.563] (0.1000) <01:09:19> ({r_i: None, r_t: [-4149.091 -4149.091 -4149.091], critic_loss: 8135.08203125, actor_loss: -0.4749999940395355, eps: 0.1})
Step:  159500, Reward: [-432.762 -432.762 -432.762] [88.833], Avg: [-419.604 -419.604 -419.604] (0.1000) <01:09:32> ({r_i: None, r_t: [-4119.671 -4119.671 -4119.671], critic_loss: 8226.8720703125, actor_loss: 0.06400000303983688, eps: 0.1})
Step:  160000, Reward: [-419.925 -419.925 -419.925] [57.318], Avg: [-419.605 -419.605 -419.605] (0.1000) <01:09:45> ({r_i: None, r_t: [-4110.992 -4110.992 -4110.992], critic_loss: 7293.88623046875, actor_loss: 0.25999999046325684, eps: 0.1})
Step:  160500, Reward: [-419.863 -419.863 -419.863] [61.063], Avg: [-419.606 -419.606 -419.606] (0.1000) <01:09:58> ({r_i: None, r_t: [-4077.178 -4077.178 -4077.178], critic_loss: 8314.2451171875, actor_loss: -0.08500000089406967, eps: 0.1})
Step:  161000, Reward: [-402.669 -402.669 -402.669] [68.534], Avg: [-419.553 -419.553 -419.553] (0.1000) <01:10:11> ({r_i: None, r_t: [-4143.800 -4143.800 -4143.800], critic_loss: 7800.2939453125, actor_loss: -0.2939999997615814, eps: 0.1})
Step:  161500, Reward: [-425.979 -425.979 -425.979] [87.198], Avg: [-419.573 -419.573 -419.573] (0.1000) <01:10:24> ({r_i: None, r_t: [-4150.451 -4150.451 -4150.451], critic_loss: 8191.4541015625, actor_loss: -0.10000000149011612, eps: 0.1})
Step:  162000, Reward: [-379.799 -379.799 -379.799] [64.197], Avg: [-419.451 -419.451 -419.451] (0.1000) <01:10:37> ({r_i: None, r_t: [-4083.283 -4083.283 -4083.283], critic_loss: 8745.216796875, actor_loss: 0.2919999957084656, eps: 0.1})
Step:  162500, Reward: [-406.594 -406.594 -406.594] [90.058], Avg: [-419.411 -419.411 -419.411] (0.1000) <01:10:50> ({r_i: None, r_t: [-4077.207 -4077.207 -4077.207], critic_loss: 7678.06591796875, actor_loss: -0.14900000393390656, eps: 0.1})
Step:  163000, Reward: [-381.336 -381.336 -381.336] [68.413], Avg: [-419.295 -419.295 -419.295] (0.1000) <01:11:04> ({r_i: None, r_t: [-4202.943 -4202.943 -4202.943], critic_loss: 7663.33984375, actor_loss: -0.3880000114440918, eps: 0.1})
Step:  163500, Reward: [-404.393 -404.393 -404.393] [84.654], Avg: [-419.249 -419.249 -419.249] (0.1000) <01:11:16> ({r_i: None, r_t: [-4110.227 -4110.227 -4110.227], critic_loss: 7956.39990234375, actor_loss: -0.057999998331069946, eps: 0.1})
Step:  164000, Reward: [-429.847 -429.847 -429.847] [65.916], Avg: [-419.282 -419.282 -419.282] (0.1000) <01:11:30> ({r_i: None, r_t: [-4088.561 -4088.561 -4088.561], critic_loss: 8010.19921875, actor_loss: 0.07900000363588333, eps: 0.1})
Step:  164500, Reward: [-409.408 -409.408 -409.408] [68.882], Avg: [-419.252 -419.252 -419.252] (0.1000) <01:11:43> ({r_i: None, r_t: [-4157.631 -4157.631 -4157.631], critic_loss: 8113.5419921875, actor_loss: -0.1120000034570694, eps: 0.1})
Step:  165000, Reward: [-431.374 -431.374 -431.374] [85.081], Avg: [-419.288 -419.288 -419.288] (0.1000) <01:11:57> ({r_i: None, r_t: [-4104.890 -4104.890 -4104.890], critic_loss: 7540.51611328125, actor_loss: 0.24300000071525574, eps: 0.1})
Step:  165500, Reward: [-429.530 -429.530 -429.530] [58.093], Avg: [-419.319 -419.319 -419.319] (0.1000) <01:12:10> ({r_i: None, r_t: [-4140.802 -4140.802 -4140.802], critic_loss: 8042.19384765625, actor_loss: -0.0989999994635582, eps: 0.1})
Step:  166000, Reward: [-411.513 -411.513 -411.513] [77.789], Avg: [-419.296 -419.296 -419.296] (0.1000) <01:12:23> ({r_i: None, r_t: [-3982.812 -3982.812 -3982.812], critic_loss: 7623.5380859375, actor_loss: 0.2630000114440918, eps: 0.1})
Step:  166500, Reward: [-396.096 -396.096 -396.096] [58.465], Avg: [-419.226 -419.226 -419.226] (0.1000) <01:12:37> ({r_i: None, r_t: [-4122.003 -4122.003 -4122.003], critic_loss: 7749.23388671875, actor_loss: -0.28600001335144043, eps: 0.1})
Step:  167000, Reward: [-407.843 -407.843 -407.843] [95.005], Avg: [-419.192 -419.192 -419.192] (0.1000) <01:12:50> ({r_i: None, r_t: [-4037.482 -4037.482 -4037.482], critic_loss: 7257.55078125, actor_loss: -0.27900001406669617, eps: 0.1})
Step:  167500, Reward: [-434.347 -434.347 -434.347] [77.509], Avg: [-419.237 -419.237 -419.237] (0.1000) <01:13:03> ({r_i: None, r_t: [-4028.807 -4028.807 -4028.807], critic_loss: 7568.43017578125, actor_loss: 0.4050000011920929, eps: 0.1})
Step:  168000, Reward: [-400.400 -400.400 -400.400] [65.367], Avg: [-419.181 -419.181 -419.181] (0.1000) <01:13:16> ({r_i: None, r_t: [-4058.809 -4058.809 -4058.809], critic_loss: 6732.166015625, actor_loss: 0.1379999965429306, eps: 0.1})
Step:  168500, Reward: [-396.000 -396.000 -396.000] [73.915], Avg: [-419.113 -419.113 -419.113] (0.1000) <01:13:29> ({r_i: None, r_t: [-4090.935 -4090.935 -4090.935], critic_loss: 6524.77001953125, actor_loss: 0.14499999582767487, eps: 0.1})
Step:  169000, Reward: [-399.257 -399.257 -399.257] [59.136], Avg: [-419.054 -419.054 -419.054] (0.1000) <01:13:42> ({r_i: None, r_t: [-4017.763 -4017.763 -4017.763], critic_loss: 6955.8818359375, actor_loss: 0.23100000619888306, eps: 0.1})
Step:  169500, Reward: [-402.107 -402.107 -402.107] [60.247], Avg: [-419.004 -419.004 -419.004] (0.1000) <01:13:56> ({r_i: None, r_t: [-3947.232 -3947.232 -3947.232], critic_loss: 6122.18017578125, actor_loss: -0.23000000417232513, eps: 0.1})
Step:  170000, Reward: [-399.050 -399.050 -399.050] [82.952], Avg: [-418.946 -418.946 -418.946] (0.1000) <01:14:09> ({r_i: None, r_t: [-4020.934 -4020.934 -4020.934], critic_loss: 5759.8017578125, actor_loss: 0.01600000075995922, eps: 0.1})
Step:  170500, Reward: [-376.460 -376.460 -376.460] [56.342], Avg: [-418.822 -418.822 -418.822] (0.1000) <01:14:22> ({r_i: None, r_t: [-4023.669 -4023.669 -4023.669], critic_loss: 6666.77978515625, actor_loss: -0.4909999966621399, eps: 0.1})
Step:  171000, Reward: [-410.322 -410.322 -410.322] [69.217], Avg: [-418.797 -418.797 -418.797] (0.1000) <01:14:35> ({r_i: None, r_t: [-4135.598 -4135.598 -4135.598], critic_loss: 7387.80419921875, actor_loss: -0.19599999487400055, eps: 0.1})
Step:  171500, Reward: [-418.195 -418.195 -418.195] [55.536], Avg: [-418.795 -418.795 -418.795] (0.1000) <01:14:48> ({r_i: None, r_t: [-4125.215 -4125.215 -4125.215], critic_loss: 7085.97412109375, actor_loss: -0.029999999329447746, eps: 0.1})
Step:  172000, Reward: [-441.150 -441.150 -441.150] [95.744], Avg: [-418.860 -418.860 -418.860] (0.1000) <01:15:01> ({r_i: None, r_t: [-4077.524 -4077.524 -4077.524], critic_loss: 7362.40185546875, actor_loss: -0.34599998593330383, eps: 0.1})
Step:  172500, Reward: [-409.739 -409.739 -409.739] [75.474], Avg: [-418.834 -418.834 -418.834] (0.1000) <01:15:14> ({r_i: None, r_t: [-4048.592 -4048.592 -4048.592], critic_loss: 7679.3349609375, actor_loss: -0.029999999329447746, eps: 0.1})
Step:  173000, Reward: [-405.394 -405.394 -405.394] [93.925], Avg: [-418.795 -418.795 -418.795] (0.1000) <01:15:27> ({r_i: None, r_t: [-4054.186 -4054.186 -4054.186], critic_loss: 6845.658203125, actor_loss: 0.19300000369548798, eps: 0.1})
Step:  173500, Reward: [-385.918 -385.918 -385.918] [63.367], Avg: [-418.700 -418.700 -418.700] (0.1000) <01:15:40> ({r_i: None, r_t: [-4020.438 -4020.438 -4020.438], critic_loss: 6863.68017578125, actor_loss: -0.032999999821186066, eps: 0.1})
Step:  174000, Reward: [-416.272 -416.272 -416.272] [57.922], Avg: [-418.693 -418.693 -418.693] (0.1000) <01:15:53> ({r_i: None, r_t: [-4043.025 -4043.025 -4043.025], critic_loss: 7239.416015625, actor_loss: -0.09200000017881393, eps: 0.1})
Step:  174500, Reward: [-406.529 -406.529 -406.529] [65.249], Avg: [-418.659 -418.659 -418.659] (0.1000) <01:16:07> ({r_i: None, r_t: [-4063.679 -4063.679 -4063.679], critic_loss: 6426.91015625, actor_loss: 0.17399999499320984, eps: 0.1})
Step:  175000, Reward: [-396.577 -396.577 -396.577] [63.711], Avg: [-418.596 -418.596 -418.596] (0.1000) <01:16:20> ({r_i: None, r_t: [-3915.634 -3915.634 -3915.634], critic_loss: 6134.3779296875, actor_loss: 0.10499999672174454, eps: 0.1})
Step:  175500, Reward: [-403.282 -403.282 -403.282] [57.474], Avg: [-418.552 -418.552 -418.552] (0.1000) <01:16:33> ({r_i: None, r_t: [-4121.631 -4121.631 -4121.631], critic_loss: 6514.44482421875, actor_loss: 0.22300000488758087, eps: 0.1})
Step:  176000, Reward: [-397.639 -397.639 -397.639] [56.004], Avg: [-418.493 -418.493 -418.493] (0.1000) <01:16:47> ({r_i: None, r_t: [-4008.933 -4008.933 -4008.933], critic_loss: 6567.2138671875, actor_loss: -0.16599999368190765, eps: 0.1})
Step:  176500, Reward: [-412.438 -412.438 -412.438] [53.342], Avg: [-418.476 -418.476 -418.476] (0.1000) <01:17:00> ({r_i: None, r_t: [-4114.013 -4114.013 -4114.013], critic_loss: 6759.52978515625, actor_loss: -0.08799999952316284, eps: 0.1})
Step:  177000, Reward: [-383.815 -383.815 -383.815] [55.822], Avg: [-418.378 -418.378 -418.378] (0.1000) <01:17:14> ({r_i: None, r_t: [-4080.030 -4080.030 -4080.030], critic_loss: 6194.91015625, actor_loss: 0.06400000303983688, eps: 0.1})
Step:  177500, Reward: [-424.659 -424.659 -424.659] [62.849], Avg: [-418.396 -418.396 -418.396] (0.1000) <01:17:27> ({r_i: None, r_t: [-4105.520 -4105.520 -4105.520], critic_loss: 6382.501953125, actor_loss: -0.06800000369548798, eps: 0.1})
Step:  178000, Reward: [-382.860 -382.860 -382.860] [50.008], Avg: [-418.296 -418.296 -418.296] (0.1000) <01:17:40> ({r_i: None, r_t: [-4085.466 -4085.466 -4085.466], critic_loss: 7002.30322265625, actor_loss: -0.1289999932050705, eps: 0.1})
Step:  178500, Reward: [-426.215 -426.215 -426.215] [75.453], Avg: [-418.319 -418.319 -418.319] (0.1000) <01:17:53> ({r_i: None, r_t: [-4031.513 -4031.513 -4031.513], critic_loss: 6536.7021484375, actor_loss: -0.2070000022649765, eps: 0.1})
Step:  179000, Reward: [-414.261 -414.261 -414.261] [93.583], Avg: [-418.307 -418.307 -418.307] (0.1000) <01:18:06> ({r_i: None, r_t: [-4020.805 -4020.805 -4020.805], critic_loss: 6248.1640625, actor_loss: -0.35199999809265137, eps: 0.1})
Step:  179500, Reward: [-364.101 -364.101 -364.101] [69.771], Avg: [-418.157 -418.157 -418.157] (0.1000) <01:18:19> ({r_i: None, r_t: [-3894.621 -3894.621 -3894.621], critic_loss: 6201.30419921875, actor_loss: -0.23199999332427979, eps: 0.1})
Step:  180000, Reward: [-427.602 -427.602 -427.602] [77.063], Avg: [-418.183 -418.183 -418.183] (0.1000) <01:18:32> ({r_i: None, r_t: [-4022.430 -4022.430 -4022.430], critic_loss: 7426.3818359375, actor_loss: -0.5189999938011169, eps: 0.1})
Step:  180500, Reward: [-410.945 -410.945 -410.945] [73.125], Avg: [-418.163 -418.163 -418.163] (0.1000) <01:18:45> ({r_i: None, r_t: [-3981.038 -3981.038 -3981.038], critic_loss: 7913.826171875, actor_loss: -0.22599999606609344, eps: 0.1})
Step:  181000, Reward: [-450.700 -450.700 -450.700] [70.740], Avg: [-418.252 -418.252 -418.252] (0.1000) <01:18:58> ({r_i: None, r_t: [-3945.322 -3945.322 -3945.322], critic_loss: 7409.11376953125, actor_loss: -0.3100000023841858, eps: 0.1})
Step:  181500, Reward: [-447.277 -447.277 -447.277] [84.807], Avg: [-418.332 -418.332 -418.332] (0.1000) <01:19:11> ({r_i: None, r_t: [-4060.576 -4060.576 -4060.576], critic_loss: 9148.623046875, actor_loss: 0.15000000596046448, eps: 0.1})
Step:  182000, Reward: [-451.541 -451.541 -451.541] [82.343], Avg: [-418.423 -418.423 -418.423] (0.1000) <01:19:24> ({r_i: None, r_t: [-4218.626 -4218.626 -4218.626], critic_loss: 9446.255859375, actor_loss: -0.10599999874830246, eps: 0.1})
Step:  182500, Reward: [-394.673 -394.673 -394.673] [77.355], Avg: [-418.358 -418.358 -418.358] (0.1000) <01:19:37> ({r_i: None, r_t: [-4060.594 -4060.594 -4060.594], critic_loss: 8885.615234375, actor_loss: -0.25999999046325684, eps: 0.1})
Step:  183000, Reward: [-379.292 -379.292 -379.292] [62.176], Avg: [-418.252 -418.252 -418.252] (0.1000) <01:19:50> ({r_i: None, r_t: [-4068.457 -4068.457 -4068.457], critic_loss: 7690.35400390625, actor_loss: 0.05700000002980232, eps: 0.1})
Step:  183500, Reward: [-414.435 -414.435 -414.435] [66.751], Avg: [-418.241 -418.241 -418.241] (0.1000) <01:20:03> ({r_i: None, r_t: [-3901.026 -3901.026 -3901.026], critic_loss: 7297.64013671875, actor_loss: -0.36399999260902405, eps: 0.1})
Step:  184000, Reward: [-380.369 -380.369 -380.369] [47.592], Avg: [-418.139 -418.139 -418.139] (0.1000) <01:20:16> ({r_i: None, r_t: [-4035.459 -4035.459 -4035.459], critic_loss: 8234.0498046875, actor_loss: -0.17900000512599945, eps: 0.1})
Step:  184500, Reward: [-427.175 -427.175 -427.175] [77.563], Avg: [-418.163 -418.163 -418.163] (0.1000) <01:20:29> ({r_i: None, r_t: [-3973.120 -3973.120 -3973.120], critic_loss: 8614.0439453125, actor_loss: -0.014999999664723873, eps: 0.1})
Step:  185000, Reward: [-396.094 -396.094 -396.094] [69.628], Avg: [-418.104 -418.104 -418.104] (0.1000) <01:20:42> ({r_i: None, r_t: [-4122.097 -4122.097 -4122.097], critic_loss: 9813.083984375, actor_loss: -0.4440000057220459, eps: 0.1})
Step:  185500, Reward: [-421.573 -421.573 -421.573] [85.833], Avg: [-418.113 -418.113 -418.113] (0.1000) <01:20:55> ({r_i: None, r_t: [-3930.641 -3930.641 -3930.641], critic_loss: 7990.830078125, actor_loss: -0.39399999380111694, eps: 0.1})
Step:  186000, Reward: [-407.651 -407.651 -407.651] [53.910], Avg: [-418.085 -418.085 -418.085] (0.1000) <01:21:08> ({r_i: None, r_t: [-4002.604 -4002.604 -4002.604], critic_loss: 7629.97412109375, actor_loss: -0.019999999552965164, eps: 0.1})
Step:  186500, Reward: [-381.408 -381.408 -381.408] [58.310], Avg: [-417.987 -417.987 -417.987] (0.1000) <01:21:21> ({r_i: None, r_t: [-3961.023 -3961.023 -3961.023], critic_loss: 8116.5380859375, actor_loss: 0.006000000052154064, eps: 0.1})
Step:  187000, Reward: [-423.583 -423.583 -423.583] [60.560], Avg: [-418.002 -418.002 -418.002] (0.1000) <01:21:35> ({r_i: None, r_t: [-4182.090 -4182.090 -4182.090], critic_loss: 9309.521484375, actor_loss: 0.008999999612569809, eps: 0.1})
Step:  187500, Reward: [-417.922 -417.922 -417.922] [90.330], Avg: [-418.002 -418.002 -418.002] (0.1000) <01:21:48> ({r_i: None, r_t: [-4238.663 -4238.663 -4238.663], critic_loss: 9718.953125, actor_loss: 0.35600000619888306, eps: 0.1})
Step:  188000, Reward: [-401.873 -401.873 -401.873] [50.663], Avg: [-417.959 -417.959 -417.959] (0.1000) <01:22:01> ({r_i: None, r_t: [-4096.822 -4096.822 -4096.822], critic_loss: 8937.1171875, actor_loss: 0.21199999749660492, eps: 0.1})
Step:  188500, Reward: [-404.324 -404.324 -404.324] [47.488], Avg: [-417.923 -417.923 -417.923] (0.1000) <01:22:14> ({r_i: None, r_t: [-3986.049 -3986.049 -3986.049], critic_loss: 8233.908203125, actor_loss: 0.013000000268220901, eps: 0.1})
Step:  189000, Reward: [-396.420 -396.420 -396.420] [64.107], Avg: [-417.866 -417.866 -417.866] (0.1000) <01:22:27> ({r_i: None, r_t: [-3959.205 -3959.205 -3959.205], critic_loss: 8044.61181640625, actor_loss: -0.10999999940395355, eps: 0.1})
Step:  189500, Reward: [-385.864 -385.864 -385.864] [71.633], Avg: [-417.782 -417.782 -417.782] (0.1000) <01:22:40> ({r_i: None, r_t: [-3970.680 -3970.680 -3970.680], critic_loss: 7340.34814453125, actor_loss: 0.17000000178813934, eps: 0.1})
Step:  190000, Reward: [-411.005 -411.005 -411.005] [47.313], Avg: [-417.764 -417.764 -417.764] (0.1000) <01:22:54> ({r_i: None, r_t: [-4091.707 -4091.707 -4091.707], critic_loss: 8269.4619140625, actor_loss: -0.1469999998807907, eps: 0.1})
Step:  190500, Reward: [-382.308 -382.308 -382.308] [59.315], Avg: [-417.671 -417.671 -417.671] (0.1000) <01:23:07> ({r_i: None, r_t: [-3935.252 -3935.252 -3935.252], critic_loss: 7913.71484375, actor_loss: -0.3799999952316284, eps: 0.1})
Step:  191000, Reward: [-411.120 -411.120 -411.120] [107.619], Avg: [-417.654 -417.654 -417.654] (0.1000) <01:23:19> ({r_i: None, r_t: [-3937.898 -3937.898 -3937.898], critic_loss: 7633.06103515625, actor_loss: -0.3100000023841858, eps: 0.1})
Step:  191500, Reward: [-387.336 -387.336 -387.336] [70.832], Avg: [-417.575 -417.575 -417.575] (0.1000) <01:23:32> ({r_i: None, r_t: [-3849.620 -3849.620 -3849.620], critic_loss: 7895.828125, actor_loss: 0.16200000047683716, eps: 0.1})
Step:  192000, Reward: [-386.580 -386.580 -386.580] [57.226], Avg: [-417.495 -417.495 -417.495] (0.1000) <01:23:45> ({r_i: None, r_t: [-4198.220 -4198.220 -4198.220], critic_loss: 8727.251953125, actor_loss: 0.11900000274181366, eps: 0.1})
Step:  192500, Reward: [-433.879 -433.879 -433.879] [56.512], Avg: [-417.537 -417.537 -417.537] (0.1000) <01:23:59> ({r_i: None, r_t: [-4119.032 -4119.032 -4119.032], critic_loss: 8491.5615234375, actor_loss: 0.11900000274181366, eps: 0.1})
Step:  193000, Reward: [-394.100 -394.100 -394.100] [56.781], Avg: [-417.477 -417.477 -417.477] (0.1000) <01:24:12> ({r_i: None, r_t: [-4138.378 -4138.378 -4138.378], critic_loss: 9086.26171875, actor_loss: 0.125, eps: 0.1})
Step:  193500, Reward: [-384.582 -384.582 -384.582] [45.716], Avg: [-417.392 -417.392 -417.392] (0.1000) <01:24:24> ({r_i: None, r_t: [-4116.868 -4116.868 -4116.868], critic_loss: 8619.787109375, actor_loss: -0.45399999618530273, eps: 0.1})
Step:  194000, Reward: [-397.291 -397.291 -397.291] [93.780], Avg: [-417.340 -417.340 -417.340] (0.1000) <01:24:37> ({r_i: None, r_t: [-3949.043 -3949.043 -3949.043], critic_loss: 7553.22607421875, actor_loss: -0.03799999877810478, eps: 0.1})
Step:  194500, Reward: [-424.992 -424.992 -424.992] [94.947], Avg: [-417.360 -417.360 -417.360] (0.1000) <01:24:50> ({r_i: None, r_t: [-4062.152 -4062.152 -4062.152], critic_loss: 8396.318359375, actor_loss: -0.44600000977516174, eps: 0.1})
Step:  195000, Reward: [-423.715 -423.715 -423.715] [87.742], Avg: [-417.376 -417.376 -417.376] (0.1000) <01:25:03> ({r_i: None, r_t: [-4042.382 -4042.382 -4042.382], critic_loss: 8432.35546875, actor_loss: -0.1940000057220459, eps: 0.1})
Step:  195500, Reward: [-413.316 -413.316 -413.316] [62.699], Avg: [-417.366 -417.366 -417.366] (0.1000) <01:25:16> ({r_i: None, r_t: [-4018.595 -4018.595 -4018.595], critic_loss: 8488.3193359375, actor_loss: 0.0430000014603138, eps: 0.1})
Step:  196000, Reward: [-421.445 -421.445 -421.445] [64.590], Avg: [-417.376 -417.376 -417.376] (0.1000) <01:25:29> ({r_i: None, r_t: [-4132.636 -4132.636 -4132.636], critic_loss: 9260.638671875, actor_loss: -0.09399999678134918, eps: 0.1})
Step:  196500, Reward: [-421.351 -421.351 -421.351] [69.950], Avg: [-417.386 -417.386 -417.386] (0.1000) <01:25:42> ({r_i: None, r_t: [-4260.285 -4260.285 -4260.285], critic_loss: 10650.2236328125, actor_loss: 0.593999981880188, eps: 0.1})
Step:  197000, Reward: [-411.814 -411.814 -411.814] [49.927], Avg: [-417.372 -417.372 -417.372] (0.1000) <01:25:55> ({r_i: None, r_t: [-4146.992 -4146.992 -4146.992], critic_loss: 10204.9326171875, actor_loss: 0.4830000102519989, eps: 0.1})
Step:  197500, Reward: [-366.190 -366.190 -366.190] [53.446], Avg: [-417.243 -417.243 -417.243] (0.1000) <01:26:08> ({r_i: None, r_t: [-4155.989 -4155.989 -4155.989], critic_loss: 9231.173828125, actor_loss: -0.006000000052154064, eps: 0.1})
Step:  198000, Reward: [-403.469 -403.469 -403.469] [69.038], Avg: [-417.208 -417.208 -417.208] (0.1000) <01:26:21> ({r_i: None, r_t: [-4127.553 -4127.553 -4127.553], critic_loss: 7996.490234375, actor_loss: -0.49799999594688416, eps: 0.1})
Step:  198500, Reward: [-405.921 -405.921 -405.921] [65.054], Avg: [-417.180 -417.180 -417.180] (0.1000) <01:26:35> ({r_i: None, r_t: [-4110.232 -4110.232 -4110.232], critic_loss: 8629.677734375, actor_loss: -0.29899999499320984, eps: 0.1})
Step:  199000, Reward: [-405.511 -405.511 -405.511] [73.433], Avg: [-417.150 -417.150 -417.150] (0.1000) <01:26:48> ({r_i: None, r_t: [-4032.940 -4032.940 -4032.940], critic_loss: 7938.7138671875, actor_loss: -0.16899999976158142, eps: 0.1})
Step:  199500, Reward: [-382.158 -382.158 -382.158] [63.128], Avg: [-417.063 -417.063 -417.063] (0.1000) <01:27:01> ({r_i: None, r_t: [-4011.425 -4011.425 -4011.425], critic_loss: 8326.626953125, actor_loss: -0.07199999690055847, eps: 0.1})
Step:  200000, Reward: [-366.652 -366.652 -366.652] [52.340], Avg: [-416.937 -416.937 -416.937] (0.1000) <01:27:14> ({r_i: None, r_t: [-4059.306 -4059.306 -4059.306], critic_loss: 9056.171875, actor_loss: 0.04100000113248825, eps: 0.1})
