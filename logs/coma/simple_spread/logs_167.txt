Model: <class 'multiagent.coma.COMAAgent'>, Dir: simple_spread, Date: 13/03/2020 15:18:35
num_envs: 16,
state_size: [(1, 18), (1, 18), (1, 18)],
action_size: [[1, 5], [1, 5], [1, 5]],
action_space: [MultiDiscrete([5]), MultiDiscrete([5]), MultiDiscrete([5])],
envs: <class 'utils.envs.EnsembleEnv'>,
reward_shape: False,
icm: False,

import torch
import numpy as np
from models.rand import MultiagentReplayBuffer3
from utils.network import PTACNetwork, PTACAgent, PTCritic, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, TARGET_UPDATE_RATE, one_hot_from_indices

EPS_MIN = 0.1               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.99             	# The rate at which eps decays from EPS_MAX to EPS_MIN
REPLAY_BATCH_SIZE = 10			# Number of episodes to train on for each train step
EPISODE_BUFFER = 64				# Sets the maximum length of the replay buffer
TIME_BATCHES = 100				# The number of batches of time steps to train critic in reverse time sequence
NUM_STEPS = 500					# The number of steps to collect experience in sequence for each GAE calculation

class COMAActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_probs = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, eps):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		action_probs = self.action_probs(state).softmax(-1)
		action_probs = ((1 - eps) * action_probs + torch.ones_like(action_probs).to(state.device) * eps/action_probs.size(-1))
		action = torch.distributions.Categorical(action_probs).sample().long()
		return one_hot_from_indices(action, action_probs.size(-1)), action_probs

class COMANetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=True, load=""):
		self.actor = COMAActor([state_size[0][-1] + action_size[0][-1] + len(state_size)], action_size[0])
		self.critic = lambda s,a: PTCritic([np.sum([np.prod(s) for s in state_size]) + 2*np.sum([np.prod(a) for a in action_size]) + state_size[0][-1] + len(state_size)], action_size[0])
		super().__init__(state_size, action_size, actor=lambda s,a: self.actor, critic=self.critic, lr=lr, gpu=gpu, load=load, name="coma")

	def get_action_probs(self, inputs, eps, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			action, action_probs = self.actor_local(inputs, eps)
			return [x.cpu().numpy() if numpy else x for x in [action, action_probs]]

	def optimize(self, actions, critic_inputs, actor_inputs, rewards, dones, eps):
		critic_losses = []
		q_next_value = self.critic_target(critic_inputs)
		q_next_taken = torch.gather(q_next_value, dim=-1, index=actions.argmax(-1, keepdims=True)).squeeze(-1)
		q_next_taken = torch.cat([q_next_taken, torch.zeros_like(q_next_taken[:,-1]).unsqueeze(1)], dim=1)
		q_target = PTACAgent.compute_ma_gae(rewards.unsqueeze(-1), dones.unsqueeze(-1), q_next_taken)
		q_value = torch.zeros_like(q_next_value)
		t_batch = max(rewards.size(1)//TIME_BATCHES, 1)
		for t in reversed(range(0,min(rewards.size(1), t_batch*TIME_BATCHES),t_batch)):
			q_value[:,t:t+t_batch] = self.critic_local(critic_inputs[:,t:t+t_batch])
			q_taken = torch.gather(q_value[:,t:t+t_batch], dim=-1, index=actions[:,t:t+t_batch].argmax(-1, keepdims=True)).squeeze(-1)
			critic_error = (q_taken - q_target[:,t:t+t_batch].detach())
			critic_loss = critic_error.pow(2).mean()
			critic_losses.append(critic_loss.detach().cpu().numpy())
			self.step(self.critic_optimizer, critic_loss, self.critic_local.parameters(), retain=t>0)
		self.soft_copy(self.critic_local, self.critic_target)

		action_probs = self.get_action_probs(actor_inputs, eps, grad=True)[1]
		q_value = q_value.reshape(-1, action_probs.shape[-1])
		pi = action_probs.view(-1, action_probs.shape[-1])
		baseline = (pi * q_value).sum(-1).detach()
		q_taken = torch.gather(q_value, dim=1, index=actions.argmax(-1).reshape(-1, 1)).squeeze(1)
		pi_taken = torch.gather(pi, dim=1, index=actions.argmax(-1).reshape(-1, 1)).squeeze(1)
		advantages = (q_taken - baseline).detach()
		actor_loss = - (advantages * pi_taken.log()).mean()
		self.step(self.actor_optimizer, actor_loss, self.actor_local.parameters())
		return [np.mean(critic_losses), np.mean(actor_loss.detach().cpu().numpy())]

class COMAAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, COMANetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.replay_buffer = MultiagentReplayBuffer3(EPISODE_BUFFER, state_size, action_size)
		self.n_agents = len(action_size)
		self.stats = []

	def get_action(self, state, eps=None, sample=True, numpy=True):
		eps = self.eps if eps is None else eps
		obs = np.concatenate(state, -2)
		if not hasattr(self, "action"): self.action = np.zeros([*obs.shape[:-1], self.action_size[0][-1]])
		agent_ids = np.repeat(np.expand_dims(np.eye(self.n_agents), 0), repeats=obs.shape[0], axis=0)
		inputs = torch.from_numpy(np.concatenate([obs, self.action, agent_ids], -1)).float().to(self.network.device)
		self.action = self.network.get_action_probs(inputs, eps=self.eps, numpy=True)[0]
		return np.split(self.action, len(self.action_size), axis=-2)

	def train(self, state, action, next_state, reward, done):
		self.step = 0 if not hasattr(self, "step") else self.step + 1
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]):
			states, actions, rewards, dones = map(lambda x: torch.stack(self.to_tensor(x),2), zip(*self.buffer))
			obs, actions = [x.squeeze(-2) for x in [states, actions]]
			state = states.repeat(1,1,1,self.n_agents,1).view(*states.shape[:3],-1)
			actions_joint = actions.view(*actions.shape[:2],1,-1).repeat(1,1,self.n_agents,1)
			agent_mask = (1-torch.eye(self.n_agents, device=self.network.device))
			agent_mask = agent_mask.view(-1, 1).repeat(1, self.action_size[0][-1]).view(self.n_agents, -1).unsqueeze(0).unsqueeze(0)
			last_actions = torch.cat([torch.zeros_like(actions[:, 0:1]), actions[:, :-1]], dim=1)
			last_actions_joint = last_actions.view(*last_actions.shape[:2],1,-1).repeat(1,1,self.n_agents,1)
			agent_inds = torch.eye(self.n_agents, device=self.network.device).unsqueeze(0).unsqueeze(0).expand(*obs.shape[:2],-1,-1)
			critic_inputs = torch.cat([state, obs, actions_joint * agent_mask, last_actions_joint, agent_inds], dim=-1)
			actor_inputs = torch.cat([obs, last_actions, agent_inds], dim=-1)
			self.replay_buffer.add([self.to_numpy([x.transpose(0,1)]) for x in (actions, critic_inputs, actor_inputs, rewards, dones)])
			self.buffer.clear()
		if (self.step % self.update_freq)==0 and len(self.replay_buffer) >= REPLAY_BATCH_SIZE:
			actions, critic_inputs, actor_inputs, rewards, dones = [x[0] for x in self.replay_buffer.sample(REPLAY_BATCH_SIZE, lambda x: torch.Tensor(x).to(self.network.device))]
			self.stats.append(self.network.optimize(actions, critic_inputs, actor_inputs, rewards.mean(-1), dones.mean(-1), self.eps))
		if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)

	def get_stats(self):
		stats = {k:v for k,v in zip(["critic_loss", "actor_loss"], np.mean(self.stats, axis=0))} if len(self.stats)>0 else {}
		self.stats = []
		return {**stats, **super().get_stats()}

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0003           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.001   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 256				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 512				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.998			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.001               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 1000000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.sac import SACAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, DoubleAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv, TrainEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, MPI_SIZE, MPI_RANK
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-3]
# env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False, reward_shape=False):
	if env_name in gym_envs: return TrainEnv(gym.make(env_name))
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	ballr = lambda x,y: (np.maximum if x>0 else np.minimum)(x - np.abs(y)*np.sign(x), 0.5*x)
	reward_fn = lambda obs,reward,eps: [0.1*(ballr(o[0,88], o[0,89])) + r for o,r in zip(obs,reward)]
	return FootballTeamEnv(ggym, env_name, reward_fn if reward_shape else None)

def train(model, steps=10000, ports=16, env_name=env_name, trial_at=500, save_at=10, checkpoint=True, save_best=False, log=True, render=False, reward_shape=False, icm=False):
	envs = (EnvManager if type(ports) == list or MPI_SIZE > 1 else EnsembleEnv)(lambda: make_env(env_name, reward_shape=reward_shape), ports)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, envs.num_envs, load="", gpu=True, agent2=RandomAgent, save_dir=env_name, icm=icm) 
	logger = Logger(model, env_name, num_envs=envs.num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space, envs=type(envs), reward_shape=reward_shape, icm=icm)
	states = envs.reset(train=True)
	total_rewards = []
	for s in range(steps+1):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions, train=True)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if s%trial_at == 0:
			rollouts = rollout(envs, agent, render=render)
			total_rewards.append(np.mean(rollouts, axis=-1))
			if save_best and np.all(total_rewards[-1] >= np.max(total_rewards, axis=-1)): agent.save_model(env_name)
			if checkpoint and len(total_rewards) % save_at==0: agent.save_model(env_name, f"checkpoint{'_rs' if reward_shape else ''}{'_icm' if icm else ''}")
			if log: logger.log(f"Step: {s:7d}, Reward: {total_rewards[-1]} [{np.std(rollouts):4.3f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.eps:.4f})", agent.get_stats())

def trial(model, env_name, render):
	envs = EnsembleEnv(lambda: make_env(env_name, log=True, render=render), 0)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, gpu=False, load=f"{env_name}", agent2=RandomAgent, save_dir=env_name)
	print(f"Reward: {np.mean([rollout(envs.env, agent, eps=0.0, render=True) for _ in range(5)], axis=0)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="coma", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=200000, help="Number of steps to train the agent")
	parser.add_argument("--reward_shape", action="store_true", help="Whether to shape rewards for football")
	parser.add_argument("--icm", action="store_true", help="Whether to use intrinsic motivation")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--trial", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "sac":SACAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent, "rand":RandomAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.selfport is not None or MPI_RANK>0:
		EnvWorker(self_port=args.selfport, make_env=make_env).start()
	elif args.trial:
		trial(model=model, env_name=env_name, render=args.render)
	else:
		train(model=model, steps=args.steps, ports=args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render, reward_shape=args.reward_shape, icm=args.icm)


Step:       0, Reward: [-464.111 -464.111 -464.111] [73.408], Avg: [-464.111 -464.111 -464.111] (1.0000) <00:00:00> ({r_i: None, r_t: [-8.944 -8.944 -8.944], eps: 1.0})
Step:     500, Reward: [-474.628 -474.628 -474.628] [68.853], Avg: [-469.369 -469.369 -469.369] (0.9044) <00:00:18> ({r_i: None, r_t: [-4852.623 -4852.623 -4852.623], critic_loss: 7987.67822265625, actor_loss: -0.15800000727176666, eps: 0.904})
Step:    1000, Reward: [-521.011 -521.011 -521.011] [134.505], Avg: [-486.583 -486.583 -486.583] (0.8179) <00:00:35> ({r_i: None, r_t: [-4863.912 -4863.912 -4863.912], critic_loss: 9027.9326171875, actor_loss: -0.1340000033378601, eps: 0.818})
Step:    1500, Reward: [-497.708 -497.708 -497.708] [121.670], Avg: [-489.365 -489.365 -489.365] (0.7397) <00:00:52> ({r_i: None, r_t: [-4856.149 -4856.149 -4856.149], critic_loss: 8741.23046875, actor_loss: 0.35600000619888306, eps: 0.74})
Step:    2000, Reward: [-477.343 -477.343 -477.343] [99.220], Avg: [-486.960 -486.960 -486.960] (0.6690) <00:01:09> ({r_i: None, r_t: [-4933.016 -4933.016 -4933.016], critic_loss: 9304.8681640625, actor_loss: -0.29899999499320984, eps: 0.669})
Step:    2500, Reward: [-521.333 -521.333 -521.333] [81.130], Avg: [-492.689 -492.689 -492.689] (0.6050) <00:01:26> ({r_i: None, r_t: [-5007.810 -5007.810 -5007.810], critic_loss: 7688.73388671875, actor_loss: -0.010999999940395355, eps: 0.605})
Step:    3000, Reward: [-545.450 -545.450 -545.450] [89.640], Avg: [-500.226 -500.226 -500.226] (0.5472) <00:01:43> ({r_i: None, r_t: [-5049.711 -5049.711 -5049.711], critic_loss: 6783.30615234375, actor_loss: -0.00800000037997961, eps: 0.547})
Step:    3500, Reward: [-513.718 -513.718 -513.718] [107.176], Avg: [-501.913 -501.913 -501.913] (0.4948) <00:02:00> ({r_i: None, r_t: [-4987.443 -4987.443 -4987.443], critic_loss: 4847.98193359375, actor_loss: -0.1459999978542328, eps: 0.495})
Step:    4000, Reward: [-535.414 -535.414 -535.414] [121.279], Avg: [-505.635 -505.635 -505.635] (0.4475) <00:02:17> ({r_i: None, r_t: [-5042.790 -5042.790 -5042.790], critic_loss: 5231.72021484375, actor_loss: 0.10599999874830246, eps: 0.448})
Step:    4500, Reward: [-497.758 -497.758 -497.758] [101.776], Avg: [-504.847 -504.847 -504.847] (0.4047) <00:02:34> ({r_i: None, r_t: [-5022.301 -5022.301 -5022.301], critic_loss: 4901.0322265625, actor_loss: 0.5360000133514404, eps: 0.405})
Step:    5000, Reward: [-523.368 -523.368 -523.368] [144.221], Avg: [-506.531 -506.531 -506.531] (0.3660) <00:02:51> ({r_i: None, r_t: [-5172.008 -5172.008 -5172.008], critic_loss: 5270.53515625, actor_loss: -0.4059999883174896, eps: 0.366})
Step:    5500, Reward: [-499.501 -499.501 -499.501] [136.924], Avg: [-505.945 -505.945 -505.945] (0.3310) <00:03:08> ({r_i: None, r_t: [-5137.207 -5137.207 -5137.207], critic_loss: 5627.25, actor_loss: 0.6990000009536743, eps: 0.331})
Step:    6000, Reward: [-496.792 -496.792 -496.792] [75.445], Avg: [-505.241 -505.241 -505.241] (0.2994) <00:03:25> ({r_i: None, r_t: [-5186.252 -5186.252 -5186.252], critic_loss: 4555.3759765625, actor_loss: 0.0560000017285347, eps: 0.299})
Step:    6500, Reward: [-530.434 -530.434 -530.434] [129.651], Avg: [-507.041 -507.041 -507.041] (0.2708) <00:03:42> ({r_i: None, r_t: [-5135.169 -5135.169 -5135.169], critic_loss: 5258.0888671875, actor_loss: 0.28600001335144043, eps: 0.271})
Step:    7000, Reward: [-454.853 -454.853 -454.853] [69.024], Avg: [-503.561 -503.561 -503.561] (0.2449) <00:03:59> ({r_i: None, r_t: [-5034.785 -5034.785 -5034.785], critic_loss: 4966.32080078125, actor_loss: -0.027000000700354576, eps: 0.245})
Step:    7500, Reward: [-472.330 -472.330 -472.330] [120.072], Avg: [-501.610 -501.610 -501.610] (0.2215) <00:04:16> ({r_i: None, r_t: [-5127.964 -5127.964 -5127.964], critic_loss: 7370.68603515625, actor_loss: -0.2370000034570694, eps: 0.221})
Step:    8000, Reward: [-501.656 -501.656 -501.656] [100.346], Avg: [-501.612 -501.612 -501.612] (0.2003) <00:04:34> ({r_i: None, r_t: [-5087.009 -5087.009 -5087.009], critic_loss: 5733.05810546875, actor_loss: 0.0860000029206276, eps: 0.2})
Step:    8500, Reward: [-470.576 -470.576 -470.576] [100.919], Avg: [-499.888 -499.888 -499.888] (0.1811) <00:04:50> ({r_i: None, r_t: [-5062.730 -5062.730 -5062.730], critic_loss: 4939.34521484375, actor_loss: 0.210999995470047, eps: 0.181})
Step:    9000, Reward: [-443.109 -443.109 -443.109] [74.888], Avg: [-496.900 -496.900 -496.900] (0.1638) <00:05:07> ({r_i: None, r_t: [-4844.303 -4844.303 -4844.303], critic_loss: 4947.48388671875, actor_loss: 0.40799999237060547, eps: 0.164})
Step:    9500, Reward: [-480.099 -480.099 -480.099] [96.994], Avg: [-496.060 -496.060 -496.060] (0.1481) <00:05:25> ({r_i: None, r_t: [-5027.457 -5027.457 -5027.457], critic_loss: 4688.19384765625, actor_loss: 0.3059999942779541, eps: 0.148})
Step:   10000, Reward: [-492.377 -492.377 -492.377] [69.634], Avg: [-495.884 -495.884 -495.884] (0.1340) <00:05:42> ({r_i: None, r_t: [-4842.716 -4842.716 -4842.716], critic_loss: 5070.9658203125, actor_loss: -0.05000000074505806, eps: 0.134})
Step:   10500, Reward: [-523.169 -523.169 -523.169] [100.278], Avg: [-497.124 -497.124 -497.124] (0.1212) <00:05:59> ({r_i: None, r_t: [-4711.755 -4711.755 -4711.755], critic_loss: 4735.2001953125, actor_loss: -0.33000001311302185, eps: 0.121})
Step:   11000, Reward: [-470.353 -470.353 -470.353] [104.051], Avg: [-495.960 -495.960 -495.960] (0.1096) <00:06:16> ({r_i: None, r_t: [-4663.942 -4663.942 -4663.942], critic_loss: 3508.590087890625, actor_loss: 0.03999999910593033, eps: 0.11})
Step:   11500, Reward: [-449.508 -449.508 -449.508] [64.924], Avg: [-494.025 -494.025 -494.025] (0.1000) <00:06:33> ({r_i: None, r_t: [-4594.109 -4594.109 -4594.109], critic_loss: 4378.33203125, actor_loss: -0.2329999953508377, eps: 0.1})
Step:   12000, Reward: [-449.879 -449.879 -449.879] [63.638], Avg: [-492.259 -492.259 -492.259] (0.1000) <00:06:50> ({r_i: None, r_t: [-4559.596 -4559.596 -4559.596], critic_loss: 4172.68310546875, actor_loss: -0.25699999928474426, eps: 0.1})
Step:   12500, Reward: [-460.127 -460.127 -460.127] [90.576], Avg: [-491.023 -491.023 -491.023] (0.1000) <00:07:07> ({r_i: None, r_t: [-4583.311 -4583.311 -4583.311], critic_loss: 3978.44189453125, actor_loss: -0.35199999809265137, eps: 0.1})
Step:   13000, Reward: [-463.166 -463.166 -463.166] [67.349], Avg: [-489.991 -489.991 -489.991] (0.1000) <00:07:23> ({r_i: None, r_t: [-4530.793 -4530.793 -4530.793], critic_loss: 3073.35498046875, actor_loss: 0.007000000216066837, eps: 0.1})
Step:   13500, Reward: [-468.780 -468.780 -468.780] [98.323], Avg: [-489.234 -489.234 -489.234] (0.1000) <00:07:40> ({r_i: None, r_t: [-4686.659 -4686.659 -4686.659], critic_loss: 3031.791015625, actor_loss: -0.008999999612569809, eps: 0.1})
Step:   14000, Reward: [-423.791 -423.791 -423.791] [56.806], Avg: [-486.977 -486.977 -486.977] (0.1000) <00:07:58> ({r_i: None, r_t: [-4483.445 -4483.445 -4483.445], critic_loss: 3501.537109375, actor_loss: -0.5170000195503235, eps: 0.1})
Step:   14500, Reward: [-468.333 -468.333 -468.333] [90.127], Avg: [-486.356 -486.356 -486.356] (0.1000) <00:08:16> ({r_i: None, r_t: [-4660.309 -4660.309 -4660.309], critic_loss: 4900.408203125, actor_loss: -0.4300000071525574, eps: 0.1})
Step:   15000, Reward: [-497.239 -497.239 -497.239] [94.206], Avg: [-486.707 -486.707 -486.707] (0.1000) <00:08:33> ({r_i: None, r_t: [-4806.605 -4806.605 -4806.605], critic_loss: 4644.1748046875, actor_loss: -0.9240000247955322, eps: 0.1})
Step:   15500, Reward: [-578.735 -578.735 -578.735] [184.392], Avg: [-489.583 -489.583 -489.583] (0.1000) <00:08:50> ({r_i: None, r_t: [-4927.062 -4927.062 -4927.062], critic_loss: 3785.340087890625, actor_loss: -0.5669999718666077, eps: 0.1})
Step:   16000, Reward: [-495.260 -495.260 -495.260] [118.861], Avg: [-489.755 -489.755 -489.755] (0.1000) <00:09:08> ({r_i: None, r_t: [-5213.303 -5213.303 -5213.303], critic_loss: 5730.97802734375, actor_loss: -0.21400000154972076, eps: 0.1})
Step:   16500, Reward: [-501.705 -501.705 -501.705] [129.673], Avg: [-490.106 -490.106 -490.106] (0.1000) <00:09:25> ({r_i: None, r_t: [-5275.437 -5275.437 -5275.437], critic_loss: 18444.3515625, actor_loss: -0.023000000044703484, eps: 0.1})
Step:   17000, Reward: [-586.058 -586.058 -586.058] [141.848], Avg: [-492.848 -492.848 -492.848] (0.1000) <00:09:42> ({r_i: None, r_t: [-5324.724 -5324.724 -5324.724], critic_loss: 8825.755859375, actor_loss: -0.5270000100135803, eps: 0.1})
Step:   17500, Reward: [-578.766 -578.766 -578.766] [195.650], Avg: [-495.234 -495.234 -495.234] (0.1000) <00:09:58> ({r_i: None, r_t: [-5548.191 -5548.191 -5548.191], critic_loss: 15931.2158203125, actor_loss: -0.7839999794960022, eps: 0.1})
Step:   18000, Reward: [-575.435 -575.435 -575.435] [159.596], Avg: [-497.402 -497.402 -497.402] (0.1000) <00:10:15> ({r_i: None, r_t: [-5763.716 -5763.716 -5763.716], critic_loss: 20119.224609375, actor_loss: -0.859000027179718, eps: 0.1})
Step:   18500, Reward: [-563.983 -563.983 -563.983] [111.362], Avg: [-499.154 -499.154 -499.154] (0.1000) <00:10:33> ({r_i: None, r_t: [-5929.530 -5929.530 -5929.530], critic_loss: 24506.505859375, actor_loss: 0.2290000021457672, eps: 0.1})
Step:   19000, Reward: [-614.337 -614.337 -614.337] [160.268], Avg: [-502.107 -502.107 -502.107] (0.1000) <00:10:50> ({r_i: None, r_t: [-5829.092 -5829.092 -5829.092], critic_loss: 23175.2890625, actor_loss: 0.5509999990463257, eps: 0.1})
Step:   19500, Reward: [-670.145 -670.145 -670.145] [209.994], Avg: [-506.308 -506.308 -506.308] (0.1000) <00:11:07> ({r_i: None, r_t: [-6350.947 -6350.947 -6350.947], critic_loss: 12927.3916015625, actor_loss: -0.6430000066757202, eps: 0.1})
Step:   20000, Reward: [-567.247 -567.247 -567.247] [101.724], Avg: [-507.795 -507.795 -507.795] (0.1000) <00:11:25> ({r_i: None, r_t: [-6223.106 -6223.106 -6223.106], critic_loss: 20658.533203125, actor_loss: -2.6700000762939453, eps: 0.1})
Step:   20500, Reward: [-619.427 -619.427 -619.427] [211.066], Avg: [-510.453 -510.453 -510.453] (0.1000) <00:11:47> ({r_i: None, r_t: [-6193.682 -6193.682 -6193.682], critic_loss: 42086.6640625, actor_loss: -0.28600001335144043, eps: 0.1})
Step:   21000, Reward: [-591.548 -591.548 -591.548] [114.513], Avg: [-512.339 -512.339 -512.339] (0.1000) <00:12:06> ({r_i: None, r_t: [-6104.516 -6104.516 -6104.516], critic_loss: 16496.927734375, actor_loss: 0.7870000004768372, eps: 0.1})
Step:   21500, Reward: [-582.607 -582.607 -582.607] [158.140], Avg: [-513.936 -513.936 -513.936] (0.1000) <00:12:23> ({r_i: None, r_t: [-6103.454 -6103.454 -6103.454], critic_loss: 10407.7412109375, actor_loss: 1.2029999494552612, eps: 0.1})
Step:   22000, Reward: [-545.018 -545.018 -545.018] [89.745], Avg: [-514.626 -514.626 -514.626] (0.1000) <00:12:40> ({r_i: None, r_t: [-6116.518 -6116.518 -6116.518], critic_loss: 16401.40234375, actor_loss: 0.05400000140070915, eps: 0.1})
Step:   22500, Reward: [-552.974 -552.974 -552.974] [126.270], Avg: [-515.460 -515.460 -515.460] (0.1000) <00:12:57> ({r_i: None, r_t: [-5781.345 -5781.345 -5781.345], critic_loss: 19750.9609375, actor_loss: 1.1759999990463257, eps: 0.1})
Step:   23000, Reward: [-557.563 -557.563 -557.563] [110.788], Avg: [-516.356 -516.356 -516.356] (0.1000) <00:13:15> ({r_i: None, r_t: [-5919.904 -5919.904 -5919.904], critic_loss: 18695.92578125, actor_loss: -2.575000047683716, eps: 0.1})
Step:   23500, Reward: [-507.202 -507.202 -507.202] [137.798], Avg: [-516.165 -516.165 -516.165] (0.1000) <00:13:34> ({r_i: None, r_t: [-5453.028 -5453.028 -5453.028], critic_loss: 6248.2041015625, actor_loss: 1.7430000305175781, eps: 0.1})
Step:   24000, Reward: [-535.076 -535.076 -535.076] [121.988], Avg: [-516.551 -516.551 -516.551] (0.1000) <00:13:54> ({r_i: None, r_t: [-5650.430 -5650.430 -5650.430], critic_loss: 8285.59375, actor_loss: 1.0299999713897705, eps: 0.1})
Step:   24500, Reward: [-493.152 -493.152 -493.152] [100.087], Avg: [-516.083 -516.083 -516.083] (0.1000) <00:14:13> ({r_i: None, r_t: [-5585.762 -5585.762 -5585.762], critic_loss: 14937.9658203125, actor_loss: -3.742000102996826, eps: 0.1})
Step:   25000, Reward: [-470.512 -470.512 -470.512] [68.653], Avg: [-515.190 -515.190 -515.190] (0.1000) <00:14:33> ({r_i: None, r_t: [-5242.883 -5242.883 -5242.883], critic_loss: 7239.39501953125, actor_loss: -0.6809999942779541, eps: 0.1})
Step:   25500, Reward: [-521.473 -521.473 -521.473] [122.608], Avg: [-515.310 -515.310 -515.310] (0.1000) <00:14:50> ({r_i: None, r_t: [-5285.122 -5285.122 -5285.122], critic_loss: 7347.48779296875, actor_loss: -2.749000072479248, eps: 0.1})
Step:   26000, Reward: [-509.987 -509.987 -509.987] [92.804], Avg: [-515.210 -515.210 -515.210] (0.1000) <00:15:07> ({r_i: None, r_t: [-5224.172 -5224.172 -5224.172], critic_loss: 7923.046875, actor_loss: -2.496000051498413, eps: 0.1})
Step:   26500, Reward: [-432.780 -432.780 -432.780] [72.447], Avg: [-513.683 -513.683 -513.683] (0.1000) <00:15:24> ({r_i: None, r_t: [-5093.421 -5093.421 -5093.421], critic_loss: 6232.65576171875, actor_loss: -0.45500001311302185, eps: 0.1})
Step:   27000, Reward: [-480.401 -480.401 -480.401] [103.014], Avg: [-513.078 -513.078 -513.078] (0.1000) <00:15:42> ({r_i: None, r_t: [-4895.067 -4895.067 -4895.067], critic_loss: 7118.02197265625, actor_loss: -1.9620000123977661, eps: 0.1})
Step:   27500, Reward: [-478.900 -478.900 -478.900] [86.024], Avg: [-512.468 -512.468 -512.468] (0.1000) <00:15:59> ({r_i: None, r_t: [-4795.599 -4795.599 -4795.599], critic_loss: 4959.94482421875, actor_loss: -1.1230000257492065, eps: 0.1})
Step:   28000, Reward: [-450.586 -450.586 -450.586] [64.233], Avg: [-511.382 -511.382 -511.382] (0.1000) <00:16:16> ({r_i: None, r_t: [-4629.532 -4629.532 -4629.532], critic_loss: 4745.31787109375, actor_loss: -0.4830000102519989, eps: 0.1})
Step:   28500, Reward: [-483.624 -483.624 -483.624] [109.276], Avg: [-510.904 -510.904 -510.904] (0.1000) <00:16:35> ({r_i: None, r_t: [-4537.530 -4537.530 -4537.530], critic_loss: 5184.8681640625, actor_loss: -1.6089999675750732, eps: 0.1})
Step:   29000, Reward: [-444.010 -444.010 -444.010] [77.950], Avg: [-509.770 -509.770 -509.770] (0.1000) <00:16:52> ({r_i: None, r_t: [-4406.001 -4406.001 -4406.001], critic_loss: 3658.55810546875, actor_loss: -0.1379999965429306, eps: 0.1})
Step:   29500, Reward: [-453.527 -453.527 -453.527] [100.869], Avg: [-508.833 -508.833 -508.833] (0.1000) <00:17:08> ({r_i: None, r_t: [-4547.737 -4547.737 -4547.737], critic_loss: 2835.095947265625, actor_loss: -0.6010000109672546, eps: 0.1})
Step:   30000, Reward: [-448.206 -448.206 -448.206] [94.453], Avg: [-507.839 -507.839 -507.839] (0.1000) <00:17:25> ({r_i: None, r_t: [-4607.152 -4607.152 -4607.152], critic_loss: 3113.595947265625, actor_loss: -0.029999999329447746, eps: 0.1})
Step:   30500, Reward: [-446.855 -446.855 -446.855] [91.155], Avg: [-506.855 -506.855 -506.855] (0.1000) <00:17:40> ({r_i: None, r_t: [-4616.737 -4616.737 -4616.737], critic_loss: 4195.5400390625, actor_loss: -1.9019999504089355, eps: 0.1})
Step:   31000, Reward: [-443.594 -443.594 -443.594] [64.759], Avg: [-505.851 -505.851 -505.851] (0.1000) <00:17:55> ({r_i: None, r_t: [-4544.422 -4544.422 -4544.422], critic_loss: 5961.3818359375, actor_loss: -1.1230000257492065, eps: 0.1})
Step:   31500, Reward: [-462.934 -462.934 -462.934] [90.282], Avg: [-505.180 -505.180 -505.180] (0.1000) <00:18:11> ({r_i: None, r_t: [-4404.501 -4404.501 -4404.501], critic_loss: 4707.74609375, actor_loss: -0.9559999704360962, eps: 0.1})
Step:   32000, Reward: [-446.712 -446.712 -446.712] [90.838], Avg: [-504.281 -504.281 -504.281] (0.1000) <00:18:28> ({r_i: None, r_t: [-4462.245 -4462.245 -4462.245], critic_loss: 4715.68603515625, actor_loss: -2.321000099182129, eps: 0.1})
Step:   32500, Reward: [-437.011 -437.011 -437.011] [109.743], Avg: [-503.262 -503.262 -503.262] (0.1000) <00:18:44> ({r_i: None, r_t: [-4522.477 -4522.477 -4522.477], critic_loss: 4013.35693359375, actor_loss: -1.0740000009536743, eps: 0.1})
Step:   33000, Reward: [-453.243 -453.243 -453.243] [105.472], Avg: [-502.515 -502.515 -502.515] (0.1000) <00:19:00> ({r_i: None, r_t: [-4498.442 -4498.442 -4498.442], critic_loss: 3253.381103515625, actor_loss: 0.9829999804496765, eps: 0.1})
Step:   33500, Reward: [-428.162 -428.162 -428.162] [85.044], Avg: [-501.422 -501.422 -501.422] (0.1000) <00:19:17> ({r_i: None, r_t: [-4351.518 -4351.518 -4351.518], critic_loss: 4809.423828125, actor_loss: -0.4410000145435333, eps: 0.1})
Step:   34000, Reward: [-395.060 -395.060 -395.060] [91.627], Avg: [-499.880 -499.880 -499.880] (0.1000) <00:19:33> ({r_i: None, r_t: [-4406.395 -4406.395 -4406.395], critic_loss: 3087.389892578125, actor_loss: 1.61899995803833, eps: 0.1})
Step:   34500, Reward: [-465.012 -465.012 -465.012] [84.055], Avg: [-499.382 -499.382 -499.382] (0.1000) <00:19:50> ({r_i: None, r_t: [-4549.753 -4549.753 -4549.753], critic_loss: 3624.422119140625, actor_loss: -0.5149999856948853, eps: 0.1})
Step:   35000, Reward: [-418.333 -418.333 -418.333] [43.908], Avg: [-498.240 -498.240 -498.240] (0.1000) <00:20:07> ({r_i: None, r_t: [-4267.623 -4267.623 -4267.623], critic_loss: 3800.6259765625, actor_loss: -1.7940000295639038, eps: 0.1})
Step:   35500, Reward: [-473.914 -473.914 -473.914] [118.670], Avg: [-497.903 -497.903 -497.903] (0.1000) <00:20:23> ({r_i: None, r_t: [-4297.002 -4297.002 -4297.002], critic_loss: 4057.113037109375, actor_loss: 0.33799999952316284, eps: 0.1})
Step:   36000, Reward: [-442.228 -442.228 -442.228] [87.879], Avg: [-497.140 -497.140 -497.140] (0.1000) <00:20:40> ({r_i: None, r_t: [-4434.464 -4434.464 -4434.464], critic_loss: 3940.093994140625, actor_loss: 0.640999972820282, eps: 0.1})
Step:   36500, Reward: [-460.348 -460.348 -460.348] [73.882], Avg: [-496.643 -496.643 -496.643] (0.1000) <00:20:57> ({r_i: None, r_t: [-4532.036 -4532.036 -4532.036], critic_loss: 3370.087890625, actor_loss: 1.1009999513626099, eps: 0.1})
Step:   37000, Reward: [-455.537 -455.537 -455.537] [82.344], Avg: [-496.095 -496.095 -496.095] (0.1000) <00:21:13> ({r_i: None, r_t: [-4457.108 -4457.108 -4457.108], critic_loss: 3936.300048828125, actor_loss: 1.340000033378601, eps: 0.1})
Step:   37500, Reward: [-432.823 -432.823 -432.823] [89.843], Avg: [-495.262 -495.262 -495.262] (0.1000) <00:21:30> ({r_i: None, r_t: [-4293.771 -4293.771 -4293.771], critic_loss: 5005.14697265625, actor_loss: -0.4959999918937683, eps: 0.1})
Step:   38000, Reward: [-427.178 -427.178 -427.178] [80.193], Avg: [-494.378 -494.378 -494.378] (0.1000) <00:21:46> ({r_i: None, r_t: [-4379.986 -4379.986 -4379.986], critic_loss: 3987.764892578125, actor_loss: 0.08799999952316284, eps: 0.1})
Step:   38500, Reward: [-441.395 -441.395 -441.395] [107.611], Avg: [-493.699 -493.699 -493.699] (0.1000) <00:22:03> ({r_i: None, r_t: [-4465.529 -4465.529 -4465.529], critic_loss: 3058.218994140625, actor_loss: 0.17800000309944153, eps: 0.1})
Step:   39000, Reward: [-455.028 -455.028 -455.028] [91.020], Avg: [-493.209 -493.209 -493.209] (0.1000) <00:22:20> ({r_i: None, r_t: [-4411.727 -4411.727 -4411.727], critic_loss: 4796.86376953125, actor_loss: -1.347000002861023, eps: 0.1})
Step:   39500, Reward: [-431.767 -431.767 -431.767] [70.300], Avg: [-492.441 -492.441 -492.441] (0.1000) <00:22:38> ({r_i: None, r_t: [-4430.684 -4430.684 -4430.684], critic_loss: 3630.172119140625, actor_loss: 1.4210000038146973, eps: 0.1})
Step:   40000, Reward: [-413.808 -413.808 -413.808] [64.913], Avg: [-491.470 -491.470 -491.470] (0.1000) <00:22:55> ({r_i: None, r_t: [-4513.077 -4513.077 -4513.077], critic_loss: 4726.08984375, actor_loss: -1.1859999895095825, eps: 0.1})
Step:   40500, Reward: [-427.524 -427.524 -427.524] [89.433], Avg: [-490.691 -490.691 -490.691] (0.1000) <00:23:12> ({r_i: None, r_t: [-4391.906 -4391.906 -4391.906], critic_loss: 3472.968994140625, actor_loss: 0.3140000104904175, eps: 0.1})
Step:   41000, Reward: [-432.685 -432.685 -432.685] [79.297], Avg: [-489.992 -489.992 -489.992] (0.1000) <00:23:28> ({r_i: None, r_t: [-4443.092 -4443.092 -4443.092], critic_loss: 3000.138916015625, actor_loss: -0.39399999380111694, eps: 0.1})
Step:   41500, Reward: [-452.536 -452.536 -452.536] [90.305], Avg: [-489.546 -489.546 -489.546] (0.1000) <00:23:45> ({r_i: None, r_t: [-4376.903 -4376.903 -4376.903], critic_loss: 5921.72021484375, actor_loss: -0.7149999737739563, eps: 0.1})
Step:   42000, Reward: [-434.040 -434.040 -434.040] [108.013], Avg: [-488.893 -488.893 -488.893] (0.1000) <00:24:02> ({r_i: None, r_t: [-4417.860 -4417.860 -4417.860], critic_loss: 4318.626953125, actor_loss: -0.035999998450279236, eps: 0.1})
Step:   42500, Reward: [-461.182 -461.182 -461.182] [117.127], Avg: [-488.571 -488.571 -488.571] (0.1000) <00:24:18> ({r_i: None, r_t: [-4446.174 -4446.174 -4446.174], critic_loss: 5048.294921875, actor_loss: 0.3499999940395355, eps: 0.1})
Step:   43000, Reward: [-438.572 -438.572 -438.572] [62.650], Avg: [-487.996 -487.996 -487.996] (0.1000) <00:24:34> ({r_i: None, r_t: [-4364.569 -4364.569 -4364.569], critic_loss: 4290.798828125, actor_loss: -0.6520000100135803, eps: 0.1})
Step:   43500, Reward: [-422.050 -422.050 -422.050] [57.734], Avg: [-487.246 -487.246 -487.246] (0.1000) <00:24:53> ({r_i: None, r_t: [-4514.538 -4514.538 -4514.538], critic_loss: 5464.47216796875, actor_loss: -1.690000057220459, eps: 0.1})
Step:   44000, Reward: [-424.181 -424.181 -424.181] [50.596], Avg: [-486.538 -486.538 -486.538] (0.1000) <00:25:09> ({r_i: None, r_t: [-4461.108 -4461.108 -4461.108], critic_loss: 4665.9677734375, actor_loss: 0.2800000011920929, eps: 0.1})
Step:   44500, Reward: [-441.046 -441.046 -441.046] [64.704], Avg: [-486.032 -486.032 -486.032] (0.1000) <00:25:25> ({r_i: None, r_t: [-4405.335 -4405.335 -4405.335], critic_loss: 4067.946044921875, actor_loss: 1.121999979019165, eps: 0.1})
Step:   45000, Reward: [-426.859 -426.859 -426.859] [71.799], Avg: [-485.382 -485.382 -485.382] (0.1000) <00:25:42> ({r_i: None, r_t: [-4417.556 -4417.556 -4417.556], critic_loss: 4317.669921875, actor_loss: -0.7900000214576721, eps: 0.1})
Step:   45500, Reward: [-402.186 -402.186 -402.186] [72.962], Avg: [-484.478 -484.478 -484.478] (0.1000) <00:25:58> ({r_i: None, r_t: [-4540.051 -4540.051 -4540.051], critic_loss: 3740.60009765625, actor_loss: 0.828000009059906, eps: 0.1})
Step:   46000, Reward: [-441.350 -441.350 -441.350] [98.276], Avg: [-484.014 -484.014 -484.014] (0.1000) <00:26:14> ({r_i: None, r_t: [-4522.934 -4522.934 -4522.934], critic_loss: 4050.362060546875, actor_loss: 0.20600000023841858, eps: 0.1})
Step:   46500, Reward: [-417.854 -417.854 -417.854] [83.560], Avg: [-483.310 -483.310 -483.310] (0.1000) <00:26:31> ({r_i: None, r_t: [-4408.402 -4408.402 -4408.402], critic_loss: 2910.2119140625, actor_loss: 0.33799999952316284, eps: 0.1})
Step:   47000, Reward: [-464.054 -464.054 -464.054] [79.433], Avg: [-483.108 -483.108 -483.108] (0.1000) <00:26:47> ({r_i: None, r_t: [-4383.354 -4383.354 -4383.354], critic_loss: 4281.087890625, actor_loss: 0.5059999823570251, eps: 0.1})
Step:   47500, Reward: [-461.316 -461.316 -461.316] [137.775], Avg: [-482.881 -482.881 -482.881] (0.1000) <00:27:03> ({r_i: None, r_t: [-4390.661 -4390.661 -4390.661], critic_loss: 4679.1318359375, actor_loss: 0.9750000238418579, eps: 0.1})
Step:   48000, Reward: [-431.466 -431.466 -431.466] [72.159], Avg: [-482.351 -482.351 -482.351] (0.1000) <00:27:19> ({r_i: None, r_t: [-4348.183 -4348.183 -4348.183], critic_loss: 5082.8828125, actor_loss: 0.14300000667572021, eps: 0.1})
Step:   48500, Reward: [-446.359 -446.359 -446.359] [79.325], Avg: [-481.983 -481.983 -481.983] (0.1000) <00:27:36> ({r_i: None, r_t: [-4271.372 -4271.372 -4271.372], critic_loss: 3482.173095703125, actor_loss: 0.43700000643730164, eps: 0.1})
Step:   49000, Reward: [-471.942 -471.942 -471.942] [81.250], Avg: [-481.882 -481.882 -481.882] (0.1000) <00:27:52> ({r_i: None, r_t: [-4469.478 -4469.478 -4469.478], critic_loss: 3610.48388671875, actor_loss: -1.8389999866485596, eps: 0.1})
Step:   49500, Reward: [-460.882 -460.882 -460.882] [97.314], Avg: [-481.672 -481.672 -481.672] (0.1000) <00:28:09> ({r_i: None, r_t: [-4344.488 -4344.488 -4344.488], critic_loss: 4237.34619140625, actor_loss: 0.8119999766349792, eps: 0.1})
Step:   50000, Reward: [-434.734 -434.734 -434.734] [107.701], Avg: [-481.207 -481.207 -481.207] (0.1000) <00:28:25> ({r_i: None, r_t: [-4375.194 -4375.194 -4375.194], critic_loss: 4038.6201171875, actor_loss: -0.13500000536441803, eps: 0.1})
Step:   50500, Reward: [-447.049 -447.049 -447.049] [85.317], Avg: [-480.872 -480.872 -480.872] (0.1000) <00:28:42> ({r_i: None, r_t: [-4359.742 -4359.742 -4359.742], critic_loss: 5232.8662109375, actor_loss: -0.7120000123977661, eps: 0.1})
Step:   51000, Reward: [-482.641 -482.641 -482.641] [82.544], Avg: [-480.889 -480.889 -480.889] (0.1000) <00:28:58> ({r_i: None, r_t: [-4318.182 -4318.182 -4318.182], critic_loss: 4028.58203125, actor_loss: -0.6470000147819519, eps: 0.1})
Step:   51500, Reward: [-407.636 -407.636 -407.636] [76.199], Avg: [-480.185 -480.185 -480.185] (0.1000) <00:29:15> ({r_i: None, r_t: [-4369.190 -4369.190 -4369.190], critic_loss: 3865.23095703125, actor_loss: 0.8349999785423279, eps: 0.1})
Step:   52000, Reward: [-423.735 -423.735 -423.735] [77.177], Avg: [-479.647 -479.647 -479.647] (0.1000) <00:29:34> ({r_i: None, r_t: [-4411.859 -4411.859 -4411.859], critic_loss: 3905.64794921875, actor_loss: 0.07500000298023224, eps: 0.1})
Step:   52500, Reward: [-452.923 -452.923 -452.923] [68.845], Avg: [-479.395 -479.395 -479.395] (0.1000) <00:29:52> ({r_i: None, r_t: [-4401.934 -4401.934 -4401.934], critic_loss: 3965.72509765625, actor_loss: -0.6019999980926514, eps: 0.1})
Step:   53000, Reward: [-439.954 -439.954 -439.954] [64.047], Avg: [-479.027 -479.027 -479.027] (0.1000) <00:30:08> ({r_i: None, r_t: [-4382.548 -4382.548 -4382.548], critic_loss: 5031.5078125, actor_loss: 0.17599999904632568, eps: 0.1})
Step:   53500, Reward: [-429.663 -429.663 -429.663] [71.135], Avg: [-478.570 -478.570 -478.570] (0.1000) <00:30:24> ({r_i: None, r_t: [-4319.503 -4319.503 -4319.503], critic_loss: 4734.5361328125, actor_loss: -1.2710000276565552, eps: 0.1})
Step:   54000, Reward: [-427.765 -427.765 -427.765] [70.677], Avg: [-478.104 -478.104 -478.104] (0.1000) <00:30:41> ({r_i: None, r_t: [-4428.813 -4428.813 -4428.813], critic_loss: 3838.802001953125, actor_loss: 1.8580000400543213, eps: 0.1})
Step:   54500, Reward: [-439.454 -439.454 -439.454] [98.617], Avg: [-477.752 -477.752 -477.752] (0.1000) <00:30:57> ({r_i: None, r_t: [-4408.124 -4408.124 -4408.124], critic_loss: 3783.77587890625, actor_loss: -0.15299999713897705, eps: 0.1})
Step:   55000, Reward: [-442.316 -442.316 -442.316] [59.148], Avg: [-477.433 -477.433 -477.433] (0.1000) <00:31:14> ({r_i: None, r_t: [-4458.354 -4458.354 -4458.354], critic_loss: 5128.2021484375, actor_loss: -1.9249999523162842, eps: 0.1})
Step:   55500, Reward: [-444.820 -444.820 -444.820] [69.377], Avg: [-477.142 -477.142 -477.142] (0.1000) <00:31:31> ({r_i: None, r_t: [-4471.096 -4471.096 -4471.096], critic_loss: 4132.97802734375, actor_loss: -0.2879999876022339, eps: 0.1})
Step:   56000, Reward: [-415.030 -415.030 -415.030] [67.930], Avg: [-476.592 -476.592 -476.592] (0.1000) <00:31:47> ({r_i: None, r_t: [-4360.972 -4360.972 -4360.972], critic_loss: 4430.87109375, actor_loss: -1.0720000267028809, eps: 0.1})
Step:   56500, Reward: [-426.413 -426.413 -426.413] [84.524], Avg: [-476.152 -476.152 -476.152] (0.1000) <00:32:04> ({r_i: None, r_t: [-4360.453 -4360.453 -4360.453], critic_loss: 4211.02099609375, actor_loss: 1.2899999618530273, eps: 0.1})
Step:   57000, Reward: [-420.648 -420.648 -420.648] [85.019], Avg: [-475.669 -475.669 -475.669] (0.1000) <00:32:20> ({r_i: None, r_t: [-4275.437 -4275.437 -4275.437], critic_loss: 3396.337890625, actor_loss: 0.5149999856948853, eps: 0.1})
Step:   57500, Reward: [-438.602 -438.602 -438.602] [97.445], Avg: [-475.350 -475.350 -475.350] (0.1000) <00:32:36> ({r_i: None, r_t: [-4454.400 -4454.400 -4454.400], critic_loss: 3267.33203125, actor_loss: 1.6859999895095825, eps: 0.1})
Step:   58000, Reward: [-421.700 -421.700 -421.700] [86.355], Avg: [-474.891 -474.891 -474.891] (0.1000) <00:32:53> ({r_i: None, r_t: [-4381.271 -4381.271 -4381.271], critic_loss: 3994.39404296875, actor_loss: -0.6029999852180481, eps: 0.1})
Step:   58500, Reward: [-449.400 -449.400 -449.400] [77.599], Avg: [-474.675 -474.675 -474.675] (0.1000) <00:33:09> ({r_i: None, r_t: [-4248.327 -4248.327 -4248.327], critic_loss: 3666.865966796875, actor_loss: 0.4050000011920929, eps: 0.1})
Step:   59000, Reward: [-408.756 -408.756 -408.756] [59.952], Avg: [-474.121 -474.121 -474.121] (0.1000) <00:33:27> ({r_i: None, r_t: [-4251.100 -4251.100 -4251.100], critic_loss: 5079.5458984375, actor_loss: 1.125, eps: 0.1})
Step:   59500, Reward: [-402.722 -402.722 -402.722] [64.664], Avg: [-473.526 -473.526 -473.526] (0.1000) <00:33:43> ({r_i: None, r_t: [-4291.111 -4291.111 -4291.111], critic_loss: 4182.73193359375, actor_loss: 0.30799999833106995, eps: 0.1})
Step:   60000, Reward: [-422.291 -422.291 -422.291] [95.899], Avg: [-473.103 -473.103 -473.103] (0.1000) <00:33:59> ({r_i: None, r_t: [-4328.852 -4328.852 -4328.852], critic_loss: 4698.0078125, actor_loss: -0.8169999718666077, eps: 0.1})
Step:   60500, Reward: [-406.805 -406.805 -406.805] [67.877], Avg: [-472.559 -472.559 -472.559] (0.1000) <00:34:16> ({r_i: None, r_t: [-4377.330 -4377.330 -4377.330], critic_loss: 2862.069091796875, actor_loss: 0.48500001430511475, eps: 0.1})
Step:   61000, Reward: [-415.239 -415.239 -415.239] [41.645], Avg: [-472.093 -472.093 -472.093] (0.1000) <00:34:32> ({r_i: None, r_t: [-4385.612 -4385.612 -4385.612], critic_loss: 4465.490234375, actor_loss: 1.8819999694824219, eps: 0.1})
Step:   61500, Reward: [-460.059 -460.059 -460.059] [95.311], Avg: [-471.996 -471.996 -471.996] (0.1000) <00:34:48> ({r_i: None, r_t: [-4493.921 -4493.921 -4493.921], critic_loss: 4015.632080078125, actor_loss: 2.9019999504089355, eps: 0.1})
Step:   62000, Reward: [-444.442 -444.442 -444.442] [73.614], Avg: [-471.776 -471.776 -471.776] (0.1000) <00:35:03> ({r_i: None, r_t: [-4280.766 -4280.766 -4280.766], critic_loss: 4656.77392578125, actor_loss: 0.12999999523162842, eps: 0.1})
Step:   62500, Reward: [-395.545 -395.545 -395.545] [83.567], Avg: [-471.171 -471.171 -471.171] (0.1000) <00:35:16> ({r_i: None, r_t: [-4390.034 -4390.034 -4390.034], critic_loss: 2045.1500244140625, actor_loss: -1.4989999532699585, eps: 0.1})
Step:   63000, Reward: [-436.529 -436.529 -436.529] [57.132], Avg: [-470.898 -470.898 -470.898] (0.1000) <00:35:31> ({r_i: None, r_t: [-4414.147 -4414.147 -4414.147], critic_loss: 4391.9267578125, actor_loss: -0.34200000762939453, eps: 0.1})
Step:   63500, Reward: [-441.488 -441.488 -441.488] [72.916], Avg: [-470.668 -470.668 -470.668] (0.1000) <00:35:44> ({r_i: None, r_t: [-4450.689 -4450.689 -4450.689], critic_loss: 3906.281982421875, actor_loss: -0.6520000100135803, eps: 0.1})
Step:   64000, Reward: [-454.935 -454.935 -454.935] [99.151], Avg: [-470.546 -470.546 -470.546] (0.1000) <00:35:56> ({r_i: None, r_t: [-4346.700 -4346.700 -4346.700], critic_loss: 2567.24609375, actor_loss: 0.7210000157356262, eps: 0.1})
Step:   64500, Reward: [-426.887 -426.887 -426.887] [80.606], Avg: [-470.211 -470.211 -470.211] (0.1000) <00:36:09> ({r_i: None, r_t: [-4423.471 -4423.471 -4423.471], critic_loss: 2948.172119140625, actor_loss: -0.4690000116825104, eps: 0.1})
Step:   65000, Reward: [-435.785 -435.785 -435.785] [77.457], Avg: [-469.948 -469.948 -469.948] (0.1000) <00:36:23> ({r_i: None, r_t: [-4336.699 -4336.699 -4336.699], critic_loss: 5013.31884765625, actor_loss: -0.527999997138977, eps: 0.1})
Step:   65500, Reward: [-448.608 -448.608 -448.608] [101.708], Avg: [-469.786 -469.786 -469.786] (0.1000) <00:36:36> ({r_i: None, r_t: [-4419.049 -4419.049 -4419.049], critic_loss: 4415.759765625, actor_loss: -0.12300000339746475, eps: 0.1})
Step:   66000, Reward: [-409.890 -409.890 -409.890] [52.618], Avg: [-469.336 -469.336 -469.336] (0.1000) <00:36:49> ({r_i: None, r_t: [-4388.384 -4388.384 -4388.384], critic_loss: 3515.5380859375, actor_loss: -0.503000020980835, eps: 0.1})
Step:   66500, Reward: [-433.967 -433.967 -433.967] [54.049], Avg: [-469.072 -469.072 -469.072] (0.1000) <00:37:02> ({r_i: None, r_t: [-4325.979 -4325.979 -4325.979], critic_loss: 4449.72607421875, actor_loss: 0.42500001192092896, eps: 0.1})
Step:   67000, Reward: [-465.053 -465.053 -465.053] [124.166], Avg: [-469.042 -469.042 -469.042] (0.1000) <00:37:15> ({r_i: None, r_t: [-4391.293 -4391.293 -4391.293], critic_loss: 5179.0341796875, actor_loss: -0.367000013589859, eps: 0.1})
Step:   67500, Reward: [-434.222 -434.222 -434.222] [77.488], Avg: [-468.786 -468.786 -468.786] (0.1000) <00:37:27> ({r_i: None, r_t: [-4396.570 -4396.570 -4396.570], critic_loss: 4526.14208984375, actor_loss: 0.13600000739097595, eps: 0.1})
Step:   68000, Reward: [-466.151 -466.151 -466.151] [85.603], Avg: [-468.767 -468.767 -468.767] (0.1000) <00:37:41> ({r_i: None, r_t: [-4464.841 -4464.841 -4464.841], critic_loss: 2094.47509765625, actor_loss: 1.909999966621399, eps: 0.1})
Step:   68500, Reward: [-442.408 -442.408 -442.408] [65.094], Avg: [-468.576 -468.576 -468.576] (0.1000) <00:37:53> ({r_i: None, r_t: [-4346.777 -4346.777 -4346.777], critic_loss: 3272.1259765625, actor_loss: -0.17900000512599945, eps: 0.1})
Step:   69000, Reward: [-413.476 -413.476 -413.476] [66.133], Avg: [-468.179 -468.179 -468.179] (0.1000) <00:38:07> ({r_i: None, r_t: [-4301.769 -4301.769 -4301.769], critic_loss: 5997.76806640625, actor_loss: 0.1720000058412552, eps: 0.1})
Step:   69500, Reward: [-435.724 -435.724 -435.724] [103.278], Avg: [-467.948 -467.948 -467.948] (0.1000) <00:38:19> ({r_i: None, r_t: [-4382.594 -4382.594 -4382.594], critic_loss: 3434.66796875, actor_loss: -0.21299999952316284, eps: 0.1})
Step:   70000, Reward: [-407.603 -407.603 -407.603] [95.466], Avg: [-467.520 -467.520 -467.520] (0.1000) <00:38:33> ({r_i: None, r_t: [-4296.403 -4296.403 -4296.403], critic_loss: 4424.64794921875, actor_loss: -0.9010000228881836, eps: 0.1})
Step:   70500, Reward: [-453.515 -453.515 -453.515] [58.464], Avg: [-467.421 -467.421 -467.421] (0.1000) <00:38:45> ({r_i: None, r_t: [-4333.915 -4333.915 -4333.915], critic_loss: 3957.62109375, actor_loss: -0.2070000022649765, eps: 0.1})
Step:   71000, Reward: [-399.399 -399.399 -399.399] [73.582], Avg: [-466.945 -466.945 -466.945] (0.1000) <00:38:58> ({r_i: None, r_t: [-4302.177 -4302.177 -4302.177], critic_loss: 2296.654052734375, actor_loss: -0.7319999933242798, eps: 0.1})
Step:   71500, Reward: [-427.167 -427.167 -427.167] [53.314], Avg: [-466.669 -466.669 -466.669] (0.1000) <00:39:11> ({r_i: None, r_t: [-4340.332 -4340.332 -4340.332], critic_loss: 3195.964111328125, actor_loss: -0.45100000500679016, eps: 0.1})
Step:   72000, Reward: [-407.570 -407.570 -407.570] [83.225], Avg: [-466.261 -466.261 -466.261] (0.1000) <00:39:24> ({r_i: None, r_t: [-4291.349 -4291.349 -4291.349], critic_loss: 3292.58203125, actor_loss: -1.3389999866485596, eps: 0.1})
Step:   72500, Reward: [-419.764 -419.764 -419.764] [63.099], Avg: [-465.943 -465.943 -465.943] (0.1000) <00:39:37> ({r_i: None, r_t: [-4384.937 -4384.937 -4384.937], critic_loss: 3503.43603515625, actor_loss: -0.1459999978542328, eps: 0.1})
Step:   73000, Reward: [-412.372 -412.372 -412.372] [58.774], Avg: [-465.579 -465.579 -465.579] (0.1000) <00:39:50> ({r_i: None, r_t: [-4283.173 -4283.173 -4283.173], critic_loss: 3911.76708984375, actor_loss: 0.4390000104904175, eps: 0.1})
Step:   73500, Reward: [-442.859 -442.859 -442.859] [90.356], Avg: [-465.425 -465.425 -465.425] (0.1000) <00:40:03> ({r_i: None, r_t: [-4467.507 -4467.507 -4467.507], critic_loss: 3344.84912109375, actor_loss: 0.5260000228881836, eps: 0.1})
Step:   74000, Reward: [-424.789 -424.789 -424.789] [53.204], Avg: [-465.152 -465.152 -465.152] (0.1000) <00:40:17> ({r_i: None, r_t: [-4260.551 -4260.551 -4260.551], critic_loss: 4520.85595703125, actor_loss: -0.3050000071525574, eps: 0.1})
Step:   74500, Reward: [-458.403 -458.403 -458.403] [97.250], Avg: [-465.107 -465.107 -465.107] (0.1000) <00:40:30> ({r_i: None, r_t: [-4426.705 -4426.705 -4426.705], critic_loss: 3396.700927734375, actor_loss: -0.46000000834465027, eps: 0.1})
Step:   75000, Reward: [-455.214 -455.214 -455.214] [92.428], Avg: [-465.042 -465.042 -465.042] (0.1000) <00:40:43> ({r_i: None, r_t: [-4508.590 -4508.590 -4508.590], critic_loss: 3466.571044921875, actor_loss: -0.6549999713897705, eps: 0.1})
Step:   75500, Reward: [-475.893 -475.893 -475.893] [129.506], Avg: [-465.113 -465.113 -465.113] (0.1000) <00:40:57> ({r_i: None, r_t: [-4374.706 -4374.706 -4374.706], critic_loss: 2801.759033203125, actor_loss: -0.01899999938905239, eps: 0.1})
Step:   76000, Reward: [-438.177 -438.177 -438.177] [71.202], Avg: [-464.937 -464.937 -464.937] (0.1000) <00:41:09> ({r_i: None, r_t: [-4387.780 -4387.780 -4387.780], critic_loss: 3365.93701171875, actor_loss: 0.5239999890327454, eps: 0.1})
Step:   76500, Reward: [-453.148 -453.148 -453.148] [101.244], Avg: [-464.861 -464.861 -464.861] (0.1000) <00:41:22> ({r_i: None, r_t: [-4348.372 -4348.372 -4348.372], critic_loss: 3203.51806640625, actor_loss: 0.4819999933242798, eps: 0.1})
Step:   77000, Reward: [-449.470 -449.470 -449.470] [96.193], Avg: [-464.761 -464.761 -464.761] (0.1000) <00:41:35> ({r_i: None, r_t: [-4470.477 -4470.477 -4470.477], critic_loss: 4179.80078125, actor_loss: -0.05000000074505806, eps: 0.1})
Step:   77500, Reward: [-432.924 -432.924 -432.924] [95.944], Avg: [-464.557 -464.557 -464.557] (0.1000) <00:41:48> ({r_i: None, r_t: [-4431.827 -4431.827 -4431.827], critic_loss: 3531.75, actor_loss: 1.2949999570846558, eps: 0.1})
Step:   78000, Reward: [-453.977 -453.977 -453.977] [80.603], Avg: [-464.490 -464.490 -464.490] (0.1000) <00:42:01> ({r_i: None, r_t: [-4450.632 -4450.632 -4450.632], critic_loss: 3797.49609375, actor_loss: 1.6549999713897705, eps: 0.1})
Step:   78500, Reward: [-440.057 -440.057 -440.057] [67.683], Avg: [-464.335 -464.335 -464.335] (0.1000) <00:42:15> ({r_i: None, r_t: [-4421.044 -4421.044 -4421.044], critic_loss: 5438.2998046875, actor_loss: -0.22200000286102295, eps: 0.1})
Step:   79000, Reward: [-437.788 -437.788 -437.788] [95.884], Avg: [-464.168 -464.168 -464.168] (0.1000) <00:42:31> ({r_i: None, r_t: [-4368.919 -4368.919 -4368.919], critic_loss: 5083.39208984375, actor_loss: 0.02500000037252903, eps: 0.1})
Step:   79500, Reward: [-464.531 -464.531 -464.531] [85.445], Avg: [-464.170 -464.170 -464.170] (0.1000) <00:42:48> ({r_i: None, r_t: [-4453.905 -4453.905 -4453.905], critic_loss: 4334.078125, actor_loss: -1.75600004196167, eps: 0.1})
Step:   80000, Reward: [-422.107 -422.107 -422.107] [71.136], Avg: [-463.909 -463.909 -463.909] (0.1000) <00:43:04> ({r_i: None, r_t: [-4519.942 -4519.942 -4519.942], critic_loss: 3785.053955078125, actor_loss: -0.08699999749660492, eps: 0.1})
Step:   80500, Reward: [-462.038 -462.038 -462.038] [100.281], Avg: [-463.898 -463.898 -463.898] (0.1000) <00:43:19> ({r_i: None, r_t: [-4446.540 -4446.540 -4446.540], critic_loss: 3564.174072265625, actor_loss: -0.5899999737739563, eps: 0.1})
Step:   81000, Reward: [-460.479 -460.479 -460.479] [74.457], Avg: [-463.877 -463.877 -463.877] (0.1000) <00:43:34> ({r_i: None, r_t: [-4539.595 -4539.595 -4539.595], critic_loss: 4015.10498046875, actor_loss: 0.8420000076293945, eps: 0.1})
Step:   81500, Reward: [-448.772 -448.772 -448.772] [88.558], Avg: [-463.785 -463.785 -463.785] (0.1000) <00:43:49> ({r_i: None, r_t: [-4471.151 -4471.151 -4471.151], critic_loss: 5149.6220703125, actor_loss: -0.34599998593330383, eps: 0.1})
Step:   82000, Reward: [-428.031 -428.031 -428.031] [71.496], Avg: [-463.568 -463.568 -463.568] (0.1000) <00:44:03> ({r_i: None, r_t: [-4585.638 -4585.638 -4585.638], critic_loss: 5921.69677734375, actor_loss: -0.7490000128746033, eps: 0.1})
Step:   82500, Reward: [-472.354 -472.354 -472.354] [75.998], Avg: [-463.621 -463.621 -463.621] (0.1000) <00:44:18> ({r_i: None, r_t: [-4560.136 -4560.136 -4560.136], critic_loss: 4475.60205078125, actor_loss: -1.9140000343322754, eps: 0.1})
Step:   83000, Reward: [-469.453 -469.453 -469.453] [100.116], Avg: [-463.656 -463.656 -463.656] (0.1000) <00:44:32> ({r_i: None, r_t: [-4466.561 -4466.561 -4466.561], critic_loss: 3679.050048828125, actor_loss: -2.302000045776367, eps: 0.1})
Step:   83500, Reward: [-502.621 -502.621 -502.621] [106.671], Avg: [-463.888 -463.888 -463.888] (0.1000) <00:44:48> ({r_i: None, r_t: [-4591.267 -4591.267 -4591.267], critic_loss: 3029.083984375, actor_loss: -0.7710000276565552, eps: 0.1})
Step:   84000, Reward: [-508.799 -508.799 -508.799] [108.193], Avg: [-464.153 -464.153 -464.153] (0.1000) <00:45:04> ({r_i: None, r_t: [-4387.254 -4387.254 -4387.254], critic_loss: 4343.05810546875, actor_loss: -1.6339999437332153, eps: 0.1})
Step:   84500, Reward: [-462.151 -462.151 -462.151] [68.493], Avg: [-464.142 -464.142 -464.142] (0.1000) <00:45:20> ({r_i: None, r_t: [-4446.583 -4446.583 -4446.583], critic_loss: 3610.51611328125, actor_loss: -0.75, eps: 0.1})
Step:   85000, Reward: [-423.680 -423.680 -423.680] [78.096], Avg: [-463.905 -463.905 -463.905] (0.1000) <00:45:35> ({r_i: None, r_t: [-4466.675 -4466.675 -4466.675], critic_loss: 4180.59521484375, actor_loss: 0.3269999921321869, eps: 0.1})
Step:   85500, Reward: [-422.089 -422.089 -422.089] [87.515], Avg: [-463.662 -463.662 -463.662] (0.1000) <00:45:50> ({r_i: None, r_t: [-4421.225 -4421.225 -4421.225], critic_loss: 4237.97705078125, actor_loss: 2.6670000553131104, eps: 0.1})
Step:   86000, Reward: [-435.875 -435.875 -435.875] [81.709], Avg: [-463.501 -463.501 -463.501] (0.1000) <00:46:05> ({r_i: None, r_t: [-4439.744 -4439.744 -4439.744], critic_loss: 4865.2841796875, actor_loss: 1.4509999752044678, eps: 0.1})
Step:   86500, Reward: [-452.287 -452.287 -452.287] [81.837], Avg: [-463.437 -463.437 -463.437] (0.1000) <00:46:20> ({r_i: None, r_t: [-4244.792 -4244.792 -4244.792], critic_loss: 3140.912109375, actor_loss: 0.007000000216066837, eps: 0.1})
Step:   87000, Reward: [-442.229 -442.229 -442.229] [75.710], Avg: [-463.316 -463.316 -463.316] (0.1000) <00:46:34> ({r_i: None, r_t: [-4256.416 -4256.416 -4256.416], critic_loss: 4369.64501953125, actor_loss: -3.0139999389648438, eps: 0.1})
Step:   87500, Reward: [-415.148 -415.148 -415.148] [54.027], Avg: [-463.042 -463.042 -463.042] (0.1000) <00:46:49> ({r_i: None, r_t: [-4376.204 -4376.204 -4376.204], critic_loss: 2437.409912109375, actor_loss: 1.2079999446868896, eps: 0.1})
Step:   88000, Reward: [-423.483 -423.483 -423.483] [88.657], Avg: [-462.818 -462.818 -462.818] (0.1000) <00:47:04> ({r_i: None, r_t: [-4293.037 -4293.037 -4293.037], critic_loss: 3385.39794921875, actor_loss: -0.3720000088214874, eps: 0.1})
Step:   88500, Reward: [-441.073 -441.073 -441.073] [88.978], Avg: [-462.696 -462.696 -462.696] (0.1000) <00:47:19> ({r_i: None, r_t: [-4399.755 -4399.755 -4399.755], critic_loss: 3046.18896484375, actor_loss: 0.609000027179718, eps: 0.1})
Step:   89000, Reward: [-427.618 -427.618 -427.618] [74.876], Avg: [-462.500 -462.500 -462.500] (0.1000) <00:47:33> ({r_i: None, r_t: [-4436.709 -4436.709 -4436.709], critic_loss: 4071.0810546875, actor_loss: -0.23899999260902405, eps: 0.1})
Step:   89500, Reward: [-469.241 -469.241 -469.241] [81.502], Avg: [-462.538 -462.538 -462.538] (0.1000) <00:47:47> ({r_i: None, r_t: [-4401.524 -4401.524 -4401.524], critic_loss: 4704.65478515625, actor_loss: -1.8739999532699585, eps: 0.1})
Step:   90000, Reward: [-462.788 -462.788 -462.788] [70.362], Avg: [-462.539 -462.539 -462.539] (0.1000) <00:48:01> ({r_i: None, r_t: [-4359.206 -4359.206 -4359.206], critic_loss: 2630.280029296875, actor_loss: -0.8259999752044678, eps: 0.1})
Step:   90500, Reward: [-437.066 -437.066 -437.066] [72.915], Avg: [-462.399 -462.399 -462.399] (0.1000) <00:48:14> ({r_i: None, r_t: [-4315.884 -4315.884 -4315.884], critic_loss: 2954.201904296875, actor_loss: 0.004000000189989805, eps: 0.1})
Step:   91000, Reward: [-468.904 -468.904 -468.904] [121.609], Avg: [-462.435 -462.435 -462.435] (0.1000) <00:48:27> ({r_i: None, r_t: [-4498.870 -4498.870 -4498.870], critic_loss: 3474.991943359375, actor_loss: -0.7979999780654907, eps: 0.1})
Step:   91500, Reward: [-433.288 -433.288 -433.288] [99.691], Avg: [-462.276 -462.276 -462.276] (0.1000) <00:48:41> ({r_i: None, r_t: [-4388.066 -4388.066 -4388.066], critic_loss: 3107.09912109375, actor_loss: 0.4180000126361847, eps: 0.1})
Step:   92000, Reward: [-418.286 -418.286 -418.286] [84.645], Avg: [-462.039 -462.039 -462.039] (0.1000) <00:48:54> ({r_i: None, r_t: [-4349.487 -4349.487 -4349.487], critic_loss: 3108.906005859375, actor_loss: 0.008999999612569809, eps: 0.1})
Step:   92500, Reward: [-405.339 -405.339 -405.339] [77.840], Avg: [-461.734 -461.734 -461.734] (0.1000) <00:49:07> ({r_i: None, r_t: [-4388.163 -4388.163 -4388.163], critic_loss: 2826.8759765625, actor_loss: 0.49900001287460327, eps: 0.1})
Step:   93000, Reward: [-464.044 -464.044 -464.044] [80.162], Avg: [-461.746 -461.746 -461.746] (0.1000) <00:49:20> ({r_i: None, r_t: [-4390.024 -4390.024 -4390.024], critic_loss: 4135.35693359375, actor_loss: -0.9610000252723694, eps: 0.1})
Step:   93500, Reward: [-432.519 -432.519 -432.519] [96.189], Avg: [-461.591 -461.591 -461.591] (0.1000) <00:49:34> ({r_i: None, r_t: [-4356.953 -4356.953 -4356.953], critic_loss: 3005.08203125, actor_loss: 0.6019999980926514, eps: 0.1})
Step:   94000, Reward: [-424.968 -424.968 -424.968] [86.314], Avg: [-461.397 -461.397 -461.397] (0.1000) <00:49:47> ({r_i: None, r_t: [-4212.907 -4212.907 -4212.907], critic_loss: 3458.135986328125, actor_loss: -0.460999995470047, eps: 0.1})
Step:   94500, Reward: [-469.620 -469.620 -469.620] [80.696], Avg: [-461.440 -461.440 -461.440] (0.1000) <00:50:01> ({r_i: None, r_t: [-4314.209 -4314.209 -4314.209], critic_loss: 2386.1669921875, actor_loss: -0.25099998712539673, eps: 0.1})
Step:   95000, Reward: [-448.163 -448.163 -448.163] [88.022], Avg: [-461.371 -461.371 -461.371] (0.1000) <00:50:16> ({r_i: None, r_t: [-4408.311 -4408.311 -4408.311], critic_loss: 3406.179931640625, actor_loss: -0.7799999713897705, eps: 0.1})
Step:   95500, Reward: [-464.023 -464.023 -464.023] [105.426], Avg: [-461.384 -461.384 -461.384] (0.1000) <00:50:29> ({r_i: None, r_t: [-4382.185 -4382.185 -4382.185], critic_loss: 4395.39990234375, actor_loss: -0.33500000834465027, eps: 0.1})
Step:   96000, Reward: [-441.436 -441.436 -441.436] [99.422], Avg: [-461.281 -461.281 -461.281] (0.1000) <00:50:42> ({r_i: None, r_t: [-4247.173 -4247.173 -4247.173], critic_loss: 3076.468017578125, actor_loss: 1.9950000047683716, eps: 0.1})
Step:   96500, Reward: [-487.634 -487.634 -487.634] [105.963], Avg: [-461.417 -461.417 -461.417] (0.1000) <00:50:56> ({r_i: None, r_t: [-4402.066 -4402.066 -4402.066], critic_loss: 7018.134765625, actor_loss: 0.8519999980926514, eps: 0.1})
Step:   97000, Reward: [-443.342 -443.342 -443.342] [72.006], Avg: [-461.324 -461.324 -461.324] (0.1000) <00:51:09> ({r_i: None, r_t: [-4432.159 -4432.159 -4432.159], critic_loss: 3350.236083984375, actor_loss: -0.11900000274181366, eps: 0.1})
Step:   97500, Reward: [-449.903 -449.903 -449.903] [118.221], Avg: [-461.266 -461.266 -461.266] (0.1000) <00:51:23> ({r_i: None, r_t: [-4345.310 -4345.310 -4345.310], critic_loss: 4595.6982421875, actor_loss: 0.4169999957084656, eps: 0.1})
Step:   98000, Reward: [-407.937 -407.937 -407.937] [87.726], Avg: [-460.995 -460.995 -460.995] (0.1000) <00:51:37> ({r_i: None, r_t: [-4329.984 -4329.984 -4329.984], critic_loss: 4007.43603515625, actor_loss: -0.8029999732971191, eps: 0.1})
Step:   98500, Reward: [-412.149 -412.149 -412.149] [55.025], Avg: [-460.749 -460.749 -460.749] (0.1000) <00:51:50> ({r_i: None, r_t: [-4425.748 -4425.748 -4425.748], critic_loss: 3295.696044921875, actor_loss: 0.23600000143051147, eps: 0.1})
Step:   99000, Reward: [-422.277 -422.277 -422.277] [80.908], Avg: [-460.555 -460.555 -460.555] (0.1000) <00:52:03> ({r_i: None, r_t: [-4355.194 -4355.194 -4355.194], critic_loss: 2924.68603515625, actor_loss: 0.9509999752044678, eps: 0.1})
Step:   99500, Reward: [-440.231 -440.231 -440.231] [69.236], Avg: [-460.454 -460.454 -460.454] (0.1000) <00:52:17> ({r_i: None, r_t: [-4350.640 -4350.640 -4350.640], critic_loss: 3901.25, actor_loss: 1.0870000123977661, eps: 0.1})
Step:  100000, Reward: [-463.574 -463.574 -463.574] [83.326], Avg: [-460.469 -460.469 -460.469] (0.1000) <00:52:31> ({r_i: None, r_t: [-4314.434 -4314.434 -4314.434], critic_loss: 3752.373046875, actor_loss: 1.840999960899353, eps: 0.1})
Step:  100500, Reward: [-435.337 -435.337 -435.337] [76.455], Avg: [-460.345 -460.345 -460.345] (0.1000) <00:52:46> ({r_i: None, r_t: [-4300.185 -4300.185 -4300.185], critic_loss: 3416.4140625, actor_loss: 1.6549999713897705, eps: 0.1})
Step:  101000, Reward: [-423.817 -423.817 -423.817] [92.000], Avg: [-460.165 -460.165 -460.165] (0.1000) <00:53:00> ({r_i: None, r_t: [-4325.343 -4325.343 -4325.343], critic_loss: 4957.61376953125, actor_loss: 0.39100000262260437, eps: 0.1})
Step:  101500, Reward: [-439.803 -439.803 -439.803] [111.691], Avg: [-460.065 -460.065 -460.065] (0.1000) <00:53:15> ({r_i: None, r_t: [-4391.307 -4391.307 -4391.307], critic_loss: 2710.739990234375, actor_loss: 0.8980000019073486, eps: 0.1})
Step:  102000, Reward: [-393.511 -393.511 -393.511] [61.079], Avg: [-459.740 -459.740 -459.740] (0.1000) <00:53:30> ({r_i: None, r_t: [-4244.804 -4244.804 -4244.804], critic_loss: 2902.845947265625, actor_loss: 0.972000002861023, eps: 0.1})
Step:  102500, Reward: [-415.064 -415.064 -415.064] [75.268], Avg: [-459.523 -459.523 -459.523] (0.1000) <00:53:44> ({r_i: None, r_t: [-4326.194 -4326.194 -4326.194], critic_loss: 6134.52587890625, actor_loss: 2.2809998989105225, eps: 0.1})
Step:  103000, Reward: [-454.503 -454.503 -454.503] [79.133], Avg: [-459.499 -459.499 -459.499] (0.1000) <00:53:59> ({r_i: None, r_t: [-4349.556 -4349.556 -4349.556], critic_loss: 2435.587890625, actor_loss: 1.277999997138977, eps: 0.1})
Step:  103500, Reward: [-416.446 -416.446 -416.446] [60.666], Avg: [-459.292 -459.292 -459.292] (0.1000) <00:54:14> ({r_i: None, r_t: [-4213.095 -4213.095 -4213.095], critic_loss: 3812.31005859375, actor_loss: 1.3919999599456787, eps: 0.1})
Step:  104000, Reward: [-448.724 -448.724 -448.724] [75.606], Avg: [-459.242 -459.242 -459.242] (0.1000) <00:54:28> ({r_i: None, r_t: [-4284.887 -4284.887 -4284.887], critic_loss: 3637.333984375, actor_loss: -0.3919999897480011, eps: 0.1})
Step:  104500, Reward: [-434.693 -434.693 -434.693] [94.509], Avg: [-459.125 -459.125 -459.125] (0.1000) <00:54:43> ({r_i: None, r_t: [-4399.672 -4399.672 -4399.672], critic_loss: 3677.241943359375, actor_loss: 0.7319999933242798, eps: 0.1})
Step:  105000, Reward: [-444.718 -444.718 -444.718] [87.144], Avg: [-459.056 -459.056 -459.056] (0.1000) <00:54:58> ({r_i: None, r_t: [-4270.712 -4270.712 -4270.712], critic_loss: 3486.080078125, actor_loss: 1.1430000066757202, eps: 0.1})
Step:  105500, Reward: [-464.722 -464.722 -464.722] [102.074], Avg: [-459.083 -459.083 -459.083] (0.1000) <00:55:13> ({r_i: None, r_t: [-4274.980 -4274.980 -4274.980], critic_loss: 3394.422119140625, actor_loss: -1.2929999828338623, eps: 0.1})
Step:  106000, Reward: [-430.008 -430.008 -430.008] [74.167], Avg: [-458.947 -458.947 -458.947] (0.1000) <00:55:27> ({r_i: None, r_t: [-4325.014 -4325.014 -4325.014], critic_loss: 3098.681884765625, actor_loss: 1.0219999551773071, eps: 0.1})
Step:  106500, Reward: [-459.609 -459.609 -459.609] [92.783], Avg: [-458.950 -458.950 -458.950] (0.1000) <00:55:40> ({r_i: None, r_t: [-4281.468 -4281.468 -4281.468], critic_loss: 4402.89208984375, actor_loss: 0.40799999237060547, eps: 0.1})
Step:  107000, Reward: [-426.829 -426.829 -426.829] [54.388], Avg: [-458.800 -458.800 -458.800] (0.1000) <00:55:54> ({r_i: None, r_t: [-4421.194 -4421.194 -4421.194], critic_loss: 4560.19384765625, actor_loss: -1.8660000562667847, eps: 0.1})
Step:  107500, Reward: [-405.741 -405.741 -405.741] [71.711], Avg: [-458.555 -458.555 -458.555] (0.1000) <00:56:07> ({r_i: None, r_t: [-4240.602 -4240.602 -4240.602], critic_loss: 3947.72509765625, actor_loss: -0.8820000290870667, eps: 0.1})
Step:  108000, Reward: [-423.279 -423.279 -423.279] [86.086], Avg: [-458.392 -458.392 -458.392] (0.1000) <00:56:20> ({r_i: None, r_t: [-4355.345 -4355.345 -4355.345], critic_loss: 3392.820068359375, actor_loss: 0.3540000021457672, eps: 0.1})
Step:  108500, Reward: [-433.478 -433.478 -433.478] [60.697], Avg: [-458.278 -458.278 -458.278] (0.1000) <00:56:34> ({r_i: None, r_t: [-4248.188 -4248.188 -4248.188], critic_loss: 3763.837890625, actor_loss: 0.33799999952316284, eps: 0.1})
Step:  109000, Reward: [-410.905 -410.905 -410.905] [69.878], Avg: [-458.062 -458.062 -458.062] (0.1000) <00:56:47> ({r_i: None, r_t: [-4419.239 -4419.239 -4419.239], critic_loss: 3756.635986328125, actor_loss: -0.9490000009536743, eps: 0.1})
Step:  109500, Reward: [-411.224 -411.224 -411.224] [71.527], Avg: [-457.849 -457.849 -457.849] (0.1000) <00:57:00> ({r_i: None, r_t: [-4368.623 -4368.623 -4368.623], critic_loss: 2881.93408203125, actor_loss: -0.9649999737739563, eps: 0.1})
Step:  110000, Reward: [-421.152 -421.152 -421.152] [57.920], Avg: [-457.683 -457.683 -457.683] (0.1000) <00:57:15> ({r_i: None, r_t: [-4316.666 -4316.666 -4316.666], critic_loss: 3356.68603515625, actor_loss: -0.006000000052154064, eps: 0.1})
Step:  110500, Reward: [-417.618 -417.618 -417.618] [77.124], Avg: [-457.502 -457.502 -457.502] (0.1000) <00:57:30> ({r_i: None, r_t: [-4147.864 -4147.864 -4147.864], critic_loss: 3618.904052734375, actor_loss: -0.5049999952316284, eps: 0.1})
Step:  111000, Reward: [-434.643 -434.643 -434.643] [76.554], Avg: [-457.400 -457.400 -457.400] (0.1000) <00:57:46> ({r_i: None, r_t: [-4214.653 -4214.653 -4214.653], critic_loss: 2836.202880859375, actor_loss: -0.013000000268220901, eps: 0.1})
Step:  111500, Reward: [-449.419 -449.419 -449.419] [106.123], Avg: [-457.364 -457.364 -457.364] (0.1000) <00:58:03> ({r_i: None, r_t: [-4233.470 -4233.470 -4233.470], critic_loss: 3006.85205078125, actor_loss: 0.061000000685453415, eps: 0.1})
Step:  112000, Reward: [-421.973 -421.973 -421.973] [107.315], Avg: [-457.207 -457.207 -457.207] (0.1000) <00:58:18> ({r_i: None, r_t: [-4209.533 -4209.533 -4209.533], critic_loss: 3330.549072265625, actor_loss: -0.22100000083446503, eps: 0.1})
Step:  112500, Reward: [-385.374 -385.374 -385.374] [62.859], Avg: [-456.889 -456.889 -456.889] (0.1000) <00:58:33> ({r_i: None, r_t: [-4166.059 -4166.059 -4166.059], critic_loss: 4452.06396484375, actor_loss: 0.39100000262260437, eps: 0.1})
Step:  113000, Reward: [-442.444 -442.444 -442.444] [63.897], Avg: [-456.825 -456.825 -456.825] (0.1000) <00:58:48> ({r_i: None, r_t: [-4396.154 -4396.154 -4396.154], critic_loss: 3241.6279296875, actor_loss: 1.1399999856948853, eps: 0.1})
Step:  113500, Reward: [-434.230 -434.230 -434.230] [86.540], Avg: [-456.726 -456.726 -456.726] (0.1000) <00:59:04> ({r_i: None, r_t: [-4241.130 -4241.130 -4241.130], critic_loss: 2738.302978515625, actor_loss: 0.23199999332427979, eps: 0.1})
Step:  114000, Reward: [-440.221 -440.221 -440.221] [74.432], Avg: [-456.654 -456.654 -456.654] (0.1000) <00:59:19> ({r_i: None, r_t: [-4280.903 -4280.903 -4280.903], critic_loss: 2694.447998046875, actor_loss: 0.37400001287460327, eps: 0.1})
Step:  114500, Reward: [-433.351 -433.351 -433.351] [72.359], Avg: [-456.553 -456.553 -456.553] (0.1000) <00:59:34> ({r_i: None, r_t: [-4354.208 -4354.208 -4354.208], critic_loss: 3741.39208984375, actor_loss: -0.4869999885559082, eps: 0.1})
Step:  115000, Reward: [-429.430 -429.430 -429.430] [71.992], Avg: [-456.435 -456.435 -456.435] (0.1000) <00:59:49> ({r_i: None, r_t: [-4279.280 -4279.280 -4279.280], critic_loss: 3257.888916015625, actor_loss: -1.74399995803833, eps: 0.1})
Step:  115500, Reward: [-406.351 -406.351 -406.351] [60.874], Avg: [-456.219 -456.219 -456.219] (0.1000) <01:00:03> ({r_i: None, r_t: [-4359.401 -4359.401 -4359.401], critic_loss: 2837.02490234375, actor_loss: -0.28299999237060547, eps: 0.1})
Step:  116000, Reward: [-386.760 -386.760 -386.760] [51.930], Avg: [-455.921 -455.921 -455.921] (0.1000) <01:00:16> ({r_i: None, r_t: [-4267.930 -4267.930 -4267.930], critic_loss: 3494.48388671875, actor_loss: 1.024999976158142, eps: 0.1})
Step:  116500, Reward: [-372.182 -372.182 -372.182] [70.212], Avg: [-455.563 -455.563 -455.563] (0.1000) <01:00:30> ({r_i: None, r_t: [-4347.218 -4347.218 -4347.218], critic_loss: 3909.423095703125, actor_loss: 0.3799999952316284, eps: 0.1})
Step:  117000, Reward: [-457.798 -457.798 -457.798] [98.275], Avg: [-455.573 -455.573 -455.573] (0.1000) <01:00:43> ({r_i: None, r_t: [-4238.318 -4238.318 -4238.318], critic_loss: 3032.7939453125, actor_loss: -0.4350000023841858, eps: 0.1})
Step:  117500, Reward: [-383.709 -383.709 -383.709] [34.049], Avg: [-455.268 -455.268 -455.268] (0.1000) <01:00:56> ({r_i: None, r_t: [-4181.939 -4181.939 -4181.939], critic_loss: 2539.008056640625, actor_loss: -0.3869999945163727, eps: 0.1})
Step:  118000, Reward: [-410.005 -410.005 -410.005] [57.306], Avg: [-455.077 -455.077 -455.077] (0.1000) <01:01:10> ({r_i: None, r_t: [-4255.640 -4255.640 -4255.640], critic_loss: 3602.718017578125, actor_loss: -0.453000009059906, eps: 0.1})
Step:  118500, Reward: [-449.467 -449.467 -449.467] [54.070], Avg: [-455.054 -455.054 -455.054] (0.1000) <01:01:23> ({r_i: None, r_t: [-4258.797 -4258.797 -4258.797], critic_loss: 2534.264892578125, actor_loss: -0.7739999890327454, eps: 0.1})
Step:  119000, Reward: [-421.633 -421.633 -421.633] [62.762], Avg: [-454.914 -454.914 -454.914] (0.1000) <01:01:37> ({r_i: None, r_t: [-4121.585 -4121.585 -4121.585], critic_loss: 3810.760986328125, actor_loss: -0.45100000500679016, eps: 0.1})
Step:  119500, Reward: [-411.661 -411.661 -411.661] [55.592], Avg: [-454.734 -454.734 -454.734] (0.1000) <01:01:50> ({r_i: None, r_t: [-4111.609 -4111.609 -4111.609], critic_loss: 2325.35205078125, actor_loss: -0.23899999260902405, eps: 0.1})
Step:  120000, Reward: [-418.272 -418.272 -418.272] [56.880], Avg: [-454.583 -454.583 -454.583] (0.1000) <01:02:04> ({r_i: None, r_t: [-4300.799 -4300.799 -4300.799], critic_loss: 3358.7041015625, actor_loss: -1.0779999494552612, eps: 0.1})
Step:  120500, Reward: [-406.971 -406.971 -406.971] [58.390], Avg: [-454.386 -454.386 -454.386] (0.1000) <01:02:18> ({r_i: None, r_t: [-4309.785 -4309.785 -4309.785], critic_loss: 3578.72998046875, actor_loss: -0.453000009059906, eps: 0.1})
Step:  121000, Reward: [-432.431 -432.431 -432.431] [95.022], Avg: [-454.295 -454.295 -454.295] (0.1000) <01:02:31> ({r_i: None, r_t: [-4180.177 -4180.177 -4180.177], critic_loss: 3503.47607421875, actor_loss: -0.18199999630451202, eps: 0.1})
Step:  121500, Reward: [-390.075 -390.075 -390.075] [63.459], Avg: [-454.032 -454.032 -454.032] (0.1000) <01:02:45> ({r_i: None, r_t: [-4233.312 -4233.312 -4233.312], critic_loss: 3271.030029296875, actor_loss: 0.9819999933242798, eps: 0.1})
Step:  122000, Reward: [-396.052 -396.052 -396.052] [66.961], Avg: [-453.796 -453.796 -453.796] (0.1000) <01:02:58> ({r_i: None, r_t: [-4112.066 -4112.066 -4112.066], critic_loss: 2649.47900390625, actor_loss: 0.6959999799728394, eps: 0.1})
Step:  122500, Reward: [-426.290 -426.290 -426.290] [87.000], Avg: [-453.684 -453.684 -453.684] (0.1000) <01:03:12> ({r_i: None, r_t: [-4168.452 -4168.452 -4168.452], critic_loss: 3361.864990234375, actor_loss: -0.05400000140070915, eps: 0.1})
Step:  123000, Reward: [-412.071 -412.071 -412.071] [70.250], Avg: [-453.515 -453.515 -453.515] (0.1000) <01:03:25> ({r_i: None, r_t: [-4145.163 -4145.163 -4145.163], critic_loss: 3827.93310546875, actor_loss: -0.2709999978542328, eps: 0.1})
Step:  123500, Reward: [-414.632 -414.632 -414.632] [90.541], Avg: [-453.359 -453.359 -453.359] (0.1000) <01:03:39> ({r_i: None, r_t: [-4221.623 -4221.623 -4221.623], critic_loss: 2804.8359375, actor_loss: 0.29600000381469727, eps: 0.1})
Step:  124000, Reward: [-442.349 -442.349 -442.349] [66.310], Avg: [-453.314 -453.314 -453.314] (0.1000) <01:03:52> ({r_i: None, r_t: [-4161.815 -4161.815 -4161.815], critic_loss: 3034.5380859375, actor_loss: 0.2669999897480011, eps: 0.1})
Step:  124500, Reward: [-426.973 -426.973 -426.973] [98.469], Avg: [-453.209 -453.209 -453.209] (0.1000) <01:04:06> ({r_i: None, r_t: [-4204.008 -4204.008 -4204.008], critic_loss: 3585.133056640625, actor_loss: -0.15299999713897705, eps: 0.1})
Step:  125000, Reward: [-432.497 -432.497 -432.497] [77.354], Avg: [-453.126 -453.126 -453.126] (0.1000) <01:04:20> ({r_i: None, r_t: [-4139.300 -4139.300 -4139.300], critic_loss: 2598.580078125, actor_loss: -1.0110000371932983, eps: 0.1})
Step:  125500, Reward: [-451.908 -451.908 -451.908] [57.445], Avg: [-453.122 -453.122 -453.122] (0.1000) <01:04:34> ({r_i: None, r_t: [-4133.928 -4133.928 -4133.928], critic_loss: 3365.949951171875, actor_loss: -0.2370000034570694, eps: 0.1})
Step:  126000, Reward: [-429.744 -429.744 -429.744] [112.328], Avg: [-453.029 -453.029 -453.029] (0.1000) <01:04:48> ({r_i: None, r_t: [-4152.791 -4152.791 -4152.791], critic_loss: 2418.10791015625, actor_loss: -0.5389999747276306, eps: 0.1})
Step:  126500, Reward: [-397.477 -397.477 -397.477] [69.724], Avg: [-452.810 -452.810 -452.810] (0.1000) <01:05:01> ({r_i: None, r_t: [-4194.467 -4194.467 -4194.467], critic_loss: 2745.153076171875, actor_loss: 0.11999999731779099, eps: 0.1})
Step:  127000, Reward: [-439.163 -439.163 -439.163] [88.856], Avg: [-452.757 -452.757 -452.757] (0.1000) <01:05:15> ({r_i: None, r_t: [-4373.720 -4373.720 -4373.720], critic_loss: 3404.263916015625, actor_loss: 0.8389999866485596, eps: 0.1})
Step:  127500, Reward: [-430.128 -430.128 -430.128] [90.477], Avg: [-452.669 -452.669 -452.669] (0.1000) <01:05:28> ({r_i: None, r_t: [-4196.838 -4196.838 -4196.838], critic_loss: 2342.81298828125, actor_loss: 0.2750000059604645, eps: 0.1})
Step:  128000, Reward: [-448.833 -448.833 -448.833] [51.202], Avg: [-452.654 -452.654 -452.654] (0.1000) <01:05:42> ({r_i: None, r_t: [-4170.083 -4170.083 -4170.083], critic_loss: 3167.279052734375, actor_loss: -0.6629999876022339, eps: 0.1})
Step:  128500, Reward: [-394.156 -394.156 -394.156] [57.113], Avg: [-452.427 -452.427 -452.427] (0.1000) <01:05:55> ({r_i: None, r_t: [-4253.821 -4253.821 -4253.821], critic_loss: 3166.799072265625, actor_loss: 0.0949999988079071, eps: 0.1})
Step:  129000, Reward: [-417.898 -417.898 -417.898] [55.099], Avg: [-452.294 -452.294 -452.294] (0.1000) <01:06:09> ({r_i: None, r_t: [-4270.715 -4270.715 -4270.715], critic_loss: 3174.905029296875, actor_loss: 0.3160000145435333, eps: 0.1})
Step:  129500, Reward: [-417.169 -417.169 -417.169] [66.608], Avg: [-452.159 -452.159 -452.159] (0.1000) <01:06:23> ({r_i: None, r_t: [-4293.330 -4293.330 -4293.330], critic_loss: 4179.083984375, actor_loss: 0.8920000195503235, eps: 0.1})
Step:  130000, Reward: [-428.572 -428.572 -428.572] [82.163], Avg: [-452.068 -452.068 -452.068] (0.1000) <01:06:37> ({r_i: None, r_t: [-4245.239 -4245.239 -4245.239], critic_loss: 4656.4501953125, actor_loss: -0.3370000123977661, eps: 0.1})
Step:  130500, Reward: [-429.293 -429.293 -429.293] [65.748], Avg: [-451.981 -451.981 -451.981] (0.1000) <01:06:50> ({r_i: None, r_t: [-4305.062 -4305.062 -4305.062], critic_loss: 4381.66015625, actor_loss: -0.6940000057220459, eps: 0.1})
Step:  131000, Reward: [-414.434 -414.434 -414.434] [72.475], Avg: [-451.838 -451.838 -451.838] (0.1000) <01:07:04> ({r_i: None, r_t: [-4275.311 -4275.311 -4275.311], critic_loss: 3324.31396484375, actor_loss: -0.26899999380111694, eps: 0.1})
Step:  131500, Reward: [-403.211 -403.211 -403.211] [63.505], Avg: [-451.654 -451.654 -451.654] (0.1000) <01:07:17> ({r_i: None, r_t: [-4253.324 -4253.324 -4253.324], critic_loss: 4389.42822265625, actor_loss: -1.1100000143051147, eps: 0.1})
Step:  132000, Reward: [-420.699 -420.699 -420.699] [71.107], Avg: [-451.537 -451.537 -451.537] (0.1000) <01:07:31> ({r_i: None, r_t: [-4286.327 -4286.327 -4286.327], critic_loss: 2837.319091796875, actor_loss: -0.07699999958276749, eps: 0.1})
Step:  132500, Reward: [-405.768 -405.768 -405.768] [44.644], Avg: [-451.365 -451.365 -451.365] (0.1000) <01:07:45> ({r_i: None, r_t: [-4293.242 -4293.242 -4293.242], critic_loss: 3726.964111328125, actor_loss: -0.6899999976158142, eps: 0.1})
Step:  133000, Reward: [-415.943 -415.943 -415.943] [88.133], Avg: [-451.233 -451.233 -451.233] (0.1000) <01:07:58> ({r_i: None, r_t: [-4255.427 -4255.427 -4255.427], critic_loss: 3883.39208984375, actor_loss: -0.1850000023841858, eps: 0.1})
Step:  133500, Reward: [-447.325 -447.325 -447.325] [80.461], Avg: [-451.218 -451.218 -451.218] (0.1000) <01:08:12> ({r_i: None, r_t: [-4176.357 -4176.357 -4176.357], critic_loss: 3740.498046875, actor_loss: -0.8949999809265137, eps: 0.1})
Step:  134000, Reward: [-414.738 -414.738 -414.738] [41.364], Avg: [-451.083 -451.083 -451.083] (0.1000) <01:08:26> ({r_i: None, r_t: [-4229.531 -4229.531 -4229.531], critic_loss: 4306.89990234375, actor_loss: -1.593999981880188, eps: 0.1})
Step:  134500, Reward: [-446.090 -446.090 -446.090] [83.523], Avg: [-451.064 -451.064 -451.064] (0.1000) <01:08:39> ({r_i: None, r_t: [-4223.564 -4223.564 -4223.564], critic_loss: 3138.073974609375, actor_loss: -1.2910000085830688, eps: 0.1})
Step:  135000, Reward: [-398.158 -398.158 -398.158] [66.310], Avg: [-450.869 -450.869 -450.869] (0.1000) <01:08:53> ({r_i: None, r_t: [-4179.293 -4179.293 -4179.293], critic_loss: 2966.751953125, actor_loss: -0.34700000286102295, eps: 0.1})
Step:  135500, Reward: [-399.557 -399.557 -399.557] [70.146], Avg: [-450.680 -450.680 -450.680] (0.1000) <01:09:07> ({r_i: None, r_t: [-4262.940 -4262.940 -4262.940], critic_loss: 3105.138916015625, actor_loss: -0.9120000004768372, eps: 0.1})
Step:  136000, Reward: [-409.525 -409.525 -409.525] [59.972], Avg: [-450.529 -450.529 -450.529] (0.1000) <01:09:21> ({r_i: None, r_t: [-4150.781 -4150.781 -4150.781], critic_loss: 2903.35888671875, actor_loss: -0.968999981880188, eps: 0.1})
Step:  136500, Reward: [-469.409 -469.409 -469.409] [64.800], Avg: [-450.598 -450.598 -450.598] (0.1000) <01:09:35> ({r_i: None, r_t: [-4294.931 -4294.931 -4294.931], critic_loss: 3945.549072265625, actor_loss: -1.0679999589920044, eps: 0.1})
Step:  137000, Reward: [-434.246 -434.246 -434.246] [67.423], Avg: [-450.539 -450.539 -450.539] (0.1000) <01:09:48> ({r_i: None, r_t: [-4289.889 -4289.889 -4289.889], critic_loss: 2639.77587890625, actor_loss: 0.5979999899864197, eps: 0.1})
Step:  137500, Reward: [-410.632 -410.632 -410.632] [85.742], Avg: [-450.394 -450.394 -450.394] (0.1000) <01:10:02> ({r_i: None, r_t: [-4234.532 -4234.532 -4234.532], critic_loss: 2857.569091796875, actor_loss: 0.47999998927116394, eps: 0.1})
Step:  138000, Reward: [-455.248 -455.248 -455.248] [81.759], Avg: [-450.412 -450.412 -450.412] (0.1000) <01:10:16> ({r_i: None, r_t: [-4241.920 -4241.920 -4241.920], critic_loss: 3333.1298828125, actor_loss: -0.8790000081062317, eps: 0.1})
Step:  138500, Reward: [-415.794 -415.794 -415.794] [63.505], Avg: [-450.287 -450.287 -450.287] (0.1000) <01:10:30> ({r_i: None, r_t: [-4233.118 -4233.118 -4233.118], critic_loss: 3706.614013671875, actor_loss: -0.8190000057220459, eps: 0.1})
Step:  139000, Reward: [-432.623 -432.623 -432.623] [64.817], Avg: [-450.224 -450.224 -450.224] (0.1000) <01:10:44> ({r_i: None, r_t: [-4386.237 -4386.237 -4386.237], critic_loss: 3513.029052734375, actor_loss: -0.2529999911785126, eps: 0.1})
Step:  139500, Reward: [-412.286 -412.286 -412.286] [77.719], Avg: [-450.088 -450.088 -450.088] (0.1000) <01:10:58> ({r_i: None, r_t: [-4202.191 -4202.191 -4202.191], critic_loss: 3534.178955078125, actor_loss: 0.1979999989271164, eps: 0.1})
Step:  140000, Reward: [-422.235 -422.235 -422.235] [105.139], Avg: [-449.989 -449.989 -449.989] (0.1000) <01:11:12> ({r_i: None, r_t: [-4156.373 -4156.373 -4156.373], critic_loss: 2840.657958984375, actor_loss: 0.12800000607967377, eps: 0.1})
Step:  140500, Reward: [-436.220 -436.220 -436.220] [106.202], Avg: [-449.940 -449.940 -449.940] (0.1000) <01:11:26> ({r_i: None, r_t: [-4258.283 -4258.283 -4258.283], critic_loss: 2788.991943359375, actor_loss: -0.8140000104904175, eps: 0.1})
Step:  141000, Reward: [-463.367 -463.367 -463.367] [74.408], Avg: [-449.988 -449.988 -449.988] (0.1000) <01:11:40> ({r_i: None, r_t: [-4224.810 -4224.810 -4224.810], critic_loss: 2097.843994140625, actor_loss: 0.257999986410141, eps: 0.1})
Step:  141500, Reward: [-414.489 -414.489 -414.489] [49.658], Avg: [-449.863 -449.863 -449.863] (0.1000) <01:11:53> ({r_i: None, r_t: [-4250.707 -4250.707 -4250.707], critic_loss: 3378.7939453125, actor_loss: 0.2680000066757202, eps: 0.1})
Step:  142000, Reward: [-419.596 -419.596 -419.596] [61.378], Avg: [-449.757 -449.757 -449.757] (0.1000) <01:12:07> ({r_i: None, r_t: [-4285.505 -4285.505 -4285.505], critic_loss: 3335.60205078125, actor_loss: -1.059999942779541, eps: 0.1})
Step:  142500, Reward: [-402.271 -402.271 -402.271] [61.936], Avg: [-449.591 -449.591 -449.591] (0.1000) <01:12:21> ({r_i: None, r_t: [-4308.013 -4308.013 -4308.013], critic_loss: 5218.64208984375, actor_loss: -2.2300000190734863, eps: 0.1})
Step:  143000, Reward: [-475.253 -475.253 -475.253] [101.914], Avg: [-449.680 -449.680 -449.680] (0.1000) <01:12:35> ({r_i: None, r_t: [-4268.407 -4268.407 -4268.407], critic_loss: 2311.093017578125, actor_loss: -0.7059999704360962, eps: 0.1})
Step:  143500, Reward: [-403.559 -403.559 -403.559] [71.846], Avg: [-449.520 -449.520 -449.520] (0.1000) <01:12:50> ({r_i: None, r_t: [-4332.683 -4332.683 -4332.683], critic_loss: 4346.25390625, actor_loss: 0.8709999918937683, eps: 0.1})
Step:  144000, Reward: [-486.019 -486.019 -486.019] [114.597], Avg: [-449.646 -449.646 -449.646] (0.1000) <01:13:05> ({r_i: None, r_t: [-4301.982 -4301.982 -4301.982], critic_loss: 3896.64794921875, actor_loss: -0.4449999928474426, eps: 0.1})
Step:  144500, Reward: [-443.927 -443.927 -443.927] [83.072], Avg: [-449.627 -449.627 -449.627] (0.1000) <01:13:19> ({r_i: None, r_t: [-4267.792 -4267.792 -4267.792], critic_loss: 2585.9130859375, actor_loss: 0.07500000298023224, eps: 0.1})
Step:  145000, Reward: [-426.398 -426.398 -426.398] [63.008], Avg: [-449.547 -449.547 -449.547] (0.1000) <01:13:33> ({r_i: None, r_t: [-4314.564 -4314.564 -4314.564], critic_loss: 3247.319091796875, actor_loss: 0.7250000238418579, eps: 0.1})
Step:  145500, Reward: [-417.972 -417.972 -417.972] [64.619], Avg: [-449.439 -449.439 -449.439] (0.1000) <01:13:47> ({r_i: None, r_t: [-4275.974 -4275.974 -4275.974], critic_loss: 3010.919921875, actor_loss: 0.4339999854564667, eps: 0.1})
Step:  146000, Reward: [-423.351 -423.351 -423.351] [69.739], Avg: [-449.350 -449.350 -449.350] (0.1000) <01:14:01> ({r_i: None, r_t: [-4435.534 -4435.534 -4435.534], critic_loss: 3105.24609375, actor_loss: 0.3109999895095825, eps: 0.1})
Step:  146500, Reward: [-411.713 -411.713 -411.713] [80.208], Avg: [-449.222 -449.222 -449.222] (0.1000) <01:14:15> ({r_i: None, r_t: [-4305.434 -4305.434 -4305.434], critic_loss: 3508.18896484375, actor_loss: -0.41600000858306885, eps: 0.1})
Step:  147000, Reward: [-424.281 -424.281 -424.281] [43.126], Avg: [-449.137 -449.137 -449.137] (0.1000) <01:14:30> ({r_i: None, r_t: [-4373.960 -4373.960 -4373.960], critic_loss: 3148.365966796875, actor_loss: -0.8360000252723694, eps: 0.1})
Step:  147500, Reward: [-395.623 -395.623 -395.623] [72.550], Avg: [-448.956 -448.956 -448.956] (0.1000) <01:14:45> ({r_i: None, r_t: [-4246.048 -4246.048 -4246.048], critic_loss: 3479.625, actor_loss: -0.8510000109672546, eps: 0.1})
Step:  148000, Reward: [-420.930 -420.930 -420.930] [83.847], Avg: [-448.862 -448.862 -448.862] (0.1000) <01:14:59> ({r_i: None, r_t: [-4334.076 -4334.076 -4334.076], critic_loss: 3460.35009765625, actor_loss: 0.2639999985694885, eps: 0.1})
Step:  148500, Reward: [-417.510 -417.510 -417.510] [89.752], Avg: [-448.757 -448.757 -448.757] (0.1000) <01:15:14> ({r_i: None, r_t: [-4297.866 -4297.866 -4297.866], critic_loss: 4695.51416015625, actor_loss: 0.5849999785423279, eps: 0.1})
Step:  149000, Reward: [-410.000 -410.000 -410.000] [65.663], Avg: [-448.627 -448.627 -448.627] (0.1000) <01:15:30> ({r_i: None, r_t: [-4254.035 -4254.035 -4254.035], critic_loss: 3725.73095703125, actor_loss: 0.14300000667572021, eps: 0.1})
Step:  149500, Reward: [-457.008 -457.008 -457.008] [102.029], Avg: [-448.655 -448.655 -448.655] (0.1000) <01:15:45> ({r_i: None, r_t: [-4399.297 -4399.297 -4399.297], critic_loss: 3355.93603515625, actor_loss: -0.23100000619888306, eps: 0.1})
Step:  150000, Reward: [-407.156 -407.156 -407.156] [54.820], Avg: [-448.517 -448.517 -448.517] (0.1000) <01:16:01> ({r_i: None, r_t: [-4299.564 -4299.564 -4299.564], critic_loss: 3398.2890625, actor_loss: 0.6970000267028809, eps: 0.1})
Step:  150500, Reward: [-446.566 -446.566 -446.566] [67.874], Avg: [-448.511 -448.511 -448.511] (0.1000) <01:16:16> ({r_i: None, r_t: [-4277.080 -4277.080 -4277.080], critic_loss: 3843.875, actor_loss: 1.0520000457763672, eps: 0.1})
Step:  151000, Reward: [-458.550 -458.550 -458.550] [73.682], Avg: [-448.544 -448.544 -448.544] (0.1000) <01:16:32> ({r_i: None, r_t: [-4181.958 -4181.958 -4181.958], critic_loss: 4240.0419921875, actor_loss: 0.16899999976158142, eps: 0.1})
Step:  151500, Reward: [-398.996 -398.996 -398.996] [66.315], Avg: [-448.381 -448.381 -448.381] (0.1000) <01:16:47> ({r_i: None, r_t: [-4156.490 -4156.490 -4156.490], critic_loss: 2648.947021484375, actor_loss: 0.35100001096725464, eps: 0.1})
Step:  152000, Reward: [-446.207 -446.207 -446.207] [70.987], Avg: [-448.374 -448.374 -448.374] (0.1000) <01:17:03> ({r_i: None, r_t: [-4293.826 -4293.826 -4293.826], critic_loss: 3111.7109375, actor_loss: 0.8690000176429749, eps: 0.1})
Step:  152500, Reward: [-397.250 -397.250 -397.250] [74.343], Avg: [-448.207 -448.207 -448.207] (0.1000) <01:17:18> ({r_i: None, r_t: [-4361.351 -4361.351 -4361.351], critic_loss: 3249.031982421875, actor_loss: 0.382999986410141, eps: 0.1})
Step:  153000, Reward: [-420.331 -420.331 -420.331] [63.589], Avg: [-448.116 -448.116 -448.116] (0.1000) <01:17:34> ({r_i: None, r_t: [-4277.662 -4277.662 -4277.662], critic_loss: 5949.38818359375, actor_loss: 0.7580000162124634, eps: 0.1})
Step:  153500, Reward: [-433.884 -433.884 -433.884] [93.966], Avg: [-448.070 -448.070 -448.070] (0.1000) <01:17:49> ({r_i: None, r_t: [-4193.881 -4193.881 -4193.881], critic_loss: 2331.56689453125, actor_loss: 0.4350000023841858, eps: 0.1})
Step:  154000, Reward: [-387.266 -387.266 -387.266] [54.865], Avg: [-447.873 -447.873 -447.873] (0.1000) <01:18:04> ({r_i: None, r_t: [-4200.036 -4200.036 -4200.036], critic_loss: 2680.087890625, actor_loss: 0.9739999771118164, eps: 0.1})
Step:  154500, Reward: [-417.631 -417.631 -417.631] [88.257], Avg: [-447.775 -447.775 -447.775] (0.1000) <01:18:20> ({r_i: None, r_t: [-4379.614 -4379.614 -4379.614], critic_loss: 2762.16796875, actor_loss: 0.7839999794960022, eps: 0.1})
Step:  155000, Reward: [-447.933 -447.933 -447.933] [69.754], Avg: [-447.776 -447.776 -447.776] (0.1000) <01:18:35> ({r_i: None, r_t: [-4319.223 -4319.223 -4319.223], critic_loss: 2926.114013671875, actor_loss: -0.0729999989271164, eps: 0.1})
Step:  155500, Reward: [-416.725 -416.725 -416.725] [78.738], Avg: [-447.676 -447.676 -447.676] (0.1000) <01:18:51> ({r_i: None, r_t: [-4203.026 -4203.026 -4203.026], critic_loss: 3595.27587890625, actor_loss: 0.6449999809265137, eps: 0.1})
Step:  156000, Reward: [-413.758 -413.758 -413.758] [79.996], Avg: [-447.568 -447.568 -447.568] (0.1000) <01:19:06> ({r_i: None, r_t: [-4246.483 -4246.483 -4246.483], critic_loss: 3246.9599609375, actor_loss: -1.3450000286102295, eps: 0.1})
Step:  156500, Reward: [-423.053 -423.053 -423.053] [65.915], Avg: [-447.490 -447.490 -447.490] (0.1000) <01:19:22> ({r_i: None, r_t: [-4186.785 -4186.785 -4186.785], critic_loss: 3026.971923828125, actor_loss: -1.4279999732971191, eps: 0.1})
Step:  157000, Reward: [-414.558 -414.558 -414.558] [58.716], Avg: [-447.385 -447.385 -447.385] (0.1000) <01:19:39> ({r_i: None, r_t: [-4264.520 -4264.520 -4264.520], critic_loss: 3203.799072265625, actor_loss: -0.3149999976158142, eps: 0.1})
Step:  157500, Reward: [-394.628 -394.628 -394.628] [63.793], Avg: [-447.218 -447.218 -447.218] (0.1000) <01:19:55> ({r_i: None, r_t: [-4199.980 -4199.980 -4199.980], critic_loss: 3098.2490234375, actor_loss: -0.7509999871253967, eps: 0.1})
Step:  158000, Reward: [-432.416 -432.416 -432.416] [71.099], Avg: [-447.172 -447.172 -447.172] (0.1000) <01:20:10> ({r_i: None, r_t: [-4211.314 -4211.314 -4211.314], critic_loss: 3689.0830078125, actor_loss: -0.453000009059906, eps: 0.1})
Step:  158500, Reward: [-397.700 -397.700 -397.700] [77.658], Avg: [-447.016 -447.016 -447.016] (0.1000) <01:20:26> ({r_i: None, r_t: [-4362.443 -4362.443 -4362.443], critic_loss: 3147.412109375, actor_loss: -0.7820000052452087, eps: 0.1})
Step:  159000, Reward: [-443.273 -443.273 -443.273] [107.360], Avg: [-447.004 -447.004 -447.004] (0.1000) <01:20:41> ({r_i: None, r_t: [-4334.811 -4334.811 -4334.811], critic_loss: 3691.701904296875, actor_loss: -0.27900001406669617, eps: 0.1})
Step:  159500, Reward: [-408.839 -408.839 -408.839] [84.358], Avg: [-446.885 -446.885 -446.885] (0.1000) <01:20:57> ({r_i: None, r_t: [-4285.229 -4285.229 -4285.229], critic_loss: 3053.365966796875, actor_loss: 0.48100000619888306, eps: 0.1})
Step:  160000, Reward: [-425.933 -425.933 -425.933] [76.115], Avg: [-446.820 -446.820 -446.820] (0.1000) <01:21:12> ({r_i: None, r_t: [-4243.366 -4243.366 -4243.366], critic_loss: 2693.72998046875, actor_loss: -0.699999988079071, eps: 0.1})
Step:  160500, Reward: [-443.118 -443.118 -443.118] [74.378], Avg: [-446.808 -446.808 -446.808] (0.1000) <01:21:26> ({r_i: None, r_t: [-4259.384 -4259.384 -4259.384], critic_loss: 2775.966064453125, actor_loss: -0.2770000100135803, eps: 0.1})
Step:  161000, Reward: [-409.181 -409.181 -409.181] [73.899], Avg: [-446.692 -446.692 -446.692] (0.1000) <01:21:41> ({r_i: None, r_t: [-4191.741 -4191.741 -4191.741], critic_loss: 3217.64990234375, actor_loss: -0.09200000017881393, eps: 0.1})
Step:  161500, Reward: [-434.203 -434.203 -434.203] [84.701], Avg: [-446.653 -446.653 -446.653] (0.1000) <01:21:55> ({r_i: None, r_t: [-4199.243 -4199.243 -4199.243], critic_loss: 3021.9169921875, actor_loss: 0.7730000019073486, eps: 0.1})
Step:  162000, Reward: [-378.051 -378.051 -378.051] [56.883], Avg: [-446.442 -446.442 -446.442] (0.1000) <01:22:10> ({r_i: None, r_t: [-4221.172 -4221.172 -4221.172], critic_loss: 3363.115966796875, actor_loss: 0.6980000138282776, eps: 0.1})
Step:  162500, Reward: [-447.415 -447.415 -447.415] [63.476], Avg: [-446.445 -446.445 -446.445] (0.1000) <01:22:27> ({r_i: None, r_t: [-4261.393 -4261.393 -4261.393], critic_loss: 3005.7099609375, actor_loss: 0.11699999868869781, eps: 0.1})
Step:  163000, Reward: [-438.675 -438.675 -438.675] [66.460], Avg: [-446.421 -446.421 -446.421] (0.1000) <01:22:44> ({r_i: None, r_t: [-4255.583 -4255.583 -4255.583], critic_loss: 3471.298095703125, actor_loss: -0.43799999356269836, eps: 0.1})
Step:  163500, Reward: [-421.277 -421.277 -421.277] [73.942], Avg: [-446.345 -446.345 -446.345] (0.1000) <01:23:02> ({r_i: None, r_t: [-4186.233 -4186.233 -4186.233], critic_loss: 2364.177001953125, actor_loss: 0.3409999907016754, eps: 0.1})
Step:  164000, Reward: [-432.389 -432.389 -432.389] [118.921], Avg: [-446.302 -446.302 -446.302] (0.1000) <01:23:19> ({r_i: None, r_t: [-4262.196 -4262.196 -4262.196], critic_loss: 2898.173095703125, actor_loss: -0.16200000047683716, eps: 0.1})
Step:  164500, Reward: [-448.196 -448.196 -448.196] [69.939], Avg: [-446.308 -446.308 -446.308] (0.1000) <01:23:35> ({r_i: None, r_t: [-4166.540 -4166.540 -4166.540], critic_loss: 4473.3798828125, actor_loss: 0.35199999809265137, eps: 0.1})
Step:  165000, Reward: [-387.131 -387.131 -387.131] [58.867], Avg: [-446.129 -446.129 -446.129] (0.1000) <01:23:50> ({r_i: None, r_t: [-4277.983 -4277.983 -4277.983], critic_loss: 2468.552001953125, actor_loss: 0.07500000298023224, eps: 0.1})
Step:  165500, Reward: [-449.948 -449.948 -449.948] [80.152], Avg: [-446.141 -446.141 -446.141] (0.1000) <01:24:08> ({r_i: None, r_t: [-4155.015 -4155.015 -4155.015], critic_loss: 3558.7880859375, actor_loss: -0.10300000011920929, eps: 0.1})
Step:  166000, Reward: [-421.716 -421.716 -421.716] [58.349], Avg: [-446.067 -446.067 -446.067] (0.1000) <01:24:22> ({r_i: None, r_t: [-4223.997 -4223.997 -4223.997], critic_loss: 2719.846923828125, actor_loss: -0.8690000176429749, eps: 0.1})
Step:  166500, Reward: [-421.818 -421.818 -421.818] [92.594], Avg: [-445.995 -445.995 -445.995] (0.1000) <01:24:36> ({r_i: None, r_t: [-4242.428 -4242.428 -4242.428], critic_loss: 3488.64794921875, actor_loss: 0.6299999952316284, eps: 0.1})
Step:  167000, Reward: [-421.771 -421.771 -421.771] [71.475], Avg: [-445.922 -445.922 -445.922] (0.1000) <01:24:51> ({r_i: None, r_t: [-4242.411 -4242.411 -4242.411], critic_loss: 2672.449951171875, actor_loss: 0.007000000216066837, eps: 0.1})
Step:  167500, Reward: [-459.634 -459.634 -459.634] [110.111], Avg: [-445.963 -445.963 -445.963] (0.1000) <01:25:07> ({r_i: None, r_t: [-4214.458 -4214.458 -4214.458], critic_loss: 3813.01806640625, actor_loss: 0.5740000009536743, eps: 0.1})
Step:  168000, Reward: [-423.045 -423.045 -423.045] [80.553], Avg: [-445.895 -445.895 -445.895] (0.1000) <01:25:22> ({r_i: None, r_t: [-4198.166 -4198.166 -4198.166], critic_loss: 3224.302978515625, actor_loss: 0.7300000190734863, eps: 0.1})
Step:  168500, Reward: [-433.092 -433.092 -433.092] [65.341], Avg: [-445.857 -445.857 -445.857] (0.1000) <01:25:38> ({r_i: None, r_t: [-4197.712 -4197.712 -4197.712], critic_loss: 2637.928955078125, actor_loss: -0.019999999552965164, eps: 0.1})
Step:  169000, Reward: [-419.034 -419.034 -419.034] [72.608], Avg: [-445.778 -445.778 -445.778] (0.1000) <01:25:53> ({r_i: None, r_t: [-4241.028 -4241.028 -4241.028], critic_loss: 2822.73193359375, actor_loss: -0.44200000166893005, eps: 0.1})
Step:  169500, Reward: [-418.129 -418.129 -418.129] [90.263], Avg: [-445.697 -445.697 -445.697] (0.1000) <01:26:10> ({r_i: None, r_t: [-4287.756 -4287.756 -4287.756], critic_loss: 3913.179931640625, actor_loss: -0.28999999165534973, eps: 0.1})
Step:  170000, Reward: [-426.752 -426.752 -426.752] [80.096], Avg: [-445.641 -445.641 -445.641] (0.1000) <01:26:26> ({r_i: None, r_t: [-4241.652 -4241.652 -4241.652], critic_loss: 3039.364013671875, actor_loss: -0.27399998903274536, eps: 0.1})
Step:  170500, Reward: [-457.936 -457.936 -457.936] [65.469], Avg: [-445.677 -445.677 -445.677] (0.1000) <01:26:42> ({r_i: None, r_t: [-4316.883 -4316.883 -4316.883], critic_loss: 3274.26611328125, actor_loss: -0.1720000058412552, eps: 0.1})
Step:  171000, Reward: [-406.139 -406.139 -406.139] [68.763], Avg: [-445.562 -445.562 -445.562] (0.1000) <01:26:57> ({r_i: None, r_t: [-4334.935 -4334.935 -4334.935], critic_loss: 3389.280029296875, actor_loss: 0.257999986410141, eps: 0.1})
Step:  171500, Reward: [-412.840 -412.840 -412.840] [73.788], Avg: [-445.467 -445.467 -445.467] (0.1000) <01:27:13> ({r_i: None, r_t: [-4222.301 -4222.301 -4222.301], critic_loss: 2799.2470703125, actor_loss: 1.1130000352859497, eps: 0.1})
Step:  172000, Reward: [-412.085 -412.085 -412.085] [36.508], Avg: [-445.370 -445.370 -445.370] (0.1000) <01:27:29> ({r_i: None, r_t: [-4305.408 -4305.408 -4305.408], critic_loss: 2508.3740234375, actor_loss: 0.7319999933242798, eps: 0.1})
Step:  172500, Reward: [-413.809 -413.809 -413.809] [65.603], Avg: [-445.279 -445.279 -445.279] (0.1000) <01:27:44> ({r_i: None, r_t: [-4242.678 -4242.678 -4242.678], critic_loss: 2874.656005859375, actor_loss: 0.32199999690055847, eps: 0.1})
Step:  173000, Reward: [-430.242 -430.242 -430.242] [79.478], Avg: [-445.236 -445.236 -445.236] (0.1000) <01:27:58> ({r_i: None, r_t: [-4226.623 -4226.623 -4226.623], critic_loss: 3762.325927734375, actor_loss: 0.14900000393390656, eps: 0.1})
Step:  173500, Reward: [-407.771 -407.771 -407.771] [74.982], Avg: [-445.128 -445.128 -445.128] (0.1000) <01:28:12> ({r_i: None, r_t: [-4280.829 -4280.829 -4280.829], critic_loss: 3882.241943359375, actor_loss: -0.32499998807907104, eps: 0.1})
Step:  174000, Reward: [-440.677 -440.677 -440.677] [106.573], Avg: [-445.115 -445.115 -445.115] (0.1000) <01:28:27> ({r_i: None, r_t: [-4339.355 -4339.355 -4339.355], critic_loss: 3337.306884765625, actor_loss: -0.7979999780654907, eps: 0.1})
Step:  174500, Reward: [-436.364 -436.364 -436.364] [62.930], Avg: [-445.090 -445.090 -445.090] (0.1000) <01:28:41> ({r_i: None, r_t: [-4259.225 -4259.225 -4259.225], critic_loss: 4625.9267578125, actor_loss: -0.6309999823570251, eps: 0.1})
Step:  175000, Reward: [-435.813 -435.813 -435.813] [73.993], Avg: [-445.064 -445.064 -445.064] (0.1000) <01:28:56> ({r_i: None, r_t: [-4115.491 -4115.491 -4115.491], critic_loss: 2952.117919921875, actor_loss: 0.46399998664855957, eps: 0.1})
Step:  175500, Reward: [-412.077 -412.077 -412.077] [61.285], Avg: [-444.970 -444.970 -444.970] (0.1000) <01:29:10> ({r_i: None, r_t: [-4196.262 -4196.262 -4196.262], critic_loss: 2130.7109375, actor_loss: 0.289000004529953, eps: 0.1})
Step:  176000, Reward: [-430.736 -430.736 -430.736] [99.306], Avg: [-444.930 -444.930 -444.930] (0.1000) <01:29:25> ({r_i: None, r_t: [-4360.244 -4360.244 -4360.244], critic_loss: 2936.386962890625, actor_loss: -0.8999999761581421, eps: 0.1})
Step:  176500, Reward: [-447.142 -447.142 -447.142] [78.982], Avg: [-444.936 -444.936 -444.936] (0.1000) <01:29:39> ({r_i: None, r_t: [-4203.333 -4203.333 -4203.333], critic_loss: 2422.382080078125, actor_loss: 0.4830000102519989, eps: 0.1})
Step:  177000, Reward: [-442.950 -442.950 -442.950] [82.000], Avg: [-444.930 -444.930 -444.930] (0.1000) <01:29:53> ({r_i: None, r_t: [-4311.462 -4311.462 -4311.462], critic_loss: 3374.118896484375, actor_loss: 0.5519999861717224, eps: 0.1})
Step:  177500, Reward: [-425.571 -425.571 -425.571] [91.363], Avg: [-444.876 -444.876 -444.876] (0.1000) <01:30:08> ({r_i: None, r_t: [-4256.294 -4256.294 -4256.294], critic_loss: 2977.529052734375, actor_loss: 0.20100000500679016, eps: 0.1})
Step:  178000, Reward: [-399.713 -399.713 -399.713] [79.315], Avg: [-444.750 -444.750 -444.750] (0.1000) <01:30:23> ({r_i: None, r_t: [-4260.146 -4260.146 -4260.146], critic_loss: 3620.9970703125, actor_loss: 1.2549999952316284, eps: 0.1})
Step:  178500, Reward: [-425.955 -425.955 -425.955] [81.861], Avg: [-444.697 -444.697 -444.697] (0.1000) <01:30:39> ({r_i: None, r_t: [-4315.910 -4315.910 -4315.910], critic_loss: 2737.280029296875, actor_loss: 1.3359999656677246, eps: 0.1})
Step:  179000, Reward: [-433.994 -433.994 -433.994] [79.041], Avg: [-444.667 -444.667 -444.667] (0.1000) <01:30:55> ({r_i: None, r_t: [-4258.951 -4258.951 -4258.951], critic_loss: 3182.02001953125, actor_loss: 0.6549999713897705, eps: 0.1})
Step:  179500, Reward: [-426.922 -426.922 -426.922] [64.955], Avg: [-444.618 -444.618 -444.618] (0.1000) <01:31:10> ({r_i: None, r_t: [-4082.164 -4082.164 -4082.164], critic_loss: 3118.56005859375, actor_loss: 0.22599999606609344, eps: 0.1})
Step:  180000, Reward: [-433.585 -433.585 -433.585] [109.473], Avg: [-444.587 -444.587 -444.587] (0.1000) <01:31:27> ({r_i: None, r_t: [-4318.221 -4318.221 -4318.221], critic_loss: 2082.885986328125, actor_loss: 0.6990000009536743, eps: 0.1})
Step:  180500, Reward: [-440.349 -440.349 -440.349] [69.743], Avg: [-444.576 -444.576 -444.576] (0.1000) <01:31:43> ({r_i: None, r_t: [-4275.209 -4275.209 -4275.209], critic_loss: 2617.99609375, actor_loss: 0.7919999957084656, eps: 0.1})
Step:  181000, Reward: [-457.972 -457.972 -457.972] [64.838], Avg: [-444.613 -444.613 -444.613] (0.1000) <01:32:01> ({r_i: None, r_t: [-4244.083 -4244.083 -4244.083], critic_loss: 3191.50390625, actor_loss: 0.210999995470047, eps: 0.1})
Step:  181500, Reward: [-422.784 -422.784 -422.784] [81.769], Avg: [-444.553 -444.553 -444.553] (0.1000) <01:32:18> ({r_i: None, r_t: [-4228.695 -4228.695 -4228.695], critic_loss: 1900.85498046875, actor_loss: 0.31200000643730164, eps: 0.1})
Step:  182000, Reward: [-423.919 -423.919 -423.919] [73.899], Avg: [-444.496 -444.496 -444.496] (0.1000) <01:32:34> ({r_i: None, r_t: [-4280.789 -4280.789 -4280.789], critic_loss: 2366.10595703125, actor_loss: -0.5339999794960022, eps: 0.1})
Step:  182500, Reward: [-448.982 -448.982 -448.982] [69.203], Avg: [-444.508 -444.508 -444.508] (0.1000) <01:32:50> ({r_i: None, r_t: [-4274.446 -4274.446 -4274.446], critic_loss: 3177.05810546875, actor_loss: -0.24500000476837158, eps: 0.1})
Step:  183000, Reward: [-443.161 -443.161 -443.161] [61.739], Avg: [-444.505 -444.505 -444.505] (0.1000) <01:33:06> ({r_i: None, r_t: [-4195.415 -4195.415 -4195.415], critic_loss: 3444.81103515625, actor_loss: 0.13600000739097595, eps: 0.1})
Step:  183500, Reward: [-416.386 -416.386 -416.386] [89.913], Avg: [-444.428 -444.428 -444.428] (0.1000) <01:33:22> ({r_i: None, r_t: [-4239.783 -4239.783 -4239.783], critic_loss: 3300.43505859375, actor_loss: 0.9710000157356262, eps: 0.1})
Step:  184000, Reward: [-451.024 -451.024 -451.024] [66.915], Avg: [-444.446 -444.446 -444.446] (0.1000) <01:33:38> ({r_i: None, r_t: [-4118.965 -4118.965 -4118.965], critic_loss: 2886.40087890625, actor_loss: 0.4779999852180481, eps: 0.1})
Step:  184500, Reward: [-381.481 -381.481 -381.481] [44.886], Avg: [-444.276 -444.276 -444.276] (0.1000) <01:33:53> ({r_i: None, r_t: [-4269.395 -4269.395 -4269.395], critic_loss: 3568.654052734375, actor_loss: 0.21899999678134918, eps: 0.1})
Step:  185000, Reward: [-435.978 -435.978 -435.978] [92.627], Avg: [-444.254 -444.254 -444.254] (0.1000) <01:34:10> ({r_i: None, r_t: [-4278.061 -4278.061 -4278.061], critic_loss: 1955.010009765625, actor_loss: 0.6320000290870667, eps: 0.1})
Step:  185500, Reward: [-427.600 -427.600 -427.600] [84.287], Avg: [-444.209 -444.209 -444.209] (0.1000) <01:34:26> ({r_i: None, r_t: [-4221.513 -4221.513 -4221.513], critic_loss: 2758.882080078125, actor_loss: 1.0290000438690186, eps: 0.1})
Step:  186000, Reward: [-449.724 -449.724 -449.724] [77.116], Avg: [-444.224 -444.224 -444.224] (0.1000) <01:34:42> ({r_i: None, r_t: [-4270.792 -4270.792 -4270.792], critic_loss: 3972.534912109375, actor_loss: 0.6050000190734863, eps: 0.1})
Step:  186500, Reward: [-422.364 -422.364 -422.364] [103.433], Avg: [-444.165 -444.165 -444.165] (0.1000) <01:34:58> ({r_i: None, r_t: [-4254.045 -4254.045 -4254.045], critic_loss: 2188.81591796875, actor_loss: -0.38100001215934753, eps: 0.1})
Step:  187000, Reward: [-386.540 -386.540 -386.540] [66.058], Avg: [-444.011 -444.011 -444.011] (0.1000) <01:35:14> ({r_i: None, r_t: [-4247.413 -4247.413 -4247.413], critic_loss: 3147.31201171875, actor_loss: -1.8459999561309814, eps: 0.1})
Step:  187500, Reward: [-470.487 -470.487 -470.487] [100.178], Avg: [-444.082 -444.082 -444.082] (0.1000) <01:35:30> ({r_i: None, r_t: [-4358.478 -4358.478 -4358.478], critic_loss: 2682.998046875, actor_loss: -0.828000009059906, eps: 0.1})
Step:  188000, Reward: [-418.292 -418.292 -418.292] [69.577], Avg: [-444.013 -444.013 -444.013] (0.1000) <01:35:46> ({r_i: None, r_t: [-4294.918 -4294.918 -4294.918], critic_loss: 2965.77197265625, actor_loss: 1.2079999446868896, eps: 0.1})
Step:  188500, Reward: [-428.438 -428.438 -428.438] [70.489], Avg: [-443.972 -443.972 -443.972] (0.1000) <01:36:00> ({r_i: None, r_t: [-4207.780 -4207.780 -4207.780], critic_loss: 3459.75390625, actor_loss: 0.09700000286102295, eps: 0.1})
Step:  189000, Reward: [-420.748 -420.748 -420.748] [76.931], Avg: [-443.911 -443.911 -443.911] (0.1000) <01:36:15> ({r_i: None, r_t: [-4203.218 -4203.218 -4203.218], critic_loss: 3502.2900390625, actor_loss: -0.2680000066757202, eps: 0.1})
Step:  189500, Reward: [-450.376 -450.376 -450.376] [107.833], Avg: [-443.928 -443.928 -443.928] (0.1000) <01:36:30> ({r_i: None, r_t: [-4233.817 -4233.817 -4233.817], critic_loss: 3451.513916015625, actor_loss: -0.9909999966621399, eps: 0.1})
Step:  190000, Reward: [-434.614 -434.614 -434.614] [78.143], Avg: [-443.904 -443.904 -443.904] (0.1000) <01:36:44> ({r_i: None, r_t: [-4209.516 -4209.516 -4209.516], critic_loss: 2709.006103515625, actor_loss: 0.2849999964237213, eps: 0.1})
Step:  190500, Reward: [-418.494 -418.494 -418.494] [68.870], Avg: [-443.837 -443.837 -443.837] (0.1000) <01:36:59> ({r_i: None, r_t: [-4404.847 -4404.847 -4404.847], critic_loss: 3594.0458984375, actor_loss: -0.18700000643730164, eps: 0.1})
Step:  191000, Reward: [-414.263 -414.263 -414.263] [94.520], Avg: [-443.760 -443.760 -443.760] (0.1000) <01:37:14> ({r_i: None, r_t: [-4206.508 -4206.508 -4206.508], critic_loss: 3608.572021484375, actor_loss: 0.10400000214576721, eps: 0.1})
Step:  191500, Reward: [-403.319 -403.319 -403.319] [59.477], Avg: [-443.654 -443.654 -443.654] (0.1000) <01:37:30> ({r_i: None, r_t: [-4301.086 -4301.086 -4301.086], critic_loss: 3046.35205078125, actor_loss: -0.1080000028014183, eps: 0.1})
Step:  192000, Reward: [-431.276 -431.276 -431.276] [64.127], Avg: [-443.622 -443.622 -443.622] (0.1000) <01:37:46> ({r_i: None, r_t: [-4283.505 -4283.505 -4283.505], critic_loss: 2649.31201171875, actor_loss: 0.8450000286102295, eps: 0.1})
Step:  192500, Reward: [-452.735 -452.735 -452.735] [74.964], Avg: [-443.646 -443.646 -443.646] (0.1000) <01:38:01> ({r_i: None, r_t: [-4167.832 -4167.832 -4167.832], critic_loss: 3261.010986328125, actor_loss: 0.18700000643730164, eps: 0.1})
Step:  193000, Reward: [-420.667 -420.667 -420.667] [89.868], Avg: [-443.587 -443.587 -443.587] (0.1000) <01:38:17> ({r_i: None, r_t: [-4313.564 -4313.564 -4313.564], critic_loss: 2265.37890625, actor_loss: 0.4519999921321869, eps: 0.1})
Step:  193500, Reward: [-405.424 -405.424 -405.424] [44.782], Avg: [-443.488 -443.488 -443.488] (0.1000) <01:38:33> ({r_i: None, r_t: [-4321.231 -4321.231 -4321.231], critic_loss: 4397.35009765625, actor_loss: 0.24400000274181366, eps: 0.1})
Step:  194000, Reward: [-417.012 -417.012 -417.012] [82.916], Avg: [-443.420 -443.420 -443.420] (0.1000) <01:38:48> ({r_i: None, r_t: [-4308.729 -4308.729 -4308.729], critic_loss: 2855.297119140625, actor_loss: -0.9509999752044678, eps: 0.1})
Step:  194500, Reward: [-426.255 -426.255 -426.255] [87.142], Avg: [-443.376 -443.376 -443.376] (0.1000) <01:39:05> ({r_i: None, r_t: [-4333.503 -4333.503 -4333.503], critic_loss: 3356.9541015625, actor_loss: -0.2930000126361847, eps: 0.1})
Step:  195000, Reward: [-434.639 -434.639 -434.639] [62.306], Avg: [-443.354 -443.354 -443.354] (0.1000) <01:39:21> ({r_i: None, r_t: [-4221.172 -4221.172 -4221.172], critic_loss: 3144.032958984375, actor_loss: -0.5329999923706055, eps: 0.1})
Step:  195500, Reward: [-393.271 -393.271 -393.271] [61.707], Avg: [-443.226 -443.226 -443.226] (0.1000) <01:39:36> ({r_i: None, r_t: [-4183.965 -4183.965 -4183.965], critic_loss: 2397.18701171875, actor_loss: -0.3330000042915344, eps: 0.1})
Step:  196000, Reward: [-425.952 -425.952 -425.952] [68.690], Avg: [-443.182 -443.182 -443.182] (0.1000) <01:39:51> ({r_i: None, r_t: [-4213.518 -4213.518 -4213.518], critic_loss: 2249.303955078125, actor_loss: 0.00800000037997961, eps: 0.1})
Step:  196500, Reward: [-436.680 -436.680 -436.680] [82.025], Avg: [-443.166 -443.166 -443.166] (0.1000) <01:40:07> ({r_i: None, r_t: [-4339.247 -4339.247 -4339.247], critic_loss: 2443.25, actor_loss: 0.3709999918937683, eps: 0.1})
Step:  197000, Reward: [-414.099 -414.099 -414.099] [78.076], Avg: [-443.092 -443.092 -443.092] (0.1000) <01:40:23> ({r_i: None, r_t: [-4212.411 -4212.411 -4212.411], critic_loss: 2369.134033203125, actor_loss: 1.5399999618530273, eps: 0.1})
Step:  197500, Reward: [-486.435 -486.435 -486.435] [119.027], Avg: [-443.201 -443.201 -443.201] (0.1000) <01:40:38> ({r_i: None, r_t: [-4183.947 -4183.947 -4183.947], critic_loss: 2799.77392578125, actor_loss: 0.5659999847412109, eps: 0.1})
Step:  198000, Reward: [-393.725 -393.725 -393.725] [54.377], Avg: [-443.077 -443.077 -443.077] (0.1000) <01:40:52> ({r_i: None, r_t: [-4230.101 -4230.101 -4230.101], critic_loss: 2592.85009765625, actor_loss: 0.32899999618530273, eps: 0.1})
Step:  198500, Reward: [-415.303 -415.303 -415.303] [66.338], Avg: [-443.007 -443.007 -443.007] (0.1000) <01:41:07> ({r_i: None, r_t: [-4192.375 -4192.375 -4192.375], critic_loss: 2811.52392578125, actor_loss: -0.164000004529953, eps: 0.1})
Step:  199000, Reward: [-449.547 -449.547 -449.547] [74.225], Avg: [-443.023 -443.023 -443.023] (0.1000) <01:41:22> ({r_i: None, r_t: [-4118.732 -4118.732 -4118.732], critic_loss: 2918.617919921875, actor_loss: -0.5220000147819519, eps: 0.1})
Step:  199500, Reward: [-404.072 -404.072 -404.072] [43.716], Avg: [-442.926 -442.926 -442.926] (0.1000) <01:41:38> ({r_i: None, r_t: [-4233.309 -4233.309 -4233.309], critic_loss: 2998.830078125, actor_loss: -0.49900001287460327, eps: 0.1})
Step:  200000, Reward: [-454.091 -454.091 -454.091] [59.935], Avg: [-442.954 -442.954 -442.954] (0.1000) <01:41:53> ({r_i: None, r_t: [-4183.465 -4183.465 -4183.465], critic_loss: 2531.347900390625, actor_loss: 0.8230000138282776, eps: 0.1})
