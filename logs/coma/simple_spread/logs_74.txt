Model: <class 'multiagent.coma.COMAAgent'>, Dir: simple_spread
num_envs: 16,
state_size: [(1, 18), (1, 18), (1, 18)],
action_size: [[1, 5], [1, 5], [1, 5]],
action_space: [MultiDiscrete([5]), MultiDiscrete([5]), MultiDiscrete([5])],
envs: <class 'utils.envs.EnsembleEnv'>,
reward_shape: False,
icm: False,

import copy
import torch
import numpy as np
from models.rand import MultiagentReplayBuffer3
from utils.network import PTNetwork, PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, one_hot_from_indices

LEARNING_RATE = 0.0003
LAMBDA = 0.95
DISCOUNT_RATE = 0.99
GRAD_NORM = 1
TARGET_UPDATE = 200

HIDDEN_SIZE = 64
EPS_MAX = 0.5
EPS_MIN = 0.01
EPS_DECAY = 0.995
NUM_ENVS = 4
EPISODE_LIMIT = 50
ENTROPY_WEIGHT = 0.001			# The weight for the entropy term of the Actor loss
MAX_BUFFER_SIZE = 192000		# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 6400

# class COMAAgent(PTACAgent):
# 	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, decay=EPS_DECAY, gpu=True, load=None):
# 		super().__init__(state_size, action_size, lambda *args, **kwargs: None, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
# 		del self.network
# 		n_agents = len(action_size)
# 		n_actions = action_size[0][-1]
# 		n_obs = state_size[0][-1]
# 		state_len = int(np.sum([np.prod(space) for space in state_size]))
# 		preprocess = {"actions": ("actions_onehot", [OneHot(out_dim=n_actions)])}
# 		groups = {"agents": n_agents}
# 		scheme = {
# 			"state": {"vshape": state_len},
# 			"obs": {"vshape": n_obs, "group": "agents"},
# 			"actions": {"vshape": (1,), "group": "agents", "dtype": torch.long},
# 			"reward": {"vshape": (1,)},
# 			"done": {"vshape": (1,), "dtype": torch.uint8},
# 		}
		
# 		self.device = torch.device('cuda' if gpu and torch.cuda.is_available() else 'cpu')
# 		self.replay_buffer = ReplayBuffer(scheme, groups, 2000, EPISODE_LIMIT+1, preprocess=preprocess, device=self.device)
# 		self.mac = BasicMAC(self.replay_buffer.scheme, groups, n_agents, n_actions, device=self.device)
# 		self.learner = COMALearner(self.mac, self.replay_buffer.scheme, n_agents, n_actions, device=self.device)
# 		self.new_episode_batch = lambda batch_size: EpisodeBatch(scheme, groups, batch_size, EPISODE_LIMIT+1, preprocess=preprocess, device=self.device)
# 		self.episode_batch = self.new_episode_batch(NUM_ENVS)
# 		self.mac.init_hidden(batch_size=NUM_ENVS)
# 		self.num_envs = NUM_ENVS
# 		self.time = 0
# 		self.replay_buffer2 = MultiagentReplayBuffer(EPISODE_LIMIT*REPLAY_BATCH_SIZE, state_size, action_size)

# 	def get_action(self, state, eps=None, sample=True, numpy=True):
# 		self.num_envs = state[0].shape[0] if len(state[0].shape) > len(self.state_size[0]) else 1
# 		if np.prod(self.mac.hidden_states.shape[:-1]) != self.num_envs*len(self.action_size): self.mac.init_hidden(batch_size=self.num_envs)
# 		if self.episode_batch.batch_size != self.num_envs: self.episode_batch = self.new_episode_batch(self.num_envs)
# 		self.step = 0 if not hasattr(self, "step") else (self.step + 1)%self.replay_buffer.max_seq_length
# 		state_joint = np.concatenate(state, -1)
# 		obs = np.concatenate(state, -2)
# 		agent_ids = np.repeat(np.expand_dims(np.eye(self.learner.n_agents), 0), repeats=self.num_envs, axis=0)
# 		if not hasattr(self, "action"): self.action = np.zeros([*obs.shape[:-1], self.action_size[0][-1]])
# 		inputs = torch.from_numpy(np.concatenate([obs, self.action, agent_ids], -1))
# 		self.episode_batch.update({"state": [state_joint], "obs": [obs]}, ts=self.step)
# 		actions = self.mac.select_actions(self.episode_batch, inputs, t_ep=self.step, t_env=self.time, test_mode=False)
# 		self.action = one_hot_from_indices(actions, self.action_size[0][-1]).cpu().numpy()
# 		actions = actions.view([*state[0].shape[:-len(self.state_size[0])], actions.shape[-1]])
# 		return np.split(self.action, actions.size(-1), axis=-2)

# 	def train(self, state, action, next_state, reward, done):
# 		actions, rewards, dones = [list(zip(*x)) for x in [action, reward, done]]
# 		actions_one_hot = [np.argmax(a, -1) for a in actions]
# 		rewards = [np.mean(rewards, -1)]
# 		dones = [np.any(dones, -1)]
# 		obs = np.concatenate(state, -2)
# 		next_obs = np.concatenate(next_state, -2)
# 		agent_ids = np.repeat(np.expand_dims(np.eye(self.learner.n_agents), 0), repeats=self.num_envs, axis=0)
# 		actor_inputs = torch.from_numpy(np.concatenate([obs, self.action, agent_ids], -1))
# 		post_transition_data = {"actions": actions_one_hot, "reward": rewards, "done": dones}
# 		self.replay_buffer2.add(state, action, next_state, reward, done)
# 		self.episode_batch.update(post_transition_data, ts=self.step)
# 		if np.any(done[0]):
# 			state_joint = np.concatenate(state, -1)
# 			self.episode_batch.update({"state": [state_joint], "obs": [next_obs]}, ts=self.step)
# 			actions = self.mac.select_actions(self.episode_batch, actor_inputs, t_ep=self.step, t_env=self.time, test_mode=False)
# 			self.episode_batch.update({"actions": actions}, ts=self.step)
# 			self.replay_buffer.insert_episode_batch(self.episode_batch)
# 			if self.replay_buffer.can_sample(REPLAY_BATCH_SIZE):
# 				episode_sample = self.replay_buffer.sample(REPLAY_BATCH_SIZE)
# 				sample = self.replay_buffer2.sample(REPLAY_BATCH_SIZE, self.device)
# 				max_ep_t = episode_sample.max_t_filled()
# 				episode_sample = episode_sample[:, :max_ep_t]
# 				if episode_sample.device != self.device: episode_sample.to(self.device)
# 				self.learner.train(episode_sample)
# 			self.episode_batch = self.new_episode_batch(state[0].shape[0])
# 			self.mac.init_hidden(self.num_envs)
# 			self.time += self.step
# 			self.step = 0

# class OneHot():
# 	def __init__(self, out_dim):
# 		self.out_dim = out_dim

# 	def transform(self, tensor):
# 		y_onehot = tensor.new(*tensor.shape[:-1], self.out_dim).zero_()
# 		y_onehot.scatter_(-1, tensor.long(), 1)
# 		return y_onehot.float()

# 	def infer_output_info(self, vshape_in, dtype_in):
# 		return (self.out_dim,), torch.float32

# class COMALearner():
# 	def __init__(self, mac, scheme, n_agents, n_actions, device):
# 		self.device = device
# 		self.n_agents = n_agents
# 		self.n_actions = n_actions
# 		self.last_target_update_step = 0
# 		self.mac = mac
# 		self.critic_training_steps = 0
# 		self.critic = COMACritic(scheme, self.n_agents, self.n_actions).to(self.device)
# 		self.critic_params = list(self.critic.parameters())
# 		self.agent_params = list(mac.parameters())
# 		self.params = self.agent_params + self.critic_params
# 		self.target_critic = copy.deepcopy(self.critic)
# 		self.agent_optimiser = torch.optim.Adam(params=self.agent_params, lr=LEARNING_RATE)
# 		self.critic_optimiser = torch.optim.Adam(params=self.critic_params, lr=LEARNING_RATE)

# 	def train(self, batch):
# 		# Get the relevant quantities
# 		bs = batch.batch_size
# 		max_t = batch.max_seq_length
# 		rewards = batch["reward"][:, :-1]
# 		actions = batch["actions"][:, :]
# 		done = batch["done"][:, :-1].float()
# 		mask = batch["filled"][:, :-1].float()
# 		mask[:, 1:] = mask[:, 1:] * (1 - done[:, :-1])
# 		critic_mask = mask.clone()
# 		mask = mask.repeat(1, 1, self.n_agents).view(-1)
# 		q_vals = self._train_critic(batch, rewards, done, actions, critic_mask, bs, max_t)
# 		actions = actions[:,:-1]
# 		mac_out = []
# 		self.mac.init_hidden(batch.batch_size)
# 		for t in range(batch.max_seq_length - 1):
# 			agent_outs = self.mac.forward(batch, t=t)
# 			mac_out.append(agent_outs)
# 		mac_out = torch.stack(mac_out, dim=1)  # Concat over time
# 		# Mask out unavailable actions, renormalise (as in action selection)
# 		q_vals = q_vals.reshape(-1, self.n_actions)
# 		pi = mac_out.view(-1, self.n_actions)
# 		baseline = (pi * q_vals).sum(-1).detach()
# 		q_taken = torch.gather(q_vals, dim=1, index=actions.reshape(-1, 1)).squeeze(1)
# 		pi_taken = torch.gather(pi, dim=1, index=actions.reshape(-1, 1)).squeeze(1)
# 		pi_taken[mask == 0] = 1.0
# 		log_pi_taken = torch.log(pi_taken)
# 		advantages = (q_taken - baseline).detach()
# 		coma_loss = - ((advantages * log_pi_taken) * mask).sum() / mask.sum()
# 		self.agent_optimiser.zero_grad()
# 		coma_loss.backward()
# 		torch.nn.utils.clip_grad_norm_(self.agent_params, GRAD_NORM)
# 		self.agent_optimiser.step()
# 		if (self.critic_training_steps - self.last_target_update_step) / TARGET_UPDATE >= 1.0:
# 			self._update_targets()
# 			self.last_target_update_step = self.critic_training_steps

# 	def _train_critic(self, batch, rewards, done, actions, mask, bs, max_t):
# 		target_q_vals = self.target_critic(batch)[:, :]
# 		targets_taken = torch.gather(target_q_vals, dim=3, index=actions).squeeze(3)
# 		targets = build_td_lambda_targets(rewards, done, mask, targets_taken, self.n_agents)
# 		q_vals = torch.zeros_like(target_q_vals)[:, :-1]
# 		for t in reversed(range(rewards.size(1))):
# 			mask_t = mask[:, t].expand(-1, self.n_agents)
# 			if mask_t.sum() == 0:
# 				continue
# 			q_t = self.critic(batch, t)
# 			q_vals[:, t] = q_t.view(bs, self.n_agents, self.n_actions)
# 			q_taken = torch.gather(q_t, dim=3, index=actions[:, t:t+1]).squeeze(3).squeeze(1)
# 			targets_t = targets[:, t]
# 			td_error = (q_taken - targets_t.detach())
# 			# 0-out the targets that came from padded data
# 			masked_td_error = td_error * mask_t
# 			loss = (masked_td_error ** 2).sum() / mask_t.sum()
# 			self.critic_optimiser.zero_grad()
# 			loss.backward()
# 			torch.nn.utils.clip_grad_norm_(self.critic_params, GRAD_NORM)
# 			self.critic_optimiser.step()
# 			self.critic_training_steps += 1
# 		return q_vals

# 	def _update_targets(self):
# 		self.target_critic.load_state_dict(self.critic.state_dict())

# 	def cuda(self):
# 		self.mac.cuda()
# 		self.critic.cuda()
# 		self.target_critic.cuda()

# def build_td_lambda_targets(rewards, done, mask, target_qs, n_agents, gamma=DISCOUNT_RATE, td_lambda=LAMBDA):
# 	# Assumes  <target_qs > in B*T*A and <reward >, <done >, <mask > in (at least) B*T-1*1
# 	# Initialise  last  lambda -return  for  not  done  episodes
# 	ret = target_qs.new_zeros(*target_qs.shape)
# 	ret[:, -1] = target_qs[:, -1] * (1 - torch.sum(done, dim=1))
# 	# Backwards  recursive  update  of the "forward  view"
# 	for t in range(ret.shape[1] - 2, -1,  -1):
# 		ret[:, t] = td_lambda * gamma * ret[:, t + 1] + mask[:, t]*(rewards[:, t] + (1 - td_lambda) * gamma * target_qs[:, t + 1] * (1 - done[:, t]))
# 	# Returns lambda-return from t=0 to t=T-1, i.e. in B*T-1*A
# 	return ret[:, 0:-1]

# class COMACritic(torch.nn.Module):
# 	def __init__(self, scheme, n_agents, n_actions):
# 		super(COMACritic, self).__init__()
# 		self.n_actions = n_actions
# 		self.n_agents = n_agents
# 		input_shape = self._get_input_shape(scheme)
# 		self.output_type = "q"
# 		self.fc1 = torch.nn.Linear(input_shape, HIDDEN_SIZE)
# 		self.fc2 = torch.nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)
# 		self.fc3 = torch.nn.Linear(HIDDEN_SIZE, self.n_actions)

# 	def forward(self, batch, t=None):
# 		inputs = self._build_inputs(batch, t=t)
# 		x = torch.relu(self.fc1(inputs))
# 		x = torch.relu(self.fc2(x))
# 		q = self.fc3(x)
# 		return q

# 	def _build_inputs(self, batch, t=None):
# 		bs = batch.batch_size
# 		max_t = batch.max_seq_length if t is None else 1
# 		ts = slice(None) if t is None else slice(t, t+1)
# 		inputs = []
# 		inputs.append(batch["state"][:, ts].unsqueeze(2).repeat(1, 1, self.n_agents, 1))
# 		inputs.append(batch["obs"][:, ts])
# 		actions = batch["actions_onehot"][:, ts].view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1)
# 		agent_mask = (1 - torch.eye(self.n_agents, device=batch.device))
# 		agent_mask = agent_mask.view(-1, 1).repeat(1, self.n_actions).view(self.n_agents, -1)
# 		inputs.append(actions * agent_mask.unsqueeze(0).unsqueeze(0))
# 		# last actions
# 		if t == 0:
# 			inputs.append(torch.zeros_like(batch["actions_onehot"][:, 0:1]).view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1))
# 		elif isinstance(t, int):
# 			inputs.append(batch["actions_onehot"][:, slice(t-1, t)].view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1))
# 		else:
# 			last_actions = torch.cat([torch.zeros_like(batch["actions_onehot"][:, 0:1]), batch["actions_onehot"][:, :-1]], dim=1)
# 			last_actions = last_actions.view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1)
# 			inputs.append(last_actions)

# 		inputs.append(torch.eye(self.n_agents, device=batch.device).unsqueeze(0).unsqueeze(0).expand(bs, max_t, -1, -1))
# 		inputs = torch.cat([x.reshape(bs, max_t, self.n_agents, -1) for x in inputs], dim=-1)
# 		return inputs

# 	def _get_input_shape(self, scheme):
# 		input_shape = scheme["state"]["vshape"]
# 		input_shape += scheme["obs"]["vshape"]
# 		input_shape += scheme["actions_onehot"]["vshape"][0] * self.n_agents * 2
# 		input_shape += self.n_agents
# 		return input_shape

# class BasicMAC:
# 	def __init__(self, scheme, groups, n_agents, n_actions, device):
# 		self.device = device
# 		self.n_agents = n_agents
# 		self.n_actions = n_actions
# 		self.agent = RNNAgent(self._get_input_shape(scheme), self.n_actions).to(self.device)
# 		self.action_selector = MultinomialActionSelector()
# 		self.hidden_states = None

# 	def select_actions(self, ep_batch, inputs, t_ep, t_env, bs=slice(None), test_mode=False):
# 		agent_outputs = self.forward(ep_batch, inputs, t_ep, test_mode=test_mode)
# 		chosen_actions = self.action_selector.select_action(agent_outputs[bs], t_env, test_mode=test_mode)
# 		return chosen_actions

# 	def forward(self, ep_batch, inputs, t, test_mode=False):
# 		agent_inputs = self._build_inputs(ep_batch, t)
# 		agent_outs = self.agent(agent_inputs, self.hidden_states)
# 		agent_outs = torch.nn.functional.softmax(agent_outs, dim=-1)
# 		if not test_mode:
# 			epsilon_action_num = agent_outs.size(-1)
# 			agent_outs = ((1 - self.action_selector.epsilon) * agent_outs + torch.ones_like(agent_outs).to(self.device) * self.action_selector.epsilon/epsilon_action_num)
# 		return agent_outs.view(ep_batch.batch_size, self.n_agents, -1)

# 	def init_hidden(self, batch_size):
# 		self.hidden_states = self.agent.init_hidden().unsqueeze(0).expand(batch_size, self.n_agents, -1)  # bav

# 	def parameters(self):
# 		return self.agent.parameters()

# 	def _build_inputs(self, batch, t):
# 		bs = batch.batch_size
# 		inputs = []
# 		inputs.append(batch["obs"][:, t])  # b1av
# 		inputs.append(torch.zeros_like(batch["actions_onehot"][:, t]) if t==0 else batch["actions_onehot"][:, t-1])
# 		inputs.append(torch.eye(self.n_agents, device=batch.device).unsqueeze(0).expand(bs, -1, -1))
# 		inputs = torch.cat([x.reshape(bs, self.n_agents, -1) for x in inputs], dim=-1)
# 		return inputs

# 	def _get_input_shape(self, scheme):
# 		input_shape = scheme["obs"]["vshape"]
# 		input_shape += scheme["actions_onehot"]["vshape"][0]
# 		input_shape += self.n_agents
# 		return input_shape

# class RNNAgent(torch.nn.Module):
# 	def __init__(self, input_shape, output_shape):
# 		super(RNNAgent, self).__init__()
# 		self.fc1 = torch.nn.Linear(input_shape, HIDDEN_SIZE)
# 		self.fc3 = torch.nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)
# 		# self.rnn = torch.nn.GRUCell(HIDDEN_SIZE, HIDDEN_SIZE)
# 		self.fc2 = torch.nn.Linear(HIDDEN_SIZE, output_shape)

# 	def init_hidden(self):
# 		return self.fc1.weight.new(1, HIDDEN_SIZE).zero_()

# 	def forward(self, inputs, hidden_state):
# 		x = torch.relu(self.fc1(inputs))
# 		# h_in = hidden_state.reshape(-1, HIDDEN_SIZE)
# 		# h = self.rnn(x, h_in)
# 		x = self.fc3(x).relu()
# 		q = self.fc2(x)
# 		return q

# class MultinomialActionSelector():
# 	def __init__(self, eps_start=EPS_MAX, eps_finish=EPS_MIN, eps_decay=EPS_DECAY):
# 		self.schedule = DecayThenFlatSchedule(eps_start, eps_finish, EPISODE_LIMIT/(1-eps_decay), decay="linear")
# 		self.epsilon = self.schedule.eval(0)

# 	def select_action(self, agent_inputs, t_env, test_mode=False):
# 		self.epsilon = self.schedule.eval(t_env)
# 		masked_policies = agent_inputs.clone()
# 		picked_actions = masked_policies.max(dim=2)[1] if test_mode else torch.distributions.Categorical(masked_policies).sample().long()
# 		return picked_actions

# class DecayThenFlatSchedule():
# 	def __init__(self, start, finish, time_length, decay="exp"):
# 		self.start = start
# 		self.finish = finish
# 		self.time_length = time_length
# 		self.delta = (self.start - self.finish) / self.time_length
# 		self.decay = decay
# 		if self.decay in ["exp"]:
# 			self.exp_scaling = (-1) * self.time_length / np.log(self.finish) if self.finish > 0 else 1

# 	def eval(self, T):
# 		if self.decay in ["linear"]:
# 			return max(self.finish, self.start - self.delta * T)
# 		elif self.decay in ["exp"]:
# 			return min(self.start, max(self.finish, np.exp(- T / self.exp_scaling)))

# from types import SimpleNamespace as SN

# class EpisodeBatch():
# 	def __init__(self, scheme, groups, batch_size, max_seq_length, data=None, preprocess=None, device="cpu"):
# 		self.scheme = scheme.copy()
# 		self.groups = groups
# 		self.batch_size = batch_size
# 		self.max_seq_length = max_seq_length
# 		self.preprocess = {} if preprocess is None else preprocess
# 		self.device = device

# 		if data is not None:
# 			self.data = data
# 		else:
# 			self.data = SN()
# 			self.data.transition_data = {}
# 			self.data.episode_data = {}
# 			self._setup_data(self.scheme, self.groups, batch_size, max_seq_length, self.preprocess)

# 	def _setup_data(self, scheme, groups, batch_size, max_seq_length, preprocess):
# 		if preprocess is not None:
# 			for k in preprocess:
# 				assert k in scheme
# 				new_k = preprocess[k][0]
# 				transforms = preprocess[k][1]
# 				vshape = self.scheme[k]["vshape"]
# 				dtype = self.scheme[k]["dtype"]
# 				for transform in transforms:
# 					vshape, dtype = transform.infer_output_info(vshape, dtype)
# 				self.scheme[new_k] = {"vshape": vshape, "dtype": dtype}
# 				if "group" in self.scheme[k]:
# 					self.scheme[new_k]["group"] = self.scheme[k]["group"]
# 				if "episode_const" in self.scheme[k]:
# 					self.scheme[new_k]["episode_const"] = self.scheme[k]["episode_const"]

# 		assert "filled" not in scheme, '"filled" is a reserved key for masking.'
# 		scheme.update({"filled": {"vshape": (1,), "dtype": torch.long},})

# 		for field_key, field_info in scheme.items():
# 			assert "vshape" in field_info, "Scheme must define vshape for {}".format(field_key)
# 			vshape = field_info["vshape"]
# 			episode_const = field_info.get("episode_const", False)
# 			group = field_info.get("group", None)
# 			dtype = field_info.get("dtype", torch.float32)

# 			if isinstance(vshape, int):
# 				vshape = (vshape,)
# 			if group:
# 				assert group in groups, "Group {} must have its number of members defined in _groups_".format(group)
# 				shape = (groups[group], *vshape)
# 			else:
# 				shape = vshape
# 			if episode_const:
# 				self.data.episode_data[field_key] = torch.zeros((batch_size, *shape), dtype=dtype).to(self.device)
# 			else:
# 				self.data.transition_data[field_key] = torch.zeros((batch_size, max_seq_length, *shape), dtype=dtype).to(self.device)

# 	def extend(self, scheme, groups=None):
# 		self._setup_data(scheme, self.groups if groups is None else groups, self.batch_size, self.max_seq_length)

# 	def to(self, device):
# 		for k, v in self.data.transition_data.items():
# 			self.data.transition_data[k] = v.to(device)
# 		for k, v in self.data.episode_data.items():
# 			self.data.episode_data[k] = v.to(device)
# 		self.device = device

# 	def update(self, data, bs=slice(None), ts=slice(None), mark_filled=True):
# 		slices = self._parse_slices((bs, ts))
# 		for k, v in data.items():
# 			if k in self.data.transition_data:
# 				target = self.data.transition_data
# 				if mark_filled:
# 					target["filled"][slices] = 1
# 					mark_filled = False
# 				_slices = slices
# 			elif k in self.data.episode_data:
# 				target = self.data.episode_data
# 				_slices = slices[0]
# 			else:
# 				raise KeyError("{} not found in transition or episode data".format(k))

# 			dtype = self.scheme[k].get("dtype", torch.float32)
# 			v = v if isinstance(v, torch.Tensor) else torch.tensor(v, dtype=dtype, device=self.device)
# 			self._check_safe_view(v, target[k][_slices])
# 			target[k][_slices] = v.view_as(target[k][_slices])

# 			if k in self.preprocess:
# 				new_k = self.preprocess[k][0]
# 				v = target[k][_slices]
# 				for transform in self.preprocess[k][1]:
# 					v = transform.transform(v)
# 				target[new_k][_slices] = v.view_as(target[new_k][_slices])

# 	def _check_safe_view(self, v, dest):
# 		idx = len(v.shape) - 1
# 		for s in dest.shape[::-1]:
# 			if v.shape[idx] != s:
# 				if s != 1:
# 					raise ValueError("Unsafe reshape of {} to {}".format(v.shape, dest.shape))
# 			else:
# 				idx -= 1

# 	def __getitem__(self, item):
# 		if isinstance(item, str):
# 			if item in self.data.episode_data:
# 				return self.data.episode_data[item]
# 			elif item in self.data.transition_data:
# 				return self.data.transition_data[item]
# 			else:
# 				raise ValueError
# 		elif isinstance(item, tuple) and all([isinstance(it, str) for it in item]):
# 			new_data = self._new_data_sn()
# 			for key in item:
# 				if key in self.data.transition_data:
# 					new_data.transition_data[key] = self.data.transition_data[key]
# 				elif key in self.data.episode_data:
# 					new_data.episode_data[key] = self.data.episode_data[key]
# 				else:
# 					raise KeyError("Unrecognised key {}".format(key))

# 			# Update the scheme to only have the requested keys
# 			new_scheme = {key: self.scheme[key] for key in item}
# 			new_groups = {self.scheme[key]["group"]: self.groups[self.scheme[key]["group"]]
# 						for key in item if "group" in self.scheme[key]}
# 			ret = EpisodeBatch(new_scheme, new_groups, self.batch_size, self.max_seq_length, data=new_data, device=self.device)
# 			return ret
# 		else:
# 			item = self._parse_slices(item)
# 			new_data = self._new_data_sn()
# 			for k, v in self.data.transition_data.items():
# 				new_data.transition_data[k] = v[item]
# 			for k, v in self.data.episode_data.items():
# 				new_data.episode_data[k] = v[item[0]]

# 			ret_bs = self._get_num_items(item[0], self.batch_size)
# 			ret_max_t = self._get_num_items(item[1], self.max_seq_length)

# 			ret = EpisodeBatch(self.scheme, self.groups, ret_bs, ret_max_t, data=new_data, device=self.device)
# 			return ret

# 	def _get_num_items(self, indexing_item, max_size):
# 		if isinstance(indexing_item, list) or isinstance(indexing_item, np.ndarray):
# 			return len(indexing_item)
# 		elif isinstance(indexing_item, slice):
# 			_range = indexing_item.indices(max_size)
# 			return 1 + (_range[1] - _range[0] - 1)//_range[2]

# 	def _new_data_sn(self):
# 		new_data = SN()
# 		new_data.transition_data = {}
# 		new_data.episode_data = {}
# 		return new_data

# 	def _parse_slices(self, items):
# 		parsed = []
# 		# Only batch slice given, add full time slice
# 		if (isinstance(items, slice)  # slice a:b
# 			or isinstance(items, int)  # int i
# 			or (isinstance(items, (list, np.ndarray, torch.LongTensor, torch.cuda.LongTensor)))  # [a,b,c]
# 			):
# 			items = (items, slice(None))

# 		# Need the time indexing to be contiguous
# 		if isinstance(items[1], list):
# 			raise IndexError("Indexing across Time must be contiguous")

# 		for item in items:
# 			#TODO: stronger checks to ensure only supported options get through
# 			if isinstance(item, int):
# 				# Convert single indices to slices
# 				parsed.append(slice(item, item+1))
# 			else:
# 				# Leave slices and lists as is
# 				parsed.append(item)
# 		return parsed

# 	def max_t_filled(self):
# 		return torch.sum(self.data.transition_data["filled"], 1).max(0)[0]

# class ReplayBuffer(EpisodeBatch):
# 	def __init__(self, scheme, groups, buffer_size, max_seq_length, preprocess=None, device="cpu"):
# 		super(ReplayBuffer, self).__init__(scheme, groups, buffer_size, max_seq_length, preprocess=preprocess, device=device)
# 		self.buffer_size = buffer_size  # same as self.batch_size but more explicit
# 		self.buffer_index = 0
# 		self.episodes_in_buffer = 0

# 	def insert_episode_batch(self, ep_batch):
# 		if self.buffer_index + ep_batch.batch_size <= self.buffer_size:
# 			self.update(ep_batch.data.transition_data, slice(self.buffer_index, self.buffer_index + ep_batch.batch_size), slice(0, ep_batch.max_seq_length), mark_filled=False)
# 			self.update(ep_batch.data.episode_data, slice(self.buffer_index, self.buffer_index + ep_batch.batch_size))
# 			self.buffer_index = (self.buffer_index + ep_batch.batch_size)
# 			self.episodes_in_buffer = max(self.episodes_in_buffer, self.buffer_index)
# 			self.buffer_index = self.buffer_index % self.buffer_size
# 			assert self.buffer_index < self.buffer_size
# 		else:
# 			buffer_left = self.buffer_size - self.buffer_index
# 			self.insert_episode_batch(ep_batch[0:buffer_left, :])
# 			self.insert_episode_batch(ep_batch[buffer_left:, :])

# 	def can_sample(self, batch_size):
# 		return self.episodes_in_buffer >= batch_size

# 	def sample(self, batch_size):
# 		assert self.can_sample(batch_size)
# 		if self.episodes_in_buffer == batch_size:
# 			return self[:batch_size]
# 		else:
# 			ep_ids = np.random.choice(self.episodes_in_buffer, batch_size, replace=False)
# 			return self[ep_ids]


import torch
import random
import numpy as np
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, one_hot, gsoftmax

EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64

class COMAActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)!=3 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_probs = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.init_hidden()

	def forward(self, state, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_probs = self.action_probs(state).softmax(-1)
		dist = torch.distributions.Categorical(action_probs)
		action_in = dist.sample()
		action = one_hot_from_indices(action_in, action_probs.size(-1))
		entropy = dist.entropy()
		return action, action_probs, entropy

	def init_hidden(self, batch_size=1):
		self.hidden = torch.zeros([batch_size, ACTOR_HIDDEN])

class COMACritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)!=3 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.q_values = torch.nn.Linear(CRITIC_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		q_values = self.q_values(state)
		return q_values

class COMANetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(gpu=gpu)
		self.state_size = [state_size] if type(state_size[0]) in [int, np.int32] else state_size
		self.action_size = [action_size] if type(action_size[0]) in [int, np.int32] else action_size
		self.n_agents = lambda size: 1 if len(size)==1 else size[0]
		make_actor = lambda s_size,a_size: COMAActor([s_size[-1] + a_size[-1] + self.n_agents(s_size)], a_size)
		make_critic = lambda s_size,a_size: COMACritic([np.sum([np.prod(s) for s in self.state_size]) + 2*np.sum([np.prod(a) for a in self.action_size]) + s_size[-1] + self.n_agents(s_size)], a_size)
		self.models = [PTACNetwork(s_size, a_size, make_actor, make_critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		if load: self.load_model(load)
		
	def get_action_probs(self, state, sample=True, grad=True, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			action, action_prob, entropy = map(list, zip(*[model.actor_local(s, sample) for s,model in zip(state, self.models)]))
			return [[a.cpu().numpy().astype(np.float32) for a in x] for x in [action, action_prob, entropy]] if numpy else (action, action_prob, entropy)

	def get_value(self, state, use_target=False, grad=True, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_values = [model.critic_local(s) if use_target else model.critic_target(s) for s,model in zip(state, self.models)]
			return [q.cpu().numpy() for q in q_values] if numpy else q_values

	def optimize(self, actions, actor_inputs, critic_inputs, q_values, q_targets):
		for model,action,actor_input,critic_input,q_value,q_target in zip(self.models, actions, actor_inputs, critic_inputs, q_values, q_targets):
			q_value = model.critic_local(critic_input)
			q_select = torch.gather(q_value, dim=-1, index=action.argmax(-1, keepdims=True)).squeeze(-1)
			critic_loss = (q_select - q_target.detach()).pow(2)
			model.step(model.critic_optimizer, critic_loss.mean(), model.critic_local.parameters())
			model.soft_copy(model.critic_local, model.critic_target)

			_, action_probs, entropy = model.actor_local(actor_input)
			baseline = (action_probs * q_value).sum(-1, keepdims=True).detach()
			q_selected = torch.gather(q_value, dim=-1, index=action.argmax(-1, keepdims=True))
			log_probs = torch.gather(action_probs, dim=-1, index=action.argmax(-1, keepdims=True)).log()
			advantages = (q_selected - baseline).detach()
			actor_loss = -((advantages * log_probs).sum() + ENTROPY_WEIGHT*entropy.mean())
			model.step(model.actor_optimizer, actor_loss.mean(), model.actor_local.parameters())

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("coma", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("coma", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class COMAAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, COMANetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.replay_buffer = MultiagentReplayBuffer3(MAX_BUFFER_SIZE, state_size, action_size)

	def get_action(self, state, eps=None, sample=True, numpy=True):
		self.step = 0 if not hasattr(self, "step") else self.step + 1
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state)
		if not hasattr(self, "action"): self.action = [np.zeros_like(a) for a in action_random]
		actor_inputs = []
		state_list = state
		state_list = [state_list] if type(state_list) != list else state_list
		for i,(state,last_a,s_size,a_size) in enumerate(zip(state_list, self.action, self.state_size, self.action_size)):
			n_agents = self.network.n_agents(s_size)
			last_action = last_a if len(state.shape)-len(s_size) == len(last_a.shape)-len(a_size) else np.zeros_like(action_random[i])
			agent_ids = np.eye(n_agents) if len(state.shape)==len(s_size) else np.repeat(np.expand_dims(np.eye(n_agents), 0), repeats=state.shape[0], axis=0)
			actor_input = self.to_tensor(np.concatenate([state, last_action, agent_ids], axis=-1))
			actor_inputs.append(actor_input)
		action = self.network.get_action_probs(actor_inputs, sample=sample, grad=False, numpy=numpy)[0]
		if numpy: self.action = action
		return action

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.update_freq:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			n_agents = [self.network.n_agents(a_size) for a_size in self.action_size]
			states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, self.to_tensor(next_state))]
			actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.get_action(next_state, numpy=False))]
			states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			actions_one_hot = [one_hot(a) for a in actions]
			actions_one_hot_joint = torch.cat([a.view(*a.shape[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions_one_hot, self.action_size)], dim=-1)
			last_actions = [torch.cat([torch.zeros_like(a[0:1]), a[:-1]], dim=0) for a in actions_one_hot]
			last_actions_joint = torch.cat([a.view(*a.shape[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(last_actions, self.action_size)], dim=-1)
			agent_mask = [(1-torch.eye(n_agent)).view(-1, 1).repeat(1, a_size[-1]).view(n_agent, -1) for a_size,n_agent in zip(self.action_size, n_agents)]
			action_mask = torch.ones([1, 1, np.sum(n_agents), np.sum([n_agent*a_size[-1] for a_size,n_agent in zip(self.action_size, n_agents)])]).to(self.network.device)
			cols, rows = [0, *np.cumsum(n_agents)], [0, *np.cumsum([n_agent*a_size[-1] for a_size,n_agent in zip(self.action_size, n_agents)])]
			for i,mask in enumerate(agent_mask): action_mask[...,cols[i]:cols[i+1], rows[i]:rows[i+1]] = mask

			states_joint, actions_joint, last_actions_joint = [x.unsqueeze(-2).repeat_interleave(action_mask.shape[-2], dim=-2) for x in [states_joint, actions_one_hot_joint, last_actions_joint]]
			joint_inputs = torch.cat([states_joint, actions_joint * action_mask, last_actions_joint], dim=-1).split(n_agents, dim=-2)
			agent_ids = [torch.eye(self.network.n_agents(a_size)).unsqueeze(0).unsqueeze(0).expand(*a.shape[:2], -1, -1).to(self.network.device) for a_size, a in zip(self.action_size, actions)]
			critic_inputs = [torch.cat([joint_input, state, agent_id], dim=-1) for joint_input,state,agent_id in zip(joint_inputs, states, agent_ids)]
			actor_inputs = [torch.cat([state, last_action, agent_id], dim=-1) for state,last_action,agent_id in zip(states, last_actions, agent_ids)]

			q_values = self.network.get_value(critic_inputs, use_target=True, grad=False)
			q_selecteds = [torch.gather(q_value, dim=-1, index=a.argmax(-1, keepdims=True)).squeeze(-1) for q_value,a in zip(q_values,actions)]
			q_targets = [self.compute_gae(q_selected[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_selected[:-1])[0] for q_selected,reward,done in zip(q_selecteds, rewards, dones)]
			actions, actor_inputs, critic_inputs, q_values = [[t[:-1] for t in x] for x in [actions, actor_inputs, critic_inputs, q_values]]
			actions, actor_inputs, critic_inputs, q_values, q_targets = [[t.reshape(-1, *t.shape[2:]).cpu().numpy() for t in x] for x in [actions, actor_inputs, critic_inputs, q_values, q_targets]]
			self.replay_buffer.add((actions, actor_inputs, critic_inputs, q_values, q_targets))
		if len(self.replay_buffer) >= REPLAY_BATCH_SIZE and self.step%self.update_freq == 0:
			actions, actor_inputs, critic_inputs, q_values, q_targets = self.replay_buffer.sample(REPLAY_BATCH_SIZE, cast=self.to_tensor)
			self.network.optimize(actions, actor_inputs, critic_inputs, q_values, q_targets)
			if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0003           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.001   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 256				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 512				# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.998			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.001               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 1000000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.sac import SACAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, DoubleAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv, TrainEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, MPI_SIZE, MPI_RANK
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-3]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False, reward_shape=False):
	if env_name in gym_envs: return TrainEnv(gym.make(env_name))
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	ballr = lambda x,y: (np.maximum if x>0 else np.minimum)(x - np.abs(y)*np.sign(x), 0.5*x)
	reward_fn = lambda obs,reward: [(ballr(o[0,88], o[0,89]) + o[0,95]-o[0,96] + 2*r)/4 for o,r in zip(obs,reward)]
	return FootballTeamEnv(ggym, env_name, reward_fn if reward_shape else None)

def run(model, steps=10000, ports=16, env_name=env_name, trial_at=100, save_at=10, checkpoint=True, save_best=False, log=True, render=False, reward_shape=False, icm=False):
	envs = (EnvManager if type(ports) == list or MPI_SIZE > 1 else EnsembleEnv)(lambda: make_env(env_name, reward_shape=reward_shape), ports)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, envs.num_envs, load="", gpu=True, agent2=RandomAgent, save_dir=env_name, icm=icm) 
	logger = Logger(model, env_name, num_envs=envs.num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space, envs=type(envs), reward_shape=reward_shape, icm=icm)
	states = envs.reset(train=True)
	total_rewards = []
	for s in range(steps+1):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions, train=True)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if s%trial_at == 0:
			rollouts = rollout(envs, agent, render=render)
			total_rewards.append(np.mean(rollouts, axis=-1))
			if checkpoint and len(total_rewards) % save_at==0: agent.save_model(env_name, "checkpoint")
			if save_best and np.all(total_rewards[-1] >= np.max(total_rewards, axis=-1)): agent.save_model(env_name)
			if log: logger.log(f"Step: {s:7d}, Reward: {total_rewards[-1]} [{np.std(rollouts):4.3f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.eps:.4f})", agent.get_stats())

def trial(model, env_name, render):
	envs = EnsembleEnv(lambda: make_env(env_name, log=True, render=render), 0)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, gpu=False, load=f"{env_name}", agent2=RandomAgent, save_dir=env_name)
	print(f"Reward: {np.mean([rollout(envs.env, agent, eps=0.0, render=True) for _ in range(5)], axis=0)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="coma", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=200000, help="Number of steps to train the agent")
	parser.add_argument("--reward_shape", action="store_true", help="Whether to shape rewards for football")
	parser.add_argument("--icm", action="store_true", help="Whether to use intrinsic motivation")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--trial", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "sac":SACAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent, "rand":RandomAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.trial:
		trial(model=model, env_name=env_name, render=args.render)
	elif args.selfport is not None or MPI_RANK>0 :
		EnvWorker(self_port=args.selfport, make_env=make_env).start()
	else:
		run(model=model, steps=args.steps, ports=args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render, reward_shape=args.reward_shape, icm=args.icm)


Step:       0, Reward: [-530.819 -530.819 -530.819] [136.967], Avg: [-530.819 -530.819 -530.819] (1.0000) ({r_i: None, r_t: [-9.157 -9.157 -9.157], eps: 1.0})
Step:     100, Reward: [-564.659 -564.659 -564.659] [143.246], Avg: [-547.739 -547.739 -547.739] (1.0000) ({r_i: None, r_t: [-1124.156 -1124.156 -1124.156], eps: 1.0})
Step:     200, Reward: [-579.724 -579.724 -579.724] [117.850], Avg: [-558.401 -558.401 -558.401] (1.0000) ({r_i: None, r_t: [-1102.493 -1102.493 -1102.493], eps: 1.0})
Step:     300, Reward: [-548.741 -548.741 -548.741] [112.749], Avg: [-555.986 -555.986 -555.986] (1.0000) ({r_i: None, r_t: [-1039.863 -1039.863 -1039.863], eps: 1.0})
Step:     400, Reward: [-491.662 -491.662 -491.662] [72.288], Avg: [-543.121 -543.121 -543.121] (1.0000) ({r_i: None, r_t: [-1038.797 -1038.797 -1038.797], eps: 1.0})
Step:     500, Reward: [-515.401 -515.401 -515.401] [94.935], Avg: [-538.501 -538.501 -538.501] (1.0000) ({r_i: None, r_t: [-1016.313 -1016.313 -1016.313], eps: 1.0})
Step:     600, Reward: [-521.472 -521.472 -521.472] [109.631], Avg: [-536.068 -536.068 -536.068] (1.0000) ({r_i: None, r_t: [-1065.828 -1065.828 -1065.828], eps: 1.0})
Step:     700, Reward: [-492.673 -492.673 -492.673] [121.055], Avg: [-530.644 -530.644 -530.644] (1.0000) ({r_i: None, r_t: [-1078.970 -1078.970 -1078.970], eps: 1.0})
Step:     800, Reward: [-504.081 -504.081 -504.081] [131.968], Avg: [-527.693 -527.693 -527.693] (1.0000) ({r_i: None, r_t: [-1007.279 -1007.279 -1007.279], eps: 1.0})
Step:     900, Reward: [-493.563 -493.563 -493.563] [91.522], Avg: [-524.280 -524.280 -524.280] (1.0000) ({r_i: None, r_t: [-1060.656 -1060.656 -1060.656], eps: 1.0})
Step:    1000, Reward: [-491.890 -491.890 -491.890] [54.790], Avg: [-521.335 -521.335 -521.335] (1.0000) ({r_i: None, r_t: [-1000.091 -1000.091 -1000.091], eps: 1.0})
Step:    1100, Reward: [-519.758 -519.758 -519.758] [104.684], Avg: [-521.204 -521.204 -521.204] (1.0000) ({r_i: None, r_t: [-1121.684 -1121.684 -1121.684], eps: 1.0})
Step:    1200, Reward: [-566.057 -566.057 -566.057] [153.547], Avg: [-524.654 -524.654 -524.654] (1.0000) ({r_i: None, r_t: [-1083.958 -1083.958 -1083.958], eps: 1.0})
Step:    1300, Reward: [-520.435 -520.435 -520.435] [86.131], Avg: [-524.353 -524.353 -524.353] (1.0000) ({r_i: None, r_t: [-997.787 -997.787 -997.787], eps: 1.0})
Step:    1400, Reward: [-512.341 -512.341 -512.341] [146.940], Avg: [-523.552 -523.552 -523.552] (1.0000) ({r_i: None, r_t: [-1037.353 -1037.353 -1037.353], eps: 1.0})
Step:    1500, Reward: [-563.368 -563.368 -563.368] [139.977], Avg: [-526.040 -526.040 -526.040] (1.0000) ({r_i: None, r_t: [-1080.738 -1080.738 -1080.738], eps: 1.0})
Step:    1600, Reward: [-574.331 -574.331 -574.331] [139.057], Avg: [-528.881 -528.881 -528.881] (1.0000) ({r_i: None, r_t: [-1056.289 -1056.289 -1056.289], eps: 1.0})
Step:    1700, Reward: [-542.464 -542.464 -542.464] [132.967], Avg: [-529.636 -529.636 -529.636] (1.0000) ({r_i: None, r_t: [-1040.719 -1040.719 -1040.719], eps: 1.0})
Step:    1800, Reward: [-487.715 -487.715 -487.715] [93.184], Avg: [-527.429 -527.429 -527.429] (1.0000) ({r_i: None, r_t: [-1000.907 -1000.907 -1000.907], eps: 1.0})
Step:    1900, Reward: [-518.145 -518.145 -518.145] [109.025], Avg: [-526.965 -526.965 -526.965] (1.0000) ({r_i: None, r_t: [-1077.419 -1077.419 -1077.419], eps: 1.0})
Step:    2000, Reward: [-540.075 -540.075 -540.075] [97.787], Avg: [-527.589 -527.589 -527.589] (1.0000) ({r_i: None, r_t: [-1076.349 -1076.349 -1076.349], eps: 1.0})
Step:    2100, Reward: [-517.761 -517.761 -517.761] [91.482], Avg: [-527.142 -527.142 -527.142] (1.0000) ({r_i: None, r_t: [-1010.423 -1010.423 -1010.423], eps: 1.0})
Step:    2200, Reward: [-527.014 -527.014 -527.014] [143.054], Avg: [-527.137 -527.137 -527.137] (1.0000) ({r_i: None, r_t: [-1067.631 -1067.631 -1067.631], eps: 1.0})
Step:    2300, Reward: [-514.800 -514.800 -514.800] [76.168], Avg: [-526.623 -526.623 -526.623] (1.0000) ({r_i: None, r_t: [-1056.667 -1056.667 -1056.667], eps: 1.0})
Step:    2400, Reward: [-571.366 -571.366 -571.366] [112.915], Avg: [-528.413 -528.413 -528.413] (1.0000) ({r_i: None, r_t: [-1060.591 -1060.591 -1060.591], eps: 1.0})
Step:    2500, Reward: [-504.940 -504.940 -504.940] [75.794], Avg: [-527.510 -527.510 -527.510] (1.0000) ({r_i: None, r_t: [-1153.280 -1153.280 -1153.280], eps: 1.0})
Step:    2600, Reward: [-554.017 -554.017 -554.017] [104.852], Avg: [-528.492 -528.492 -528.492] (1.0000) ({r_i: None, r_t: [-1104.403 -1104.403 -1104.403], eps: 1.0})
Step:    2700, Reward: [-489.093 -489.093 -489.093] [75.851], Avg: [-527.084 -527.084 -527.084] (1.0000) ({r_i: None, r_t: [-1043.122 -1043.122 -1043.122], eps: 1.0})
Step:    2800, Reward: [-528.303 -528.303 -528.303] [159.603], Avg: [-527.126 -527.126 -527.126] (1.0000) ({r_i: None, r_t: [-1111.023 -1111.023 -1111.023], eps: 1.0})
Step:    2900, Reward: [-539.091 -539.091 -539.091] [110.225], Avg: [-527.525 -527.525 -527.525] (1.0000) ({r_i: None, r_t: [-1004.197 -1004.197 -1004.197], eps: 1.0})
Step:    3000, Reward: [-568.131 -568.131 -568.131] [138.378], Avg: [-528.835 -528.835 -528.835] (1.0000) ({r_i: None, r_t: [-1055.014 -1055.014 -1055.014], eps: 1.0})
Step:    3100, Reward: [-518.217 -518.217 -518.217] [99.798], Avg: [-528.503 -528.503 -528.503] (1.0000) ({r_i: None, r_t: [-1062.731 -1062.731 -1062.731], eps: 1.0})
Step:    3200, Reward: [-542.398 -542.398 -542.398] [88.967], Avg: [-528.924 -528.924 -528.924] (1.0000) ({r_i: None, r_t: [-1069.654 -1069.654 -1069.654], eps: 1.0})
Step:    3300, Reward: [-484.373 -484.373 -484.373] [63.817], Avg: [-527.614 -527.614 -527.614] (1.0000) ({r_i: None, r_t: [-1071.895 -1071.895 -1071.895], eps: 1.0})
Step:    3400, Reward: [-569.655 -569.655 -569.655] [101.199], Avg: [-528.815 -528.815 -528.815] (1.0000) ({r_i: None, r_t: [-1106.497 -1106.497 -1106.497], eps: 1.0})
Step:    3500, Reward: [-623.891 -623.891 -623.891] [215.138], Avg: [-531.456 -531.456 -531.456] (1.0000) ({r_i: None, r_t: [-1042.989 -1042.989 -1042.989], eps: 1.0})
Step:    3600, Reward: [-595.682 -595.682 -595.682] [168.828], Avg: [-533.192 -533.192 -533.192] (1.0000) ({r_i: None, r_t: [-1118.424 -1118.424 -1118.424], eps: 1.0})
Step:    3700, Reward: [-511.906 -511.906 -511.906] [82.832], Avg: [-532.632 -532.632 -532.632] (1.0000) ({r_i: None, r_t: [-1049.902 -1049.902 -1049.902], eps: 1.0})
Step:    3800, Reward: [-499.833 -499.833 -499.833] [100.143], Avg: [-531.791 -531.791 -531.791] (1.0000) ({r_i: None, r_t: [-1007.134 -1007.134 -1007.134], eps: 1.0})
Step:    3900, Reward: [-535.354 -535.354 -535.354] [89.405], Avg: [-531.880 -531.880 -531.880] (1.0000) ({r_i: None, r_t: [-1039.636 -1039.636 -1039.636], eps: 1.0})
Step:    4000, Reward: [-528.919 -528.919 -528.919] [109.608], Avg: [-531.808 -531.808 -531.808] (1.0000) ({r_i: None, r_t: [-1076.311 -1076.311 -1076.311], eps: 1.0})
Step:    4100, Reward: [-511.073 -511.073 -511.073] [87.053], Avg: [-531.314 -531.314 -531.314] (1.0000) ({r_i: None, r_t: [-1065.059 -1065.059 -1065.059], eps: 1.0})
Step:    4200, Reward: [-537.426 -537.426 -537.426] [122.602], Avg: [-531.456 -531.456 -531.456] (1.0000) ({r_i: None, r_t: [-1092.107 -1092.107 -1092.107], eps: 1.0})
Step:    4300, Reward: [-497.187 -497.187 -497.187] [88.685], Avg: [-530.677 -530.677 -530.677] (1.0000) ({r_i: None, r_t: [-1049.179 -1049.179 -1049.179], eps: 1.0})
Step:    4400, Reward: [-570.751 -570.751 -570.751] [147.481], Avg: [-531.568 -531.568 -531.568] (1.0000) ({r_i: None, r_t: [-1107.510 -1107.510 -1107.510], eps: 1.0})
Step:    4500, Reward: [-544.513 -544.513 -544.513] [132.003], Avg: [-531.849 -531.849 -531.849] (1.0000) ({r_i: None, r_t: [-1116.431 -1116.431 -1116.431], eps: 1.0})
Step:    4600, Reward: [-564.207 -564.207 -564.207] [119.386], Avg: [-532.538 -532.538 -532.538] (1.0000) ({r_i: None, r_t: [-1060.949 -1060.949 -1060.949], eps: 1.0})
Step:    4700, Reward: [-500.129 -500.129 -500.129] [88.512], Avg: [-531.863 -531.863 -531.863] (1.0000) ({r_i: None, r_t: [-1091.263 -1091.263 -1091.263], eps: 1.0})
Step:    4800, Reward: [-584.583 -584.583 -584.583] [150.179], Avg: [-532.939 -532.939 -532.939] (1.0000) ({r_i: None, r_t: [-1149.926 -1149.926 -1149.926], eps: 1.0})
Step:    4900, Reward: [-508.583 -508.583 -508.583] [73.444], Avg: [-532.451 -532.451 -532.451] (1.0000) ({r_i: None, r_t: [-1120.622 -1120.622 -1120.622], eps: 1.0})
Step:    5000, Reward: [-577.359 -577.359 -577.359] [113.809], Avg: [-533.332 -533.332 -533.332] (1.0000) ({r_i: None, r_t: [-1096.027 -1096.027 -1096.027], eps: 1.0})
Step:    5100, Reward: [-570.174 -570.174 -570.174] [105.708], Avg: [-534.040 -534.040 -534.040] (1.0000) ({r_i: None, r_t: [-1038.989 -1038.989 -1038.989], eps: 1.0})
Step:    5200, Reward: [-546.474 -546.474 -546.474] [117.876], Avg: [-534.275 -534.275 -534.275] (1.0000) ({r_i: None, r_t: [-1165.845 -1165.845 -1165.845], eps: 1.0})
Step:    5300, Reward: [-619.815 -619.815 -619.815] [171.500], Avg: [-535.859 -535.859 -535.859] (1.0000) ({r_i: None, r_t: [-1126.925 -1126.925 -1126.925], eps: 1.0})
Step:    5400, Reward: [-501.012 -501.012 -501.012] [97.368], Avg: [-535.226 -535.226 -535.226] (1.0000) ({r_i: None, r_t: [-1080.922 -1080.922 -1080.922], eps: 1.0})
Step:    5500, Reward: [-519.080 -519.080 -519.080] [141.774], Avg: [-534.937 -534.937 -534.937] (1.0000) ({r_i: None, r_t: [-1151.325 -1151.325 -1151.325], eps: 1.0})
Step:    5600, Reward: [-556.382 -556.382 -556.382] [124.339], Avg: [-535.313 -535.313 -535.313] (1.0000) ({r_i: None, r_t: [-1162.281 -1162.281 -1162.281], eps: 1.0})
Step:    5700, Reward: [-567.813 -567.813 -567.813] [113.714], Avg: [-535.874 -535.874 -535.874] (1.0000) ({r_i: None, r_t: [-1061.715 -1061.715 -1061.715], eps: 1.0})
Step:    5800, Reward: [-534.983 -534.983 -534.983] [140.882], Avg: [-535.859 -535.859 -535.859] (1.0000) ({r_i: None, r_t: [-1055.585 -1055.585 -1055.585], eps: 1.0})
Step:    5900, Reward: [-509.119 -509.119 -509.119] [83.131], Avg: [-535.413 -535.413 -535.413] (1.0000) ({r_i: None, r_t: [-1115.623 -1115.623 -1115.623], eps: 1.0})
Step:    6000, Reward: [-540.095 -540.095 -540.095] [83.524], Avg: [-535.490 -535.490 -535.490] (1.0000) ({r_i: None, r_t: [-1070.880 -1070.880 -1070.880], eps: 1.0})
Step:    6100, Reward: [-467.577 -467.577 -467.577] [143.673], Avg: [-534.394 -534.394 -534.394] (1.0000) ({r_i: None, r_t: [-1057.956 -1057.956 -1057.956], eps: 1.0})
Step:    6200, Reward: [-543.495 -543.495 -543.495] [107.481], Avg: [-534.539 -534.539 -534.539] (1.0000) ({r_i: None, r_t: [-1066.714 -1066.714 -1066.714], eps: 1.0})
Step:    6300, Reward: [-588.326 -588.326 -588.326] [122.718], Avg: [-535.379 -535.379 -535.379] (1.0000) ({r_i: None, r_t: [-1054.158 -1054.158 -1054.158], eps: 1.0})
Step:    6400, Reward: [-510.469 -510.469 -510.469] [103.270], Avg: [-534.996 -534.996 -534.996] (1.0000) ({r_i: None, r_t: [-1072.177 -1072.177 -1072.177], eps: 1.0})
Step:    6500, Reward: [-530.307 -530.307 -530.307] [138.377], Avg: [-534.925 -534.925 -534.925] (1.0000) ({r_i: None, r_t: [-1061.062 -1061.062 -1061.062], eps: 1.0})
Step:    6600, Reward: [-526.532 -526.532 -526.532] [138.646], Avg: [-534.800 -534.800 -534.800] (1.0000) ({r_i: None, r_t: [-1080.708 -1080.708 -1080.708], eps: 1.0})
Step:    6700, Reward: [-545.896 -545.896 -545.896] [81.115], Avg: [-534.963 -534.963 -534.963] (1.0000) ({r_i: None, r_t: [-1072.785 -1072.785 -1072.785], eps: 1.0})
Step:    6800, Reward: [-531.282 -531.282 -531.282] [112.346], Avg: [-534.910 -534.910 -534.910] (1.0000) ({r_i: None, r_t: [-1078.467 -1078.467 -1078.467], eps: 1.0})
Step:    6900, Reward: [-524.123 -524.123 -524.123] [84.914], Avg: [-534.755 -534.755 -534.755] (1.0000) ({r_i: None, r_t: [-1104.483 -1104.483 -1104.483], eps: 1.0})
Step:    7000, Reward: [-570.825 -570.825 -570.825] [123.081], Avg: [-535.263 -535.263 -535.263] (1.0000) ({r_i: None, r_t: [-1103.381 -1103.381 -1103.381], eps: 1.0})
Step:    7100, Reward: [-554.915 -554.915 -554.915] [97.577], Avg: [-535.536 -535.536 -535.536] (1.0000) ({r_i: None, r_t: [-1089.021 -1089.021 -1089.021], eps: 1.0})
Step:    7200, Reward: [-502.679 -502.679 -502.679] [119.789], Avg: [-535.086 -535.086 -535.086] (1.0000) ({r_i: None, r_t: [-1067.249 -1067.249 -1067.249], eps: 1.0})
Step:    7300, Reward: [-519.221 -519.221 -519.221] [89.855], Avg: [-534.872 -534.872 -534.872] (1.0000) ({r_i: None, r_t: [-1084.712 -1084.712 -1084.712], eps: 1.0})
Step:    7400, Reward: [-530.041 -530.041 -530.041] [96.480], Avg: [-534.807 -534.807 -534.807] (1.0000) ({r_i: None, r_t: [-1147.163 -1147.163 -1147.163], eps: 1.0})
Step:    7500, Reward: [-593.096 -593.096 -593.096] [130.142], Avg: [-535.574 -535.574 -535.574] (1.0000) ({r_i: None, r_t: [-1038.970 -1038.970 -1038.970], eps: 1.0})
Step:    7600, Reward: [-613.045 -613.045 -613.045] [169.685], Avg: [-536.581 -536.581 -536.581] (0.9950) ({r_i: None, r_t: [-1090.603 -1090.603 -1090.603], eps: 0.995})
Step:    7700, Reward: [-524.207 -524.207 -524.207] [80.691], Avg: [-536.422 -536.422 -536.422] (0.9950) ({r_i: None, r_t: [-1087.245 -1087.245 -1087.245], eps: 0.995})
Step:    7800, Reward: [-539.815 -539.815 -539.815] [107.201], Avg: [-536.465 -536.465 -536.465] (0.9950) ({r_i: None, r_t: [-1118.407 -1118.407 -1118.407], eps: 0.995})
Step:    7900, Reward: [-574.743 -574.743 -574.743] [114.791], Avg: [-536.943 -536.943 -536.943] (0.9950) ({r_i: None, r_t: [-1140.022 -1140.022 -1140.022], eps: 0.995})
Step:    8000, Reward: [-560.448 -560.448 -560.448] [127.508], Avg: [-537.234 -537.234 -537.234] (0.9950) ({r_i: None, r_t: [-1143.665 -1143.665 -1143.665], eps: 0.995})
Step:    8100, Reward: [-527.826 -527.826 -527.826] [98.184], Avg: [-537.119 -537.119 -537.119] (0.9950) ({r_i: None, r_t: [-1127.328 -1127.328 -1127.328], eps: 0.995})
Step:    8200, Reward: [-499.048 -499.048 -499.048] [73.772], Avg: [-536.660 -536.660 -536.660] (0.9950) ({r_i: None, r_t: [-1116.102 -1116.102 -1116.102], eps: 0.995})
Step:    8300, Reward: [-528.237 -528.237 -528.237] [101.536], Avg: [-536.560 -536.560 -536.560] (0.9950) ({r_i: None, r_t: [-1115.392 -1115.392 -1115.392], eps: 0.995})
Step:    8400, Reward: [-537.315 -537.315 -537.315] [72.761], Avg: [-536.569 -536.569 -536.569] (0.9950) ({r_i: None, r_t: [-1137.428 -1137.428 -1137.428], eps: 0.995})
Step:    8500, Reward: [-549.062 -549.062 -549.062] [86.943], Avg: [-536.714 -536.714 -536.714] (0.9950) ({r_i: None, r_t: [-1137.040 -1137.040 -1137.040], eps: 0.995})
Step:    8600, Reward: [-584.002 -584.002 -584.002] [134.152], Avg: [-537.258 -537.258 -537.258] (0.9950) ({r_i: None, r_t: [-1107.033 -1107.033 -1107.033], eps: 0.995})
Step:    8700, Reward: [-629.960 -629.960 -629.960] [122.325], Avg: [-538.311 -538.311 -538.311] (0.9950) ({r_i: None, r_t: [-1070.891 -1070.891 -1070.891], eps: 0.995})
Step:    8800, Reward: [-583.325 -583.325 -583.325] [158.684], Avg: [-538.817 -538.817 -538.817] (0.9950) ({r_i: None, r_t: [-1100.418 -1100.418 -1100.418], eps: 0.995})
Step:    8900, Reward: [-555.399 -555.399 -555.399] [111.658], Avg: [-539.001 -539.001 -539.001] (0.9950) ({r_i: None, r_t: [-1074.352 -1074.352 -1074.352], eps: 0.995})
Step:    9000, Reward: [-571.696 -571.696 -571.696] [118.043], Avg: [-539.360 -539.360 -539.360] (0.9950) ({r_i: None, r_t: [-1181.106 -1181.106 -1181.106], eps: 0.995})
Step:    9100, Reward: [-559.965 -559.965 -559.965] [94.554], Avg: [-539.584 -539.584 -539.584] (0.9950) ({r_i: None, r_t: [-1149.366 -1149.366 -1149.366], eps: 0.995})
Step:    9200, Reward: [-588.374 -588.374 -588.374] [131.241], Avg: [-540.109 -540.109 -540.109] (0.9950) ({r_i: None, r_t: [-1144.243 -1144.243 -1144.243], eps: 0.995})
Step:    9300, Reward: [-546.816 -546.816 -546.816] [125.982], Avg: [-540.180 -540.180 -540.180] (0.9950) ({r_i: None, r_t: [-1111.108 -1111.108 -1111.108], eps: 0.995})
Step:    9400, Reward: [-591.493 -591.493 -591.493] [159.545], Avg: [-540.720 -540.720 -540.720] (0.9950) ({r_i: None, r_t: [-1210.609 -1210.609 -1210.609], eps: 0.995})
Step:    9500, Reward: [-561.656 -561.656 -561.656] [111.603], Avg: [-540.938 -540.938 -540.938] (0.9950) ({r_i: None, r_t: [-1067.141 -1067.141 -1067.141], eps: 0.995})
Step:    9600, Reward: [-570.074 -570.074 -570.074] [116.749], Avg: [-541.239 -541.239 -541.239] (0.9950) ({r_i: None, r_t: [-1073.580 -1073.580 -1073.580], eps: 0.995})
Step:    9700, Reward: [-587.871 -587.871 -587.871] [120.847], Avg: [-541.715 -541.715 -541.715] (0.9950) ({r_i: None, r_t: [-1100.086 -1100.086 -1100.086], eps: 0.995})
Step:    9800, Reward: [-569.725 -569.725 -569.725] [115.311], Avg: [-541.998 -541.998 -541.998] (0.9950) ({r_i: None, r_t: [-1104.372 -1104.372 -1104.372], eps: 0.995})
Step:    9900, Reward: [-574.292 -574.292 -574.292] [163.568], Avg: [-542.321 -542.321 -542.321] (0.9950) ({r_i: None, r_t: [-1075.424 -1075.424 -1075.424], eps: 0.995})
Step:   10000, Reward: [-568.740 -568.740 -568.740] [112.060], Avg: [-542.582 -542.582 -542.582] (0.9950) ({r_i: None, r_t: [-1286.195 -1286.195 -1286.195], eps: 0.995})
Step:   10100, Reward: [-607.561 -607.561 -607.561] [106.645], Avg: [-543.219 -543.219 -543.219] (0.9950) ({r_i: None, r_t: [-1246.396 -1246.396 -1246.396], eps: 0.995})
Step:   10200, Reward: [-513.837 -513.837 -513.837] [108.091], Avg: [-542.934 -542.934 -542.934] (0.9950) ({r_i: None, r_t: [-1125.601 -1125.601 -1125.601], eps: 0.995})
Step:   10300, Reward: [-599.696 -599.696 -599.696] [155.895], Avg: [-543.480 -543.480 -543.480] (0.9950) ({r_i: None, r_t: [-1125.357 -1125.357 -1125.357], eps: 0.995})
Step:   10400, Reward: [-583.308 -583.308 -583.308] [128.124], Avg: [-543.859 -543.859 -543.859] (0.9950) ({r_i: None, r_t: [-1129.320 -1129.320 -1129.320], eps: 0.995})
Step:   10500, Reward: [-585.401 -585.401 -585.401] [136.405], Avg: [-544.251 -544.251 -544.251] (0.9950) ({r_i: None, r_t: [-1195.996 -1195.996 -1195.996], eps: 0.995})
Step:   10600, Reward: [-601.858 -601.858 -601.858] [111.835], Avg: [-544.789 -544.789 -544.789] (0.9950) ({r_i: None, r_t: [-1108.932 -1108.932 -1108.932], eps: 0.995})
Step:   10700, Reward: [-543.314 -543.314 -543.314] [103.900], Avg: [-544.776 -544.776 -544.776] (0.9950) ({r_i: None, r_t: [-1108.554 -1108.554 -1108.554], eps: 0.995})
Step:   10800, Reward: [-638.497 -638.497 -638.497] [205.766], Avg: [-545.635 -545.635 -545.635] (0.9950) ({r_i: None, r_t: [-1097.524 -1097.524 -1097.524], eps: 0.995})
Step:   10900, Reward: [-616.691 -616.691 -616.691] [120.398], Avg: [-546.281 -546.281 -546.281] (0.9950) ({r_i: None, r_t: [-1076.858 -1076.858 -1076.858], eps: 0.995})
Step:   11000, Reward: [-558.041 -558.041 -558.041] [99.146], Avg: [-546.387 -546.387 -546.387] (0.9950) ({r_i: None, r_t: [-1153.774 -1153.774 -1153.774], eps: 0.995})
Step:   11100, Reward: [-603.859 -603.859 -603.859] [139.072], Avg: [-546.901 -546.901 -546.901] (0.9950) ({r_i: None, r_t: [-1176.839 -1176.839 -1176.839], eps: 0.995})
Step:   11200, Reward: [-585.577 -585.577 -585.577] [158.134], Avg: [-547.243 -547.243 -547.243] (0.9950) ({r_i: None, r_t: [-1113.044 -1113.044 -1113.044], eps: 0.995})
Step:   11300, Reward: [-571.001 -571.001 -571.001] [123.813], Avg: [-547.451 -547.451 -547.451] (0.9950) ({r_i: None, r_t: [-1033.093 -1033.093 -1033.093], eps: 0.995})
Step:   11400, Reward: [-616.352 -616.352 -616.352] [132.936], Avg: [-548.050 -548.050 -548.050] (0.9950) ({r_i: None, r_t: [-1213.657 -1213.657 -1213.657], eps: 0.995})
Step:   11500, Reward: [-585.285 -585.285 -585.285] [123.813], Avg: [-548.371 -548.371 -548.371] (0.9950) ({r_i: None, r_t: [-1158.401 -1158.401 -1158.401], eps: 0.995})
Step:   11600, Reward: [-626.243 -626.243 -626.243] [129.974], Avg: [-549.037 -549.037 -549.037] (0.9950) ({r_i: None, r_t: [-1209.814 -1209.814 -1209.814], eps: 0.995})
Step:   11700, Reward: [-559.653 -559.653 -559.653] [106.027], Avg: [-549.127 -549.127 -549.127] (0.9950) ({r_i: None, r_t: [-1163.223 -1163.223 -1163.223], eps: 0.995})
Step:   11800, Reward: [-575.728 -575.728 -575.728] [114.454], Avg: [-549.350 -549.350 -549.350] (0.9950) ({r_i: None, r_t: [-1161.523 -1161.523 -1161.523], eps: 0.995})
Step:   11900, Reward: [-578.876 -578.876 -578.876] [171.945], Avg: [-549.596 -549.596 -549.596] (0.9950) ({r_i: None, r_t: [-1155.471 -1155.471 -1155.471], eps: 0.995})
Step:   12000, Reward: [-585.497 -585.497 -585.497] [128.318], Avg: [-549.893 -549.893 -549.893] (0.9950) ({r_i: None, r_t: [-1111.917 -1111.917 -1111.917], eps: 0.995})
Step:   12100, Reward: [-577.776 -577.776 -577.776] [131.784], Avg: [-550.122 -550.122 -550.122] (0.9950) ({r_i: None, r_t: [-1179.692 -1179.692 -1179.692], eps: 0.995})
Step:   12200, Reward: [-548.281 -548.281 -548.281] [108.263], Avg: [-550.107 -550.107 -550.107] (0.9950) ({r_i: None, r_t: [-1193.476 -1193.476 -1193.476], eps: 0.995})
Step:   12300, Reward: [-556.314 -556.314 -556.314] [193.645], Avg: [-550.157 -550.157 -550.157] (0.9950) ({r_i: None, r_t: [-1207.842 -1207.842 -1207.842], eps: 0.995})
Step:   12400, Reward: [-541.768 -541.768 -541.768] [102.785], Avg: [-550.090 -550.090 -550.090] (0.9950) ({r_i: None, r_t: [-1104.772 -1104.772 -1104.772], eps: 0.995})
Step:   12500, Reward: [-571.363 -571.363 -571.363] [117.050], Avg: [-550.258 -550.258 -550.258] (0.9950) ({r_i: None, r_t: [-1098.369 -1098.369 -1098.369], eps: 0.995})
Step:   12600, Reward: [-606.650 -606.650 -606.650] [114.426], Avg: [-550.703 -550.703 -550.703] (0.9950) ({r_i: None, r_t: [-1109.966 -1109.966 -1109.966], eps: 0.995})
Step:   12700, Reward: [-541.007 -541.007 -541.007] [119.785], Avg: [-550.627 -550.627 -550.627] (0.9950) ({r_i: None, r_t: [-1162.562 -1162.562 -1162.562], eps: 0.995})
Step:   12800, Reward: [-622.769 -622.769 -622.769] [171.521], Avg: [-551.186 -551.186 -551.186] (0.9950) ({r_i: None, r_t: [-1176.285 -1176.285 -1176.285], eps: 0.995})
Step:   12900, Reward: [-611.425 -611.425 -611.425] [145.575], Avg: [-551.649 -551.649 -551.649] (0.9950) ({r_i: None, r_t: [-1169.764 -1169.764 -1169.764], eps: 0.995})
Step:   13000, Reward: [-569.726 -569.726 -569.726] [103.660], Avg: [-551.787 -551.787 -551.787] (0.9950) ({r_i: None, r_t: [-1196.573 -1196.573 -1196.573], eps: 0.995})
Step:   13100, Reward: [-567.524 -567.524 -567.524] [112.993], Avg: [-551.907 -551.907 -551.907] (0.9950) ({r_i: None, r_t: [-1117.239 -1117.239 -1117.239], eps: 0.995})
Step:   13200, Reward: [-573.031 -573.031 -573.031] [96.455], Avg: [-552.065 -552.065 -552.065] (0.9950) ({r_i: None, r_t: [-1077.569 -1077.569 -1077.569], eps: 0.995})
Step:   13300, Reward: [-578.735 -578.735 -578.735] [158.729], Avg: [-552.264 -552.264 -552.264] (0.9950) ({r_i: None, r_t: [-1161.104 -1161.104 -1161.104], eps: 0.995})
Step:   13400, Reward: [-575.974 -575.974 -575.974] [147.222], Avg: [-552.440 -552.440 -552.440] (0.9950) ({r_i: None, r_t: [-1141.575 -1141.575 -1141.575], eps: 0.995})
Step:   13500, Reward: [-576.695 -576.695 -576.695] [124.823], Avg: [-552.618 -552.618 -552.618] (0.9950) ({r_i: None, r_t: [-1256.741 -1256.741 -1256.741], eps: 0.995})
Step:   13600, Reward: [-593.649 -593.649 -593.649] [121.025], Avg: [-552.918 -552.918 -552.918] (0.9950) ({r_i: None, r_t: [-1182.149 -1182.149 -1182.149], eps: 0.995})
Step:   13700, Reward: [-598.047 -598.047 -598.047] [130.871], Avg: [-553.245 -553.245 -553.245] (0.9950) ({r_i: None, r_t: [-1218.966 -1218.966 -1218.966], eps: 0.995})
Step:   13800, Reward: [-622.359 -622.359 -622.359] [198.593], Avg: [-553.742 -553.742 -553.742] (0.9950) ({r_i: None, r_t: [-1179.174 -1179.174 -1179.174], eps: 0.995})
Step:   13900, Reward: [-573.415 -573.415 -573.415] [97.906], Avg: [-553.883 -553.883 -553.883] (0.9950) ({r_i: None, r_t: [-1099.520 -1099.520 -1099.520], eps: 0.995})
Step:   14000, Reward: [-593.011 -593.011 -593.011] [102.074], Avg: [-554.160 -554.160 -554.160] (0.9950) ({r_i: None, r_t: [-1203.742 -1203.742 -1203.742], eps: 0.995})
Step:   14100, Reward: [-579.828 -579.828 -579.828] [133.857], Avg: [-554.341 -554.341 -554.341] (0.9950) ({r_i: None, r_t: [-1252.283 -1252.283 -1252.283], eps: 0.995})
Step:   14200, Reward: [-648.084 -648.084 -648.084] [152.615], Avg: [-554.997 -554.997 -554.997] (0.9950) ({r_i: None, r_t: [-1151.773 -1151.773 -1151.773], eps: 0.995})
Step:   14300, Reward: [-649.041 -649.041 -649.041] [135.600], Avg: [-555.650 -555.650 -555.650] (0.9950) ({r_i: None, r_t: [-1196.534 -1196.534 -1196.534], eps: 0.995})
Step:   14400, Reward: [-563.157 -563.157 -563.157] [162.403], Avg: [-555.701 -555.701 -555.701] (0.9950) ({r_i: None, r_t: [-1109.019 -1109.019 -1109.019], eps: 0.995})
Step:   14500, Reward: [-579.537 -579.537 -579.537] [106.481], Avg: [-555.865 -555.865 -555.865] (0.9950) ({r_i: None, r_t: [-1162.702 -1162.702 -1162.702], eps: 0.995})
Step:   14600, Reward: [-585.707 -585.707 -585.707] [142.036], Avg: [-556.068 -556.068 -556.068] (0.9950) ({r_i: None, r_t: [-1251.859 -1251.859 -1251.859], eps: 0.995})
Step:   14700, Reward: [-574.160 -574.160 -574.160] [130.725], Avg: [-556.190 -556.190 -556.190] (0.9950) ({r_i: None, r_t: [-1138.271 -1138.271 -1138.271], eps: 0.995})
Step:   14800, Reward: [-614.075 -614.075 -614.075] [175.657], Avg: [-556.578 -556.578 -556.578] (0.9950) ({r_i: None, r_t: [-1219.441 -1219.441 -1219.441], eps: 0.995})
Step:   14900, Reward: [-563.382 -563.382 -563.382] [134.344], Avg: [-556.624 -556.624 -556.624] (0.9950) ({r_i: None, r_t: [-1251.994 -1251.994 -1251.994], eps: 0.995})
Step:   15000, Reward: [-621.507 -621.507 -621.507] [167.053], Avg: [-557.053 -557.053 -557.053] (0.9950) ({r_i: None, r_t: [-1192.800 -1192.800 -1192.800], eps: 0.995})
Step:   15100, Reward: [-574.362 -574.362 -574.362] [90.313], Avg: [-557.167 -557.167 -557.167] (0.9950) ({r_i: None, r_t: [-1204.174 -1204.174 -1204.174], eps: 0.995})
Step:   15200, Reward: [-593.476 -593.476 -593.476] [118.131], Avg: [-557.405 -557.405 -557.405] (0.9950) ({r_i: None, r_t: [-1182.881 -1182.881 -1182.881], eps: 0.995})
Step:   15300, Reward: [-623.443 -623.443 -623.443] [134.433], Avg: [-557.833 -557.833 -557.833] (0.9950) ({r_i: None, r_t: [-1184.044 -1184.044 -1184.044], eps: 0.995})
Step:   15400, Reward: [-603.044 -603.044 -603.044] [164.699], Avg: [-558.125 -558.125 -558.125] (0.9950) ({r_i: None, r_t: [-1120.806 -1120.806 -1120.806], eps: 0.995})
Step:   15500, Reward: [-621.356 -621.356 -621.356] [134.464], Avg: [-558.530 -558.530 -558.530] (0.9950) ({r_i: None, r_t: [-1134.104 -1134.104 -1134.104], eps: 0.995})
Step:   15600, Reward: [-623.829 -623.829 -623.829] [132.099], Avg: [-558.946 -558.946 -558.946] (0.9950) ({r_i: None, r_t: [-1184.778 -1184.778 -1184.778], eps: 0.995})
Step:   15700, Reward: [-542.698 -542.698 -542.698] [114.925], Avg: [-558.844 -558.844 -558.844] (0.9950) ({r_i: None, r_t: [-1265.846 -1265.846 -1265.846], eps: 0.995})
Step:   15800, Reward: [-648.002 -648.002 -648.002] [144.716], Avg: [-559.404 -559.404 -559.404] (0.9950) ({r_i: None, r_t: [-1205.793 -1205.793 -1205.793], eps: 0.995})
Step:   15900, Reward: [-617.656 -617.656 -617.656] [113.193], Avg: [-559.768 -559.768 -559.768] (0.9950) ({r_i: None, r_t: [-1240.507 -1240.507 -1240.507], eps: 0.995})
Step:   16000, Reward: [-563.586 -563.586 -563.586] [115.271], Avg: [-559.792 -559.792 -559.792] (0.9950) ({r_i: None, r_t: [-1135.202 -1135.202 -1135.202], eps: 0.995})
Step:   16100, Reward: [-540.330 -540.330 -540.330] [97.337], Avg: [-559.672 -559.672 -559.672] (0.9950) ({r_i: None, r_t: [-1160.525 -1160.525 -1160.525], eps: 0.995})
Step:   16200, Reward: [-635.264 -635.264 -635.264] [134.644], Avg: [-560.136 -560.136 -560.136] (0.9950) ({r_i: None, r_t: [-1172.036 -1172.036 -1172.036], eps: 0.995})
Step:   16300, Reward: [-571.220 -571.220 -571.220] [115.189], Avg: [-560.203 -560.203 -560.203] (0.9950) ({r_i: None, r_t: [-1279.340 -1279.340 -1279.340], eps: 0.995})
Step:   16400, Reward: [-550.028 -550.028 -550.028] [89.137], Avg: [-560.142 -560.142 -560.142] (0.9950) ({r_i: None, r_t: [-1151.014 -1151.014 -1151.014], eps: 0.995})
Step:   16500, Reward: [-576.661 -576.661 -576.661] [139.513], Avg: [-560.241 -560.241 -560.241] (0.9950) ({r_i: None, r_t: [-1208.381 -1208.381 -1208.381], eps: 0.995})
Step:   16600, Reward: [-602.315 -602.315 -602.315] [158.214], Avg: [-560.493 -560.493 -560.493] (0.9950) ({r_i: None, r_t: [-1235.800 -1235.800 -1235.800], eps: 0.995})
Step:   16700, Reward: [-578.149 -578.149 -578.149] [136.811], Avg: [-560.598 -560.598 -560.598] (0.9950) ({r_i: None, r_t: [-1182.008 -1182.008 -1182.008], eps: 0.995})
Step:   16800, Reward: [-582.590 -582.590 -582.590] [130.640], Avg: [-560.728 -560.728 -560.728] (0.9950) ({r_i: None, r_t: [-1256.109 -1256.109 -1256.109], eps: 0.995})
Step:   16900, Reward: [-612.687 -612.687 -612.687] [168.655], Avg: [-561.034 -561.034 -561.034] (0.9950) ({r_i: None, r_t: [-1151.162 -1151.162 -1151.162], eps: 0.995})
Step:   17000, Reward: [-660.129 -660.129 -660.129] [157.333], Avg: [-561.613 -561.613 -561.613] (0.9950) ({r_i: None, r_t: [-1201.978 -1201.978 -1201.978], eps: 0.995})
Step:   17100, Reward: [-653.543 -653.543 -653.543] [186.698], Avg: [-562.148 -562.148 -562.148] (0.9950) ({r_i: None, r_t: [-1261.787 -1261.787 -1261.787], eps: 0.995})
Step:   17200, Reward: [-600.747 -600.747 -600.747] [164.443], Avg: [-562.371 -562.371 -562.371] (0.9950) ({r_i: None, r_t: [-1121.725 -1121.725 -1121.725], eps: 0.995})
Step:   17300, Reward: [-567.767 -567.767 -567.767] [120.113], Avg: [-562.402 -562.402 -562.402] (0.9950) ({r_i: None, r_t: [-1192.637 -1192.637 -1192.637], eps: 0.995})
Step:   17400, Reward: [-609.287 -609.287 -609.287] [153.278], Avg: [-562.670 -562.670 -562.670] (0.9950) ({r_i: None, r_t: [-1206.573 -1206.573 -1206.573], eps: 0.995})
Step:   17500, Reward: [-612.469 -612.469 -612.469] [112.909], Avg: [-562.953 -562.953 -562.953] (0.9950) ({r_i: None, r_t: [-1298.213 -1298.213 -1298.213], eps: 0.995})
Step:   17600, Reward: [-598.178 -598.178 -598.178] [105.149], Avg: [-563.152 -563.152 -563.152] (0.9950) ({r_i: None, r_t: [-1253.706 -1253.706 -1253.706], eps: 0.995})
Step:   17700, Reward: [-603.556 -603.556 -603.556] [126.134], Avg: [-563.379 -563.379 -563.379] (0.9950) ({r_i: None, r_t: [-1178.658 -1178.658 -1178.658], eps: 0.995})
Step:   17800, Reward: [-589.352 -589.352 -589.352] [132.307], Avg: [-563.524 -563.524 -563.524] (0.9950) ({r_i: None, r_t: [-1359.954 -1359.954 -1359.954], eps: 0.995})
Step:   17900, Reward: [-681.337 -681.337 -681.337] [128.496], Avg: [-564.179 -564.179 -564.179] (0.9950) ({r_i: None, r_t: [-1286.841 -1286.841 -1286.841], eps: 0.995})
Step:   18000, Reward: [-581.031 -581.031 -581.031] [139.069], Avg: [-564.272 -564.272 -564.272] (0.9950) ({r_i: None, r_t: [-1189.307 -1189.307 -1189.307], eps: 0.995})
Step:   18100, Reward: [-657.046 -657.046 -657.046] [149.954], Avg: [-564.781 -564.781 -564.781] (0.9950) ({r_i: None, r_t: [-1249.354 -1249.354 -1249.354], eps: 0.995})
Step:   18200, Reward: [-584.220 -584.220 -584.220] [136.106], Avg: [-564.888 -564.888 -564.888] (0.9950) ({r_i: None, r_t: [-1212.517 -1212.517 -1212.517], eps: 0.995})
Step:   18300, Reward: [-624.021 -624.021 -624.021] [125.813], Avg: [-565.209 -565.209 -565.209] (0.9950) ({r_i: None, r_t: [-1236.412 -1236.412 -1236.412], eps: 0.995})
Step:   18400, Reward: [-727.866 -727.866 -727.866] [112.107], Avg: [-566.088 -566.088 -566.088] (0.9950) ({r_i: None, r_t: [-1197.242 -1197.242 -1197.242], eps: 0.995})
Step:   18500, Reward: [-603.083 -603.083 -603.083] [142.119], Avg: [-566.287 -566.287 -566.287] (0.9950) ({r_i: None, r_t: [-1235.487 -1235.487 -1235.487], eps: 0.995})
Step:   18600, Reward: [-667.570 -667.570 -667.570] [113.153], Avg: [-566.829 -566.829 -566.829] (0.9950) ({r_i: None, r_t: [-1267.278 -1267.278 -1267.278], eps: 0.995})
Step:   18700, Reward: [-584.694 -584.694 -584.694] [139.575], Avg: [-566.924 -566.924 -566.924] (0.9950) ({r_i: None, r_t: [-1265.419 -1265.419 -1265.419], eps: 0.995})
Step:   18800, Reward: [-633.167 -633.167 -633.167] [155.014], Avg: [-567.274 -567.274 -567.274] (0.9950) ({r_i: None, r_t: [-1214.634 -1214.634 -1214.634], eps: 0.995})
Step:   18900, Reward: [-570.422 -570.422 -570.422] [84.436], Avg: [-567.291 -567.291 -567.291] (0.9950) ({r_i: None, r_t: [-1229.958 -1229.958 -1229.958], eps: 0.995})
Step:   19000, Reward: [-643.537 -643.537 -643.537] [137.071], Avg: [-567.690 -567.690 -567.690] (0.9950) ({r_i: None, r_t: [-1169.001 -1169.001 -1169.001], eps: 0.995})
Step:   19100, Reward: [-575.153 -575.153 -575.153] [179.366], Avg: [-567.729 -567.729 -567.729] (0.9950) ({r_i: None, r_t: [-1220.924 -1220.924 -1220.924], eps: 0.995})
Step:   19200, Reward: [-631.472 -631.472 -631.472] [176.665], Avg: [-568.059 -568.059 -568.059] (0.9950) ({r_i: None, r_t: [-1256.999 -1256.999 -1256.999], eps: 0.995})
Step:   19300, Reward: [-532.169 -532.169 -532.169] [78.054], Avg: [-567.874 -567.874 -567.874] (0.9950) ({r_i: None, r_t: [-1238.017 -1238.017 -1238.017], eps: 0.995})
Step:   19400, Reward: [-592.776 -592.776 -592.776] [109.209], Avg: [-568.002 -568.002 -568.002] (0.9950) ({r_i: None, r_t: [-1234.213 -1234.213 -1234.213], eps: 0.995})
Step:   19500, Reward: [-612.366 -612.366 -612.366] [103.274], Avg: [-568.228 -568.228 -568.228] (0.9950) ({r_i: None, r_t: [-1352.959 -1352.959 -1352.959], eps: 0.995})
Step:   19600, Reward: [-614.035 -614.035 -614.035] [149.341], Avg: [-568.461 -568.461 -568.461] (0.9950) ({r_i: None, r_t: [-1307.815 -1307.815 -1307.815], eps: 0.995})
Step:   19700, Reward: [-610.164 -610.164 -610.164] [118.156], Avg: [-568.671 -568.671 -568.671] (0.9950) ({r_i: None, r_t: [-1290.308 -1290.308 -1290.308], eps: 0.995})
Step:   19800, Reward: [-620.540 -620.540 -620.540] [156.180], Avg: [-568.932 -568.932 -568.932] (0.9950) ({r_i: None, r_t: [-1296.356 -1296.356 -1296.356], eps: 0.995})
Step:   19900, Reward: [-666.346 -666.346 -666.346] [156.461], Avg: [-569.419 -569.419 -569.419] (0.9950) ({r_i: None, r_t: [-1217.531 -1217.531 -1217.531], eps: 0.995})
Step:   20000, Reward: [-622.508 -622.508 -622.508] [121.805], Avg: [-569.683 -569.683 -569.683] (0.9950) ({r_i: None, r_t: [-1312.144 -1312.144 -1312.144], eps: 0.995})
Step:   20100, Reward: [-656.770 -656.770 -656.770] [150.530], Avg: [-570.114 -570.114 -570.114] (0.9900) ({r_i: None, r_t: [-1262.554 -1262.554 -1262.554], eps: 0.99})
Step:   20200, Reward: [-665.588 -665.588 -665.588] [126.090], Avg: [-570.585 -570.585 -570.585] (0.9900) ({r_i: None, r_t: [-1271.742 -1271.742 -1271.742], eps: 0.99})
Step:   20300, Reward: [-622.787 -622.787 -622.787] [194.640], Avg: [-570.841 -570.841 -570.841] (0.9900) ({r_i: None, r_t: [-1273.798 -1273.798 -1273.798], eps: 0.99})
Step:   20400, Reward: [-657.731 -657.731 -657.731] [160.031], Avg: [-571.264 -571.264 -571.264] (0.9900) ({r_i: None, r_t: [-1369.844 -1369.844 -1369.844], eps: 0.99})
Step:   20500, Reward: [-642.900 -642.900 -642.900] [130.320], Avg: [-571.612 -571.612 -571.612] (0.9900) ({r_i: None, r_t: [-1232.349 -1232.349 -1232.349], eps: 0.99})
Step:   20600, Reward: [-625.298 -625.298 -625.298] [142.362], Avg: [-571.871 -571.871 -571.871] (0.9900) ({r_i: None, r_t: [-1223.633 -1223.633 -1223.633], eps: 0.99})
Step:   20700, Reward: [-616.695 -616.695 -616.695] [115.661], Avg: [-572.087 -572.087 -572.087] (0.9900) ({r_i: None, r_t: [-1244.186 -1244.186 -1244.186], eps: 0.99})
Step:   20800, Reward: [-592.741 -592.741 -592.741] [103.701], Avg: [-572.186 -572.186 -572.186] (0.9900) ({r_i: None, r_t: [-1257.343 -1257.343 -1257.343], eps: 0.99})
Step:   20900, Reward: [-624.050 -624.050 -624.050] [130.681], Avg: [-572.433 -572.433 -572.433] (0.9900) ({r_i: None, r_t: [-1335.971 -1335.971 -1335.971], eps: 0.99})
Step:   21000, Reward: [-632.674 -632.674 -632.674] [124.638], Avg: [-572.718 -572.718 -572.718] (0.9900) ({r_i: None, r_t: [-1355.236 -1355.236 -1355.236], eps: 0.99})
Step:   21100, Reward: [-690.567 -690.567 -690.567] [172.963], Avg: [-573.274 -573.274 -573.274] (0.9900) ({r_i: None, r_t: [-1280.943 -1280.943 -1280.943], eps: 0.99})
Step:   21200, Reward: [-659.983 -659.983 -659.983] [170.434], Avg: [-573.681 -573.681 -573.681] (0.9900) ({r_i: None, r_t: [-1218.292 -1218.292 -1218.292], eps: 0.99})
Step:   21300, Reward: [-663.400 -663.400 -663.400] [166.019], Avg: [-574.100 -574.100 -574.100] (0.9900) ({r_i: None, r_t: [-1243.293 -1243.293 -1243.293], eps: 0.99})
Step:   21400, Reward: [-637.629 -637.629 -637.629] [146.827], Avg: [-574.396 -574.396 -574.396] (0.9900) ({r_i: None, r_t: [-1337.990 -1337.990 -1337.990], eps: 0.99})
Step:   21500, Reward: [-726.879 -726.879 -726.879] [136.248], Avg: [-575.102 -575.102 -575.102] (0.9900) ({r_i: None, r_t: [-1402.590 -1402.590 -1402.590], eps: 0.99})
Step:   21600, Reward: [-707.517 -707.517 -707.517] [162.345], Avg: [-575.712 -575.712 -575.712] (0.9900) ({r_i: None, r_t: [-1340.564 -1340.564 -1340.564], eps: 0.99})
Step:   21700, Reward: [-631.708 -631.708 -631.708] [115.239], Avg: [-575.969 -575.969 -575.969] (0.9900) ({r_i: None, r_t: [-1408.591 -1408.591 -1408.591], eps: 0.99})
Step:   21800, Reward: [-722.532 -722.532 -722.532] [198.191], Avg: [-576.638 -576.638 -576.638] (0.9900) ({r_i: None, r_t: [-1309.491 -1309.491 -1309.491], eps: 0.99})
Step:   21900, Reward: [-661.797 -661.797 -661.797] [177.545], Avg: [-577.025 -577.025 -577.025] (0.9900) ({r_i: None, r_t: [-1368.238 -1368.238 -1368.238], eps: 0.99})
Step:   22000, Reward: [-623.759 -623.759 -623.759] [97.619], Avg: [-577.237 -577.237 -577.237] (0.9900) ({r_i: None, r_t: [-1325.672 -1325.672 -1325.672], eps: 0.99})
Step:   22100, Reward: [-648.719 -648.719 -648.719] [185.506], Avg: [-577.559 -577.559 -577.559] (0.9900) ({r_i: None, r_t: [-1296.897 -1296.897 -1296.897], eps: 0.99})
Step:   22200, Reward: [-690.144 -690.144 -690.144] [141.838], Avg: [-578.064 -578.064 -578.064] (0.9900) ({r_i: None, r_t: [-1265.835 -1265.835 -1265.835], eps: 0.99})
Step:   22300, Reward: [-602.775 -602.775 -602.775] [124.960], Avg: [-578.174 -578.174 -578.174] (0.9900) ({r_i: None, r_t: [-1305.725 -1305.725 -1305.725], eps: 0.99})
Step:   22400, Reward: [-645.527 -645.527 -645.527] [143.468], Avg: [-578.473 -578.473 -578.473] (0.9900) ({r_i: None, r_t: [-1276.388 -1276.388 -1276.388], eps: 0.99})
Step:   22500, Reward: [-732.642 -732.642 -732.642] [146.874], Avg: [-579.155 -579.155 -579.155] (0.9900) ({r_i: None, r_t: [-1346.032 -1346.032 -1346.032], eps: 0.99})
Step:   22600, Reward: [-696.917 -696.917 -696.917] [204.389], Avg: [-579.674 -579.674 -579.674] (0.9900) ({r_i: None, r_t: [-1423.224 -1423.224 -1423.224], eps: 0.99})
Step:   22700, Reward: [-711.440 -711.440 -711.440] [146.067], Avg: [-580.252 -580.252 -580.252] (0.9900) ({r_i: None, r_t: [-1439.518 -1439.518 -1439.518], eps: 0.99})
Step:   22800, Reward: [-711.019 -711.019 -711.019] [142.145], Avg: [-580.823 -580.823 -580.823] (0.9900) ({r_i: None, r_t: [-1520.734 -1520.734 -1520.734], eps: 0.99})
Step:   22900, Reward: [-672.000 -672.000 -672.000] [179.753], Avg: [-581.220 -581.220 -581.220] (0.9900) ({r_i: None, r_t: [-1318.193 -1318.193 -1318.193], eps: 0.99})
Step:   23000, Reward: [-652.745 -652.745 -652.745] [206.859], Avg: [-581.529 -581.529 -581.529] (0.9900) ({r_i: None, r_t: [-1337.720 -1337.720 -1337.720], eps: 0.99})
Step:   23100, Reward: [-680.916 -680.916 -680.916] [176.968], Avg: [-581.958 -581.958 -581.958] (0.9900) ({r_i: None, r_t: [-1317.147 -1317.147 -1317.147], eps: 0.99})
Step:   23200, Reward: [-667.079 -667.079 -667.079] [171.758], Avg: [-582.323 -582.323 -582.323] (0.9900) ({r_i: None, r_t: [-1395.444 -1395.444 -1395.444], eps: 0.99})
Step:   23300, Reward: [-640.375 -640.375 -640.375] [104.393], Avg: [-582.571 -582.571 -582.571] (0.9900) ({r_i: None, r_t: [-1470.269 -1470.269 -1470.269], eps: 0.99})
Step:   23400, Reward: [-701.335 -701.335 -701.335] [150.455], Avg: [-583.076 -583.076 -583.076] (0.9900) ({r_i: None, r_t: [-1406.092 -1406.092 -1406.092], eps: 0.99})
Step:   23500, Reward: [-697.988 -697.988 -697.988] [164.984], Avg: [-583.563 -583.563 -583.563] (0.9900) ({r_i: None, r_t: [-1413.112 -1413.112 -1413.112], eps: 0.99})
Step:   23600, Reward: [-746.857 -746.857 -746.857] [247.016], Avg: [-584.252 -584.252 -584.252] (0.9900) ({r_i: None, r_t: [-1420.778 -1420.778 -1420.778], eps: 0.99})
Step:   23700, Reward: [-717.892 -717.892 -717.892] [131.381], Avg: [-584.814 -584.814 -584.814] (0.9900) ({r_i: None, r_t: [-1305.108 -1305.108 -1305.108], eps: 0.99})
Step:   23800, Reward: [-639.330 -639.330 -639.330] [206.600], Avg: [-585.042 -585.042 -585.042] (0.9900) ({r_i: None, r_t: [-1408.153 -1408.153 -1408.153], eps: 0.99})
Step:   23900, Reward: [-768.756 -768.756 -768.756] [168.077], Avg: [-585.807 -585.807 -585.807] (0.9900) ({r_i: None, r_t: [-1370.757 -1370.757 -1370.757], eps: 0.99})
Step:   24000, Reward: [-692.194 -692.194 -692.194] [185.472], Avg: [-586.249 -586.249 -586.249] (0.9900) ({r_i: None, r_t: [-1399.406 -1399.406 -1399.406], eps: 0.99})
Step:   24100, Reward: [-669.935 -669.935 -669.935] [161.217], Avg: [-586.595 -586.595 -586.595] (0.9900) ({r_i: None, r_t: [-1392.483 -1392.483 -1392.483], eps: 0.99})
Step:   24200, Reward: [-644.209 -644.209 -644.209] [153.146], Avg: [-586.832 -586.832 -586.832] (0.9900) ({r_i: None, r_t: [-1343.921 -1343.921 -1343.921], eps: 0.99})
Step:   24300, Reward: [-700.890 -700.890 -700.890] [133.500], Avg: [-587.299 -587.299 -587.299] (0.9900) ({r_i: None, r_t: [-1462.432 -1462.432 -1462.432], eps: 0.99})
Step:   24400, Reward: [-754.609 -754.609 -754.609] [173.956], Avg: [-587.982 -587.982 -587.982] (0.9900) ({r_i: None, r_t: [-1429.946 -1429.946 -1429.946], eps: 0.99})
Step:   24500, Reward: [-717.291 -717.291 -717.291] [148.686], Avg: [-588.508 -588.508 -588.508] (0.9900) ({r_i: None, r_t: [-1390.679 -1390.679 -1390.679], eps: 0.99})
Step:   24600, Reward: [-677.773 -677.773 -677.773] [188.977], Avg: [-588.869 -588.869 -588.869] (0.9900) ({r_i: None, r_t: [-1568.519 -1568.519 -1568.519], eps: 0.99})
Step:   24700, Reward: [-704.551 -704.551 -704.551] [207.843], Avg: [-589.336 -589.336 -589.336] (0.9900) ({r_i: None, r_t: [-1546.484 -1546.484 -1546.484], eps: 0.99})
Step:   24800, Reward: [-696.878 -696.878 -696.878] [122.576], Avg: [-589.768 -589.768 -589.768] (0.9900) ({r_i: None, r_t: [-1464.231 -1464.231 -1464.231], eps: 0.99})
Step:   24900, Reward: [-772.668 -772.668 -772.668] [215.170], Avg: [-590.499 -590.499 -590.499] (0.9900) ({r_i: None, r_t: [-1357.032 -1357.032 -1357.032], eps: 0.99})
Step:   25000, Reward: [-771.109 -771.109 -771.109] [193.318], Avg: [-591.219 -591.219 -591.219] (0.9900) ({r_i: None, r_t: [-1440.061 -1440.061 -1440.061], eps: 0.99})
Step:   25100, Reward: [-750.848 -750.848 -750.848] [195.309], Avg: [-591.852 -591.852 -591.852] (0.9900) ({r_i: None, r_t: [-1481.900 -1481.900 -1481.900], eps: 0.99})
Step:   25200, Reward: [-772.060 -772.060 -772.060] [159.833], Avg: [-592.564 -592.564 -592.564] (0.9900) ({r_i: None, r_t: [-1433.984 -1433.984 -1433.984], eps: 0.99})
Step:   25300, Reward: [-657.334 -657.334 -657.334] [208.005], Avg: [-592.819 -592.819 -592.819] (0.9900) ({r_i: None, r_t: [-1302.005 -1302.005 -1302.005], eps: 0.99})
Step:   25400, Reward: [-750.336 -750.336 -750.336] [137.277], Avg: [-593.437 -593.437 -593.437] (0.9900) ({r_i: None, r_t: [-1379.176 -1379.176 -1379.176], eps: 0.99})
Step:   25500, Reward: [-742.835 -742.835 -742.835] [166.225], Avg: [-594.021 -594.021 -594.021] (0.9900) ({r_i: None, r_t: [-1339.517 -1339.517 -1339.517], eps: 0.99})
Step:   25600, Reward: [-743.614 -743.614 -743.614] [184.502], Avg: [-594.603 -594.603 -594.603] (0.9900) ({r_i: None, r_t: [-1424.605 -1424.605 -1424.605], eps: 0.99})
Step:   25700, Reward: [-677.749 -677.749 -677.749] [120.855], Avg: [-594.925 -594.925 -594.925] (0.9900) ({r_i: None, r_t: [-1618.505 -1618.505 -1618.505], eps: 0.99})
Step:   25800, Reward: [-666.397 -666.397 -666.397] [160.823], Avg: [-595.201 -595.201 -595.201] (0.9900) ({r_i: None, r_t: [-1456.432 -1456.432 -1456.432], eps: 0.99})
Step:   25900, Reward: [-696.944 -696.944 -696.944] [158.442], Avg: [-595.592 -595.592 -595.592] (0.9900) ({r_i: None, r_t: [-1408.053 -1408.053 -1408.053], eps: 0.99})
Step:   26000, Reward: [-763.569 -763.569 -763.569] [131.982], Avg: [-596.236 -596.236 -596.236] (0.9900) ({r_i: None, r_t: [-1430.398 -1430.398 -1430.398], eps: 0.99})
Step:   26100, Reward: [-696.653 -696.653 -696.653] [133.051], Avg: [-596.619 -596.619 -596.619] (0.9900) ({r_i: None, r_t: [-1574.186 -1574.186 -1574.186], eps: 0.99})
Step:   26200, Reward: [-656.595 -656.595 -656.595] [152.609], Avg: [-596.847 -596.847 -596.847] (0.9900) ({r_i: None, r_t: [-1515.126 -1515.126 -1515.126], eps: 0.99})
Step:   26300, Reward: [-738.992 -738.992 -738.992] [178.973], Avg: [-597.386 -597.386 -597.386] (0.9900) ({r_i: None, r_t: [-1544.520 -1544.520 -1544.520], eps: 0.99})
Step:   26400, Reward: [-744.048 -744.048 -744.048] [142.951], Avg: [-597.939 -597.939 -597.939] (0.9900) ({r_i: None, r_t: [-1474.149 -1474.149 -1474.149], eps: 0.99})
Step:   26500, Reward: [-717.147 -717.147 -717.147] [160.472], Avg: [-598.387 -598.387 -598.387] (0.9900) ({r_i: None, r_t: [-1617.730 -1617.730 -1617.730], eps: 0.99})
Step:   26600, Reward: [-679.542 -679.542 -679.542] [156.964], Avg: [-598.691 -598.691 -598.691] (0.9900) ({r_i: None, r_t: [-1515.719 -1515.719 -1515.719], eps: 0.99})
Step:   26700, Reward: [-739.609 -739.609 -739.609] [162.739], Avg: [-599.217 -599.217 -599.217] (0.9900) ({r_i: None, r_t: [-1541.493 -1541.493 -1541.493], eps: 0.99})
Step:   26800, Reward: [-666.872 -666.872 -666.872] [161.385], Avg: [-599.469 -599.469 -599.469] (0.9900) ({r_i: None, r_t: [-1411.611 -1411.611 -1411.611], eps: 0.99})
Step:   26900, Reward: [-750.078 -750.078 -750.078] [168.200], Avg: [-600.026 -600.026 -600.026] (0.9900) ({r_i: None, r_t: [-1527.149 -1527.149 -1527.149], eps: 0.99})
Step:   27000, Reward: [-782.241 -782.241 -782.241] [148.152], Avg: [-600.699 -600.699 -600.699] (0.9900) ({r_i: None, r_t: [-1462.784 -1462.784 -1462.784], eps: 0.99})
Step:   27100, Reward: [-743.505 -743.505 -743.505] [157.619], Avg: [-601.224 -601.224 -601.224] (0.9900) ({r_i: None, r_t: [-1335.528 -1335.528 -1335.528], eps: 0.99})
Step:   27200, Reward: [-798.358 -798.358 -798.358] [158.737], Avg: [-601.946 -601.946 -601.946] (0.9900) ({r_i: None, r_t: [-1463.652 -1463.652 -1463.652], eps: 0.99})
Step:   27300, Reward: [-690.341 -690.341 -690.341] [165.108], Avg: [-602.268 -602.268 -602.268] (0.9900) ({r_i: None, r_t: [-1489.977 -1489.977 -1489.977], eps: 0.99})
Step:   27400, Reward: [-795.786 -795.786 -795.786] [172.250], Avg: [-602.972 -602.972 -602.972] (0.9900) ({r_i: None, r_t: [-1563.313 -1563.313 -1563.313], eps: 0.99})
Step:   27500, Reward: [-802.134 -802.134 -802.134] [134.017], Avg: [-603.694 -603.694 -603.694] (0.9900) ({r_i: None, r_t: [-1633.233 -1633.233 -1633.233], eps: 0.99})
Step:   27600, Reward: [-789.888 -789.888 -789.888] [226.902], Avg: [-604.366 -604.366 -604.366] (0.9900) ({r_i: None, r_t: [-1406.012 -1406.012 -1406.012], eps: 0.99})
Step:   27700, Reward: [-807.311 -807.311 -807.311] [180.964], Avg: [-605.096 -605.096 -605.096] (0.9900) ({r_i: None, r_t: [-1502.701 -1502.701 -1502.701], eps: 0.99})
Step:   27800, Reward: [-831.847 -831.847 -831.847] [193.001], Avg: [-605.909 -605.909 -605.909] (0.9900) ({r_i: None, r_t: [-1693.735 -1693.735 -1693.735], eps: 0.99})
Step:   27900, Reward: [-744.588 -744.588 -744.588] [171.738], Avg: [-606.404 -606.404 -606.404] (0.9900) ({r_i: None, r_t: [-1597.791 -1597.791 -1597.791], eps: 0.99})
Step:   28000, Reward: [-726.588 -726.588 -726.588] [174.688], Avg: [-606.832 -606.832 -606.832] (0.9900) ({r_i: None, r_t: [-1525.678 -1525.678 -1525.678], eps: 0.99})
Step:   28100, Reward: [-803.538 -803.538 -803.538] [213.390], Avg: [-607.529 -607.529 -607.529] (0.9900) ({r_i: None, r_t: [-1538.499 -1538.499 -1538.499], eps: 0.99})
Step:   28200, Reward: [-763.174 -763.174 -763.174] [172.643], Avg: [-608.079 -608.079 -608.079] (0.9900) ({r_i: None, r_t: [-1529.340 -1529.340 -1529.340], eps: 0.99})
Step:   28300, Reward: [-753.901 -753.901 -753.901] [158.280], Avg: [-608.593 -608.593 -608.593] (0.9900) ({r_i: None, r_t: [-1587.665 -1587.665 -1587.665], eps: 0.99})
Step:   28400, Reward: [-842.537 -842.537 -842.537] [174.608], Avg: [-609.414 -609.414 -609.414] (0.9900) ({r_i: None, r_t: [-1549.653 -1549.653 -1549.653], eps: 0.99})
Step:   28500, Reward: [-843.248 -843.248 -843.248] [193.186], Avg: [-610.231 -610.231 -610.231] (0.9900) ({r_i: None, r_t: [-1549.878 -1549.878 -1549.878], eps: 0.99})
Step:   28600, Reward: [-833.424 -833.424 -833.424] [211.028], Avg: [-611.009 -611.009 -611.009] (0.9900) ({r_i: None, r_t: [-1492.200 -1492.200 -1492.200], eps: 0.99})
Step:   28700, Reward: [-802.238 -802.238 -802.238] [203.458], Avg: [-611.673 -611.673 -611.673] (0.9900) ({r_i: None, r_t: [-1653.336 -1653.336 -1653.336], eps: 0.99})
Step:   28800, Reward: [-749.802 -749.802 -749.802] [164.644], Avg: [-612.151 -612.151 -612.151] (0.9900) ({r_i: None, r_t: [-1550.480 -1550.480 -1550.480], eps: 0.99})
Step:   28900, Reward: [-794.162 -794.162 -794.162] [177.750], Avg: [-612.778 -612.778 -612.778] (0.9900) ({r_i: None, r_t: [-1546.093 -1546.093 -1546.093], eps: 0.99})
Step:   29000, Reward: [-834.814 -834.814 -834.814] [264.713], Avg: [-613.541 -613.541 -613.541] (0.9900) ({r_i: None, r_t: [-1631.140 -1631.140 -1631.140], eps: 0.99})
Step:   29100, Reward: [-747.205 -747.205 -747.205] [180.655], Avg: [-613.999 -613.999 -613.999] (0.9900) ({r_i: None, r_t: [-1675.111 -1675.111 -1675.111], eps: 0.99})
Step:   29200, Reward: [-921.860 -921.860 -921.860] [224.233], Avg: [-615.050 -615.050 -615.050] (0.9900) ({r_i: None, r_t: [-1525.225 -1525.225 -1525.225], eps: 0.99})
Step:   29300, Reward: [-786.007 -786.007 -786.007] [149.079], Avg: [-615.631 -615.631 -615.631] (0.9900) ({r_i: None, r_t: [-1614.280 -1614.280 -1614.280], eps: 0.99})
Step:   29400, Reward: [-838.959 -838.959 -838.959] [208.480], Avg: [-616.388 -616.388 -616.388] (0.9900) ({r_i: None, r_t: [-1735.917 -1735.917 -1735.917], eps: 0.99})
Step:   29500, Reward: [-884.248 -884.248 -884.248] [250.962], Avg: [-617.293 -617.293 -617.293] (0.9900) ({r_i: None, r_t: [-1666.069 -1666.069 -1666.069], eps: 0.99})
Step:   29600, Reward: [-861.767 -861.767 -861.767] [222.376], Avg: [-618.116 -618.116 -618.116] (0.9900) ({r_i: None, r_t: [-1538.830 -1538.830 -1538.830], eps: 0.99})
Step:   29700, Reward: [-864.326 -864.326 -864.326] [193.832], Avg: [-618.943 -618.943 -618.943] (0.9900) ({r_i: None, r_t: [-1688.935 -1688.935 -1688.935], eps: 0.99})
Step:   29800, Reward: [-819.077 -819.077 -819.077] [261.639], Avg: [-619.612 -619.612 -619.612] (0.9900) ({r_i: None, r_t: [-1703.448 -1703.448 -1703.448], eps: 0.99})
Step:   29900, Reward: [-790.668 -790.668 -790.668] [194.661], Avg: [-620.182 -620.182 -620.182] (0.9900) ({r_i: None, r_t: [-1633.228 -1633.228 -1633.228], eps: 0.99})
Step:   30000, Reward: [-879.085 -879.085 -879.085] [236.768], Avg: [-621.042 -621.042 -621.042] (0.9900) ({r_i: None, r_t: [-1592.265 -1592.265 -1592.265], eps: 0.99})
Step:   30100, Reward: [-872.983 -872.983 -872.983] [218.445], Avg: [-621.877 -621.877 -621.877] (0.9900) ({r_i: None, r_t: [-1571.395 -1571.395 -1571.395], eps: 0.99})
Step:   30200, Reward: [-903.679 -903.679 -903.679] [177.369], Avg: [-622.807 -622.807 -622.807] (0.9900) ({r_i: None, r_t: [-1769.063 -1769.063 -1769.063], eps: 0.99})
Step:   30300, Reward: [-780.788 -780.788 -780.788] [185.478], Avg: [-623.326 -623.326 -623.326] (0.9900) ({r_i: None, r_t: [-1646.108 -1646.108 -1646.108], eps: 0.99})
Step:   30400, Reward: [-898.291 -898.291 -898.291] [190.487], Avg: [-624.228 -624.228 -624.228] (0.9900) ({r_i: None, r_t: [-1698.675 -1698.675 -1698.675], eps: 0.99})
Step:   30500, Reward: [-779.174 -779.174 -779.174] [195.531], Avg: [-624.734 -624.734 -624.734] (0.9900) ({r_i: None, r_t: [-1761.392 -1761.392 -1761.392], eps: 0.99})
Step:   30600, Reward: [-832.526 -832.526 -832.526] [239.635], Avg: [-625.411 -625.411 -625.411] (0.9900) ({r_i: None, r_t: [-1763.825 -1763.825 -1763.825], eps: 0.99})
Step:   30700, Reward: [-786.499 -786.499 -786.499] [142.260], Avg: [-625.934 -625.934 -625.934] (0.9900) ({r_i: None, r_t: [-1557.192 -1557.192 -1557.192], eps: 0.99})
Step:   30800, Reward: [-924.976 -924.976 -924.976] [233.342], Avg: [-626.902 -626.902 -626.902] (0.9900) ({r_i: None, r_t: [-1698.903 -1698.903 -1698.903], eps: 0.99})
Step:   30900, Reward: [-811.973 -811.973 -811.973] [219.017], Avg: [-627.499 -627.499 -627.499] (0.9900) ({r_i: None, r_t: [-1643.145 -1643.145 -1643.145], eps: 0.99})
Step:   31000, Reward: [-911.436 -911.436 -911.436] [235.551], Avg: [-628.412 -628.412 -628.412] (0.9900) ({r_i: None, r_t: [-1727.287 -1727.287 -1727.287], eps: 0.99})
Step:   31100, Reward: [-808.010 -808.010 -808.010] [196.852], Avg: [-628.987 -628.987 -628.987] (0.9900) ({r_i: None, r_t: [-1653.073 -1653.073 -1653.073], eps: 0.99})
Step:   31200, Reward: [-744.658 -744.658 -744.658] [192.651], Avg: [-629.357 -629.357 -629.357] (0.9900) ({r_i: None, r_t: [-1723.633 -1723.633 -1723.633], eps: 0.99})
Step:   31300, Reward: [-749.269 -749.269 -749.269] [164.423], Avg: [-629.739 -629.739 -629.739] (0.9900) ({r_i: None, r_t: [-1752.018 -1752.018 -1752.018], eps: 0.99})
Step:   31400, Reward: [-911.281 -911.281 -911.281] [243.114], Avg: [-630.633 -630.633 -630.633] (0.9900) ({r_i: None, r_t: [-1670.727 -1670.727 -1670.727], eps: 0.99})
Step:   31500, Reward: [-800.048 -800.048 -800.048] [126.471], Avg: [-631.169 -631.169 -631.169] (0.9900) ({r_i: None, r_t: [-1769.972 -1769.972 -1769.972], eps: 0.99})
Step:   31600, Reward: [-869.757 -869.757 -869.757] [223.294], Avg: [-631.921 -631.921 -631.921] (0.9900) ({r_i: None, r_t: [-1814.302 -1814.302 -1814.302], eps: 0.99})
Step:   31700, Reward: [-961.723 -961.723 -961.723] [299.713], Avg: [-632.959 -632.959 -632.959] (0.9900) ({r_i: None, r_t: [-1692.493 -1692.493 -1692.493], eps: 0.99})
Step:   31800, Reward: [-852.926 -852.926 -852.926] [165.007], Avg: [-633.648 -633.648 -633.648] (0.9900) ({r_i: None, r_t: [-1690.317 -1690.317 -1690.317], eps: 0.99})
Step:   31900, Reward: [-865.737 -865.737 -865.737] [176.616], Avg: [-634.373 -634.373 -634.373] (0.9900) ({r_i: None, r_t: [-1554.931 -1554.931 -1554.931], eps: 0.99})
Step:   32000, Reward: [-945.293 -945.293 -945.293] [213.785], Avg: [-635.342 -635.342 -635.342] (0.9900) ({r_i: None, r_t: [-1681.696 -1681.696 -1681.696], eps: 0.99})
Step:   32100, Reward: [-883.536 -883.536 -883.536] [189.316], Avg: [-636.113 -636.113 -636.113] (0.9900) ({r_i: None, r_t: [-1707.855 -1707.855 -1707.855], eps: 0.99})
Step:   32200, Reward: [-908.506 -908.506 -908.506] [183.081], Avg: [-636.956 -636.956 -636.956] (0.9900) ({r_i: None, r_t: [-1760.646 -1760.646 -1760.646], eps: 0.99})
Step:   32300, Reward: [-840.388 -840.388 -840.388] [214.479], Avg: [-637.584 -637.584 -637.584] (0.9900) ({r_i: None, r_t: [-1746.662 -1746.662 -1746.662], eps: 0.99})
Step:   32400, Reward: [-827.131 -827.131 -827.131] [232.101], Avg: [-638.167 -638.167 -638.167] (0.9900) ({r_i: None, r_t: [-1739.307 -1739.307 -1739.307], eps: 0.99})
Step:   32500, Reward: [-762.162 -762.162 -762.162] [298.284], Avg: [-638.548 -638.548 -638.548] (0.9900) ({r_i: None, r_t: [-1695.157 -1695.157 -1695.157], eps: 0.99})
Step:   32600, Reward: [-949.460 -949.460 -949.460] [268.427], Avg: [-639.498 -639.498 -639.498] (0.9851) ({r_i: None, r_t: [-1688.177 -1688.177 -1688.177], eps: 0.985})
Step:   32700, Reward: [-860.261 -860.261 -860.261] [170.398], Avg: [-640.171 -640.171 -640.171] (0.9851) ({r_i: None, r_t: [-1750.264 -1750.264 -1750.264], eps: 0.985})
Step:   32800, Reward: [-891.061 -891.061 -891.061] [256.342], Avg: [-640.934 -640.934 -640.934] (0.9851) ({r_i: None, r_t: [-1706.724 -1706.724 -1706.724], eps: 0.985})
Step:   32900, Reward: [-840.189 -840.189 -840.189] [174.219], Avg: [-641.538 -641.538 -641.538] (0.9851) ({r_i: None, r_t: [-1664.902 -1664.902 -1664.902], eps: 0.985})
Step:   33000, Reward: [-817.991 -817.991 -817.991] [220.972], Avg: [-642.071 -642.071 -642.071] (0.9851) ({r_i: None, r_t: [-1752.322 -1752.322 -1752.322], eps: 0.985})
Step:   33100, Reward: [-1039.189 -1039.189 -1039.189] [302.266], Avg: [-643.267 -643.267 -643.267] (0.9851) ({r_i: None, r_t: [-1793.200 -1793.200 -1793.200], eps: 0.985})
Step:   33200, Reward: [-866.594 -866.594 -866.594] [184.728], Avg: [-643.938 -643.938 -643.938] (0.9851) ({r_i: None, r_t: [-1815.076 -1815.076 -1815.076], eps: 0.985})
Step:   33300, Reward: [-972.883 -972.883 -972.883] [241.186], Avg: [-644.923 -644.923 -644.923] (0.9851) ({r_i: None, r_t: [-1940.325 -1940.325 -1940.325], eps: 0.985})
Step:   33400, Reward: [-944.310 -944.310 -944.310] [283.947], Avg: [-645.816 -645.816 -645.816] (0.9851) ({r_i: None, r_t: [-1918.609 -1918.609 -1918.609], eps: 0.985})
Step:   33500, Reward: [-897.039 -897.039 -897.039] [251.715], Avg: [-646.564 -646.564 -646.564] (0.9851) ({r_i: None, r_t: [-1741.644 -1741.644 -1741.644], eps: 0.985})
Step:   33600, Reward: [-948.465 -948.465 -948.465] [194.217], Avg: [-647.460 -647.460 -647.460] (0.9851) ({r_i: None, r_t: [-1824.388 -1824.388 -1824.388], eps: 0.985})
Step:   33700, Reward: [-951.439 -951.439 -951.439] [309.466], Avg: [-648.359 -648.359 -648.359] (0.9851) ({r_i: None, r_t: [-1828.736 -1828.736 -1828.736], eps: 0.985})
Step:   33800, Reward: [-895.459 -895.459 -895.459] [296.670], Avg: [-649.088 -649.088 -649.088] (0.9851) ({r_i: None, r_t: [-1886.804 -1886.804 -1886.804], eps: 0.985})
Step:   33900, Reward: [-882.883 -882.883 -882.883] [193.982], Avg: [-649.776 -649.776 -649.776] (0.9851) ({r_i: None, r_t: [-1656.185 -1656.185 -1656.185], eps: 0.985})
Step:   34000, Reward: [-1004.506 -1004.506 -1004.506] [256.663], Avg: [-650.816 -650.816 -650.816] (0.9851) ({r_i: None, r_t: [-1803.781 -1803.781 -1803.781], eps: 0.985})
Step:   34100, Reward: [-895.000 -895.000 -895.000] [279.640], Avg: [-651.530 -651.530 -651.530] (0.9851) ({r_i: None, r_t: [-1829.352 -1829.352 -1829.352], eps: 0.985})
Step:   34200, Reward: [-830.633 -830.633 -830.633] [175.270], Avg: [-652.052 -652.052 -652.052] (0.9851) ({r_i: None, r_t: [-1741.065 -1741.065 -1741.065], eps: 0.985})
Step:   34300, Reward: [-1061.420 -1061.420 -1061.420] [240.087], Avg: [-653.242 -653.242 -653.242] (0.9851) ({r_i: None, r_t: [-1832.678 -1832.678 -1832.678], eps: 0.985})
Step:   34400, Reward: [-866.628 -866.628 -866.628] [236.109], Avg: [-653.861 -653.861 -653.861] (0.9851) ({r_i: None, r_t: [-1722.660 -1722.660 -1722.660], eps: 0.985})
Step:   34500, Reward: [-956.165 -956.165 -956.165] [210.298], Avg: [-654.734 -654.734 -654.734] (0.9851) ({r_i: None, r_t: [-1730.520 -1730.520 -1730.520], eps: 0.985})
Step:   34600, Reward: [-936.027 -936.027 -936.027] [244.248], Avg: [-655.545 -655.545 -655.545] (0.9851) ({r_i: None, r_t: [-1906.282 -1906.282 -1906.282], eps: 0.985})
Step:   34700, Reward: [-833.653 -833.653 -833.653] [175.519], Avg: [-656.057 -656.057 -656.057] (0.9851) ({r_i: None, r_t: [-1729.130 -1729.130 -1729.130], eps: 0.985})
Step:   34800, Reward: [-937.219 -937.219 -937.219] [253.350], Avg: [-656.862 -656.862 -656.862] (0.9851) ({r_i: None, r_t: [-1729.878 -1729.878 -1729.878], eps: 0.985})
Step:   34900, Reward: [-987.795 -987.795 -987.795] [254.276], Avg: [-657.808 -657.808 -657.808] (0.9851) ({r_i: None, r_t: [-1863.735 -1863.735 -1863.735], eps: 0.985})
Step:   35000, Reward: [-893.921 -893.921 -893.921] [170.588], Avg: [-658.481 -658.481 -658.481] (0.9851) ({r_i: None, r_t: [-1662.061 -1662.061 -1662.061], eps: 0.985})
Step:   35100, Reward: [-921.504 -921.504 -921.504] [234.828], Avg: [-659.228 -659.228 -659.228] (0.9851) ({r_i: None, r_t: [-1878.671 -1878.671 -1878.671], eps: 0.985})
Step:   35200, Reward: [-950.991 -950.991 -950.991] [247.447], Avg: [-660.054 -660.054 -660.054] (0.9851) ({r_i: None, r_t: [-1857.870 -1857.870 -1857.870], eps: 0.985})
Step:   35300, Reward: [-896.082 -896.082 -896.082] [240.928], Avg: [-660.721 -660.721 -660.721] (0.9851) ({r_i: None, r_t: [-1803.083 -1803.083 -1803.083], eps: 0.985})
Step:   35400, Reward: [-913.600 -913.600 -913.600] [219.391], Avg: [-661.433 -661.433 -661.433] (0.9851) ({r_i: None, r_t: [-1906.817 -1906.817 -1906.817], eps: 0.985})
Step:   35500, Reward: [-936.001 -936.001 -936.001] [229.770], Avg: [-662.205 -662.205 -662.205] (0.9851) ({r_i: None, r_t: [-1869.755 -1869.755 -1869.755], eps: 0.985})
Step:   35600, Reward: [-960.154 -960.154 -960.154] [153.929], Avg: [-663.039 -663.039 -663.039] (0.9851) ({r_i: None, r_t: [-1765.627 -1765.627 -1765.627], eps: 0.985})
Step:   35700, Reward: [-995.507 -995.507 -995.507] [305.062], Avg: [-663.968 -663.968 -663.968] (0.9851) ({r_i: None, r_t: [-1875.947 -1875.947 -1875.947], eps: 0.985})
Step:   35800, Reward: [-939.607 -939.607 -939.607] [274.777], Avg: [-664.736 -664.736 -664.736] (0.9851) ({r_i: None, r_t: [-1763.638 -1763.638 -1763.638], eps: 0.985})
Step:   35900, Reward: [-822.735 -822.735 -822.735] [173.490], Avg: [-665.175 -665.175 -665.175] (0.9851) ({r_i: None, r_t: [-2059.820 -2059.820 -2059.820], eps: 0.985})
Step:   36000, Reward: [-897.871 -897.871 -897.871] [261.406], Avg: [-665.819 -665.819 -665.819] (0.9851) ({r_i: None, r_t: [-1919.399 -1919.399 -1919.399], eps: 0.985})
Step:   36100, Reward: [-986.687 -986.687 -986.687] [246.959], Avg: [-666.706 -666.706 -666.706] (0.9851) ({r_i: None, r_t: [-1966.930 -1966.930 -1966.930], eps: 0.985})
Step:   36200, Reward: [-1018.250 -1018.250 -1018.250] [268.034], Avg: [-667.674 -667.674 -667.674] (0.9851) ({r_i: None, r_t: [-1886.529 -1886.529 -1886.529], eps: 0.985})
Step:   36300, Reward: [-983.490 -983.490 -983.490] [299.817], Avg: [-668.542 -668.542 -668.542] (0.9851) ({r_i: None, r_t: [-1875.059 -1875.059 -1875.059], eps: 0.985})
Step:   36400, Reward: [-1092.794 -1092.794 -1092.794] [319.526], Avg: [-669.704 -669.704 -669.704] (0.9851) ({r_i: None, r_t: [-2023.795 -2023.795 -2023.795], eps: 0.985})
Step:   36500, Reward: [-885.004 -885.004 -885.004] [201.488], Avg: [-670.292 -670.292 -670.292] (0.9851) ({r_i: None, r_t: [-1896.213 -1896.213 -1896.213], eps: 0.985})
Step:   36600, Reward: [-1060.095 -1060.095 -1060.095] [265.640], Avg: [-671.354 -671.354 -671.354] (0.9851) ({r_i: None, r_t: [-1880.509 -1880.509 -1880.509], eps: 0.985})
Step:   36700, Reward: [-1021.090 -1021.090 -1021.090] [286.891], Avg: [-672.305 -672.305 -672.305] (0.9851) ({r_i: None, r_t: [-2061.409 -2061.409 -2061.409], eps: 0.985})
Step:   36800, Reward: [-855.076 -855.076 -855.076] [188.394], Avg: [-672.800 -672.800 -672.800] (0.9851) ({r_i: None, r_t: [-1848.340 -1848.340 -1848.340], eps: 0.985})
Step:   36900, Reward: [-890.645 -890.645 -890.645] [225.756], Avg: [-673.389 -673.389 -673.389] (0.9851) ({r_i: None, r_t: [-2089.891 -2089.891 -2089.891], eps: 0.985})
Step:   37000, Reward: [-930.338 -930.338 -930.338] [201.759], Avg: [-674.081 -674.081 -674.081] (0.9851) ({r_i: None, r_t: [-1859.654 -1859.654 -1859.654], eps: 0.985})
Step:   37100, Reward: [-989.913 -989.913 -989.913] [298.864], Avg: [-674.930 -674.930 -674.930] (0.9851) ({r_i: None, r_t: [-1909.465 -1909.465 -1909.465], eps: 0.985})
Step:   37200, Reward: [-1056.247 -1056.247 -1056.247] [248.605], Avg: [-675.953 -675.953 -675.953] (0.9851) ({r_i: None, r_t: [-1966.123 -1966.123 -1966.123], eps: 0.985})
Step:   37300, Reward: [-993.445 -993.445 -993.445] [316.869], Avg: [-676.802 -676.802 -676.802] (0.9851) ({r_i: None, r_t: [-2071.432 -2071.432 -2071.432], eps: 0.985})
Step:   37400, Reward: [-895.119 -895.119 -895.119] [193.497], Avg: [-677.384 -677.384 -677.384] (0.9851) ({r_i: None, r_t: [-1877.899 -1877.899 -1877.899], eps: 0.985})
Step:   37500, Reward: [-1009.518 -1009.518 -1009.518] [186.692], Avg: [-678.267 -678.267 -678.267] (0.9851) ({r_i: None, r_t: [-2047.970 -2047.970 -2047.970], eps: 0.985})
Step:   37600, Reward: [-1048.669 -1048.669 -1048.669] [335.464], Avg: [-679.250 -679.250 -679.250] (0.9851) ({r_i: None, r_t: [-1965.978 -1965.978 -1965.978], eps: 0.985})
Step:   37700, Reward: [-1004.455 -1004.455 -1004.455] [229.496], Avg: [-680.110 -680.110 -680.110] (0.9851) ({r_i: None, r_t: [-1913.831 -1913.831 -1913.831], eps: 0.985})
Step:   37800, Reward: [-970.194 -970.194 -970.194] [256.671], Avg: [-680.875 -680.875 -680.875] (0.9851) ({r_i: None, r_t: [-1873.279 -1873.279 -1873.279], eps: 0.985})
Step:   37900, Reward: [-1052.127 -1052.127 -1052.127] [323.041], Avg: [-681.852 -681.852 -681.852] (0.9851) ({r_i: None, r_t: [-1999.804 -1999.804 -1999.804], eps: 0.985})
Step:   38000, Reward: [-1083.422 -1083.422 -1083.422] [279.833], Avg: [-682.906 -682.906 -682.906] (0.9851) ({r_i: None, r_t: [-2115.281 -2115.281 -2115.281], eps: 0.985})
Step:   38100, Reward: [-855.666 -855.666 -855.666] [175.355], Avg: [-683.359 -683.359 -683.359] (0.9851) ({r_i: None, r_t: [-1946.266 -1946.266 -1946.266], eps: 0.985})
Step:   38200, Reward: [-1019.090 -1019.090 -1019.090] [364.541], Avg: [-684.235 -684.235 -684.235] (0.9851) ({r_i: None, r_t: [-2075.413 -2075.413 -2075.413], eps: 0.985})
Step:   38300, Reward: [-1100.592 -1100.592 -1100.592] [404.062], Avg: [-685.319 -685.319 -685.319] (0.9851) ({r_i: None, r_t: [-2113.125 -2113.125 -2113.125], eps: 0.985})
Step:   38400, Reward: [-955.016 -955.016 -955.016] [263.355], Avg: [-686.020 -686.020 -686.020] (0.9851) ({r_i: None, r_t: [-1985.894 -1985.894 -1985.894], eps: 0.985})
Step:   38500, Reward: [-1002.839 -1002.839 -1002.839] [249.797], Avg: [-686.841 -686.841 -686.841] (0.9851) ({r_i: None, r_t: [-1985.233 -1985.233 -1985.233], eps: 0.985})
Step:   38600, Reward: [-1021.308 -1021.308 -1021.308] [314.695], Avg: [-687.705 -687.705 -687.705] (0.9851) ({r_i: None, r_t: [-1881.785 -1881.785 -1881.785], eps: 0.985})
Step:   38700, Reward: [-994.421 -994.421 -994.421] [324.581], Avg: [-688.495 -688.495 -688.495] (0.9851) ({r_i: None, r_t: [-1939.229 -1939.229 -1939.229], eps: 0.985})
Step:   38800, Reward: [-1012.891 -1012.891 -1012.891] [250.663], Avg: [-689.329 -689.329 -689.329] (0.9851) ({r_i: None, r_t: [-1983.317 -1983.317 -1983.317], eps: 0.985})
Step:   38900, Reward: [-941.498 -941.498 -941.498] [246.930], Avg: [-689.976 -689.976 -689.976] (0.9851) ({r_i: None, r_t: [-2139.790 -2139.790 -2139.790], eps: 0.985})
Step:   39000, Reward: [-1146.733 -1146.733 -1146.733] [271.941], Avg: [-691.144 -691.144 -691.144] (0.9851) ({r_i: None, r_t: [-1992.294 -1992.294 -1992.294], eps: 0.985})
Step:   39100, Reward: [-1065.468 -1065.468 -1065.468] [268.849], Avg: [-692.099 -692.099 -692.099] (0.9851) ({r_i: None, r_t: [-2093.264 -2093.264 -2093.264], eps: 0.985})
Step:   39200, Reward: [-883.493 -883.493 -883.493] [226.673], Avg: [-692.586 -692.586 -692.586] (0.9851) ({r_i: None, r_t: [-2120.211 -2120.211 -2120.211], eps: 0.985})
Step:   39300, Reward: [-1011.213 -1011.213 -1011.213] [263.188], Avg: [-693.395 -693.395 -693.395] (0.9851) ({r_i: None, r_t: [-2035.920 -2035.920 -2035.920], eps: 0.985})
Step:   39400, Reward: [-1123.722 -1123.722 -1123.722] [257.092], Avg: [-694.484 -694.484 -694.484] (0.9851) ({r_i: None, r_t: [-1936.360 -1936.360 -1936.360], eps: 0.985})
Step:   39500, Reward: [-888.585 -888.585 -888.585] [242.277], Avg: [-694.974 -694.974 -694.974] (0.9851) ({r_i: None, r_t: [-2014.934 -2014.934 -2014.934], eps: 0.985})
Step:   39600, Reward: [-910.127 -910.127 -910.127] [251.033], Avg: [-695.516 -695.516 -695.516] (0.9851) ({r_i: None, r_t: [-2150.928 -2150.928 -2150.928], eps: 0.985})
Step:   39700, Reward: [-1131.895 -1131.895 -1131.895] [262.127], Avg: [-696.613 -696.613 -696.613] (0.9851) ({r_i: None, r_t: [-2045.341 -2045.341 -2045.341], eps: 0.985})
Step:   39800, Reward: [-1009.870 -1009.870 -1009.870] [326.577], Avg: [-697.398 -697.398 -697.398] (0.9851) ({r_i: None, r_t: [-2086.829 -2086.829 -2086.829], eps: 0.985})
Step:   39900, Reward: [-1067.306 -1067.306 -1067.306] [334.919], Avg: [-698.323 -698.323 -698.323] (0.9851) ({r_i: None, r_t: [-2058.765 -2058.765 -2058.765], eps: 0.985})
Step:   40000, Reward: [-943.631 -943.631 -943.631] [238.835], Avg: [-698.934 -698.934 -698.934] (0.9851) ({r_i: None, r_t: [-2001.146 -2001.146 -2001.146], eps: 0.985})
Step:   40100, Reward: [-891.491 -891.491 -891.491] [302.972], Avg: [-699.413 -699.413 -699.413] (0.9851) ({r_i: None, r_t: [-2131.989 -2131.989 -2131.989], eps: 0.985})
Step:   40200, Reward: [-989.200 -989.200 -989.200] [189.317], Avg: [-700.132 -700.132 -700.132] (0.9851) ({r_i: None, r_t: [-1809.635 -1809.635 -1809.635], eps: 0.985})
Step:   40300, Reward: [-1112.153 -1112.153 -1112.153] [350.758], Avg: [-701.152 -701.152 -701.152] (0.9851) ({r_i: None, r_t: [-2027.885 -2027.885 -2027.885], eps: 0.985})
Step:   40400, Reward: [-1006.310 -1006.310 -1006.310] [308.408], Avg: [-701.906 -701.906 -701.906] (0.9851) ({r_i: None, r_t: [-2051.116 -2051.116 -2051.116], eps: 0.985})
Step:   40500, Reward: [-1064.672 -1064.672 -1064.672] [276.156], Avg: [-702.799 -702.799 -702.799] (0.9851) ({r_i: None, r_t: [-1883.217 -1883.217 -1883.217], eps: 0.985})
Step:   40600, Reward: [-983.267 -983.267 -983.267] [299.645], Avg: [-703.488 -703.488 -703.488] (0.9851) ({r_i: None, r_t: [-2024.427 -2024.427 -2024.427], eps: 0.985})
Step:   40700, Reward: [-1067.367 -1067.367 -1067.367] [275.785], Avg: [-704.380 -704.380 -704.380] (0.9851) ({r_i: None, r_t: [-1939.514 -1939.514 -1939.514], eps: 0.985})
Step:   40800, Reward: [-919.119 -919.119 -919.119] [258.464], Avg: [-704.905 -704.905 -704.905] (0.9851) ({r_i: None, r_t: [-1903.995 -1903.995 -1903.995], eps: 0.985})
Step:   40900, Reward: [-1028.157 -1028.157 -1028.157] [219.857], Avg: [-705.694 -705.694 -705.694] (0.9851) ({r_i: None, r_t: [-2121.033 -2121.033 -2121.033], eps: 0.985})
Step:   41000, Reward: [-966.948 -966.948 -966.948] [276.605], Avg: [-706.329 -706.329 -706.329] (0.9851) ({r_i: None, r_t: [-2010.632 -2010.632 -2010.632], eps: 0.985})
Step:   41100, Reward: [-941.729 -941.729 -941.729] [288.902], Avg: [-706.901 -706.901 -706.901] (0.9851) ({r_i: None, r_t: [-1974.117 -1974.117 -1974.117], eps: 0.985})
Step:   41200, Reward: [-1039.836 -1039.836 -1039.836] [341.841], Avg: [-707.707 -707.707 -707.707] (0.9851) ({r_i: None, r_t: [-1793.085 -1793.085 -1793.085], eps: 0.985})
Step:   41300, Reward: [-1031.794 -1031.794 -1031.794] [287.348], Avg: [-708.490 -708.490 -708.490] (0.9851) ({r_i: None, r_t: [-2201.140 -2201.140 -2201.140], eps: 0.985})
Step:   41400, Reward: [-1120.646 -1120.646 -1120.646] [268.465], Avg: [-709.483 -709.483 -709.483] (0.9851) ({r_i: None, r_t: [-2054.147 -2054.147 -2054.147], eps: 0.985})
Step:   41500, Reward: [-843.367 -843.367 -843.367] [282.858], Avg: [-709.805 -709.805 -709.805] (0.9851) ({r_i: None, r_t: [-2025.580 -2025.580 -2025.580], eps: 0.985})
Step:   41600, Reward: [-978.231 -978.231 -978.231] [310.791], Avg: [-710.448 -710.448 -710.448] (0.9851) ({r_i: None, r_t: [-2241.775 -2241.775 -2241.775], eps: 0.985})
Step:   41700, Reward: [-1042.746 -1042.746 -1042.746] [323.292], Avg: [-711.243 -711.243 -711.243] (0.9851) ({r_i: None, r_t: [-1860.809 -1860.809 -1860.809], eps: 0.985})
Step:   41800, Reward: [-1062.760 -1062.760 -1062.760] [237.995], Avg: [-712.082 -712.082 -712.082] (0.9851) ({r_i: None, r_t: [-2151.246 -2151.246 -2151.246], eps: 0.985})
Step:   41900, Reward: [-955.270 -955.270 -955.270] [346.969], Avg: [-712.661 -712.661 -712.661] (0.9851) ({r_i: None, r_t: [-2036.680 -2036.680 -2036.680], eps: 0.985})
Step:   42000, Reward: [-990.495 -990.495 -990.495] [246.706], Avg: [-713.321 -713.321 -713.321] (0.9851) ({r_i: None, r_t: [-2074.310 -2074.310 -2074.310], eps: 0.985})
Step:   42100, Reward: [-1020.432 -1020.432 -1020.432] [322.852], Avg: [-714.049 -714.049 -714.049] (0.9851) ({r_i: None, r_t: [-1967.997 -1967.997 -1967.997], eps: 0.985})
Step:   42200, Reward: [-1035.665 -1035.665 -1035.665] [262.829], Avg: [-714.809 -714.809 -714.809] (0.9851) ({r_i: None, r_t: [-2273.124 -2273.124 -2273.124], eps: 0.985})
Step:   42300, Reward: [-1000.196 -1000.196 -1000.196] [273.889], Avg: [-715.482 -715.482 -715.482] (0.9851) ({r_i: None, r_t: [-2258.943 -2258.943 -2258.943], eps: 0.985})
Step:   42400, Reward: [-925.932 -925.932 -925.932] [264.589], Avg: [-715.978 -715.978 -715.978] (0.9851) ({r_i: None, r_t: [-2073.624 -2073.624 -2073.624], eps: 0.985})
Step:   42500, Reward: [-1137.382 -1137.382 -1137.382] [304.978], Avg: [-716.967 -716.967 -716.967] (0.9851) ({r_i: None, r_t: [-2002.474 -2002.474 -2002.474], eps: 0.985})
Step:   42600, Reward: [-1057.436 -1057.436 -1057.436] [457.312], Avg: [-717.764 -717.764 -717.764] (0.9851) ({r_i: None, r_t: [-2056.744 -2056.744 -2056.744], eps: 0.985})
Step:   42700, Reward: [-1015.745 -1015.745 -1015.745] [265.050], Avg: [-718.460 -718.460 -718.460] (0.9851) ({r_i: None, r_t: [-2029.057 -2029.057 -2029.057], eps: 0.985})
Step:   42800, Reward: [-1026.402 -1026.402 -1026.402] [323.497], Avg: [-719.178 -719.178 -719.178] (0.9851) ({r_i: None, r_t: [-2024.741 -2024.741 -2024.741], eps: 0.985})
Step:   42900, Reward: [-1004.685 -1004.685 -1004.685] [396.181], Avg: [-719.842 -719.842 -719.842] (0.9851) ({r_i: None, r_t: [-2056.568 -2056.568 -2056.568], eps: 0.985})
Step:   43000, Reward: [-1092.697 -1092.697 -1092.697] [361.666], Avg: [-720.707 -720.707 -720.707] (0.9851) ({r_i: None, r_t: [-2148.222 -2148.222 -2148.222], eps: 0.985})
Step:   43100, Reward: [-904.032 -904.032 -904.032] [301.060], Avg: [-721.132 -721.132 -721.132] (0.9851) ({r_i: None, r_t: [-2079.896 -2079.896 -2079.896], eps: 0.985})
Step:   43200, Reward: [-935.276 -935.276 -935.276] [258.293], Avg: [-721.626 -721.626 -721.626] (0.9851) ({r_i: None, r_t: [-1897.771 -1897.771 -1897.771], eps: 0.985})
Step:   43300, Reward: [-1155.588 -1155.588 -1155.588] [283.291], Avg: [-722.626 -722.626 -722.626] (0.9851) ({r_i: None, r_t: [-2128.745 -2128.745 -2128.745], eps: 0.985})
Step:   43400, Reward: [-1006.645 -1006.645 -1006.645] [257.133], Avg: [-723.279 -723.279 -723.279] (0.9851) ({r_i: None, r_t: [-1852.096 -1852.096 -1852.096], eps: 0.985})
Step:   43500, Reward: [-1146.427 -1146.427 -1146.427] [366.613], Avg: [-724.249 -724.249 -724.249] (0.9851) ({r_i: None, r_t: [-2134.510 -2134.510 -2134.510], eps: 0.985})
Step:   43600, Reward: [-1083.128 -1083.128 -1083.128] [418.870], Avg: [-725.071 -725.071 -725.071] (0.9851) ({r_i: None, r_t: [-2017.897 -2017.897 -2017.897], eps: 0.985})
Step:   43700, Reward: [-1184.394 -1184.394 -1184.394] [324.547], Avg: [-726.119 -726.119 -726.119] (0.9851) ({r_i: None, r_t: [-2017.120 -2017.120 -2017.120], eps: 0.985})
Step:   43800, Reward: [-1093.802 -1093.802 -1093.802] [362.889], Avg: [-726.957 -726.957 -726.957] (0.9851) ({r_i: None, r_t: [-1881.921 -1881.921 -1881.921], eps: 0.985})
Step:   43900, Reward: [-1016.501 -1016.501 -1016.501] [418.483], Avg: [-727.615 -727.615 -727.615] (0.9851) ({r_i: None, r_t: [-1949.528 -1949.528 -1949.528], eps: 0.985})
Step:   44000, Reward: [-1079.262 -1079.262 -1079.262] [331.199], Avg: [-728.412 -728.412 -728.412] (0.9851) ({r_i: None, r_t: [-1894.852 -1894.852 -1894.852], eps: 0.985})
Step:   44100, Reward: [-863.810 -863.810 -863.810] [291.679], Avg: [-728.719 -728.719 -728.719] (0.9851) ({r_i: None, r_t: [-2039.635 -2039.635 -2039.635], eps: 0.985})
Step:   44200, Reward: [-897.461 -897.461 -897.461] [355.508], Avg: [-729.100 -729.100 -729.100] (0.9851) ({r_i: None, r_t: [-1992.135 -1992.135 -1992.135], eps: 0.985})
Step:   44300, Reward: [-900.892 -900.892 -900.892] [318.295], Avg: [-729.487 -729.487 -729.487] (0.9851) ({r_i: None, r_t: [-1885.159 -1885.159 -1885.159], eps: 0.985})
Step:   44400, Reward: [-1094.982 -1094.982 -1094.982] [317.439], Avg: [-730.308 -730.308 -730.308] (0.9851) ({r_i: None, r_t: [-1954.629 -1954.629 -1954.629], eps: 0.985})
Step:   44500, Reward: [-787.320 -787.320 -787.320] [157.318], Avg: [-730.436 -730.436 -730.436] (0.9851) ({r_i: None, r_t: [-2149.373 -2149.373 -2149.373], eps: 0.985})
Step:   44600, Reward: [-1018.351 -1018.351 -1018.351] [415.300], Avg: [-731.080 -731.080 -731.080] (0.9851) ({r_i: None, r_t: [-2023.306 -2023.306 -2023.306], eps: 0.985})
Step:   44700, Reward: [-921.169 -921.169 -921.169] [431.188], Avg: [-731.504 -731.504 -731.504] (0.9851) ({r_i: None, r_t: [-2135.703 -2135.703 -2135.703], eps: 0.985})
Step:   44800, Reward: [-925.629 -925.629 -925.629] [249.136], Avg: [-731.936 -731.936 -731.936] (0.9851) ({r_i: None, r_t: [-1953.280 -1953.280 -1953.280], eps: 0.985})
Step:   44900, Reward: [-791.055 -791.055 -791.055] [282.166], Avg: [-732.068 -732.068 -732.068] (0.9851) ({r_i: None, r_t: [-1904.118 -1904.118 -1904.118], eps: 0.985})
Step:   45000, Reward: [-1096.411 -1096.411 -1096.411] [425.973], Avg: [-732.876 -732.876 -732.876] (0.9851) ({r_i: None, r_t: [-2073.542 -2073.542 -2073.542], eps: 0.985})
Step:   45100, Reward: [-975.845 -975.845 -975.845] [316.163], Avg: [-733.413 -733.413 -733.413] (0.9801) ({r_i: None, r_t: [-1931.743 -1931.743 -1931.743], eps: 0.98})
Step:   45200, Reward: [-943.212 -943.212 -943.212] [279.411], Avg: [-733.876 -733.876 -733.876] (0.9801) ({r_i: None, r_t: [-1936.467 -1936.467 -1936.467], eps: 0.98})
Step:   45300, Reward: [-961.334 -961.334 -961.334] [323.054], Avg: [-734.377 -734.377 -734.377] (0.9801) ({r_i: None, r_t: [-2042.148 -2042.148 -2042.148], eps: 0.98})
Step:   45400, Reward: [-914.815 -914.815 -914.815] [348.693], Avg: [-734.774 -734.774 -734.774] (0.9801) ({r_i: None, r_t: [-2285.944 -2285.944 -2285.944], eps: 0.98})
Step:   45500, Reward: [-944.909 -944.909 -944.909] [321.560], Avg: [-735.235 -735.235 -735.235] (0.9801) ({r_i: None, r_t: [-1788.279 -1788.279 -1788.279], eps: 0.98})
Step:   45600, Reward: [-977.185 -977.185 -977.185] [251.485], Avg: [-735.764 -735.764 -735.764] (0.9801) ({r_i: None, r_t: [-1855.745 -1855.745 -1855.745], eps: 0.98})
Step:   45700, Reward: [-775.229 -775.229 -775.229] [183.530], Avg: [-735.850 -735.850 -735.850] (0.9801) ({r_i: None, r_t: [-2045.328 -2045.328 -2045.328], eps: 0.98})
Step:   45800, Reward: [-841.326 -841.326 -841.326] [286.066], Avg: [-736.080 -736.080 -736.080] (0.9801) ({r_i: None, r_t: [-1962.088 -1962.088 -1962.088], eps: 0.98})
Step:   45900, Reward: [-1196.767 -1196.767 -1196.767] [318.896], Avg: [-737.082 -737.082 -737.082] (0.9801) ({r_i: None, r_t: [-1904.631 -1904.631 -1904.631], eps: 0.98})
Step:   46000, Reward: [-998.932 -998.932 -998.932] [311.009], Avg: [-737.650 -737.650 -737.650] (0.9801) ({r_i: None, r_t: [-1704.386 -1704.386 -1704.386], eps: 0.98})
Step:   46100, Reward: [-908.377 -908.377 -908.377] [329.781], Avg: [-738.019 -738.019 -738.019] (0.9801) ({r_i: None, r_t: [-1642.177 -1642.177 -1642.177], eps: 0.98})
Step:   46200, Reward: [-952.143 -952.143 -952.143] [300.634], Avg: [-738.482 -738.482 -738.482] (0.9801) ({r_i: None, r_t: [-2007.667 -2007.667 -2007.667], eps: 0.98})
Step:   46300, Reward: [-814.879 -814.879 -814.879] [234.785], Avg: [-738.646 -738.646 -738.646] (0.9801) ({r_i: None, r_t: [-1923.828 -1923.828 -1923.828], eps: 0.98})
Step:   46400, Reward: [-940.170 -940.170 -940.170] [245.189], Avg: [-739.080 -739.080 -739.080] (0.9801) ({r_i: None, r_t: [-1721.547 -1721.547 -1721.547], eps: 0.98})
Step:   46500, Reward: [-806.927 -806.927 -806.927] [265.899], Avg: [-739.225 -739.225 -739.225] (0.9801) ({r_i: None, r_t: [-1684.337 -1684.337 -1684.337], eps: 0.98})
Step:   46600, Reward: [-896.468 -896.468 -896.468] [225.813], Avg: [-739.562 -739.562 -739.562] (0.9801) ({r_i: None, r_t: [-1676.023 -1676.023 -1676.023], eps: 0.98})
Step:   46700, Reward: [-895.214 -895.214 -895.214] [365.611], Avg: [-739.895 -739.895 -739.895] (0.9801) ({r_i: None, r_t: [-1716.627 -1716.627 -1716.627], eps: 0.98})
Step:   46800, Reward: [-766.849 -766.849 -766.849] [219.769], Avg: [-739.952 -739.952 -739.952] (0.9801) ({r_i: None, r_t: [-1792.075 -1792.075 -1792.075], eps: 0.98})
Step:   46900, Reward: [-877.462 -877.462 -877.462] [318.797], Avg: [-740.245 -740.245 -740.245] (0.9801) ({r_i: None, r_t: [-1968.687 -1968.687 -1968.687], eps: 0.98})
Step:   47000, Reward: [-812.521 -812.521 -812.521] [223.067], Avg: [-740.398 -740.398 -740.398] (0.9801) ({r_i: None, r_t: [-1663.193 -1663.193 -1663.193], eps: 0.98})
Step:   47100, Reward: [-793.822 -793.822 -793.822] [277.210], Avg: [-740.511 -740.511 -740.511] (0.9801) ({r_i: None, r_t: [-1617.682 -1617.682 -1617.682], eps: 0.98})
Step:   47200, Reward: [-742.910 -742.910 -742.910] [253.254], Avg: [-740.516 -740.516 -740.516] (0.9801) ({r_i: None, r_t: [-1695.387 -1695.387 -1695.387], eps: 0.98})
Step:   47300, Reward: [-902.958 -902.958 -902.958] [308.821], Avg: [-740.859 -740.859 -740.859] (0.9801) ({r_i: None, r_t: [-1620.845 -1620.845 -1620.845], eps: 0.98})
Step:   47400, Reward: [-783.789 -783.789 -783.789] [349.484], Avg: [-740.949 -740.949 -740.949] (0.9801) ({r_i: None, r_t: [-1544.768 -1544.768 -1544.768], eps: 0.98})
Step:   47500, Reward: [-745.587 -745.587 -745.587] [209.024], Avg: [-740.959 -740.959 -740.959] (0.9801) ({r_i: None, r_t: [-1528.915 -1528.915 -1528.915], eps: 0.98})
Step:   47600, Reward: [-753.909 -753.909 -753.909] [149.330], Avg: [-740.986 -740.986 -740.986] (0.9801) ({r_i: None, r_t: [-1599.894 -1599.894 -1599.894], eps: 0.98})
Step:   47700, Reward: [-709.400 -709.400 -709.400] [183.794], Avg: [-740.920 -740.920 -740.920] (0.9801) ({r_i: None, r_t: [-1567.091 -1567.091 -1567.091], eps: 0.98})
Step:   47800, Reward: [-845.605 -845.605 -845.605] [193.765], Avg: [-741.139 -741.139 -741.139] (0.9801) ({r_i: None, r_t: [-1537.484 -1537.484 -1537.484], eps: 0.98})
Step:   47900, Reward: [-830.238 -830.238 -830.238] [202.667], Avg: [-741.324 -741.324 -741.324] (0.9801) ({r_i: None, r_t: [-1388.399 -1388.399 -1388.399], eps: 0.98})
Step:   48000, Reward: [-738.086 -738.086 -738.086] [277.782], Avg: [-741.318 -741.318 -741.318] (0.9801) ({r_i: None, r_t: [-1549.442 -1549.442 -1549.442], eps: 0.98})
Step:   48100, Reward: [-706.588 -706.588 -706.588] [188.295], Avg: [-741.246 -741.246 -741.246] (0.9801) ({r_i: None, r_t: [-1537.823 -1537.823 -1537.823], eps: 0.98})
Step:   48200, Reward: [-907.201 -907.201 -907.201] [309.839], Avg: [-741.589 -741.589 -741.589] (0.9801) ({r_i: None, r_t: [-1628.091 -1628.091 -1628.091], eps: 0.98})
Step:   48300, Reward: [-702.392 -702.392 -702.392] [206.883], Avg: [-741.508 -741.508 -741.508] (0.9801) ({r_i: None, r_t: [-1438.107 -1438.107 -1438.107], eps: 0.98})
Step:   48400, Reward: [-758.211 -758.211 -758.211] [212.043], Avg: [-741.543 -741.543 -741.543] (0.9801) ({r_i: None, r_t: [-1542.145 -1542.145 -1542.145], eps: 0.98})
Step:   48500, Reward: [-747.392 -747.392 -747.392] [175.845], Avg: [-741.555 -741.555 -741.555] (0.9801) ({r_i: None, r_t: [-1468.617 -1468.617 -1468.617], eps: 0.98})
Step:   48600, Reward: [-694.705 -694.705 -694.705] [153.300], Avg: [-741.458 -741.458 -741.458] (0.9801) ({r_i: None, r_t: [-1454.998 -1454.998 -1454.998], eps: 0.98})
Step:   48700, Reward: [-763.890 -763.890 -763.890] [228.029], Avg: [-741.504 -741.504 -741.504] (0.9801) ({r_i: None, r_t: [-1341.773 -1341.773 -1341.773], eps: 0.98})
Step:   48800, Reward: [-825.997 -825.997 -825.997] [272.871], Avg: [-741.677 -741.677 -741.677] (0.9801) ({r_i: None, r_t: [-1376.528 -1376.528 -1376.528], eps: 0.98})
Step:   48900, Reward: [-657.026 -657.026 -657.026] [207.489], Avg: [-741.504 -741.504 -741.504] (0.9801) ({r_i: None, r_t: [-1408.885 -1408.885 -1408.885], eps: 0.98})
Step:   49000, Reward: [-802.375 -802.375 -802.375] [253.353], Avg: [-741.628 -741.628 -741.628] (0.9801) ({r_i: None, r_t: [-1235.838 -1235.838 -1235.838], eps: 0.98})
Step:   49100, Reward: [-671.545 -671.545 -671.545] [217.243], Avg: [-741.486 -741.486 -741.486] (0.9801) ({r_i: None, r_t: [-1391.651 -1391.651 -1391.651], eps: 0.98})
Step:   49200, Reward: [-704.306 -704.306 -704.306] [221.216], Avg: [-741.411 -741.411 -741.411] (0.9801) ({r_i: None, r_t: [-1496.829 -1496.829 -1496.829], eps: 0.98})
Step:   49300, Reward: [-673.026 -673.026 -673.026] [194.248], Avg: [-741.272 -741.272 -741.272] (0.9801) ({r_i: None, r_t: [-1379.799 -1379.799 -1379.799], eps: 0.98})
Step:   49400, Reward: [-654.935 -654.935 -654.935] [163.388], Avg: [-741.098 -741.098 -741.098] (0.9801) ({r_i: None, r_t: [-1340.553 -1340.553 -1340.553], eps: 0.98})
Step:   49500, Reward: [-692.191 -692.191 -692.191] [206.042], Avg: [-740.999 -740.999 -740.999] (0.9801) ({r_i: None, r_t: [-1314.685 -1314.685 -1314.685], eps: 0.98})
Step:   49600, Reward: [-730.869 -730.869 -730.869] [208.880], Avg: [-740.979 -740.979 -740.979] (0.9801) ({r_i: None, r_t: [-1413.952 -1413.952 -1413.952], eps: 0.98})
Step:   49700, Reward: [-627.042 -627.042 -627.042] [127.271], Avg: [-740.750 -740.750 -740.750] (0.9801) ({r_i: None, r_t: [-1391.963 -1391.963 -1391.963], eps: 0.98})
Step:   49800, Reward: [-650.001 -650.001 -650.001] [117.034], Avg: [-740.568 -740.568 -740.568] (0.9801) ({r_i: None, r_t: [-1327.983 -1327.983 -1327.983], eps: 0.98})
Step:   49900, Reward: [-609.331 -609.331 -609.331] [109.070], Avg: [-740.306 -740.306 -740.306] (0.9801) ({r_i: None, r_t: [-1403.735 -1403.735 -1403.735], eps: 0.98})
Step:   50000, Reward: [-694.723 -694.723 -694.723] [164.231], Avg: [-740.215 -740.215 -740.215] (0.9801) ({r_i: None, r_t: [-1350.346 -1350.346 -1350.346], eps: 0.98})
Step:   50100, Reward: [-584.929 -584.929 -584.929] [94.490], Avg: [-739.905 -739.905 -739.905] (0.9801) ({r_i: None, r_t: [-1235.566 -1235.566 -1235.566], eps: 0.98})
Step:   50200, Reward: [-669.151 -669.151 -669.151] [112.431], Avg: [-739.765 -739.765 -739.765] (0.9801) ({r_i: None, r_t: [-1281.134 -1281.134 -1281.134], eps: 0.98})
Step:   50300, Reward: [-667.595 -667.595 -667.595] [186.333], Avg: [-739.621 -739.621 -739.621] (0.9801) ({r_i: None, r_t: [-1293.847 -1293.847 -1293.847], eps: 0.98})
Step:   50400, Reward: [-579.292 -579.292 -579.292] [83.544], Avg: [-739.304 -739.304 -739.304] (0.9801) ({r_i: None, r_t: [-1311.132 -1311.132 -1311.132], eps: 0.98})
Step:   50500, Reward: [-652.453 -652.453 -652.453] [94.783], Avg: [-739.132 -739.132 -739.132] (0.9801) ({r_i: None, r_t: [-1242.763 -1242.763 -1242.763], eps: 0.98})
Step:   50600, Reward: [-698.471 -698.471 -698.471] [152.994], Avg: [-739.052 -739.052 -739.052] (0.9801) ({r_i: None, r_t: [-1341.975 -1341.975 -1341.975], eps: 0.98})
Step:   50700, Reward: [-654.445 -654.445 -654.445] [165.454], Avg: [-738.886 -738.886 -738.886] (0.9801) ({r_i: None, r_t: [-1280.355 -1280.355 -1280.355], eps: 0.98})
Step:   50800, Reward: [-650.139 -650.139 -650.139] [121.379], Avg: [-738.711 -738.711 -738.711] (0.9801) ({r_i: None, r_t: [-1203.019 -1203.019 -1203.019], eps: 0.98})
Step:   50900, Reward: [-640.011 -640.011 -640.011] [146.362], Avg: [-738.518 -738.518 -738.518] (0.9801) ({r_i: None, r_t: [-1293.142 -1293.142 -1293.142], eps: 0.98})
Step:   51000, Reward: [-732.538 -732.538 -732.538] [153.198], Avg: [-738.506 -738.506 -738.506] (0.9801) ({r_i: None, r_t: [-1366.738 -1366.738 -1366.738], eps: 0.98})
Step:   51100, Reward: [-670.339 -670.339 -670.339] [170.450], Avg: [-738.373 -738.373 -738.373] (0.9801) ({r_i: None, r_t: [-1230.990 -1230.990 -1230.990], eps: 0.98})
Step:   51200, Reward: [-613.219 -613.219 -613.219] [103.180], Avg: [-738.129 -738.129 -738.129] (0.9801) ({r_i: None, r_t: [-1242.144 -1242.144 -1242.144], eps: 0.98})
Step:   51300, Reward: [-599.657 -599.657 -599.657] [125.915], Avg: [-737.860 -737.860 -737.860] (0.9801) ({r_i: None, r_t: [-1317.314 -1317.314 -1317.314], eps: 0.98})
Step:   51400, Reward: [-623.722 -623.722 -623.722] [122.455], Avg: [-737.638 -737.638 -737.638] (0.9801) ({r_i: None, r_t: [-1275.674 -1275.674 -1275.674], eps: 0.98})
Step:   51500, Reward: [-632.319 -632.319 -632.319] [113.191], Avg: [-737.434 -737.434 -737.434] (0.9801) ({r_i: None, r_t: [-1292.041 -1292.041 -1292.041], eps: 0.98})
Step:   51600, Reward: [-578.702 -578.702 -578.702] [74.303], Avg: [-737.127 -737.127 -737.127] (0.9801) ({r_i: None, r_t: [-1183.415 -1183.415 -1183.415], eps: 0.98})
Step:   51700, Reward: [-722.485 -722.485 -722.485] [153.041], Avg: [-737.098 -737.098 -737.098] (0.9801) ({r_i: None, r_t: [-1220.360 -1220.360 -1220.360], eps: 0.98})
Step:   51800, Reward: [-564.305 -564.305 -564.305] [94.240], Avg: [-736.766 -736.766 -736.766] (0.9801) ({r_i: None, r_t: [-1220.149 -1220.149 -1220.149], eps: 0.98})
Step:   51900, Reward: [-659.445 -659.445 -659.445] [137.256], Avg: [-736.617 -736.617 -736.617] (0.9801) ({r_i: None, r_t: [-1292.677 -1292.677 -1292.677], eps: 0.98})
Step:   52000, Reward: [-654.686 -654.686 -654.686] [157.243], Avg: [-736.460 -736.460 -736.460] (0.9801) ({r_i: None, r_t: [-1273.860 -1273.860 -1273.860], eps: 0.98})
Step:   52100, Reward: [-636.318 -636.318 -636.318] [144.087], Avg: [-736.268 -736.268 -736.268] (0.9801) ({r_i: None, r_t: [-1336.494 -1336.494 -1336.494], eps: 0.98})
Step:   52200, Reward: [-593.933 -593.933 -593.933] [105.497], Avg: [-735.996 -735.996 -735.996] (0.9801) ({r_i: None, r_t: [-1228.444 -1228.444 -1228.444], eps: 0.98})
Step:   52300, Reward: [-655.589 -655.589 -655.589] [163.584], Avg: [-735.842 -735.842 -735.842] (0.9801) ({r_i: None, r_t: [-1311.835 -1311.835 -1311.835], eps: 0.98})
Step:   52400, Reward: [-619.483 -619.483 -619.483] [110.888], Avg: [-735.621 -735.621 -735.621] (0.9801) ({r_i: None, r_t: [-1412.757 -1412.757 -1412.757], eps: 0.98})
Step:   52500, Reward: [-613.007 -613.007 -613.007] [149.994], Avg: [-735.387 -735.387 -735.387] (0.9801) ({r_i: None, r_t: [-1254.119 -1254.119 -1254.119], eps: 0.98})
Step:   52600, Reward: [-614.875 -614.875 -614.875] [129.035], Avg: [-735.159 -735.159 -735.159] (0.9801) ({r_i: None, r_t: [-1267.100 -1267.100 -1267.100], eps: 0.98})
Step:   52700, Reward: [-695.594 -695.594 -695.594] [143.277], Avg: [-735.084 -735.084 -735.084] (0.9801) ({r_i: None, r_t: [-1304.826 -1304.826 -1304.826], eps: 0.98})
Step:   52800, Reward: [-672.149 -672.149 -672.149] [104.706], Avg: [-734.965 -734.965 -734.965] (0.9801) ({r_i: None, r_t: [-1253.639 -1253.639 -1253.639], eps: 0.98})
Step:   52900, Reward: [-646.904 -646.904 -646.904] [186.389], Avg: [-734.799 -734.799 -734.799] (0.9801) ({r_i: None, r_t: [-1295.174 -1295.174 -1295.174], eps: 0.98})
Step:   53000, Reward: [-651.946 -651.946 -651.946] [133.667], Avg: [-734.643 -734.643 -734.643] (0.9801) ({r_i: None, r_t: [-1239.479 -1239.479 -1239.479], eps: 0.98})
Step:   53100, Reward: [-644.986 -644.986 -644.986] [184.025], Avg: [-734.474 -734.474 -734.474] (0.9801) ({r_i: None, r_t: [-1246.615 -1246.615 -1246.615], eps: 0.98})
Step:   53200, Reward: [-696.860 -696.860 -696.860] [168.019], Avg: [-734.404 -734.404 -734.404] (0.9801) ({r_i: None, r_t: [-1418.262 -1418.262 -1418.262], eps: 0.98})
Step:   53300, Reward: [-641.077 -641.077 -641.077] [201.262], Avg: [-734.229 -734.229 -734.229] (0.9801) ({r_i: None, r_t: [-1365.985 -1365.985 -1365.985], eps: 0.98})
Step:   53400, Reward: [-658.587 -658.587 -658.587] [153.267], Avg: [-734.087 -734.087 -734.087] (0.9801) ({r_i: None, r_t: [-1312.385 -1312.385 -1312.385], eps: 0.98})
Step:   53500, Reward: [-650.468 -650.468 -650.468] [112.865], Avg: [-733.931 -733.931 -733.931] (0.9801) ({r_i: None, r_t: [-1331.780 -1331.780 -1331.780], eps: 0.98})
Step:   53600, Reward: [-654.494 -654.494 -654.494] [156.406], Avg: [-733.783 -733.783 -733.783] (0.9801) ({r_i: None, r_t: [-1393.399 -1393.399 -1393.399], eps: 0.98})
Step:   53700, Reward: [-676.386 -676.386 -676.386] [156.869], Avg: [-733.677 -733.677 -733.677] (0.9801) ({r_i: None, r_t: [-1301.082 -1301.082 -1301.082], eps: 0.98})
Step:   53800, Reward: [-720.775 -720.775 -720.775] [141.928], Avg: [-733.653 -733.653 -733.653] (0.9801) ({r_i: None, r_t: [-1349.022 -1349.022 -1349.022], eps: 0.98})
Step:   53900, Reward: [-643.251 -643.251 -643.251] [172.289], Avg: [-733.485 -733.485 -733.485] (0.9801) ({r_i: None, r_t: [-1263.207 -1263.207 -1263.207], eps: 0.98})
Step:   54000, Reward: [-626.920 -626.920 -626.920] [118.812], Avg: [-733.288 -733.288 -733.288] (0.9801) ({r_i: None, r_t: [-1374.421 -1374.421 -1374.421], eps: 0.98})
Step:   54100, Reward: [-692.238 -692.238 -692.238] [184.174], Avg: [-733.213 -733.213 -733.213] (0.9801) ({r_i: None, r_t: [-1357.432 -1357.432 -1357.432], eps: 0.98})
Step:   54200, Reward: [-642.263 -642.263 -642.263] [128.262], Avg: [-733.045 -733.045 -733.045] (0.9801) ({r_i: None, r_t: [-1314.792 -1314.792 -1314.792], eps: 0.98})
Step:   54300, Reward: [-662.908 -662.908 -662.908] [152.616], Avg: [-732.916 -732.916 -732.916] (0.9801) ({r_i: None, r_t: [-1327.883 -1327.883 -1327.883], eps: 0.98})
Step:   54400, Reward: [-670.997 -670.997 -670.997] [169.898], Avg: [-732.803 -732.803 -732.803] (0.9801) ({r_i: None, r_t: [-1374.552 -1374.552 -1374.552], eps: 0.98})
Step:   54500, Reward: [-677.441 -677.441 -677.441] [129.092], Avg: [-732.701 -732.701 -732.701] (0.9801) ({r_i: None, r_t: [-1247.683 -1247.683 -1247.683], eps: 0.98})
Step:   54600, Reward: [-699.161 -699.161 -699.161] [199.173], Avg: [-732.640 -732.640 -732.640] (0.9801) ({r_i: None, r_t: [-1371.095 -1371.095 -1371.095], eps: 0.98})
Step:   54700, Reward: [-751.752 -751.752 -751.752] [196.629], Avg: [-732.675 -732.675 -732.675] (0.9801) ({r_i: None, r_t: [-1289.013 -1289.013 -1289.013], eps: 0.98})
Step:   54800, Reward: [-683.806 -683.806 -683.806] [178.307], Avg: [-732.586 -732.586 -732.586] (0.9801) ({r_i: None, r_t: [-1412.184 -1412.184 -1412.184], eps: 0.98})
Step:   54900, Reward: [-691.309 -691.309 -691.309] [190.936], Avg: [-732.511 -732.511 -732.511] (0.9801) ({r_i: None, r_t: [-1400.060 -1400.060 -1400.060], eps: 0.98})
Step:   55000, Reward: [-737.128 -737.128 -737.128] [92.719], Avg: [-732.519 -732.519 -732.519] (0.9801) ({r_i: None, r_t: [-1367.565 -1367.565 -1367.565], eps: 0.98})
Step:   55100, Reward: [-701.629 -701.629 -701.629] [173.132], Avg: [-732.463 -732.463 -732.463] (0.9801) ({r_i: None, r_t: [-1378.753 -1378.753 -1378.753], eps: 0.98})
Step:   55200, Reward: [-733.095 -733.095 -733.095] [212.799], Avg: [-732.464 -732.464 -732.464] (0.9801) ({r_i: None, r_t: [-1286.492 -1286.492 -1286.492], eps: 0.98})
Step:   55300, Reward: [-739.736 -739.736 -739.736] [230.273], Avg: [-732.477 -732.477 -732.477] (0.9801) ({r_i: None, r_t: [-1469.444 -1469.444 -1469.444], eps: 0.98})
Step:   55400, Reward: [-616.324 -616.324 -616.324] [112.783], Avg: [-732.268 -732.268 -732.268] (0.9801) ({r_i: None, r_t: [-1432.810 -1432.810 -1432.810], eps: 0.98})
Step:   55500, Reward: [-703.865 -703.865 -703.865] [157.515], Avg: [-732.217 -732.217 -732.217] (0.9801) ({r_i: None, r_t: [-1528.545 -1528.545 -1528.545], eps: 0.98})
Step:   55600, Reward: [-720.034 -720.034 -720.034] [222.120], Avg: [-732.195 -732.195 -732.195] (0.9801) ({r_i: None, r_t: [-1491.038 -1491.038 -1491.038], eps: 0.98})
Step:   55700, Reward: [-733.058 -733.058 -733.058] [189.652], Avg: [-732.197 -732.197 -732.197] (0.9801) ({r_i: None, r_t: [-1502.523 -1502.523 -1502.523], eps: 0.98})
Step:   55800, Reward: [-736.909 -736.909 -736.909] [238.799], Avg: [-732.205 -732.205 -732.205] (0.9801) ({r_i: None, r_t: [-1436.109 -1436.109 -1436.109], eps: 0.98})
Step:   55900, Reward: [-686.688 -686.688 -686.688] [194.333], Avg: [-732.124 -732.124 -732.124] (0.9801) ({r_i: None, r_t: [-1417.133 -1417.133 -1417.133], eps: 0.98})
Step:   56000, Reward: [-779.660 -779.660 -779.660] [222.122], Avg: [-732.209 -732.209 -732.209] (0.9801) ({r_i: None, r_t: [-1458.083 -1458.083 -1458.083], eps: 0.98})
Step:   56100, Reward: [-751.854 -751.854 -751.854] [189.081], Avg: [-732.244 -732.244 -732.244] (0.9801) ({r_i: None, r_t: [-1396.286 -1396.286 -1396.286], eps: 0.98})
Step:   56200, Reward: [-700.995 -700.995 -700.995] [182.516], Avg: [-732.188 -732.188 -732.188] (0.9801) ({r_i: None, r_t: [-1490.541 -1490.541 -1490.541], eps: 0.98})
Step:   56300, Reward: [-705.023 -705.023 -705.023] [179.913], Avg: [-732.140 -732.140 -732.140] (0.9801) ({r_i: None, r_t: [-1392.286 -1392.286 -1392.286], eps: 0.98})
Step:   56400, Reward: [-786.999 -786.999 -786.999] [189.958], Avg: [-732.237 -732.237 -732.237] (0.9801) ({r_i: None, r_t: [-1441.634 -1441.634 -1441.634], eps: 0.98})
Step:   56500, Reward: [-718.434 -718.434 -718.434] [281.874], Avg: [-732.213 -732.213 -732.213] (0.9801) ({r_i: None, r_t: [-1640.934 -1640.934 -1640.934], eps: 0.98})
Step:   56600, Reward: [-840.049 -840.049 -840.049] [272.953], Avg: [-732.403 -732.403 -732.403] (0.9801) ({r_i: None, r_t: [-1553.593 -1553.593 -1553.593], eps: 0.98})
Step:   56700, Reward: [-777.456 -777.456 -777.456] [194.339], Avg: [-732.482 -732.482 -732.482] (0.9801) ({r_i: None, r_t: [-1480.048 -1480.048 -1480.048], eps: 0.98})
Step:   56800, Reward: [-748.820 -748.820 -748.820] [158.579], Avg: [-732.511 -732.511 -732.511] (0.9801) ({r_i: None, r_t: [-1482.674 -1482.674 -1482.674], eps: 0.98})
Step:   56900, Reward: [-668.594 -668.594 -668.594] [180.160], Avg: [-732.399 -732.399 -732.399] (0.9801) ({r_i: None, r_t: [-1703.049 -1703.049 -1703.049], eps: 0.98})
Step:   57000, Reward: [-780.281 -780.281 -780.281] [179.700], Avg: [-732.483 -732.483 -732.483] (0.9801) ({r_i: None, r_t: [-1550.463 -1550.463 -1550.463], eps: 0.98})
Step:   57100, Reward: [-782.175 -782.175 -782.175] [246.639], Avg: [-732.569 -732.569 -732.569] (0.9801) ({r_i: None, r_t: [-1428.407 -1428.407 -1428.407], eps: 0.98})
Step:   57200, Reward: [-753.954 -753.954 -753.954] [156.263], Avg: [-732.607 -732.607 -732.607] (0.9801) ({r_i: None, r_t: [-1624.204 -1624.204 -1624.204], eps: 0.98})
Step:   57300, Reward: [-676.383 -676.383 -676.383] [170.096], Avg: [-732.509 -732.509 -732.509] (0.9801) ({r_i: None, r_t: [-1662.679 -1662.679 -1662.679], eps: 0.98})
Step:   57400, Reward: [-773.388 -773.388 -773.388] [216.248], Avg: [-732.580 -732.580 -732.580] (0.9801) ({r_i: None, r_t: [-1650.745 -1650.745 -1650.745], eps: 0.98})
Step:   57500, Reward: [-761.075 -761.075 -761.075] [130.916], Avg: [-732.629 -732.629 -732.629] (0.9801) ({r_i: None, r_t: [-1590.247 -1590.247 -1590.247], eps: 0.98})
Step:   57600, Reward: [-719.329 -719.329 -719.329] [151.707], Avg: [-732.606 -732.606 -732.606] (0.9752) ({r_i: None, r_t: [-1655.616 -1655.616 -1655.616], eps: 0.975})
Step:   57700, Reward: [-786.251 -786.251 -786.251] [207.237], Avg: [-732.699 -732.699 -732.699] (0.9752) ({r_i: None, r_t: [-1709.253 -1709.253 -1709.253], eps: 0.975})
Step:   57800, Reward: [-797.134 -797.134 -797.134] [154.583], Avg: [-732.810 -732.810 -732.810] (0.9752) ({r_i: None, r_t: [-1566.038 -1566.038 -1566.038], eps: 0.975})
Step:   57900, Reward: [-723.088 -723.088 -723.088] [152.205], Avg: [-732.794 -732.794 -732.794] (0.9752) ({r_i: None, r_t: [-1663.016 -1663.016 -1663.016], eps: 0.975})
Step:   58000, Reward: [-844.345 -844.345 -844.345] [151.352], Avg: [-732.986 -732.986 -732.986] (0.9752) ({r_i: None, r_t: [-1522.702 -1522.702 -1522.702], eps: 0.975})
Step:   58100, Reward: [-806.881 -806.881 -806.881] [261.487], Avg: [-733.113 -733.113 -733.113] (0.9752) ({r_i: None, r_t: [-1553.838 -1553.838 -1553.838], eps: 0.975})
Step:   58200, Reward: [-736.773 -736.773 -736.773] [188.304], Avg: [-733.119 -733.119 -733.119] (0.9752) ({r_i: None, r_t: [-1492.523 -1492.523 -1492.523], eps: 0.975})
Step:   58300, Reward: [-752.981 -752.981 -752.981] [138.949], Avg: [-733.153 -733.153 -733.153] (0.9752) ({r_i: None, r_t: [-1826.955 -1826.955 -1826.955], eps: 0.975})
Step:   58400, Reward: [-841.108 -841.108 -841.108] [211.251], Avg: [-733.337 -733.337 -733.337] (0.9752) ({r_i: None, r_t: [-1778.723 -1778.723 -1778.723], eps: 0.975})
Step:   58500, Reward: [-784.371 -784.371 -784.371] [155.892], Avg: [-733.425 -733.425 -733.425] (0.9752) ({r_i: None, r_t: [-1707.007 -1707.007 -1707.007], eps: 0.975})
Step:   58600, Reward: [-960.709 -960.709 -960.709] [158.495], Avg: [-733.812 -733.812 -733.812] (0.9752) ({r_i: None, r_t: [-1724.061 -1724.061 -1724.061], eps: 0.975})
Step:   58700, Reward: [-785.990 -785.990 -785.990] [217.280], Avg: [-733.900 -733.900 -733.900] (0.9752) ({r_i: None, r_t: [-1546.537 -1546.537 -1546.537], eps: 0.975})
Step:   58800, Reward: [-831.177 -831.177 -831.177] [267.332], Avg: [-734.066 -734.066 -734.066] (0.9752) ({r_i: None, r_t: [-1540.596 -1540.596 -1540.596], eps: 0.975})
Step:   58900, Reward: [-821.730 -821.730 -821.730] [223.872], Avg: [-734.214 -734.214 -734.214] (0.9752) ({r_i: None, r_t: [-1656.959 -1656.959 -1656.959], eps: 0.975})
Step:   59000, Reward: [-868.744 -868.744 -868.744] [112.100], Avg: [-734.442 -734.442 -734.442] (0.9752) ({r_i: None, r_t: [-1618.874 -1618.874 -1618.874], eps: 0.975})
Step:   59100, Reward: [-832.975 -832.975 -832.975] [189.700], Avg: [-734.608 -734.608 -734.608] (0.9752) ({r_i: None, r_t: [-1761.151 -1761.151 -1761.151], eps: 0.975})
Step:   59200, Reward: [-842.836 -842.836 -842.836] [161.667], Avg: [-734.791 -734.791 -734.791] (0.9752) ({r_i: None, r_t: [-1701.638 -1701.638 -1701.638], eps: 0.975})
Step:   59300, Reward: [-814.809 -814.809 -814.809] [252.710], Avg: [-734.926 -734.926 -734.926] (0.9752) ({r_i: None, r_t: [-1765.674 -1765.674 -1765.674], eps: 0.975})
Step:   59400, Reward: [-880.879 -880.879 -880.879] [171.848], Avg: [-735.171 -735.171 -735.171] (0.9752) ({r_i: None, r_t: [-1651.906 -1651.906 -1651.906], eps: 0.975})
Step:   59500, Reward: [-867.982 -867.982 -867.982] [209.147], Avg: [-735.394 -735.394 -735.394] (0.9752) ({r_i: None, r_t: [-1707.121 -1707.121 -1707.121], eps: 0.975})
Step:   59600, Reward: [-788.302 -788.302 -788.302] [178.538], Avg: [-735.482 -735.482 -735.482] (0.9752) ({r_i: None, r_t: [-1719.079 -1719.079 -1719.079], eps: 0.975})
Step:   59700, Reward: [-845.821 -845.821 -845.821] [188.681], Avg: [-735.667 -735.667 -735.667] (0.9752) ({r_i: None, r_t: [-1963.254 -1963.254 -1963.254], eps: 0.975})
Step:   59800, Reward: [-832.670 -832.670 -832.670] [262.997], Avg: [-735.829 -735.829 -735.829] (0.9752) ({r_i: None, r_t: [-1875.873 -1875.873 -1875.873], eps: 0.975})
Step:   59900, Reward: [-899.343 -899.343 -899.343] [297.387], Avg: [-736.101 -736.101 -736.101] (0.9752) ({r_i: None, r_t: [-1570.832 -1570.832 -1570.832], eps: 0.975})
Step:   60000, Reward: [-831.500 -831.500 -831.500] [129.043], Avg: [-736.260 -736.260 -736.260] (0.9752) ({r_i: None, r_t: [-1872.908 -1872.908 -1872.908], eps: 0.975})
Step:   60100, Reward: [-784.894 -784.894 -784.894] [236.308], Avg: [-736.341 -736.341 -736.341] (0.9752) ({r_i: None, r_t: [-1874.378 -1874.378 -1874.378], eps: 0.975})
Step:   60200, Reward: [-876.451 -876.451 -876.451] [205.318], Avg: [-736.573 -736.573 -736.573] (0.9752) ({r_i: None, r_t: [-1819.172 -1819.172 -1819.172], eps: 0.975})
Step:   60300, Reward: [-887.755 -887.755 -887.755] [253.251], Avg: [-736.823 -736.823 -736.823] (0.9752) ({r_i: None, r_t: [-1804.028 -1804.028 -1804.028], eps: 0.975})
Step:   60400, Reward: [-960.299 -960.299 -960.299] [250.074], Avg: [-737.193 -737.193 -737.193] (0.9752) ({r_i: None, r_t: [-1850.307 -1850.307 -1850.307], eps: 0.975})
Step:   60500, Reward: [-971.495 -971.495 -971.495] [204.016], Avg: [-737.579 -737.579 -737.579] (0.9752) ({r_i: None, r_t: [-1744.828 -1744.828 -1744.828], eps: 0.975})
Step:   60600, Reward: [-980.015 -980.015 -980.015] [246.585], Avg: [-737.979 -737.979 -737.979] (0.9752) ({r_i: None, r_t: [-1747.229 -1747.229 -1747.229], eps: 0.975})
Step:   60700, Reward: [-923.574 -923.574 -923.574] [248.474], Avg: [-738.284 -738.284 -738.284] (0.9752) ({r_i: None, r_t: [-1864.116 -1864.116 -1864.116], eps: 0.975})
Step:   60800, Reward: [-905.983 -905.983 -905.983] [265.613], Avg: [-738.559 -738.559 -738.559] (0.9752) ({r_i: None, r_t: [-1810.759 -1810.759 -1810.759], eps: 0.975})
Step:   60900, Reward: [-964.630 -964.630 -964.630] [254.352], Avg: [-738.930 -738.930 -738.930] (0.9752) ({r_i: None, r_t: [-1774.775 -1774.775 -1774.775], eps: 0.975})
Step:   61000, Reward: [-876.512 -876.512 -876.512] [257.678], Avg: [-739.155 -739.155 -739.155] (0.9752) ({r_i: None, r_t: [-1952.526 -1952.526 -1952.526], eps: 0.975})
Step:   61100, Reward: [-1000.027 -1000.027 -1000.027] [255.156], Avg: [-739.582 -739.582 -739.582] (0.9752) ({r_i: None, r_t: [-1891.288 -1891.288 -1891.288], eps: 0.975})
Step:   61200, Reward: [-903.909 -903.909 -903.909] [230.033], Avg: [-739.850 -739.850 -739.850] (0.9752) ({r_i: None, r_t: [-1868.792 -1868.792 -1868.792], eps: 0.975})
Step:   61300, Reward: [-890.722 -890.722 -890.722] [240.168], Avg: [-740.095 -740.095 -740.095] (0.9752) ({r_i: None, r_t: [-1878.181 -1878.181 -1878.181], eps: 0.975})
Step:   61400, Reward: [-917.226 -917.226 -917.226] [272.363], Avg: [-740.383 -740.383 -740.383] (0.9752) ({r_i: None, r_t: [-1913.539 -1913.539 -1913.539], eps: 0.975})
Step:   61500, Reward: [-905.276 -905.276 -905.276] [299.204], Avg: [-740.651 -740.651 -740.651] (0.9752) ({r_i: None, r_t: [-1949.154 -1949.154 -1949.154], eps: 0.975})
Step:   61600, Reward: [-1056.765 -1056.765 -1056.765] [339.495], Avg: [-741.163 -741.163 -741.163] (0.9752) ({r_i: None, r_t: [-1942.575 -1942.575 -1942.575], eps: 0.975})
Step:   61700, Reward: [-1099.915 -1099.915 -1099.915] [340.684], Avg: [-741.744 -741.744 -741.744] (0.9752) ({r_i: None, r_t: [-1926.207 -1926.207 -1926.207], eps: 0.975})
Step:   61800, Reward: [-856.252 -856.252 -856.252] [260.764], Avg: [-741.929 -741.929 -741.929] (0.9752) ({r_i: None, r_t: [-1773.498 -1773.498 -1773.498], eps: 0.975})
Step:   61900, Reward: [-961.333 -961.333 -961.333] [440.507], Avg: [-742.283 -742.283 -742.283] (0.9752) ({r_i: None, r_t: [-1965.735 -1965.735 -1965.735], eps: 0.975})
Step:   62000, Reward: [-1028.339 -1028.339 -1028.339] [300.880], Avg: [-742.743 -742.743 -742.743] (0.9752) ({r_i: None, r_t: [-1954.342 -1954.342 -1954.342], eps: 0.975})
Step:   62100, Reward: [-1000.089 -1000.089 -1000.089] [305.861], Avg: [-743.157 -743.157 -743.157] (0.9752) ({r_i: None, r_t: [-1935.397 -1935.397 -1935.397], eps: 0.975})
Step:   62200, Reward: [-1061.801 -1061.801 -1061.801] [312.882], Avg: [-743.669 -743.669 -743.669] (0.9752) ({r_i: None, r_t: [-1924.102 -1924.102 -1924.102], eps: 0.975})
Step:   62300, Reward: [-976.867 -976.867 -976.867] [389.867], Avg: [-744.042 -744.042 -744.042] (0.9752) ({r_i: None, r_t: [-2071.984 -2071.984 -2071.984], eps: 0.975})
Step:   62400, Reward: [-925.733 -925.733 -925.733] [379.852], Avg: [-744.333 -744.333 -744.333] (0.9752) ({r_i: None, r_t: [-1905.151 -1905.151 -1905.151], eps: 0.975})
Step:   62500, Reward: [-970.694 -970.694 -970.694] [336.533], Avg: [-744.695 -744.695 -744.695] (0.9752) ({r_i: None, r_t: [-1902.673 -1902.673 -1902.673], eps: 0.975})
Step:   62600, Reward: [-1020.363 -1020.363 -1020.363] [265.408], Avg: [-745.134 -745.134 -745.134] (0.9752) ({r_i: None, r_t: [-1958.663 -1958.663 -1958.663], eps: 0.975})
Step:   62700, Reward: [-1019.505 -1019.505 -1019.505] [278.438], Avg: [-745.571 -745.571 -745.571] (0.9752) ({r_i: None, r_t: [-1910.217 -1910.217 -1910.217], eps: 0.975})
Step:   62800, Reward: [-1002.044 -1002.044 -1002.044] [357.500], Avg: [-745.979 -745.979 -745.979] (0.9752) ({r_i: None, r_t: [-1934.992 -1934.992 -1934.992], eps: 0.975})
Step:   62900, Reward: [-1013.304 -1013.304 -1013.304] [269.280], Avg: [-746.403 -746.403 -746.403] (0.9752) ({r_i: None, r_t: [-1836.610 -1836.610 -1836.610], eps: 0.975})
Step:   63000, Reward: [-988.319 -988.319 -988.319] [325.202], Avg: [-746.787 -746.787 -746.787] (0.9752) ({r_i: None, r_t: [-1870.026 -1870.026 -1870.026], eps: 0.975})
Step:   63100, Reward: [-1069.908 -1069.908 -1069.908] [264.517], Avg: [-747.298 -747.298 -747.298] (0.9752) ({r_i: None, r_t: [-1866.951 -1866.951 -1866.951], eps: 0.975})
Step:   63200, Reward: [-900.373 -900.373 -900.373] [330.421], Avg: [-747.540 -747.540 -747.540] (0.9752) ({r_i: None, r_t: [-2155.312 -2155.312 -2155.312], eps: 0.975})
Step:   63300, Reward: [-957.368 -957.368 -957.368] [343.913], Avg: [-747.871 -747.871 -747.871] (0.9752) ({r_i: None, r_t: [-2021.920 -2021.920 -2021.920], eps: 0.975})
Step:   63400, Reward: [-851.368 -851.368 -851.368] [281.525], Avg: [-748.034 -748.034 -748.034] (0.9752) ({r_i: None, r_t: [-1995.329 -1995.329 -1995.329], eps: 0.975})
Step:   63500, Reward: [-979.571 -979.571 -979.571] [296.519], Avg: [-748.398 -748.398 -748.398] (0.9752) ({r_i: None, r_t: [-2006.150 -2006.150 -2006.150], eps: 0.975})
Step:   63600, Reward: [-990.306 -990.306 -990.306] [349.326], Avg: [-748.777 -748.777 -748.777] (0.9752) ({r_i: None, r_t: [-1957.750 -1957.750 -1957.750], eps: 0.975})
Step:   63700, Reward: [-993.668 -993.668 -993.668] [381.367], Avg: [-749.161 -749.161 -749.161] (0.9752) ({r_i: None, r_t: [-1798.602 -1798.602 -1798.602], eps: 0.975})
Step:   63800, Reward: [-873.516 -873.516 -873.516] [328.807], Avg: [-749.356 -749.356 -749.356] (0.9752) ({r_i: None, r_t: [-1938.979 -1938.979 -1938.979], eps: 0.975})
Step:   63900, Reward: [-955.455 -955.455 -955.455] [389.696], Avg: [-749.678 -749.678 -749.678] (0.9752) ({r_i: None, r_t: [-2027.458 -2027.458 -2027.458], eps: 0.975})
Step:   64000, Reward: [-851.309 -851.309 -851.309] [220.848], Avg: [-749.837 -749.837 -749.837] (0.9752) ({r_i: None, r_t: [-1972.327 -1972.327 -1972.327], eps: 0.975})
Step:   64100, Reward: [-995.384 -995.384 -995.384] [359.531], Avg: [-750.219 -750.219 -750.219] (0.9752) ({r_i: None, r_t: [-1934.248 -1934.248 -1934.248], eps: 0.975})
Step:   64200, Reward: [-1058.008 -1058.008 -1058.008] [339.373], Avg: [-750.698 -750.698 -750.698] (0.9752) ({r_i: None, r_t: [-1937.391 -1937.391 -1937.391], eps: 0.975})
Step:   64300, Reward: [-843.839 -843.839 -843.839] [252.437], Avg: [-750.842 -750.842 -750.842] (0.9752) ({r_i: None, r_t: [-2051.728 -2051.728 -2051.728], eps: 0.975})
Step:   64400, Reward: [-1004.595 -1004.595 -1004.595] [257.221], Avg: [-751.236 -751.236 -751.236] (0.9752) ({r_i: None, r_t: [-2078.407 -2078.407 -2078.407], eps: 0.975})
Step:   64500, Reward: [-936.845 -936.845 -936.845] [337.250], Avg: [-751.523 -751.523 -751.523] (0.9752) ({r_i: None, r_t: [-1855.432 -1855.432 -1855.432], eps: 0.975})
Step:   64600, Reward: [-1022.992 -1022.992 -1022.992] [359.225], Avg: [-751.943 -751.943 -751.943] (0.9752) ({r_i: None, r_t: [-1898.968 -1898.968 -1898.968], eps: 0.975})
Step:   64700, Reward: [-926.381 -926.381 -926.381] [393.068], Avg: [-752.212 -752.212 -752.212] (0.9752) ({r_i: None, r_t: [-2019.166 -2019.166 -2019.166], eps: 0.975})
Step:   64800, Reward: [-899.591 -899.591 -899.591] [278.264], Avg: [-752.439 -752.439 -752.439] (0.9752) ({r_i: None, r_t: [-2059.907 -2059.907 -2059.907], eps: 0.975})
Step:   64900, Reward: [-1011.865 -1011.865 -1011.865] [275.516], Avg: [-752.838 -752.838 -752.838] (0.9752) ({r_i: None, r_t: [-1969.940 -1969.940 -1969.940], eps: 0.975})
Step:   65000, Reward: [-1216.385 -1216.385 -1216.385] [386.352], Avg: [-753.550 -753.550 -753.550] (0.9752) ({r_i: None, r_t: [-1737.251 -1737.251 -1737.251], eps: 0.975})
Step:   65100, Reward: [-1002.059 -1002.059 -1002.059] [391.256], Avg: [-753.931 -753.931 -753.931] (0.9752) ({r_i: None, r_t: [-1867.310 -1867.310 -1867.310], eps: 0.975})
Step:   65200, Reward: [-855.498 -855.498 -855.498] [290.731], Avg: [-754.087 -754.087 -754.087] (0.9752) ({r_i: None, r_t: [-1868.300 -1868.300 -1868.300], eps: 0.975})
Step:   65300, Reward: [-911.346 -911.346 -911.346] [358.128], Avg: [-754.327 -754.327 -754.327] (0.9752) ({r_i: None, r_t: [-1918.032 -1918.032 -1918.032], eps: 0.975})
Step:   65400, Reward: [-982.885 -982.885 -982.885] [337.726], Avg: [-754.676 -754.676 -754.676] (0.9752) ({r_i: None, r_t: [-1904.004 -1904.004 -1904.004], eps: 0.975})
Step:   65500, Reward: [-842.845 -842.845 -842.845] [276.605], Avg: [-754.811 -754.811 -754.811] (0.9752) ({r_i: None, r_t: [-1982.921 -1982.921 -1982.921], eps: 0.975})
Step:   65600, Reward: [-970.238 -970.238 -970.238] [310.916], Avg: [-755.138 -755.138 -755.138] (0.9752) ({r_i: None, r_t: [-1892.730 -1892.730 -1892.730], eps: 0.975})
Step:   65700, Reward: [-1053.950 -1053.950 -1053.950] [402.023], Avg: [-755.593 -755.593 -755.593] (0.9752) ({r_i: None, r_t: [-2253.666 -2253.666 -2253.666], eps: 0.975})
Step:   65800, Reward: [-888.273 -888.273 -888.273] [303.838], Avg: [-755.794 -755.794 -755.794] (0.9752) ({r_i: None, r_t: [-1953.798 -1953.798 -1953.798], eps: 0.975})
Step:   65900, Reward: [-914.556 -914.556 -914.556] [300.697], Avg: [-756.034 -756.034 -756.034] (0.9752) ({r_i: None, r_t: [-1876.794 -1876.794 -1876.794], eps: 0.975})
Step:   66000, Reward: [-859.150 -859.150 -859.150] [324.244], Avg: [-756.190 -756.190 -756.190] (0.9752) ({r_i: None, r_t: [-1874.123 -1874.123 -1874.123], eps: 0.975})
Step:   66100, Reward: [-928.981 -928.981 -928.981] [393.920], Avg: [-756.451 -756.451 -756.451] (0.9752) ({r_i: None, r_t: [-1965.865 -1965.865 -1965.865], eps: 0.975})
Step:   66200, Reward: [-1010.592 -1010.592 -1010.592] [410.256], Avg: [-756.835 -756.835 -756.835] (0.9752) ({r_i: None, r_t: [-1959.811 -1959.811 -1959.811], eps: 0.975})
Step:   66300, Reward: [-1017.533 -1017.533 -1017.533] [294.598], Avg: [-757.227 -757.227 -757.227] (0.9752) ({r_i: None, r_t: [-1897.458 -1897.458 -1897.458], eps: 0.975})
Step:   66400, Reward: [-1006.300 -1006.300 -1006.300] [330.952], Avg: [-757.602 -757.602 -757.602] (0.9752) ({r_i: None, r_t: [-1955.279 -1955.279 -1955.279], eps: 0.975})
Step:   66500, Reward: [-969.904 -969.904 -969.904] [436.767], Avg: [-757.921 -757.921 -757.921] (0.9752) ({r_i: None, r_t: [-1995.999 -1995.999 -1995.999], eps: 0.975})
Step:   66600, Reward: [-859.145 -859.145 -859.145] [301.675], Avg: [-758.072 -758.072 -758.072] (0.9752) ({r_i: None, r_t: [-1804.178 -1804.178 -1804.178], eps: 0.975})
Step:   66700, Reward: [-995.361 -995.361 -995.361] [389.409], Avg: [-758.428 -758.428 -758.428] (0.9752) ({r_i: None, r_t: [-1833.710 -1833.710 -1833.710], eps: 0.975})
Step:   66800, Reward: [-1011.756 -1011.756 -1011.756] [355.764], Avg: [-758.806 -758.806 -758.806] (0.9752) ({r_i: None, r_t: [-1912.722 -1912.722 -1912.722], eps: 0.975})
Step:   66900, Reward: [-920.456 -920.456 -920.456] [302.577], Avg: [-759.048 -759.048 -759.048] (0.9752) ({r_i: None, r_t: [-1947.996 -1947.996 -1947.996], eps: 0.975})
Step:   67000, Reward: [-963.951 -963.951 -963.951] [355.301], Avg: [-759.353 -759.353 -759.353] (0.9752) ({r_i: None, r_t: [-1914.646 -1914.646 -1914.646], eps: 0.975})
Step:   67100, Reward: [-1014.835 -1014.835 -1014.835] [370.901], Avg: [-759.733 -759.733 -759.733] (0.9752) ({r_i: None, r_t: [-1997.180 -1997.180 -1997.180], eps: 0.975})
Step:   67200, Reward: [-785.876 -785.876 -785.876] [242.007], Avg: [-759.772 -759.772 -759.772] (0.9752) ({r_i: None, r_t: [-1859.746 -1859.746 -1859.746], eps: 0.975})
Step:   67300, Reward: [-814.423 -814.423 -814.423] [317.097], Avg: [-759.853 -759.853 -759.853] (0.9752) ({r_i: None, r_t: [-1889.246 -1889.246 -1889.246], eps: 0.975})
Step:   67400, Reward: [-868.916 -868.916 -868.916] [473.321], Avg: [-760.015 -760.015 -760.015] (0.9752) ({r_i: None, r_t: [-1894.673 -1894.673 -1894.673], eps: 0.975})
Step:   67500, Reward: [-910.731 -910.731 -910.731] [316.561], Avg: [-760.238 -760.238 -760.238] (0.9752) ({r_i: None, r_t: [-1860.637 -1860.637 -1860.637], eps: 0.975})
Step:   67600, Reward: [-980.858 -980.858 -980.858] [303.784], Avg: [-760.564 -760.564 -760.564] (0.9752) ({r_i: None, r_t: [-1852.641 -1852.641 -1852.641], eps: 0.975})
Step:   67700, Reward: [-930.909 -930.909 -930.909] [327.348], Avg: [-760.815 -760.815 -760.815] (0.9752) ({r_i: None, r_t: [-1854.794 -1854.794 -1854.794], eps: 0.975})
Step:   67800, Reward: [-743.289 -743.289 -743.289] [237.586], Avg: [-760.789 -760.789 -760.789] (0.9752) ({r_i: None, r_t: [-1975.850 -1975.850 -1975.850], eps: 0.975})
Step:   67900, Reward: [-828.749 -828.749 -828.749] [331.482], Avg: [-760.889 -760.889 -760.889] (0.9752) ({r_i: None, r_t: [-1505.532 -1505.532 -1505.532], eps: 0.975})
Step:   68000, Reward: [-903.162 -903.162 -903.162] [326.594], Avg: [-761.098 -761.098 -761.098] (0.9752) ({r_i: None, r_t: [-1673.006 -1673.006 -1673.006], eps: 0.975})
Step:   68100, Reward: [-929.559 -929.559 -929.559] [401.212], Avg: [-761.345 -761.345 -761.345] (0.9752) ({r_i: None, r_t: [-1699.595 -1699.595 -1699.595], eps: 0.975})
Step:   68200, Reward: [-917.398 -917.398 -917.398] [313.007], Avg: [-761.573 -761.573 -761.573] (0.9752) ({r_i: None, r_t: [-1812.712 -1812.712 -1812.712], eps: 0.975})
Step:   68300, Reward: [-980.975 -980.975 -980.975] [304.821], Avg: [-761.894 -761.894 -761.894] (0.9752) ({r_i: None, r_t: [-1766.617 -1766.617 -1766.617], eps: 0.975})
Step:   68400, Reward: [-839.448 -839.448 -839.448] [270.136], Avg: [-762.007 -762.007 -762.007] (0.9752) ({r_i: None, r_t: [-1748.929 -1748.929 -1748.929], eps: 0.975})
Step:   68500, Reward: [-919.503 -919.503 -919.503] [359.913], Avg: [-762.237 -762.237 -762.237] (0.9752) ({r_i: None, r_t: [-1667.953 -1667.953 -1667.953], eps: 0.975})
Step:   68600, Reward: [-910.577 -910.577 -910.577] [398.379], Avg: [-762.453 -762.453 -762.453] (0.9752) ({r_i: None, r_t: [-1673.770 -1673.770 -1673.770], eps: 0.975})
Step:   68700, Reward: [-1020.711 -1020.711 -1020.711] [345.241], Avg: [-762.828 -762.828 -762.828] (0.9752) ({r_i: None, r_t: [-1611.981 -1611.981 -1611.981], eps: 0.975})
Step:   68800, Reward: [-765.749 -765.749 -765.749] [358.251], Avg: [-762.832 -762.832 -762.832] (0.9752) ({r_i: None, r_t: [-1620.315 -1620.315 -1620.315], eps: 0.975})
Step:   68900, Reward: [-932.229 -932.229 -932.229] [300.990], Avg: [-763.078 -763.078 -763.078] (0.9752) ({r_i: None, r_t: [-1799.371 -1799.371 -1799.371], eps: 0.975})
Step:   69000, Reward: [-744.982 -744.982 -744.982] [265.401], Avg: [-763.052 -763.052 -763.052] (0.9752) ({r_i: None, r_t: [-1812.977 -1812.977 -1812.977], eps: 0.975})
Step:   69100, Reward: [-864.605 -864.605 -864.605] [348.666], Avg: [-763.198 -763.198 -763.198] (0.9752) ({r_i: None, r_t: [-1852.936 -1852.936 -1852.936], eps: 0.975})
Step:   69200, Reward: [-749.598 -749.598 -749.598] [247.650], Avg: [-763.179 -763.179 -763.179] (0.9752) ({r_i: None, r_t: [-1884.832 -1884.832 -1884.832], eps: 0.975})
Step:   69300, Reward: [-783.711 -783.711 -783.711] [220.015], Avg: [-763.208 -763.208 -763.208] (0.9752) ({r_i: None, r_t: [-1467.361 -1467.361 -1467.361], eps: 0.975})
Step:   69400, Reward: [-812.959 -812.959 -812.959] [221.611], Avg: [-763.280 -763.280 -763.280] (0.9752) ({r_i: None, r_t: [-1848.249 -1848.249 -1848.249], eps: 0.975})
Step:   69500, Reward: [-794.049 -794.049 -794.049] [350.816], Avg: [-763.324 -763.324 -763.324] (0.9752) ({r_i: None, r_t: [-1337.923 -1337.923 -1337.923], eps: 0.975})
Step:   69600, Reward: [-698.233 -698.233 -698.233] [240.534], Avg: [-763.231 -763.231 -763.231] (0.9752) ({r_i: None, r_t: [-1735.572 -1735.572 -1735.572], eps: 0.975})
Step:   69700, Reward: [-897.325 -897.325 -897.325] [364.526], Avg: [-763.423 -763.423 -763.423] (0.9752) ({r_i: None, r_t: [-1715.756 -1715.756 -1715.756], eps: 0.975})
Step:   69800, Reward: [-787.117 -787.117 -787.117] [432.597], Avg: [-763.457 -763.457 -763.457] (0.9752) ({r_i: None, r_t: [-1655.411 -1655.411 -1655.411], eps: 0.975})
Step:   69900, Reward: [-779.801 -779.801 -779.801] [271.431], Avg: [-763.480 -763.480 -763.480] (0.9752) ({r_i: None, r_t: [-1783.377 -1783.377 -1783.377], eps: 0.975})
Step:   70000, Reward: [-822.349 -822.349 -822.349] [275.210], Avg: [-763.564 -763.564 -763.564] (0.9752) ({r_i: None, r_t: [-1649.395 -1649.395 -1649.395], eps: 0.975})
Step:   70100, Reward: [-743.606 -743.606 -743.606] [184.513], Avg: [-763.536 -763.536 -763.536] (0.9704) ({r_i: None, r_t: [-1603.024 -1603.024 -1603.024], eps: 0.97})
Step:   70200, Reward: [-736.863 -736.863 -736.863] [211.194], Avg: [-763.498 -763.498 -763.498] (0.9704) ({r_i: None, r_t: [-1630.942 -1630.942 -1630.942], eps: 0.97})
Step:   70300, Reward: [-836.967 -836.967 -836.967] [393.845], Avg: [-763.602 -763.602 -763.602] (0.9704) ({r_i: None, r_t: [-1698.714 -1698.714 -1698.714], eps: 0.97})
Step:   70400, Reward: [-713.013 -713.013 -713.013] [214.033], Avg: [-763.530 -763.530 -763.530] (0.9704) ({r_i: None, r_t: [-1741.746 -1741.746 -1741.746], eps: 0.97})
Step:   70500, Reward: [-647.689 -647.689 -647.689] [276.686], Avg: [-763.366 -763.366 -763.366] (0.9704) ({r_i: None, r_t: [-1315.510 -1315.510 -1315.510], eps: 0.97})
Step:   70600, Reward: [-667.767 -667.767 -667.767] [160.379], Avg: [-763.231 -763.231 -763.231] (0.9704) ({r_i: None, r_t: [-1625.021 -1625.021 -1625.021], eps: 0.97})
Step:   70700, Reward: [-679.591 -679.591 -679.591] [179.034], Avg: [-763.113 -763.113 -763.113] (0.9704) ({r_i: None, r_t: [-1522.171 -1522.171 -1522.171], eps: 0.97})
Step:   70800, Reward: [-746.640 -746.640 -746.640] [272.067], Avg: [-763.090 -763.090 -763.090] (0.9704) ({r_i: None, r_t: [-1543.948 -1543.948 -1543.948], eps: 0.97})
Step:   70900, Reward: [-845.646 -845.646 -845.646] [351.478], Avg: [-763.206 -763.206 -763.206] (0.9704) ({r_i: None, r_t: [-1617.233 -1617.233 -1617.233], eps: 0.97})
Step:   71000, Reward: [-728.734 -728.734 -728.734] [199.133], Avg: [-763.158 -763.158 -763.158] (0.9704) ({r_i: None, r_t: [-1334.929 -1334.929 -1334.929], eps: 0.97})
Step:   71100, Reward: [-809.588 -809.588 -809.588] [292.509], Avg: [-763.223 -763.223 -763.223] (0.9704) ({r_i: None, r_t: [-1496.144 -1496.144 -1496.144], eps: 0.97})
Step:   71200, Reward: [-685.318 -685.318 -685.318] [133.812], Avg: [-763.113 -763.113 -763.113] (0.9704) ({r_i: None, r_t: [-1456.572 -1456.572 -1456.572], eps: 0.97})
Step:   71300, Reward: [-744.088 -744.088 -744.088] [231.979], Avg: [-763.087 -763.087 -763.087] (0.9704) ({r_i: None, r_t: [-1573.261 -1573.261 -1573.261], eps: 0.97})
Step:   71400, Reward: [-694.910 -694.910 -694.910] [227.708], Avg: [-762.991 -762.991 -762.991] (0.9704) ({r_i: None, r_t: [-1531.532 -1531.532 -1531.532], eps: 0.97})
Step:   71500, Reward: [-731.307 -731.307 -731.307] [193.272], Avg: [-762.947 -762.947 -762.947] (0.9704) ({r_i: None, r_t: [-1455.726 -1455.726 -1455.726], eps: 0.97})
Step:   71600, Reward: [-624.517 -624.517 -624.517] [152.959], Avg: [-762.754 -762.754 -762.754] (0.9704) ({r_i: None, r_t: [-1470.304 -1470.304 -1470.304], eps: 0.97})
Step:   71700, Reward: [-726.574 -726.574 -726.574] [245.297], Avg: [-762.704 -762.704 -762.704] (0.9704) ({r_i: None, r_t: [-1400.214 -1400.214 -1400.214], eps: 0.97})
Step:   71800, Reward: [-693.542 -693.542 -693.542] [206.100], Avg: [-762.608 -762.608 -762.608] (0.9704) ({r_i: None, r_t: [-1288.209 -1288.209 -1288.209], eps: 0.97})
Step:   71900, Reward: [-727.913 -727.913 -727.913] [214.589], Avg: [-762.559 -762.559 -762.559] (0.9704) ({r_i: None, r_t: [-1356.180 -1356.180 -1356.180], eps: 0.97})
Step:   72000, Reward: [-747.427 -747.427 -747.427] [210.962], Avg: [-762.538 -762.538 -762.538] (0.9704) ({r_i: None, r_t: [-1445.133 -1445.133 -1445.133], eps: 0.97})
Step:   72100, Reward: [-685.117 -685.117 -685.117] [228.190], Avg: [-762.431 -762.431 -762.431] (0.9704) ({r_i: None, r_t: [-1369.926 -1369.926 -1369.926], eps: 0.97})
Step:   72200, Reward: [-654.871 -654.871 -654.871] [182.911], Avg: [-762.282 -762.282 -762.282] (0.9704) ({r_i: None, r_t: [-1349.643 -1349.643 -1349.643], eps: 0.97})
Step:   72300, Reward: [-658.812 -658.812 -658.812] [184.299], Avg: [-762.139 -762.139 -762.139] (0.9704) ({r_i: None, r_t: [-1413.376 -1413.376 -1413.376], eps: 0.97})
Step:   72400, Reward: [-662.069 -662.069 -662.069] [135.266], Avg: [-762.001 -762.001 -762.001] (0.9704) ({r_i: None, r_t: [-1347.367 -1347.367 -1347.367], eps: 0.97})
Step:   72500, Reward: [-637.261 -637.261 -637.261] [163.899], Avg: [-761.830 -761.830 -761.830] (0.9704) ({r_i: None, r_t: [-1339.532 -1339.532 -1339.532], eps: 0.97})
Step:   72600, Reward: [-710.133 -710.133 -710.133] [182.644], Avg: [-761.759 -761.759 -761.759] (0.9704) ({r_i: None, r_t: [-1380.095 -1380.095 -1380.095], eps: 0.97})
Step:   72700, Reward: [-698.705 -698.705 -698.705] [221.706], Avg: [-761.672 -761.672 -761.672] (0.9704) ({r_i: None, r_t: [-1360.267 -1360.267 -1360.267], eps: 0.97})
Step:   72800, Reward: [-697.045 -697.045 -697.045] [139.685], Avg: [-761.583 -761.583 -761.583] (0.9704) ({r_i: None, r_t: [-1250.710 -1250.710 -1250.710], eps: 0.97})
Step:   72900, Reward: [-710.216 -710.216 -710.216] [194.248], Avg: [-761.513 -761.513 -761.513] (0.9704) ({r_i: None, r_t: [-1419.982 -1419.982 -1419.982], eps: 0.97})
Step:   73000, Reward: [-632.500 -632.500 -632.500] [154.375], Avg: [-761.336 -761.336 -761.336] (0.9704) ({r_i: None, r_t: [-1305.409 -1305.409 -1305.409], eps: 0.97})
Step:   73100, Reward: [-652.294 -652.294 -652.294] [196.368], Avg: [-761.187 -761.187 -761.187] (0.9704) ({r_i: None, r_t: [-1207.321 -1207.321 -1207.321], eps: 0.97})
Step:   73200, Reward: [-625.058 -625.058 -625.058] [156.582], Avg: [-761.002 -761.002 -761.002] (0.9704) ({r_i: None, r_t: [-1327.727 -1327.727 -1327.727], eps: 0.97})
Step:   73300, Reward: [-591.324 -591.324 -591.324] [131.249], Avg: [-760.771 -760.771 -760.771] (0.9704) ({r_i: None, r_t: [-1318.489 -1318.489 -1318.489], eps: 0.97})
Step:   73400, Reward: [-663.725 -663.725 -663.725] [197.197], Avg: [-760.639 -760.639 -760.639] (0.9704) ({r_i: None, r_t: [-1304.373 -1304.373 -1304.373], eps: 0.97})
Step:   73500, Reward: [-673.049 -673.049 -673.049] [172.462], Avg: [-760.520 -760.520 -760.520] (0.9704) ({r_i: None, r_t: [-1199.086 -1199.086 -1199.086], eps: 0.97})
Step:   73600, Reward: [-682.166 -682.166 -682.166] [157.826], Avg: [-760.413 -760.413 -760.413] (0.9704) ({r_i: None, r_t: [-1282.325 -1282.325 -1282.325], eps: 0.97})
Step:   73700, Reward: [-654.060 -654.060 -654.060] [143.918], Avg: [-760.269 -760.269 -760.269] (0.9704) ({r_i: None, r_t: [-1250.822 -1250.822 -1250.822], eps: 0.97})
Step:   73800, Reward: [-640.724 -640.724 -640.724] [146.444], Avg: [-760.107 -760.107 -760.107] (0.9704) ({r_i: None, r_t: [-1295.487 -1295.487 -1295.487], eps: 0.97})
Step:   73900, Reward: [-581.648 -581.648 -581.648] [152.288], Avg: [-759.866 -759.866 -759.866] (0.9704) ({r_i: None, r_t: [-1329.247 -1329.247 -1329.247], eps: 0.97})
Step:   74000, Reward: [-643.709 -643.709 -643.709] [155.200], Avg: [-759.709 -759.709 -759.709] (0.9704) ({r_i: None, r_t: [-1352.983 -1352.983 -1352.983], eps: 0.97})
Step:   74100, Reward: [-578.164 -578.164 -578.164] [151.317], Avg: [-759.465 -759.465 -759.465] (0.9704) ({r_i: None, r_t: [-1297.420 -1297.420 -1297.420], eps: 0.97})
Step:   74200, Reward: [-688.567 -688.567 -688.567] [181.821], Avg: [-759.369 -759.369 -759.369] (0.9704) ({r_i: None, r_t: [-1296.993 -1296.993 -1296.993], eps: 0.97})
Step:   74300, Reward: [-642.343 -642.343 -642.343] [130.472], Avg: [-759.212 -759.212 -759.212] (0.9704) ({r_i: None, r_t: [-1263.352 -1263.352 -1263.352], eps: 0.97})
Step:   74400, Reward: [-657.760 -657.760 -657.760] [135.376], Avg: [-759.076 -759.076 -759.076] (0.9704) ({r_i: None, r_t: [-1213.434 -1213.434 -1213.434], eps: 0.97})
Step:   74500, Reward: [-588.057 -588.057 -588.057] [178.991], Avg: [-758.847 -758.847 -758.847] (0.9704) ({r_i: None, r_t: [-1227.896 -1227.896 -1227.896], eps: 0.97})
Step:   74600, Reward: [-643.684 -643.684 -643.684] [108.007], Avg: [-758.692 -758.692 -758.692] (0.9704) ({r_i: None, r_t: [-1314.717 -1314.717 -1314.717], eps: 0.97})
Step:   74700, Reward: [-677.638 -677.638 -677.638] [147.857], Avg: [-758.584 -758.584 -758.584] (0.9704) ({r_i: None, r_t: [-1235.515 -1235.515 -1235.515], eps: 0.97})
Step:   74800, Reward: [-656.157 -656.157 -656.157] [161.804], Avg: [-758.447 -758.447 -758.447] (0.9704) ({r_i: None, r_t: [-1283.388 -1283.388 -1283.388], eps: 0.97})
Step:   74900, Reward: [-565.301 -565.301 -565.301] [122.991], Avg: [-758.190 -758.190 -758.190] (0.9704) ({r_i: None, r_t: [-1201.515 -1201.515 -1201.515], eps: 0.97})
Step:   75000, Reward: [-585.556 -585.556 -585.556] [108.460], Avg: [-757.960 -757.960 -757.960] (0.9704) ({r_i: None, r_t: [-1234.301 -1234.301 -1234.301], eps: 0.97})
Step:   75100, Reward: [-664.982 -664.982 -664.982] [121.463], Avg: [-757.836 -757.836 -757.836] (0.9704) ({r_i: None, r_t: [-1301.648 -1301.648 -1301.648], eps: 0.97})
Step:   75200, Reward: [-660.366 -660.366 -660.366] [153.950], Avg: [-757.707 -757.707 -757.707] (0.9704) ({r_i: None, r_t: [-1287.308 -1287.308 -1287.308], eps: 0.97})
Step:   75300, Reward: [-570.823 -570.823 -570.823] [133.722], Avg: [-757.459 -757.459 -757.459] (0.9704) ({r_i: None, r_t: [-1186.431 -1186.431 -1186.431], eps: 0.97})
Step:   75400, Reward: [-546.487 -546.487 -546.487] [113.467], Avg: [-757.180 -757.180 -757.180] (0.9704) ({r_i: None, r_t: [-1265.626 -1265.626 -1265.626], eps: 0.97})
Step:   75500, Reward: [-588.975 -588.975 -588.975] [138.927], Avg: [-756.957 -756.957 -756.957] (0.9704) ({r_i: None, r_t: [-1245.075 -1245.075 -1245.075], eps: 0.97})
Step:   75600, Reward: [-563.557 -563.557 -563.557] [116.642], Avg: [-756.702 -756.702 -756.702] (0.9704) ({r_i: None, r_t: [-1258.401 -1258.401 -1258.401], eps: 0.97})
Step:   75700, Reward: [-621.502 -621.502 -621.502] [173.154], Avg: [-756.523 -756.523 -756.523] (0.9704) ({r_i: None, r_t: [-1225.362 -1225.362 -1225.362], eps: 0.97})
Step:   75800, Reward: [-526.879 -526.879 -526.879] [94.931], Avg: [-756.221 -756.221 -756.221] (0.9704) ({r_i: None, r_t: [-1228.980 -1228.980 -1228.980], eps: 0.97})
Step:   75900, Reward: [-637.409 -637.409 -637.409] [134.391], Avg: [-756.064 -756.064 -756.064] (0.9704) ({r_i: None, r_t: [-1227.279 -1227.279 -1227.279], eps: 0.97})
Step:   76000, Reward: [-583.508 -583.508 -583.508] [211.568], Avg: [-755.838 -755.838 -755.838] (0.9704) ({r_i: None, r_t: [-1225.630 -1225.630 -1225.630], eps: 0.97})
Step:   76100, Reward: [-627.962 -627.962 -627.962] [92.718], Avg: [-755.670 -755.670 -755.670] (0.9704) ({r_i: None, r_t: [-1190.256 -1190.256 -1190.256], eps: 0.97})
Step:   76200, Reward: [-655.070 -655.070 -655.070] [79.296], Avg: [-755.538 -755.538 -755.538] (0.9704) ({r_i: None, r_t: [-1292.007 -1292.007 -1292.007], eps: 0.97})
Step:   76300, Reward: [-634.294 -634.294 -634.294] [123.427], Avg: [-755.379 -755.379 -755.379] (0.9704) ({r_i: None, r_t: [-1256.578 -1256.578 -1256.578], eps: 0.97})
Step:   76400, Reward: [-608.140 -608.140 -608.140] [135.107], Avg: [-755.187 -755.187 -755.187] (0.9704) ({r_i: None, r_t: [-1311.127 -1311.127 -1311.127], eps: 0.97})
Step:   76500, Reward: [-616.221 -616.221 -616.221] [114.948], Avg: [-755.005 -755.005 -755.005] (0.9704) ({r_i: None, r_t: [-1192.059 -1192.059 -1192.059], eps: 0.97})
Step:   76600, Reward: [-606.590 -606.590 -606.590] [97.210], Avg: [-754.812 -754.812 -754.812] (0.9704) ({r_i: None, r_t: [-1280.517 -1280.517 -1280.517], eps: 0.97})
Step:   76700, Reward: [-607.863 -607.863 -607.863] [121.870], Avg: [-754.620 -754.620 -754.620] (0.9704) ({r_i: None, r_t: [-1212.008 -1212.008 -1212.008], eps: 0.97})
Step:   76800, Reward: [-601.712 -601.712 -601.712] [170.043], Avg: [-754.422 -754.422 -754.422] (0.9704) ({r_i: None, r_t: [-1205.112 -1205.112 -1205.112], eps: 0.97})
Step:   76900, Reward: [-589.148 -589.148 -589.148] [132.691], Avg: [-754.207 -754.207 -754.207] (0.9704) ({r_i: None, r_t: [-1182.823 -1182.823 -1182.823], eps: 0.97})
Step:   77000, Reward: [-582.753 -582.753 -582.753] [140.947], Avg: [-753.985 -753.985 -753.985] (0.9704) ({r_i: None, r_t: [-1225.967 -1225.967 -1225.967], eps: 0.97})
Step:   77100, Reward: [-560.138 -560.138 -560.138] [83.791], Avg: [-753.734 -753.734 -753.734] (0.9704) ({r_i: None, r_t: [-1145.466 -1145.466 -1145.466], eps: 0.97})
Step:   77200, Reward: [-559.333 -559.333 -559.333] [126.478], Avg: [-753.482 -753.482 -753.482] (0.9704) ({r_i: None, r_t: [-1187.083 -1187.083 -1187.083], eps: 0.97})
Step:   77300, Reward: [-580.690 -580.690 -580.690] [136.626], Avg: [-753.259 -753.259 -753.259] (0.9704) ({r_i: None, r_t: [-1198.588 -1198.588 -1198.588], eps: 0.97})
Step:   77400, Reward: [-641.634 -641.634 -641.634] [137.710], Avg: [-753.115 -753.115 -753.115] (0.9704) ({r_i: None, r_t: [-1183.620 -1183.620 -1183.620], eps: 0.97})
Step:   77500, Reward: [-604.946 -604.946 -604.946] [125.592], Avg: [-752.924 -752.924 -752.924] (0.9704) ({r_i: None, r_t: [-1282.512 -1282.512 -1282.512], eps: 0.97})
Step:   77600, Reward: [-567.360 -567.360 -567.360] [120.696], Avg: [-752.685 -752.685 -752.685] (0.9704) ({r_i: None, r_t: [-1261.372 -1261.372 -1261.372], eps: 0.97})
Step:   77700, Reward: [-565.809 -565.809 -565.809] [110.502], Avg: [-752.445 -752.445 -752.445] (0.9704) ({r_i: None, r_t: [-1208.250 -1208.250 -1208.250], eps: 0.97})
Step:   77800, Reward: [-615.763 -615.763 -615.763] [131.049], Avg: [-752.269 -752.269 -752.269] (0.9704) ({r_i: None, r_t: [-1184.400 -1184.400 -1184.400], eps: 0.97})
Step:   77900, Reward: [-588.798 -588.798 -588.798] [127.388], Avg: [-752.060 -752.060 -752.060] (0.9704) ({r_i: None, r_t: [-1160.847 -1160.847 -1160.847], eps: 0.97})
Step:   78000, Reward: [-637.368 -637.368 -637.368] [128.407], Avg: [-751.913 -751.913 -751.913] (0.9704) ({r_i: None, r_t: [-1261.012 -1261.012 -1261.012], eps: 0.97})
Step:   78100, Reward: [-653.729 -653.729 -653.729] [99.659], Avg: [-751.787 -751.787 -751.787] (0.9704) ({r_i: None, r_t: [-1177.781 -1177.781 -1177.781], eps: 0.97})
Step:   78200, Reward: [-589.927 -589.927 -589.927] [122.003], Avg: [-751.581 -751.581 -751.581] (0.9704) ({r_i: None, r_t: [-1262.108 -1262.108 -1262.108], eps: 0.97})
Step:   78300, Reward: [-629.367 -629.367 -629.367] [152.654], Avg: [-751.425 -751.425 -751.425] (0.9704) ({r_i: None, r_t: [-1228.362 -1228.362 -1228.362], eps: 0.97})
Step:   78400, Reward: [-590.968 -590.968 -590.968] [106.465], Avg: [-751.220 -751.220 -751.220] (0.9704) ({r_i: None, r_t: [-1231.232 -1231.232 -1231.232], eps: 0.97})
Step:   78500, Reward: [-562.517 -562.517 -562.517] [160.713], Avg: [-750.980 -750.980 -750.980] (0.9704) ({r_i: None, r_t: [-1184.694 -1184.694 -1184.694], eps: 0.97})
Step:   78600, Reward: [-554.729 -554.729 -554.729] [121.523], Avg: [-750.731 -750.731 -750.731] (0.9704) ({r_i: None, r_t: [-1214.228 -1214.228 -1214.228], eps: 0.97})
Step:   78700, Reward: [-568.750 -568.750 -568.750] [128.944], Avg: [-750.500 -750.500 -750.500] (0.9704) ({r_i: None, r_t: [-1234.818 -1234.818 -1234.818], eps: 0.97})
Step:   78800, Reward: [-615.075 -615.075 -615.075] [120.880], Avg: [-750.328 -750.328 -750.328] (0.9704) ({r_i: None, r_t: [-1251.272 -1251.272 -1251.272], eps: 0.97})
Step:   78900, Reward: [-589.810 -589.810 -589.810] [133.453], Avg: [-750.125 -750.125 -750.125] (0.9704) ({r_i: None, r_t: [-1269.644 -1269.644 -1269.644], eps: 0.97})
Step:   79000, Reward: [-585.628 -585.628 -585.628] [107.222], Avg: [-749.917 -749.917 -749.917] (0.9704) ({r_i: None, r_t: [-1308.109 -1308.109 -1308.109], eps: 0.97})
Step:   79100, Reward: [-644.965 -644.965 -644.965] [180.045], Avg: [-749.785 -749.785 -749.785] (0.9704) ({r_i: None, r_t: [-1176.327 -1176.327 -1176.327], eps: 0.97})
Step:   79200, Reward: [-536.126 -536.126 -536.126] [118.551], Avg: [-749.515 -749.515 -749.515] (0.9704) ({r_i: None, r_t: [-1219.251 -1219.251 -1219.251], eps: 0.97})
Step:   79300, Reward: [-633.189 -633.189 -633.189] [90.485], Avg: [-749.369 -749.369 -749.369] (0.9704) ({r_i: None, r_t: [-1260.954 -1260.954 -1260.954], eps: 0.97})
Step:   79400, Reward: [-579.260 -579.260 -579.260] [103.114], Avg: [-749.155 -749.155 -749.155] (0.9704) ({r_i: None, r_t: [-1183.142 -1183.142 -1183.142], eps: 0.97})
Step:   79500, Reward: [-556.673 -556.673 -556.673] [113.056], Avg: [-748.913 -748.913 -748.913] (0.9704) ({r_i: None, r_t: [-1149.386 -1149.386 -1149.386], eps: 0.97})
Step:   79600, Reward: [-561.420 -561.420 -561.420] [148.163], Avg: [-748.678 -748.678 -748.678] (0.9704) ({r_i: None, r_t: [-1169.795 -1169.795 -1169.795], eps: 0.97})
Step:   79700, Reward: [-609.694 -609.694 -609.694] [154.083], Avg: [-748.504 -748.504 -748.504] (0.9704) ({r_i: None, r_t: [-1137.014 -1137.014 -1137.014], eps: 0.97})
Step:   79800, Reward: [-606.172 -606.172 -606.172] [134.742], Avg: [-748.325 -748.325 -748.325] (0.9704) ({r_i: None, r_t: [-1133.028 -1133.028 -1133.028], eps: 0.97})
Step:   79900, Reward: [-645.009 -645.009 -645.009] [121.288], Avg: [-748.196 -748.196 -748.196] (0.9704) ({r_i: None, r_t: [-1181.088 -1181.088 -1181.088], eps: 0.97})
Step:   80000, Reward: [-584.131 -584.131 -584.131] [124.226], Avg: [-747.991 -747.991 -747.991] (0.9704) ({r_i: None, r_t: [-1284.257 -1284.257 -1284.257], eps: 0.97})
Step:   80100, Reward: [-591.889 -591.889 -591.889] [103.047], Avg: [-747.797 -747.797 -747.797] (0.9704) ({r_i: None, r_t: [-1203.274 -1203.274 -1203.274], eps: 0.97})
Step:   80200, Reward: [-598.651 -598.651 -598.651] [128.919], Avg: [-747.611 -747.611 -747.611] (0.9704) ({r_i: None, r_t: [-1162.146 -1162.146 -1162.146], eps: 0.97})
Step:   80300, Reward: [-594.804 -594.804 -594.804] [114.513], Avg: [-747.421 -747.421 -747.421] (0.9704) ({r_i: None, r_t: [-1210.411 -1210.411 -1210.411], eps: 0.97})
Step:   80400, Reward: [-571.570 -571.570 -571.570] [133.644], Avg: [-747.203 -747.203 -747.203] (0.9704) ({r_i: None, r_t: [-1155.967 -1155.967 -1155.967], eps: 0.97})
Step:   80500, Reward: [-591.476 -591.476 -591.476] [124.850], Avg: [-747.009 -747.009 -747.009] (0.9704) ({r_i: None, r_t: [-1154.870 -1154.870 -1154.870], eps: 0.97})
Step:   80600, Reward: [-569.282 -569.282 -569.282] [138.739], Avg: [-746.789 -746.789 -746.789] (0.9704) ({r_i: None, r_t: [-1225.892 -1225.892 -1225.892], eps: 0.97})
Step:   80700, Reward: [-608.705 -608.705 -608.705] [168.443], Avg: [-746.618 -746.618 -746.618] (0.9704) ({r_i: None, r_t: [-1240.583 -1240.583 -1240.583], eps: 0.97})
Step:   80800, Reward: [-579.321 -579.321 -579.321] [114.460], Avg: [-746.411 -746.411 -746.411] (0.9704) ({r_i: None, r_t: [-1254.191 -1254.191 -1254.191], eps: 0.97})
Step:   80900, Reward: [-574.083 -574.083 -574.083] [168.113], Avg: [-746.199 -746.199 -746.199] (0.9704) ({r_i: None, r_t: [-1183.856 -1183.856 -1183.856], eps: 0.97})
Step:   81000, Reward: [-591.370 -591.370 -591.370] [110.770], Avg: [-746.008 -746.008 -746.008] (0.9704) ({r_i: None, r_t: [-1201.152 -1201.152 -1201.152], eps: 0.97})
Step:   81100, Reward: [-557.929 -557.929 -557.929] [108.685], Avg: [-745.776 -745.776 -745.776] (0.9704) ({r_i: None, r_t: [-1165.890 -1165.890 -1165.890], eps: 0.97})
Step:   81200, Reward: [-599.662 -599.662 -599.662] [134.045], Avg: [-745.596 -745.596 -745.596] (0.9704) ({r_i: None, r_t: [-1185.929 -1185.929 -1185.929], eps: 0.97})
Step:   81300, Reward: [-615.146 -615.146 -615.146] [136.056], Avg: [-745.436 -745.436 -745.436] (0.9704) ({r_i: None, r_t: [-1213.898 -1213.898 -1213.898], eps: 0.97})
Step:   81400, Reward: [-593.316 -593.316 -593.316] [156.483], Avg: [-745.249 -745.249 -745.249] (0.9704) ({r_i: None, r_t: [-1200.100 -1200.100 -1200.100], eps: 0.97})
Step:   81500, Reward: [-600.079 -600.079 -600.079] [111.296], Avg: [-745.072 -745.072 -745.072] (0.9704) ({r_i: None, r_t: [-1166.256 -1166.256 -1166.256], eps: 0.97})
Step:   81600, Reward: [-585.888 -585.888 -585.888] [92.004], Avg: [-744.877 -744.877 -744.877] (0.9704) ({r_i: None, r_t: [-1236.742 -1236.742 -1236.742], eps: 0.97})
Step:   81700, Reward: [-573.490 -573.490 -573.490] [98.501], Avg: [-744.667 -744.667 -744.667] (0.9704) ({r_i: None, r_t: [-1166.425 -1166.425 -1166.425], eps: 0.97})
Step:   81800, Reward: [-613.691 -613.691 -613.691] [151.683], Avg: [-744.507 -744.507 -744.507] (0.9704) ({r_i: None, r_t: [-1218.359 -1218.359 -1218.359], eps: 0.97})
Step:   81900, Reward: [-598.403 -598.403 -598.403] [143.849], Avg: [-744.329 -744.329 -744.329] (0.9704) ({r_i: None, r_t: [-1152.303 -1152.303 -1152.303], eps: 0.97})
Step:   82000, Reward: [-578.241 -578.241 -578.241] [105.566], Avg: [-744.127 -744.127 -744.127] (0.9704) ({r_i: None, r_t: [-1158.890 -1158.890 -1158.890], eps: 0.97})
Step:   82100, Reward: [-632.156 -632.156 -632.156] [142.602], Avg: [-743.991 -743.991 -743.991] (0.9704) ({r_i: None, r_t: [-1123.685 -1123.685 -1123.685], eps: 0.97})
Step:   82200, Reward: [-594.575 -594.575 -594.575] [75.487], Avg: [-743.809 -743.809 -743.809] (0.9704) ({r_i: None, r_t: [-1174.312 -1174.312 -1174.312], eps: 0.97})
Step:   82300, Reward: [-582.783 -582.783 -582.783] [91.652], Avg: [-743.614 -743.614 -743.614] (0.9704) ({r_i: None, r_t: [-1159.698 -1159.698 -1159.698], eps: 0.97})
Step:   82400, Reward: [-626.031 -626.031 -626.031] [132.165], Avg: [-743.471 -743.471 -743.471] (0.9704) ({r_i: None, r_t: [-1178.985 -1178.985 -1178.985], eps: 0.97})
Step:   82500, Reward: [-598.085 -598.085 -598.085] [114.976], Avg: [-743.295 -743.295 -743.295] (0.9704) ({r_i: None, r_t: [-1222.395 -1222.395 -1222.395], eps: 0.97})
Step:   82600, Reward: [-588.696 -588.696 -588.696] [155.376], Avg: [-743.108 -743.108 -743.108] (0.9655) ({r_i: None, r_t: [-1233.255 -1233.255 -1233.255], eps: 0.966})
Step:   82700, Reward: [-591.008 -591.008 -591.008] [152.617], Avg: [-742.924 -742.924 -742.924] (0.9655) ({r_i: None, r_t: [-1127.300 -1127.300 -1127.300], eps: 0.966})
Step:   82800, Reward: [-583.115 -583.115 -583.115] [122.089], Avg: [-742.732 -742.732 -742.732] (0.9655) ({r_i: None, r_t: [-1217.292 -1217.292 -1217.292], eps: 0.966})
Step:   82900, Reward: [-572.715 -572.715 -572.715] [112.822], Avg: [-742.527 -742.527 -742.527] (0.9655) ({r_i: None, r_t: [-1202.753 -1202.753 -1202.753], eps: 0.966})
Step:   83000, Reward: [-549.545 -549.545 -549.545] [124.240], Avg: [-742.295 -742.295 -742.295] (0.9655) ({r_i: None, r_t: [-1221.834 -1221.834 -1221.834], eps: 0.966})
Step:   83100, Reward: [-625.041 -625.041 -625.041] [157.272], Avg: [-742.154 -742.154 -742.154] (0.9655) ({r_i: None, r_t: [-1205.673 -1205.673 -1205.673], eps: 0.966})
Step:   83200, Reward: [-585.208 -585.208 -585.208] [108.239], Avg: [-741.965 -741.965 -741.965] (0.9655) ({r_i: None, r_t: [-1096.812 -1096.812 -1096.812], eps: 0.966})
Step:   83300, Reward: [-656.973 -656.973 -656.973] [161.069], Avg: [-741.863 -741.863 -741.863] (0.9655) ({r_i: None, r_t: [-1100.665 -1100.665 -1100.665], eps: 0.966})
Step:   83400, Reward: [-534.114 -534.114 -534.114] [112.065], Avg: [-741.615 -741.615 -741.615] (0.9655) ({r_i: None, r_t: [-1121.394 -1121.394 -1121.394], eps: 0.966})
Step:   83500, Reward: [-587.269 -587.269 -587.269] [130.970], Avg: [-741.430 -741.430 -741.430] (0.9655) ({r_i: None, r_t: [-1164.293 -1164.293 -1164.293], eps: 0.966})
Step:   83600, Reward: [-619.863 -619.863 -619.863] [108.195], Avg: [-741.285 -741.285 -741.285] (0.9655) ({r_i: None, r_t: [-1152.574 -1152.574 -1152.574], eps: 0.966})
Step:   83700, Reward: [-612.506 -612.506 -612.506] [144.298], Avg: [-741.131 -741.131 -741.131] (0.9655) ({r_i: None, r_t: [-1208.709 -1208.709 -1208.709], eps: 0.966})
Step:   83800, Reward: [-575.491 -575.491 -575.491] [169.828], Avg: [-740.934 -740.934 -740.934] (0.9655) ({r_i: None, r_t: [-1110.301 -1110.301 -1110.301], eps: 0.966})
Step:   83900, Reward: [-556.541 -556.541 -556.541] [164.528], Avg: [-740.714 -740.714 -740.714] (0.9655) ({r_i: None, r_t: [-1159.414 -1159.414 -1159.414], eps: 0.966})
Step:   84000, Reward: [-553.321 -553.321 -553.321] [133.924], Avg: [-740.491 -740.491 -740.491] (0.9655) ({r_i: None, r_t: [-1204.421 -1204.421 -1204.421], eps: 0.966})
Step:   84100, Reward: [-579.850 -579.850 -579.850] [107.348], Avg: [-740.300 -740.300 -740.300] (0.9655) ({r_i: None, r_t: [-1164.637 -1164.637 -1164.637], eps: 0.966})
Step:   84200, Reward: [-626.925 -626.925 -626.925] [165.375], Avg: [-740.166 -740.166 -740.166] (0.9655) ({r_i: None, r_t: [-1179.840 -1179.840 -1179.840], eps: 0.966})
Step:   84300, Reward: [-603.334 -603.334 -603.334] [134.461], Avg: [-740.004 -740.004 -740.004] (0.9655) ({r_i: None, r_t: [-1124.423 -1124.423 -1124.423], eps: 0.966})
Step:   84400, Reward: [-550.445 -550.445 -550.445] [114.147], Avg: [-739.780 -739.780 -739.780] (0.9655) ({r_i: None, r_t: [-1125.000 -1125.000 -1125.000], eps: 0.966})
Step:   84500, Reward: [-542.487 -542.487 -542.487] [115.325], Avg: [-739.546 -739.546 -739.546] (0.9655) ({r_i: None, r_t: [-1113.224 -1113.224 -1113.224], eps: 0.966})
Step:   84600, Reward: [-626.197 -626.197 -626.197] [123.793], Avg: [-739.413 -739.413 -739.413] (0.9655) ({r_i: None, r_t: [-1165.831 -1165.831 -1165.831], eps: 0.966})
Step:   84700, Reward: [-602.447 -602.447 -602.447] [114.340], Avg: [-739.251 -739.251 -739.251] (0.9655) ({r_i: None, r_t: [-1158.126 -1158.126 -1158.126], eps: 0.966})
Step:   84800, Reward: [-531.547 -531.547 -531.547] [58.911], Avg: [-739.006 -739.006 -739.006] (0.9655) ({r_i: None, r_t: [-1154.208 -1154.208 -1154.208], eps: 0.966})
Step:   84900, Reward: [-612.209 -612.209 -612.209] [96.058], Avg: [-738.857 -738.857 -738.857] (0.9655) ({r_i: None, r_t: [-1104.253 -1104.253 -1104.253], eps: 0.966})
Step:   85000, Reward: [-613.649 -613.649 -613.649] [156.244], Avg: [-738.710 -738.710 -738.710] (0.9655) ({r_i: None, r_t: [-1168.328 -1168.328 -1168.328], eps: 0.966})
Step:   85100, Reward: [-562.113 -562.113 -562.113] [114.446], Avg: [-738.503 -738.503 -738.503] (0.9655) ({r_i: None, r_t: [-1185.707 -1185.707 -1185.707], eps: 0.966})
Step:   85200, Reward: [-558.197 -558.197 -558.197] [101.844], Avg: [-738.291 -738.291 -738.291] (0.9655) ({r_i: None, r_t: [-1152.650 -1152.650 -1152.650], eps: 0.966})
Step:   85300, Reward: [-589.270 -589.270 -589.270] [86.143], Avg: [-738.117 -738.117 -738.117] (0.9655) ({r_i: None, r_t: [-1092.677 -1092.677 -1092.677], eps: 0.966})
Step:   85400, Reward: [-659.705 -659.705 -659.705] [170.002], Avg: [-738.025 -738.025 -738.025] (0.9655) ({r_i: None, r_t: [-1137.640 -1137.640 -1137.640], eps: 0.966})
Step:   85500, Reward: [-585.005 -585.005 -585.005] [105.996], Avg: [-737.846 -737.846 -737.846] (0.9655) ({r_i: None, r_t: [-1158.070 -1158.070 -1158.070], eps: 0.966})
Step:   85600, Reward: [-640.733 -640.733 -640.733] [101.347], Avg: [-737.733 -737.733 -737.733] (0.9655) ({r_i: None, r_t: [-1217.826 -1217.826 -1217.826], eps: 0.966})
Step:   85700, Reward: [-553.764 -553.764 -553.764] [127.467], Avg: [-737.519 -737.519 -737.519] (0.9655) ({r_i: None, r_t: [-1176.845 -1176.845 -1176.845], eps: 0.966})
Step:   85800, Reward: [-637.210 -637.210 -637.210] [176.499], Avg: [-737.402 -737.402 -737.402] (0.9655) ({r_i: None, r_t: [-1115.854 -1115.854 -1115.854], eps: 0.966})
Step:   85900, Reward: [-567.009 -567.009 -567.009] [81.845], Avg: [-737.204 -737.204 -737.204] (0.9655) ({r_i: None, r_t: [-1226.243 -1226.243 -1226.243], eps: 0.966})
Step:   86000, Reward: [-561.625 -561.625 -561.625] [113.027], Avg: [-737.000 -737.000 -737.000] (0.9655) ({r_i: None, r_t: [-1147.979 -1147.979 -1147.979], eps: 0.966})
Step:   86100, Reward: [-537.376 -537.376 -537.376] [84.657], Avg: [-736.768 -736.768 -736.768] (0.9655) ({r_i: None, r_t: [-1214.524 -1214.524 -1214.524], eps: 0.966})
Step:   86200, Reward: [-619.576 -619.576 -619.576] [127.640], Avg: [-736.632 -736.632 -736.632] (0.9655) ({r_i: None, r_t: [-1199.652 -1199.652 -1199.652], eps: 0.966})
Step:   86300, Reward: [-607.034 -607.034 -607.034] [109.437], Avg: [-736.482 -736.482 -736.482] (0.9655) ({r_i: None, r_t: [-1210.889 -1210.889 -1210.889], eps: 0.966})
Step:   86400, Reward: [-626.404 -626.404 -626.404] [182.184], Avg: [-736.355 -736.355 -736.355] (0.9655) ({r_i: None, r_t: [-1169.558 -1169.558 -1169.558], eps: 0.966})
Step:   86500, Reward: [-582.191 -582.191 -582.191] [110.762], Avg: [-736.177 -736.177 -736.177] (0.9655) ({r_i: None, r_t: [-1124.388 -1124.388 -1124.388], eps: 0.966})
Step:   86600, Reward: [-620.051 -620.051 -620.051] [122.329], Avg: [-736.043 -736.043 -736.043] (0.9655) ({r_i: None, r_t: [-1208.338 -1208.338 -1208.338], eps: 0.966})
Step:   86700, Reward: [-585.083 -585.083 -585.083] [126.451], Avg: [-735.869 -735.869 -735.869] (0.9655) ({r_i: None, r_t: [-1167.599 -1167.599 -1167.599], eps: 0.966})
Step:   86800, Reward: [-604.565 -604.565 -604.565] [133.673], Avg: [-735.718 -735.718 -735.718] (0.9655) ({r_i: None, r_t: [-1135.164 -1135.164 -1135.164], eps: 0.966})
Step:   86900, Reward: [-553.613 -553.613 -553.613] [109.818], Avg: [-735.509 -735.509 -735.509] (0.9655) ({r_i: None, r_t: [-1228.935 -1228.935 -1228.935], eps: 0.966})
Step:   87000, Reward: [-606.821 -606.821 -606.821] [119.369], Avg: [-735.361 -735.361 -735.361] (0.9655) ({r_i: None, r_t: [-1145.017 -1145.017 -1145.017], eps: 0.966})
Step:   87100, Reward: [-583.390 -583.390 -583.390] [168.550], Avg: [-735.187 -735.187 -735.187] (0.9655) ({r_i: None, r_t: [-1174.292 -1174.292 -1174.292], eps: 0.966})
Step:   87200, Reward: [-580.508 -580.508 -580.508] [119.820], Avg: [-735.010 -735.010 -735.010] (0.9655) ({r_i: None, r_t: [-1089.421 -1089.421 -1089.421], eps: 0.966})
Step:   87300, Reward: [-596.542 -596.542 -596.542] [160.047], Avg: [-734.851 -734.851 -734.851] (0.9655) ({r_i: None, r_t: [-1142.638 -1142.638 -1142.638], eps: 0.966})
Step:   87400, Reward: [-625.560 -625.560 -625.560] [127.061], Avg: [-734.726 -734.726 -734.726] (0.9655) ({r_i: None, r_t: [-1140.498 -1140.498 -1140.498], eps: 0.966})
Step:   87500, Reward: [-556.777 -556.777 -556.777] [127.129], Avg: [-734.523 -734.523 -734.523] (0.9655) ({r_i: None, r_t: [-1184.440 -1184.440 -1184.440], eps: 0.966})
Step:   87600, Reward: [-554.842 -554.842 -554.842] [151.309], Avg: [-734.318 -734.318 -734.318] (0.9655) ({r_i: None, r_t: [-1019.487 -1019.487 -1019.487], eps: 0.966})
Step:   87700, Reward: [-585.494 -585.494 -585.494] [112.340], Avg: [-734.149 -734.149 -734.149] (0.9655) ({r_i: None, r_t: [-1121.589 -1121.589 -1121.589], eps: 0.966})
Step:   87800, Reward: [-535.082 -535.082 -535.082] [125.749], Avg: [-733.922 -733.922 -733.922] (0.9655) ({r_i: None, r_t: [-1080.026 -1080.026 -1080.026], eps: 0.966})
Step:   87900, Reward: [-578.684 -578.684 -578.684] [115.985], Avg: [-733.746 -733.746 -733.746] (0.9655) ({r_i: None, r_t: [-1096.434 -1096.434 -1096.434], eps: 0.966})
Step:   88000, Reward: [-547.782 -547.782 -547.782] [102.966], Avg: [-733.535 -733.535 -733.535] (0.9655) ({r_i: None, r_t: [-1143.258 -1143.258 -1143.258], eps: 0.966})
Step:   88100, Reward: [-545.196 -545.196 -545.196] [157.156], Avg: [-733.321 -733.321 -733.321] (0.9655) ({r_i: None, r_t: [-1160.213 -1160.213 -1160.213], eps: 0.966})
Step:   88200, Reward: [-552.510 -552.510 -552.510] [76.972], Avg: [-733.117 -733.117 -733.117] (0.9655) ({r_i: None, r_t: [-1096.658 -1096.658 -1096.658], eps: 0.966})
Step:   88300, Reward: [-555.049 -555.049 -555.049] [141.217], Avg: [-732.915 -732.915 -732.915] (0.9655) ({r_i: None, r_t: [-1143.549 -1143.549 -1143.549], eps: 0.966})
Step:   88400, Reward: [-512.543 -512.543 -512.543] [88.250], Avg: [-732.666 -732.666 -732.666] (0.9655) ({r_i: None, r_t: [-1202.023 -1202.023 -1202.023], eps: 0.966})
Step:   88500, Reward: [-567.393 -567.393 -567.393] [88.506], Avg: [-732.480 -732.480 -732.480] (0.9655) ({r_i: None, r_t: [-1124.164 -1124.164 -1124.164], eps: 0.966})
Step:   88600, Reward: [-594.791 -594.791 -594.791] [127.664], Avg: [-732.324 -732.324 -732.324] (0.9655) ({r_i: None, r_t: [-1068.863 -1068.863 -1068.863], eps: 0.966})
Step:   88700, Reward: [-523.952 -523.952 -523.952] [115.467], Avg: [-732.090 -732.090 -732.090] (0.9655) ({r_i: None, r_t: [-1150.369 -1150.369 -1150.369], eps: 0.966})
Step:   88800, Reward: [-524.446 -524.446 -524.446] [119.114], Avg: [-731.856 -731.856 -731.856] (0.9655) ({r_i: None, r_t: [-1085.499 -1085.499 -1085.499], eps: 0.966})
Step:   88900, Reward: [-598.528 -598.528 -598.528] [99.617], Avg: [-731.706 -731.706 -731.706] (0.9655) ({r_i: None, r_t: [-1082.949 -1082.949 -1082.949], eps: 0.966})
Step:   89000, Reward: [-528.672 -528.672 -528.672] [85.217], Avg: [-731.478 -731.478 -731.478] (0.9655) ({r_i: None, r_t: [-1067.273 -1067.273 -1067.273], eps: 0.966})
Step:   89100, Reward: [-554.544 -554.544 -554.544] [130.144], Avg: [-731.280 -731.280 -731.280] (0.9655) ({r_i: None, r_t: [-1151.468 -1151.468 -1151.468], eps: 0.966})
Step:   89200, Reward: [-523.751 -523.751 -523.751] [103.930], Avg: [-731.048 -731.048 -731.048] (0.9655) ({r_i: None, r_t: [-1070.618 -1070.618 -1070.618], eps: 0.966})
Step:   89300, Reward: [-559.779 -559.779 -559.779] [148.218], Avg: [-730.856 -730.856 -730.856] (0.9655) ({r_i: None, r_t: [-1141.787 -1141.787 -1141.787], eps: 0.966})
Step:   89400, Reward: [-573.054 -573.054 -573.054] [94.219], Avg: [-730.680 -730.680 -730.680] (0.9655) ({r_i: None, r_t: [-1116.549 -1116.549 -1116.549], eps: 0.966})
Step:   89500, Reward: [-554.084 -554.084 -554.084] [92.103], Avg: [-730.483 -730.483 -730.483] (0.9655) ({r_i: None, r_t: [-1131.683 -1131.683 -1131.683], eps: 0.966})
Step:   89600, Reward: [-521.586 -521.586 -521.586] [87.143], Avg: [-730.250 -730.250 -730.250] (0.9655) ({r_i: None, r_t: [-1138.059 -1138.059 -1138.059], eps: 0.966})
Step:   89700, Reward: [-529.698 -529.698 -529.698] [145.391], Avg: [-730.027 -730.027 -730.027] (0.9655) ({r_i: None, r_t: [-1102.226 -1102.226 -1102.226], eps: 0.966})
Step:   89800, Reward: [-563.764 -563.764 -563.764] [114.881], Avg: [-729.842 -729.842 -729.842] (0.9655) ({r_i: None, r_t: [-1044.801 -1044.801 -1044.801], eps: 0.966})
Step:   89900, Reward: [-505.619 -505.619 -505.619] [121.375], Avg: [-729.592 -729.592 -729.592] (0.9655) ({r_i: None, r_t: [-1129.491 -1129.491 -1129.491], eps: 0.966})
Step:   90000, Reward: [-544.591 -544.591 -544.591] [112.752], Avg: [-729.387 -729.387 -729.387] (0.9655) ({r_i: None, r_t: [-1071.881 -1071.881 -1071.881], eps: 0.966})
Step:   90100, Reward: [-580.758 -580.758 -580.758] [171.678], Avg: [-729.222 -729.222 -729.222] (0.9655) ({r_i: None, r_t: [-1095.576 -1095.576 -1095.576], eps: 0.966})
Step:   90200, Reward: [-545.628 -545.628 -545.628] [95.752], Avg: [-729.019 -729.019 -729.019] (0.9655) ({r_i: None, r_t: [-1170.275 -1170.275 -1170.275], eps: 0.966})
Step:   90300, Reward: [-588.930 -588.930 -588.930] [117.004], Avg: [-728.864 -728.864 -728.864] (0.9655) ({r_i: None, r_t: [-1134.127 -1134.127 -1134.127], eps: 0.966})
Step:   90400, Reward: [-577.767 -577.767 -577.767] [134.044], Avg: [-728.697 -728.697 -728.697] (0.9655) ({r_i: None, r_t: [-1130.803 -1130.803 -1130.803], eps: 0.966})
Step:   90500, Reward: [-610.626 -610.626 -610.626] [107.555], Avg: [-728.567 -728.567 -728.567] (0.9655) ({r_i: None, r_t: [-1056.079 -1056.079 -1056.079], eps: 0.966})
Step:   90600, Reward: [-543.353 -543.353 -543.353] [95.301], Avg: [-728.363 -728.363 -728.363] (0.9655) ({r_i: None, r_t: [-1036.997 -1036.997 -1036.997], eps: 0.966})
Step:   90700, Reward: [-519.122 -519.122 -519.122] [147.465], Avg: [-728.132 -728.132 -728.132] (0.9655) ({r_i: None, r_t: [-1120.482 -1120.482 -1120.482], eps: 0.966})
Step:   90800, Reward: [-540.736 -540.736 -540.736] [112.567], Avg: [-727.926 -727.926 -727.926] (0.9655) ({r_i: None, r_t: [-1132.503 -1132.503 -1132.503], eps: 0.966})
Step:   90900, Reward: [-517.229 -517.229 -517.229] [126.445], Avg: [-727.694 -727.694 -727.694] (0.9655) ({r_i: None, r_t: [-1154.016 -1154.016 -1154.016], eps: 0.966})
Step:   91000, Reward: [-547.481 -547.481 -547.481] [89.232], Avg: [-727.497 -727.497 -727.497] (0.9655) ({r_i: None, r_t: [-1041.593 -1041.593 -1041.593], eps: 0.966})
Step:   91100, Reward: [-592.216 -592.216 -592.216] [161.069], Avg: [-727.348 -727.348 -727.348] (0.9655) ({r_i: None, r_t: [-1088.450 -1088.450 -1088.450], eps: 0.966})
Step:   91200, Reward: [-530.446 -530.446 -530.446] [103.589], Avg: [-727.133 -727.133 -727.133] (0.9655) ({r_i: None, r_t: [-1078.665 -1078.665 -1078.665], eps: 0.966})
Step:   91300, Reward: [-562.871 -562.871 -562.871] [148.935], Avg: [-726.953 -726.953 -726.953] (0.9655) ({r_i: None, r_t: [-1102.249 -1102.249 -1102.249], eps: 0.966})
Step:   91400, Reward: [-564.279 -564.279 -564.279] [137.599], Avg: [-726.775 -726.775 -726.775] (0.9655) ({r_i: None, r_t: [-1106.967 -1106.967 -1106.967], eps: 0.966})
Step:   91500, Reward: [-532.726 -532.726 -532.726] [84.775], Avg: [-726.563 -726.563 -726.563] (0.9655) ({r_i: None, r_t: [-1043.045 -1043.045 -1043.045], eps: 0.966})
Step:   91600, Reward: [-565.234 -565.234 -565.234] [127.108], Avg: [-726.387 -726.387 -726.387] (0.9655) ({r_i: None, r_t: [-1171.692 -1171.692 -1171.692], eps: 0.966})
Step:   91700, Reward: [-507.196 -507.196 -507.196] [116.174], Avg: [-726.149 -726.149 -726.149] (0.9655) ({r_i: None, r_t: [-1121.172 -1121.172 -1121.172], eps: 0.966})
Step:   91800, Reward: [-519.822 -519.822 -519.822] [98.898], Avg: [-725.924 -725.924 -725.924] (0.9655) ({r_i: None, r_t: [-1215.431 -1215.431 -1215.431], eps: 0.966})
Step:   91900, Reward: [-560.992 -560.992 -560.992] [106.383], Avg: [-725.745 -725.745 -725.745] (0.9655) ({r_i: None, r_t: [-1101.396 -1101.396 -1101.396], eps: 0.966})
Step:   92000, Reward: [-582.803 -582.803 -582.803] [192.029], Avg: [-725.590 -725.590 -725.590] (0.9655) ({r_i: None, r_t: [-966.494 -966.494 -966.494], eps: 0.966})
Step:   92100, Reward: [-542.158 -542.158 -542.158] [105.059], Avg: [-725.391 -725.391 -725.391] (0.9655) ({r_i: None, r_t: [-1111.956 -1111.956 -1111.956], eps: 0.966})
Step:   92200, Reward: [-533.253 -533.253 -533.253] [102.480], Avg: [-725.182 -725.182 -725.182] (0.9655) ({r_i: None, r_t: [-1078.640 -1078.640 -1078.640], eps: 0.966})
Step:   92300, Reward: [-590.730 -590.730 -590.730] [113.324], Avg: [-725.037 -725.037 -725.037] (0.9655) ({r_i: None, r_t: [-1102.496 -1102.496 -1102.496], eps: 0.966})
Step:   92400, Reward: [-580.301 -580.301 -580.301] [110.969], Avg: [-724.880 -724.880 -724.880] (0.9655) ({r_i: None, r_t: [-1060.536 -1060.536 -1060.536], eps: 0.966})
Step:   92500, Reward: [-526.681 -526.681 -526.681] [113.866], Avg: [-724.666 -724.666 -724.666] (0.9655) ({r_i: None, r_t: [-1162.318 -1162.318 -1162.318], eps: 0.966})
Step:   92600, Reward: [-547.374 -547.374 -547.374] [69.943], Avg: [-724.475 -724.475 -724.475] (0.9655) ({r_i: None, r_t: [-1071.786 -1071.786 -1071.786], eps: 0.966})
Step:   92700, Reward: [-485.715 -485.715 -485.715] [69.956], Avg: [-724.218 -724.218 -724.218] (0.9655) ({r_i: None, r_t: [-1055.680 -1055.680 -1055.680], eps: 0.966})
Step:   92800, Reward: [-532.191 -532.191 -532.191] [111.486], Avg: [-724.011 -724.011 -724.011] (0.9655) ({r_i: None, r_t: [-1084.337 -1084.337 -1084.337], eps: 0.966})
Step:   92900, Reward: [-593.512 -593.512 -593.512] [178.296], Avg: [-723.871 -723.871 -723.871] (0.9655) ({r_i: None, r_t: [-1042.013 -1042.013 -1042.013], eps: 0.966})
Step:   93000, Reward: [-560.308 -560.308 -560.308] [112.734], Avg: [-723.695 -723.695 -723.695] (0.9655) ({r_i: None, r_t: [-1110.688 -1110.688 -1110.688], eps: 0.966})
Step:   93100, Reward: [-561.233 -561.233 -561.233] [93.203], Avg: [-723.521 -723.521 -723.521] (0.9655) ({r_i: None, r_t: [-1161.329 -1161.329 -1161.329], eps: 0.966})
Step:   93200, Reward: [-543.965 -543.965 -543.965] [129.706], Avg: [-723.328 -723.328 -723.328] (0.9655) ({r_i: None, r_t: [-1129.909 -1129.909 -1129.909], eps: 0.966})
Step:   93300, Reward: [-544.698 -544.698 -544.698] [115.806], Avg: [-723.137 -723.137 -723.137] (0.9655) ({r_i: None, r_t: [-1085.222 -1085.222 -1085.222], eps: 0.966})
Step:   93400, Reward: [-533.668 -533.668 -533.668] [121.453], Avg: [-722.935 -722.935 -722.935] (0.9655) ({r_i: None, r_t: [-1109.387 -1109.387 -1109.387], eps: 0.966})
Step:   93500, Reward: [-553.225 -553.225 -553.225] [146.287], Avg: [-722.753 -722.753 -722.753] (0.9655) ({r_i: None, r_t: [-1037.355 -1037.355 -1037.355], eps: 0.966})
Step:   93600, Reward: [-545.833 -545.833 -545.833] [111.822], Avg: [-722.564 -722.564 -722.564] (0.9655) ({r_i: None, r_t: [-998.912 -998.912 -998.912], eps: 0.966})
Step:   93700, Reward: [-490.311 -490.311 -490.311] [131.598], Avg: [-722.317 -722.317 -722.317] (0.9655) ({r_i: None, r_t: [-1111.733 -1111.733 -1111.733], eps: 0.966})
Step:   93800, Reward: [-541.357 -541.357 -541.357] [157.312], Avg: [-722.124 -722.124 -722.124] (0.9655) ({r_i: None, r_t: [-1119.701 -1119.701 -1119.701], eps: 0.966})
Step:   93900, Reward: [-507.360 -507.360 -507.360] [103.441], Avg: [-721.896 -721.896 -721.896] (0.9655) ({r_i: None, r_t: [-1055.504 -1055.504 -1055.504], eps: 0.966})
Step:   94000, Reward: [-538.453 -538.453 -538.453] [125.453], Avg: [-721.701 -721.701 -721.701] (0.9655) ({r_i: None, r_t: [-1087.356 -1087.356 -1087.356], eps: 0.966})
Step:   94100, Reward: [-467.641 -467.641 -467.641] [97.505], Avg: [-721.431 -721.431 -721.431] (0.9655) ({r_i: None, r_t: [-1111.601 -1111.601 -1111.601], eps: 0.966})
Step:   94200, Reward: [-543.721 -543.721 -543.721] [133.370], Avg: [-721.243 -721.243 -721.243] (0.9655) ({r_i: None, r_t: [-1028.086 -1028.086 -1028.086], eps: 0.966})
Step:   94300, Reward: [-529.837 -529.837 -529.837] [133.741], Avg: [-721.040 -721.040 -721.040] (0.9655) ({r_i: None, r_t: [-1037.457 -1037.457 -1037.457], eps: 0.966})
Step:   94400, Reward: [-572.736 -572.736 -572.736] [127.414], Avg: [-720.883 -720.883 -720.883] (0.9655) ({r_i: None, r_t: [-1076.596 -1076.596 -1076.596], eps: 0.966})
Step:   94500, Reward: [-514.502 -514.502 -514.502] [113.251], Avg: [-720.665 -720.665 -720.665] (0.9655) ({r_i: None, r_t: [-1204.830 -1204.830 -1204.830], eps: 0.966})
Step:   94600, Reward: [-552.948 -552.948 -552.948] [158.922], Avg: [-720.488 -720.488 -720.488] (0.9655) ({r_i: None, r_t: [-1125.642 -1125.642 -1125.642], eps: 0.966})
Step:   94700, Reward: [-569.603 -569.603 -569.603] [151.061], Avg: [-720.328 -720.328 -720.328] (0.9655) ({r_i: None, r_t: [-1050.113 -1050.113 -1050.113], eps: 0.966})
Step:   94800, Reward: [-598.923 -598.923 -598.923] [112.070], Avg: [-720.200 -720.200 -720.200] (0.9655) ({r_i: None, r_t: [-1083.816 -1083.816 -1083.816], eps: 0.966})
Step:   94900, Reward: [-511.817 -511.817 -511.817] [103.035], Avg: [-719.981 -719.981 -719.981] (0.9655) ({r_i: None, r_t: [-1082.624 -1082.624 -1082.624], eps: 0.966})
Step:   95000, Reward: [-556.814 -556.814 -556.814] [165.527], Avg: [-719.810 -719.810 -719.810] (0.9655) ({r_i: None, r_t: [-1073.828 -1073.828 -1073.828], eps: 0.966})
Step:   95100, Reward: [-605.626 -605.626 -605.626] [169.723], Avg: [-719.690 -719.690 -719.690] (0.9607) ({r_i: None, r_t: [-1142.821 -1142.821 -1142.821], eps: 0.961})
Step:   95200, Reward: [-504.837 -504.837 -504.837] [95.061], Avg: [-719.464 -719.464 -719.464] (0.9607) ({r_i: None, r_t: [-1110.175 -1110.175 -1110.175], eps: 0.961})
Step:   95300, Reward: [-563.606 -563.606 -563.606] [106.315], Avg: [-719.301 -719.301 -719.301] (0.9607) ({r_i: None, r_t: [-1042.829 -1042.829 -1042.829], eps: 0.961})
Step:   95400, Reward: [-533.839 -533.839 -533.839] [160.920], Avg: [-719.107 -719.107 -719.107] (0.9607) ({r_i: None, r_t: [-1088.971 -1088.971 -1088.971], eps: 0.961})
Step:   95500, Reward: [-585.246 -585.246 -585.246] [176.339], Avg: [-718.967 -718.967 -718.967] (0.9607) ({r_i: None, r_t: [-1153.220 -1153.220 -1153.220], eps: 0.961})
Step:   95600, Reward: [-560.928 -560.928 -560.928] [169.457], Avg: [-718.801 -718.801 -718.801] (0.9607) ({r_i: None, r_t: [-1054.576 -1054.576 -1054.576], eps: 0.961})
Step:   95700, Reward: [-519.943 -519.943 -519.943] [104.571], Avg: [-718.594 -718.594 -718.594] (0.9607) ({r_i: None, r_t: [-1074.085 -1074.085 -1074.085], eps: 0.961})
Step:   95800, Reward: [-531.636 -531.636 -531.636] [144.004], Avg: [-718.399 -718.399 -718.399] (0.9607) ({r_i: None, r_t: [-1089.546 -1089.546 -1089.546], eps: 0.961})
Step:   95900, Reward: [-535.228 -535.228 -535.228] [95.089], Avg: [-718.208 -718.208 -718.208] (0.9607) ({r_i: None, r_t: [-1124.161 -1124.161 -1124.161], eps: 0.961})
Step:   96000, Reward: [-546.647 -546.647 -546.647] [117.732], Avg: [-718.030 -718.030 -718.030] (0.9607) ({r_i: None, r_t: [-1087.380 -1087.380 -1087.380], eps: 0.961})
Step:   96100, Reward: [-582.958 -582.958 -582.958] [142.820], Avg: [-717.889 -717.889 -717.889] (0.9607) ({r_i: None, r_t: [-1128.231 -1128.231 -1128.231], eps: 0.961})
Step:   96200, Reward: [-478.467 -478.467 -478.467] [96.401], Avg: [-717.641 -717.641 -717.641] (0.9607) ({r_i: None, r_t: [-1048.144 -1048.144 -1048.144], eps: 0.961})
Step:   96300, Reward: [-523.203 -523.203 -523.203] [93.812], Avg: [-717.439 -717.439 -717.439] (0.9607) ({r_i: None, r_t: [-1021.447 -1021.447 -1021.447], eps: 0.961})
Step:   96400, Reward: [-512.978 -512.978 -512.978] [88.225], Avg: [-717.227 -717.227 -717.227] (0.9607) ({r_i: None, r_t: [-1128.931 -1128.931 -1128.931], eps: 0.961})
Step:   96500, Reward: [-555.858 -555.858 -555.858] [145.766], Avg: [-717.060 -717.060 -717.060] (0.9607) ({r_i: None, r_t: [-1059.291 -1059.291 -1059.291], eps: 0.961})
Step:   96600, Reward: [-463.688 -463.688 -463.688] [99.179], Avg: [-716.798 -716.798 -716.798] (0.9607) ({r_i: None, r_t: [-1114.931 -1114.931 -1114.931], eps: 0.961})
Step:   96700, Reward: [-609.951 -609.951 -609.951] [143.054], Avg: [-716.688 -716.688 -716.688] (0.9607) ({r_i: None, r_t: [-1128.623 -1128.623 -1128.623], eps: 0.961})
Step:   96800, Reward: [-565.293 -565.293 -565.293] [174.342], Avg: [-716.531 -716.531 -716.531] (0.9607) ({r_i: None, r_t: [-1040.223 -1040.223 -1040.223], eps: 0.961})
Step:   96900, Reward: [-594.615 -594.615 -594.615] [106.465], Avg: [-716.406 -716.406 -716.406] (0.9607) ({r_i: None, r_t: [-1057.334 -1057.334 -1057.334], eps: 0.961})
Step:   97000, Reward: [-548.665 -548.665 -548.665] [111.925], Avg: [-716.233 -716.233 -716.233] (0.9607) ({r_i: None, r_t: [-1044.419 -1044.419 -1044.419], eps: 0.961})
Step:   97100, Reward: [-579.893 -579.893 -579.893] [118.336], Avg: [-716.093 -716.093 -716.093] (0.9607) ({r_i: None, r_t: [-1168.558 -1168.558 -1168.558], eps: 0.961})
Step:   97200, Reward: [-557.348 -557.348 -557.348] [119.118], Avg: [-715.929 -715.929 -715.929] (0.9607) ({r_i: None, r_t: [-1123.830 -1123.830 -1123.830], eps: 0.961})
Step:   97300, Reward: [-578.507 -578.507 -578.507] [149.915], Avg: [-715.788 -715.788 -715.788] (0.9607) ({r_i: None, r_t: [-1127.920 -1127.920 -1127.920], eps: 0.961})
Step:   97400, Reward: [-603.589 -603.589 -603.589] [162.539], Avg: [-715.673 -715.673 -715.673] (0.9607) ({r_i: None, r_t: [-1066.455 -1066.455 -1066.455], eps: 0.961})
Step:   97500, Reward: [-526.215 -526.215 -526.215] [111.494], Avg: [-715.479 -715.479 -715.479] (0.9607) ({r_i: None, r_t: [-1107.395 -1107.395 -1107.395], eps: 0.961})
Step:   97600, Reward: [-562.854 -562.854 -562.854] [134.245], Avg: [-715.323 -715.323 -715.323] (0.9607) ({r_i: None, r_t: [-1052.972 -1052.972 -1052.972], eps: 0.961})
Step:   97700, Reward: [-584.284 -584.284 -584.284] [107.102], Avg: [-715.189 -715.189 -715.189] (0.9607) ({r_i: None, r_t: [-1109.194 -1109.194 -1109.194], eps: 0.961})
Step:   97800, Reward: [-552.976 -552.976 -552.976] [134.626], Avg: [-715.023 -715.023 -715.023] (0.9607) ({r_i: None, r_t: [-1135.344 -1135.344 -1135.344], eps: 0.961})
Step:   97900, Reward: [-600.000 -600.000 -600.000] [171.213], Avg: [-714.906 -714.906 -714.906] (0.9607) ({r_i: None, r_t: [-1072.946 -1072.946 -1072.946], eps: 0.961})
Step:   98000, Reward: [-565.855 -565.855 -565.855] [115.399], Avg: [-714.754 -714.754 -714.754] (0.9607) ({r_i: None, r_t: [-1068.482 -1068.482 -1068.482], eps: 0.961})
Step:   98100, Reward: [-557.073 -557.073 -557.073] [166.792], Avg: [-714.593 -714.593 -714.593] (0.9607) ({r_i: None, r_t: [-1111.174 -1111.174 -1111.174], eps: 0.961})
Step:   98200, Reward: [-544.897 -544.897 -544.897] [112.000], Avg: [-714.421 -714.421 -714.421] (0.9607) ({r_i: None, r_t: [-1095.494 -1095.494 -1095.494], eps: 0.961})
Step:   98300, Reward: [-612.301 -612.301 -612.301] [161.363], Avg: [-714.317 -714.317 -714.317] (0.9607) ({r_i: None, r_t: [-1155.449 -1155.449 -1155.449], eps: 0.961})
Step:   98400, Reward: [-572.156 -572.156 -572.156] [108.571], Avg: [-714.173 -714.173 -714.173] (0.9607) ({r_i: None, r_t: [-1074.408 -1074.408 -1074.408], eps: 0.961})
Step:   98500, Reward: [-558.377 -558.377 -558.377] [140.307], Avg: [-714.015 -714.015 -714.015] (0.9607) ({r_i: None, r_t: [-1049.351 -1049.351 -1049.351], eps: 0.961})
Step:   98600, Reward: [-597.391 -597.391 -597.391] [106.567], Avg: [-713.896 -713.896 -713.896] (0.9607) ({r_i: None, r_t: [-1107.795 -1107.795 -1107.795], eps: 0.961})
Step:   98700, Reward: [-571.262 -571.262 -571.262] [148.228], Avg: [-713.752 -713.752 -713.752] (0.9607) ({r_i: None, r_t: [-1096.243 -1096.243 -1096.243], eps: 0.961})
Step:   98800, Reward: [-480.259 -480.259 -480.259] [91.514], Avg: [-713.516 -713.516 -713.516] (0.9607) ({r_i: None, r_t: [-1017.896 -1017.896 -1017.896], eps: 0.961})
Step:   98900, Reward: [-568.695 -568.695 -568.695] [123.722], Avg: [-713.370 -713.370 -713.370] (0.9607) ({r_i: None, r_t: [-1161.249 -1161.249 -1161.249], eps: 0.961})
Step:   99000, Reward: [-576.401 -576.401 -576.401] [138.357], Avg: [-713.232 -713.232 -713.232] (0.9607) ({r_i: None, r_t: [-1016.179 -1016.179 -1016.179], eps: 0.961})
Step:   99100, Reward: [-541.600 -541.600 -541.600] [75.350], Avg: [-713.058 -713.058 -713.058] (0.9607) ({r_i: None, r_t: [-1095.196 -1095.196 -1095.196], eps: 0.961})
Step:   99200, Reward: [-578.982 -578.982 -578.982] [149.916], Avg: [-712.923 -712.923 -712.923] (0.9607) ({r_i: None, r_t: [-1089.939 -1089.939 -1089.939], eps: 0.961})
Step:   99300, Reward: [-557.718 -557.718 -557.718] [107.517], Avg: [-712.767 -712.767 -712.767] (0.9607) ({r_i: None, r_t: [-1136.137 -1136.137 -1136.137], eps: 0.961})
Step:   99400, Reward: [-520.463 -520.463 -520.463] [104.782], Avg: [-712.574 -712.574 -712.574] (0.9607) ({r_i: None, r_t: [-1131.341 -1131.341 -1131.341], eps: 0.961})
Step:   99500, Reward: [-575.442 -575.442 -575.442] [199.622], Avg: [-712.436 -712.436 -712.436] (0.9607) ({r_i: None, r_t: [-1193.898 -1193.898 -1193.898], eps: 0.961})
Step:   99600, Reward: [-503.645 -503.645 -503.645] [92.136], Avg: [-712.227 -712.227 -712.227] (0.9607) ({r_i: None, r_t: [-1114.137 -1114.137 -1114.137], eps: 0.961})
Step:   99700, Reward: [-622.888 -622.888 -622.888] [189.540], Avg: [-712.137 -712.137 -712.137] (0.9607) ({r_i: None, r_t: [-1057.408 -1057.408 -1057.408], eps: 0.961})
Step:   99800, Reward: [-563.303 -563.303 -563.303] [122.144], Avg: [-711.988 -711.988 -711.988] (0.9607) ({r_i: None, r_t: [-1169.418 -1169.418 -1169.418], eps: 0.961})
Step:   99900, Reward: [-568.636 -568.636 -568.636] [122.833], Avg: [-711.845 -711.845 -711.845] (0.9607) ({r_i: None, r_t: [-1090.309 -1090.309 -1090.309], eps: 0.961})
Step:  100000, Reward: [-553.438 -553.438 -553.438] [123.784], Avg: [-711.687 -711.687 -711.687] (0.9607) ({r_i: None, r_t: [-1150.692 -1150.692 -1150.692], eps: 0.961})
Step:  100100, Reward: [-562.390 -562.390 -562.390] [158.990], Avg: [-711.538 -711.538 -711.538] (0.9607) ({r_i: None, r_t: [-1089.754 -1089.754 -1089.754], eps: 0.961})
Step:  100200, Reward: [-548.854 -548.854 -548.854] [181.711], Avg: [-711.376 -711.376 -711.376] (0.9607) ({r_i: None, r_t: [-1153.257 -1153.257 -1153.257], eps: 0.961})
Step:  100300, Reward: [-557.066 -557.066 -557.066] [135.362], Avg: [-711.222 -711.222 -711.222] (0.9607) ({r_i: None, r_t: [-1072.036 -1072.036 -1072.036], eps: 0.961})
Step:  100400, Reward: [-608.327 -608.327 -608.327] [134.581], Avg: [-711.120 -711.120 -711.120] (0.9607) ({r_i: None, r_t: [-1210.714 -1210.714 -1210.714], eps: 0.961})
Step:  100500, Reward: [-593.756 -593.756 -593.756] [137.885], Avg: [-711.003 -711.003 -711.003] (0.9607) ({r_i: None, r_t: [-1159.339 -1159.339 -1159.339], eps: 0.961})
Step:  100600, Reward: [-523.586 -523.586 -523.586] [113.309], Avg: [-710.817 -710.817 -710.817] (0.9607) ({r_i: None, r_t: [-1191.167 -1191.167 -1191.167], eps: 0.961})
Step:  100700, Reward: [-563.312 -563.312 -563.312] [174.307], Avg: [-710.670 -710.670 -710.670] (0.9607) ({r_i: None, r_t: [-1163.373 -1163.373 -1163.373], eps: 0.961})
Step:  100800, Reward: [-575.710 -575.710 -575.710] [169.001], Avg: [-710.537 -710.537 -710.537] (0.9607) ({r_i: None, r_t: [-1106.575 -1106.575 -1106.575], eps: 0.961})
Step:  100900, Reward: [-601.455 -601.455 -601.455] [151.414], Avg: [-710.429 -710.429 -710.429] (0.9607) ({r_i: None, r_t: [-1140.444 -1140.444 -1140.444], eps: 0.961})
Step:  101000, Reward: [-628.590 -628.590 -628.590] [197.856], Avg: [-710.348 -710.348 -710.348] (0.9607) ({r_i: None, r_t: [-1183.295 -1183.295 -1183.295], eps: 0.961})
Step:  101100, Reward: [-576.910 -576.910 -576.910] [129.302], Avg: [-710.216 -710.216 -710.216] (0.9607) ({r_i: None, r_t: [-1166.456 -1166.456 -1166.456], eps: 0.961})
Step:  101200, Reward: [-588.399 -588.399 -588.399] [132.602], Avg: [-710.096 -710.096 -710.096] (0.9607) ({r_i: None, r_t: [-1161.183 -1161.183 -1161.183], eps: 0.961})
Step:  101300, Reward: [-612.434 -612.434 -612.434] [171.823], Avg: [-709.999 -709.999 -709.999] (0.9607) ({r_i: None, r_t: [-1150.689 -1150.689 -1150.689], eps: 0.961})
Step:  101400, Reward: [-548.968 -548.968 -548.968] [93.641], Avg: [-709.841 -709.841 -709.841] (0.9607) ({r_i: None, r_t: [-1158.104 -1158.104 -1158.104], eps: 0.961})
Step:  101500, Reward: [-618.878 -618.878 -618.878] [142.227], Avg: [-709.751 -709.751 -709.751] (0.9607) ({r_i: None, r_t: [-1194.795 -1194.795 -1194.795], eps: 0.961})
Step:  101600, Reward: [-539.322 -539.322 -539.322] [141.519], Avg: [-709.584 -709.584 -709.584] (0.9607) ({r_i: None, r_t: [-1252.376 -1252.376 -1252.376], eps: 0.961})
Step:  101700, Reward: [-677.533 -677.533 -677.533] [182.555], Avg: [-709.552 -709.552 -709.552] (0.9607) ({r_i: None, r_t: [-1092.105 -1092.105 -1092.105], eps: 0.961})
Step:  101800, Reward: [-608.812 -608.812 -608.812] [134.311], Avg: [-709.453 -709.453 -709.453] (0.9607) ({r_i: None, r_t: [-1171.615 -1171.615 -1171.615], eps: 0.961})
Step:  101900, Reward: [-592.063 -592.063 -592.063] [142.672], Avg: [-709.338 -709.338 -709.338] (0.9607) ({r_i: None, r_t: [-1144.236 -1144.236 -1144.236], eps: 0.961})
Step:  102000, Reward: [-554.223 -554.223 -554.223] [178.998], Avg: [-709.186 -709.186 -709.186] (0.9607) ({r_i: None, r_t: [-1165.841 -1165.841 -1165.841], eps: 0.961})
Step:  102100, Reward: [-638.106 -638.106 -638.106] [131.798], Avg: [-709.117 -709.117 -709.117] (0.9607) ({r_i: None, r_t: [-1041.623 -1041.623 -1041.623], eps: 0.961})
Step:  102200, Reward: [-582.619 -582.619 -582.619] [167.761], Avg: [-708.993 -708.993 -708.993] (0.9607) ({r_i: None, r_t: [-1197.785 -1197.785 -1197.785], eps: 0.961})
Step:  102300, Reward: [-552.892 -552.892 -552.892] [121.624], Avg: [-708.841 -708.841 -708.841] (0.9607) ({r_i: None, r_t: [-1106.994 -1106.994 -1106.994], eps: 0.961})
Step:  102400, Reward: [-608.483 -608.483 -608.483] [155.646], Avg: [-708.743 -708.743 -708.743] (0.9607) ({r_i: None, r_t: [-1056.868 -1056.868 -1056.868], eps: 0.961})
Step:  102500, Reward: [-599.521 -599.521 -599.521] [211.080], Avg: [-708.636 -708.636 -708.636] (0.9607) ({r_i: None, r_t: [-1179.926 -1179.926 -1179.926], eps: 0.961})
Step:  102600, Reward: [-555.793 -555.793 -555.793] [173.960], Avg: [-708.487 -708.487 -708.487] (0.9607) ({r_i: None, r_t: [-1193.763 -1193.763 -1193.763], eps: 0.961})
Step:  102700, Reward: [-581.421 -581.421 -581.421] [128.762], Avg: [-708.364 -708.364 -708.364] (0.9607) ({r_i: None, r_t: [-1127.341 -1127.341 -1127.341], eps: 0.961})
Step:  102800, Reward: [-572.602 -572.602 -572.602] [145.286], Avg: [-708.232 -708.232 -708.232] (0.9607) ({r_i: None, r_t: [-1248.928 -1248.928 -1248.928], eps: 0.961})
Step:  102900, Reward: [-593.477 -593.477 -593.477] [197.890], Avg: [-708.120 -708.120 -708.120] (0.9607) ({r_i: None, r_t: [-1195.764 -1195.764 -1195.764], eps: 0.961})
Step:  103000, Reward: [-599.740 -599.740 -599.740] [187.977], Avg: [-708.015 -708.015 -708.015] (0.9607) ({r_i: None, r_t: [-1177.673 -1177.673 -1177.673], eps: 0.961})
Step:  103100, Reward: [-666.265 -666.265 -666.265] [249.611], Avg: [-707.975 -707.975 -707.975] (0.9607) ({r_i: None, r_t: [-1129.319 -1129.319 -1129.319], eps: 0.961})
Step:  103200, Reward: [-608.176 -608.176 -608.176] [171.527], Avg: [-707.878 -707.878 -707.878] (0.9607) ({r_i: None, r_t: [-1104.292 -1104.292 -1104.292], eps: 0.961})
Step:  103300, Reward: [-549.429 -549.429 -549.429] [117.433], Avg: [-707.725 -707.725 -707.725] (0.9607) ({r_i: None, r_t: [-1299.009 -1299.009 -1299.009], eps: 0.961})
Step:  103400, Reward: [-620.493 -620.493 -620.493] [135.270], Avg: [-707.641 -707.641 -707.641] (0.9607) ({r_i: None, r_t: [-1081.283 -1081.283 -1081.283], eps: 0.961})
Step:  103500, Reward: [-537.791 -537.791 -537.791] [116.706], Avg: [-707.477 -707.477 -707.477] (0.9607) ({r_i: None, r_t: [-1199.410 -1199.410 -1199.410], eps: 0.961})
Step:  103600, Reward: [-636.424 -636.424 -636.424] [127.207], Avg: [-707.408 -707.408 -707.408] (0.9607) ({r_i: None, r_t: [-1239.191 -1239.191 -1239.191], eps: 0.961})
Step:  103700, Reward: [-584.819 -584.819 -584.819] [125.291], Avg: [-707.290 -707.290 -707.290] (0.9607) ({r_i: None, r_t: [-1339.056 -1339.056 -1339.056], eps: 0.961})
Step:  103800, Reward: [-576.967 -576.967 -576.967] [141.004], Avg: [-707.165 -707.165 -707.165] (0.9607) ({r_i: None, r_t: [-1285.991 -1285.991 -1285.991], eps: 0.961})
Step:  103900, Reward: [-559.370 -559.370 -559.370] [181.032], Avg: [-707.023 -707.023 -707.023] (0.9607) ({r_i: None, r_t: [-1209.751 -1209.751 -1209.751], eps: 0.961})
Step:  104000, Reward: [-598.281 -598.281 -598.281] [159.535], Avg: [-706.918 -706.918 -706.918] (0.9607) ({r_i: None, r_t: [-1281.959 -1281.959 -1281.959], eps: 0.961})
Step:  104100, Reward: [-567.772 -567.772 -567.772] [152.558], Avg: [-706.785 -706.785 -706.785] (0.9607) ({r_i: None, r_t: [-1288.783 -1288.783 -1288.783], eps: 0.961})
Step:  104200, Reward: [-627.761 -627.761 -627.761] [167.300], Avg: [-706.709 -706.709 -706.709] (0.9607) ({r_i: None, r_t: [-1194.950 -1194.950 -1194.950], eps: 0.961})
Step:  104300, Reward: [-633.496 -633.496 -633.496] [204.917], Avg: [-706.639 -706.639 -706.639] (0.9607) ({r_i: None, r_t: [-1316.272 -1316.272 -1316.272], eps: 0.961})
Step:  104400, Reward: [-630.563 -630.563 -630.563] [235.744], Avg: [-706.566 -706.566 -706.566] (0.9607) ({r_i: None, r_t: [-1295.567 -1295.567 -1295.567], eps: 0.961})
Step:  104500, Reward: [-639.427 -639.427 -639.427] [238.964], Avg: [-706.502 -706.502 -706.502] (0.9607) ({r_i: None, r_t: [-1278.634 -1278.634 -1278.634], eps: 0.961})
Step:  104600, Reward: [-668.966 -668.966 -668.966] [185.677], Avg: [-706.466 -706.466 -706.466] (0.9607) ({r_i: None, r_t: [-1211.913 -1211.913 -1211.913], eps: 0.961})
Step:  104700, Reward: [-603.532 -603.532 -603.532] [195.251], Avg: [-706.368 -706.368 -706.368] (0.9607) ({r_i: None, r_t: [-1175.945 -1175.945 -1175.945], eps: 0.961})
Step:  104800, Reward: [-649.720 -649.720 -649.720] [134.026], Avg: [-706.314 -706.314 -706.314] (0.9607) ({r_i: None, r_t: [-1217.923 -1217.923 -1217.923], eps: 0.961})
Step:  104900, Reward: [-600.411 -600.411 -600.411] [194.839], Avg: [-706.213 -706.213 -706.213] (0.9607) ({r_i: None, r_t: [-1212.714 -1212.714 -1212.714], eps: 0.961})
Step:  105000, Reward: [-568.330 -568.330 -568.330] [124.729], Avg: [-706.082 -706.082 -706.082] (0.9607) ({r_i: None, r_t: [-1340.339 -1340.339 -1340.339], eps: 0.961})
Step:  105100, Reward: [-700.864 -700.864 -700.864] [219.158], Avg: [-706.077 -706.077 -706.077] (0.9607) ({r_i: None, r_t: [-1268.298 -1268.298 -1268.298], eps: 0.961})
Step:  105200, Reward: [-617.180 -617.180 -617.180] [175.996], Avg: [-705.992 -705.992 -705.992] (0.9607) ({r_i: None, r_t: [-1165.744 -1165.744 -1165.744], eps: 0.961})
Step:  105300, Reward: [-695.235 -695.235 -695.235] [168.163], Avg: [-705.982 -705.982 -705.982] (0.9607) ({r_i: None, r_t: [-1266.461 -1266.461 -1266.461], eps: 0.961})
Step:  105400, Reward: [-713.054 -713.054 -713.054] [303.874], Avg: [-705.989 -705.989 -705.989] (0.9607) ({r_i: None, r_t: [-1275.407 -1275.407 -1275.407], eps: 0.961})
Step:  105500, Reward: [-719.966 -719.966 -719.966] [300.969], Avg: [-706.002 -706.002 -706.002] (0.9607) ({r_i: None, r_t: [-1407.851 -1407.851 -1407.851], eps: 0.961})
Step:  105600, Reward: [-649.911 -649.911 -649.911] [218.694], Avg: [-705.949 -705.949 -705.949] (0.9607) ({r_i: None, r_t: [-1399.801 -1399.801 -1399.801], eps: 0.961})
Step:  105700, Reward: [-706.333 -706.333 -706.333] [171.510], Avg: [-705.949 -705.949 -705.949] (0.9607) ({r_i: None, r_t: [-1292.067 -1292.067 -1292.067], eps: 0.961})
Step:  105800, Reward: [-650.714 -650.714 -650.714] [169.320], Avg: [-705.897 -705.897 -705.897] (0.9607) ({r_i: None, r_t: [-1360.837 -1360.837 -1360.837], eps: 0.961})
Step:  105900, Reward: [-662.296 -662.296 -662.296] [174.997], Avg: [-705.856 -705.856 -705.856] (0.9607) ({r_i: None, r_t: [-1254.293 -1254.293 -1254.293], eps: 0.961})
Step:  106000, Reward: [-544.103 -544.103 -544.103] [115.018], Avg: [-705.704 -705.704 -705.704] (0.9607) ({r_i: None, r_t: [-1172.311 -1172.311 -1172.311], eps: 0.961})
Step:  106100, Reward: [-616.321 -616.321 -616.321] [207.414], Avg: [-705.619 -705.619 -705.619] (0.9607) ({r_i: None, r_t: [-1277.917 -1277.917 -1277.917], eps: 0.961})
Step:  106200, Reward: [-726.898 -726.898 -726.898] [288.898], Avg: [-705.639 -705.639 -705.639] (0.9607) ({r_i: None, r_t: [-1262.415 -1262.415 -1262.415], eps: 0.961})
Step:  106300, Reward: [-664.683 -664.683 -664.683] [260.048], Avg: [-705.601 -705.601 -705.601] (0.9607) ({r_i: None, r_t: [-1345.532 -1345.532 -1345.532], eps: 0.961})
Step:  106400, Reward: [-638.844 -638.844 -638.844] [173.846], Avg: [-705.538 -705.538 -705.538] (0.9607) ({r_i: None, r_t: [-1427.730 -1427.730 -1427.730], eps: 0.961})
Step:  106500, Reward: [-600.190 -600.190 -600.190] [134.707], Avg: [-705.439 -705.439 -705.439] (0.9607) ({r_i: None, r_t: [-1241.123 -1241.123 -1241.123], eps: 0.961})
Step:  106600, Reward: [-575.390 -575.390 -575.390] [126.422], Avg: [-705.317 -705.317 -705.317] (0.9607) ({r_i: None, r_t: [-1165.386 -1165.386 -1165.386], eps: 0.961})
Step:  106700, Reward: [-639.837 -639.837 -639.837] [240.350], Avg: [-705.256 -705.256 -705.256] (0.9607) ({r_i: None, r_t: [-1322.405 -1322.405 -1322.405], eps: 0.961})
Step:  106800, Reward: [-636.031 -636.031 -636.031] [185.749], Avg: [-705.191 -705.191 -705.191] (0.9607) ({r_i: None, r_t: [-1321.160 -1321.160 -1321.160], eps: 0.961})
Step:  106900, Reward: [-655.535 -655.535 -655.535] [203.424], Avg: [-705.145 -705.145 -705.145] (0.9607) ({r_i: None, r_t: [-1297.920 -1297.920 -1297.920], eps: 0.961})
Step:  107000, Reward: [-802.565 -802.565 -802.565] [240.025], Avg: [-705.236 -705.236 -705.236] (0.9607) ({r_i: None, r_t: [-1513.357 -1513.357 -1513.357], eps: 0.961})
Step:  107100, Reward: [-734.881 -734.881 -734.881] [213.262], Avg: [-705.264 -705.264 -705.264] (0.9607) ({r_i: None, r_t: [-1401.526 -1401.526 -1401.526], eps: 0.961})
Step:  107200, Reward: [-681.928 -681.928 -681.928] [297.646], Avg: [-705.242 -705.242 -705.242] (0.9607) ({r_i: None, r_t: [-1407.119 -1407.119 -1407.119], eps: 0.961})
Step:  107300, Reward: [-696.946 -696.946 -696.946] [262.337], Avg: [-705.234 -705.234 -705.234] (0.9607) ({r_i: None, r_t: [-1430.981 -1430.981 -1430.981], eps: 0.961})
Step:  107400, Reward: [-688.236 -688.236 -688.236] [249.875], Avg: [-705.218 -705.218 -705.218] (0.9607) ({r_i: None, r_t: [-1363.574 -1363.574 -1363.574], eps: 0.961})
Step:  107500, Reward: [-665.460 -665.460 -665.460] [213.812], Avg: [-705.181 -705.181 -705.181] (0.9607) ({r_i: None, r_t: [-1502.638 -1502.638 -1502.638], eps: 0.961})
Step:  107600, Reward: [-721.860 -721.860 -721.860] [227.694], Avg: [-705.197 -705.197 -705.197] (0.9559) ({r_i: None, r_t: [-1529.996 -1529.996 -1529.996], eps: 0.956})
Step:  107700, Reward: [-652.028 -652.028 -652.028] [187.486], Avg: [-705.148 -705.148 -705.148] (0.9559) ({r_i: None, r_t: [-1201.013 -1201.013 -1201.013], eps: 0.956})
Step:  107800, Reward: [-673.162 -673.162 -673.162] [193.446], Avg: [-705.118 -705.118 -705.118] (0.9559) ({r_i: None, r_t: [-1452.111 -1452.111 -1452.111], eps: 0.956})
Step:  107900, Reward: [-752.400 -752.400 -752.400] [234.917], Avg: [-705.162 -705.162 -705.162] (0.9559) ({r_i: None, r_t: [-1484.695 -1484.695 -1484.695], eps: 0.956})
Step:  108000, Reward: [-665.761 -665.761 -665.761] [332.435], Avg: [-705.125 -705.125 -705.125] (0.9559) ({r_i: None, r_t: [-1579.169 -1579.169 -1579.169], eps: 0.956})
Step:  108100, Reward: [-596.657 -596.657 -596.657] [188.349], Avg: [-705.025 -705.025 -705.025] (0.9559) ({r_i: None, r_t: [-1348.186 -1348.186 -1348.186], eps: 0.956})
Step:  108200, Reward: [-805.446 -805.446 -805.446] [357.320], Avg: [-705.118 -705.118 -705.118] (0.9559) ({r_i: None, r_t: [-1468.557 -1468.557 -1468.557], eps: 0.956})
Step:  108300, Reward: [-715.647 -715.647 -715.647] [220.629], Avg: [-705.127 -705.127 -705.127] (0.9559) ({r_i: None, r_t: [-1534.832 -1534.832 -1534.832], eps: 0.956})
Step:  108400, Reward: [-823.431 -823.431 -823.431] [313.790], Avg: [-705.236 -705.236 -705.236] (0.9559) ({r_i: None, r_t: [-1653.309 -1653.309 -1653.309], eps: 0.956})
Step:  108500, Reward: [-675.794 -675.794 -675.794] [320.976], Avg: [-705.209 -705.209 -705.209] (0.9559) ({r_i: None, r_t: [-1358.557 -1358.557 -1358.557], eps: 0.956})
Step:  108600, Reward: [-652.728 -652.728 -652.728] [216.053], Avg: [-705.161 -705.161 -705.161] (0.9559) ({r_i: None, r_t: [-1314.624 -1314.624 -1314.624], eps: 0.956})
Step:  108700, Reward: [-675.059 -675.059 -675.059] [142.317], Avg: [-705.133 -705.133 -705.133] (0.9559) ({r_i: None, r_t: [-1280.169 -1280.169 -1280.169], eps: 0.956})
Step:  108800, Reward: [-853.196 -853.196 -853.196] [273.672], Avg: [-705.269 -705.269 -705.269] (0.9559) ({r_i: None, r_t: [-1322.622 -1322.622 -1322.622], eps: 0.956})
Step:  108900, Reward: [-735.359 -735.359 -735.359] [345.514], Avg: [-705.297 -705.297 -705.297] (0.9559) ({r_i: None, r_t: [-1409.637 -1409.637 -1409.637], eps: 0.956})
Step:  109000, Reward: [-720.362 -720.362 -720.362] [248.510], Avg: [-705.311 -705.311 -705.311] (0.9559) ({r_i: None, r_t: [-1488.090 -1488.090 -1488.090], eps: 0.956})
Step:  109100, Reward: [-781.055 -781.055 -781.055] [269.930], Avg: [-705.380 -705.380 -705.380] (0.9559) ({r_i: None, r_t: [-1568.456 -1568.456 -1568.456], eps: 0.956})
Step:  109200, Reward: [-827.706 -827.706 -827.706] [318.005], Avg: [-705.492 -705.492 -705.492] (0.9559) ({r_i: None, r_t: [-1409.997 -1409.997 -1409.997], eps: 0.956})
Step:  109300, Reward: [-828.383 -828.383 -828.383] [244.924], Avg: [-705.604 -705.604 -705.604] (0.9559) ({r_i: None, r_t: [-1429.282 -1429.282 -1429.282], eps: 0.956})
Step:  109400, Reward: [-667.047 -667.047 -667.047] [168.049], Avg: [-705.569 -705.569 -705.569] (0.9559) ({r_i: None, r_t: [-1456.677 -1456.677 -1456.677], eps: 0.956})
Step:  109500, Reward: [-861.242 -861.242 -861.242] [357.208], Avg: [-705.711 -705.711 -705.711] (0.9559) ({r_i: None, r_t: [-1533.507 -1533.507 -1533.507], eps: 0.956})
Step:  109600, Reward: [-667.066 -667.066 -667.066] [304.153], Avg: [-705.676 -705.676 -705.676] (0.9559) ({r_i: None, r_t: [-1434.600 -1434.600 -1434.600], eps: 0.956})
Step:  109700, Reward: [-815.788 -815.788 -815.788] [383.639], Avg: [-705.776 -705.776 -705.776] (0.9559) ({r_i: None, r_t: [-1492.674 -1492.674 -1492.674], eps: 0.956})
Step:  109800, Reward: [-744.998 -744.998 -744.998] [252.856], Avg: [-705.812 -705.812 -705.812] (0.9559) ({r_i: None, r_t: [-1429.876 -1429.876 -1429.876], eps: 0.956})
Step:  109900, Reward: [-789.539 -789.539 -789.539] [284.230], Avg: [-705.888 -705.888 -705.888] (0.9559) ({r_i: None, r_t: [-1533.521 -1533.521 -1533.521], eps: 0.956})
Step:  110000, Reward: [-838.341 -838.341 -838.341] [316.461], Avg: [-706.008 -706.008 -706.008] (0.9559) ({r_i: None, r_t: [-1477.225 -1477.225 -1477.225], eps: 0.956})
Step:  110100, Reward: [-760.694 -760.694 -760.694] [370.459], Avg: [-706.058 -706.058 -706.058] (0.9559) ({r_i: None, r_t: [-1635.296 -1635.296 -1635.296], eps: 0.956})
Step:  110200, Reward: [-881.677 -881.677 -881.677] [363.914], Avg: [-706.217 -706.217 -706.217] (0.9559) ({r_i: None, r_t: [-1728.076 -1728.076 -1728.076], eps: 0.956})
Step:  110300, Reward: [-700.566 -700.566 -700.566] [203.056], Avg: [-706.212 -706.212 -706.212] (0.9559) ({r_i: None, r_t: [-1859.343 -1859.343 -1859.343], eps: 0.956})
Step:  110400, Reward: [-807.636 -807.636 -807.636] [336.161], Avg: [-706.304 -706.304 -706.304] (0.9559) ({r_i: None, r_t: [-1714.045 -1714.045 -1714.045], eps: 0.956})
Step:  110500, Reward: [-845.297 -845.297 -845.297] [360.988], Avg: [-706.430 -706.430 -706.430] (0.9559) ({r_i: None, r_t: [-1594.661 -1594.661 -1594.661], eps: 0.956})
Step:  110600, Reward: [-912.041 -912.041 -912.041] [416.923], Avg: [-706.615 -706.615 -706.615] (0.9559) ({r_i: None, r_t: [-1753.385 -1753.385 -1753.385], eps: 0.956})
Step:  110700, Reward: [-807.777 -807.777 -807.777] [257.838], Avg: [-706.707 -706.707 -706.707] (0.9559) ({r_i: None, r_t: [-1757.261 -1757.261 -1757.261], eps: 0.956})
Step:  110800, Reward: [-683.814 -683.814 -683.814] [237.279], Avg: [-706.686 -706.686 -706.686] (0.9559) ({r_i: None, r_t: [-1622.894 -1622.894 -1622.894], eps: 0.956})
Step:  110900, Reward: [-853.832 -853.832 -853.832] [249.092], Avg: [-706.819 -706.819 -706.819] (0.9559) ({r_i: None, r_t: [-1628.883 -1628.883 -1628.883], eps: 0.956})
Step:  111000, Reward: [-817.531 -817.531 -817.531] [326.133], Avg: [-706.918 -706.918 -706.918] (0.9559) ({r_i: None, r_t: [-1604.101 -1604.101 -1604.101], eps: 0.956})
Step:  111100, Reward: [-828.296 -828.296 -828.296] [412.380], Avg: [-707.027 -707.027 -707.027] (0.9559) ({r_i: None, r_t: [-1911.561 -1911.561 -1911.561], eps: 0.956})
Step:  111200, Reward: [-775.957 -775.957 -775.957] [342.487], Avg: [-707.089 -707.089 -707.089] (0.9559) ({r_i: None, r_t: [-1566.820 -1566.820 -1566.820], eps: 0.956})
Step:  111300, Reward: [-825.725 -825.725 -825.725] [327.972], Avg: [-707.196 -707.196 -707.196] (0.9559) ({r_i: None, r_t: [-1608.109 -1608.109 -1608.109], eps: 0.956})
Step:  111400, Reward: [-855.344 -855.344 -855.344] [303.410], Avg: [-707.329 -707.329 -707.329] (0.9559) ({r_i: None, r_t: [-1537.996 -1537.996 -1537.996], eps: 0.956})
Step:  111500, Reward: [-752.612 -752.612 -752.612] [292.733], Avg: [-707.369 -707.369 -707.369] (0.9559) ({r_i: None, r_t: [-1598.231 -1598.231 -1598.231], eps: 0.956})
Step:  111600, Reward: [-1060.717 -1060.717 -1060.717] [445.311], Avg: [-707.686 -707.686 -707.686] (0.9559) ({r_i: None, r_t: [-1739.285 -1739.285 -1739.285], eps: 0.956})
Step:  111700, Reward: [-886.039 -886.039 -886.039] [416.167], Avg: [-707.845 -707.845 -707.845] (0.9559) ({r_i: None, r_t: [-1602.494 -1602.494 -1602.494], eps: 0.956})
Step:  111800, Reward: [-1037.980 -1037.980 -1037.980] [432.708], Avg: [-708.140 -708.140 -708.140] (0.9559) ({r_i: None, r_t: [-1675.766 -1675.766 -1675.766], eps: 0.956})
Step:  111900, Reward: [-778.975 -778.975 -778.975] [416.962], Avg: [-708.203 -708.203 -708.203] (0.9559) ({r_i: None, r_t: [-1785.616 -1785.616 -1785.616], eps: 0.956})
Step:  112000, Reward: [-756.208 -756.208 -756.208] [291.999], Avg: [-708.246 -708.246 -708.246] (0.9559) ({r_i: None, r_t: [-1637.568 -1637.568 -1637.568], eps: 0.956})
Step:  112100, Reward: [-940.330 -940.330 -940.330] [295.139], Avg: [-708.453 -708.453 -708.453] (0.9559) ({r_i: None, r_t: [-1832.569 -1832.569 -1832.569], eps: 0.956})
Step:  112200, Reward: [-924.486 -924.486 -924.486] [444.862], Avg: [-708.645 -708.645 -708.645] (0.9559) ({r_i: None, r_t: [-1602.860 -1602.860 -1602.860], eps: 0.956})
Step:  112300, Reward: [-870.013 -870.013 -870.013] [298.887], Avg: [-708.789 -708.789 -708.789] (0.9559) ({r_i: None, r_t: [-1785.444 -1785.444 -1785.444], eps: 0.956})
Step:  112400, Reward: [-852.852 -852.852 -852.852] [369.698], Avg: [-708.917 -708.917 -708.917] (0.9559) ({r_i: None, r_t: [-1829.221 -1829.221 -1829.221], eps: 0.956})
Step:  112500, Reward: [-853.837 -853.837 -853.837] [314.388], Avg: [-709.046 -709.046 -709.046] (0.9559) ({r_i: None, r_t: [-2036.265 -2036.265 -2036.265], eps: 0.956})
Step:  112600, Reward: [-930.325 -930.325 -930.325] [420.699], Avg: [-709.242 -709.242 -709.242] (0.9559) ({r_i: None, r_t: [-1895.564 -1895.564 -1895.564], eps: 0.956})
Step:  112700, Reward: [-840.975 -840.975 -840.975] [329.709], Avg: [-709.359 -709.359 -709.359] (0.9559) ({r_i: None, r_t: [-1794.790 -1794.790 -1794.790], eps: 0.956})
Step:  112800, Reward: [-888.280 -888.280 -888.280] [314.730], Avg: [-709.517 -709.517 -709.517] (0.9559) ({r_i: None, r_t: [-1865.165 -1865.165 -1865.165], eps: 0.956})
Step:  112900, Reward: [-916.967 -916.967 -916.967] [412.555], Avg: [-709.701 -709.701 -709.701] (0.9559) ({r_i: None, r_t: [-1807.209 -1807.209 -1807.209], eps: 0.956})
Step:  113000, Reward: [-1001.330 -1001.330 -1001.330] [431.295], Avg: [-709.959 -709.959 -709.959] (0.9559) ({r_i: None, r_t: [-1893.858 -1893.858 -1893.858], eps: 0.956})
Step:  113100, Reward: [-844.653 -844.653 -844.653] [303.231], Avg: [-710.078 -710.078 -710.078] (0.9559) ({r_i: None, r_t: [-1962.828 -1962.828 -1962.828], eps: 0.956})
Step:  113200, Reward: [-963.264 -963.264 -963.264] [324.931], Avg: [-710.301 -710.301 -710.301] (0.9559) ({r_i: None, r_t: [-1895.445 -1895.445 -1895.445], eps: 0.956})
Step:  113300, Reward: [-991.946 -991.946 -991.946] [437.504], Avg: [-710.550 -710.550 -710.550] (0.9559) ({r_i: None, r_t: [-1955.113 -1955.113 -1955.113], eps: 0.956})
Step:  113400, Reward: [-1028.338 -1028.338 -1028.338] [473.862], Avg: [-710.830 -710.830 -710.830] (0.9559) ({r_i: None, r_t: [-1875.201 -1875.201 -1875.201], eps: 0.956})
Step:  113500, Reward: [-1185.633 -1185.633 -1185.633] [363.987], Avg: [-711.248 -711.248 -711.248] (0.9559) ({r_i: None, r_t: [-1873.593 -1873.593 -1873.593], eps: 0.956})
Step:  113600, Reward: [-1052.446 -1052.446 -1052.446] [369.640], Avg: [-711.548 -711.548 -711.548] (0.9559) ({r_i: None, r_t: [-1948.832 -1948.832 -1948.832], eps: 0.956})
Step:  113700, Reward: [-976.960 -976.960 -976.960] [270.271], Avg: [-711.781 -711.781 -711.781] (0.9559) ({r_i: None, r_t: [-1852.420 -1852.420 -1852.420], eps: 0.956})
Step:  113800, Reward: [-955.001 -955.001 -955.001] [400.489], Avg: [-711.994 -711.994 -711.994] (0.9559) ({r_i: None, r_t: [-2073.785 -2073.785 -2073.785], eps: 0.956})
Step:  113900, Reward: [-912.420 -912.420 -912.420] [404.964], Avg: [-712.170 -712.170 -712.170] (0.9559) ({r_i: None, r_t: [-1823.581 -1823.581 -1823.581], eps: 0.956})
Step:  114000, Reward: [-855.724 -855.724 -855.724] [412.639], Avg: [-712.296 -712.296 -712.296] (0.9559) ({r_i: None, r_t: [-1838.438 -1838.438 -1838.438], eps: 0.956})
Step:  114100, Reward: [-1014.360 -1014.360 -1014.360] [389.655], Avg: [-712.560 -712.560 -712.560] (0.9559) ({r_i: None, r_t: [-2013.308 -2013.308 -2013.308], eps: 0.956})
Step:  114200, Reward: [-941.230 -941.230 -941.230] [407.608], Avg: [-712.761 -712.761 -712.761] (0.9559) ({r_i: None, r_t: [-1445.829 -1445.829 -1445.829], eps: 0.956})
Step:  114300, Reward: [-905.997 -905.997 -905.997] [327.709], Avg: [-712.929 -712.929 -712.929] (0.9559) ({r_i: None, r_t: [-2100.295 -2100.295 -2100.295], eps: 0.956})
Step:  114400, Reward: [-944.450 -944.450 -944.450] [399.751], Avg: [-713.132 -713.132 -713.132] (0.9559) ({r_i: None, r_t: [-1966.461 -1966.461 -1966.461], eps: 0.956})
Step:  114500, Reward: [-1095.442 -1095.442 -1095.442] [299.659], Avg: [-713.465 -713.465 -713.465] (0.9559) ({r_i: None, r_t: [-2215.107 -2215.107 -2215.107], eps: 0.956})
Step:  114600, Reward: [-926.714 -926.714 -926.714] [392.860], Avg: [-713.651 -713.651 -713.651] (0.9559) ({r_i: None, r_t: [-1782.492 -1782.492 -1782.492], eps: 0.956})
Step:  114700, Reward: [-1007.495 -1007.495 -1007.495] [503.227], Avg: [-713.907 -713.907 -713.907] (0.9559) ({r_i: None, r_t: [-2068.577 -2068.577 -2068.577], eps: 0.956})
Step:  114800, Reward: [-886.185 -886.185 -886.185] [424.580], Avg: [-714.057 -714.057 -714.057] (0.9559) ({r_i: None, r_t: [-2074.051 -2074.051 -2074.051], eps: 0.956})
Step:  114900, Reward: [-979.602 -979.602 -979.602] [462.855], Avg: [-714.288 -714.288 -714.288] (0.9559) ({r_i: None, r_t: [-2014.774 -2014.774 -2014.774], eps: 0.956})
Step:  115000, Reward: [-1045.641 -1045.641 -1045.641] [301.915], Avg: [-714.576 -714.576 -714.576] (0.9559) ({r_i: None, r_t: [-1801.961 -1801.961 -1801.961], eps: 0.956})
Step:  115100, Reward: [-904.431 -904.431 -904.431] [363.260], Avg: [-714.741 -714.741 -714.741] (0.9559) ({r_i: None, r_t: [-2190.811 -2190.811 -2190.811], eps: 0.956})
Step:  115200, Reward: [-995.408 -995.408 -995.408] [318.727], Avg: [-714.984 -714.984 -714.984] (0.9559) ({r_i: None, r_t: [-2270.878 -2270.878 -2270.878], eps: 0.956})
Step:  115300, Reward: [-1064.473 -1064.473 -1064.473] [494.912], Avg: [-715.287 -715.287 -715.287] (0.9559) ({r_i: None, r_t: [-2142.090 -2142.090 -2142.090], eps: 0.956})
Step:  115400, Reward: [-1026.237 -1026.237 -1026.237] [248.592], Avg: [-715.556 -715.556 -715.556] (0.9559) ({r_i: None, r_t: [-2026.123 -2026.123 -2026.123], eps: 0.956})
Step:  115500, Reward: [-1060.778 -1060.778 -1060.778] [316.286], Avg: [-715.855 -715.855 -715.855] (0.9559) ({r_i: None, r_t: [-1952.938 -1952.938 -1952.938], eps: 0.956})
Step:  115600, Reward: [-1056.965 -1056.965 -1056.965] [432.671], Avg: [-716.150 -716.150 -716.150] (0.9559) ({r_i: None, r_t: [-1887.106 -1887.106 -1887.106], eps: 0.956})
Step:  115700, Reward: [-898.435 -898.435 -898.435] [374.159], Avg: [-716.307 -716.307 -716.307] (0.9559) ({r_i: None, r_t: [-2336.296 -2336.296 -2336.296], eps: 0.956})
Step:  115800, Reward: [-919.697 -919.697 -919.697] [417.360], Avg: [-716.483 -716.483 -716.483] (0.9559) ({r_i: None, r_t: [-2109.348 -2109.348 -2109.348], eps: 0.956})
Step:  115900, Reward: [-1130.619 -1130.619 -1130.619] [447.632], Avg: [-716.840 -716.840 -716.840] (0.9559) ({r_i: None, r_t: [-1955.705 -1955.705 -1955.705], eps: 0.956})
Step:  116000, Reward: [-989.536 -989.536 -989.536] [384.590], Avg: [-717.074 -717.074 -717.074] (0.9559) ({r_i: None, r_t: [-1985.924 -1985.924 -1985.924], eps: 0.956})
Step:  116100, Reward: [-1011.695 -1011.695 -1011.695] [342.449], Avg: [-717.328 -717.328 -717.328] (0.9559) ({r_i: None, r_t: [-2253.838 -2253.838 -2253.838], eps: 0.956})
Step:  116200, Reward: [-1189.420 -1189.420 -1189.420] [359.174], Avg: [-717.734 -717.734 -717.734] (0.9559) ({r_i: None, r_t: [-2001.758 -2001.758 -2001.758], eps: 0.956})
Step:  116300, Reward: [-930.314 -930.314 -930.314] [280.431], Avg: [-717.917 -717.917 -717.917] (0.9559) ({r_i: None, r_t: [-2161.382 -2161.382 -2161.382], eps: 0.956})
Step:  116400, Reward: [-1068.003 -1068.003 -1068.003] [354.140], Avg: [-718.217 -718.217 -718.217] (0.9559) ({r_i: None, r_t: [-2026.655 -2026.655 -2026.655], eps: 0.956})
Step:  116500, Reward: [-1226.413 -1226.413 -1226.413] [350.272], Avg: [-718.653 -718.653 -718.653] (0.9559) ({r_i: None, r_t: [-2072.375 -2072.375 -2072.375], eps: 0.956})
Step:  116600, Reward: [-1177.783 -1177.783 -1177.783] [344.986], Avg: [-719.046 -719.046 -719.046] (0.9559) ({r_i: None, r_t: [-1877.129 -1877.129 -1877.129], eps: 0.956})
Step:  116700, Reward: [-994.247 -994.247 -994.247] [400.206], Avg: [-719.282 -719.282 -719.282] (0.9559) ({r_i: None, r_t: [-2393.059 -2393.059 -2393.059], eps: 0.956})
Step:  116800, Reward: [-1039.336 -1039.336 -1039.336] [384.751], Avg: [-719.556 -719.556 -719.556] (0.9559) ({r_i: None, r_t: [-2335.039 -2335.039 -2335.039], eps: 0.956})
Step:  116900, Reward: [-1288.163 -1288.163 -1288.163] [272.428], Avg: [-720.042 -720.042 -720.042] (0.9559) ({r_i: None, r_t: [-1821.988 -1821.988 -1821.988], eps: 0.956})
Step:  117000, Reward: [-846.264 -846.264 -846.264] [268.676], Avg: [-720.149 -720.149 -720.149] (0.9559) ({r_i: None, r_t: [-2182.742 -2182.742 -2182.742], eps: 0.956})
Step:  117100, Reward: [-1232.934 -1232.934 -1232.934] [532.747], Avg: [-720.587 -720.587 -720.587] (0.9559) ({r_i: None, r_t: [-2243.508 -2243.508 -2243.508], eps: 0.956})
Step:  117200, Reward: [-947.499 -947.499 -947.499] [422.546], Avg: [-720.780 -720.780 -720.780] (0.9559) ({r_i: None, r_t: [-1948.897 -1948.897 -1948.897], eps: 0.956})
Step:  117300, Reward: [-1055.763 -1055.763 -1055.763] [327.869], Avg: [-721.066 -721.066 -721.066] (0.9559) ({r_i: None, r_t: [-2008.259 -2008.259 -2008.259], eps: 0.956})
Step:  117400, Reward: [-1026.529 -1026.529 -1026.529] [435.102], Avg: [-721.326 -721.326 -721.326] (0.9559) ({r_i: None, r_t: [-1962.393 -1962.393 -1962.393], eps: 0.956})
Step:  117500, Reward: [-1081.251 -1081.251 -1081.251] [382.570], Avg: [-721.632 -721.632 -721.632] (0.9559) ({r_i: None, r_t: [-2043.828 -2043.828 -2043.828], eps: 0.956})
Step:  117600, Reward: [-1060.885 -1060.885 -1060.885] [330.468], Avg: [-721.920 -721.920 -721.920] (0.9559) ({r_i: None, r_t: [-2359.212 -2359.212 -2359.212], eps: 0.956})
Step:  117700, Reward: [-1134.126 -1134.126 -1134.126] [373.187], Avg: [-722.270 -722.270 -722.270] (0.9559) ({r_i: None, r_t: [-2274.875 -2274.875 -2274.875], eps: 0.956})
Step:  117800, Reward: [-1006.252 -1006.252 -1006.252] [367.587], Avg: [-722.511 -722.511 -722.511] (0.9559) ({r_i: None, r_t: [-2281.000 -2281.000 -2281.000], eps: 0.956})
Step:  117900, Reward: [-924.569 -924.569 -924.569] [355.721], Avg: [-722.682 -722.682 -722.682] (0.9559) ({r_i: None, r_t: [-2135.166 -2135.166 -2135.166], eps: 0.956})
Step:  118000, Reward: [-1008.156 -1008.156 -1008.156] [307.414], Avg: [-722.924 -722.924 -722.924] (0.9559) ({r_i: None, r_t: [-2243.754 -2243.754 -2243.754], eps: 0.956})
Step:  118100, Reward: [-1106.405 -1106.405 -1106.405] [296.763], Avg: [-723.248 -723.248 -723.248] (0.9559) ({r_i: None, r_t: [-2114.515 -2114.515 -2114.515], eps: 0.956})
Step:  118200, Reward: [-1011.155 -1011.155 -1011.155] [297.420], Avg: [-723.492 -723.492 -723.492] (0.9559) ({r_i: None, r_t: [-1916.994 -1916.994 -1916.994], eps: 0.956})
Step:  118300, Reward: [-1088.014 -1088.014 -1088.014] [435.914], Avg: [-723.799 -723.799 -723.799] (0.9559) ({r_i: None, r_t: [-2425.522 -2425.522 -2425.522], eps: 0.956})
Step:  118400, Reward: [-1046.566 -1046.566 -1046.566] [339.115], Avg: [-724.072 -724.072 -724.072] (0.9559) ({r_i: None, r_t: [-2103.468 -2103.468 -2103.468], eps: 0.956})
Step:  118500, Reward: [-1108.462 -1108.462 -1108.462] [265.332], Avg: [-724.396 -724.396 -724.396] (0.9559) ({r_i: None, r_t: [-2130.642 -2130.642 -2130.642], eps: 0.956})
Step:  118600, Reward: [-1193.117 -1193.117 -1193.117] [521.002], Avg: [-724.791 -724.791 -724.791] (0.9559) ({r_i: None, r_t: [-2031.822 -2031.822 -2031.822], eps: 0.956})
Step:  118700, Reward: [-1114.932 -1114.932 -1114.932] [414.351], Avg: [-725.119 -725.119 -725.119] (0.9559) ({r_i: None, r_t: [-2448.704 -2448.704 -2448.704], eps: 0.956})
Step:  118800, Reward: [-1118.980 -1118.980 -1118.980] [345.476], Avg: [-725.451 -725.451 -725.451] (0.9559) ({r_i: None, r_t: [-2237.396 -2237.396 -2237.396], eps: 0.956})
Step:  118900, Reward: [-1081.553 -1081.553 -1081.553] [286.397], Avg: [-725.750 -725.750 -725.750] (0.9559) ({r_i: None, r_t: [-2265.669 -2265.669 -2265.669], eps: 0.956})
Step:  119000, Reward: [-1074.491 -1074.491 -1074.491] [386.500], Avg: [-726.043 -726.043 -726.043] (0.9559) ({r_i: None, r_t: [-1876.543 -1876.543 -1876.543], eps: 0.956})
Step:  119100, Reward: [-931.496 -931.496 -931.496] [227.447], Avg: [-726.215 -726.215 -726.215] (0.9559) ({r_i: None, r_t: [-2053.695 -2053.695 -2053.695], eps: 0.956})
Step:  119200, Reward: [-1046.758 -1046.758 -1046.758] [430.677], Avg: [-726.484 -726.484 -726.484] (0.9559) ({r_i: None, r_t: [-2251.101 -2251.101 -2251.101], eps: 0.956})
Step:  119300, Reward: [-962.975 -962.975 -962.975] [244.399], Avg: [-726.682 -726.682 -726.682] (0.9559) ({r_i: None, r_t: [-2072.985 -2072.985 -2072.985], eps: 0.956})
Step:  119400, Reward: [-995.632 -995.632 -995.632] [257.323], Avg: [-726.907 -726.907 -726.907] (0.9559) ({r_i: None, r_t: [-2131.743 -2131.743 -2131.743], eps: 0.956})
Step:  119500, Reward: [-1055.602 -1055.602 -1055.602] [323.513], Avg: [-727.182 -727.182 -727.182] (0.9559) ({r_i: None, r_t: [-2117.717 -2117.717 -2117.717], eps: 0.956})
Step:  119600, Reward: [-1128.479 -1128.479 -1128.479] [316.706], Avg: [-727.517 -727.517 -727.517] (0.9559) ({r_i: None, r_t: [-2195.816 -2195.816 -2195.816], eps: 0.956})
Step:  119700, Reward: [-1005.778 -1005.778 -1005.778] [328.102], Avg: [-727.749 -727.749 -727.749] (0.9559) ({r_i: None, r_t: [-1951.207 -1951.207 -1951.207], eps: 0.956})
Step:  119800, Reward: [-1038.747 -1038.747 -1038.747] [322.570], Avg: [-728.008 -728.008 -728.008] (0.9559) ({r_i: None, r_t: [-2104.817 -2104.817 -2104.817], eps: 0.956})
Step:  119900, Reward: [-1161.436 -1161.436 -1161.436] [298.750], Avg: [-728.370 -728.370 -728.370] (0.9559) ({r_i: None, r_t: [-2143.246 -2143.246 -2143.246], eps: 0.956})
Step:  120000, Reward: [-1027.147 -1027.147 -1027.147] [217.533], Avg: [-728.618 -728.618 -728.618] (0.9559) ({r_i: None, r_t: [-2195.006 -2195.006 -2195.006], eps: 0.956})
Step:  120100, Reward: [-902.504 -902.504 -902.504] [182.531], Avg: [-728.763 -728.763 -728.763] (0.9511) ({r_i: None, r_t: [-1879.704 -1879.704 -1879.704], eps: 0.951})
Step:  120200, Reward: [-1032.053 -1032.053 -1032.053] [366.221], Avg: [-729.015 -729.015 -729.015] (0.9511) ({r_i: None, r_t: [-2263.597 -2263.597 -2263.597], eps: 0.951})
Step:  120300, Reward: [-983.685 -983.685 -983.685] [262.333], Avg: [-729.227 -729.227 -729.227] (0.9511) ({r_i: None, r_t: [-1916.497 -1916.497 -1916.497], eps: 0.951})
Step:  120400, Reward: [-1115.401 -1115.401 -1115.401] [303.120], Avg: [-729.547 -729.547 -729.547] (0.9511) ({r_i: None, r_t: [-1825.356 -1825.356 -1825.356], eps: 0.951})
Step:  120500, Reward: [-1024.536 -1024.536 -1024.536] [262.575], Avg: [-729.792 -729.792 -729.792] (0.9511) ({r_i: None, r_t: [-2046.627 -2046.627 -2046.627], eps: 0.951})
Step:  120600, Reward: [-984.956 -984.956 -984.956] [249.888], Avg: [-730.003 -730.003 -730.003] (0.9511) ({r_i: None, r_t: [-1990.823 -1990.823 -1990.823], eps: 0.951})
Step:  120700, Reward: [-1044.048 -1044.048 -1044.048] [218.718], Avg: [-730.263 -730.263 -730.263] (0.9511) ({r_i: None, r_t: [-2089.538 -2089.538 -2089.538], eps: 0.951})
Step:  120800, Reward: [-977.918 -977.918 -977.918] [251.777], Avg: [-730.468 -730.468 -730.468] (0.9511) ({r_i: None, r_t: [-1919.973 -1919.973 -1919.973], eps: 0.951})
Step:  120900, Reward: [-1082.101 -1082.101 -1082.101] [214.385], Avg: [-730.759 -730.759 -730.759] (0.9511) ({r_i: None, r_t: [-2095.694 -2095.694 -2095.694], eps: 0.951})
Step:  121000, Reward: [-1010.518 -1010.518 -1010.518] [233.361], Avg: [-730.990 -730.990 -730.990] (0.9511) ({r_i: None, r_t: [-2091.975 -2091.975 -2091.975], eps: 0.951})
Step:  121100, Reward: [-930.749 -930.749 -930.749] [227.221], Avg: [-731.154 -731.154 -731.154] (0.9511) ({r_i: None, r_t: [-1854.074 -1854.074 -1854.074], eps: 0.951})
Step:  121200, Reward: [-1040.403 -1040.403 -1040.403] [298.348], Avg: [-731.409 -731.409 -731.409] (0.9511) ({r_i: None, r_t: [-1743.435 -1743.435 -1743.435], eps: 0.951})
Step:  121300, Reward: [-970.761 -970.761 -970.761] [256.977], Avg: [-731.607 -731.607 -731.607] (0.9511) ({r_i: None, r_t: [-1811.424 -1811.424 -1811.424], eps: 0.951})
Step:  121400, Reward: [-960.238 -960.238 -960.238] [268.240], Avg: [-731.795 -731.795 -731.795] (0.9511) ({r_i: None, r_t: [-1850.443 -1850.443 -1850.443], eps: 0.951})
Step:  121500, Reward: [-924.192 -924.192 -924.192] [197.109], Avg: [-731.953 -731.953 -731.953] (0.9511) ({r_i: None, r_t: [-1758.944 -1758.944 -1758.944], eps: 0.951})
Step:  121600, Reward: [-985.697 -985.697 -985.697] [230.592], Avg: [-732.161 -732.161 -732.161] (0.9511) ({r_i: None, r_t: [-2021.051 -2021.051 -2021.051], eps: 0.951})
Step:  121700, Reward: [-907.614 -907.614 -907.614] [214.398], Avg: [-732.306 -732.306 -732.306] (0.9511) ({r_i: None, r_t: [-1887.063 -1887.063 -1887.063], eps: 0.951})
Step:  121800, Reward: [-997.650 -997.650 -997.650] [241.991], Avg: [-732.523 -732.523 -732.523] (0.9511) ({r_i: None, r_t: [-1877.540 -1877.540 -1877.540], eps: 0.951})
Step:  121900, Reward: [-907.207 -907.207 -907.207] [234.977], Avg: [-732.666 -732.666 -732.666] (0.9511) ({r_i: None, r_t: [-1958.995 -1958.995 -1958.995], eps: 0.951})
Step:  122000, Reward: [-967.677 -967.677 -967.677] [283.098], Avg: [-732.859 -732.859 -732.859] (0.9511) ({r_i: None, r_t: [-1792.684 -1792.684 -1792.684], eps: 0.951})
Step:  122100, Reward: [-1000.902 -1000.902 -1000.902] [231.742], Avg: [-733.078 -733.078 -733.078] (0.9511) ({r_i: None, r_t: [-1846.003 -1846.003 -1846.003], eps: 0.951})
Step:  122200, Reward: [-1002.759 -1002.759 -1002.759] [146.612], Avg: [-733.299 -733.299 -733.299] (0.9511) ({r_i: None, r_t: [-1827.709 -1827.709 -1827.709], eps: 0.951})
Step:  122300, Reward: [-898.807 -898.807 -898.807] [166.700], Avg: [-733.434 -733.434 -733.434] (0.9511) ({r_i: None, r_t: [-1768.476 -1768.476 -1768.476], eps: 0.951})
Step:  122400, Reward: [-930.554 -930.554 -930.554] [265.702], Avg: [-733.595 -733.595 -733.595] (0.9511) ({r_i: None, r_t: [-1878.069 -1878.069 -1878.069], eps: 0.951})
Step:  122500, Reward: [-964.124 -964.124 -964.124] [248.429], Avg: [-733.783 -733.783 -733.783] (0.9511) ({r_i: None, r_t: [-1991.151 -1991.151 -1991.151], eps: 0.951})
Step:  122600, Reward: [-915.535 -915.535 -915.535] [236.773], Avg: [-733.931 -733.931 -733.931] (0.9511) ({r_i: None, r_t: [-1835.377 -1835.377 -1835.377], eps: 0.951})
Step:  122700, Reward: [-903.624 -903.624 -903.624] [287.247], Avg: [-734.069 -734.069 -734.069] (0.9511) ({r_i: None, r_t: [-1829.300 -1829.300 -1829.300], eps: 0.951})
Step:  122800, Reward: [-876.680 -876.680 -876.680] [136.536], Avg: [-734.185 -734.185 -734.185] (0.9511) ({r_i: None, r_t: [-1710.512 -1710.512 -1710.512], eps: 0.951})
Step:  122900, Reward: [-909.807 -909.807 -909.807] [174.279], Avg: [-734.328 -734.328 -734.328] (0.9511) ({r_i: None, r_t: [-1674.916 -1674.916 -1674.916], eps: 0.951})
Step:  123000, Reward: [-1075.219 -1075.219 -1075.219] [186.502], Avg: [-734.605 -734.605 -734.605] (0.9511) ({r_i: None, r_t: [-1884.211 -1884.211 -1884.211], eps: 0.951})
Step:  123100, Reward: [-862.807 -862.807 -862.807] [198.891], Avg: [-734.709 -734.709 -734.709] (0.9511) ({r_i: None, r_t: [-1790.502 -1790.502 -1790.502], eps: 0.951})
Step:  123200, Reward: [-991.127 -991.127 -991.127] [260.435], Avg: [-734.917 -734.917 -734.917] (0.9511) ({r_i: None, r_t: [-1579.346 -1579.346 -1579.346], eps: 0.951})
Step:  123300, Reward: [-849.310 -849.310 -849.310] [210.773], Avg: [-735.010 -735.010 -735.010] (0.9511) ({r_i: None, r_t: [-1814.855 -1814.855 -1814.855], eps: 0.951})
Step:  123400, Reward: [-931.267 -931.267 -931.267] [231.562], Avg: [-735.169 -735.169 -735.169] (0.9511) ({r_i: None, r_t: [-1769.306 -1769.306 -1769.306], eps: 0.951})
Step:  123500, Reward: [-1003.726 -1003.726 -1003.726] [307.724], Avg: [-735.386 -735.386 -735.386] (0.9511) ({r_i: None, r_t: [-1676.559 -1676.559 -1676.559], eps: 0.951})
Step:  123600, Reward: [-831.554 -831.554 -831.554] [170.755], Avg: [-735.464 -735.464 -735.464] (0.9511) ({r_i: None, r_t: [-1769.297 -1769.297 -1769.297], eps: 0.951})
Step:  123700, Reward: [-866.603 -866.603 -866.603] [193.888], Avg: [-735.570 -735.570 -735.570] (0.9511) ({r_i: None, r_t: [-1702.586 -1702.586 -1702.586], eps: 0.951})
Step:  123800, Reward: [-923.998 -923.998 -923.998] [205.512], Avg: [-735.722 -735.722 -735.722] (0.9511) ({r_i: None, r_t: [-1704.238 -1704.238 -1704.238], eps: 0.951})
Step:  123900, Reward: [-843.036 -843.036 -843.036] [186.347], Avg: [-735.808 -735.808 -735.808] (0.9511) ({r_i: None, r_t: [-1622.786 -1622.786 -1622.786], eps: 0.951})
Step:  124000, Reward: [-841.921 -841.921 -841.921] [219.483], Avg: [-735.894 -735.894 -735.894] (0.9511) ({r_i: None, r_t: [-1703.515 -1703.515 -1703.515], eps: 0.951})
Step:  124100, Reward: [-834.333 -834.333 -834.333] [217.424], Avg: [-735.973 -735.973 -735.973] (0.9511) ({r_i: None, r_t: [-1710.375 -1710.375 -1710.375], eps: 0.951})
Step:  124200, Reward: [-819.509 -819.509 -819.509] [167.127], Avg: [-736.040 -736.040 -736.040] (0.9511) ({r_i: None, r_t: [-1697.750 -1697.750 -1697.750], eps: 0.951})
Step:  124300, Reward: [-905.216 -905.216 -905.216] [238.005], Avg: [-736.176 -736.176 -736.176] (0.9511) ({r_i: None, r_t: [-1759.985 -1759.985 -1759.985], eps: 0.951})
Step:  124400, Reward: [-839.972 -839.972 -839.972] [189.202], Avg: [-736.259 -736.259 -736.259] (0.9511) ({r_i: None, r_t: [-1666.412 -1666.412 -1666.412], eps: 0.951})
Step:  124500, Reward: [-865.727 -865.727 -865.727] [187.732], Avg: [-736.363 -736.363 -736.363] (0.9511) ({r_i: None, r_t: [-1815.121 -1815.121 -1815.121], eps: 0.951})
Step:  124600, Reward: [-825.399 -825.399 -825.399] [169.036], Avg: [-736.435 -736.435 -736.435] (0.9511) ({r_i: None, r_t: [-1809.463 -1809.463 -1809.463], eps: 0.951})
Step:  124700, Reward: [-806.744 -806.744 -806.744] [204.023], Avg: [-736.491 -736.491 -736.491] (0.9511) ({r_i: None, r_t: [-1652.782 -1652.782 -1652.782], eps: 0.951})
Step:  124800, Reward: [-791.079 -791.079 -791.079] [214.998], Avg: [-736.535 -736.535 -736.535] (0.9511) ({r_i: None, r_t: [-1890.638 -1890.638 -1890.638], eps: 0.951})
Step:  124900, Reward: [-830.377 -830.377 -830.377] [155.905], Avg: [-736.610 -736.610 -736.610] (0.9511) ({r_i: None, r_t: [-1723.736 -1723.736 -1723.736], eps: 0.951})
Step:  125000, Reward: [-810.469 -810.469 -810.469] [216.058], Avg: [-736.669 -736.669 -736.669] (0.9511) ({r_i: None, r_t: [-1685.656 -1685.656 -1685.656], eps: 0.951})
Step:  125100, Reward: [-825.374 -825.374 -825.374] [190.903], Avg: [-736.740 -736.740 -736.740] (0.9511) ({r_i: None, r_t: [-1588.491 -1588.491 -1588.491], eps: 0.951})
Step:  125200, Reward: [-772.037 -772.037 -772.037] [145.310], Avg: [-736.768 -736.768 -736.768] (0.9511) ({r_i: None, r_t: [-1557.197 -1557.197 -1557.197], eps: 0.951})
Step:  125300, Reward: [-778.581 -778.581 -778.581] [224.864], Avg: [-736.801 -736.801 -736.801] (0.9511) ({r_i: None, r_t: [-1590.668 -1590.668 -1590.668], eps: 0.951})
Step:  125400, Reward: [-763.447 -763.447 -763.447] [169.859], Avg: [-736.823 -736.823 -736.823] (0.9511) ({r_i: None, r_t: [-1634.487 -1634.487 -1634.487], eps: 0.951})
Step:  125500, Reward: [-856.261 -856.261 -856.261] [175.443], Avg: [-736.918 -736.918 -736.918] (0.9511) ({r_i: None, r_t: [-1674.549 -1674.549 -1674.549], eps: 0.951})
Step:  125600, Reward: [-844.242 -844.242 -844.242] [187.935], Avg: [-737.003 -737.003 -737.003] (0.9511) ({r_i: None, r_t: [-1451.133 -1451.133 -1451.133], eps: 0.951})
Step:  125700, Reward: [-875.719 -875.719 -875.719] [203.423], Avg: [-737.113 -737.113 -737.113] (0.9511) ({r_i: None, r_t: [-1525.580 -1525.580 -1525.580], eps: 0.951})
Step:  125800, Reward: [-832.598 -832.598 -832.598] [191.751], Avg: [-737.189 -737.189 -737.189] (0.9511) ({r_i: None, r_t: [-1449.906 -1449.906 -1449.906], eps: 0.951})
Step:  125900, Reward: [-827.771 -827.771 -827.771] [218.646], Avg: [-737.261 -737.261 -737.261] (0.9511) ({r_i: None, r_t: [-1709.953 -1709.953 -1709.953], eps: 0.951})
Step:  126000, Reward: [-892.259 -892.259 -892.259] [177.249], Avg: [-737.384 -737.384 -737.384] (0.9511) ({r_i: None, r_t: [-1773.486 -1773.486 -1773.486], eps: 0.951})
Step:  126100, Reward: [-817.104 -817.104 -817.104] [232.495], Avg: [-737.447 -737.447 -737.447] (0.9511) ({r_i: None, r_t: [-1622.078 -1622.078 -1622.078], eps: 0.951})
Step:  126200, Reward: [-787.929 -787.929 -787.929] [186.411], Avg: [-737.487 -737.487 -737.487] (0.9511) ({r_i: None, r_t: [-1597.234 -1597.234 -1597.234], eps: 0.951})
Step:  126300, Reward: [-809.867 -809.867 -809.867] [181.882], Avg: [-737.544 -737.544 -737.544] (0.9511) ({r_i: None, r_t: [-1547.558 -1547.558 -1547.558], eps: 0.951})
Step:  126400, Reward: [-689.133 -689.133 -689.133] [155.321], Avg: [-737.506 -737.506 -737.506] (0.9511) ({r_i: None, r_t: [-1516.491 -1516.491 -1516.491], eps: 0.951})
Step:  126500, Reward: [-815.232 -815.232 -815.232] [215.349], Avg: [-737.567 -737.567 -737.567] (0.9511) ({r_i: None, r_t: [-1596.910 -1596.910 -1596.910], eps: 0.951})
Step:  126600, Reward: [-887.352 -887.352 -887.352] [176.707], Avg: [-737.686 -737.686 -737.686] (0.9511) ({r_i: None, r_t: [-1613.817 -1613.817 -1613.817], eps: 0.951})
Step:  126700, Reward: [-864.452 -864.452 -864.452] [206.978], Avg: [-737.786 -737.786 -737.786] (0.9511) ({r_i: None, r_t: [-1598.423 -1598.423 -1598.423], eps: 0.951})
Step:  126800, Reward: [-700.896 -700.896 -700.896] [186.134], Avg: [-737.757 -737.757 -737.757] (0.9511) ({r_i: None, r_t: [-1553.312 -1553.312 -1553.312], eps: 0.951})
Step:  126900, Reward: [-802.194 -802.194 -802.194] [199.370], Avg: [-737.807 -737.807 -737.807] (0.9511) ({r_i: None, r_t: [-1563.769 -1563.769 -1563.769], eps: 0.951})
Step:  127000, Reward: [-718.853 -718.853 -718.853] [159.725], Avg: [-737.792 -737.792 -737.792] (0.9511) ({r_i: None, r_t: [-1561.117 -1561.117 -1561.117], eps: 0.951})
Step:  127100, Reward: [-851.705 -851.705 -851.705] [186.601], Avg: [-737.882 -737.882 -737.882] (0.9511) ({r_i: None, r_t: [-1618.778 -1618.778 -1618.778], eps: 0.951})
Step:  127200, Reward: [-715.064 -715.064 -715.064] [180.109], Avg: [-737.864 -737.864 -737.864] (0.9511) ({r_i: None, r_t: [-1565.023 -1565.023 -1565.023], eps: 0.951})
Step:  127300, Reward: [-755.738 -755.738 -755.738] [165.608], Avg: [-737.878 -737.878 -737.878] (0.9511) ({r_i: None, r_t: [-1632.179 -1632.179 -1632.179], eps: 0.951})
Step:  127400, Reward: [-742.292 -742.292 -742.292] [181.689], Avg: [-737.882 -737.882 -737.882] (0.9511) ({r_i: None, r_t: [-1634.530 -1634.530 -1634.530], eps: 0.951})
Step:  127500, Reward: [-753.459 -753.459 -753.459] [174.518], Avg: [-737.894 -737.894 -737.894] (0.9511) ({r_i: None, r_t: [-1395.993 -1395.993 -1395.993], eps: 0.951})
Step:  127600, Reward: [-852.998 -852.998 -852.998] [189.088], Avg: [-737.984 -737.984 -737.984] (0.9511) ({r_i: None, r_t: [-1413.265 -1413.265 -1413.265], eps: 0.951})
Step:  127700, Reward: [-714.795 -714.795 -714.795] [120.822], Avg: [-737.966 -737.966 -737.966] (0.9511) ({r_i: None, r_t: [-1452.327 -1452.327 -1452.327], eps: 0.951})
Step:  127800, Reward: [-737.834 -737.834 -737.834] [196.951], Avg: [-737.966 -737.966 -737.966] (0.9511) ({r_i: None, r_t: [-1516.015 -1516.015 -1516.015], eps: 0.951})
Step:  127900, Reward: [-763.569 -763.569 -763.569] [193.114], Avg: [-737.986 -737.986 -737.986] (0.9511) ({r_i: None, r_t: [-1547.300 -1547.300 -1547.300], eps: 0.951})
Step:  128000, Reward: [-778.841 -778.841 -778.841] [162.774], Avg: [-738.018 -738.018 -738.018] (0.9511) ({r_i: None, r_t: [-1475.734 -1475.734 -1475.734], eps: 0.951})
Step:  128100, Reward: [-752.912 -752.912 -752.912] [181.065], Avg: [-738.029 -738.029 -738.029] (0.9511) ({r_i: None, r_t: [-1507.330 -1507.330 -1507.330], eps: 0.951})
Step:  128200, Reward: [-725.011 -725.011 -725.011] [160.389], Avg: [-738.019 -738.019 -738.019] (0.9511) ({r_i: None, r_t: [-1386.009 -1386.009 -1386.009], eps: 0.951})
Step:  128300, Reward: [-744.819 -744.819 -744.819] [177.449], Avg: [-738.024 -738.024 -738.024] (0.9511) ({r_i: None, r_t: [-1504.305 -1504.305 -1504.305], eps: 0.951})
Step:  128400, Reward: [-749.411 -749.411 -749.411] [97.242], Avg: [-738.033 -738.033 -738.033] (0.9511) ({r_i: None, r_t: [-1485.230 -1485.230 -1485.230], eps: 0.951})
Step:  128500, Reward: [-767.727 -767.727 -767.727] [176.939], Avg: [-738.056 -738.056 -738.056] (0.9511) ({r_i: None, r_t: [-1420.522 -1420.522 -1420.522], eps: 0.951})
Step:  128600, Reward: [-689.285 -689.285 -689.285] [160.571], Avg: [-738.018 -738.018 -738.018] (0.9511) ({r_i: None, r_t: [-1383.149 -1383.149 -1383.149], eps: 0.951})
Step:  128700, Reward: [-662.833 -662.833 -662.833] [165.949], Avg: [-737.960 -737.960 -737.960] (0.9511) ({r_i: None, r_t: [-1542.172 -1542.172 -1542.172], eps: 0.951})
Step:  128800, Reward: [-737.084 -737.084 -737.084] [209.409], Avg: [-737.959 -737.959 -737.959] (0.9511) ({r_i: None, r_t: [-1418.304 -1418.304 -1418.304], eps: 0.951})
Step:  128900, Reward: [-799.467 -799.467 -799.467] [123.932], Avg: [-738.007 -738.007 -738.007] (0.9511) ({r_i: None, r_t: [-1518.848 -1518.848 -1518.848], eps: 0.951})
Step:  129000, Reward: [-710.380 -710.380 -710.380] [188.428], Avg: [-737.986 -737.986 -737.986] (0.9511) ({r_i: None, r_t: [-1472.919 -1472.919 -1472.919], eps: 0.951})
Step:  129100, Reward: [-760.403 -760.403 -760.403] [137.029], Avg: [-738.003 -738.003 -738.003] (0.9511) ({r_i: None, r_t: [-1448.978 -1448.978 -1448.978], eps: 0.951})
Step:  129200, Reward: [-675.161 -675.161 -675.161] [121.862], Avg: [-737.954 -737.954 -737.954] (0.9511) ({r_i: None, r_t: [-1543.073 -1543.073 -1543.073], eps: 0.951})
Step:  129300, Reward: [-660.802 -660.802 -660.802] [111.485], Avg: [-737.895 -737.895 -737.895] (0.9511) ({r_i: None, r_t: [-1416.472 -1416.472 -1416.472], eps: 0.951})
Step:  129400, Reward: [-675.351 -675.351 -675.351] [140.765], Avg: [-737.846 -737.846 -737.846] (0.9511) ({r_i: None, r_t: [-1508.541 -1508.541 -1508.541], eps: 0.951})
Step:  129500, Reward: [-753.049 -753.049 -753.049] [146.268], Avg: [-737.858 -737.858 -737.858] (0.9511) ({r_i: None, r_t: [-1450.388 -1450.388 -1450.388], eps: 0.951})
Step:  129600, Reward: [-641.446 -641.446 -641.446] [138.809], Avg: [-737.784 -737.784 -737.784] (0.9511) ({r_i: None, r_t: [-1536.938 -1536.938 -1536.938], eps: 0.951})
Step:  129700, Reward: [-695.731 -695.731 -695.731] [128.482], Avg: [-737.751 -737.751 -737.751] (0.9511) ({r_i: None, r_t: [-1463.842 -1463.842 -1463.842], eps: 0.951})
Step:  129800, Reward: [-673.222 -673.222 -673.222] [187.035], Avg: [-737.702 -737.702 -737.702] (0.9511) ({r_i: None, r_t: [-1429.322 -1429.322 -1429.322], eps: 0.951})
Step:  129900, Reward: [-737.997 -737.997 -737.997] [166.321], Avg: [-737.702 -737.702 -737.702] (0.9511) ({r_i: None, r_t: [-1417.217 -1417.217 -1417.217], eps: 0.951})
Step:  130000, Reward: [-668.152 -668.152 -668.152] [159.796], Avg: [-737.648 -737.648 -737.648] (0.9511) ({r_i: None, r_t: [-1417.872 -1417.872 -1417.872], eps: 0.951})
Step:  130100, Reward: [-716.616 -716.616 -716.616] [162.440], Avg: [-737.632 -737.632 -737.632] (0.9511) ({r_i: None, r_t: [-1436.769 -1436.769 -1436.769], eps: 0.951})
Step:  130200, Reward: [-637.143 -637.143 -637.143] [195.565], Avg: [-737.555 -737.555 -737.555] (0.9511) ({r_i: None, r_t: [-1456.553 -1456.553 -1456.553], eps: 0.951})
Step:  130300, Reward: [-722.530 -722.530 -722.530] [175.475], Avg: [-737.544 -737.544 -737.544] (0.9511) ({r_i: None, r_t: [-1425.036 -1425.036 -1425.036], eps: 0.951})
Step:  130400, Reward: [-671.700 -671.700 -671.700] [180.633], Avg: [-737.493 -737.493 -737.493] (0.9511) ({r_i: None, r_t: [-1420.181 -1420.181 -1420.181], eps: 0.951})
Step:  130500, Reward: [-675.220 -675.220 -675.220] [136.298], Avg: [-737.446 -737.446 -737.446] (0.9511) ({r_i: None, r_t: [-1337.891 -1337.891 -1337.891], eps: 0.951})
Step:  130600, Reward: [-703.904 -703.904 -703.904] [125.128], Avg: [-737.420 -737.420 -737.420] (0.9511) ({r_i: None, r_t: [-1347.234 -1347.234 -1347.234], eps: 0.951})
Step:  130700, Reward: [-680.330 -680.330 -680.330] [239.032], Avg: [-737.376 -737.376 -737.376] (0.9511) ({r_i: None, r_t: [-1303.694 -1303.694 -1303.694], eps: 0.951})
Step:  130800, Reward: [-602.818 -602.818 -602.818] [104.500], Avg: [-737.273 -737.273 -737.273] (0.9511) ({r_i: None, r_t: [-1338.771 -1338.771 -1338.771], eps: 0.951})
Step:  130900, Reward: [-641.386 -641.386 -641.386] [160.857], Avg: [-737.200 -737.200 -737.200] (0.9511) ({r_i: None, r_t: [-1315.781 -1315.781 -1315.781], eps: 0.951})
Step:  131000, Reward: [-644.517 -644.517 -644.517] [156.081], Avg: [-737.130 -737.130 -737.130] (0.9511) ({r_i: None, r_t: [-1333.235 -1333.235 -1333.235], eps: 0.951})
Step:  131100, Reward: [-696.373 -696.373 -696.373] [151.833], Avg: [-737.098 -737.098 -737.098] (0.9511) ({r_i: None, r_t: [-1276.208 -1276.208 -1276.208], eps: 0.951})
Step:  131200, Reward: [-677.719 -677.719 -677.719] [188.502], Avg: [-737.053 -737.053 -737.053] (0.9511) ({r_i: None, r_t: [-1344.623 -1344.623 -1344.623], eps: 0.951})
Step:  131300, Reward: [-689.195 -689.195 -689.195] [170.021], Avg: [-737.017 -737.017 -737.017] (0.9511) ({r_i: None, r_t: [-1268.350 -1268.350 -1268.350], eps: 0.951})
Step:  131400, Reward: [-702.130 -702.130 -702.130] [217.270], Avg: [-736.990 -736.990 -736.990] (0.9511) ({r_i: None, r_t: [-1322.369 -1322.369 -1322.369], eps: 0.951})
Step:  131500, Reward: [-712.833 -712.833 -712.833] [154.053], Avg: [-736.972 -736.972 -736.972] (0.9511) ({r_i: None, r_t: [-1310.364 -1310.364 -1310.364], eps: 0.951})
Step:  131600, Reward: [-567.687 -567.687 -567.687] [131.617], Avg: [-736.843 -736.843 -736.843] (0.9511) ({r_i: None, r_t: [-1305.121 -1305.121 -1305.121], eps: 0.951})
Step:  131700, Reward: [-669.155 -669.155 -669.155] [129.095], Avg: [-736.792 -736.792 -736.792] (0.9511) ({r_i: None, r_t: [-1445.104 -1445.104 -1445.104], eps: 0.951})
Step:  131800, Reward: [-587.478 -587.478 -587.478] [134.884], Avg: [-736.679 -736.679 -736.679] (0.9511) ({r_i: None, r_t: [-1230.348 -1230.348 -1230.348], eps: 0.951})
Step:  131900, Reward: [-680.112 -680.112 -680.112] [179.644], Avg: [-736.636 -736.636 -736.636] (0.9511) ({r_i: None, r_t: [-1310.445 -1310.445 -1310.445], eps: 0.951})
Step:  132000, Reward: [-594.573 -594.573 -594.573] [141.515], Avg: [-736.528 -736.528 -736.528] (0.9511) ({r_i: None, r_t: [-1388.605 -1388.605 -1388.605], eps: 0.951})
Step:  132100, Reward: [-582.815 -582.815 -582.815] [130.348], Avg: [-736.412 -736.412 -736.412] (0.9511) ({r_i: None, r_t: [-1311.574 -1311.574 -1311.574], eps: 0.951})
Step:  132200, Reward: [-635.380 -635.380 -635.380] [171.135], Avg: [-736.336 -736.336 -736.336] (0.9511) ({r_i: None, r_t: [-1346.728 -1346.728 -1346.728], eps: 0.951})
Step:  132300, Reward: [-644.110 -644.110 -644.110] [153.425], Avg: [-736.266 -736.266 -736.266] (0.9511) ({r_i: None, r_t: [-1262.558 -1262.558 -1262.558], eps: 0.951})
Step:  132400, Reward: [-573.875 -573.875 -573.875] [101.978], Avg: [-736.144 -736.144 -736.144] (0.9511) ({r_i: None, r_t: [-1230.980 -1230.980 -1230.980], eps: 0.951})
Step:  132500, Reward: [-569.287 -569.287 -569.287] [139.180], Avg: [-736.018 -736.018 -736.018] (0.9511) ({r_i: None, r_t: [-1239.023 -1239.023 -1239.023], eps: 0.951})
Step:  132600, Reward: [-608.355 -608.355 -608.355] [126.800], Avg: [-735.922 -735.922 -735.922] (0.9464) ({r_i: None, r_t: [-1190.545 -1190.545 -1190.545], eps: 0.946})
Step:  132700, Reward: [-593.869 -593.869 -593.869] [143.178], Avg: [-735.815 -735.815 -735.815] (0.9464) ({r_i: None, r_t: [-1139.139 -1139.139 -1139.139], eps: 0.946})
Step:  132800, Reward: [-648.551 -648.551 -648.551] [152.080], Avg: [-735.749 -735.749 -735.749] (0.9464) ({r_i: None, r_t: [-1182.313 -1182.313 -1182.313], eps: 0.946})
Step:  132900, Reward: [-629.852 -629.852 -629.852] [173.331], Avg: [-735.669 -735.669 -735.669] (0.9464) ({r_i: None, r_t: [-1174.537 -1174.537 -1174.537], eps: 0.946})
Step:  133000, Reward: [-628.391 -628.391 -628.391] [195.435], Avg: [-735.589 -735.589 -735.589] (0.9464) ({r_i: None, r_t: [-1187.902 -1187.902 -1187.902], eps: 0.946})
Step:  133100, Reward: [-619.569 -619.569 -619.569] [164.214], Avg: [-735.502 -735.502 -735.502] (0.9464) ({r_i: None, r_t: [-1178.228 -1178.228 -1178.228], eps: 0.946})
Step:  133200, Reward: [-574.435 -574.435 -574.435] [85.914], Avg: [-735.381 -735.381 -735.381] (0.9464) ({r_i: None, r_t: [-1179.667 -1179.667 -1179.667], eps: 0.946})
Step:  133300, Reward: [-577.719 -577.719 -577.719] [86.400], Avg: [-735.263 -735.263 -735.263] (0.9464) ({r_i: None, r_t: [-1278.922 -1278.922 -1278.922], eps: 0.946})
Step:  133400, Reward: [-587.797 -587.797 -587.797] [109.957], Avg: [-735.152 -735.152 -735.152] (0.9464) ({r_i: None, r_t: [-1168.238 -1168.238 -1168.238], eps: 0.946})
Step:  133500, Reward: [-636.150 -636.150 -636.150] [145.011], Avg: [-735.078 -735.078 -735.078] (0.9464) ({r_i: None, r_t: [-1127.746 -1127.746 -1127.746], eps: 0.946})
Step:  133600, Reward: [-546.574 -546.574 -546.574] [128.656], Avg: [-734.937 -734.937 -734.937] (0.9464) ({r_i: None, r_t: [-1251.335 -1251.335 -1251.335], eps: 0.946})
Step:  133700, Reward: [-560.057 -560.057 -560.057] [115.736], Avg: [-734.806 -734.806 -734.806] (0.9464) ({r_i: None, r_t: [-1097.991 -1097.991 -1097.991], eps: 0.946})
Step:  133800, Reward: [-595.386 -595.386 -595.386] [101.052], Avg: [-734.702 -734.702 -734.702] (0.9464) ({r_i: None, r_t: [-1259.853 -1259.853 -1259.853], eps: 0.946})
Step:  133900, Reward: [-616.558 -616.558 -616.558] [116.771], Avg: [-734.614 -734.614 -734.614] (0.9464) ({r_i: None, r_t: [-1046.315 -1046.315 -1046.315], eps: 0.946})
Step:  134000, Reward: [-548.011 -548.011 -548.011] [141.834], Avg: [-734.475 -734.475 -734.475] (0.9464) ({r_i: None, r_t: [-1106.097 -1106.097 -1106.097], eps: 0.946})
Step:  134100, Reward: [-500.940 -500.940 -500.940] [86.856], Avg: [-734.301 -734.301 -734.301] (0.9464) ({r_i: None, r_t: [-1080.331 -1080.331 -1080.331], eps: 0.946})
Step:  134200, Reward: [-512.335 -512.335 -512.335] [101.897], Avg: [-734.136 -734.136 -734.136] (0.9464) ({r_i: None, r_t: [-1057.313 -1057.313 -1057.313], eps: 0.946})
Step:  134300, Reward: [-511.939 -511.939 -511.939] [130.489], Avg: [-733.970 -733.970 -733.970] (0.9464) ({r_i: None, r_t: [-1076.055 -1076.055 -1076.055], eps: 0.946})
Step:  134400, Reward: [-600.564 -600.564 -600.564] [94.063], Avg: [-733.871 -733.871 -733.871] (0.9464) ({r_i: None, r_t: [-1090.497 -1090.497 -1090.497], eps: 0.946})
Step:  134500, Reward: [-587.382 -587.382 -587.382] [113.604], Avg: [-733.762 -733.762 -733.762] (0.9464) ({r_i: None, r_t: [-1127.162 -1127.162 -1127.162], eps: 0.946})
Step:  134600, Reward: [-494.074 -494.074 -494.074] [119.679], Avg: [-733.584 -733.584 -733.584] (0.9464) ({r_i: None, r_t: [-1050.802 -1050.802 -1050.802], eps: 0.946})
Step:  134700, Reward: [-534.292 -534.292 -534.292] [113.395], Avg: [-733.436 -733.436 -733.436] (0.9464) ({r_i: None, r_t: [-1049.912 -1049.912 -1049.912], eps: 0.946})
Step:  134800, Reward: [-496.260 -496.260 -496.260] [91.225], Avg: [-733.261 -733.261 -733.261] (0.9464) ({r_i: None, r_t: [-1026.690 -1026.690 -1026.690], eps: 0.946})
Step:  134900, Reward: [-501.251 -501.251 -501.251] [79.184], Avg: [-733.089 -733.089 -733.089] (0.9464) ({r_i: None, r_t: [-1022.791 -1022.791 -1022.791], eps: 0.946})
Step:  135000, Reward: [-497.648 -497.648 -497.648] [95.250], Avg: [-732.915 -732.915 -732.915] (0.9464) ({r_i: None, r_t: [-1085.901 -1085.901 -1085.901], eps: 0.946})
Step:  135100, Reward: [-530.993 -530.993 -530.993] [129.351], Avg: [-732.765 -732.765 -732.765] (0.9464) ({r_i: None, r_t: [-1094.413 -1094.413 -1094.413], eps: 0.946})
Step:  135200, Reward: [-492.961 -492.961 -492.961] [95.310], Avg: [-732.588 -732.588 -732.588] (0.9464) ({r_i: None, r_t: [-1023.881 -1023.881 -1023.881], eps: 0.946})
Step:  135300, Reward: [-494.720 -494.720 -494.720] [91.489], Avg: [-732.412 -732.412 -732.412] (0.9464) ({r_i: None, r_t: [-980.335 -980.335 -980.335], eps: 0.946})
Step:  135400, Reward: [-463.180 -463.180 -463.180] [76.389], Avg: [-732.214 -732.214 -732.214] (0.9464) ({r_i: None, r_t: [-1069.480 -1069.480 -1069.480], eps: 0.946})
Step:  135500, Reward: [-501.441 -501.441 -501.441] [128.411], Avg: [-732.043 -732.043 -732.043] (0.9464) ({r_i: None, r_t: [-1070.299 -1070.299 -1070.299], eps: 0.946})
Step:  135600, Reward: [-515.616 -515.616 -515.616] [97.408], Avg: [-731.884 -731.884 -731.884] (0.9464) ({r_i: None, r_t: [-969.909 -969.909 -969.909], eps: 0.946})
Step:  135700, Reward: [-554.449 -554.449 -554.449] [109.825], Avg: [-731.753 -731.753 -731.753] (0.9464) ({r_i: None, r_t: [-975.001 -975.001 -975.001], eps: 0.946})
Step:  135800, Reward: [-515.402 -515.402 -515.402] [96.426], Avg: [-731.594 -731.594 -731.594] (0.9464) ({r_i: None, r_t: [-971.581 -971.581 -971.581], eps: 0.946})
Step:  135900, Reward: [-556.375 -556.375 -556.375] [136.516], Avg: [-731.465 -731.465 -731.465] (0.9464) ({r_i: None, r_t: [-956.139 -956.139 -956.139], eps: 0.946})
Step:  136000, Reward: [-471.210 -471.210 -471.210] [92.190], Avg: [-731.274 -731.274 -731.274] (0.9464) ({r_i: None, r_t: [-1001.711 -1001.711 -1001.711], eps: 0.946})
Step:  136100, Reward: [-487.337 -487.337 -487.337] [79.235], Avg: [-731.095 -731.095 -731.095] (0.9464) ({r_i: None, r_t: [-1033.517 -1033.517 -1033.517], eps: 0.946})
Step:  136200, Reward: [-490.492 -490.492 -490.492] [108.413], Avg: [-730.918 -730.918 -730.918] (0.9464) ({r_i: None, r_t: [-968.320 -968.320 -968.320], eps: 0.946})
Step:  136300, Reward: [-475.243 -475.243 -475.243] [71.971], Avg: [-730.731 -730.731 -730.731] (0.9464) ({r_i: None, r_t: [-955.822 -955.822 -955.822], eps: 0.946})
Step:  136400, Reward: [-498.685 -498.685 -498.685] [64.430], Avg: [-730.561 -730.561 -730.561] (0.9464) ({r_i: None, r_t: [-1051.926 -1051.926 -1051.926], eps: 0.946})
Step:  136500, Reward: [-507.466 -507.466 -507.466] [49.496], Avg: [-730.398 -730.398 -730.398] (0.9464) ({r_i: None, r_t: [-970.592 -970.592 -970.592], eps: 0.946})
Step:  136600, Reward: [-526.073 -526.073 -526.073] [103.538], Avg: [-730.248 -730.248 -730.248] (0.9464) ({r_i: None, r_t: [-997.329 -997.329 -997.329], eps: 0.946})
Step:  136700, Reward: [-486.205 -486.205 -486.205] [75.481], Avg: [-730.070 -730.070 -730.070] (0.9464) ({r_i: None, r_t: [-985.685 -985.685 -985.685], eps: 0.946})
Step:  136800, Reward: [-472.536 -472.536 -472.536] [88.877], Avg: [-729.882 -729.882 -729.882] (0.9464) ({r_i: None, r_t: [-974.704 -974.704 -974.704], eps: 0.946})
Step:  136900, Reward: [-525.198 -525.198 -525.198] [89.582], Avg: [-729.732 -729.732 -729.732] (0.9464) ({r_i: None, r_t: [-1023.578 -1023.578 -1023.578], eps: 0.946})
Step:  137000, Reward: [-514.073 -514.073 -514.073] [66.210], Avg: [-729.575 -729.575 -729.575] (0.9464) ({r_i: None, r_t: [-997.497 -997.497 -997.497], eps: 0.946})
Step:  137100, Reward: [-516.600 -516.600 -516.600] [103.779], Avg: [-729.420 -729.420 -729.420] (0.9464) ({r_i: None, r_t: [-971.916 -971.916 -971.916], eps: 0.946})
Step:  137200, Reward: [-480.408 -480.408 -480.408] [78.385], Avg: [-729.238 -729.238 -729.238] (0.9464) ({r_i: None, r_t: [-967.989 -967.989 -967.989], eps: 0.946})
Step:  137300, Reward: [-492.249 -492.249 -492.249] [78.528], Avg: [-729.066 -729.066 -729.066] (0.9464) ({r_i: None, r_t: [-1013.819 -1013.819 -1013.819], eps: 0.946})
Step:  137400, Reward: [-529.400 -529.400 -529.400] [135.114], Avg: [-728.921 -728.921 -728.921] (0.9464) ({r_i: None, r_t: [-1051.412 -1051.412 -1051.412], eps: 0.946})
Step:  137500, Reward: [-529.122 -529.122 -529.122] [84.439], Avg: [-728.775 -728.775 -728.775] (0.9464) ({r_i: None, r_t: [-1025.869 -1025.869 -1025.869], eps: 0.946})
Step:  137600, Reward: [-532.704 -532.704 -532.704] [70.998], Avg: [-728.633 -728.633 -728.633] (0.9464) ({r_i: None, r_t: [-959.550 -959.550 -959.550], eps: 0.946})
Step:  137700, Reward: [-457.197 -457.197 -457.197] [63.626], Avg: [-728.436 -728.436 -728.436] (0.9464) ({r_i: None, r_t: [-1043.512 -1043.512 -1043.512], eps: 0.946})
Step:  137800, Reward: [-518.364 -518.364 -518.364] [115.411], Avg: [-728.284 -728.284 -728.284] (0.9464) ({r_i: None, r_t: [-992.373 -992.373 -992.373], eps: 0.946})
Step:  137900, Reward: [-495.554 -495.554 -495.554] [120.683], Avg: [-728.115 -728.115 -728.115] (0.9464) ({r_i: None, r_t: [-1021.098 -1021.098 -1021.098], eps: 0.946})
Step:  138000, Reward: [-521.166 -521.166 -521.166] [82.808], Avg: [-727.965 -727.965 -727.965] (0.9464) ({r_i: None, r_t: [-997.858 -997.858 -997.858], eps: 0.946})
Step:  138100, Reward: [-455.046 -455.046 -455.046] [73.740], Avg: [-727.768 -727.768 -727.768] (0.9464) ({r_i: None, r_t: [-1054.385 -1054.385 -1054.385], eps: 0.946})
Step:  138200, Reward: [-538.068 -538.068 -538.068] [87.476], Avg: [-727.631 -727.631 -727.631] (0.9464) ({r_i: None, r_t: [-1063.519 -1063.519 -1063.519], eps: 0.946})
Step:  138300, Reward: [-555.079 -555.079 -555.079] [128.105], Avg: [-727.506 -727.506 -727.506] (0.9464) ({r_i: None, r_t: [-976.849 -976.849 -976.849], eps: 0.946})
Step:  138400, Reward: [-548.957 -548.957 -548.957] [128.554], Avg: [-727.377 -727.377 -727.377] (0.9464) ({r_i: None, r_t: [-1051.432 -1051.432 -1051.432], eps: 0.946})
Step:  138500, Reward: [-534.321 -534.321 -534.321] [116.657], Avg: [-727.238 -727.238 -727.238] (0.9464) ({r_i: None, r_t: [-1056.898 -1056.898 -1056.898], eps: 0.946})
Step:  138600, Reward: [-543.802 -543.802 -543.802] [104.569], Avg: [-727.105 -727.105 -727.105] (0.9464) ({r_i: None, r_t: [-1090.378 -1090.378 -1090.378], eps: 0.946})
Step:  138700, Reward: [-532.566 -532.566 -532.566] [97.143], Avg: [-726.965 -726.965 -726.965] (0.9464) ({r_i: None, r_t: [-1077.237 -1077.237 -1077.237], eps: 0.946})
Step:  138800, Reward: [-520.646 -520.646 -520.646] [115.796], Avg: [-726.817 -726.817 -726.817] (0.9464) ({r_i: None, r_t: [-985.748 -985.748 -985.748], eps: 0.946})
Step:  138900, Reward: [-541.773 -541.773 -541.773] [88.669], Avg: [-726.684 -726.684 -726.684] (0.9464) ({r_i: None, r_t: [-1066.355 -1066.355 -1066.355], eps: 0.946})
Step:  139000, Reward: [-513.410 -513.410 -513.410] [126.136], Avg: [-726.530 -726.530 -726.530] (0.9464) ({r_i: None, r_t: [-990.566 -990.566 -990.566], eps: 0.946})
Step:  139100, Reward: [-528.835 -528.835 -528.835] [93.027], Avg: [-726.388 -726.388 -726.388] (0.9464) ({r_i: None, r_t: [-1080.417 -1080.417 -1080.417], eps: 0.946})
Step:  139200, Reward: [-533.457 -533.457 -533.457] [62.705], Avg: [-726.250 -726.250 -726.250] (0.9464) ({r_i: None, r_t: [-1166.675 -1166.675 -1166.675], eps: 0.946})
Step:  139300, Reward: [-618.565 -618.565 -618.565] [108.270], Avg: [-726.172 -726.172 -726.172] (0.9464) ({r_i: None, r_t: [-1138.119 -1138.119 -1138.119], eps: 0.946})
Step:  139400, Reward: [-587.578 -587.578 -587.578] [105.967], Avg: [-726.073 -726.073 -726.073] (0.9464) ({r_i: None, r_t: [-1083.328 -1083.328 -1083.328], eps: 0.946})
Step:  139500, Reward: [-542.341 -542.341 -542.341] [112.328], Avg: [-725.942 -725.942 -725.942] (0.9464) ({r_i: None, r_t: [-1066.375 -1066.375 -1066.375], eps: 0.946})
Step:  139600, Reward: [-499.083 -499.083 -499.083] [99.344], Avg: [-725.779 -725.779 -725.779] (0.9464) ({r_i: None, r_t: [-1051.983 -1051.983 -1051.983], eps: 0.946})
Step:  139700, Reward: [-517.991 -517.991 -517.991] [71.539], Avg: [-725.631 -725.631 -725.631] (0.9464) ({r_i: None, r_t: [-1118.091 -1118.091 -1118.091], eps: 0.946})
Step:  139800, Reward: [-535.090 -535.090 -535.090] [101.662], Avg: [-725.494 -725.494 -725.494] (0.9464) ({r_i: None, r_t: [-1070.253 -1070.253 -1070.253], eps: 0.946})
Step:  139900, Reward: [-612.374 -612.374 -612.374] [108.876], Avg: [-725.414 -725.414 -725.414] (0.9464) ({r_i: None, r_t: [-1087.156 -1087.156 -1087.156], eps: 0.946})
Step:  140000, Reward: [-565.253 -565.253 -565.253] [86.928], Avg: [-725.299 -725.299 -725.299] (0.9464) ({r_i: None, r_t: [-1062.695 -1062.695 -1062.695], eps: 0.946})
Step:  140100, Reward: [-558.625 -558.625 -558.625] [124.929], Avg: [-725.180 -725.180 -725.180] (0.9464) ({r_i: None, r_t: [-1054.117 -1054.117 -1054.117], eps: 0.946})
Step:  140200, Reward: [-550.564 -550.564 -550.564] [138.650], Avg: [-725.056 -725.056 -725.056] (0.9464) ({r_i: None, r_t: [-1025.612 -1025.612 -1025.612], eps: 0.946})
Step:  140300, Reward: [-552.726 -552.726 -552.726] [133.284], Avg: [-724.933 -724.933 -724.933] (0.9464) ({r_i: None, r_t: [-1076.641 -1076.641 -1076.641], eps: 0.946})
Step:  140400, Reward: [-511.803 -511.803 -511.803] [113.384], Avg: [-724.781 -724.781 -724.781] (0.9464) ({r_i: None, r_t: [-1048.448 -1048.448 -1048.448], eps: 0.946})
Step:  140500, Reward: [-605.479 -605.479 -605.479] [133.895], Avg: [-724.697 -724.697 -724.697] (0.9464) ({r_i: None, r_t: [-1020.341 -1020.341 -1020.341], eps: 0.946})
Step:  140600, Reward: [-553.541 -553.541 -553.541] [156.796], Avg: [-724.575 -724.575 -724.575] (0.9464) ({r_i: None, r_t: [-1137.361 -1137.361 -1137.361], eps: 0.946})
Step:  140700, Reward: [-567.623 -567.623 -567.623] [120.605], Avg: [-724.463 -724.463 -724.463] (0.9464) ({r_i: None, r_t: [-1170.215 -1170.215 -1170.215], eps: 0.946})
Step:  140800, Reward: [-590.961 -590.961 -590.961] [104.971], Avg: [-724.369 -724.369 -724.369] (0.9464) ({r_i: None, r_t: [-1069.123 -1069.123 -1069.123], eps: 0.946})
Step:  140900, Reward: [-539.984 -539.984 -539.984] [82.390], Avg: [-724.238 -724.238 -724.238] (0.9464) ({r_i: None, r_t: [-1101.228 -1101.228 -1101.228], eps: 0.946})
Step:  141000, Reward: [-577.583 -577.583 -577.583] [94.667], Avg: [-724.134 -724.134 -724.134] (0.9464) ({r_i: None, r_t: [-1075.619 -1075.619 -1075.619], eps: 0.946})
Step:  141100, Reward: [-575.321 -575.321 -575.321] [101.225], Avg: [-724.029 -724.029 -724.029] (0.9464) ({r_i: None, r_t: [-1069.782 -1069.782 -1069.782], eps: 0.946})
Step:  141200, Reward: [-513.477 -513.477 -513.477] [86.061], Avg: [-723.880 -723.880 -723.880] (0.9464) ({r_i: None, r_t: [-1146.693 -1146.693 -1146.693], eps: 0.946})
Step:  141300, Reward: [-581.795 -581.795 -581.795] [104.566], Avg: [-723.779 -723.779 -723.779] (0.9464) ({r_i: None, r_t: [-1133.611 -1133.611 -1133.611], eps: 0.946})
Step:  141400, Reward: [-564.141 -564.141 -564.141] [141.234], Avg: [-723.666 -723.666 -723.666] (0.9464) ({r_i: None, r_t: [-1113.620 -1113.620 -1113.620], eps: 0.946})
Step:  141500, Reward: [-535.870 -535.870 -535.870] [83.517], Avg: [-723.534 -723.534 -723.534] (0.9464) ({r_i: None, r_t: [-1122.766 -1122.766 -1122.766], eps: 0.946})
Step:  141600, Reward: [-586.852 -586.852 -586.852] [99.585], Avg: [-723.437 -723.437 -723.437] (0.9464) ({r_i: None, r_t: [-1162.880 -1162.880 -1162.880], eps: 0.946})
Step:  141700, Reward: [-612.751 -612.751 -612.751] [168.883], Avg: [-723.359 -723.359 -723.359] (0.9464) ({r_i: None, r_t: [-1123.108 -1123.108 -1123.108], eps: 0.946})
Step:  141800, Reward: [-596.355 -596.355 -596.355] [117.467], Avg: [-723.270 -723.270 -723.270] (0.9464) ({r_i: None, r_t: [-1093.589 -1093.589 -1093.589], eps: 0.946})
Step:  141900, Reward: [-623.367 -623.367 -623.367] [117.186], Avg: [-723.199 -723.199 -723.199] (0.9464) ({r_i: None, r_t: [-1103.317 -1103.317 -1103.317], eps: 0.946})
Step:  142000, Reward: [-616.719 -616.719 -616.719] [109.629], Avg: [-723.124 -723.124 -723.124] (0.9464) ({r_i: None, r_t: [-1155.203 -1155.203 -1155.203], eps: 0.946})
Step:  142100, Reward: [-574.669 -574.669 -574.669] [126.353], Avg: [-723.020 -723.020 -723.020] (0.9464) ({r_i: None, r_t: [-1164.571 -1164.571 -1164.571], eps: 0.946})
Step:  142200, Reward: [-610.958 -610.958 -610.958] [101.899], Avg: [-722.941 -722.941 -722.941] (0.9464) ({r_i: None, r_t: [-1105.184 -1105.184 -1105.184], eps: 0.946})
Step:  142300, Reward: [-532.627 -532.627 -532.627] [65.064], Avg: [-722.808 -722.808 -722.808] (0.9464) ({r_i: None, r_t: [-1141.110 -1141.110 -1141.110], eps: 0.946})
Step:  142400, Reward: [-540.946 -540.946 -540.946] [79.532], Avg: [-722.680 -722.680 -722.680] (0.9464) ({r_i: None, r_t: [-1097.704 -1097.704 -1097.704], eps: 0.946})
Step:  142500, Reward: [-529.275 -529.275 -529.275] [103.597], Avg: [-722.544 -722.544 -722.544] (0.9464) ({r_i: None, r_t: [-1178.838 -1178.838 -1178.838], eps: 0.946})
Step:  142600, Reward: [-550.153 -550.153 -550.153] [116.322], Avg: [-722.424 -722.424 -722.424] (0.9464) ({r_i: None, r_t: [-1132.472 -1132.472 -1132.472], eps: 0.946})
Step:  142700, Reward: [-582.319 -582.319 -582.319] [149.631], Avg: [-722.325 -722.325 -722.325] (0.9464) ({r_i: None, r_t: [-1145.669 -1145.669 -1145.669], eps: 0.946})
Step:  142800, Reward: [-537.528 -537.528 -537.528] [93.372], Avg: [-722.196 -722.196 -722.196] (0.9464) ({r_i: None, r_t: [-1179.052 -1179.052 -1179.052], eps: 0.946})
Step:  142900, Reward: [-592.379 -592.379 -592.379] [115.386], Avg: [-722.105 -722.105 -722.105] (0.9464) ({r_i: None, r_t: [-1200.804 -1200.804 -1200.804], eps: 0.946})
Step:  143000, Reward: [-560.303 -560.303 -560.303] [149.900], Avg: [-721.992 -721.992 -721.992] (0.9464) ({r_i: None, r_t: [-1169.878 -1169.878 -1169.878], eps: 0.946})
Step:  143100, Reward: [-554.618 -554.618 -554.618] [75.138], Avg: [-721.875 -721.875 -721.875] (0.9464) ({r_i: None, r_t: [-1154.377 -1154.377 -1154.377], eps: 0.946})
Step:  143200, Reward: [-616.455 -616.455 -616.455] [137.985], Avg: [-721.802 -721.802 -721.802] (0.9464) ({r_i: None, r_t: [-1156.456 -1156.456 -1156.456], eps: 0.946})
Step:  143300, Reward: [-565.855 -565.855 -565.855] [104.823], Avg: [-721.693 -721.693 -721.693] (0.9464) ({r_i: None, r_t: [-1169.210 -1169.210 -1169.210], eps: 0.946})
Step:  143400, Reward: [-625.857 -625.857 -625.857] [126.603], Avg: [-721.626 -721.626 -721.626] (0.9464) ({r_i: None, r_t: [-1128.729 -1128.729 -1128.729], eps: 0.946})
Step:  143500, Reward: [-626.970 -626.970 -626.970] [180.729], Avg: [-721.560 -721.560 -721.560] (0.9464) ({r_i: None, r_t: [-1148.758 -1148.758 -1148.758], eps: 0.946})
Step:  143600, Reward: [-583.226 -583.226 -583.226] [120.231], Avg: [-721.464 -721.464 -721.464] (0.9464) ({r_i: None, r_t: [-1202.209 -1202.209 -1202.209], eps: 0.946})
Step:  143700, Reward: [-608.659 -608.659 -608.659] [134.526], Avg: [-721.386 -721.386 -721.386] (0.9464) ({r_i: None, r_t: [-1157.010 -1157.010 -1157.010], eps: 0.946})
Step:  143800, Reward: [-614.732 -614.732 -614.732] [68.889], Avg: [-721.311 -721.311 -721.311] (0.9464) ({r_i: None, r_t: [-1181.892 -1181.892 -1181.892], eps: 0.946})
Step:  143900, Reward: [-581.510 -581.510 -581.510] [155.439], Avg: [-721.214 -721.214 -721.214] (0.9464) ({r_i: None, r_t: [-1176.979 -1176.979 -1176.979], eps: 0.946})
Step:  144000, Reward: [-559.731 -559.731 -559.731] [107.117], Avg: [-721.102 -721.102 -721.102] (0.9464) ({r_i: None, r_t: [-1265.896 -1265.896 -1265.896], eps: 0.946})
Step:  144100, Reward: [-594.616 -594.616 -594.616] [107.567], Avg: [-721.015 -721.015 -721.015] (0.9464) ({r_i: None, r_t: [-1183.430 -1183.430 -1183.430], eps: 0.946})
Step:  144200, Reward: [-554.144 -554.144 -554.144] [104.742], Avg: [-720.899 -720.899 -720.899] (0.9464) ({r_i: None, r_t: [-1176.973 -1176.973 -1176.973], eps: 0.946})
Step:  144300, Reward: [-587.526 -587.526 -587.526] [88.520], Avg: [-720.807 -720.807 -720.807] (0.9464) ({r_i: None, r_t: [-1195.362 -1195.362 -1195.362], eps: 0.946})
Step:  144400, Reward: [-607.685 -607.685 -607.685] [106.271], Avg: [-720.728 -720.728 -720.728] (0.9464) ({r_i: None, r_t: [-1246.378 -1246.378 -1246.378], eps: 0.946})
Step:  144500, Reward: [-591.161 -591.161 -591.161] [91.208], Avg: [-720.639 -720.639 -720.639] (0.9464) ({r_i: None, r_t: [-1207.716 -1207.716 -1207.716], eps: 0.946})
Step:  144600, Reward: [-567.747 -567.747 -567.747] [129.896], Avg: [-720.533 -720.533 -720.533] (0.9464) ({r_i: None, r_t: [-1116.937 -1116.937 -1116.937], eps: 0.946})
Step:  144700, Reward: [-622.573 -622.573 -622.573] [156.120], Avg: [-720.465 -720.465 -720.465] (0.9464) ({r_i: None, r_t: [-1156.933 -1156.933 -1156.933], eps: 0.946})
Step:  144800, Reward: [-539.950 -539.950 -539.950] [108.452], Avg: [-720.341 -720.341 -720.341] (0.9464) ({r_i: None, r_t: [-1207.312 -1207.312 -1207.312], eps: 0.946})
Step:  144900, Reward: [-618.805 -618.805 -618.805] [146.421], Avg: [-720.271 -720.271 -720.271] (0.9464) ({r_i: None, r_t: [-1218.325 -1218.325 -1218.325], eps: 0.946})
Step:  145000, Reward: [-602.084 -602.084 -602.084] [106.232], Avg: [-720.189 -720.189 -720.189] (0.9464) ({r_i: None, r_t: [-1227.157 -1227.157 -1227.157], eps: 0.946})
Step:  145100, Reward: [-574.833 -574.833 -574.833] [120.205], Avg: [-720.089 -720.089 -720.089] (0.9416) ({r_i: None, r_t: [-1163.274 -1163.274 -1163.274], eps: 0.942})
Step:  145200, Reward: [-594.873 -594.873 -594.873] [97.965], Avg: [-720.003 -720.003 -720.003] (0.9416) ({r_i: None, r_t: [-1221.277 -1221.277 -1221.277], eps: 0.942})
Step:  145300, Reward: [-583.740 -583.740 -583.740] [143.574], Avg: [-719.909 -719.909 -719.909] (0.9416) ({r_i: None, r_t: [-1204.751 -1204.751 -1204.751], eps: 0.942})
Step:  145400, Reward: [-650.275 -650.275 -650.275] [92.224], Avg: [-719.862 -719.862 -719.862] (0.9416) ({r_i: None, r_t: [-1156.861 -1156.861 -1156.861], eps: 0.942})
Step:  145500, Reward: [-609.728 -609.728 -609.728] [140.935], Avg: [-719.786 -719.786 -719.786] (0.9416) ({r_i: None, r_t: [-1137.735 -1137.735 -1137.735], eps: 0.942})
Step:  145600, Reward: [-586.636 -586.636 -586.636] [126.787], Avg: [-719.694 -719.694 -719.694] (0.9416) ({r_i: None, r_t: [-1293.068 -1293.068 -1293.068], eps: 0.942})
Step:  145700, Reward: [-599.906 -599.906 -599.906] [116.602], Avg: [-719.612 -719.612 -719.612] (0.9416) ({r_i: None, r_t: [-1229.944 -1229.944 -1229.944], eps: 0.942})
Step:  145800, Reward: [-643.923 -643.923 -643.923] [109.011], Avg: [-719.560 -719.560 -719.560] (0.9416) ({r_i: None, r_t: [-1186.705 -1186.705 -1186.705], eps: 0.942})
Step:  145900, Reward: [-609.894 -609.894 -609.894] [124.615], Avg: [-719.485 -719.485 -719.485] (0.9416) ({r_i: None, r_t: [-1251.271 -1251.271 -1251.271], eps: 0.942})
Step:  146000, Reward: [-621.365 -621.365 -621.365] [141.554], Avg: [-719.418 -719.418 -719.418] (0.9416) ({r_i: None, r_t: [-1281.885 -1281.885 -1281.885], eps: 0.942})
Step:  146100, Reward: [-622.553 -622.553 -622.553] [152.475], Avg: [-719.352 -719.352 -719.352] (0.9416) ({r_i: None, r_t: [-1261.385 -1261.385 -1261.385], eps: 0.942})
Step:  146200, Reward: [-596.182 -596.182 -596.182] [127.772], Avg: [-719.268 -719.268 -719.268] (0.9416) ({r_i: None, r_t: [-1219.608 -1219.608 -1219.608], eps: 0.942})
Step:  146300, Reward: [-648.941 -648.941 -648.941] [174.671], Avg: [-719.220 -719.220 -719.220] (0.9416) ({r_i: None, r_t: [-1134.741 -1134.741 -1134.741], eps: 0.942})
Step:  146400, Reward: [-588.649 -588.649 -588.649] [105.989], Avg: [-719.131 -719.131 -719.131] (0.9416) ({r_i: None, r_t: [-1313.865 -1313.865 -1313.865], eps: 0.942})
Step:  146500, Reward: [-565.766 -565.766 -565.766] [121.695], Avg: [-719.026 -719.026 -719.026] (0.9416) ({r_i: None, r_t: [-1194.727 -1194.727 -1194.727], eps: 0.942})
Step:  146600, Reward: [-590.852 -590.852 -590.852] [108.228], Avg: [-718.939 -718.939 -718.939] (0.9416) ({r_i: None, r_t: [-1239.812 -1239.812 -1239.812], eps: 0.942})
Step:  146700, Reward: [-565.152 -565.152 -565.152] [131.558], Avg: [-718.834 -718.834 -718.834] (0.9416) ({r_i: None, r_t: [-1105.929 -1105.929 -1105.929], eps: 0.942})
Step:  146800, Reward: [-649.352 -649.352 -649.352] [128.878], Avg: [-718.787 -718.787 -718.787] (0.9416) ({r_i: None, r_t: [-1238.316 -1238.316 -1238.316], eps: 0.942})
Step:  146900, Reward: [-613.806 -613.806 -613.806] [134.932], Avg: [-718.715 -718.715 -718.715] (0.9416) ({r_i: None, r_t: [-1174.524 -1174.524 -1174.524], eps: 0.942})
Step:  147000, Reward: [-668.918 -668.918 -668.918] [118.335], Avg: [-718.681 -718.681 -718.681] (0.9416) ({r_i: None, r_t: [-1188.213 -1188.213 -1188.213], eps: 0.942})
Step:  147100, Reward: [-650.928 -650.928 -650.928] [177.675], Avg: [-718.635 -718.635 -718.635] (0.9416) ({r_i: None, r_t: [-1149.689 -1149.689 -1149.689], eps: 0.942})
Step:  147200, Reward: [-607.076 -607.076 -607.076] [116.242], Avg: [-718.559 -718.559 -718.559] (0.9416) ({r_i: None, r_t: [-1203.595 -1203.595 -1203.595], eps: 0.942})
Step:  147300, Reward: [-664.662 -664.662 -664.662] [120.368], Avg: [-718.523 -718.523 -718.523] (0.9416) ({r_i: None, r_t: [-1168.547 -1168.547 -1168.547], eps: 0.942})
Step:  147400, Reward: [-636.064 -636.064 -636.064] [96.436], Avg: [-718.467 -718.467 -718.467] (0.9416) ({r_i: None, r_t: [-1218.296 -1218.296 -1218.296], eps: 0.942})
Step:  147500, Reward: [-593.525 -593.525 -593.525] [124.411], Avg: [-718.382 -718.382 -718.382] (0.9416) ({r_i: None, r_t: [-1154.964 -1154.964 -1154.964], eps: 0.942})
Step:  147600, Reward: [-624.375 -624.375 -624.375] [148.304], Avg: [-718.319 -718.319 -718.319] (0.9416) ({r_i: None, r_t: [-1232.167 -1232.167 -1232.167], eps: 0.942})
Step:  147700, Reward: [-609.253 -609.253 -609.253] [108.785], Avg: [-718.245 -718.245 -718.245] (0.9416) ({r_i: None, r_t: [-1138.233 -1138.233 -1138.233], eps: 0.942})
Step:  147800, Reward: [-608.786 -608.786 -608.786] [177.423], Avg: [-718.171 -718.171 -718.171] (0.9416) ({r_i: None, r_t: [-1217.583 -1217.583 -1217.583], eps: 0.942})
Step:  147900, Reward: [-621.566 -621.566 -621.566] [136.506], Avg: [-718.106 -718.106 -718.106] (0.9416) ({r_i: None, r_t: [-1115.556 -1115.556 -1115.556], eps: 0.942})
Step:  148000, Reward: [-595.519 -595.519 -595.519] [128.151], Avg: [-718.023 -718.023 -718.023] (0.9416) ({r_i: None, r_t: [-1225.692 -1225.692 -1225.692], eps: 0.942})
Step:  148100, Reward: [-625.064 -625.064 -625.064] [120.035], Avg: [-717.960 -717.960 -717.960] (0.9416) ({r_i: None, r_t: [-1207.234 -1207.234 -1207.234], eps: 0.942})
Step:  148200, Reward: [-600.853 -600.853 -600.853] [87.650], Avg: [-717.881 -717.881 -717.881] (0.9416) ({r_i: None, r_t: [-1141.438 -1141.438 -1141.438], eps: 0.942})
Step:  148300, Reward: [-524.083 -524.083 -524.083] [101.105], Avg: [-717.751 -717.751 -717.751] (0.9416) ({r_i: None, r_t: [-1283.248 -1283.248 -1283.248], eps: 0.942})
Step:  148400, Reward: [-584.326 -584.326 -584.326] [125.393], Avg: [-717.661 -717.661 -717.661] (0.9416) ({r_i: None, r_t: [-1160.627 -1160.627 -1160.627], eps: 0.942})
Step:  148500, Reward: [-582.489 -582.489 -582.489] [113.494], Avg: [-717.570 -717.570 -717.570] (0.9416) ({r_i: None, r_t: [-1142.860 -1142.860 -1142.860], eps: 0.942})
Step:  148600, Reward: [-660.024 -660.024 -660.024] [144.339], Avg: [-717.531 -717.531 -717.531] (0.9416) ({r_i: None, r_t: [-1215.782 -1215.782 -1215.782], eps: 0.942})
Step:  148700, Reward: [-568.340 -568.340 -568.340] [117.244], Avg: [-717.431 -717.431 -717.431] (0.9416) ({r_i: None, r_t: [-1187.360 -1187.360 -1187.360], eps: 0.942})
Step:  148800, Reward: [-593.563 -593.563 -593.563] [139.428], Avg: [-717.348 -717.348 -717.348] (0.9416) ({r_i: None, r_t: [-1162.066 -1162.066 -1162.066], eps: 0.942})
Step:  148900, Reward: [-644.986 -644.986 -644.986] [105.636], Avg: [-717.299 -717.299 -717.299] (0.9416) ({r_i: None, r_t: [-1218.900 -1218.900 -1218.900], eps: 0.942})
Step:  149000, Reward: [-649.444 -649.444 -649.444] [148.004], Avg: [-717.254 -717.254 -717.254] (0.9416) ({r_i: None, r_t: [-1183.248 -1183.248 -1183.248], eps: 0.942})
Step:  149100, Reward: [-623.626 -623.626 -623.626] [132.554], Avg: [-717.191 -717.191 -717.191] (0.9416) ({r_i: None, r_t: [-1205.567 -1205.567 -1205.567], eps: 0.942})
Step:  149200, Reward: [-572.103 -572.103 -572.103] [93.670], Avg: [-717.094 -717.094 -717.094] (0.9416) ({r_i: None, r_t: [-1215.789 -1215.789 -1215.789], eps: 0.942})
Step:  149300, Reward: [-627.522 -627.522 -627.522] [147.326], Avg: [-717.034 -717.034 -717.034] (0.9416) ({r_i: None, r_t: [-1184.020 -1184.020 -1184.020], eps: 0.942})
Step:  149400, Reward: [-597.070 -597.070 -597.070] [90.736], Avg: [-716.953 -716.953 -716.953] (0.9416) ({r_i: None, r_t: [-1232.495 -1232.495 -1232.495], eps: 0.942})
Step:  149500, Reward: [-601.602 -601.602 -601.602] [139.529], Avg: [-716.876 -716.876 -716.876] (0.9416) ({r_i: None, r_t: [-1155.435 -1155.435 -1155.435], eps: 0.942})
Step:  149600, Reward: [-550.480 -550.480 -550.480] [138.056], Avg: [-716.765 -716.765 -716.765] (0.9416) ({r_i: None, r_t: [-1209.105 -1209.105 -1209.105], eps: 0.942})
Step:  149700, Reward: [-625.949 -625.949 -625.949] [140.517], Avg: [-716.705 -716.705 -716.705] (0.9416) ({r_i: None, r_t: [-1229.167 -1229.167 -1229.167], eps: 0.942})
Step:  149800, Reward: [-589.436 -589.436 -589.436] [146.293], Avg: [-716.620 -716.620 -716.620] (0.9416) ({r_i: None, r_t: [-1196.863 -1196.863 -1196.863], eps: 0.942})
Step:  149900, Reward: [-621.888 -621.888 -621.888] [147.385], Avg: [-716.556 -716.556 -716.556] (0.9416) ({r_i: None, r_t: [-1179.188 -1179.188 -1179.188], eps: 0.942})
Step:  150000, Reward: [-617.152 -617.152 -617.152] [130.095], Avg: [-716.490 -716.490 -716.490] (0.9416) ({r_i: None, r_t: [-1258.462 -1258.462 -1258.462], eps: 0.942})
Step:  150100, Reward: [-561.463 -561.463 -561.463] [124.315], Avg: [-716.387 -716.387 -716.387] (0.9416) ({r_i: None, r_t: [-1181.547 -1181.547 -1181.547], eps: 0.942})
Step:  150200, Reward: [-572.408 -572.408 -572.408] [95.182], Avg: [-716.291 -716.291 -716.291] (0.9416) ({r_i: None, r_t: [-1245.597 -1245.597 -1245.597], eps: 0.942})
Step:  150300, Reward: [-582.810 -582.810 -582.810] [88.343], Avg: [-716.202 -716.202 -716.202] (0.9416) ({r_i: None, r_t: [-1199.278 -1199.278 -1199.278], eps: 0.942})
Step:  150400, Reward: [-579.441 -579.441 -579.441] [78.207], Avg: [-716.112 -716.112 -716.112] (0.9416) ({r_i: None, r_t: [-1193.087 -1193.087 -1193.087], eps: 0.942})
Step:  150500, Reward: [-628.034 -628.034 -628.034] [82.027], Avg: [-716.053 -716.053 -716.053] (0.9416) ({r_i: None, r_t: [-1151.822 -1151.822 -1151.822], eps: 0.942})
Step:  150600, Reward: [-592.600 -592.600 -592.600] [169.665], Avg: [-715.971 -715.971 -715.971] (0.9416) ({r_i: None, r_t: [-1226.598 -1226.598 -1226.598], eps: 0.942})
Step:  150700, Reward: [-572.198 -572.198 -572.198] [89.621], Avg: [-715.876 -715.876 -715.876] (0.9416) ({r_i: None, r_t: [-1195.186 -1195.186 -1195.186], eps: 0.942})
Step:  150800, Reward: [-598.309 -598.309 -598.309] [106.788], Avg: [-715.798 -715.798 -715.798] (0.9416) ({r_i: None, r_t: [-1130.331 -1130.331 -1130.331], eps: 0.942})
Step:  150900, Reward: [-573.293 -573.293 -573.293] [112.279], Avg: [-715.704 -715.704 -715.704] (0.9416) ({r_i: None, r_t: [-1164.832 -1164.832 -1164.832], eps: 0.942})
Step:  151000, Reward: [-561.301 -561.301 -561.301] [111.223], Avg: [-715.601 -715.601 -715.601] (0.9416) ({r_i: None, r_t: [-1133.828 -1133.828 -1133.828], eps: 0.942})
Step:  151100, Reward: [-576.911 -576.911 -576.911] [126.783], Avg: [-715.510 -715.510 -715.510] (0.9416) ({r_i: None, r_t: [-1164.895 -1164.895 -1164.895], eps: 0.942})
Step:  151200, Reward: [-561.844 -561.844 -561.844] [95.844], Avg: [-715.408 -715.408 -715.408] (0.9416) ({r_i: None, r_t: [-1169.954 -1169.954 -1169.954], eps: 0.942})
Step:  151300, Reward: [-538.002 -538.002 -538.002] [87.738], Avg: [-715.291 -715.291 -715.291] (0.9416) ({r_i: None, r_t: [-1191.208 -1191.208 -1191.208], eps: 0.942})
Step:  151400, Reward: [-601.958 -601.958 -601.958] [125.344], Avg: [-715.216 -715.216 -715.216] (0.9416) ({r_i: None, r_t: [-1171.555 -1171.555 -1171.555], eps: 0.942})
Step:  151500, Reward: [-546.789 -546.789 -546.789] [111.318], Avg: [-715.105 -715.105 -715.105] (0.9416) ({r_i: None, r_t: [-1220.777 -1220.777 -1220.777], eps: 0.942})
Step:  151600, Reward: [-570.259 -570.259 -570.259] [146.151], Avg: [-715.010 -715.010 -715.010] (0.9416) ({r_i: None, r_t: [-1133.838 -1133.838 -1133.838], eps: 0.942})
Step:  151700, Reward: [-582.405 -582.405 -582.405] [116.217], Avg: [-714.922 -714.922 -714.922] (0.9416) ({r_i: None, r_t: [-1146.492 -1146.492 -1146.492], eps: 0.942})
Step:  151800, Reward: [-531.334 -531.334 -531.334] [77.256], Avg: [-714.801 -714.801 -714.801] (0.9416) ({r_i: None, r_t: [-1125.301 -1125.301 -1125.301], eps: 0.942})
Step:  151900, Reward: [-568.322 -568.322 -568.322] [124.697], Avg: [-714.705 -714.705 -714.705] (0.9416) ({r_i: None, r_t: [-1165.447 -1165.447 -1165.447], eps: 0.942})
Step:  152000, Reward: [-582.327 -582.327 -582.327] [113.302], Avg: [-714.618 -714.618 -714.618] (0.9416) ({r_i: None, r_t: [-1117.834 -1117.834 -1117.834], eps: 0.942})
Step:  152100, Reward: [-565.934 -565.934 -565.934] [78.017], Avg: [-714.520 -714.520 -714.520] (0.9416) ({r_i: None, r_t: [-1106.304 -1106.304 -1106.304], eps: 0.942})
Step:  152200, Reward: [-554.527 -554.527 -554.527] [123.897], Avg: [-714.415 -714.415 -714.415] (0.9416) ({r_i: None, r_t: [-1112.762 -1112.762 -1112.762], eps: 0.942})
Step:  152300, Reward: [-556.538 -556.538 -556.538] [148.610], Avg: [-714.312 -714.312 -714.312] (0.9416) ({r_i: None, r_t: [-1105.278 -1105.278 -1105.278], eps: 0.942})
Step:  152400, Reward: [-538.593 -538.593 -538.593] [84.793], Avg: [-714.196 -714.196 -714.196] (0.9416) ({r_i: None, r_t: [-1099.447 -1099.447 -1099.447], eps: 0.942})
Step:  152500, Reward: [-547.028 -547.028 -547.028] [76.512], Avg: [-714.087 -714.087 -714.087] (0.9416) ({r_i: None, r_t: [-1075.321 -1075.321 -1075.321], eps: 0.942})
Step:  152600, Reward: [-544.943 -544.943 -544.943] [90.641], Avg: [-713.976 -713.976 -713.976] (0.9416) ({r_i: None, r_t: [-1136.504 -1136.504 -1136.504], eps: 0.942})
Step:  152700, Reward: [-572.667 -572.667 -572.667] [97.664], Avg: [-713.884 -713.884 -713.884] (0.9416) ({r_i: None, r_t: [-1151.082 -1151.082 -1151.082], eps: 0.942})
Step:  152800, Reward: [-560.138 -560.138 -560.138] [80.110], Avg: [-713.783 -713.783 -713.783] (0.9416) ({r_i: None, r_t: [-1084.389 -1084.389 -1084.389], eps: 0.942})
Step:  152900, Reward: [-542.996 -542.996 -542.996] [78.013], Avg: [-713.671 -713.671 -713.671] (0.9416) ({r_i: None, r_t: [-1126.748 -1126.748 -1126.748], eps: 0.942})
Step:  153000, Reward: [-539.945 -539.945 -539.945] [101.119], Avg: [-713.558 -713.558 -713.558] (0.9416) ({r_i: None, r_t: [-1146.116 -1146.116 -1146.116], eps: 0.942})
Step:  153100, Reward: [-511.653 -511.653 -511.653] [76.976], Avg: [-713.426 -713.426 -713.426] (0.9416) ({r_i: None, r_t: [-1084.205 -1084.205 -1084.205], eps: 0.942})
Step:  153200, Reward: [-602.243 -602.243 -602.243] [103.921], Avg: [-713.354 -713.354 -713.354] (0.9416) ({r_i: None, r_t: [-1076.792 -1076.792 -1076.792], eps: 0.942})
Step:  153300, Reward: [-512.311 -512.311 -512.311] [80.129], Avg: [-713.223 -713.223 -713.223] (0.9416) ({r_i: None, r_t: [-1075.560 -1075.560 -1075.560], eps: 0.942})
Step:  153400, Reward: [-556.712 -556.712 -556.712] [96.339], Avg: [-713.121 -713.121 -713.121] (0.9416) ({r_i: None, r_t: [-1055.077 -1055.077 -1055.077], eps: 0.942})
Step:  153500, Reward: [-552.398 -552.398 -552.398] [111.272], Avg: [-713.016 -713.016 -713.016] (0.9416) ({r_i: None, r_t: [-1066.562 -1066.562 -1066.562], eps: 0.942})
Step:  153600, Reward: [-566.403 -566.403 -566.403] [79.446], Avg: [-712.921 -712.921 -712.921] (0.9416) ({r_i: None, r_t: [-1142.974 -1142.974 -1142.974], eps: 0.942})
Step:  153700, Reward: [-533.510 -533.510 -533.510] [78.037], Avg: [-712.804 -712.804 -712.804] (0.9416) ({r_i: None, r_t: [-1144.901 -1144.901 -1144.901], eps: 0.942})
Step:  153800, Reward: [-542.529 -542.529 -542.529] [121.920], Avg: [-712.693 -712.693 -712.693] (0.9416) ({r_i: None, r_t: [-1035.972 -1035.972 -1035.972], eps: 0.942})
Step:  153900, Reward: [-528.660 -528.660 -528.660] [89.621], Avg: [-712.574 -712.574 -712.574] (0.9416) ({r_i: None, r_t: [-1084.822 -1084.822 -1084.822], eps: 0.942})
Step:  154000, Reward: [-515.069 -515.069 -515.069] [110.028], Avg: [-712.446 -712.446 -712.446] (0.9416) ({r_i: None, r_t: [-1092.809 -1092.809 -1092.809], eps: 0.942})
Step:  154100, Reward: [-567.180 -567.180 -567.180] [112.056], Avg: [-712.351 -712.351 -712.351] (0.9416) ({r_i: None, r_t: [-1042.625 -1042.625 -1042.625], eps: 0.942})
Step:  154200, Reward: [-497.211 -497.211 -497.211] [74.796], Avg: [-712.212 -712.212 -712.212] (0.9416) ({r_i: None, r_t: [-1076.149 -1076.149 -1076.149], eps: 0.942})
Step:  154300, Reward: [-515.844 -515.844 -515.844] [90.789], Avg: [-712.085 -712.085 -712.085] (0.9416) ({r_i: None, r_t: [-1017.424 -1017.424 -1017.424], eps: 0.942})
Step:  154400, Reward: [-566.313 -566.313 -566.313] [107.156], Avg: [-711.990 -711.990 -711.990] (0.9416) ({r_i: None, r_t: [-997.776 -997.776 -997.776], eps: 0.942})
Step:  154500, Reward: [-540.409 -540.409 -540.409] [107.625], Avg: [-711.879 -711.879 -711.879] (0.9416) ({r_i: None, r_t: [-1036.226 -1036.226 -1036.226], eps: 0.942})
Step:  154600, Reward: [-484.644 -484.644 -484.644] [82.113], Avg: [-711.733 -711.733 -711.733] (0.9416) ({r_i: None, r_t: [-1049.658 -1049.658 -1049.658], eps: 0.942})
Step:  154700, Reward: [-533.693 -533.693 -533.693] [77.259], Avg: [-711.618 -711.618 -711.618] (0.9416) ({r_i: None, r_t: [-1032.398 -1032.398 -1032.398], eps: 0.942})
Step:  154800, Reward: [-535.594 -535.594 -535.594] [98.691], Avg: [-711.504 -711.504 -711.504] (0.9416) ({r_i: None, r_t: [-1046.287 -1046.287 -1046.287], eps: 0.942})
Step:  154900, Reward: [-537.719 -537.719 -537.719] [131.001], Avg: [-711.392 -711.392 -711.392] (0.9416) ({r_i: None, r_t: [-1043.235 -1043.235 -1043.235], eps: 0.942})
Step:  155000, Reward: [-508.421 -508.421 -508.421] [66.423], Avg: [-711.261 -711.261 -711.261] (0.9416) ({r_i: None, r_t: [-1004.707 -1004.707 -1004.707], eps: 0.942})
Step:  155100, Reward: [-480.027 -480.027 -480.027] [61.526], Avg: [-711.112 -711.112 -711.112] (0.9416) ({r_i: None, r_t: [-1016.224 -1016.224 -1016.224], eps: 0.942})
Step:  155200, Reward: [-534.023 -534.023 -534.023] [131.003], Avg: [-710.998 -710.998 -710.998] (0.9416) ({r_i: None, r_t: [-1136.940 -1136.940 -1136.940], eps: 0.942})
Step:  155300, Reward: [-519.165 -519.165 -519.165] [66.487], Avg: [-710.874 -710.874 -710.874] (0.9416) ({r_i: None, r_t: [-1043.136 -1043.136 -1043.136], eps: 0.942})
Step:  155400, Reward: [-511.732 -511.732 -511.732] [73.104], Avg: [-710.746 -710.746 -710.746] (0.9416) ({r_i: None, r_t: [-1070.104 -1070.104 -1070.104], eps: 0.942})
Step:  155500, Reward: [-497.696 -497.696 -497.696] [90.976], Avg: [-710.609 -710.609 -710.609] (0.9416) ({r_i: None, r_t: [-1028.046 -1028.046 -1028.046], eps: 0.942})
Step:  155600, Reward: [-498.791 -498.791 -498.791] [73.814], Avg: [-710.473 -710.473 -710.473] (0.9416) ({r_i: None, r_t: [-979.918 -979.918 -979.918], eps: 0.942})
Step:  155700, Reward: [-521.750 -521.750 -521.750] [106.245], Avg: [-710.352 -710.352 -710.352] (0.9416) ({r_i: None, r_t: [-1030.217 -1030.217 -1030.217], eps: 0.942})
Step:  155800, Reward: [-492.486 -492.486 -492.486] [97.075], Avg: [-710.213 -710.213 -710.213] (0.9416) ({r_i: None, r_t: [-1066.016 -1066.016 -1066.016], eps: 0.942})
Step:  155900, Reward: [-525.119 -525.119 -525.119] [100.139], Avg: [-710.094 -710.094 -710.094] (0.9416) ({r_i: None, r_t: [-1015.015 -1015.015 -1015.015], eps: 0.942})
Step:  156000, Reward: [-550.215 -550.215 -550.215] [90.629], Avg: [-709.991 -709.991 -709.991] (0.9416) ({r_i: None, r_t: [-1078.624 -1078.624 -1078.624], eps: 0.942})
Step:  156100, Reward: [-500.114 -500.114 -500.114] [98.344], Avg: [-709.857 -709.857 -709.857] (0.9416) ({r_i: None, r_t: [-1029.516 -1029.516 -1029.516], eps: 0.942})
Step:  156200, Reward: [-509.233 -509.233 -509.233] [75.965], Avg: [-709.729 -709.729 -709.729] (0.9416) ({r_i: None, r_t: [-968.383 -968.383 -968.383], eps: 0.942})
Step:  156300, Reward: [-526.895 -526.895 -526.895] [101.715], Avg: [-709.612 -709.612 -709.612] (0.9416) ({r_i: None, r_t: [-995.079 -995.079 -995.079], eps: 0.942})
Step:  156400, Reward: [-453.849 -453.849 -453.849] [67.253], Avg: [-709.448 -709.448 -709.448] (0.9416) ({r_i: None, r_t: [-1011.608 -1011.608 -1011.608], eps: 0.942})
Step:  156500, Reward: [-489.022 -489.022 -489.022] [110.327], Avg: [-709.308 -709.308 -709.308] (0.9416) ({r_i: None, r_t: [-990.641 -990.641 -990.641], eps: 0.942})
Step:  156600, Reward: [-533.884 -533.884 -533.884] [118.988], Avg: [-709.196 -709.196 -709.196] (0.9416) ({r_i: None, r_t: [-975.147 -975.147 -975.147], eps: 0.942})
Step:  156700, Reward: [-518.686 -518.686 -518.686] [99.913], Avg: [-709.074 -709.074 -709.074] (0.9416) ({r_i: None, r_t: [-1002.056 -1002.056 -1002.056], eps: 0.942})
Step:  156800, Reward: [-490.865 -490.865 -490.865] [86.173], Avg: [-708.935 -708.935 -708.935] (0.9416) ({r_i: None, r_t: [-1049.567 -1049.567 -1049.567], eps: 0.942})
Step:  156900, Reward: [-503.075 -503.075 -503.075] [81.631], Avg: [-708.804 -708.804 -708.804] (0.9416) ({r_i: None, r_t: [-990.325 -990.325 -990.325], eps: 0.942})
Step:  157000, Reward: [-528.238 -528.238 -528.238] [137.182], Avg: [-708.689 -708.689 -708.689] (0.9416) ({r_i: None, r_t: [-1022.561 -1022.561 -1022.561], eps: 0.942})
Step:  157100, Reward: [-511.476 -511.476 -511.476] [116.282], Avg: [-708.564 -708.564 -708.564] (0.9416) ({r_i: None, r_t: [-1034.059 -1034.059 -1034.059], eps: 0.942})
Step:  157200, Reward: [-526.303 -526.303 -526.303] [90.687], Avg: [-708.448 -708.448 -708.448] (0.9416) ({r_i: None, r_t: [-1030.075 -1030.075 -1030.075], eps: 0.942})
Step:  157300, Reward: [-519.847 -519.847 -519.847] [99.852], Avg: [-708.328 -708.328 -708.328] (0.9416) ({r_i: None, r_t: [-980.477 -980.477 -980.477], eps: 0.942})
Step:  157400, Reward: [-491.796 -491.796 -491.796] [98.962], Avg: [-708.190 -708.190 -708.190] (0.9416) ({r_i: None, r_t: [-1017.613 -1017.613 -1017.613], eps: 0.942})
Step:  157500, Reward: [-536.646 -536.646 -536.646] [82.135], Avg: [-708.082 -708.082 -708.082] (0.9416) ({r_i: None, r_t: [-923.142 -923.142 -923.142], eps: 0.942})
Step:  157600, Reward: [-573.858 -573.858 -573.858] [103.463], Avg: [-707.997 -707.997 -707.997] (0.9369) ({r_i: None, r_t: [-976.895 -976.895 -976.895], eps: 0.937})
Step:  157700, Reward: [-523.528 -523.528 -523.528] [98.010], Avg: [-707.880 -707.880 -707.880] (0.9369) ({r_i: None, r_t: [-1018.163 -1018.163 -1018.163], eps: 0.937})
Step:  157800, Reward: [-521.707 -521.707 -521.707] [106.870], Avg: [-707.762 -707.762 -707.762] (0.9369) ({r_i: None, r_t: [-1000.800 -1000.800 -1000.800], eps: 0.937})
Step:  157900, Reward: [-511.155 -511.155 -511.155] [87.974], Avg: [-707.637 -707.637 -707.637] (0.9369) ({r_i: None, r_t: [-1004.620 -1004.620 -1004.620], eps: 0.937})
Step:  158000, Reward: [-528.498 -528.498 -528.498] [90.942], Avg: [-707.524 -707.524 -707.524] (0.9369) ({r_i: None, r_t: [-1004.272 -1004.272 -1004.272], eps: 0.937})
Step:  158100, Reward: [-493.304 -493.304 -493.304] [117.733], Avg: [-707.389 -707.389 -707.389] (0.9369) ({r_i: None, r_t: [-1020.740 -1020.740 -1020.740], eps: 0.937})
Step:  158200, Reward: [-528.232 -528.232 -528.232] [70.857], Avg: [-707.275 -707.275 -707.275] (0.9369) ({r_i: None, r_t: [-1000.656 -1000.656 -1000.656], eps: 0.937})
Step:  158300, Reward: [-530.585 -530.585 -530.585] [101.071], Avg: [-707.164 -707.164 -707.164] (0.9369) ({r_i: None, r_t: [-1013.051 -1013.051 -1013.051], eps: 0.937})
Step:  158400, Reward: [-503.095 -503.095 -503.095] [110.286], Avg: [-707.035 -707.035 -707.035] (0.9369) ({r_i: None, r_t: [-987.515 -987.515 -987.515], eps: 0.937})
Step:  158500, Reward: [-545.500 -545.500 -545.500] [118.716], Avg: [-706.933 -706.933 -706.933] (0.9369) ({r_i: None, r_t: [-1021.366 -1021.366 -1021.366], eps: 0.937})
Step:  158600, Reward: [-615.367 -615.367 -615.367] [157.515], Avg: [-706.876 -706.876 -706.876] (0.9369) ({r_i: None, r_t: [-950.248 -950.248 -950.248], eps: 0.937})
Step:  158700, Reward: [-518.919 -518.919 -518.919] [80.650], Avg: [-706.757 -706.757 -706.757] (0.9369) ({r_i: None, r_t: [-1029.901 -1029.901 -1029.901], eps: 0.937})
Step:  158800, Reward: [-523.019 -523.019 -523.019] [70.562], Avg: [-706.642 -706.642 -706.642] (0.9369) ({r_i: None, r_t: [-1016.792 -1016.792 -1016.792], eps: 0.937})
Step:  158900, Reward: [-562.705 -562.705 -562.705] [111.461], Avg: [-706.551 -706.551 -706.551] (0.9369) ({r_i: None, r_t: [-1058.743 -1058.743 -1058.743], eps: 0.937})
Step:  159000, Reward: [-499.799 -499.799 -499.799] [70.759], Avg: [-706.421 -706.421 -706.421] (0.9369) ({r_i: None, r_t: [-1034.434 -1034.434 -1034.434], eps: 0.937})
Step:  159100, Reward: [-476.086 -476.086 -476.086] [75.669], Avg: [-706.276 -706.276 -706.276] (0.9369) ({r_i: None, r_t: [-1048.670 -1048.670 -1048.670], eps: 0.937})
Step:  159200, Reward: [-514.651 -514.651 -514.651] [113.584], Avg: [-706.156 -706.156 -706.156] (0.9369) ({r_i: None, r_t: [-1042.272 -1042.272 -1042.272], eps: 0.937})
Step:  159300, Reward: [-553.690 -553.690 -553.690] [95.662], Avg: [-706.060 -706.060 -706.060] (0.9369) ({r_i: None, r_t: [-1026.248 -1026.248 -1026.248], eps: 0.937})
Step:  159400, Reward: [-571.581 -571.581 -571.581] [129.394], Avg: [-705.976 -705.976 -705.976] (0.9369) ({r_i: None, r_t: [-1007.231 -1007.231 -1007.231], eps: 0.937})
Step:  159500, Reward: [-497.354 -497.354 -497.354] [77.489], Avg: [-705.845 -705.845 -705.845] (0.9369) ({r_i: None, r_t: [-1030.622 -1030.622 -1030.622], eps: 0.937})
Step:  159600, Reward: [-491.462 -491.462 -491.462] [79.565], Avg: [-705.711 -705.711 -705.711] (0.9369) ({r_i: None, r_t: [-1062.587 -1062.587 -1062.587], eps: 0.937})
Step:  159700, Reward: [-488.471 -488.471 -488.471] [83.929], Avg: [-705.575 -705.575 -705.575] (0.9369) ({r_i: None, r_t: [-1059.243 -1059.243 -1059.243], eps: 0.937})
Step:  159800, Reward: [-541.116 -541.116 -541.116] [84.129], Avg: [-705.472 -705.472 -705.472] (0.9369) ({r_i: None, r_t: [-1078.445 -1078.445 -1078.445], eps: 0.937})
Step:  159900, Reward: [-561.482 -561.482 -561.482] [85.615], Avg: [-705.382 -705.382 -705.382] (0.9369) ({r_i: None, r_t: [-1053.492 -1053.492 -1053.492], eps: 0.937})
Step:  160000, Reward: [-538.430 -538.430 -538.430] [133.684], Avg: [-705.278 -705.278 -705.278] (0.9369) ({r_i: None, r_t: [-1027.709 -1027.709 -1027.709], eps: 0.937})
Step:  160100, Reward: [-500.459 -500.459 -500.459] [67.918], Avg: [-705.150 -705.150 -705.150] (0.9369) ({r_i: None, r_t: [-1019.110 -1019.110 -1019.110], eps: 0.937})
Step:  160200, Reward: [-504.171 -504.171 -504.171] [102.809], Avg: [-705.025 -705.025 -705.025] (0.9369) ({r_i: None, r_t: [-1061.097 -1061.097 -1061.097], eps: 0.937})
Step:  160300, Reward: [-575.414 -575.414 -575.414] [75.645], Avg: [-704.944 -704.944 -704.944] (0.9369) ({r_i: None, r_t: [-1075.476 -1075.476 -1075.476], eps: 0.937})
Step:  160400, Reward: [-521.518 -521.518 -521.518] [105.121], Avg: [-704.830 -704.830 -704.830] (0.9369) ({r_i: None, r_t: [-1054.840 -1054.840 -1054.840], eps: 0.937})
Step:  160500, Reward: [-517.985 -517.985 -517.985] [89.636], Avg: [-704.713 -704.713 -704.713] (0.9369) ({r_i: None, r_t: [-1041.109 -1041.109 -1041.109], eps: 0.937})
Step:  160600, Reward: [-529.150 -529.150 -529.150] [80.341], Avg: [-704.604 -704.604 -704.604] (0.9369) ({r_i: None, r_t: [-1102.089 -1102.089 -1102.089], eps: 0.937})
Step:  160700, Reward: [-520.518 -520.518 -520.518] [60.213], Avg: [-704.490 -704.490 -704.490] (0.9369) ({r_i: None, r_t: [-1078.092 -1078.092 -1078.092], eps: 0.937})
Step:  160800, Reward: [-523.268 -523.268 -523.268] [91.861], Avg: [-704.377 -704.377 -704.377] (0.9369) ({r_i: None, r_t: [-1048.429 -1048.429 -1048.429], eps: 0.937})
Step:  160900, Reward: [-540.164 -540.164 -540.164] [102.843], Avg: [-704.275 -704.275 -704.275] (0.9369) ({r_i: None, r_t: [-1082.883 -1082.883 -1082.883], eps: 0.937})
Step:  161000, Reward: [-564.102 -564.102 -564.102] [109.037], Avg: [-704.188 -704.188 -704.188] (0.9369) ({r_i: None, r_t: [-1114.698 -1114.698 -1114.698], eps: 0.937})
Step:  161100, Reward: [-573.301 -573.301 -573.301] [80.617], Avg: [-704.107 -704.107 -704.107] (0.9369) ({r_i: None, r_t: [-1091.898 -1091.898 -1091.898], eps: 0.937})
Step:  161200, Reward: [-550.334 -550.334 -550.334] [84.936], Avg: [-704.012 -704.012 -704.012] (0.9369) ({r_i: None, r_t: [-1037.824 -1037.824 -1037.824], eps: 0.937})
Step:  161300, Reward: [-557.550 -557.550 -557.550] [133.027], Avg: [-703.921 -703.921 -703.921] (0.9369) ({r_i: None, r_t: [-1158.292 -1158.292 -1158.292], eps: 0.937})
Step:  161400, Reward: [-514.974 -514.974 -514.974] [91.390], Avg: [-703.804 -703.804 -703.804] (0.9369) ({r_i: None, r_t: [-1083.180 -1083.180 -1083.180], eps: 0.937})
Step:  161500, Reward: [-568.376 -568.376 -568.376] [88.647], Avg: [-703.720 -703.720 -703.720] (0.9369) ({r_i: None, r_t: [-1202.495 -1202.495 -1202.495], eps: 0.937})
Step:  161600, Reward: [-540.707 -540.707 -540.707] [92.947], Avg: [-703.619 -703.619 -703.619] (0.9369) ({r_i: None, r_t: [-1202.013 -1202.013 -1202.013], eps: 0.937})
Step:  161700, Reward: [-537.122 -537.122 -537.122] [84.839], Avg: [-703.516 -703.516 -703.516] (0.9369) ({r_i: None, r_t: [-1140.880 -1140.880 -1140.880], eps: 0.937})
Step:  161800, Reward: [-608.537 -608.537 -608.537] [120.287], Avg: [-703.458 -703.458 -703.458] (0.9369) ({r_i: None, r_t: [-1068.348 -1068.348 -1068.348], eps: 0.937})
Step:  161900, Reward: [-596.203 -596.203 -596.203] [91.472], Avg: [-703.391 -703.391 -703.391] (0.9369) ({r_i: None, r_t: [-1173.097 -1173.097 -1173.097], eps: 0.937})
Step:  162000, Reward: [-562.246 -562.246 -562.246] [88.809], Avg: [-703.304 -703.304 -703.304] (0.9369) ({r_i: None, r_t: [-1185.392 -1185.392 -1185.392], eps: 0.937})
Step:  162100, Reward: [-606.998 -606.998 -606.998] [110.712], Avg: [-703.245 -703.245 -703.245] (0.9369) ({r_i: None, r_t: [-1133.588 -1133.588 -1133.588], eps: 0.937})
Step:  162200, Reward: [-544.452 -544.452 -544.452] [62.175], Avg: [-703.147 -703.147 -703.147] (0.9369) ({r_i: None, r_t: [-1194.814 -1194.814 -1194.814], eps: 0.937})
Step:  162300, Reward: [-618.736 -618.736 -618.736] [85.444], Avg: [-703.095 -703.095 -703.095] (0.9369) ({r_i: None, r_t: [-1165.133 -1165.133 -1165.133], eps: 0.937})
Step:  162400, Reward: [-593.736 -593.736 -593.736] [57.668], Avg: [-703.028 -703.028 -703.028] (0.9369) ({r_i: None, r_t: [-1198.390 -1198.390 -1198.390], eps: 0.937})
Step:  162500, Reward: [-560.491 -560.491 -560.491] [88.648], Avg: [-702.940 -702.940 -702.940] (0.9369) ({r_i: None, r_t: [-1204.765 -1204.765 -1204.765], eps: 0.937})
Step:  162600, Reward: [-593.939 -593.939 -593.939] [121.363], Avg: [-702.873 -702.873 -702.873] (0.9369) ({r_i: None, r_t: [-1211.509 -1211.509 -1211.509], eps: 0.937})
Step:  162700, Reward: [-639.573 -639.573 -639.573] [110.679], Avg: [-702.834 -702.834 -702.834] (0.9369) ({r_i: None, r_t: [-1211.553 -1211.553 -1211.553], eps: 0.937})
Step:  162800, Reward: [-594.283 -594.283 -594.283] [85.812], Avg: [-702.768 -702.768 -702.768] (0.9369) ({r_i: None, r_t: [-1211.188 -1211.188 -1211.188], eps: 0.937})
Step:  162900, Reward: [-596.556 -596.556 -596.556] [86.765], Avg: [-702.703 -702.703 -702.703] (0.9369) ({r_i: None, r_t: [-1192.218 -1192.218 -1192.218], eps: 0.937})
Step:  163000, Reward: [-643.043 -643.043 -643.043] [95.887], Avg: [-702.666 -702.666 -702.666] (0.9369) ({r_i: None, r_t: [-1217.862 -1217.862 -1217.862], eps: 0.937})
Step:  163100, Reward: [-578.830 -578.830 -578.830] [88.617], Avg: [-702.590 -702.590 -702.590] (0.9369) ({r_i: None, r_t: [-1229.506 -1229.506 -1229.506], eps: 0.937})
Step:  163200, Reward: [-552.929 -552.929 -552.929] [113.591], Avg: [-702.498 -702.498 -702.498] (0.9369) ({r_i: None, r_t: [-1219.222 -1219.222 -1219.222], eps: 0.937})
Step:  163300, Reward: [-672.558 -672.558 -672.558] [85.388], Avg: [-702.480 -702.480 -702.480] (0.9369) ({r_i: None, r_t: [-1244.386 -1244.386 -1244.386], eps: 0.937})
Step:  163400, Reward: [-602.070 -602.070 -602.070] [76.963], Avg: [-702.419 -702.419 -702.419] (0.9369) ({r_i: None, r_t: [-1255.380 -1255.380 -1255.380], eps: 0.937})
Step:  163500, Reward: [-649.458 -649.458 -649.458] [78.594], Avg: [-702.386 -702.386 -702.386] (0.9369) ({r_i: None, r_t: [-1313.627 -1313.627 -1313.627], eps: 0.937})
Step:  163600, Reward: [-609.416 -609.416 -609.416] [94.164], Avg: [-702.330 -702.330 -702.330] (0.9369) ({r_i: None, r_t: [-1273.569 -1273.569 -1273.569], eps: 0.937})
Step:  163700, Reward: [-616.441 -616.441 -616.441] [87.152], Avg: [-702.277 -702.277 -702.277] (0.9369) ({r_i: None, r_t: [-1221.392 -1221.392 -1221.392], eps: 0.937})
Step:  163800, Reward: [-602.728 -602.728 -602.728] [98.103], Avg: [-702.216 -702.216 -702.216] (0.9369) ({r_i: None, r_t: [-1302.385 -1302.385 -1302.385], eps: 0.937})
Step:  163900, Reward: [-677.155 -677.155 -677.155] [135.417], Avg: [-702.201 -702.201 -702.201] (0.9369) ({r_i: None, r_t: [-1250.905 -1250.905 -1250.905], eps: 0.937})
Step:  164000, Reward: [-706.738 -706.738 -706.738] [107.851], Avg: [-702.204 -702.204 -702.204] (0.9369) ({r_i: None, r_t: [-1236.304 -1236.304 -1236.304], eps: 0.937})
Step:  164100, Reward: [-588.003 -588.003 -588.003] [105.273], Avg: [-702.134 -702.134 -702.134] (0.9369) ({r_i: None, r_t: [-1362.331 -1362.331 -1362.331], eps: 0.937})
Step:  164200, Reward: [-652.683 -652.683 -652.683] [113.057], Avg: [-702.104 -702.104 -702.104] (0.9369) ({r_i: None, r_t: [-1305.674 -1305.674 -1305.674], eps: 0.937})
Step:  164300, Reward: [-634.106 -634.106 -634.106] [84.133], Avg: [-702.063 -702.063 -702.063] (0.9369) ({r_i: None, r_t: [-1269.231 -1269.231 -1269.231], eps: 0.937})
Step:  164400, Reward: [-643.573 -643.573 -643.573] [106.744], Avg: [-702.027 -702.027 -702.027] (0.9369) ({r_i: None, r_t: [-1298.089 -1298.089 -1298.089], eps: 0.937})
Step:  164500, Reward: [-675.134 -675.134 -675.134] [126.810], Avg: [-702.011 -702.011 -702.011] (0.9369) ({r_i: None, r_t: [-1364.334 -1364.334 -1364.334], eps: 0.937})
Step:  164600, Reward: [-686.574 -686.574 -686.574] [81.803], Avg: [-702.002 -702.002 -702.002] (0.9369) ({r_i: None, r_t: [-1379.438 -1379.438 -1379.438], eps: 0.937})
Step:  164700, Reward: [-684.404 -684.404 -684.404] [110.024], Avg: [-701.991 -701.991 -701.991] (0.9369) ({r_i: None, r_t: [-1335.988 -1335.988 -1335.988], eps: 0.937})
Step:  164800, Reward: [-664.271 -664.271 -664.271] [71.858], Avg: [-701.968 -701.968 -701.968] (0.9369) ({r_i: None, r_t: [-1296.408 -1296.408 -1296.408], eps: 0.937})
Step:  164900, Reward: [-696.886 -696.886 -696.886] [116.201], Avg: [-701.965 -701.965 -701.965] (0.9369) ({r_i: None, r_t: [-1292.053 -1292.053 -1292.053], eps: 0.937})
Step:  165000, Reward: [-668.536 -668.536 -668.536] [97.388], Avg: [-701.945 -701.945 -701.945] (0.9369) ({r_i: None, r_t: [-1422.413 -1422.413 -1422.413], eps: 0.937})
Step:  165100, Reward: [-671.116 -671.116 -671.116] [119.697], Avg: [-701.926 -701.926 -701.926] (0.9369) ({r_i: None, r_t: [-1384.833 -1384.833 -1384.833], eps: 0.937})
Step:  165200, Reward: [-653.252 -653.252 -653.252] [136.250], Avg: [-701.897 -701.897 -701.897] (0.9369) ({r_i: None, r_t: [-1309.311 -1309.311 -1309.311], eps: 0.937})
Step:  165300, Reward: [-685.209 -685.209 -685.209] [102.387], Avg: [-701.886 -701.886 -701.886] (0.9369) ({r_i: None, r_t: [-1331.598 -1331.598 -1331.598], eps: 0.937})
Step:  165400, Reward: [-661.397 -661.397 -661.397] [108.203], Avg: [-701.862 -701.862 -701.862] (0.9369) ({r_i: None, r_t: [-1334.251 -1334.251 -1334.251], eps: 0.937})
Step:  165500, Reward: [-724.859 -724.859 -724.859] [104.002], Avg: [-701.876 -701.876 -701.876] (0.9369) ({r_i: None, r_t: [-1359.463 -1359.463 -1359.463], eps: 0.937})
Step:  165600, Reward: [-636.526 -636.526 -636.526] [113.954], Avg: [-701.836 -701.836 -701.836] (0.9369) ({r_i: None, r_t: [-1340.732 -1340.732 -1340.732], eps: 0.937})
Step:  165700, Reward: [-663.368 -663.368 -663.368] [98.957], Avg: [-701.813 -701.813 -701.813] (0.9369) ({r_i: None, r_t: [-1417.387 -1417.387 -1417.387], eps: 0.937})
Step:  165800, Reward: [-649.033 -649.033 -649.033] [94.254], Avg: [-701.781 -701.781 -701.781] (0.9369) ({r_i: None, r_t: [-1471.407 -1471.407 -1471.407], eps: 0.937})
Step:  165900, Reward: [-709.608 -709.608 -709.608] [89.822], Avg: [-701.786 -701.786 -701.786] (0.9369) ({r_i: None, r_t: [-1406.990 -1406.990 -1406.990], eps: 0.937})
Step:  166000, Reward: [-752.670 -752.670 -752.670] [120.311], Avg: [-701.817 -701.817 -701.817] (0.9369) ({r_i: None, r_t: [-1448.595 -1448.595 -1448.595], eps: 0.937})
Step:  166100, Reward: [-726.977 -726.977 -726.977] [87.042], Avg: [-701.832 -701.832 -701.832] (0.9369) ({r_i: None, r_t: [-1458.141 -1458.141 -1458.141], eps: 0.937})
Step:  166200, Reward: [-725.793 -725.793 -725.793] [143.235], Avg: [-701.846 -701.846 -701.846] (0.9369) ({r_i: None, r_t: [-1408.422 -1408.422 -1408.422], eps: 0.937})
Step:  166300, Reward: [-737.027 -737.027 -737.027] [128.107], Avg: [-701.867 -701.867 -701.867] (0.9369) ({r_i: None, r_t: [-1451.028 -1451.028 -1451.028], eps: 0.937})
Step:  166400, Reward: [-711.678 -711.678 -711.678] [106.783], Avg: [-701.873 -701.873 -701.873] (0.9369) ({r_i: None, r_t: [-1453.428 -1453.428 -1453.428], eps: 0.937})
Step:  166500, Reward: [-781.256 -781.256 -781.256] [126.188], Avg: [-701.921 -701.921 -701.921] (0.9369) ({r_i: None, r_t: [-1494.057 -1494.057 -1494.057], eps: 0.937})
Step:  166600, Reward: [-690.904 -690.904 -690.904] [103.101], Avg: [-701.914 -701.914 -701.914] (0.9369) ({r_i: None, r_t: [-1482.170 -1482.170 -1482.170], eps: 0.937})
Step:  166700, Reward: [-678.690 -678.690 -678.690] [153.174], Avg: [-701.900 -701.900 -701.900] (0.9369) ({r_i: None, r_t: [-1453.655 -1453.655 -1453.655], eps: 0.937})
Step:  166800, Reward: [-752.462 -752.462 -752.462] [123.342], Avg: [-701.931 -701.931 -701.931] (0.9369) ({r_i: None, r_t: [-1482.445 -1482.445 -1482.445], eps: 0.937})
Step:  166900, Reward: [-746.216 -746.216 -746.216] [78.154], Avg: [-701.957 -701.957 -701.957] (0.9369) ({r_i: None, r_t: [-1577.719 -1577.719 -1577.719], eps: 0.937})
Step:  167000, Reward: [-752.758 -752.758 -752.758] [114.613], Avg: [-701.988 -701.988 -701.988] (0.9369) ({r_i: None, r_t: [-1503.046 -1503.046 -1503.046], eps: 0.937})
Step:  167100, Reward: [-741.671 -741.671 -741.671] [85.045], Avg: [-702.011 -702.011 -702.011] (0.9369) ({r_i: None, r_t: [-1534.265 -1534.265 -1534.265], eps: 0.937})
Step:  167200, Reward: [-738.676 -738.676 -738.676] [103.709], Avg: [-702.033 -702.033 -702.033] (0.9369) ({r_i: None, r_t: [-1470.789 -1470.789 -1470.789], eps: 0.937})
Step:  167300, Reward: [-794.785 -794.785 -794.785] [67.897], Avg: [-702.089 -702.089 -702.089] (0.9369) ({r_i: None, r_t: [-1556.538 -1556.538 -1556.538], eps: 0.937})
Step:  167400, Reward: [-728.408 -728.408 -728.408] [148.720], Avg: [-702.104 -702.104 -702.104] (0.9369) ({r_i: None, r_t: [-1516.854 -1516.854 -1516.854], eps: 0.937})
Step:  167500, Reward: [-759.499 -759.499 -759.499] [85.812], Avg: [-702.139 -702.139 -702.139] (0.9369) ({r_i: None, r_t: [-1558.896 -1558.896 -1558.896], eps: 0.937})
Step:  167600, Reward: [-769.676 -769.676 -769.676] [144.395], Avg: [-702.179 -702.179 -702.179] (0.9369) ({r_i: None, r_t: [-1561.860 -1561.860 -1561.860], eps: 0.937})
Step:  167700, Reward: [-771.026 -771.026 -771.026] [118.794], Avg: [-702.220 -702.220 -702.220] (0.9369) ({r_i: None, r_t: [-1561.453 -1561.453 -1561.453], eps: 0.937})
Step:  167800, Reward: [-803.424 -803.424 -803.424] [106.719], Avg: [-702.280 -702.280 -702.280] (0.9369) ({r_i: None, r_t: [-1574.666 -1574.666 -1574.666], eps: 0.937})
Step:  167900, Reward: [-784.596 -784.596 -784.596] [125.604], Avg: [-702.329 -702.329 -702.329] (0.9369) ({r_i: None, r_t: [-1620.773 -1620.773 -1620.773], eps: 0.937})
Step:  168000, Reward: [-778.279 -778.279 -778.279] [88.925], Avg: [-702.374 -702.374 -702.374] (0.9369) ({r_i: None, r_t: [-1654.462 -1654.462 -1654.462], eps: 0.937})
Step:  168100, Reward: [-825.988 -825.988 -825.988] [122.928], Avg: [-702.448 -702.448 -702.448] (0.9369) ({r_i: None, r_t: [-1646.552 -1646.552 -1646.552], eps: 0.937})
Step:  168200, Reward: [-779.667 -779.667 -779.667] [155.236], Avg: [-702.494 -702.494 -702.494] (0.9369) ({r_i: None, r_t: [-1651.847 -1651.847 -1651.847], eps: 0.937})
Step:  168300, Reward: [-805.189 -805.189 -805.189] [149.098], Avg: [-702.555 -702.555 -702.555] (0.9369) ({r_i: None, r_t: [-1613.605 -1613.605 -1613.605], eps: 0.937})
Step:  168400, Reward: [-865.779 -865.779 -865.779] [139.446], Avg: [-702.652 -702.652 -702.652] (0.9369) ({r_i: None, r_t: [-1616.198 -1616.198 -1616.198], eps: 0.937})
Step:  168500, Reward: [-847.668 -847.668 -847.668] [114.036], Avg: [-702.738 -702.738 -702.738] (0.9369) ({r_i: None, r_t: [-1624.805 -1624.805 -1624.805], eps: 0.937})
Step:  168600, Reward: [-870.176 -870.176 -870.176] [139.674], Avg: [-702.837 -702.837 -702.837] (0.9369) ({r_i: None, r_t: [-1586.416 -1586.416 -1586.416], eps: 0.937})
Step:  168700, Reward: [-818.257 -818.257 -818.257] [119.484], Avg: [-702.905 -702.905 -702.905] (0.9369) ({r_i: None, r_t: [-1651.425 -1651.425 -1651.425], eps: 0.937})
Step:  168800, Reward: [-835.817 -835.817 -835.817] [118.581], Avg: [-702.984 -702.984 -702.984] (0.9369) ({r_i: None, r_t: [-1729.772 -1729.772 -1729.772], eps: 0.937})
Step:  168900, Reward: [-817.736 -817.736 -817.736] [138.531], Avg: [-703.052 -703.052 -703.052] (0.9369) ({r_i: None, r_t: [-1708.313 -1708.313 -1708.313], eps: 0.937})
Step:  169000, Reward: [-832.935 -832.935 -832.935] [168.088], Avg: [-703.129 -703.129 -703.129] (0.9369) ({r_i: None, r_t: [-1688.557 -1688.557 -1688.557], eps: 0.937})
Step:  169100, Reward: [-926.463 -926.463 -926.463] [138.591], Avg: [-703.261 -703.261 -703.261] (0.9369) ({r_i: None, r_t: [-1655.588 -1655.588 -1655.588], eps: 0.937})
Step:  169200, Reward: [-825.806 -825.806 -825.806] [108.741], Avg: [-703.333 -703.333 -703.333] (0.9369) ({r_i: None, r_t: [-1844.220 -1844.220 -1844.220], eps: 0.937})
Step:  169300, Reward: [-946.234 -946.234 -946.234] [151.687], Avg: [-703.476 -703.476 -703.476] (0.9369) ({r_i: None, r_t: [-1734.950 -1734.950 -1734.950], eps: 0.937})
Step:  169400, Reward: [-926.437 -926.437 -926.437] [107.770], Avg: [-703.608 -703.608 -703.608] (0.9369) ({r_i: None, r_t: [-1753.444 -1753.444 -1753.444], eps: 0.937})
Step:  169500, Reward: [-860.888 -860.888 -860.888] [121.192], Avg: [-703.701 -703.701 -703.701] (0.9369) ({r_i: None, r_t: [-1783.595 -1783.595 -1783.595], eps: 0.937})
Step:  169600, Reward: [-918.674 -918.674 -918.674] [115.986], Avg: [-703.827 -703.827 -703.827] (0.9369) ({r_i: None, r_t: [-1737.364 -1737.364 -1737.364], eps: 0.937})
Step:  169700, Reward: [-877.970 -877.970 -877.970] [100.515], Avg: [-703.930 -703.930 -703.930] (0.9369) ({r_i: None, r_t: [-1824.189 -1824.189 -1824.189], eps: 0.937})
Step:  169800, Reward: [-879.686 -879.686 -879.686] [125.577], Avg: [-704.033 -704.033 -704.033] (0.9369) ({r_i: None, r_t: [-1847.563 -1847.563 -1847.563], eps: 0.937})
Step:  169900, Reward: [-951.057 -951.057 -951.057] [123.959], Avg: [-704.179 -704.179 -704.179] (0.9369) ({r_i: None, r_t: [-1756.283 -1756.283 -1756.283], eps: 0.937})
Step:  170000, Reward: [-850.353 -850.353 -850.353] [141.820], Avg: [-704.265 -704.265 -704.265] (0.9369) ({r_i: None, r_t: [-1809.769 -1809.769 -1809.769], eps: 0.937})
Step:  170100, Reward: [-876.239 -876.239 -876.239] [94.699], Avg: [-704.366 -704.366 -704.366] (0.9322) ({r_i: None, r_t: [-1781.970 -1781.970 -1781.970], eps: 0.932})
Step:  170200, Reward: [-956.541 -956.541 -956.541] [118.627], Avg: [-704.514 -704.514 -704.514] (0.9322) ({r_i: None, r_t: [-1855.127 -1855.127 -1855.127], eps: 0.932})
Step:  170300, Reward: [-913.206 -913.206 -913.206] [179.254], Avg: [-704.636 -704.636 -704.636] (0.9322) ({r_i: None, r_t: [-1872.034 -1872.034 -1872.034], eps: 0.932})
Step:  170400, Reward: [-947.930 -947.930 -947.930] [152.277], Avg: [-704.779 -704.779 -704.779] (0.9322) ({r_i: None, r_t: [-1822.728 -1822.728 -1822.728], eps: 0.932})
Step:  170500, Reward: [-957.110 -957.110 -957.110] [138.068], Avg: [-704.927 -704.927 -704.927] (0.9322) ({r_i: None, r_t: [-1835.325 -1835.325 -1835.325], eps: 0.932})
Step:  170600, Reward: [-948.492 -948.492 -948.492] [92.662], Avg: [-705.070 -705.070 -705.070] (0.9322) ({r_i: None, r_t: [-1826.577 -1826.577 -1826.577], eps: 0.932})
Step:  170700, Reward: [-982.152 -982.152 -982.152] [163.968], Avg: [-705.232 -705.232 -705.232] (0.9322) ({r_i: None, r_t: [-1876.362 -1876.362 -1876.362], eps: 0.932})
Step:  170800, Reward: [-939.966 -939.966 -939.966] [130.969], Avg: [-705.369 -705.369 -705.369] (0.9322) ({r_i: None, r_t: [-1920.191 -1920.191 -1920.191], eps: 0.932})
Step:  170900, Reward: [-960.773 -960.773 -960.773] [163.406], Avg: [-705.519 -705.519 -705.519] (0.9322) ({r_i: None, r_t: [-1924.252 -1924.252 -1924.252], eps: 0.932})
Step:  171000, Reward: [-925.406 -925.406 -925.406] [102.869], Avg: [-705.647 -705.647 -705.647] (0.9322) ({r_i: None, r_t: [-1910.840 -1910.840 -1910.840], eps: 0.932})
Step:  171100, Reward: [-995.013 -995.013 -995.013] [171.258], Avg: [-705.816 -705.816 -705.816] (0.9322) ({r_i: None, r_t: [-1892.604 -1892.604 -1892.604], eps: 0.932})
Step:  171200, Reward: [-1015.950 -1015.950 -1015.950] [147.249], Avg: [-705.997 -705.997 -705.997] (0.9322) ({r_i: None, r_t: [-1903.691 -1903.691 -1903.691], eps: 0.932})
Step:  171300, Reward: [-920.349 -920.349 -920.349] [141.105], Avg: [-706.122 -706.122 -706.122] (0.9322) ({r_i: None, r_t: [-1873.116 -1873.116 -1873.116], eps: 0.932})
Step:  171400, Reward: [-991.753 -991.753 -991.753] [133.463], Avg: [-706.289 -706.289 -706.289] (0.9322) ({r_i: None, r_t: [-1985.195 -1985.195 -1985.195], eps: 0.932})
Step:  171500, Reward: [-1003.453 -1003.453 -1003.453] [172.914], Avg: [-706.462 -706.462 -706.462] (0.9322) ({r_i: None, r_t: [-1942.974 -1942.974 -1942.974], eps: 0.932})
Step:  171600, Reward: [-1036.639 -1036.639 -1036.639] [158.795], Avg: [-706.654 -706.654 -706.654] (0.9322) ({r_i: None, r_t: [-1973.636 -1973.636 -1973.636], eps: 0.932})
Step:  171700, Reward: [-1019.972 -1019.972 -1019.972] [154.216], Avg: [-706.837 -706.837 -706.837] (0.9322) ({r_i: None, r_t: [-1954.982 -1954.982 -1954.982], eps: 0.932})
Step:  171800, Reward: [-962.907 -962.907 -962.907] [182.892], Avg: [-706.986 -706.986 -706.986] (0.9322) ({r_i: None, r_t: [-1952.005 -1952.005 -1952.005], eps: 0.932})
Step:  171900, Reward: [-964.441 -964.441 -964.441] [152.458], Avg: [-707.135 -707.135 -707.135] (0.9322) ({r_i: None, r_t: [-2093.761 -2093.761 -2093.761], eps: 0.932})
Step:  172000, Reward: [-966.411 -966.411 -966.411] [119.473], Avg: [-707.286 -707.286 -707.286] (0.9322) ({r_i: None, r_t: [-2040.670 -2040.670 -2040.670], eps: 0.932})
Step:  172100, Reward: [-996.905 -996.905 -996.905] [163.069], Avg: [-707.454 -707.454 -707.454] (0.9322) ({r_i: None, r_t: [-2098.564 -2098.564 -2098.564], eps: 0.932})
Step:  172200, Reward: [-1038.682 -1038.682 -1038.682] [159.545], Avg: [-707.646 -707.646 -707.646] (0.9322) ({r_i: None, r_t: [-2082.236 -2082.236 -2082.236], eps: 0.932})
Step:  172300, Reward: [-1013.055 -1013.055 -1013.055] [146.131], Avg: [-707.823 -707.823 -707.823] (0.9322) ({r_i: None, r_t: [-2035.377 -2035.377 -2035.377], eps: 0.932})
Step:  172400, Reward: [-1027.555 -1027.555 -1027.555] [165.521], Avg: [-708.009 -708.009 -708.009] (0.9322) ({r_i: None, r_t: [-1997.077 -1997.077 -1997.077], eps: 0.932})
Step:  172500, Reward: [-1081.275 -1081.275 -1081.275] [117.237], Avg: [-708.225 -708.225 -708.225] (0.9322) ({r_i: None, r_t: [-2079.570 -2079.570 -2079.570], eps: 0.932})
Step:  172600, Reward: [-1031.599 -1031.599 -1031.599] [119.457], Avg: [-708.412 -708.412 -708.412] (0.9322) ({r_i: None, r_t: [-2061.009 -2061.009 -2061.009], eps: 0.932})
Step:  172700, Reward: [-1103.919 -1103.919 -1103.919] [138.380], Avg: [-708.641 -708.641 -708.641] (0.9322) ({r_i: None, r_t: [-1988.059 -1988.059 -1988.059], eps: 0.932})
Step:  172800, Reward: [-1067.196 -1067.196 -1067.196] [159.496], Avg: [-708.849 -708.849 -708.849] (0.9322) ({r_i: None, r_t: [-2070.342 -2070.342 -2070.342], eps: 0.932})
Step:  172900, Reward: [-1111.981 -1111.981 -1111.981] [172.806], Avg: [-709.082 -709.082 -709.082] (0.9322) ({r_i: None, r_t: [-2101.689 -2101.689 -2101.689], eps: 0.932})
Step:  173000, Reward: [-1037.108 -1037.108 -1037.108] [158.524], Avg: [-709.271 -709.271 -709.271] (0.9322) ({r_i: None, r_t: [-2116.066 -2116.066 -2116.066], eps: 0.932})
Step:  173100, Reward: [-1015.845 -1015.845 -1015.845] [177.774], Avg: [-709.448 -709.448 -709.448] (0.9322) ({r_i: None, r_t: [-2141.485 -2141.485 -2141.485], eps: 0.932})
Step:  173200, Reward: [-1034.578 -1034.578 -1034.578] [119.506], Avg: [-709.636 -709.636 -709.636] (0.9322) ({r_i: None, r_t: [-2161.718 -2161.718 -2161.718], eps: 0.932})
Step:  173300, Reward: [-1051.660 -1051.660 -1051.660] [148.910], Avg: [-709.833 -709.833 -709.833] (0.9322) ({r_i: None, r_t: [-2166.054 -2166.054 -2166.054], eps: 0.932})
Step:  173400, Reward: [-1143.963 -1143.963 -1143.963] [128.596], Avg: [-710.083 -710.083 -710.083] (0.9322) ({r_i: None, r_t: [-2193.572 -2193.572 -2193.572], eps: 0.932})
Step:  173500, Reward: [-1089.906 -1089.906 -1089.906] [175.528], Avg: [-710.302 -710.302 -710.302] (0.9322) ({r_i: None, r_t: [-2118.559 -2118.559 -2118.559], eps: 0.932})
Step:  173600, Reward: [-1028.441 -1028.441 -1028.441] [152.332], Avg: [-710.485 -710.485 -710.485] (0.9322) ({r_i: None, r_t: [-2243.241 -2243.241 -2243.241], eps: 0.932})
Step:  173700, Reward: [-1108.168 -1108.168 -1108.168] [115.873], Avg: [-710.714 -710.714 -710.714] (0.9322) ({r_i: None, r_t: [-2171.924 -2171.924 -2171.924], eps: 0.932})
Step:  173800, Reward: [-1175.802 -1175.802 -1175.802] [152.589], Avg: [-710.981 -710.981 -710.981] (0.9322) ({r_i: None, r_t: [-2225.533 -2225.533 -2225.533], eps: 0.932})
Step:  173900, Reward: [-1102.835 -1102.835 -1102.835] [141.022], Avg: [-711.207 -711.207 -711.207] (0.9322) ({r_i: None, r_t: [-2224.602 -2224.602 -2224.602], eps: 0.932})
Step:  174000, Reward: [-1114.293 -1114.293 -1114.293] [140.799], Avg: [-711.438 -711.438 -711.438] (0.9322) ({r_i: None, r_t: [-2221.145 -2221.145 -2221.145], eps: 0.932})
Step:  174100, Reward: [-1163.243 -1163.243 -1163.243] [169.727], Avg: [-711.697 -711.697 -711.697] (0.9322) ({r_i: None, r_t: [-2110.216 -2110.216 -2110.216], eps: 0.932})
Step:  174200, Reward: [-1134.601 -1134.601 -1134.601] [175.032], Avg: [-711.940 -711.940 -711.940] (0.9322) ({r_i: None, r_t: [-2250.275 -2250.275 -2250.275], eps: 0.932})
Step:  174300, Reward: [-1146.120 -1146.120 -1146.120] [144.190], Avg: [-712.189 -712.189 -712.189] (0.9322) ({r_i: None, r_t: [-2366.966 -2366.966 -2366.966], eps: 0.932})
Step:  174400, Reward: [-1150.552 -1150.552 -1150.552] [211.678], Avg: [-712.440 -712.440 -712.440] (0.9322) ({r_i: None, r_t: [-2195.449 -2195.449 -2195.449], eps: 0.932})
Step:  174500, Reward: [-1225.058 -1225.058 -1225.058] [229.351], Avg: [-712.734 -712.734 -712.734] (0.9322) ({r_i: None, r_t: [-2232.572 -2232.572 -2232.572], eps: 0.932})
Step:  174600, Reward: [-1100.281 -1100.281 -1100.281] [173.204], Avg: [-712.956 -712.956 -712.956] (0.9322) ({r_i: None, r_t: [-2316.015 -2316.015 -2316.015], eps: 0.932})
Step:  174700, Reward: [-1292.518 -1292.518 -1292.518] [146.325], Avg: [-713.287 -713.287 -713.287] (0.9322) ({r_i: None, r_t: [-2351.784 -2351.784 -2351.784], eps: 0.932})
Step:  174800, Reward: [-1204.870 -1204.870 -1204.870] [150.185], Avg: [-713.568 -713.568 -713.568] (0.9322) ({r_i: None, r_t: [-2366.798 -2366.798 -2366.798], eps: 0.932})
Step:  174900, Reward: [-1151.240 -1151.240 -1151.240] [142.350], Avg: [-713.818 -713.818 -713.818] (0.9322) ({r_i: None, r_t: [-2314.064 -2314.064 -2314.064], eps: 0.932})
Step:  175000, Reward: [-1174.708 -1174.708 -1174.708] [191.206], Avg: [-714.082 -714.082 -714.082] (0.9322) ({r_i: None, r_t: [-2279.130 -2279.130 -2279.130], eps: 0.932})
Step:  175100, Reward: [-1191.940 -1191.940 -1191.940] [116.237], Avg: [-714.354 -714.354 -714.354] (0.9322) ({r_i: None, r_t: [-2423.850 -2423.850 -2423.850], eps: 0.932})
Step:  175200, Reward: [-1300.792 -1300.792 -1300.792] [144.173], Avg: [-714.689 -714.689 -714.689] (0.9322) ({r_i: None, r_t: [-2565.825 -2565.825 -2565.825], eps: 0.932})
Step:  175300, Reward: [-1257.875 -1257.875 -1257.875] [207.318], Avg: [-714.999 -714.999 -714.999] (0.9322) ({r_i: None, r_t: [-2482.853 -2482.853 -2482.853], eps: 0.932})
Step:  175400, Reward: [-1227.831 -1227.831 -1227.831] [155.882], Avg: [-715.291 -715.291 -715.291] (0.9322) ({r_i: None, r_t: [-2470.690 -2470.690 -2470.690], eps: 0.932})
Step:  175500, Reward: [-1224.089 -1224.089 -1224.089] [156.495], Avg: [-715.581 -715.581 -715.581] (0.9322) ({r_i: None, r_t: [-2504.707 -2504.707 -2504.707], eps: 0.932})
Step:  175600, Reward: [-1173.624 -1173.624 -1173.624] [188.509], Avg: [-715.841 -715.841 -715.841] (0.9322) ({r_i: None, r_t: [-2485.224 -2485.224 -2485.224], eps: 0.932})
Step:  175700, Reward: [-1264.281 -1264.281 -1264.281] [199.104], Avg: [-716.153 -716.153 -716.153] (0.9322) ({r_i: None, r_t: [-2573.096 -2573.096 -2573.096], eps: 0.932})
Step:  175800, Reward: [-1363.158 -1363.158 -1363.158] [217.161], Avg: [-716.521 -716.521 -716.521] (0.9322) ({r_i: None, r_t: [-2593.337 -2593.337 -2593.337], eps: 0.932})
Step:  175900, Reward: [-1284.853 -1284.853 -1284.853] [162.525], Avg: [-716.844 -716.844 -716.844] (0.9322) ({r_i: None, r_t: [-2634.523 -2634.523 -2634.523], eps: 0.932})
Step:  176000, Reward: [-1388.214 -1388.214 -1388.214] [252.248], Avg: [-717.225 -717.225 -717.225] (0.9322) ({r_i: None, r_t: [-2601.399 -2601.399 -2601.399], eps: 0.932})
Step:  176100, Reward: [-1300.432 -1300.432 -1300.432] [266.841], Avg: [-717.556 -717.556 -717.556] (0.9322) ({r_i: None, r_t: [-2606.159 -2606.159 -2606.159], eps: 0.932})
Step:  176200, Reward: [-1290.016 -1290.016 -1290.016] [221.476], Avg: [-717.881 -717.881 -717.881] (0.9322) ({r_i: None, r_t: [-2643.743 -2643.743 -2643.743], eps: 0.932})
Step:  176300, Reward: [-1289.132 -1289.132 -1289.132] [171.610], Avg: [-718.205 -718.205 -718.205] (0.9322) ({r_i: None, r_t: [-2706.946 -2706.946 -2706.946], eps: 0.932})
Step:  176400, Reward: [-1231.541 -1231.541 -1231.541] [287.213], Avg: [-718.496 -718.496 -718.496] (0.9322) ({r_i: None, r_t: [-2721.095 -2721.095 -2721.095], eps: 0.932})
Step:  176500, Reward: [-1323.366 -1323.366 -1323.366] [206.309], Avg: [-718.838 -718.838 -718.838] (0.9322) ({r_i: None, r_t: [-2563.208 -2563.208 -2563.208], eps: 0.932})
Step:  176600, Reward: [-1206.541 -1206.541 -1206.541] [187.154], Avg: [-719.114 -719.114 -719.114] (0.9322) ({r_i: None, r_t: [-2754.632 -2754.632 -2754.632], eps: 0.932})
Step:  176700, Reward: [-1262.593 -1262.593 -1262.593] [205.643], Avg: [-719.421 -719.421 -719.421] (0.9322) ({r_i: None, r_t: [-2624.712 -2624.712 -2624.712], eps: 0.932})
Step:  176800, Reward: [-1437.610 -1437.610 -1437.610] [187.990], Avg: [-719.827 -719.827 -719.827] (0.9322) ({r_i: None, r_t: [-2755.886 -2755.886 -2755.886], eps: 0.932})
Step:  176900, Reward: [-1464.305 -1464.305 -1464.305] [206.645], Avg: [-720.248 -720.248 -720.248] (0.9322) ({r_i: None, r_t: [-2783.440 -2783.440 -2783.440], eps: 0.932})
Step:  177000, Reward: [-1426.547 -1426.547 -1426.547] [170.461], Avg: [-720.647 -720.647 -720.647] (0.9322) ({r_i: None, r_t: [-2702.704 -2702.704 -2702.704], eps: 0.932})
Step:  177100, Reward: [-1459.586 -1459.586 -1459.586] [190.918], Avg: [-721.064 -721.064 -721.064] (0.9322) ({r_i: None, r_t: [-2949.720 -2949.720 -2949.720], eps: 0.932})
Step:  177200, Reward: [-1526.609 -1526.609 -1526.609] [183.079], Avg: [-721.518 -721.518 -721.518] (0.9322) ({r_i: None, r_t: [-2874.313 -2874.313 -2874.313], eps: 0.932})
Step:  177300, Reward: [-1415.187 -1415.187 -1415.187] [222.887], Avg: [-721.909 -721.909 -721.909] (0.9322) ({r_i: None, r_t: [-2939.401 -2939.401 -2939.401], eps: 0.932})
Step:  177400, Reward: [-1510.197 -1510.197 -1510.197] [137.975], Avg: [-722.353 -722.353 -722.353] (0.9322) ({r_i: None, r_t: [-2950.404 -2950.404 -2950.404], eps: 0.932})
Step:  177500, Reward: [-1370.776 -1370.776 -1370.776] [192.707], Avg: [-722.718 -722.718 -722.718] (0.9322) ({r_i: None, r_t: [-2940.193 -2940.193 -2940.193], eps: 0.932})
Step:  177600, Reward: [-1401.134 -1401.134 -1401.134] [205.269], Avg: [-723.100 -723.100 -723.100] (0.9322) ({r_i: None, r_t: [-2865.756 -2865.756 -2865.756], eps: 0.932})
Step:  177700, Reward: [-1628.018 -1628.018 -1628.018] [247.158], Avg: [-723.609 -723.609 -723.609] (0.9322) ({r_i: None, r_t: [-2933.925 -2933.925 -2933.925], eps: 0.932})
Step:  177800, Reward: [-1386.518 -1386.518 -1386.518] [274.567], Avg: [-723.982 -723.982 -723.982] (0.9322) ({r_i: None, r_t: [-2824.362 -2824.362 -2824.362], eps: 0.932})
Step:  177900, Reward: [-1369.723 -1369.723 -1369.723] [237.083], Avg: [-724.345 -724.345 -724.345] (0.9322) ({r_i: None, r_t: [-2875.946 -2875.946 -2875.946], eps: 0.932})
Step:  178000, Reward: [-1395.417 -1395.417 -1395.417] [271.507], Avg: [-724.721 -724.721 -724.721] (0.9322) ({r_i: None, r_t: [-2848.050 -2848.050 -2848.050], eps: 0.932})
Step:  178100, Reward: [-1478.373 -1478.373 -1478.373] [173.193], Avg: [-725.144 -725.144 -725.144] (0.9322) ({r_i: None, r_t: [-3065.229 -3065.229 -3065.229], eps: 0.932})
Step:  178200, Reward: [-1505.201 -1505.201 -1505.201] [287.328], Avg: [-725.582 -725.582 -725.582] (0.9322) ({r_i: None, r_t: [-2985.872 -2985.872 -2985.872], eps: 0.932})
Step:  178300, Reward: [-1448.064 -1448.064 -1448.064] [187.526], Avg: [-725.987 -725.987 -725.987] (0.9322) ({r_i: None, r_t: [-3004.380 -3004.380 -3004.380], eps: 0.932})
Step:  178400, Reward: [-1485.500 -1485.500 -1485.500] [235.704], Avg: [-726.412 -726.412 -726.412] (0.9322) ({r_i: None, r_t: [-3111.575 -3111.575 -3111.575], eps: 0.932})
Step:  178500, Reward: [-1585.857 -1585.857 -1585.857] [195.408], Avg: [-726.894 -726.894 -726.894] (0.9322) ({r_i: None, r_t: [-2929.390 -2929.390 -2929.390], eps: 0.932})
Step:  178600, Reward: [-1630.126 -1630.126 -1630.126] [216.875], Avg: [-727.399 -727.399 -727.399] (0.9322) ({r_i: None, r_t: [-3063.118 -3063.118 -3063.118], eps: 0.932})
Step:  178700, Reward: [-1569.792 -1569.792 -1569.792] [189.452], Avg: [-727.870 -727.870 -727.870] (0.9322) ({r_i: None, r_t: [-3001.458 -3001.458 -3001.458], eps: 0.932})
Step:  178800, Reward: [-1551.828 -1551.828 -1551.828] [213.947], Avg: [-728.331 -728.331 -728.331] (0.9322) ({r_i: None, r_t: [-3030.512 -3030.512 -3030.512], eps: 0.932})
Step:  178900, Reward: [-1549.712 -1549.712 -1549.712] [231.638], Avg: [-728.790 -728.790 -728.790] (0.9322) ({r_i: None, r_t: [-2984.924 -2984.924 -2984.924], eps: 0.932})
Step:  179000, Reward: [-1465.532 -1465.532 -1465.532] [255.310], Avg: [-729.201 -729.201 -729.201] (0.9322) ({r_i: None, r_t: [-3196.479 -3196.479 -3196.479], eps: 0.932})
Step:  179100, Reward: [-1672.321 -1672.321 -1672.321] [177.728], Avg: [-729.727 -729.727 -729.727] (0.9322) ({r_i: None, r_t: [-3132.209 -3132.209 -3132.209], eps: 0.932})
Step:  179200, Reward: [-1522.286 -1522.286 -1522.286] [243.389], Avg: [-730.169 -730.169 -730.169] (0.9322) ({r_i: None, r_t: [-3157.889 -3157.889 -3157.889], eps: 0.932})
Step:  179300, Reward: [-1690.678 -1690.678 -1690.678] [176.272], Avg: [-730.705 -730.705 -730.705] (0.9322) ({r_i: None, r_t: [-3196.772 -3196.772 -3196.772], eps: 0.932})
Step:  179400, Reward: [-1685.062 -1685.062 -1685.062] [193.386], Avg: [-731.236 -731.236 -731.236] (0.9322) ({r_i: None, r_t: [-3277.166 -3277.166 -3277.166], eps: 0.932})
Step:  179500, Reward: [-1534.814 -1534.814 -1534.814] [184.394], Avg: [-731.684 -731.684 -731.684] (0.9322) ({r_i: None, r_t: [-3375.951 -3375.951 -3375.951], eps: 0.932})
Step:  179600, Reward: [-1615.526 -1615.526 -1615.526] [262.387], Avg: [-732.176 -732.176 -732.176] (0.9322) ({r_i: None, r_t: [-3308.655 -3308.655 -3308.655], eps: 0.932})
Step:  179700, Reward: [-1614.667 -1614.667 -1614.667] [198.812], Avg: [-732.666 -732.666 -732.666] (0.9322) ({r_i: None, r_t: [-3360.213 -3360.213 -3360.213], eps: 0.932})
Step:  179800, Reward: [-1584.849 -1584.849 -1584.849] [195.800], Avg: [-733.140 -733.140 -733.140] (0.9322) ({r_i: None, r_t: [-3252.884 -3252.884 -3252.884], eps: 0.932})
Step:  179900, Reward: [-1516.891 -1516.891 -1516.891] [228.878], Avg: [-733.575 -733.575 -733.575] (0.9322) ({r_i: None, r_t: [-3351.553 -3351.553 -3351.553], eps: 0.932})
Step:  180000, Reward: [-1577.960 -1577.960 -1577.960] [295.831], Avg: [-734.044 -734.044 -734.044] (0.9322) ({r_i: None, r_t: [-3338.904 -3338.904 -3338.904], eps: 0.932})
Step:  180100, Reward: [-1643.761 -1643.761 -1643.761] [198.223], Avg: [-734.549 -734.549 -734.549] (0.9322) ({r_i: None, r_t: [-3432.918 -3432.918 -3432.918], eps: 0.932})
Step:  180200, Reward: [-1614.572 -1614.572 -1614.572] [247.373], Avg: [-735.037 -735.037 -735.037] (0.9322) ({r_i: None, r_t: [-3330.683 -3330.683 -3330.683], eps: 0.932})
Step:  180300, Reward: [-1685.301 -1685.301 -1685.301] [298.732], Avg: [-735.564 -735.564 -735.564] (0.9322) ({r_i: None, r_t: [-3349.803 -3349.803 -3349.803], eps: 0.932})
Step:  180400, Reward: [-1773.574 -1773.574 -1773.574] [131.373], Avg: [-736.139 -736.139 -736.139] (0.9322) ({r_i: None, r_t: [-3376.239 -3376.239 -3376.239], eps: 0.932})
Step:  180500, Reward: [-1697.070 -1697.070 -1697.070] [197.191], Avg: [-736.671 -736.671 -736.671] (0.9322) ({r_i: None, r_t: [-3448.884 -3448.884 -3448.884], eps: 0.932})
Step:  180600, Reward: [-1759.255 -1759.255 -1759.255] [222.766], Avg: [-737.237 -737.237 -737.237] (0.9322) ({r_i: None, r_t: [-3275.996 -3275.996 -3275.996], eps: 0.932})
Step:  180700, Reward: [-1683.551 -1683.551 -1683.551] [201.014], Avg: [-737.760 -737.760 -737.760] (0.9322) ({r_i: None, r_t: [-3449.548 -3449.548 -3449.548], eps: 0.932})
Step:  180800, Reward: [-1658.488 -1658.488 -1658.488] [237.126], Avg: [-738.269 -738.269 -738.269] (0.9322) ({r_i: None, r_t: [-3415.385 -3415.385 -3415.385], eps: 0.932})
Step:  180900, Reward: [-1784.649 -1784.649 -1784.649] [213.283], Avg: [-738.848 -738.848 -738.848] (0.9322) ({r_i: None, r_t: [-3486.380 -3486.380 -3486.380], eps: 0.932})
Step:  181000, Reward: [-1727.375 -1727.375 -1727.375] [255.102], Avg: [-739.393 -739.393 -739.393] (0.9322) ({r_i: None, r_t: [-3503.772 -3503.772 -3503.772], eps: 0.932})
Step:  181100, Reward: [-1755.128 -1755.128 -1755.128] [198.544], Avg: [-739.954 -739.954 -739.954] (0.9322) ({r_i: None, r_t: [-3301.984 -3301.984 -3301.984], eps: 0.932})
Step:  181200, Reward: [-1656.153 -1656.153 -1656.153] [191.763], Avg: [-740.459 -740.459 -740.459] (0.9322) ({r_i: None, r_t: [-3511.341 -3511.341 -3511.341], eps: 0.932})
Step:  181300, Reward: [-1725.631 -1725.631 -1725.631] [209.028], Avg: [-741.002 -741.002 -741.002] (0.9322) ({r_i: None, r_t: [-3349.395 -3349.395 -3349.395], eps: 0.932})
Step:  181400, Reward: [-1736.189 -1736.189 -1736.189] [175.162], Avg: [-741.551 -741.551 -741.551] (0.9322) ({r_i: None, r_t: [-3592.923 -3592.923 -3592.923], eps: 0.932})
Step:  181500, Reward: [-1844.545 -1844.545 -1844.545] [166.958], Avg: [-742.158 -742.158 -742.158] (0.9322) ({r_i: None, r_t: [-3437.357 -3437.357 -3437.357], eps: 0.932})
Step:  181600, Reward: [-1811.144 -1811.144 -1811.144] [172.853], Avg: [-742.746 -742.746 -742.746] (0.9322) ({r_i: None, r_t: [-3379.624 -3379.624 -3379.624], eps: 0.932})
Step:  181700, Reward: [-1786.483 -1786.483 -1786.483] [169.889], Avg: [-743.321 -743.321 -743.321] (0.9322) ({r_i: None, r_t: [-3382.828 -3382.828 -3382.828], eps: 0.932})
Step:  181800, Reward: [-1768.228 -1768.228 -1768.228] [237.059], Avg: [-743.884 -743.884 -743.884] (0.9322) ({r_i: None, r_t: [-3543.371 -3543.371 -3543.371], eps: 0.932})
Step:  181900, Reward: [-1790.678 -1790.678 -1790.678] [250.736], Avg: [-744.459 -744.459 -744.459] (0.9322) ({r_i: None, r_t: [-3481.748 -3481.748 -3481.748], eps: 0.932})
Step:  182000, Reward: [-1754.424 -1754.424 -1754.424] [268.455], Avg: [-745.014 -745.014 -745.014] (0.9322) ({r_i: None, r_t: [-3522.539 -3522.539 -3522.539], eps: 0.932})
Step:  182100, Reward: [-1786.806 -1786.806 -1786.806] [229.012], Avg: [-745.586 -745.586 -745.586] (0.9322) ({r_i: None, r_t: [-3432.367 -3432.367 -3432.367], eps: 0.932})
Step:  182200, Reward: [-1820.701 -1820.701 -1820.701] [207.074], Avg: [-746.175 -746.175 -746.175] (0.9322) ({r_i: None, r_t: [-3393.673 -3393.673 -3393.673], eps: 0.932})
Step:  182300, Reward: [-1838.545 -1838.545 -1838.545] [233.695], Avg: [-746.774 -746.774 -746.774] (0.9322) ({r_i: None, r_t: [-3479.494 -3479.494 -3479.494], eps: 0.932})
Step:  182400, Reward: [-1852.856 -1852.856 -1852.856] [169.401], Avg: [-747.380 -747.380 -747.380] (0.9322) ({r_i: None, r_t: [-3558.033 -3558.033 -3558.033], eps: 0.932})
Step:  182500, Reward: [-1806.538 -1806.538 -1806.538] [251.361], Avg: [-747.960 -747.960 -747.960] (0.9322) ({r_i: None, r_t: [-3420.224 -3420.224 -3420.224], eps: 0.932})
Step:  182600, Reward: [-1860.997 -1860.997 -1860.997] [253.174], Avg: [-748.570 -748.570 -748.570] (0.9276) ({r_i: None, r_t: [-3490.203 -3490.203 -3490.203], eps: 0.928})
Step:  182700, Reward: [-1855.078 -1855.078 -1855.078] [221.526], Avg: [-749.175 -749.175 -749.175] (0.9276) ({r_i: None, r_t: [-3580.653 -3580.653 -3580.653], eps: 0.928})
Step:  182800, Reward: [-1732.051 -1732.051 -1732.051] [256.556], Avg: [-749.712 -749.712 -749.712] (0.9276) ({r_i: None, r_t: [-3634.436 -3634.436 -3634.436], eps: 0.928})
Step:  182900, Reward: [-1867.619 -1867.619 -1867.619] [256.780], Avg: [-750.323 -750.323 -750.323] (0.9276) ({r_i: None, r_t: [-3596.039 -3596.039 -3596.039], eps: 0.928})
Step:  183000, Reward: [-1863.635 -1863.635 -1863.635] [133.195], Avg: [-750.931 -750.931 -750.931] (0.9276) ({r_i: None, r_t: [-3661.909 -3661.909 -3661.909], eps: 0.928})
Step:  183100, Reward: [-1792.235 -1792.235 -1792.235] [249.389], Avg: [-751.500 -751.500 -751.500] (0.9276) ({r_i: None, r_t: [-3682.168 -3682.168 -3682.168], eps: 0.928})
Step:  183200, Reward: [-1755.898 -1755.898 -1755.898] [125.129], Avg: [-752.047 -752.047 -752.047] (0.9276) ({r_i: None, r_t: [-3633.748 -3633.748 -3633.748], eps: 0.928})
Step:  183300, Reward: [-1842.118 -1842.118 -1842.118] [254.018], Avg: [-752.642 -752.642 -752.642] (0.9276) ({r_i: None, r_t: [-3542.634 -3542.634 -3542.634], eps: 0.928})
Step:  183400, Reward: [-1805.140 -1805.140 -1805.140] [310.097], Avg: [-753.215 -753.215 -753.215] (0.9276) ({r_i: None, r_t: [-3661.258 -3661.258 -3661.258], eps: 0.928})
Step:  183500, Reward: [-1805.123 -1805.123 -1805.123] [216.998], Avg: [-753.788 -753.788 -753.788] (0.9276) ({r_i: None, r_t: [-3641.679 -3641.679 -3641.679], eps: 0.928})
Step:  183600, Reward: [-1855.115 -1855.115 -1855.115] [233.929], Avg: [-754.388 -754.388 -754.388] (0.9276) ({r_i: None, r_t: [-3551.149 -3551.149 -3551.149], eps: 0.928})
Step:  183700, Reward: [-1812.657 -1812.657 -1812.657] [182.349], Avg: [-754.964 -754.964 -754.964] (0.9276) ({r_i: None, r_t: [-3613.066 -3613.066 -3613.066], eps: 0.928})
Step:  183800, Reward: [-1850.505 -1850.505 -1850.505] [293.221], Avg: [-755.559 -755.559 -755.559] (0.9276) ({r_i: None, r_t: [-3788.543 -3788.543 -3788.543], eps: 0.928})
Step:  183900, Reward: [-1849.340 -1849.340 -1849.340] [255.719], Avg: [-756.154 -756.154 -756.154] (0.9276) ({r_i: None, r_t: [-3801.771 -3801.771 -3801.771], eps: 0.928})
Step:  184000, Reward: [-1867.023 -1867.023 -1867.023] [206.167], Avg: [-756.757 -756.757 -756.757] (0.9276) ({r_i: None, r_t: [-3823.494 -3823.494 -3823.494], eps: 0.928})
Step:  184100, Reward: [-1796.223 -1796.223 -1796.223] [198.211], Avg: [-757.322 -757.322 -757.322] (0.9276) ({r_i: None, r_t: [-3618.729 -3618.729 -3618.729], eps: 0.928})
Step:  184200, Reward: [-1846.556 -1846.556 -1846.556] [180.576], Avg: [-757.913 -757.913 -757.913] (0.9276) ({r_i: None, r_t: [-3630.676 -3630.676 -3630.676], eps: 0.928})
Step:  184300, Reward: [-1811.179 -1811.179 -1811.179] [178.877], Avg: [-758.484 -758.484 -758.484] (0.9276) ({r_i: None, r_t: [-3677.371 -3677.371 -3677.371], eps: 0.928})
Step:  184400, Reward: [-1876.638 -1876.638 -1876.638] [176.766], Avg: [-759.090 -759.090 -759.090] (0.9276) ({r_i: None, r_t: [-3610.194 -3610.194 -3610.194], eps: 0.928})
Step:  184500, Reward: [-1917.822 -1917.822 -1917.822] [160.103], Avg: [-759.717 -759.717 -759.717] (0.9276) ({r_i: None, r_t: [-3778.359 -3778.359 -3778.359], eps: 0.928})
Step:  184600, Reward: [-1791.936 -1791.936 -1791.936] [201.873], Avg: [-760.276 -760.276 -760.276] (0.9276) ({r_i: None, r_t: [-3524.192 -3524.192 -3524.192], eps: 0.928})
Step:  184700, Reward: [-1869.031 -1869.031 -1869.031] [198.882], Avg: [-760.876 -760.876 -760.876] (0.9276) ({r_i: None, r_t: [-3655.922 -3655.922 -3655.922], eps: 0.928})
Step:  184800, Reward: [-1866.829 -1866.829 -1866.829] [205.955], Avg: [-761.474 -761.474 -761.474] (0.9276) ({r_i: None, r_t: [-3724.100 -3724.100 -3724.100], eps: 0.928})
Step:  184900, Reward: [-1855.984 -1855.984 -1855.984] [231.377], Avg: [-762.066 -762.066 -762.066] (0.9276) ({r_i: None, r_t: [-3652.752 -3652.752 -3652.752], eps: 0.928})
Step:  185000, Reward: [-1929.779 -1929.779 -1929.779] [185.723], Avg: [-762.697 -762.697 -762.697] (0.9276) ({r_i: None, r_t: [-3600.524 -3600.524 -3600.524], eps: 0.928})
Step:  185100, Reward: [-1851.198 -1851.198 -1851.198] [194.478], Avg: [-763.285 -763.285 -763.285] (0.9276) ({r_i: None, r_t: [-3758.640 -3758.640 -3758.640], eps: 0.928})
Step:  185200, Reward: [-1849.878 -1849.878 -1849.878] [184.780], Avg: [-763.871 -763.871 -763.871] (0.9276) ({r_i: None, r_t: [-3728.596 -3728.596 -3728.596], eps: 0.928})
Step:  185300, Reward: [-1929.145 -1929.145 -1929.145] [191.135], Avg: [-764.500 -764.500 -764.500] (0.9276) ({r_i: None, r_t: [-3629.299 -3629.299 -3629.299], eps: 0.928})
Step:  185400, Reward: [-1839.007 -1839.007 -1839.007] [181.046], Avg: [-765.079 -765.079 -765.079] (0.9276) ({r_i: None, r_t: [-3762.065 -3762.065 -3762.065], eps: 0.928})
Step:  185500, Reward: [-1897.602 -1897.602 -1897.602] [196.469], Avg: [-765.689 -765.689 -765.689] (0.9276) ({r_i: None, r_t: [-3821.822 -3821.822 -3821.822], eps: 0.928})
Step:  185600, Reward: [-1769.188 -1769.188 -1769.188] [208.990], Avg: [-766.229 -766.229 -766.229] (0.9276) ({r_i: None, r_t: [-3796.956 -3796.956 -3796.956], eps: 0.928})
Step:  185700, Reward: [-1800.044 -1800.044 -1800.044] [221.646], Avg: [-766.786 -766.786 -766.786] (0.9276) ({r_i: None, r_t: [-3674.500 -3674.500 -3674.500], eps: 0.928})
Step:  185800, Reward: [-1924.797 -1924.797 -1924.797] [208.293], Avg: [-767.409 -767.409 -767.409] (0.9276) ({r_i: None, r_t: [-3606.871 -3606.871 -3606.871], eps: 0.928})
Step:  185900, Reward: [-1883.107 -1883.107 -1883.107] [195.024], Avg: [-768.009 -768.009 -768.009] (0.9276) ({r_i: None, r_t: [-3673.958 -3673.958 -3673.958], eps: 0.928})
Step:  186000, Reward: [-1816.140 -1816.140 -1816.140] [203.431], Avg: [-768.572 -768.572 -768.572] (0.9276) ({r_i: None, r_t: [-3701.365 -3701.365 -3701.365], eps: 0.928})
Step:  186100, Reward: [-1870.094 -1870.094 -1870.094] [130.521], Avg: [-769.163 -769.163 -769.163] (0.9276) ({r_i: None, r_t: [-3710.802 -3710.802 -3710.802], eps: 0.928})
Step:  186200, Reward: [-1843.064 -1843.064 -1843.064] [203.871], Avg: [-769.740 -769.740 -769.740] (0.9276) ({r_i: None, r_t: [-3682.824 -3682.824 -3682.824], eps: 0.928})
Step:  186300, Reward: [-1899.752 -1899.752 -1899.752] [130.688], Avg: [-770.346 -770.346 -770.346] (0.9276) ({r_i: None, r_t: [-3670.589 -3670.589 -3670.589], eps: 0.928})
Step:  186400, Reward: [-1877.293 -1877.293 -1877.293] [246.970], Avg: [-770.940 -770.940 -770.940] (0.9276) ({r_i: None, r_t: [-3774.079 -3774.079 -3774.079], eps: 0.928})
Step:  186500, Reward: [-1837.174 -1837.174 -1837.174] [248.797], Avg: [-771.511 -771.511 -771.511] (0.9276) ({r_i: None, r_t: [-3757.189 -3757.189 -3757.189], eps: 0.928})
Step:  186600, Reward: [-1912.000 -1912.000 -1912.000] [158.798], Avg: [-772.122 -772.122 -772.122] (0.9276) ({r_i: None, r_t: [-3646.489 -3646.489 -3646.489], eps: 0.928})
Step:  186700, Reward: [-1939.114 -1939.114 -1939.114] [281.767], Avg: [-772.747 -772.747 -772.747] (0.9276) ({r_i: None, r_t: [-3764.243 -3764.243 -3764.243], eps: 0.928})
Step:  186800, Reward: [-1837.735 -1837.735 -1837.735] [237.725], Avg: [-773.316 -773.316 -773.316] (0.9276) ({r_i: None, r_t: [-3680.193 -3680.193 -3680.193], eps: 0.928})
Step:  186900, Reward: [-1814.593 -1814.593 -1814.593] [254.071], Avg: [-773.873 -773.873 -773.873] (0.9276) ({r_i: None, r_t: [-3612.114 -3612.114 -3612.114], eps: 0.928})
Step:  187000, Reward: [-1881.863 -1881.863 -1881.863] [223.921], Avg: [-774.465 -774.465 -774.465] (0.9276) ({r_i: None, r_t: [-3667.310 -3667.310 -3667.310], eps: 0.928})
Step:  187100, Reward: [-1774.787 -1774.787 -1774.787] [218.974], Avg: [-775.000 -775.000 -775.000] (0.9276) ({r_i: None, r_t: [-3684.984 -3684.984 -3684.984], eps: 0.928})
Step:  187200, Reward: [-1848.457 -1848.457 -1848.457] [249.495], Avg: [-775.573 -775.573 -775.573] (0.9276) ({r_i: None, r_t: [-3668.848 -3668.848 -3668.848], eps: 0.928})
Step:  187300, Reward: [-1835.325 -1835.325 -1835.325] [225.459], Avg: [-776.138 -776.138 -776.138] (0.9276) ({r_i: None, r_t: [-3763.032 -3763.032 -3763.032], eps: 0.928})
Step:  187400, Reward: [-1869.533 -1869.533 -1869.533] [185.367], Avg: [-776.722 -776.722 -776.722] (0.9276) ({r_i: None, r_t: [-3647.692 -3647.692 -3647.692], eps: 0.928})
Step:  187500, Reward: [-1910.887 -1910.887 -1910.887] [132.366], Avg: [-777.326 -777.326 -777.326] (0.9276) ({r_i: None, r_t: [-3747.260 -3747.260 -3747.260], eps: 0.928})
Step:  187600, Reward: [-1828.365 -1828.365 -1828.365] [225.164], Avg: [-777.886 -777.886 -777.886] (0.9276) ({r_i: None, r_t: [-3763.996 -3763.996 -3763.996], eps: 0.928})
Step:  187700, Reward: [-1927.404 -1927.404 -1927.404] [213.630], Avg: [-778.498 -778.498 -778.498] (0.9276) ({r_i: None, r_t: [-3728.501 -3728.501 -3728.501], eps: 0.928})
Step:  187800, Reward: [-1919.120 -1919.120 -1919.120] [172.703], Avg: [-779.105 -779.105 -779.105] (0.9276) ({r_i: None, r_t: [-3739.346 -3739.346 -3739.346], eps: 0.928})
Step:  187900, Reward: [-1818.554 -1818.554 -1818.554] [272.675], Avg: [-779.658 -779.658 -779.658] (0.9276) ({r_i: None, r_t: [-3769.534 -3769.534 -3769.534], eps: 0.928})
Step:  188000, Reward: [-1890.438 -1890.438 -1890.438] [207.418], Avg: [-780.249 -780.249 -780.249] (0.9276) ({r_i: None, r_t: [-3775.449 -3775.449 -3775.449], eps: 0.928})
Step:  188100, Reward: [-1882.562 -1882.562 -1882.562] [186.862], Avg: [-780.834 -780.834 -780.834] (0.9276) ({r_i: None, r_t: [-3853.756 -3853.756 -3853.756], eps: 0.928})
Step:  188200, Reward: [-1941.450 -1941.450 -1941.450] [166.339], Avg: [-781.451 -781.451 -781.451] (0.9276) ({r_i: None, r_t: [-3950.021 -3950.021 -3950.021], eps: 0.928})
Step:  188300, Reward: [-1924.601 -1924.601 -1924.601] [233.527], Avg: [-782.057 -782.057 -782.057] (0.9276) ({r_i: None, r_t: [-3601.895 -3601.895 -3601.895], eps: 0.928})
Step:  188400, Reward: [-1863.127 -1863.127 -1863.127] [206.196], Avg: [-782.631 -782.631 -782.631] (0.9276) ({r_i: None, r_t: [-3725.339 -3725.339 -3725.339], eps: 0.928})
Step:  188500, Reward: [-1922.949 -1922.949 -1922.949] [178.521], Avg: [-783.236 -783.236 -783.236] (0.9276) ({r_i: None, r_t: [-3850.719 -3850.719 -3850.719], eps: 0.928})
Step:  188600, Reward: [-1899.932 -1899.932 -1899.932] [276.331], Avg: [-783.827 -783.827 -783.827] (0.9276) ({r_i: None, r_t: [-3711.433 -3711.433 -3711.433], eps: 0.928})
Step:  188700, Reward: [-1818.563 -1818.563 -1818.563] [197.662], Avg: [-784.375 -784.375 -784.375] (0.9276) ({r_i: None, r_t: [-3822.475 -3822.475 -3822.475], eps: 0.928})
Step:  188800, Reward: [-1879.579 -1879.579 -1879.579] [277.175], Avg: [-784.955 -784.955 -784.955] (0.9276) ({r_i: None, r_t: [-3662.161 -3662.161 -3662.161], eps: 0.928})
Step:  188900, Reward: [-1814.839 -1814.839 -1814.839] [285.818], Avg: [-785.500 -785.500 -785.500] (0.9276) ({r_i: None, r_t: [-3700.785 -3700.785 -3700.785], eps: 0.928})
Step:  189000, Reward: [-2015.755 -2015.755 -2015.755] [196.077], Avg: [-786.151 -786.151 -786.151] (0.9276) ({r_i: None, r_t: [-3525.262 -3525.262 -3525.262], eps: 0.928})
Step:  189100, Reward: [-1907.878 -1907.878 -1907.878] [146.926], Avg: [-786.744 -786.744 -786.744] (0.9276) ({r_i: None, r_t: [-3836.643 -3836.643 -3836.643], eps: 0.928})
Step:  189200, Reward: [-1908.948 -1908.948 -1908.948] [238.651], Avg: [-787.336 -787.336 -787.336] (0.9276) ({r_i: None, r_t: [-3736.329 -3736.329 -3736.329], eps: 0.928})
Step:  189300, Reward: [-1809.850 -1809.850 -1809.850] [257.235], Avg: [-787.876 -787.876 -787.876] (0.9276) ({r_i: None, r_t: [-3750.294 -3750.294 -3750.294], eps: 0.928})
Step:  189400, Reward: [-1820.303 -1820.303 -1820.303] [234.558], Avg: [-788.421 -788.421 -788.421] (0.9276) ({r_i: None, r_t: [-3543.303 -3543.303 -3543.303], eps: 0.928})
Step:  189500, Reward: [-1902.456 -1902.456 -1902.456] [164.708], Avg: [-789.009 -789.009 -789.009] (0.9276) ({r_i: None, r_t: [-3731.762 -3731.762 -3731.762], eps: 0.928})
Step:  189600, Reward: [-1879.646 -1879.646 -1879.646] [251.198], Avg: [-789.584 -789.584 -789.584] (0.9276) ({r_i: None, r_t: [-3720.671 -3720.671 -3720.671], eps: 0.928})
Step:  189700, Reward: [-1876.593 -1876.593 -1876.593] [168.619], Avg: [-790.156 -790.156 -790.156] (0.9276) ({r_i: None, r_t: [-3686.471 -3686.471 -3686.471], eps: 0.928})
Step:  189800, Reward: [-1905.963 -1905.963 -1905.963] [203.760], Avg: [-790.744 -790.744 -790.744] (0.9276) ({r_i: None, r_t: [-3722.708 -3722.708 -3722.708], eps: 0.928})
Step:  189900, Reward: [-1969.143 -1969.143 -1969.143] [223.252], Avg: [-791.364 -791.364 -791.364] (0.9276) ({r_i: None, r_t: [-3660.150 -3660.150 -3660.150], eps: 0.928})
Step:  190000, Reward: [-1868.685 -1868.685 -1868.685] [279.677], Avg: [-791.931 -791.931 -791.931] (0.9276) ({r_i: None, r_t: [-3821.987 -3821.987 -3821.987], eps: 0.928})
Step:  190100, Reward: [-1920.669 -1920.669 -1920.669] [210.623], Avg: [-792.524 -792.524 -792.524] (0.9276) ({r_i: None, r_t: [-3784.939 -3784.939 -3784.939], eps: 0.928})
Step:  190200, Reward: [-1857.425 -1857.425 -1857.425] [284.718], Avg: [-793.084 -793.084 -793.084] (0.9276) ({r_i: None, r_t: [-3829.591 -3829.591 -3829.591], eps: 0.928})
Step:  190300, Reward: [-1949.662 -1949.662 -1949.662] [293.185], Avg: [-793.691 -793.691 -793.691] (0.9276) ({r_i: None, r_t: [-3861.825 -3861.825 -3861.825], eps: 0.928})
Step:  190400, Reward: [-1878.165 -1878.165 -1878.165] [136.966], Avg: [-794.261 -794.261 -794.261] (0.9276) ({r_i: None, r_t: [-3709.065 -3709.065 -3709.065], eps: 0.928})
Step:  190500, Reward: [-1868.176 -1868.176 -1868.176] [174.351], Avg: [-794.824 -794.824 -794.824] (0.9276) ({r_i: None, r_t: [-3868.940 -3868.940 -3868.940], eps: 0.928})
Step:  190600, Reward: [-1906.449 -1906.449 -1906.449] [200.172], Avg: [-795.407 -795.407 -795.407] (0.9276) ({r_i: None, r_t: [-3855.561 -3855.561 -3855.561], eps: 0.928})
Step:  190700, Reward: [-1961.613 -1961.613 -1961.613] [181.726], Avg: [-796.018 -796.018 -796.018] (0.9276) ({r_i: None, r_t: [-3780.370 -3780.370 -3780.370], eps: 0.928})
Step:  190800, Reward: [-1923.037 -1923.037 -1923.037] [182.957], Avg: [-796.609 -796.609 -796.609] (0.9276) ({r_i: None, r_t: [-3836.095 -3836.095 -3836.095], eps: 0.928})
Step:  190900, Reward: [-1845.722 -1845.722 -1845.722] [260.449], Avg: [-797.158 -797.158 -797.158] (0.9276) ({r_i: None, r_t: [-3749.566 -3749.566 -3749.566], eps: 0.928})
Step:  191000, Reward: [-1959.124 -1959.124 -1959.124] [168.613], Avg: [-797.766 -797.766 -797.766] (0.9276) ({r_i: None, r_t: [-3742.189 -3742.189 -3742.189], eps: 0.928})
Step:  191100, Reward: [-1963.122 -1963.122 -1963.122] [162.147], Avg: [-798.375 -798.375 -798.375] (0.9276) ({r_i: None, r_t: [-3770.610 -3770.610 -3770.610], eps: 0.928})
Step:  191200, Reward: [-1947.691 -1947.691 -1947.691] [151.987], Avg: [-798.976 -798.976 -798.976] (0.9276) ({r_i: None, r_t: [-3746.376 -3746.376 -3746.376], eps: 0.928})
Step:  191300, Reward: [-1843.079 -1843.079 -1843.079] [234.808], Avg: [-799.522 -799.522 -799.522] (0.9276) ({r_i: None, r_t: [-3637.934 -3637.934 -3637.934], eps: 0.928})
Step:  191400, Reward: [-1976.186 -1976.186 -1976.186] [151.295], Avg: [-800.136 -800.136 -800.136] (0.9276) ({r_i: None, r_t: [-3717.843 -3717.843 -3717.843], eps: 0.928})
Step:  191500, Reward: [-1763.695 -1763.695 -1763.695] [218.993], Avg: [-800.639 -800.639 -800.639] (0.9276) ({r_i: None, r_t: [-3680.669 -3680.669 -3680.669], eps: 0.928})
Step:  191600, Reward: [-1856.704 -1856.704 -1856.704] [279.485], Avg: [-801.190 -801.190 -801.190] (0.9276) ({r_i: None, r_t: [-3802.235 -3802.235 -3802.235], eps: 0.928})
Step:  191700, Reward: [-1847.388 -1847.388 -1847.388] [195.490], Avg: [-801.735 -801.735 -801.735] (0.9276) ({r_i: None, r_t: [-3843.117 -3843.117 -3843.117], eps: 0.928})
Step:  191800, Reward: [-1868.449 -1868.449 -1868.449] [182.284], Avg: [-802.291 -802.291 -802.291] (0.9276) ({r_i: None, r_t: [-3734.513 -3734.513 -3734.513], eps: 0.928})
Step:  191900, Reward: [-1914.851 -1914.851 -1914.851] [206.057], Avg: [-802.871 -802.871 -802.871] (0.9276) ({r_i: None, r_t: [-3734.565 -3734.565 -3734.565], eps: 0.928})
Step:  192000, Reward: [-1946.107 -1946.107 -1946.107] [140.896], Avg: [-803.466 -803.466 -803.466] (0.9276) ({r_i: None, r_t: [-3745.794 -3745.794 -3745.794], eps: 0.928})
Step:  192100, Reward: [-1860.452 -1860.452 -1860.452] [223.347], Avg: [-804.016 -804.016 -804.016] (0.9276) ({r_i: None, r_t: [-3816.334 -3816.334 -3816.334], eps: 0.928})
Step:  192200, Reward: [-1878.452 -1878.452 -1878.452] [206.694], Avg: [-804.574 -804.574 -804.574] (0.9276) ({r_i: None, r_t: [-3856.939 -3856.939 -3856.939], eps: 0.928})
Step:  192300, Reward: [-1866.275 -1866.275 -1866.275] [163.605], Avg: [-805.126 -805.126 -805.126] (0.9276) ({r_i: None, r_t: [-3821.523 -3821.523 -3821.523], eps: 0.928})
Step:  192400, Reward: [-1838.759 -1838.759 -1838.759] [163.256], Avg: [-805.663 -805.663 -805.663] (0.9276) ({r_i: None, r_t: [-3708.332 -3708.332 -3708.332], eps: 0.928})
Step:  192500, Reward: [-1860.218 -1860.218 -1860.218] [170.547], Avg: [-806.211 -806.211 -806.211] (0.9276) ({r_i: None, r_t: [-3647.068 -3647.068 -3647.068], eps: 0.928})
Step:  192600, Reward: [-1914.238 -1914.238 -1914.238] [184.799], Avg: [-806.786 -806.786 -806.786] (0.9276) ({r_i: None, r_t: [-3776.811 -3776.811 -3776.811], eps: 0.928})
Step:  192700, Reward: [-1902.158 -1902.158 -1902.158] [258.771], Avg: [-807.354 -807.354 -807.354] (0.9276) ({r_i: None, r_t: [-3942.345 -3942.345 -3942.345], eps: 0.928})
Step:  192800, Reward: [-1888.781 -1888.781 -1888.781] [230.118], Avg: [-807.915 -807.915 -807.915] (0.9276) ({r_i: None, r_t: [-3634.984 -3634.984 -3634.984], eps: 0.928})
Step:  192900, Reward: [-1801.025 -1801.025 -1801.025] [156.153], Avg: [-808.429 -808.429 -808.429] (0.9276) ({r_i: None, r_t: [-3619.359 -3619.359 -3619.359], eps: 0.928})
Step:  193000, Reward: [-1841.635 -1841.635 -1841.635] [171.356], Avg: [-808.964 -808.964 -808.964] (0.9276) ({r_i: None, r_t: [-3696.964 -3696.964 -3696.964], eps: 0.928})
Step:  193100, Reward: [-1791.808 -1791.808 -1791.808] [149.523], Avg: [-809.473 -809.473 -809.473] (0.9276) ({r_i: None, r_t: [-3709.992 -3709.992 -3709.992], eps: 0.928})
Step:  193200, Reward: [-1856.807 -1856.807 -1856.807] [149.788], Avg: [-810.015 -810.015 -810.015] (0.9276) ({r_i: None, r_t: [-3541.684 -3541.684 -3541.684], eps: 0.928})
Step:  193300, Reward: [-1804.353 -1804.353 -1804.353] [170.698], Avg: [-810.529 -810.529 -810.529] (0.9276) ({r_i: None, r_t: [-3765.255 -3765.255 -3765.255], eps: 0.928})
Step:  193400, Reward: [-1831.777 -1831.777 -1831.777] [154.479], Avg: [-811.057 -811.057 -811.057] (0.9276) ({r_i: None, r_t: [-3628.608 -3628.608 -3628.608], eps: 0.928})
Step:  193500, Reward: [-1868.797 -1868.797 -1868.797] [249.264], Avg: [-811.603 -811.603 -811.603] (0.9276) ({r_i: None, r_t: [-3779.611 -3779.611 -3779.611], eps: 0.928})
Step:  193600, Reward: [-1864.597 -1864.597 -1864.597] [253.331], Avg: [-812.147 -812.147 -812.147] (0.9276) ({r_i: None, r_t: [-3754.143 -3754.143 -3754.143], eps: 0.928})
Step:  193700, Reward: [-1798.032 -1798.032 -1798.032] [173.579], Avg: [-812.655 -812.655 -812.655] (0.9276) ({r_i: None, r_t: [-3847.869 -3847.869 -3847.869], eps: 0.928})
Step:  193800, Reward: [-1891.835 -1891.835 -1891.835] [218.423], Avg: [-813.212 -813.212 -813.212] (0.9276) ({r_i: None, r_t: [-3729.317 -3729.317 -3729.317], eps: 0.928})
Step:  193900, Reward: [-1902.164 -1902.164 -1902.164] [198.935], Avg: [-813.773 -813.773 -813.773] (0.9276) ({r_i: None, r_t: [-3476.957 -3476.957 -3476.957], eps: 0.928})
Step:  194000, Reward: [-1772.318 -1772.318 -1772.318] [265.655], Avg: [-814.267 -814.267 -814.267] (0.9276) ({r_i: None, r_t: [-3608.361 -3608.361 -3608.361], eps: 0.928})
Step:  194100, Reward: [-1931.825 -1931.825 -1931.825] [246.217], Avg: [-814.842 -814.842 -814.842] (0.9276) ({r_i: None, r_t: [-3791.358 -3791.358 -3791.358], eps: 0.928})
Step:  194200, Reward: [-1760.855 -1760.855 -1760.855] [226.277], Avg: [-815.329 -815.329 -815.329] (0.9276) ({r_i: None, r_t: [-3616.582 -3616.582 -3616.582], eps: 0.928})
Step:  194300, Reward: [-1795.285 -1795.285 -1795.285] [264.928], Avg: [-815.833 -815.833 -815.833] (0.9276) ({r_i: None, r_t: [-3585.956 -3585.956 -3585.956], eps: 0.928})
Step:  194400, Reward: [-1917.037 -1917.037 -1917.037] [172.992], Avg: [-816.400 -816.400 -816.400] (0.9276) ({r_i: None, r_t: [-3792.316 -3792.316 -3792.316], eps: 0.928})
Step:  194500, Reward: [-1762.029 -1762.029 -1762.029] [313.471], Avg: [-816.886 -816.886 -816.886] (0.9276) ({r_i: None, r_t: [-3815.545 -3815.545 -3815.545], eps: 0.928})
Step:  194600, Reward: [-1788.223 -1788.223 -1788.223] [200.892], Avg: [-817.384 -817.384 -817.384] (0.9276) ({r_i: None, r_t: [-3831.637 -3831.637 -3831.637], eps: 0.928})
Step:  194700, Reward: [-1828.289 -1828.289 -1828.289] [248.647], Avg: [-817.903 -817.903 -817.903] (0.9276) ({r_i: None, r_t: [-3729.081 -3729.081 -3729.081], eps: 0.928})
Step:  194800, Reward: [-1796.025 -1796.025 -1796.025] [193.582], Avg: [-818.405 -818.405 -818.405] (0.9276) ({r_i: None, r_t: [-3531.035 -3531.035 -3531.035], eps: 0.928})
Step:  194900, Reward: [-1837.604 -1837.604 -1837.604] [304.979], Avg: [-818.928 -818.928 -818.928] (0.9276) ({r_i: None, r_t: [-3643.209 -3643.209 -3643.209], eps: 0.928})
Step:  195000, Reward: [-1890.089 -1890.089 -1890.089] [208.265], Avg: [-819.477 -819.477 -819.477] (0.9276) ({r_i: None, r_t: [-3681.212 -3681.212 -3681.212], eps: 0.928})
Step:  195100, Reward: [-1817.172 -1817.172 -1817.172] [251.860], Avg: [-819.988 -819.988 -819.988] (0.9229) ({r_i: None, r_t: [-3569.173 -3569.173 -3569.173], eps: 0.923})
Step:  195200, Reward: [-1810.581 -1810.581 -1810.581] [315.379], Avg: [-820.495 -820.495 -820.495] (0.9229) ({r_i: None, r_t: [-3506.113 -3506.113 -3506.113], eps: 0.923})
Step:  195300, Reward: [-1764.494 -1764.494 -1764.494] [306.407], Avg: [-820.978 -820.978 -820.978] (0.9229) ({r_i: None, r_t: [-3585.402 -3585.402 -3585.402], eps: 0.923})
Step:  195400, Reward: [-1881.347 -1881.347 -1881.347] [207.777], Avg: [-821.521 -821.521 -821.521] (0.9229) ({r_i: None, r_t: [-3707.291 -3707.291 -3707.291], eps: 0.923})
Step:  195500, Reward: [-1807.127 -1807.127 -1807.127] [270.055], Avg: [-822.025 -822.025 -822.025] (0.9229) ({r_i: None, r_t: [-3472.239 -3472.239 -3472.239], eps: 0.923})
Step:  195600, Reward: [-1902.235 -1902.235 -1902.235] [225.445], Avg: [-822.577 -822.577 -822.577] (0.9229) ({r_i: None, r_t: [-3496.090 -3496.090 -3496.090], eps: 0.923})
Step:  195700, Reward: [-1708.584 -1708.584 -1708.584] [241.056], Avg: [-823.029 -823.029 -823.029] (0.9229) ({r_i: None, r_t: [-3683.009 -3683.009 -3683.009], eps: 0.923})
Step:  195800, Reward: [-1770.239 -1770.239 -1770.239] [290.678], Avg: [-823.513 -823.513 -823.513] (0.9229) ({r_i: None, r_t: [-3384.500 -3384.500 -3384.500], eps: 0.923})
Step:  195900, Reward: [-1809.507 -1809.507 -1809.507] [166.128], Avg: [-824.016 -824.016 -824.016] (0.9229) ({r_i: None, r_t: [-3499.870 -3499.870 -3499.870], eps: 0.923})
Step:  196000, Reward: [-1611.285 -1611.285 -1611.285] [284.887], Avg: [-824.417 -824.417 -824.417] (0.9229) ({r_i: None, r_t: [-3693.972 -3693.972 -3693.972], eps: 0.923})
Step:  196100, Reward: [-1849.339 -1849.339 -1849.339] [220.912], Avg: [-824.940 -824.940 -824.940] (0.9229) ({r_i: None, r_t: [-3392.770 -3392.770 -3392.770], eps: 0.923})
Step:  196200, Reward: [-1730.002 -1730.002 -1730.002] [261.603], Avg: [-825.401 -825.401 -825.401] (0.9229) ({r_i: None, r_t: [-3426.452 -3426.452 -3426.452], eps: 0.923})
Step:  196300, Reward: [-1641.588 -1641.588 -1641.588] [396.246], Avg: [-825.816 -825.816 -825.816] (0.9229) ({r_i: None, r_t: [-3523.721 -3523.721 -3523.721], eps: 0.923})
Step:  196400, Reward: [-1762.798 -1762.798 -1762.798] [188.370], Avg: [-826.293 -826.293 -826.293] (0.9229) ({r_i: None, r_t: [-3426.950 -3426.950 -3426.950], eps: 0.923})
Step:  196500, Reward: [-1842.485 -1842.485 -1842.485] [256.481], Avg: [-826.810 -826.810 -826.810] (0.9229) ({r_i: None, r_t: [-3453.994 -3453.994 -3453.994], eps: 0.923})
Step:  196600, Reward: [-1659.128 -1659.128 -1659.128] [290.770], Avg: [-827.233 -827.233 -827.233] (0.9229) ({r_i: None, r_t: [-3314.446 -3314.446 -3314.446], eps: 0.923})
Step:  196700, Reward: [-1672.760 -1672.760 -1672.760] [202.258], Avg: [-827.663 -827.663 -827.663] (0.9229) ({r_i: None, r_t: [-3622.338 -3622.338 -3622.338], eps: 0.923})
Step:  196800, Reward: [-1706.313 -1706.313 -1706.313] [288.551], Avg: [-828.109 -828.109 -828.109] (0.9229) ({r_i: None, r_t: [-3332.434 -3332.434 -3332.434], eps: 0.923})
Step:  196900, Reward: [-1687.004 -1687.004 -1687.004] [360.239], Avg: [-828.545 -828.545 -828.545] (0.9229) ({r_i: None, r_t: [-3489.626 -3489.626 -3489.626], eps: 0.923})
Step:  197000, Reward: [-1861.201 -1861.201 -1861.201] [200.233], Avg: [-829.069 -829.069 -829.069] (0.9229) ({r_i: None, r_t: [-3240.784 -3240.784 -3240.784], eps: 0.923})
Step:  197100, Reward: [-1549.570 -1549.570 -1549.570] [272.838], Avg: [-829.434 -829.434 -829.434] (0.9229) ({r_i: None, r_t: [-3213.253 -3213.253 -3213.253], eps: 0.923})
Step:  197200, Reward: [-1719.572 -1719.572 -1719.572] [217.542], Avg: [-829.885 -829.885 -829.885] (0.9229) ({r_i: None, r_t: [-3330.345 -3330.345 -3330.345], eps: 0.923})
Step:  197300, Reward: [-1717.744 -1717.744 -1717.744] [291.237], Avg: [-830.335 -830.335 -830.335] (0.9229) ({r_i: None, r_t: [-3371.618 -3371.618 -3371.618], eps: 0.923})
Step:  197400, Reward: [-1695.293 -1695.293 -1695.293] [366.031], Avg: [-830.773 -830.773 -830.773] (0.9229) ({r_i: None, r_t: [-3341.403 -3341.403 -3341.403], eps: 0.923})
Step:  197500, Reward: [-1616.084 -1616.084 -1616.084] [413.568], Avg: [-831.171 -831.171 -831.171] (0.9229) ({r_i: None, r_t: [-3279.210 -3279.210 -3279.210], eps: 0.923})
Step:  197600, Reward: [-1715.933 -1715.933 -1715.933] [259.301], Avg: [-831.618 -831.618 -831.618] (0.9229) ({r_i: None, r_t: [-3475.322 -3475.322 -3475.322], eps: 0.923})
Step:  197700, Reward: [-1673.633 -1673.633 -1673.633] [350.141], Avg: [-832.044 -832.044 -832.044] (0.9229) ({r_i: None, r_t: [-3168.899 -3168.899 -3168.899], eps: 0.923})
Step:  197800, Reward: [-1717.445 -1717.445 -1717.445] [241.431], Avg: [-832.491 -832.491 -832.491] (0.9229) ({r_i: None, r_t: [-3246.391 -3246.391 -3246.391], eps: 0.923})
Step:  197900, Reward: [-1722.630 -1722.630 -1722.630] [330.193], Avg: [-832.941 -832.941 -832.941] (0.9229) ({r_i: None, r_t: [-3287.813 -3287.813 -3287.813], eps: 0.923})
Step:  198000, Reward: [-1654.774 -1654.774 -1654.774] [303.538], Avg: [-833.356 -833.356 -833.356] (0.9229) ({r_i: None, r_t: [-3151.915 -3151.915 -3151.915], eps: 0.923})
Step:  198100, Reward: [-1690.714 -1690.714 -1690.714] [307.633], Avg: [-833.788 -833.788 -833.788] (0.9229) ({r_i: None, r_t: [-3412.847 -3412.847 -3412.847], eps: 0.923})
Step:  198200, Reward: [-1562.527 -1562.527 -1562.527] [385.234], Avg: [-834.156 -834.156 -834.156] (0.9229) ({r_i: None, r_t: [-3309.525 -3309.525 -3309.525], eps: 0.923})
Step:  198300, Reward: [-1708.858 -1708.858 -1708.858] [283.581], Avg: [-834.597 -834.597 -834.597] (0.9229) ({r_i: None, r_t: [-3324.781 -3324.781 -3324.781], eps: 0.923})
Step:  198400, Reward: [-1646.170 -1646.170 -1646.170] [284.060], Avg: [-835.005 -835.005 -835.005] (0.9229) ({r_i: None, r_t: [-3073.416 -3073.416 -3073.416], eps: 0.923})
Step:  198500, Reward: [-1553.011 -1553.011 -1553.011] [382.155], Avg: [-835.367 -835.367 -835.367] (0.9229) ({r_i: None, r_t: [-3287.009 -3287.009 -3287.009], eps: 0.923})
Step:  198600, Reward: [-1593.683 -1593.683 -1593.683] [410.434], Avg: [-835.749 -835.749 -835.749] (0.9229) ({r_i: None, r_t: [-3082.272 -3082.272 -3082.272], eps: 0.923})
Step:  198700, Reward: [-1721.443 -1721.443 -1721.443] [333.754], Avg: [-836.194 -836.194 -836.194] (0.9229) ({r_i: None, r_t: [-2957.483 -2957.483 -2957.483], eps: 0.923})
Step:  198800, Reward: [-1459.241 -1459.241 -1459.241] [413.336], Avg: [-836.507 -836.507 -836.507] (0.9229) ({r_i: None, r_t: [-3160.346 -3160.346 -3160.346], eps: 0.923})
Step:  198900, Reward: [-1541.985 -1541.985 -1541.985] [331.918], Avg: [-836.862 -836.862 -836.862] (0.9229) ({r_i: None, r_t: [-3009.310 -3009.310 -3009.310], eps: 0.923})
Step:  199000, Reward: [-1513.868 -1513.868 -1513.868] [497.883], Avg: [-837.202 -837.202 -837.202] (0.9229) ({r_i: None, r_t: [-3183.803 -3183.803 -3183.803], eps: 0.923})
Step:  199100, Reward: [-1634.729 -1634.729 -1634.729] [261.301], Avg: [-837.602 -837.602 -837.602] (0.9229) ({r_i: None, r_t: [-3194.551 -3194.551 -3194.551], eps: 0.923})
Step:  199200, Reward: [-1672.955 -1672.955 -1672.955] [285.438], Avg: [-838.021 -838.021 -838.021] (0.9229) ({r_i: None, r_t: [-2963.052 -2963.052 -2963.052], eps: 0.923})
Step:  199300, Reward: [-1706.495 -1706.495 -1706.495] [293.139], Avg: [-838.457 -838.457 -838.457] (0.9229) ({r_i: None, r_t: [-2716.136 -2716.136 -2716.136], eps: 0.923})
Step:  199400, Reward: [-1500.032 -1500.032 -1500.032] [353.064], Avg: [-838.789 -838.789 -838.789] (0.9229) ({r_i: None, r_t: [-3051.242 -3051.242 -3051.242], eps: 0.923})
Step:  199500, Reward: [-1420.278 -1420.278 -1420.278] [365.010], Avg: [-839.080 -839.080 -839.080] (0.9229) ({r_i: None, r_t: [-3198.091 -3198.091 -3198.091], eps: 0.923})
Step:  199600, Reward: [-1425.182 -1425.182 -1425.182] [405.638], Avg: [-839.373 -839.373 -839.373] (0.9229) ({r_i: None, r_t: [-3024.912 -3024.912 -3024.912], eps: 0.923})
Step:  199700, Reward: [-1411.638 -1411.638 -1411.638] [421.323], Avg: [-839.660 -839.660 -839.660] (0.9229) ({r_i: None, r_t: [-2917.361 -2917.361 -2917.361], eps: 0.923})
Step:  199800, Reward: [-1449.873 -1449.873 -1449.873] [389.599], Avg: [-839.965 -839.965 -839.965] (0.9229) ({r_i: None, r_t: [-2673.190 -2673.190 -2673.190], eps: 0.923})
Step:  199900, Reward: [-1449.345 -1449.345 -1449.345] [392.298], Avg: [-840.270 -840.270 -840.270] (0.9229) ({r_i: None, r_t: [-2584.013 -2584.013 -2584.013], eps: 0.923})
Step:  200000, Reward: [-1255.478 -1255.478 -1255.478] [481.751], Avg: [-840.477 -840.477 -840.477] (0.9229) ({r_i: None, r_t: [-3037.724 -3037.724 -3037.724], eps: 0.923})
