Model: <class 'multiagent.coma.COMAAgent'>, Dir: simple_spread
num_envs: 16,
state_size: [(1, 18), (1, 18), (1, 18)],
action_size: [[1, 5], [1, 5], [1, 5]],
action_space: [MultiDiscrete([5]), MultiDiscrete([5]), MultiDiscrete([5])],
envs: <class 'utils.envs.EnsembleEnv'>,
reward_shape: False,
icm: False,

import copy
import torch
import numpy as np
from models.rand import MultiagentReplayBuffer3
from utils.network import PTNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, one_hot_from_indices

LEARNING_RATE = 0.0003
LAMBDA = 0.95
DISCOUNT_RATE = 0.99
GRAD_NORM = 1
TARGET_UPDATE = 200

HIDDEN_SIZE = 64
EPS_MAX = 0.5
EPS_MIN = 0.01
EPS_DECAY = 0.995
NUM_ENVS = 16
EPISODE_LIMIT = 50
ENTROPY_WEIGHT = 0.001			# The weight for the entropy term of the Actor loss
MAX_BUFFER_SIZE = 192000		# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 16

class PTCNetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE, gpu=True, load="", name="ptac"): 
		super().__init__(tau, gpu, name)

	def save_model(self, net="qlearning", dirname="pytorch", name="checkpoint"):
		pass
		
	def load_model(self, net="qlearning", dirname="pytorch", name="checkpoint"):
		pass

class COMAAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, PTCNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.n_agents = len(action_size)
		n_actions = action_size[0][-1]
		n_obs = state_size[0][-1]
		state_len = int(np.sum([np.prod(space) for space in state_size]))
		preprocess = {"actions": ("actions_onehot", [OneHot(out_dim=n_actions)])}
		groups = {"agents": self.n_agents}
		scheme = {
			"state": {"vshape": state_len},
			"obs": {"vshape": n_obs, "group": "agents"},
			"actions": {"vshape": (1,), "group": "agents", "dtype": torch.long},
			"reward": {"vshape": (1,)},
			"done": {"vshape": (1,), "dtype": torch.uint8},
		}
		
		self.device = torch.device('cuda' if gpu and torch.cuda.is_available() else 'cpu')
		self.replay_buffer = ReplayBuffer(scheme, groups, 2000, EPISODE_LIMIT+1, preprocess=preprocess, device=self.device)
		self.mac = BasicMAC(self.replay_buffer.scheme, groups, self.n_agents, n_actions, device=self.device)
		self.learner = COMALearner(self.mac, self.replay_buffer.scheme, self.n_agents, n_actions, device=self.device)
		self.new_episode_batch = lambda batch_size: EpisodeBatch(scheme, groups, batch_size, EPISODE_LIMIT+1, preprocess=preprocess, device=self.device)
		self.episode_batch = self.new_episode_batch(NUM_ENVS)
		self.mac.init_hidden(batch_size=NUM_ENVS)
		self.num_envs = NUM_ENVS
		self.time = 0
		self.replay_buffer2 = MultiagentReplayBuffer3(EPISODE_LIMIT*REPLAY_BATCH_SIZE, state_size, action_size)
		self.buffer = []

	def get_action(self, state, eps=None, sample=True, numpy=True):
		self.num_envs = state[0].shape[0] if len(state[0].shape) > len(self.state_size[0]) else 1
		if np.prod(self.mac.hidden_states.shape[:-1]) != self.num_envs*len(self.action_size): self.mac.init_hidden(batch_size=self.num_envs)
		if self.episode_batch.batch_size != self.num_envs: self.episode_batch = self.new_episode_batch(self.num_envs)
		self.step = 0 if not hasattr(self, "step") else (self.step + 1)%self.replay_buffer.max_seq_length
		state_joint = np.concatenate(state, -1)
		obs = np.concatenate(state, -2)
		agent_ids = np.repeat(np.expand_dims(np.eye(self.learner.n_agents), 0), repeats=self.num_envs, axis=0)
		if not hasattr(self, "action"): self.action = np.zeros([*obs.shape[:-1], self.action_size[0][-1]])
		inputs = torch.from_numpy(np.concatenate([obs, self.action, agent_ids], -1))
		self.episode_batch.update({"state": [state_joint], "obs": [obs]}, ts=self.step)
		actions = self.mac.select_actions(self.episode_batch, inputs, t_ep=self.step, t_env=self.time, test_mode=False)
		self.action = one_hot_from_indices(actions, self.action_size[0][-1]).cpu().numpy()
		actions = actions.view([*state[0].shape[:-len(self.state_size[0])], actions.shape[-1]])
		return np.split(self.action, actions.size(-1), axis=-2)

	def train(self, state, action, next_state, reward, done):
		actions, rewards, dones = [list(zip(*x)) for x in [action, reward, done]]
		actions_one_hot = [np.argmax(a, -1) for a in actions]
		rewards = [np.mean(rewards, -1)]
		dones = [np.any(dones, -1)]
		obs = np.concatenate(state, -2)
		next_obs = np.concatenate(next_state, -2)
		agent_ids = np.repeat(np.expand_dims(np.eye(self.learner.n_agents), 0), repeats=self.num_envs, axis=0)
		actor_inputs = torch.from_numpy(np.concatenate([obs, self.action, agent_ids], -1))
		post_transition_data = {"actions": actions_one_hot, "reward": rewards, "done": dones}
		self.episode_batch.update(post_transition_data, ts=self.step)
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]):
			states_, actions_, rewards_, dones_ = map(lambda x: [np.stack(t, axis=1) for t in list(zip(*x))], zip(*self.buffer))
			self.replay_buffer2.add((states_, actions_, rewards_, dones_))
			self.buffer.clear()



			state_joint = np.concatenate(state, -1)
			self.episode_batch.update({"state": [state_joint], "obs": [next_obs]}, ts=self.step)
			actions = self.mac.select_actions(self.episode_batch, actor_inputs, t_ep=self.step, t_env=self.time, test_mode=False)
			self.episode_batch.update({"actions": actions}, ts=self.step)
			self.replay_buffer.insert_episode_batch(self.episode_batch)
			if self.replay_buffer.can_sample(REPLAY_BATCH_SIZE):
				episode_sample = self.replay_buffer.sample(REPLAY_BATCH_SIZE)
				sample = self.replay_buffer2.sample(REPLAY_BATCH_SIZE, lambda x: torch.Tensor(x).to(self.network.device))
				
				states_, actions_, rewards_, dones_ = map(lambda x:torch.stack(x,2), sample)
				state = states_.repeat(1, 1, 1, self.n_agents, 1).view(*states_.shape[:3],-1)
				obs = states_.squeeze(-2)
				actions_ = actions_.squeeze(-2)
				actions_joint = actions_.view(*actions_.shape[:2], 1, -1).repeat(1, 1, self.n_agents, 1)
				agent_mask = (1 - torch.eye(self.n_agents, device=self.network.device))
				agent_mask = agent_mask.view(-1, 1).repeat(1, self.action_size[0][-1]).view(self.n_agents, -1).unsqueeze(0).unsqueeze(0)
				action_masked = actions_joint * agent_mask
				last_actions = torch.cat([torch.zeros_like(actions_[:, 0:1]), actions_[:, :-1]], dim=1)
				last_actions_joint = last_actions.view(*last_actions.shape[:2], 1, -1).repeat(1, 1, self.n_agents, 1)
				agent_inds = torch.eye(self.n_agents, device=self.network.device).unsqueeze(0).unsqueeze(0).expand(*obs.shape[:2], -1, -1)

				critic_inputs = torch.cat([state, obs, action_masked, last_actions_joint, agent_inds], dim=-1)
				actor_inputs = torch.cat([obs, last_actions, agent_inds], dim=-1)

				self.learner.train(episode_sample, actions_, critic_inputs, actor_inputs, rewards_.mean(-1, keepdims=True), dones_.mean(-1, keepdims=True))
			self.episode_batch = self.new_episode_batch(state[0].shape[0])
			self.mac.init_hidden(self.num_envs)
			self.time += self.step
			self.step = 0

class OneHot():
	def __init__(self, out_dim):
		self.out_dim = out_dim

	def transform(self, tensor):
		y_onehot = tensor.new(*tensor.shape[:-1], self.out_dim).zero_()
		y_onehot.scatter_(-1, tensor.long(), 1)
		return y_onehot.float()

	def infer_output_info(self, vshape_in, dtype_in):
		return (self.out_dim,), torch.float32

class COMALearner():
	def __init__(self, mac, scheme, n_agents, n_actions, device):
		self.device = device
		self.n_agents = n_agents
		self.n_actions = n_actions
		self.last_target_update_step = 0
		self.mac = mac
		self.critic_training_steps = 0
		self.critic = COMACritic(scheme, self.n_agents, self.n_actions).to(self.device)
		self.critic_params = list(self.critic.parameters())
		self.agent_params = list(mac.parameters())
		self.params = self.agent_params + self.critic_params
		self.target_critic = copy.deepcopy(self.critic)
		self.agent_optimiser = torch.optim.Adam(params=self.agent_params, lr=LEARNING_RATE)
		self.critic_optimiser = torch.optim.Adam(params=self.critic_params, lr=LEARNING_RATE)

	def train(self, batch, actions_, critic_inputs, actor_inputs, rewards_, dones_):
		bs = batch.batch_size
		max_t = batch.max_seq_length
		rewards = batch["reward"][:, :-1]
		actions = batch["actions"][:, :]
		done = batch["done"][:, :-1].float()
		q_vals = self._train_critic(batch, rewards, done, actions, bs, max_t, (actions_, critic_inputs, actor_inputs, rewards_, dones_))
		actions = actions[:,:-1]
		# mac_out = torch.stack([self.mac.forward(batch, actor_inputs[:,t], t) for t in range(actions.shape[1])], dim=1)
		mac_out = torch.stack([self.mac.forward(batch, actor_inputs[:,t], t) for t in range(actor_inputs.shape[1])], dim=1)
		q_vals = q_vals.reshape(-1, self.n_actions)
		pi = mac_out.view(-1, self.n_actions)
		baseline = (pi * q_vals).sum(-1).detach()
		q_taken = torch.gather(q_vals, dim=1, index=actions_.argmax(-1).reshape(-1, 1)).squeeze(1)
		# q_taken = torch.gather(q_vals, dim=1, index=actions.reshape(-1, 1)).squeeze(1)
		pi_taken = torch.gather(pi, dim=1, index=actions_.argmax(-1).reshape(-1, 1)).squeeze(1)
		# pi_taken = torch.gather(pi, dim=1, index=actions.reshape(-1, 1)).squeeze(1)
		log_pi_taken = torch.log(pi_taken)
		advantages = (q_taken - baseline).detach()
		coma_loss = - (advantages * log_pi_taken).sum()
		self.agent_optimiser.zero_grad()
		coma_loss.backward()
		torch.nn.utils.clip_grad_norm_(self.agent_params, GRAD_NORM)
		self.agent_optimiser.step()
		if (self.critic_training_steps - self.last_target_update_step) / TARGET_UPDATE >= 1.0:
			self._update_targets()
			self.last_target_update_step = self.critic_training_steps

	def _train_critic(self, batch, rewards, done, actions, bs, max_t, sample):
		actions_, critic_inputs, actor_inputs, rewards_, dones_ = sample
		target_q_vals = self.target_critic(batch, critic_inputs)[:, :]
		targets_taken = torch.gather(target_q_vals, dim=3, index=actions_.argmax(-1, keepdims=True)).squeeze(-1)
		targets_taken = torch.cat([targets_taken, torch.zeros_like(targets_taken[:,-1]).unsqueeze(1)], dim=1)
		# targets_taken = torch.gather(target_q_vals, dim=3, index=actions).squeeze(3)
		targets = build_td_lambda_targets(rewards_, dones_, targets_taken, self.n_agents)
		# targets = build_td_lambda_targets(rewards, done, targets_taken, self.n_agents)
		q_vals = torch.zeros_like(target_q_vals)
		for t in reversed(range(rewards.size(1))):
			q_t = self.critic(batch, critic_inputs[:,t], t)
			q_vals[:, t] = q_t.view(bs, self.n_agents, self.n_actions)
			q_taken = torch.gather(q_t, dim=-1, index=actions_[:, t].argmax(-1, keepdims=True)).squeeze(-1)
			# q_taken = torch.gather(q_t, dim=3, index=actions[:, t:t+1]).squeeze(3).squeeze(1)
			targets_t = targets[:, t]
			td_error = (q_taken - targets_t.detach())
			loss = (td_error ** 2).sum()
			self.critic_optimiser.zero_grad()
			loss.backward()
			torch.nn.utils.clip_grad_norm_(self.critic_params, GRAD_NORM)
			self.critic_optimiser.step()
			self.critic_training_steps += 1
		return q_vals

	def _update_targets(self):
		self.target_critic.load_state_dict(self.critic.state_dict())

	def cuda(self):
		self.mac.cuda()
		self.critic.cuda()
		self.target_critic.cuda()

def build_td_lambda_targets(rewards, done, target_qs, n_agents, gamma=DISCOUNT_RATE, td_lambda=LAMBDA):
	ret = target_qs.new_zeros(*target_qs.shape)
	ret[:, -1] = target_qs[:, -1] * (1 - torch.sum(done, dim=1))
	for t in range(ret.shape[1] - 2, -1,  -1):
		ret[:, t] = td_lambda * gamma * ret[:, t + 1] + (rewards[:, t] + (1 - td_lambda) * gamma * target_qs[:, t + 1] * (1 - done[:, t]))
	return ret[:, 0:-1]

class COMACritic(torch.nn.Module):
	def __init__(self, scheme, n_agents, n_actions):
		super(COMACritic, self).__init__()
		self.n_actions = n_actions
		self.n_agents = n_agents
		input_shape = self._get_input_shape(scheme)
		self.output_type = "q"
		self.fc1 = torch.nn.Linear(input_shape, HIDDEN_SIZE)
		self.fc2 = torch.nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)
		self.fc3 = torch.nn.Linear(HIDDEN_SIZE, self.n_actions)

	def forward(self, batch, critic_inputs, t=None):
		inputs = self._build_inputs(batch, t=t)
		# x = torch.relu(self.fc1(inputs))
		x = torch.relu(self.fc1(critic_inputs))
		x = torch.relu(self.fc2(x))
		q = self.fc3(x)
		return q

	def _build_inputs(self, batch, t=None):
		bs = batch.batch_size
		max_t = batch.max_seq_length if t is None else 1
		ts = slice(None) if t is None else slice(t, t+1)
		inputs = []
		inputs.append(batch["state"][:, ts].unsqueeze(2).repeat(1, 1, self.n_agents, 1))
		inputs.append(batch["obs"][:, ts])
		actions = batch["actions_onehot"][:, ts].view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1)
		agent_mask = (1 - torch.eye(self.n_agents, device=batch.device))
		agent_mask = agent_mask.view(-1, 1).repeat(1, self.n_actions).view(self.n_agents, -1)
		inputs.append(actions * agent_mask.unsqueeze(0).unsqueeze(0))
		# last actions
		if t == 0:
			inputs.append(torch.zeros_like(batch["actions_onehot"][:, 0:1]).view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1))
		elif isinstance(t, int):
			inputs.append(batch["actions_onehot"][:, slice(t-1, t)].view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1))
		else:
			last_actions = torch.cat([torch.zeros_like(batch["actions_onehot"][:, 0:1]), batch["actions_onehot"][:, :-1]], dim=1)
			last_actions = last_actions.view(bs, max_t, 1, -1).repeat(1, 1, self.n_agents, 1)
			inputs.append(last_actions)

		inputs.append(torch.eye(self.n_agents, device=batch.device).unsqueeze(0).unsqueeze(0).expand(bs, max_t, -1, -1))
		inputs = torch.cat([x.reshape(bs, max_t, self.n_agents, -1) for x in inputs], dim=-1)
		return inputs

	def _get_input_shape(self, scheme):
		input_shape = scheme["state"]["vshape"]
		input_shape += scheme["obs"]["vshape"]
		input_shape += scheme["actions_onehot"]["vshape"][0] * self.n_agents * 2
		input_shape += self.n_agents
		return input_shape

class BasicMAC:
	def __init__(self, scheme, groups, n_agents, n_actions, device):
		self.device = device
		self.n_agents = n_agents
		self.n_actions = n_actions
		self.agent = RNNAgent(self._get_input_shape(scheme), self.n_actions).to(self.device)
		self.action_selector = MultinomialActionSelector()
		self.hidden_states = None

	def select_actions(self, ep_batch, inputs, t_ep, t_env, bs=slice(None), test_mode=False):
		agent_outputs = self.forward(ep_batch, inputs, t_ep, test_mode=test_mode)
		chosen_actions = self.action_selector.select_action(agent_outputs[bs], t_env, test_mode=test_mode)
		return chosen_actions

	def forward(self, ep_batch, inputs, t, test_mode=False):
		agent_inputs = self._build_inputs(ep_batch, t)
		agent_outs = self.agent(agent_inputs, self.hidden_states)
		agent_outs = torch.nn.functional.softmax(agent_outs, dim=-1)
		if not test_mode:
			epsilon_action_num = agent_outs.size(-1)
			agent_outs = ((1 - self.action_selector.epsilon) * agent_outs + torch.ones_like(agent_outs).to(self.device) * self.action_selector.epsilon/epsilon_action_num)
		return agent_outs.view(ep_batch.batch_size, self.n_agents, -1)

	def init_hidden(self, batch_size):
		self.hidden_states = self.agent.init_hidden().unsqueeze(0).expand(batch_size, self.n_agents, -1)  # bav

	def parameters(self):
		return self.agent.parameters()

	def _build_inputs(self, batch, t):
		bs = batch.batch_size
		inputs = []
		inputs.append(batch["obs"][:, t])  # b1av
		inputs.append(torch.zeros_like(batch["actions_onehot"][:, t]) if t==0 else batch["actions_onehot"][:, t-1])
		inputs.append(torch.eye(self.n_agents, device=batch.device).unsqueeze(0).expand(bs, -1, -1))
		inputs = torch.cat([x.reshape(bs, self.n_agents, -1) for x in inputs], dim=-1)
		return inputs

	def _get_input_shape(self, scheme):
		input_shape = scheme["obs"]["vshape"]
		input_shape += scheme["actions_onehot"]["vshape"][0]
		input_shape += self.n_agents
		return input_shape

class RNNAgent(torch.nn.Module):
	def __init__(self, input_shape, output_shape):
		super(RNNAgent, self).__init__()
		self.fc1 = torch.nn.Linear(input_shape, HIDDEN_SIZE)
		self.fc3 = torch.nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)
		self.fc2 = torch.nn.Linear(HIDDEN_SIZE, output_shape)

	def init_hidden(self):
		return self.fc1.weight.new(1, HIDDEN_SIZE).zero_()

	def forward(self, inputs, hidden_state):
		x = torch.relu(self.fc1(inputs))
		x = self.fc3(x).relu()
		q = self.fc2(x)
		return q

class MultinomialActionSelector():
	def __init__(self, eps_start=EPS_MAX, eps_finish=EPS_MIN, eps_decay=EPS_DECAY):
		self.schedule = DecayThenFlatSchedule(eps_start, eps_finish, EPISODE_LIMIT/(1-eps_decay), decay="linear")
		self.epsilon = self.schedule.eval(0)

	def select_action(self, agent_inputs, t_env, test_mode=False):
		self.epsilon = self.schedule.eval(t_env)
		masked_policies = agent_inputs.clone()
		picked_actions = masked_policies.max(dim=2)[1] if test_mode else torch.distributions.Categorical(masked_policies).sample().long()
		return picked_actions

class DecayThenFlatSchedule():
	def __init__(self, start, finish, time_length, decay="exp"):
		self.start = start
		self.finish = finish
		self.time_length = time_length
		self.delta = (self.start - self.finish) / self.time_length
		self.decay = decay
		if self.decay in ["exp"]:
			self.exp_scaling = (-1) * self.time_length / np.log(self.finish) if self.finish > 0 else 1

	def eval(self, T):
		if self.decay in ["linear"]:
			return max(self.finish, self.start - self.delta * T)
		elif self.decay in ["exp"]:
			return min(self.start, max(self.finish, np.exp(- T / self.exp_scaling)))

from types import SimpleNamespace as SN

class EpisodeBatch():
	def __init__(self, scheme, groups, batch_size, max_seq_length, data=None, preprocess=None, device="cpu"):
		self.scheme = scheme.copy()
		self.groups = groups
		self.batch_size = batch_size
		self.max_seq_length = max_seq_length
		self.preprocess = {} if preprocess is None else preprocess
		self.device = device

		if data is not None:
			self.data = data
		else:
			self.data = SN()
			self.data.transition_data = {}
			self.data.episode_data = {}
			self._setup_data(self.scheme, self.groups, batch_size, max_seq_length, self.preprocess)

	def _setup_data(self, scheme, groups, batch_size, max_seq_length, preprocess):
		if preprocess is not None:
			for k in preprocess:
				assert k in scheme
				new_k = preprocess[k][0]
				transforms = preprocess[k][1]
				vshape = self.scheme[k]["vshape"]
				dtype = self.scheme[k]["dtype"]
				for transform in transforms:
					vshape, dtype = transform.infer_output_info(vshape, dtype)
				self.scheme[new_k] = {"vshape": vshape, "dtype": dtype}
				if "group" in self.scheme[k]:
					self.scheme[new_k]["group"] = self.scheme[k]["group"]
				if "episode_const" in self.scheme[k]:
					self.scheme[new_k]["episode_const"] = self.scheme[k]["episode_const"]

		assert "filled" not in scheme, '"filled" is a reserved key for masking.'
		scheme.update({"filled": {"vshape": (1,), "dtype": torch.long},})

		for field_key, field_info in scheme.items():
			assert "vshape" in field_info, "Scheme must define vshape for {}".format(field_key)
			vshape = field_info["vshape"]
			episode_const = field_info.get("episode_const", False)
			group = field_info.get("group", None)
			dtype = field_info.get("dtype", torch.float32)

			if isinstance(vshape, int):
				vshape = (vshape,)
			if group:
				assert group in groups, "Group {} must have its number of members defined in _groups_".format(group)
				shape = (groups[group], *vshape)
			else:
				shape = vshape
			if episode_const:
				self.data.episode_data[field_key] = torch.zeros((batch_size, *shape), dtype=dtype).to(self.device)
			else:
				self.data.transition_data[field_key] = torch.zeros((batch_size, max_seq_length, *shape), dtype=dtype).to(self.device)

	def extend(self, scheme, groups=None):
		self._setup_data(scheme, self.groups if groups is None else groups, self.batch_size, self.max_seq_length)

	def to(self, device):
		for k, v in self.data.transition_data.items():
			self.data.transition_data[k] = v.to(device)
		for k, v in self.data.episode_data.items():
			self.data.episode_data[k] = v.to(device)
		self.device = device

	def update(self, data, bs=slice(None), ts=slice(None), mark_filled=True):
		slices = self._parse_slices((bs, ts))
		for k, v in data.items():
			if k in self.data.transition_data:
				target = self.data.transition_data
				if mark_filled:
					target["filled"][slices] = 1
					mark_filled = False
				_slices = slices
			elif k in self.data.episode_data:
				target = self.data.episode_data
				_slices = slices[0]
			else:
				raise KeyError("{} not found in transition or episode data".format(k))

			dtype = self.scheme[k].get("dtype", torch.float32)
			v = v if isinstance(v, torch.Tensor) else torch.tensor(v, dtype=dtype, device=self.device)
			self._check_safe_view(v, target[k][_slices])
			target[k][_slices] = v.view_as(target[k][_slices])

			if k in self.preprocess:
				new_k = self.preprocess[k][0]
				v = target[k][_slices]
				for transform in self.preprocess[k][1]:
					v = transform.transform(v)
				target[new_k][_slices] = v.view_as(target[new_k][_slices])

	def _check_safe_view(self, v, dest):
		idx = len(v.shape) - 1
		for s in dest.shape[::-1]:
			if v.shape[idx] != s:
				if s != 1:
					raise ValueError("Unsafe reshape of {} to {}".format(v.shape, dest.shape))
			else:
				idx -= 1

	def __getitem__(self, item):
		if isinstance(item, str):
			if item in self.data.episode_data:
				return self.data.episode_data[item]
			elif item in self.data.transition_data:
				return self.data.transition_data[item]
			else:
				raise ValueError
		elif isinstance(item, tuple) and all([isinstance(it, str) for it in item]):
			new_data = self._new_data_sn()
			for key in item:
				if key in self.data.transition_data:
					new_data.transition_data[key] = self.data.transition_data[key]
				elif key in self.data.episode_data:
					new_data.episode_data[key] = self.data.episode_data[key]
				else:
					raise KeyError("Unrecognised key {}".format(key))

			# Update the scheme to only have the requested keys
			new_scheme = {key: self.scheme[key] for key in item}
			new_groups = {self.scheme[key]["group"]: self.groups[self.scheme[key]["group"]]
						for key in item if "group" in self.scheme[key]}
			ret = EpisodeBatch(new_scheme, new_groups, self.batch_size, self.max_seq_length, data=new_data, device=self.device)
			return ret
		else:
			item = self._parse_slices(item)
			new_data = self._new_data_sn()
			for k, v in self.data.transition_data.items():
				new_data.transition_data[k] = v[item]
			for k, v in self.data.episode_data.items():
				new_data.episode_data[k] = v[item[0]]

			ret_bs = self._get_num_items(item[0], self.batch_size)
			ret_max_t = self._get_num_items(item[1], self.max_seq_length)

			ret = EpisodeBatch(self.scheme, self.groups, ret_bs, ret_max_t, data=new_data, device=self.device)
			return ret

	def _get_num_items(self, indexing_item, max_size):
		if isinstance(indexing_item, list) or isinstance(indexing_item, np.ndarray):
			return len(indexing_item)
		elif isinstance(indexing_item, slice):
			_range = indexing_item.indices(max_size)
			return 1 + (_range[1] - _range[0] - 1)//_range[2]

	def _new_data_sn(self):
		new_data = SN()
		new_data.transition_data = {}
		new_data.episode_data = {}
		return new_data

	def _parse_slices(self, items):
		parsed = []
		# Only batch slice given, add full time slice
		if (isinstance(items, slice)  # slice a:b
			or isinstance(items, int)  # int i
			or (isinstance(items, (list, np.ndarray, torch.LongTensor, torch.cuda.LongTensor)))  # [a,b,c]
			):
			items = (items, slice(None))

		# Need the time indexing to be contiguous
		if isinstance(items[1], list):
			raise IndexError("Indexing across Time must be contiguous")

		for item in items:
			#TODO: stronger checks to ensure only supported options get through
			if isinstance(item, int):
				# Convert single indices to slices
				parsed.append(slice(item, item+1))
			else:
				# Leave slices and lists as is
				parsed.append(item)
		return parsed

	def max_t_filled(self):
		return torch.sum(self.data.transition_data["filled"], 1).max(0)[0]

class ReplayBuffer(EpisodeBatch):
	def __init__(self, scheme, groups, buffer_size, max_seq_length, preprocess=None, device="cpu"):
		super(ReplayBuffer, self).__init__(scheme, groups, buffer_size, max_seq_length, preprocess=preprocess, device=device)
		self.buffer_size = buffer_size  # same as self.batch_size but more explicit
		self.buffer_index = 0
		self.episodes_in_buffer = 0

	def insert_episode_batch(self, ep_batch):
		if self.buffer_index + ep_batch.batch_size <= self.buffer_size:
			self.update(ep_batch.data.transition_data, slice(self.buffer_index, self.buffer_index + ep_batch.batch_size), slice(0, ep_batch.max_seq_length), mark_filled=False)
			self.update(ep_batch.data.episode_data, slice(self.buffer_index, self.buffer_index + ep_batch.batch_size))
			self.buffer_index = (self.buffer_index + ep_batch.batch_size)
			self.episodes_in_buffer = max(self.episodes_in_buffer, self.buffer_index)
			self.buffer_index = self.buffer_index % self.buffer_size
			assert self.buffer_index < self.buffer_size
		else:
			buffer_left = self.buffer_size - self.buffer_index
			self.insert_episode_batch(ep_batch[0:buffer_left, :])
			self.insert_episode_batch(ep_batch[buffer_left:, :])

	def can_sample(self, batch_size):
		return self.episodes_in_buffer >= batch_size

	def sample(self, batch_size):
		assert self.can_sample(batch_size)
		if self.episodes_in_buffer == batch_size:
			return self[:batch_size]
		else:
			ep_ids = np.random.choice(self.episodes_in_buffer, batch_size, replace=False)
			return self[ep_ids]


import torch
import random
import numpy as np
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, one_hot, gsoftmax

EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64

# class COMAActor(torch.nn.Module):
# 	def __init__(self, state_size, action_size):
# 		super().__init__()
# 		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)!=3 else Conv(state_size, INPUT_LAYER)
# 		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
# 		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
# 		self.action_probs = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
# 		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
# 		self.init_hidden()

# 	def forward(self, state, sample=True):
# 		state = self.layer1(state).relu()
# 		state = self.layer2(state).relu()
# 		state = self.layer3(state).relu()
# 		action_probs = self.action_probs(state).softmax(-1)
# 		dist = torch.distributions.Categorical(action_probs)
# 		action_in = dist.sample()
# 		action = one_hot_from_indices(action_in, action_probs.size(-1))
# 		entropy = dist.entropy()
# 		return action, action_probs, entropy

# 	def init_hidden(self, batch_size=1):
# 		self.hidden = torch.zeros([batch_size, ACTOR_HIDDEN])

# class COMACritic(torch.nn.Module):
# 	def __init__(self, state_size, action_size):
# 		super().__init__()
# 		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)!=3 else Conv(state_size, INPUT_LAYER)
# 		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
# 		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
# 		self.q_values = torch.nn.Linear(CRITIC_HIDDEN, action_size[-1])
# 		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

# 	def forward(self, state):
# 		state = self.layer1(state).relu()
# 		state = self.layer2(state).relu()
# 		state = self.layer3(state).relu()
# 		q_values = self.q_values(state)
# 		return q_values

class COMANetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(gpu=gpu)
		self.state_size = [state_size] if type(state_size[0]) in [int, np.int32] else state_size
		self.action_size = [action_size] if type(action_size[0]) in [int, np.int32] else action_size
		self.n_agents = lambda size: 1 if len(size)==1 else size[0]
		make_actor = lambda s,a: COMAActor([s[-1] + a[-1] + self.n_agents(s)], a)
		make_critic = lambda s,a: COMACritic([np.sum([np.prod(s) for s in self.state_size]) + 2*np.sum([np.prod(a) for a in self.action_size]) + s[-1] + self.n_agents(s)], a)
		self.models = [PTACNetwork(s_size, a_size, make_actor, make_critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		if load: self.load_model(load)
		
	def get_action_probs(self, state, sample=True, grad=True, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			action, action_prob, entropy = map(list, zip(*[model.actor_local(s, sample) for s,model in zip(state, self.models)]))
			return [[a.cpu().numpy().astype(np.float32) for a in x] for x in [action, action_prob, entropy]] if numpy else (action, action_prob, entropy)

	def get_value(self, state, use_target=False, grad=True, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_values = [model.critic_local(s) if use_target else model.critic_target(s) for s,model in zip(state, self.models)]
			return [q.cpu().numpy() for q in q_values] if numpy else q_values

	def optimize(self, actions, actor_inputs, critic_inputs, q_values, q_targets):
		for model,action,actor_input,critic_input,q_value,q_target in zip(self.models, actions, actor_inputs, critic_inputs, q_values, q_targets):
			q_value = model.critic_local(critic_input)
			q_select = torch.gather(q_value, dim=-1, index=action.argmax(-1, keepdims=True)).squeeze(-1)
			critic_loss = (q_select - q_target.detach()).pow(2)
			model.step(model.critic_optimizer, critic_loss.mean(), model.critic_local.parameters())
			model.soft_copy(model.critic_local, model.critic_target)

			_, action_probs, entropy = model.actor_local(actor_input)
			baseline = (action_probs * q_value).sum(-1, keepdims=True).detach()
			q_selected = torch.gather(q_value, dim=-1, index=action.argmax(-1, keepdims=True))
			log_probs = torch.gather(action_probs, dim=-1, index=action.argmax(-1, keepdims=True)).log()
			advantages = (q_selected - baseline).detach()
			actor_loss = -((advantages * log_probs).sum() + ENTROPY_WEIGHT*entropy.mean())
			model.step(model.actor_optimizer, actor_loss.mean(), model.actor_local.parameters())

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("coma", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("coma", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class COMAAgent2(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, COMANetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.replay_buffer = MultiagentReplayBuffer3(MAX_BUFFER_SIZE, state_size, action_size)

	def get_action(self, state, eps=None, sample=True, numpy=True):
		self.step = 0 if not hasattr(self, "step") else self.step + 1
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state)
		if not hasattr(self, "action"): self.action = [np.zeros_like(a) for a in action_random]
		actor_inputs = []
		state_list = state
		state_list = [state_list] if type(state_list) != list else state_list
		for i,(state,last_a,s_size,a_size) in enumerate(zip(state_list, self.action, self.state_size, self.action_size)):
			n_agents = self.network.n_agents(s_size)
			last_action = last_a if len(state.shape)-len(s_size) == len(last_a.shape)-len(a_size) else np.zeros_like(action_random[i])
			agent_ids = np.eye(n_agents) if len(state.shape)==len(s_size) else np.repeat(np.expand_dims(np.eye(n_agents), 0), repeats=state.shape[0], axis=0)
			actor_input = self.to_tensor(np.concatenate([state, last_action, agent_ids], axis=-1))
			actor_inputs.append(actor_input)
		action = self.network.get_action_probs(actor_inputs, sample=sample, grad=False, numpy=numpy)[0]
		if numpy: self.action = action
		return action

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.update_freq:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			n_agents = [self.network.n_agents(a_size) for a_size in self.action_size]
			states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, self.to_tensor(next_state))]
			actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.get_action(next_state, numpy=False))]
			states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			actions_one_hot = [one_hot(a) for a in actions]
			actions_one_hot_joint = torch.cat([a.view(*a.shape[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions_one_hot, self.action_size)], dim=-1)
			last_actions = [torch.cat([torch.zeros_like(a[0:1]), a[:-1]], dim=0) for a in actions_one_hot]
			last_actions_joint = torch.cat([a.view(*a.shape[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(last_actions, self.action_size)], dim=-1)
			agent_mask = [(1-torch.eye(n_agent)).view(-1, 1).repeat(1, a_size[-1]).view(n_agent, -1) for a_size,n_agent in zip(self.action_size, n_agents)]
			action_mask = torch.ones([1, 1, np.sum(n_agents), np.sum([n_agent*a_size[-1] for a_size,n_agent in zip(self.action_size, n_agents)])]).to(self.network.device)
			cols, rows = [0, *np.cumsum(n_agents)], [0, *np.cumsum([n_agent*a_size[-1] for a_size,n_agent in zip(self.action_size, n_agents)])]
			for i,mask in enumerate(agent_mask): action_mask[...,cols[i]:cols[i+1], rows[i]:rows[i+1]] = mask

			states_joint, actions_joint, last_actions_joint = [x.unsqueeze(-2).repeat_interleave(action_mask.shape[-2], dim=-2) for x in [states_joint, actions_one_hot_joint, last_actions_joint]]
			joint_inputs = torch.cat([states_joint, actions_joint * action_mask, last_actions_joint], dim=-1).split(n_agents, dim=-2)
			agent_ids = [torch.eye(self.network.n_agents(a_size)).unsqueeze(0).unsqueeze(0).expand(*a.shape[:2], -1, -1).to(self.network.device) for a_size, a in zip(self.action_size, actions)]
			critic_inputs = [torch.cat([joint_input, state, agent_id], dim=-1) for joint_input,state,agent_id in zip(joint_inputs, states, agent_ids)]
			actor_inputs = [torch.cat([state, last_action, agent_id], dim=-1) for state,last_action,agent_id in zip(states, last_actions, agent_ids)]

			q_values = self.network.get_value(critic_inputs, use_target=True, grad=False)
			q_selecteds = [torch.gather(q_value, dim=-1, index=a.argmax(-1, keepdims=True)).squeeze(-1) for q_value,a in zip(q_values,actions)]
			q_targets = [self.compute_gae(q_selected[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_selected[:-1])[0] for q_selected,reward,done in zip(q_selecteds, rewards, dones)]
			actions, actor_inputs, critic_inputs, q_values = [[t[:-1] for t in x] for x in [actions, actor_inputs, critic_inputs, q_values]]
			actions, actor_inputs, critic_inputs, q_values, q_targets = [[t.reshape(-1, *t.shape[2:]).cpu().numpy() for t in x] for x in [actions, actor_inputs, critic_inputs, q_values, q_targets]]
			self.replay_buffer.add((actions, actor_inputs, critic_inputs, q_values, q_targets))
		if len(self.replay_buffer) >= REPLAY_BATCH_SIZE and self.step%self.update_freq == 0:
			actions, actor_inputs, critic_inputs, q_values, q_targets = self.replay_buffer.sample(REPLAY_BATCH_SIZE, cast=self.to_tensor)
			self.network.optimize(actions, actor_inputs, critic_inputs, q_values, q_targets)
			if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0003           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.001   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 256				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 512				# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.998			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.001               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 1000000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.sac import SACAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, DoubleAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv, TrainEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, MPI_SIZE, MPI_RANK
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-3]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False, reward_shape=False):
	if env_name in gym_envs: return TrainEnv(gym.make(env_name))
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	ballr = lambda x,y: (np.maximum if x>0 else np.minimum)(x - np.abs(y)*np.sign(x), 0.5*x)
	reward_fn = lambda obs,reward: [(ballr(o[0,88], o[0,89]) + o[0,95]-o[0,96] + 2*r)/4 for o,r in zip(obs,reward)]
	return FootballTeamEnv(ggym, env_name, reward_fn if reward_shape else None)

def run(model, steps=10000, ports=16, env_name=env_name, trial_at=100, save_at=10, checkpoint=True, save_best=False, log=True, render=False, reward_shape=False, icm=False):
	envs = (EnvManager if type(ports) == list or MPI_SIZE > 1 else EnsembleEnv)(lambda: make_env(env_name, reward_shape=reward_shape), ports)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, envs.num_envs, load="", gpu=True, agent2=RandomAgent, save_dir=env_name, icm=icm) 
	logger = Logger(model, env_name, num_envs=envs.num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space, envs=type(envs), reward_shape=reward_shape, icm=icm)
	states = envs.reset(train=True)
	total_rewards = []
	for s in range(steps+1):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions, train=True)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if s%trial_at == 0:
			rollouts = rollout(envs, agent, render=render)
			total_rewards.append(np.mean(rollouts, axis=-1))
			if checkpoint and len(total_rewards) % save_at==0: agent.save_model(env_name, "checkpoint")
			if save_best and np.all(total_rewards[-1] >= np.max(total_rewards, axis=-1)): agent.save_model(env_name)
			if log: logger.log(f"Step: {s:7d}, Reward: {total_rewards[-1]} [{np.std(rollouts):4.3f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.eps:.4f})", agent.get_stats())

def trial(model, env_name, render):
	envs = EnsembleEnv(lambda: make_env(env_name, log=True, render=render), 0)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, gpu=False, load=f"{env_name}", agent2=RandomAgent, save_dir=env_name)
	print(f"Reward: {np.mean([rollout(envs.env, agent, eps=0.0, render=True) for _ in range(5)], axis=0)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="coma", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=200000, help="Number of steps to train the agent")
	parser.add_argument("--reward_shape", action="store_true", help="Whether to shape rewards for football")
	parser.add_argument("--icm", action="store_true", help="Whether to use intrinsic motivation")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--trial", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "sac":SACAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent, "rand":RandomAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.trial:
		trial(model=model, env_name=env_name, render=args.render)
	elif args.selfport is not None or MPI_RANK>0 :
		EnvWorker(self_port=args.selfport, make_env=make_env).start()
	else:
		run(model=model, steps=args.steps, ports=args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render, reward_shape=args.reward_shape, icm=args.icm)


Step:       0, Reward: [-478.590 -478.590 -478.590] [87.185], Avg: [-478.590 -478.590 -478.590] (1.0000) ({r_i: None, r_t: [-8.769 -8.769 -8.769], eps: 1.0})
Step:     100, Reward: [-491.556 -491.556 -491.556] [114.864], Avg: [-485.073 -485.073 -485.073] (1.0000) ({r_i: None, r_t: [-974.614 -974.614 -974.614], eps: 1.0})
Step:     200, Reward: [-465.310 -465.310 -465.310] [87.689], Avg: [-478.485 -478.485 -478.485] (1.0000) ({r_i: None, r_t: [-973.810 -973.810 -973.810], eps: 1.0})
Step:     300, Reward: [-472.486 -472.486 -472.486] [81.998], Avg: [-476.985 -476.985 -476.985] (1.0000) ({r_i: None, r_t: [-1033.665 -1033.665 -1033.665], eps: 1.0})
Step:     400, Reward: [-503.855 -503.855 -503.855] [83.128], Avg: [-482.359 -482.359 -482.359] (1.0000) ({r_i: None, r_t: [-937.498 -937.498 -937.498], eps: 1.0})
Step:     500, Reward: [-513.473 -513.473 -513.473] [99.747], Avg: [-487.545 -487.545 -487.545] (1.0000) ({r_i: None, r_t: [-973.978 -973.978 -973.978], eps: 1.0})
Step:     600, Reward: [-446.801 -446.801 -446.801] [60.985], Avg: [-481.724 -481.724 -481.724] (1.0000) ({r_i: None, r_t: [-962.700 -962.700 -962.700], eps: 1.0})
Step:     700, Reward: [-491.510 -491.510 -491.510] [103.180], Avg: [-482.948 -482.948 -482.948] (1.0000) ({r_i: None, r_t: [-944.039 -944.039 -944.039], eps: 1.0})
Step:     800, Reward: [-503.460 -503.460 -503.460] [137.005], Avg: [-485.227 -485.227 -485.227] (1.0000) ({r_i: None, r_t: [-996.675 -996.675 -996.675], eps: 1.0})
Step:     900, Reward: [-511.231 -511.231 -511.231] [88.161], Avg: [-487.827 -487.827 -487.827] (1.0000) ({r_i: None, r_t: [-1009.725 -1009.725 -1009.725], eps: 1.0})
Step:    1000, Reward: [-515.662 -515.662 -515.662] [136.854], Avg: [-490.358 -490.358 -490.358] (1.0000) ({r_i: None, r_t: [-967.482 -967.482 -967.482], eps: 1.0})
Step:    1100, Reward: [-486.962 -486.962 -486.962] [69.555], Avg: [-490.075 -490.075 -490.075] (1.0000) ({r_i: None, r_t: [-978.732 -978.732 -978.732], eps: 1.0})
Step:    1200, Reward: [-510.123 -510.123 -510.123] [73.348], Avg: [-491.617 -491.617 -491.617] (1.0000) ({r_i: None, r_t: [-1020.142 -1020.142 -1020.142], eps: 1.0})
Step:    1300, Reward: [-534.814 -534.814 -534.814] [94.390], Avg: [-494.702 -494.702 -494.702] (1.0000) ({r_i: None, r_t: [-961.804 -961.804 -961.804], eps: 1.0})
Step:    1400, Reward: [-446.901 -446.901 -446.901] [61.626], Avg: [-491.516 -491.516 -491.516] (1.0000) ({r_i: None, r_t: [-1019.811 -1019.811 -1019.811], eps: 1.0})
Step:    1500, Reward: [-501.046 -501.046 -501.046] [95.935], Avg: [-492.111 -492.111 -492.111] (1.0000) ({r_i: None, r_t: [-922.438 -922.438 -922.438], eps: 1.0})
Step:    1600, Reward: [-519.382 -519.382 -519.382] [73.263], Avg: [-493.715 -493.715 -493.715] (1.0000) ({r_i: None, r_t: [-1019.926 -1019.926 -1019.926], eps: 1.0})
Step:    1700, Reward: [-491.638 -491.638 -491.638] [80.126], Avg: [-493.600 -493.600 -493.600] (1.0000) ({r_i: None, r_t: [-1029.152 -1029.152 -1029.152], eps: 1.0})
Step:    1800, Reward: [-492.513 -492.513 -492.513] [103.033], Avg: [-493.543 -493.543 -493.543] (1.0000) ({r_i: None, r_t: [-963.055 -963.055 -963.055], eps: 1.0})
Step:    1900, Reward: [-505.949 -505.949 -505.949] [91.232], Avg: [-494.163 -494.163 -494.163] (1.0000) ({r_i: None, r_t: [-1013.038 -1013.038 -1013.038], eps: 1.0})
Step:    2000, Reward: [-505.590 -505.590 -505.590] [79.264], Avg: [-494.707 -494.707 -494.707] (1.0000) ({r_i: None, r_t: [-1000.108 -1000.108 -1000.108], eps: 1.0})
Step:    2100, Reward: [-475.439 -475.439 -475.439] [104.840], Avg: [-493.831 -493.831 -493.831] (1.0000) ({r_i: None, r_t: [-1060.559 -1060.559 -1060.559], eps: 1.0})
Step:    2200, Reward: [-463.540 -463.540 -463.540] [92.129], Avg: [-492.514 -492.514 -492.514] (1.0000) ({r_i: None, r_t: [-957.714 -957.714 -957.714], eps: 1.0})
Step:    2300, Reward: [-479.458 -479.458 -479.458] [87.768], Avg: [-491.970 -491.970 -491.970] (1.0000) ({r_i: None, r_t: [-1009.279 -1009.279 -1009.279], eps: 1.0})
Step:    2400, Reward: [-471.440 -471.440 -471.440] [94.633], Avg: [-491.149 -491.149 -491.149] (1.0000) ({r_i: None, r_t: [-989.725 -989.725 -989.725], eps: 1.0})
Step:    2500, Reward: [-524.878 -524.878 -524.878] [99.288], Avg: [-492.446 -492.446 -492.446] (1.0000) ({r_i: None, r_t: [-1027.023 -1027.023 -1027.023], eps: 1.0})
Step:    2600, Reward: [-480.330 -480.330 -480.330] [128.664], Avg: [-491.998 -491.998 -491.998] (1.0000) ({r_i: None, r_t: [-941.013 -941.013 -941.013], eps: 1.0})
Step:    2700, Reward: [-503.829 -503.829 -503.829] [81.641], Avg: [-492.420 -492.420 -492.420] (1.0000) ({r_i: None, r_t: [-1068.291 -1068.291 -1068.291], eps: 1.0})
Step:    2800, Reward: [-458.545 -458.545 -458.545] [102.597], Avg: [-491.252 -491.252 -491.252] (1.0000) ({r_i: None, r_t: [-969.184 -969.184 -969.184], eps: 1.0})
Step:    2900, Reward: [-514.387 -514.387 -514.387] [94.152], Avg: [-492.023 -492.023 -492.023] (1.0000) ({r_i: None, r_t: [-958.182 -958.182 -958.182], eps: 1.0})
Step:    3000, Reward: [-445.483 -445.483 -445.483] [68.040], Avg: [-490.522 -490.522 -490.522] (1.0000) ({r_i: None, r_t: [-955.360 -955.360 -955.360], eps: 1.0})
Step:    3100, Reward: [-528.085 -528.085 -528.085] [102.688], Avg: [-491.696 -491.696 -491.696] (1.0000) ({r_i: None, r_t: [-1002.020 -1002.020 -1002.020], eps: 1.0})
Step:    3200, Reward: [-482.216 -482.216 -482.216] [73.015], Avg: [-491.409 -491.409 -491.409] (1.0000) ({r_i: None, r_t: [-995.995 -995.995 -995.995], eps: 1.0})
Step:    3300, Reward: [-506.480 -506.480 -506.480] [73.353], Avg: [-491.852 -491.852 -491.852] (1.0000) ({r_i: None, r_t: [-951.892 -951.892 -951.892], eps: 1.0})
Step:    3400, Reward: [-459.782 -459.782 -459.782] [58.532], Avg: [-490.936 -490.936 -490.936] (1.0000) ({r_i: None, r_t: [-1005.573 -1005.573 -1005.573], eps: 1.0})
Step:    3500, Reward: [-469.169 -469.169 -469.169] [87.884], Avg: [-490.331 -490.331 -490.331] (1.0000) ({r_i: None, r_t: [-1021.866 -1021.866 -1021.866], eps: 1.0})
Step:    3600, Reward: [-470.488 -470.488 -470.488] [104.225], Avg: [-489.795 -489.795 -489.795] (1.0000) ({r_i: None, r_t: [-949.362 -949.362 -949.362], eps: 1.0})
Step:    3700, Reward: [-526.516 -526.516 -526.516] [143.916], Avg: [-490.761 -490.761 -490.761] (1.0000) ({r_i: None, r_t: [-958.769 -958.769 -958.769], eps: 1.0})
Step:    3800, Reward: [-476.548 -476.548 -476.548] [65.735], Avg: [-490.397 -490.397 -490.397] (1.0000) ({r_i: None, r_t: [-967.658 -967.658 -967.658], eps: 1.0})
Step:    3900, Reward: [-487.130 -487.130 -487.130] [101.545], Avg: [-490.315 -490.315 -490.315] (1.0000) ({r_i: None, r_t: [-971.281 -971.281 -971.281], eps: 1.0})
Step:    4000, Reward: [-523.700 -523.700 -523.700] [94.614], Avg: [-491.129 -491.129 -491.129] (1.0000) ({r_i: None, r_t: [-945.522 -945.522 -945.522], eps: 1.0})
Step:    4100, Reward: [-495.786 -495.786 -495.786] [99.187], Avg: [-491.240 -491.240 -491.240] (1.0000) ({r_i: None, r_t: [-1040.323 -1040.323 -1040.323], eps: 1.0})
Step:    4200, Reward: [-465.778 -465.778 -465.778] [58.322], Avg: [-490.648 -490.648 -490.648] (1.0000) ({r_i: None, r_t: [-936.370 -936.370 -936.370], eps: 1.0})
Step:    4300, Reward: [-502.625 -502.625 -502.625] [101.231], Avg: [-490.920 -490.920 -490.920] (1.0000) ({r_i: None, r_t: [-991.298 -991.298 -991.298], eps: 1.0})
Step:    4400, Reward: [-487.433 -487.433 -487.433] [77.964], Avg: [-490.843 -490.843 -490.843] (1.0000) ({r_i: None, r_t: [-969.997 -969.997 -969.997], eps: 1.0})
Step:    4500, Reward: [-528.959 -528.959 -528.959] [157.012], Avg: [-491.671 -491.671 -491.671] (1.0000) ({r_i: None, r_t: [-1001.026 -1001.026 -1001.026], eps: 1.0})
Step:    4600, Reward: [-467.659 -467.659 -467.659] [78.192], Avg: [-491.160 -491.160 -491.160] (1.0000) ({r_i: None, r_t: [-970.217 -970.217 -970.217], eps: 1.0})
Step:    4700, Reward: [-523.022 -523.022 -523.022] [118.643], Avg: [-491.824 -491.824 -491.824] (1.0000) ({r_i: None, r_t: [-954.115 -954.115 -954.115], eps: 1.0})
Step:    4800, Reward: [-455.087 -455.087 -455.087] [77.071], Avg: [-491.074 -491.074 -491.074] (1.0000) ({r_i: None, r_t: [-1015.417 -1015.417 -1015.417], eps: 1.0})
Step:    4900, Reward: [-481.773 -481.773 -481.773] [86.144], Avg: [-490.888 -490.888 -490.888] (1.0000) ({r_i: None, r_t: [-953.246 -953.246 -953.246], eps: 1.0})
Step:    5000, Reward: [-528.816 -528.816 -528.816] [99.027], Avg: [-491.632 -491.632 -491.632] (1.0000) ({r_i: None, r_t: [-979.018 -979.018 -979.018], eps: 1.0})
Step:    5100, Reward: [-492.174 -492.174 -492.174] [60.203], Avg: [-491.642 -491.642 -491.642] (1.0000) ({r_i: None, r_t: [-970.532 -970.532 -970.532], eps: 1.0})
Step:    5200, Reward: [-519.793 -519.793 -519.793] [98.360], Avg: [-492.174 -492.174 -492.174] (1.0000) ({r_i: None, r_t: [-972.677 -972.677 -972.677], eps: 1.0})
Step:    5300, Reward: [-514.347 -514.347 -514.347] [88.709], Avg: [-492.584 -492.584 -492.584] (1.0000) ({r_i: None, r_t: [-985.175 -985.175 -985.175], eps: 1.0})
Step:    5400, Reward: [-483.830 -483.830 -483.830] [86.486], Avg: [-492.425 -492.425 -492.425] (1.0000) ({r_i: None, r_t: [-982.431 -982.431 -982.431], eps: 1.0})
Step:    5500, Reward: [-533.872 -533.872 -533.872] [137.223], Avg: [-493.165 -493.165 -493.165] (1.0000) ({r_i: None, r_t: [-1011.008 -1011.008 -1011.008], eps: 1.0})
Step:    5600, Reward: [-489.559 -489.559 -489.559] [93.621], Avg: [-493.102 -493.102 -493.102] (1.0000) ({r_i: None, r_t: [-992.444 -992.444 -992.444], eps: 1.0})
Step:    5700, Reward: [-487.683 -487.683 -487.683] [101.826], Avg: [-493.008 -493.008 -493.008] (1.0000) ({r_i: None, r_t: [-973.501 -973.501 -973.501], eps: 1.0})
Step:    5800, Reward: [-463.692 -463.692 -463.692] [67.723], Avg: [-492.512 -492.512 -492.512] (1.0000) ({r_i: None, r_t: [-975.332 -975.332 -975.332], eps: 1.0})
Step:    5900, Reward: [-477.665 -477.665 -477.665] [87.116], Avg: [-492.264 -492.264 -492.264] (1.0000) ({r_i: None, r_t: [-955.859 -955.859 -955.859], eps: 1.0})
Step:    6000, Reward: [-513.670 -513.670 -513.670] [124.462], Avg: [-492.615 -492.615 -492.615] (1.0000) ({r_i: None, r_t: [-1006.585 -1006.585 -1006.585], eps: 1.0})
Step:    6100, Reward: [-505.741 -505.741 -505.741] [92.669], Avg: [-492.827 -492.827 -492.827] (1.0000) ({r_i: None, r_t: [-943.785 -943.785 -943.785], eps: 1.0})
Step:    6200, Reward: [-492.502 -492.502 -492.502] [87.644], Avg: [-492.822 -492.822 -492.822] (1.0000) ({r_i: None, r_t: [-974.114 -974.114 -974.114], eps: 1.0})
Step:    6300, Reward: [-489.460 -489.460 -489.460] [104.566], Avg: [-492.769 -492.769 -492.769] (1.0000) ({r_i: None, r_t: [-1003.712 -1003.712 -1003.712], eps: 1.0})
Step:    6400, Reward: [-503.446 -503.446 -503.446] [115.347], Avg: [-492.933 -492.933 -492.933] (1.0000) ({r_i: None, r_t: [-1003.001 -1003.001 -1003.001], eps: 1.0})
Step:    6500, Reward: [-483.369 -483.369 -483.369] [98.285], Avg: [-492.788 -492.788 -492.788] (1.0000) ({r_i: None, r_t: [-1040.767 -1040.767 -1040.767], eps: 1.0})
Step:    6600, Reward: [-530.823 -530.823 -530.823] [114.405], Avg: [-493.356 -493.356 -493.356] (1.0000) ({r_i: None, r_t: [-1016.610 -1016.610 -1016.610], eps: 1.0})
Step:    6700, Reward: [-462.525 -462.525 -462.525] [52.968], Avg: [-492.903 -492.903 -492.903] (1.0000) ({r_i: None, r_t: [-1054.450 -1054.450 -1054.450], eps: 1.0})
Step:    6800, Reward: [-487.995 -487.995 -487.995] [77.315], Avg: [-492.832 -492.832 -492.832] (1.0000) ({r_i: None, r_t: [-980.740 -980.740 -980.740], eps: 1.0})
Step:    6900, Reward: [-468.544 -468.544 -468.544] [91.597], Avg: [-492.485 -492.485 -492.485] (1.0000) ({r_i: None, r_t: [-929.091 -929.091 -929.091], eps: 1.0})
Step:    7000, Reward: [-477.738 -477.738 -477.738] [104.882], Avg: [-492.277 -492.277 -492.277] (1.0000) ({r_i: None, r_t: [-1008.771 -1008.771 -1008.771], eps: 1.0})
Step:    7100, Reward: [-493.172 -493.172 -493.172] [76.849], Avg: [-492.289 -492.289 -492.289] (1.0000) ({r_i: None, r_t: [-1088.570 -1088.570 -1088.570], eps: 1.0})
Step:    7200, Reward: [-466.423 -466.423 -466.423] [53.039], Avg: [-491.935 -491.935 -491.935] (1.0000) ({r_i: None, r_t: [-1022.892 -1022.892 -1022.892], eps: 1.0})
Step:    7300, Reward: [-512.611 -512.611 -512.611] [149.013], Avg: [-492.214 -492.214 -492.214] (1.0000) ({r_i: None, r_t: [-1050.633 -1050.633 -1050.633], eps: 1.0})
Step:    7400, Reward: [-482.116 -482.116 -482.116] [88.844], Avg: [-492.080 -492.080 -492.080] (1.0000) ({r_i: None, r_t: [-976.818 -976.818 -976.818], eps: 1.0})
Step:    7500, Reward: [-498.251 -498.251 -498.251] [75.580], Avg: [-492.161 -492.161 -492.161] (1.0000) ({r_i: None, r_t: [-955.502 -955.502 -955.502], eps: 1.0})
Step:    7600, Reward: [-507.034 -507.034 -507.034] [111.437], Avg: [-492.354 -492.354 -492.354] (1.0000) ({r_i: None, r_t: [-1001.393 -1001.393 -1001.393], eps: 1.0})
Step:    7700, Reward: [-482.939 -482.939 -482.939] [131.060], Avg: [-492.233 -492.233 -492.233] (1.0000) ({r_i: None, r_t: [-978.465 -978.465 -978.465], eps: 1.0})
Step:    7800, Reward: [-506.198 -506.198 -506.198] [98.703], Avg: [-492.410 -492.410 -492.410] (1.0000) ({r_i: None, r_t: [-971.494 -971.494 -971.494], eps: 1.0})
Step:    7900, Reward: [-505.349 -505.349 -505.349] [87.907], Avg: [-492.572 -492.572 -492.572] (1.0000) ({r_i: None, r_t: [-950.789 -950.789 -950.789], eps: 1.0})
Step:    8000, Reward: [-455.366 -455.366 -455.366] [88.656], Avg: [-492.113 -492.113 -492.113] (1.0000) ({r_i: None, r_t: [-990.530 -990.530 -990.530], eps: 1.0})
Step:    8100, Reward: [-478.095 -478.095 -478.095] [76.023], Avg: [-491.942 -491.942 -491.942] (1.0000) ({r_i: None, r_t: [-967.542 -967.542 -967.542], eps: 1.0})
Step:    8200, Reward: [-489.874 -489.874 -489.874] [86.801], Avg: [-491.917 -491.917 -491.917] (1.0000) ({r_i: None, r_t: [-976.721 -976.721 -976.721], eps: 1.0})
Step:    8300, Reward: [-478.092 -478.092 -478.092] [110.783], Avg: [-491.752 -491.752 -491.752] (1.0000) ({r_i: None, r_t: [-994.763 -994.763 -994.763], eps: 1.0})
Step:    8400, Reward: [-480.782 -480.782 -480.782] [96.856], Avg: [-491.623 -491.623 -491.623] (1.0000) ({r_i: None, r_t: [-959.610 -959.610 -959.610], eps: 1.0})
Step:    8500, Reward: [-545.481 -545.481 -545.481] [103.213], Avg: [-492.249 -492.249 -492.249] (1.0000) ({r_i: None, r_t: [-948.294 -948.294 -948.294], eps: 1.0})
Step:    8600, Reward: [-436.143 -436.143 -436.143] [70.741], Avg: [-491.604 -491.604 -491.604] (1.0000) ({r_i: None, r_t: [-1027.150 -1027.150 -1027.150], eps: 1.0})
Step:    8700, Reward: [-469.257 -469.257 -469.257] [116.149], Avg: [-491.350 -491.350 -491.350] (1.0000) ({r_i: None, r_t: [-1019.356 -1019.356 -1019.356], eps: 1.0})
Step:    8800, Reward: [-539.185 -539.185 -539.185] [127.664], Avg: [-491.888 -491.888 -491.888] (1.0000) ({r_i: None, r_t: [-960.846 -960.846 -960.846], eps: 1.0})
Step:    8900, Reward: [-522.640 -522.640 -522.640] [94.273], Avg: [-492.230 -492.230 -492.230] (1.0000) ({r_i: None, r_t: [-1000.927 -1000.927 -1000.927], eps: 1.0})
Step:    9000, Reward: [-502.162 -502.162 -502.162] [128.883], Avg: [-492.339 -492.339 -492.339] (1.0000) ({r_i: None, r_t: [-1020.738 -1020.738 -1020.738], eps: 1.0})
Step:    9100, Reward: [-541.417 -541.417 -541.417] [166.187], Avg: [-492.872 -492.872 -492.872] (1.0000) ({r_i: None, r_t: [-1009.199 -1009.199 -1009.199], eps: 1.0})
Step:    9200, Reward: [-559.569 -559.569 -559.569] [136.199], Avg: [-493.589 -493.589 -493.589] (1.0000) ({r_i: None, r_t: [-985.215 -985.215 -985.215], eps: 1.0})
Step:    9300, Reward: [-519.215 -519.215 -519.215] [157.767], Avg: [-493.862 -493.862 -493.862] (1.0000) ({r_i: None, r_t: [-1020.235 -1020.235 -1020.235], eps: 1.0})
Step:    9400, Reward: [-564.778 -564.778 -564.778] [133.198], Avg: [-494.609 -494.609 -494.609] (1.0000) ({r_i: None, r_t: [-1019.147 -1019.147 -1019.147], eps: 1.0})
Step:    9500, Reward: [-556.447 -556.447 -556.447] [118.736], Avg: [-495.253 -495.253 -495.253] (1.0000) ({r_i: None, r_t: [-1150.363 -1150.363 -1150.363], eps: 1.0})
Step:    9600, Reward: [-532.259 -532.259 -532.259] [107.222], Avg: [-495.634 -495.634 -495.634] (1.0000) ({r_i: None, r_t: [-1100.223 -1100.223 -1100.223], eps: 1.0})
Step:    9700, Reward: [-512.273 -512.273 -512.273] [113.430], Avg: [-495.804 -495.804 -495.804] (1.0000) ({r_i: None, r_t: [-1096.410 -1096.410 -1096.410], eps: 1.0})
Step:    9800, Reward: [-528.029 -528.029 -528.029] [118.313], Avg: [-496.129 -496.129 -496.129] (1.0000) ({r_i: None, r_t: [-984.423 -984.423 -984.423], eps: 1.0})
Step:    9900, Reward: [-516.111 -516.111 -516.111] [102.704], Avg: [-496.329 -496.329 -496.329] (1.0000) ({r_i: None, r_t: [-1059.264 -1059.264 -1059.264], eps: 1.0})
Step:   10000, Reward: [-525.882 -525.882 -525.882] [128.709], Avg: [-496.622 -496.622 -496.622] (1.0000) ({r_i: None, r_t: [-972.538 -972.538 -972.538], eps: 1.0})
Step:   10100, Reward: [-458.590 -458.590 -458.590] [63.258], Avg: [-496.249 -496.249 -496.249] (1.0000) ({r_i: None, r_t: [-959.001 -959.001 -959.001], eps: 1.0})
Step:   10200, Reward: [-532.003 -532.003 -532.003] [120.523], Avg: [-496.596 -496.596 -496.596] (1.0000) ({r_i: None, r_t: [-1055.147 -1055.147 -1055.147], eps: 1.0})
Step:   10300, Reward: [-558.620 -558.620 -558.620] [106.244], Avg: [-497.193 -497.193 -497.193] (1.0000) ({r_i: None, r_t: [-1101.661 -1101.661 -1101.661], eps: 1.0})
Step:   10400, Reward: [-507.565 -507.565 -507.565] [133.690], Avg: [-497.291 -497.291 -497.291] (1.0000) ({r_i: None, r_t: [-1020.198 -1020.198 -1020.198], eps: 1.0})
Step:   10500, Reward: [-513.401 -513.401 -513.401] [85.402], Avg: [-497.443 -497.443 -497.443] (1.0000) ({r_i: None, r_t: [-1094.765 -1094.765 -1094.765], eps: 1.0})
Step:   10600, Reward: [-554.458 -554.458 -554.458] [168.952], Avg: [-497.976 -497.976 -497.976] (1.0000) ({r_i: None, r_t: [-1095.301 -1095.301 -1095.301], eps: 1.0})
Step:   10700, Reward: [-487.342 -487.342 -487.342] [104.903], Avg: [-497.878 -497.878 -497.878] (1.0000) ({r_i: None, r_t: [-1005.673 -1005.673 -1005.673], eps: 1.0})
Step:   10800, Reward: [-502.561 -502.561 -502.561] [126.681], Avg: [-497.921 -497.921 -497.921] (1.0000) ({r_i: None, r_t: [-1081.772 -1081.772 -1081.772], eps: 1.0})
Step:   10900, Reward: [-497.477 -497.477 -497.477] [92.685], Avg: [-497.917 -497.917 -497.917] (1.0000) ({r_i: None, r_t: [-985.851 -985.851 -985.851], eps: 1.0})
Step:   11000, Reward: [-495.925 -495.925 -495.925] [76.367], Avg: [-497.899 -497.899 -497.899] (1.0000) ({r_i: None, r_t: [-1020.978 -1020.978 -1020.978], eps: 1.0})
Step:   11100, Reward: [-451.273 -451.273 -451.273] [85.131], Avg: [-497.482 -497.482 -497.482] (1.0000) ({r_i: None, r_t: [-1002.208 -1002.208 -1002.208], eps: 1.0})
Step:   11200, Reward: [-470.328 -470.328 -470.328] [81.931], Avg: [-497.242 -497.242 -497.242] (1.0000) ({r_i: None, r_t: [-1043.602 -1043.602 -1043.602], eps: 1.0})
Step:   11300, Reward: [-490.309 -490.309 -490.309] [89.412], Avg: [-497.181 -497.181 -497.181] (1.0000) ({r_i: None, r_t: [-965.708 -965.708 -965.708], eps: 1.0})
Step:   11400, Reward: [-527.843 -527.843 -527.843] [107.864], Avg: [-497.448 -497.448 -497.448] (1.0000) ({r_i: None, r_t: [-955.348 -955.348 -955.348], eps: 1.0})
Step:   11500, Reward: [-509.199 -509.199 -509.199] [105.657], Avg: [-497.549 -497.549 -497.549] (1.0000) ({r_i: None, r_t: [-974.425 -974.425 -974.425], eps: 1.0})
Step:   11600, Reward: [-501.165 -501.165 -501.165] [96.476], Avg: [-497.580 -497.580 -497.580] (1.0000) ({r_i: None, r_t: [-999.475 -999.475 -999.475], eps: 1.0})
Step:   11700, Reward: [-473.059 -473.059 -473.059] [88.323], Avg: [-497.372 -497.372 -497.372] (1.0000) ({r_i: None, r_t: [-998.560 -998.560 -998.560], eps: 1.0})
Step:   11800, Reward: [-470.005 -470.005 -470.005] [91.674], Avg: [-497.142 -497.142 -497.142] (1.0000) ({r_i: None, r_t: [-983.878 -983.878 -983.878], eps: 1.0})
Step:   11900, Reward: [-479.153 -479.153 -479.153] [80.838], Avg: [-496.992 -496.992 -496.992] (1.0000) ({r_i: None, r_t: [-998.996 -998.996 -998.996], eps: 1.0})
Step:   12000, Reward: [-519.470 -519.470 -519.470] [99.631], Avg: [-497.178 -497.178 -497.178] (1.0000) ({r_i: None, r_t: [-978.668 -978.668 -978.668], eps: 1.0})
Step:   12100, Reward: [-468.804 -468.804 -468.804] [87.341], Avg: [-496.946 -496.946 -496.946] (1.0000) ({r_i: None, r_t: [-991.687 -991.687 -991.687], eps: 1.0})
Step:   12200, Reward: [-466.933 -466.933 -466.933] [51.365], Avg: [-496.702 -496.702 -496.702] (1.0000) ({r_i: None, r_t: [-993.791 -993.791 -993.791], eps: 1.0})
Step:   12300, Reward: [-508.825 -508.825 -508.825] [99.523], Avg: [-496.799 -496.799 -496.799] (1.0000) ({r_i: None, r_t: [-1058.417 -1058.417 -1058.417], eps: 1.0})
Step:   12400, Reward: [-505.391 -505.391 -505.391] [107.157], Avg: [-496.868 -496.868 -496.868] (1.0000) ({r_i: None, r_t: [-937.677 -937.677 -937.677], eps: 1.0})
Step:   12500, Reward: [-481.145 -481.145 -481.145] [86.480], Avg: [-496.743 -496.743 -496.743] (1.0000) ({r_i: None, r_t: [-928.718 -928.718 -928.718], eps: 1.0})
Step:   12600, Reward: [-495.806 -495.806 -495.806] [119.992], Avg: [-496.736 -496.736 -496.736] (1.0000) ({r_i: None, r_t: [-942.831 -942.831 -942.831], eps: 1.0})
Step:   12700, Reward: [-444.059 -444.059 -444.059] [80.798], Avg: [-496.324 -496.324 -496.324] (1.0000) ({r_i: None, r_t: [-937.682 -937.682 -937.682], eps: 1.0})
Step:   12800, Reward: [-458.469 -458.469 -458.469] [76.494], Avg: [-496.031 -496.031 -496.031] (1.0000) ({r_i: None, r_t: [-980.683 -980.683 -980.683], eps: 1.0})
Step:   12900, Reward: [-501.246 -501.246 -501.246] [93.645], Avg: [-496.071 -496.071 -496.071] (1.0000) ({r_i: None, r_t: [-995.440 -995.440 -995.440], eps: 1.0})
Step:   13000, Reward: [-466.820 -466.820 -466.820] [95.469], Avg: [-495.848 -495.848 -495.848] (1.0000) ({r_i: None, r_t: [-978.891 -978.891 -978.891], eps: 1.0})
Step:   13100, Reward: [-475.990 -475.990 -475.990] [112.519], Avg: [-495.697 -495.697 -495.697] (1.0000) ({r_i: None, r_t: [-957.811 -957.811 -957.811], eps: 1.0})
Step:   13200, Reward: [-487.915 -487.915 -487.915] [80.816], Avg: [-495.639 -495.639 -495.639] (1.0000) ({r_i: None, r_t: [-965.303 -965.303 -965.303], eps: 1.0})
Step:   13300, Reward: [-512.658 -512.658 -512.658] [83.406], Avg: [-495.766 -495.766 -495.766] (1.0000) ({r_i: None, r_t: [-932.339 -932.339 -932.339], eps: 1.0})
Step:   13400, Reward: [-502.308 -502.308 -502.308] [86.716], Avg: [-495.814 -495.814 -495.814] (1.0000) ({r_i: None, r_t: [-949.481 -949.481 -949.481], eps: 1.0})
Step:   13500, Reward: [-491.638 -491.638 -491.638] [94.937], Avg: [-495.784 -495.784 -495.784] (1.0000) ({r_i: None, r_t: [-929.790 -929.790 -929.790], eps: 1.0})
Step:   13600, Reward: [-523.882 -523.882 -523.882] [104.486], Avg: [-495.989 -495.989 -495.989] (1.0000) ({r_i: None, r_t: [-975.327 -975.327 -975.327], eps: 1.0})
Step:   13700, Reward: [-441.062 -441.062 -441.062] [89.448], Avg: [-495.591 -495.591 -495.591] (1.0000) ({r_i: None, r_t: [-937.542 -937.542 -937.542], eps: 1.0})
Step:   13800, Reward: [-492.547 -492.547 -492.547] [114.384], Avg: [-495.569 -495.569 -495.569] (1.0000) ({r_i: None, r_t: [-898.025 -898.025 -898.025], eps: 1.0})
Step:   13900, Reward: [-502.140 -502.140 -502.140] [116.617], Avg: [-495.616 -495.616 -495.616] (1.0000) ({r_i: None, r_t: [-925.460 -925.460 -925.460], eps: 1.0})
Step:   14000, Reward: [-429.655 -429.655 -429.655] [75.528], Avg: [-495.148 -495.148 -495.148] (1.0000) ({r_i: None, r_t: [-963.692 -963.692 -963.692], eps: 1.0})
Step:   14100, Reward: [-497.672 -497.672 -497.672] [105.794], Avg: [-495.166 -495.166 -495.166] (1.0000) ({r_i: None, r_t: [-924.879 -924.879 -924.879], eps: 1.0})
Step:   14200, Reward: [-460.630 -460.630 -460.630] [56.509], Avg: [-494.924 -494.924 -494.924] (1.0000) ({r_i: None, r_t: [-958.414 -958.414 -958.414], eps: 1.0})
Step:   14300, Reward: [-472.067 -472.067 -472.067] [105.205], Avg: [-494.765 -494.765 -494.765] (1.0000) ({r_i: None, r_t: [-987.393 -987.393 -987.393], eps: 1.0})
Step:   14400, Reward: [-504.157 -504.157 -504.157] [101.689], Avg: [-494.830 -494.830 -494.830] (1.0000) ({r_i: None, r_t: [-983.035 -983.035 -983.035], eps: 1.0})
Step:   14500, Reward: [-478.458 -478.458 -478.458] [82.732], Avg: [-494.718 -494.718 -494.718] (1.0000) ({r_i: None, r_t: [-959.730 -959.730 -959.730], eps: 1.0})
Step:   14600, Reward: [-461.654 -461.654 -461.654] [76.022], Avg: [-494.493 -494.493 -494.493] (1.0000) ({r_i: None, r_t: [-965.530 -965.530 -965.530], eps: 1.0})
Step:   14700, Reward: [-526.467 -526.467 -526.467] [136.704], Avg: [-494.709 -494.709 -494.709] (1.0000) ({r_i: None, r_t: [-985.072 -985.072 -985.072], eps: 1.0})
Step:   14800, Reward: [-462.136 -462.136 -462.136] [97.312], Avg: [-494.491 -494.491 -494.491] (1.0000) ({r_i: None, r_t: [-880.591 -880.591 -880.591], eps: 1.0})
Step:   14900, Reward: [-437.842 -437.842 -437.842] [89.427], Avg: [-494.113 -494.113 -494.113] (1.0000) ({r_i: None, r_t: [-911.130 -911.130 -911.130], eps: 1.0})
Step:   15000, Reward: [-459.432 -459.432 -459.432] [90.557], Avg: [-493.883 -493.883 -493.883] (1.0000) ({r_i: None, r_t: [-994.555 -994.555 -994.555], eps: 1.0})
Step:   15100, Reward: [-456.829 -456.829 -456.829] [75.743], Avg: [-493.639 -493.639 -493.639] (1.0000) ({r_i: None, r_t: [-930.190 -930.190 -930.190], eps: 1.0})
Step:   15200, Reward: [-472.366 -472.366 -472.366] [75.951], Avg: [-493.500 -493.500 -493.500] (1.0000) ({r_i: None, r_t: [-958.784 -958.784 -958.784], eps: 1.0})
Step:   15300, Reward: [-492.748 -492.748 -492.748] [144.285], Avg: [-493.495 -493.495 -493.495] (1.0000) ({r_i: None, r_t: [-904.127 -904.127 -904.127], eps: 1.0})
Step:   15400, Reward: [-479.813 -479.813 -479.813] [80.449], Avg: [-493.407 -493.407 -493.407] (1.0000) ({r_i: None, r_t: [-1024.911 -1024.911 -1024.911], eps: 1.0})
Step:   15500, Reward: [-449.435 -449.435 -449.435] [94.673], Avg: [-493.125 -493.125 -493.125] (1.0000) ({r_i: None, r_t: [-896.667 -896.667 -896.667], eps: 1.0})
Step:   15600, Reward: [-436.210 -436.210 -436.210] [95.603], Avg: [-492.763 -492.763 -492.763] (1.0000) ({r_i: None, r_t: [-931.448 -931.448 -931.448], eps: 1.0})
Step:   15700, Reward: [-448.135 -448.135 -448.135] [85.232], Avg: [-492.480 -492.480 -492.480] (1.0000) ({r_i: None, r_t: [-931.186 -931.186 -931.186], eps: 1.0})
Step:   15800, Reward: [-473.070 -473.070 -473.070] [85.570], Avg: [-492.358 -492.358 -492.358] (1.0000) ({r_i: None, r_t: [-899.483 -899.483 -899.483], eps: 1.0})
Step:   15900, Reward: [-478.989 -478.989 -478.989] [64.954], Avg: [-492.275 -492.275 -492.275] (1.0000) ({r_i: None, r_t: [-952.944 -952.944 -952.944], eps: 1.0})
Step:   16000, Reward: [-486.243 -486.243 -486.243] [102.714], Avg: [-492.237 -492.237 -492.237] (1.0000) ({r_i: None, r_t: [-913.526 -913.526 -913.526], eps: 1.0})
Step:   16100, Reward: [-451.458 -451.458 -451.458] [53.482], Avg: [-491.986 -491.986 -491.986] (1.0000) ({r_i: None, r_t: [-882.458 -882.458 -882.458], eps: 1.0})
Step:   16200, Reward: [-461.738 -461.738 -461.738] [118.933], Avg: [-491.800 -491.800 -491.800] (1.0000) ({r_i: None, r_t: [-892.628 -892.628 -892.628], eps: 1.0})
Step:   16300, Reward: [-473.756 -473.756 -473.756] [100.264], Avg: [-491.690 -491.690 -491.690] (1.0000) ({r_i: None, r_t: [-859.205 -859.205 -859.205], eps: 1.0})
Step:   16400, Reward: [-469.536 -469.536 -469.536] [101.984], Avg: [-491.556 -491.556 -491.556] (1.0000) ({r_i: None, r_t: [-864.882 -864.882 -864.882], eps: 1.0})
Step:   16500, Reward: [-419.268 -419.268 -419.268] [57.305], Avg: [-491.120 -491.120 -491.120] (1.0000) ({r_i: None, r_t: [-954.417 -954.417 -954.417], eps: 1.0})
Step:   16600, Reward: [-463.445 -463.445 -463.445] [98.615], Avg: [-490.955 -490.955 -490.955] (1.0000) ({r_i: None, r_t: [-893.266 -893.266 -893.266], eps: 1.0})
Step:   16700, Reward: [-442.137 -442.137 -442.137] [106.482], Avg: [-490.664 -490.664 -490.664] (1.0000) ({r_i: None, r_t: [-878.637 -878.637 -878.637], eps: 1.0})
Step:   16800, Reward: [-486.066 -486.066 -486.066] [101.396], Avg: [-490.637 -490.637 -490.637] (1.0000) ({r_i: None, r_t: [-909.480 -909.480 -909.480], eps: 1.0})
Step:   16900, Reward: [-454.456 -454.456 -454.456] [115.806], Avg: [-490.424 -490.424 -490.424] (1.0000) ({r_i: None, r_t: [-880.032 -880.032 -880.032], eps: 1.0})
Step:   17000, Reward: [-476.014 -476.014 -476.014] [86.182], Avg: [-490.340 -490.340 -490.340] (1.0000) ({r_i: None, r_t: [-864.612 -864.612 -864.612], eps: 1.0})
Step:   17100, Reward: [-420.737 -420.737 -420.737] [64.368], Avg: [-489.935 -489.935 -489.935] (1.0000) ({r_i: None, r_t: [-959.287 -959.287 -959.287], eps: 1.0})
Step:   17200, Reward: [-481.230 -481.230 -481.230] [88.164], Avg: [-489.885 -489.885 -489.885] (1.0000) ({r_i: None, r_t: [-881.656 -881.656 -881.656], eps: 1.0})
Step:   17300, Reward: [-446.838 -446.838 -446.838] [86.198], Avg: [-489.637 -489.637 -489.637] (1.0000) ({r_i: None, r_t: [-889.260 -889.260 -889.260], eps: 1.0})
Step:   17400, Reward: [-430.835 -430.835 -430.835] [76.801], Avg: [-489.301 -489.301 -489.301] (1.0000) ({r_i: None, r_t: [-899.011 -899.011 -899.011], eps: 1.0})
Step:   17500, Reward: [-414.818 -414.818 -414.818] [78.439], Avg: [-488.878 -488.878 -488.878] (1.0000) ({r_i: None, r_t: [-900.181 -900.181 -900.181], eps: 1.0})
Step:   17600, Reward: [-456.187 -456.187 -456.187] [107.097], Avg: [-488.693 -488.693 -488.693] (1.0000) ({r_i: None, r_t: [-884.406 -884.406 -884.406], eps: 1.0})
Step:   17700, Reward: [-432.860 -432.860 -432.860] [88.089], Avg: [-488.380 -488.380 -488.380] (1.0000) ({r_i: None, r_t: [-862.918 -862.918 -862.918], eps: 1.0})
Step:   17800, Reward: [-419.180 -419.180 -419.180] [89.020], Avg: [-487.993 -487.993 -487.993] (1.0000) ({r_i: None, r_t: [-910.534 -910.534 -910.534], eps: 1.0})
Step:   17900, Reward: [-415.455 -415.455 -415.455] [58.003], Avg: [-487.590 -487.590 -487.590] (1.0000) ({r_i: None, r_t: [-880.303 -880.303 -880.303], eps: 1.0})
Step:   18000, Reward: [-460.997 -460.997 -460.997] [88.738], Avg: [-487.443 -487.443 -487.443] (1.0000) ({r_i: None, r_t: [-902.056 -902.056 -902.056], eps: 1.0})
Step:   18100, Reward: [-444.309 -444.309 -444.309] [88.410], Avg: [-487.206 -487.206 -487.206] (1.0000) ({r_i: None, r_t: [-880.045 -880.045 -880.045], eps: 1.0})
Step:   18200, Reward: [-421.026 -421.026 -421.026] [69.096], Avg: [-486.845 -486.845 -486.845] (1.0000) ({r_i: None, r_t: [-880.226 -880.226 -880.226], eps: 1.0})
Step:   18300, Reward: [-428.806 -428.806 -428.806] [65.020], Avg: [-486.529 -486.529 -486.529] (1.0000) ({r_i: None, r_t: [-846.005 -846.005 -846.005], eps: 1.0})
Step:   18400, Reward: [-425.998 -425.998 -425.998] [75.642], Avg: [-486.202 -486.202 -486.202] (1.0000) ({r_i: None, r_t: [-911.369 -911.369 -911.369], eps: 1.0})
Step:   18500, Reward: [-451.472 -451.472 -451.472] [125.516], Avg: [-486.015 -486.015 -486.015] (1.0000) ({r_i: None, r_t: [-856.069 -856.069 -856.069], eps: 1.0})
Step:   18600, Reward: [-445.978 -445.978 -445.978] [77.362], Avg: [-485.801 -485.801 -485.801] (1.0000) ({r_i: None, r_t: [-872.248 -872.248 -872.248], eps: 1.0})
Step:   18700, Reward: [-466.294 -466.294 -466.294] [98.475], Avg: [-485.697 -485.697 -485.697] (1.0000) ({r_i: None, r_t: [-805.954 -805.954 -805.954], eps: 1.0})
Step:   18800, Reward: [-427.749 -427.749 -427.749] [114.949], Avg: [-485.391 -485.391 -485.391] (1.0000) ({r_i: None, r_t: [-814.617 -814.617 -814.617], eps: 1.0})
Step:   18900, Reward: [-450.501 -450.501 -450.501] [69.260], Avg: [-485.207 -485.207 -485.207] (1.0000) ({r_i: None, r_t: [-818.983 -818.983 -818.983], eps: 1.0})
Step:   19000, Reward: [-427.281 -427.281 -427.281] [119.404], Avg: [-484.904 -484.904 -484.904] (1.0000) ({r_i: None, r_t: [-885.559 -885.559 -885.559], eps: 1.0})
Step:   19100, Reward: [-443.090 -443.090 -443.090] [94.536], Avg: [-484.686 -484.686 -484.686] (1.0000) ({r_i: None, r_t: [-808.007 -808.007 -808.007], eps: 1.0})
Step:   19200, Reward: [-446.663 -446.663 -446.663] [76.036], Avg: [-484.489 -484.489 -484.489] (1.0000) ({r_i: None, r_t: [-828.884 -828.884 -828.884], eps: 1.0})
Step:   19300, Reward: [-430.488 -430.488 -430.488] [107.998], Avg: [-484.211 -484.211 -484.211] (1.0000) ({r_i: None, r_t: [-897.131 -897.131 -897.131], eps: 1.0})
Step:   19400, Reward: [-438.477 -438.477 -438.477] [95.112], Avg: [-483.976 -483.976 -483.976] (1.0000) ({r_i: None, r_t: [-855.458 -855.458 -855.458], eps: 1.0})
Step:   19500, Reward: [-452.352 -452.352 -452.352] [78.345], Avg: [-483.815 -483.815 -483.815] (1.0000) ({r_i: None, r_t: [-886.525 -886.525 -886.525], eps: 1.0})
Step:   19600, Reward: [-427.182 -427.182 -427.182] [117.670], Avg: [-483.527 -483.527 -483.527] (1.0000) ({r_i: None, r_t: [-884.678 -884.678 -884.678], eps: 1.0})
Step:   19700, Reward: [-438.793 -438.793 -438.793] [103.418], Avg: [-483.301 -483.301 -483.301] (1.0000) ({r_i: None, r_t: [-839.771 -839.771 -839.771], eps: 1.0})
Step:   19800, Reward: [-405.215 -405.215 -405.215] [67.089], Avg: [-482.909 -482.909 -482.909] (1.0000) ({r_i: None, r_t: [-893.704 -893.704 -893.704], eps: 1.0})
Step:   19900, Reward: [-478.300 -478.300 -478.300] [148.854], Avg: [-482.886 -482.886 -482.886] (1.0000) ({r_i: None, r_t: [-898.637 -898.637 -898.637], eps: 1.0})
Step:   20000, Reward: [-480.209 -480.209 -480.209] [95.778], Avg: [-482.873 -482.873 -482.873] (1.0000) ({r_i: None, r_t: [-897.431 -897.431 -897.431], eps: 1.0})
Step:   20100, Reward: [-464.602 -464.602 -464.602] [78.787], Avg: [-482.782 -482.782 -482.782] (1.0000) ({r_i: None, r_t: [-884.722 -884.722 -884.722], eps: 1.0})
Step:   20200, Reward: [-455.996 -455.996 -455.996] [111.970], Avg: [-482.650 -482.650 -482.650] (1.0000) ({r_i: None, r_t: [-844.358 -844.358 -844.358], eps: 1.0})
Step:   20300, Reward: [-419.603 -419.603 -419.603] [67.081], Avg: [-482.341 -482.341 -482.341] (1.0000) ({r_i: None, r_t: [-866.809 -866.809 -866.809], eps: 1.0})
Step:   20400, Reward: [-426.631 -426.631 -426.631] [67.899], Avg: [-482.069 -482.069 -482.069] (1.0000) ({r_i: None, r_t: [-928.938 -928.938 -928.938], eps: 1.0})
Step:   20500, Reward: [-396.160 -396.160 -396.160] [69.922], Avg: [-481.652 -481.652 -481.652] (1.0000) ({r_i: None, r_t: [-894.090 -894.090 -894.090], eps: 1.0})
Step:   20600, Reward: [-433.975 -433.975 -433.975] [55.594], Avg: [-481.422 -481.422 -481.422] (1.0000) ({r_i: None, r_t: [-896.061 -896.061 -896.061], eps: 1.0})
Step:   20700, Reward: [-449.615 -449.615 -449.615] [115.364], Avg: [-481.269 -481.269 -481.269] (1.0000) ({r_i: None, r_t: [-862.448 -862.448 -862.448], eps: 1.0})
Step:   20800, Reward: [-439.119 -439.119 -439.119] [122.391], Avg: [-481.067 -481.067 -481.067] (1.0000) ({r_i: None, r_t: [-836.937 -836.937 -836.937], eps: 1.0})
Step:   20900, Reward: [-446.237 -446.237 -446.237] [63.185], Avg: [-480.902 -480.902 -480.902] (1.0000) ({r_i: None, r_t: [-898.038 -898.038 -898.038], eps: 1.0})
Step:   21000, Reward: [-436.400 -436.400 -436.400] [78.009], Avg: [-480.691 -480.691 -480.691] (1.0000) ({r_i: None, r_t: [-929.504 -929.504 -929.504], eps: 1.0})
Step:   21100, Reward: [-435.965 -435.965 -435.965] [84.839], Avg: [-480.480 -480.480 -480.480] (1.0000) ({r_i: None, r_t: [-921.427 -921.427 -921.427], eps: 1.0})
Step:   21200, Reward: [-406.053 -406.053 -406.053] [79.626], Avg: [-480.130 -480.130 -480.130] (1.0000) ({r_i: None, r_t: [-894.969 -894.969 -894.969], eps: 1.0})
Step:   21300, Reward: [-440.053 -440.053 -440.053] [54.123], Avg: [-479.943 -479.943 -479.943] (1.0000) ({r_i: None, r_t: [-877.114 -877.114 -877.114], eps: 1.0})
Step:   21400, Reward: [-445.537 -445.537 -445.537] [85.252], Avg: [-479.783 -479.783 -479.783] (1.0000) ({r_i: None, r_t: [-877.645 -877.645 -877.645], eps: 1.0})
Step:   21500, Reward: [-433.998 -433.998 -433.998] [100.846], Avg: [-479.571 -479.571 -479.571] (1.0000) ({r_i: None, r_t: [-868.227 -868.227 -868.227], eps: 1.0})
Step:   21600, Reward: [-439.513 -439.513 -439.513] [80.285], Avg: [-479.386 -479.386 -479.386] (1.0000) ({r_i: None, r_t: [-846.015 -846.015 -846.015], eps: 1.0})
Step:   21700, Reward: [-469.573 -469.573 -469.573] [127.228], Avg: [-479.341 -479.341 -479.341] (1.0000) ({r_i: None, r_t: [-854.659 -854.659 -854.659], eps: 1.0})
Step:   21800, Reward: [-443.780 -443.780 -443.780] [77.198], Avg: [-479.179 -479.179 -479.179] (1.0000) ({r_i: None, r_t: [-906.555 -906.555 -906.555], eps: 1.0})
Step:   21900, Reward: [-447.550 -447.550 -447.550] [91.212], Avg: [-479.035 -479.035 -479.035] (1.0000) ({r_i: None, r_t: [-837.043 -837.043 -837.043], eps: 1.0})
Step:   22000, Reward: [-439.490 -439.490 -439.490] [96.650], Avg: [-478.856 -478.856 -478.856] (1.0000) ({r_i: None, r_t: [-915.643 -915.643 -915.643], eps: 1.0})
Step:   22100, Reward: [-478.077 -478.077 -478.077] [99.663], Avg: [-478.853 -478.853 -478.853] (1.0000) ({r_i: None, r_t: [-896.792 -896.792 -896.792], eps: 1.0})
Step:   22200, Reward: [-456.149 -456.149 -456.149] [57.182], Avg: [-478.751 -478.751 -478.751] (1.0000) ({r_i: None, r_t: [-893.906 -893.906 -893.906], eps: 1.0})
Step:   22300, Reward: [-435.035 -435.035 -435.035] [67.128], Avg: [-478.556 -478.556 -478.556] (1.0000) ({r_i: None, r_t: [-870.010 -870.010 -870.010], eps: 1.0})
Step:   22400, Reward: [-410.843 -410.843 -410.843] [88.520], Avg: [-478.255 -478.255 -478.255] (1.0000) ({r_i: None, r_t: [-847.019 -847.019 -847.019], eps: 1.0})
Step:   22500, Reward: [-499.975 -499.975 -499.975] [83.148], Avg: [-478.351 -478.351 -478.351] (1.0000) ({r_i: None, r_t: [-923.046 -923.046 -923.046], eps: 1.0})
Step:   22600, Reward: [-450.038 -450.038 -450.038] [112.969], Avg: [-478.226 -478.226 -478.226] (1.0000) ({r_i: None, r_t: [-887.583 -887.583 -887.583], eps: 1.0})
Step:   22700, Reward: [-426.398 -426.398 -426.398] [79.008], Avg: [-477.999 -477.999 -477.999] (1.0000) ({r_i: None, r_t: [-856.011 -856.011 -856.011], eps: 1.0})
Step:   22800, Reward: [-415.611 -415.611 -415.611] [107.980], Avg: [-477.727 -477.727 -477.727] (1.0000) ({r_i: None, r_t: [-865.251 -865.251 -865.251], eps: 1.0})
Step:   22900, Reward: [-442.074 -442.074 -442.074] [96.513], Avg: [-477.572 -477.572 -477.572] (1.0000) ({r_i: None, r_t: [-880.840 -880.840 -880.840], eps: 1.0})
Step:   23000, Reward: [-432.076 -432.076 -432.076] [100.371], Avg: [-477.375 -477.375 -477.375] (1.0000) ({r_i: None, r_t: [-841.849 -841.849 -841.849], eps: 1.0})
Step:   23100, Reward: [-394.805 -394.805 -394.805] [71.830], Avg: [-477.019 -477.019 -477.019] (1.0000) ({r_i: None, r_t: [-872.938 -872.938 -872.938], eps: 1.0})
Step:   23200, Reward: [-443.352 -443.352 -443.352] [103.530], Avg: [-476.874 -476.874 -476.874] (1.0000) ({r_i: None, r_t: [-805.975 -805.975 -805.975], eps: 1.0})
Step:   23300, Reward: [-465.356 -465.356 -465.356] [72.753], Avg: [-476.825 -476.825 -476.825] (1.0000) ({r_i: None, r_t: [-825.368 -825.368 -825.368], eps: 1.0})
Step:   23400, Reward: [-415.019 -415.019 -415.019] [93.579], Avg: [-476.562 -476.562 -476.562] (1.0000) ({r_i: None, r_t: [-864.210 -864.210 -864.210], eps: 1.0})
Step:   23500, Reward: [-413.769 -413.769 -413.769] [55.090], Avg: [-476.296 -476.296 -476.296] (1.0000) ({r_i: None, r_t: [-871.068 -871.068 -871.068], eps: 1.0})
Step:   23600, Reward: [-444.453 -444.453 -444.453] [113.292], Avg: [-476.162 -476.162 -476.162] (1.0000) ({r_i: None, r_t: [-809.156 -809.156 -809.156], eps: 1.0})
Step:   23700, Reward: [-457.778 -457.778 -457.778] [103.003], Avg: [-476.084 -476.084 -476.084] (1.0000) ({r_i: None, r_t: [-897.175 -897.175 -897.175], eps: 1.0})
Step:   23800, Reward: [-415.172 -415.172 -415.172] [69.280], Avg: [-475.829 -475.829 -475.829] (1.0000) ({r_i: None, r_t: [-896.466 -896.466 -896.466], eps: 1.0})
Step:   23900, Reward: [-401.528 -401.528 -401.528] [68.238], Avg: [-475.520 -475.520 -475.520] (1.0000) ({r_i: None, r_t: [-925.417 -925.417 -925.417], eps: 1.0})
Step:   24000, Reward: [-464.316 -464.316 -464.316] [83.782], Avg: [-475.473 -475.473 -475.473] (1.0000) ({r_i: None, r_t: [-854.536 -854.536 -854.536], eps: 1.0})
Step:   24100, Reward: [-436.494 -436.494 -436.494] [57.805], Avg: [-475.312 -475.312 -475.312] (1.0000) ({r_i: None, r_t: [-895.612 -895.612 -895.612], eps: 1.0})
Step:   24200, Reward: [-398.661 -398.661 -398.661] [71.708], Avg: [-474.997 -474.997 -474.997] (1.0000) ({r_i: None, r_t: [-837.984 -837.984 -837.984], eps: 1.0})
Step:   24300, Reward: [-468.948 -468.948 -468.948] [82.906], Avg: [-474.972 -474.972 -474.972] (1.0000) ({r_i: None, r_t: [-902.171 -902.171 -902.171], eps: 1.0})
Step:   24400, Reward: [-428.993 -428.993 -428.993] [103.710], Avg: [-474.784 -474.784 -474.784] (1.0000) ({r_i: None, r_t: [-913.737 -913.737 -913.737], eps: 1.0})
Step:   24500, Reward: [-416.477 -416.477 -416.477] [86.803], Avg: [-474.547 -474.547 -474.547] (1.0000) ({r_i: None, r_t: [-853.813 -853.813 -853.813], eps: 1.0})
Step:   24600, Reward: [-428.306 -428.306 -428.306] [87.193], Avg: [-474.360 -474.360 -474.360] (1.0000) ({r_i: None, r_t: [-951.083 -951.083 -951.083], eps: 1.0})
Step:   24700, Reward: [-431.550 -431.550 -431.550] [82.434], Avg: [-474.187 -474.187 -474.187] (1.0000) ({r_i: None, r_t: [-892.686 -892.686 -892.686], eps: 1.0})
Step:   24800, Reward: [-436.715 -436.715 -436.715] [71.760], Avg: [-474.037 -474.037 -474.037] (1.0000) ({r_i: None, r_t: [-942.895 -942.895 -942.895], eps: 1.0})
Step:   24900, Reward: [-384.687 -384.687 -384.687] [69.286], Avg: [-473.680 -473.680 -473.680] (1.0000) ({r_i: None, r_t: [-837.049 -837.049 -837.049], eps: 1.0})
Step:   25000, Reward: [-422.767 -422.767 -422.767] [103.652], Avg: [-473.477 -473.477 -473.477] (1.0000) ({r_i: None, r_t: [-885.052 -885.052 -885.052], eps: 1.0})
Step:   25100, Reward: [-446.798 -446.798 -446.798] [99.493], Avg: [-473.371 -473.371 -473.371] (1.0000) ({r_i: None, r_t: [-917.848 -917.848 -917.848], eps: 1.0})
Step:   25200, Reward: [-411.685 -411.685 -411.685] [69.980], Avg: [-473.127 -473.127 -473.127] (1.0000) ({r_i: None, r_t: [-855.238 -855.238 -855.238], eps: 1.0})
Step:   25300, Reward: [-430.934 -430.934 -430.934] [101.053], Avg: [-472.961 -472.961 -472.961] (1.0000) ({r_i: None, r_t: [-867.538 -867.538 -867.538], eps: 1.0})
Step:   25400, Reward: [-431.996 -431.996 -431.996] [74.009], Avg: [-472.800 -472.800 -472.800] (1.0000) ({r_i: None, r_t: [-829.918 -829.918 -829.918], eps: 1.0})
Step:   25500, Reward: [-436.418 -436.418 -436.418] [70.070], Avg: [-472.658 -472.658 -472.658] (1.0000) ({r_i: None, r_t: [-867.511 -867.511 -867.511], eps: 1.0})
Step:   25600, Reward: [-464.982 -464.982 -464.982] [81.182], Avg: [-472.628 -472.628 -472.628] (1.0000) ({r_i: None, r_t: [-871.516 -871.516 -871.516], eps: 1.0})
Step:   25700, Reward: [-466.686 -466.686 -466.686] [91.664], Avg: [-472.605 -472.605 -472.605] (1.0000) ({r_i: None, r_t: [-824.409 -824.409 -824.409], eps: 1.0})
Step:   25800, Reward: [-422.383 -422.383 -422.383] [77.171], Avg: [-472.411 -472.411 -472.411] (1.0000) ({r_i: None, r_t: [-911.650 -911.650 -911.650], eps: 1.0})
Step:   25900, Reward: [-456.795 -456.795 -456.795] [94.780], Avg: [-472.351 -472.351 -472.351] (1.0000) ({r_i: None, r_t: [-897.490 -897.490 -897.490], eps: 1.0})
Step:   26000, Reward: [-448.718 -448.718 -448.718] [90.536], Avg: [-472.261 -472.261 -472.261] (1.0000) ({r_i: None, r_t: [-905.336 -905.336 -905.336], eps: 1.0})
Step:   26100, Reward: [-437.549 -437.549 -437.549] [97.914], Avg: [-472.128 -472.128 -472.128] (1.0000) ({r_i: None, r_t: [-848.261 -848.261 -848.261], eps: 1.0})
Step:   26200, Reward: [-468.753 -468.753 -468.753] [80.742], Avg: [-472.115 -472.115 -472.115] (1.0000) ({r_i: None, r_t: [-898.933 -898.933 -898.933], eps: 1.0})
Step:   26300, Reward: [-482.585 -482.585 -482.585] [92.971], Avg: [-472.155 -472.155 -472.155] (1.0000) ({r_i: None, r_t: [-815.906 -815.906 -815.906], eps: 1.0})
Step:   26400, Reward: [-458.171 -458.171 -458.171] [91.636], Avg: [-472.102 -472.102 -472.102] (1.0000) ({r_i: None, r_t: [-835.066 -835.066 -835.066], eps: 1.0})
Step:   26500, Reward: [-464.266 -464.266 -464.266] [103.227], Avg: [-472.073 -472.073 -472.073] (1.0000) ({r_i: None, r_t: [-915.515 -915.515 -915.515], eps: 1.0})
Step:   26600, Reward: [-441.050 -441.050 -441.050] [85.500], Avg: [-471.957 -471.957 -471.957] (1.0000) ({r_i: None, r_t: [-882.746 -882.746 -882.746], eps: 1.0})
Step:   26700, Reward: [-416.215 -416.215 -416.215] [88.720], Avg: [-471.749 -471.749 -471.749] (1.0000) ({r_i: None, r_t: [-873.309 -873.309 -873.309], eps: 1.0})
Step:   26800, Reward: [-435.316 -435.316 -435.316] [54.815], Avg: [-471.613 -471.613 -471.613] (1.0000) ({r_i: None, r_t: [-820.121 -820.121 -820.121], eps: 1.0})
Step:   26900, Reward: [-464.619 -464.619 -464.619] [75.925], Avg: [-471.587 -471.587 -471.587] (1.0000) ({r_i: None, r_t: [-834.476 -834.476 -834.476], eps: 1.0})
Step:   27000, Reward: [-483.800 -483.800 -483.800] [74.504], Avg: [-471.632 -471.632 -471.632] (1.0000) ({r_i: None, r_t: [-898.371 -898.371 -898.371], eps: 1.0})
Step:   27100, Reward: [-472.833 -472.833 -472.833] [64.528], Avg: [-471.637 -471.637 -471.637] (1.0000) ({r_i: None, r_t: [-861.296 -861.296 -861.296], eps: 1.0})
Step:   27200, Reward: [-455.082 -455.082 -455.082] [63.136], Avg: [-471.576 -471.576 -471.576] (1.0000) ({r_i: None, r_t: [-899.725 -899.725 -899.725], eps: 1.0})
Step:   27300, Reward: [-453.264 -453.264 -453.264] [71.323], Avg: [-471.509 -471.509 -471.509] (1.0000) ({r_i: None, r_t: [-874.586 -874.586 -874.586], eps: 1.0})
Step:   27400, Reward: [-487.786 -487.786 -487.786] [89.650], Avg: [-471.569 -471.569 -471.569] (1.0000) ({r_i: None, r_t: [-968.526 -968.526 -968.526], eps: 1.0})
Step:   27500, Reward: [-468.231 -468.231 -468.231] [125.945], Avg: [-471.556 -471.556 -471.556] (1.0000) ({r_i: None, r_t: [-854.166 -854.166 -854.166], eps: 1.0})
Step:   27600, Reward: [-451.439 -451.439 -451.439] [78.429], Avg: [-471.484 -471.484 -471.484] (1.0000) ({r_i: None, r_t: [-902.967 -902.967 -902.967], eps: 1.0})
Step:   27700, Reward: [-483.271 -483.271 -483.271] [101.868], Avg: [-471.526 -471.526 -471.526] (1.0000) ({r_i: None, r_t: [-945.538 -945.538 -945.538], eps: 1.0})
Step:   27800, Reward: [-429.487 -429.487 -429.487] [53.589], Avg: [-471.376 -471.376 -471.376] (1.0000) ({r_i: None, r_t: [-899.073 -899.073 -899.073], eps: 1.0})
Step:   27900, Reward: [-438.009 -438.009 -438.009] [84.708], Avg: [-471.256 -471.256 -471.256] (1.0000) ({r_i: None, r_t: [-927.620 -927.620 -927.620], eps: 1.0})
Step:   28000, Reward: [-476.202 -476.202 -476.202] [85.964], Avg: [-471.274 -471.274 -471.274] (1.0000) ({r_i: None, r_t: [-924.280 -924.280 -924.280], eps: 1.0})
Step:   28100, Reward: [-434.535 -434.535 -434.535] [84.656], Avg: [-471.144 -471.144 -471.144] (1.0000) ({r_i: None, r_t: [-915.778 -915.778 -915.778], eps: 1.0})
Step:   28200, Reward: [-459.370 -459.370 -459.370] [111.515], Avg: [-471.102 -471.102 -471.102] (1.0000) ({r_i: None, r_t: [-853.753 -853.753 -853.753], eps: 1.0})
Step:   28300, Reward: [-426.189 -426.189 -426.189] [129.969], Avg: [-470.944 -470.944 -470.944] (1.0000) ({r_i: None, r_t: [-910.408 -910.408 -910.408], eps: 1.0})
Step:   28400, Reward: [-443.171 -443.171 -443.171] [73.795], Avg: [-470.847 -470.847 -470.847] (1.0000) ({r_i: None, r_t: [-854.713 -854.713 -854.713], eps: 1.0})
Step:   28500, Reward: [-473.674 -473.674 -473.674] [81.874], Avg: [-470.856 -470.856 -470.856] (1.0000) ({r_i: None, r_t: [-964.349 -964.349 -964.349], eps: 1.0})
Step:   28600, Reward: [-522.182 -522.182 -522.182] [130.178], Avg: [-471.035 -471.035 -471.035] (1.0000) ({r_i: None, r_t: [-931.438 -931.438 -931.438], eps: 1.0})
Step:   28700, Reward: [-464.464 -464.464 -464.464] [81.017], Avg: [-471.012 -471.012 -471.012] (1.0000) ({r_i: None, r_t: [-875.299 -875.299 -875.299], eps: 1.0})
Step:   28800, Reward: [-458.901 -458.901 -458.901] [70.982], Avg: [-470.971 -470.971 -470.971] (1.0000) ({r_i: None, r_t: [-834.590 -834.590 -834.590], eps: 1.0})
Step:   28900, Reward: [-461.627 -461.627 -461.627] [98.657], Avg: [-470.938 -470.938 -470.938] (1.0000) ({r_i: None, r_t: [-899.815 -899.815 -899.815], eps: 1.0})
Step:   29000, Reward: [-417.831 -417.831 -417.831] [74.770], Avg: [-470.756 -470.756 -470.756] (1.0000) ({r_i: None, r_t: [-883.873 -883.873 -883.873], eps: 1.0})
Step:   29100, Reward: [-499.010 -499.010 -499.010] [109.206], Avg: [-470.853 -470.853 -470.853] (1.0000) ({r_i: None, r_t: [-926.702 -926.702 -926.702], eps: 1.0})
Step:   29200, Reward: [-481.340 -481.340 -481.340] [100.266], Avg: [-470.888 -470.888 -470.888] (1.0000) ({r_i: None, r_t: [-910.467 -910.467 -910.467], eps: 1.0})
Step:   29300, Reward: [-446.041 -446.041 -446.041] [93.525], Avg: [-470.804 -470.804 -470.804] (1.0000) ({r_i: None, r_t: [-837.922 -837.922 -837.922], eps: 1.0})
Step:   29400, Reward: [-468.723 -468.723 -468.723] [56.482], Avg: [-470.797 -470.797 -470.797] (1.0000) ({r_i: None, r_t: [-871.009 -871.009 -871.009], eps: 1.0})
Step:   29500, Reward: [-436.483 -436.483 -436.483] [69.423], Avg: [-470.681 -470.681 -470.681] (1.0000) ({r_i: None, r_t: [-826.470 -826.470 -826.470], eps: 1.0})
Step:   29600, Reward: [-424.725 -424.725 -424.725] [64.767], Avg: [-470.526 -470.526 -470.526] (1.0000) ({r_i: None, r_t: [-905.565 -905.565 -905.565], eps: 1.0})
Step:   29700, Reward: [-443.555 -443.555 -443.555] [93.134], Avg: [-470.436 -470.436 -470.436] (1.0000) ({r_i: None, r_t: [-873.097 -873.097 -873.097], eps: 1.0})
Step:   29800, Reward: [-451.382 -451.382 -451.382] [78.271], Avg: [-470.372 -470.372 -470.372] (1.0000) ({r_i: None, r_t: [-888.357 -888.357 -888.357], eps: 1.0})
Step:   29900, Reward: [-453.095 -453.095 -453.095] [104.891], Avg: [-470.314 -470.314 -470.314] (1.0000) ({r_i: None, r_t: [-846.205 -846.205 -846.205], eps: 1.0})
Step:   30000, Reward: [-426.876 -426.876 -426.876] [64.073], Avg: [-470.170 -470.170 -470.170] (1.0000) ({r_i: None, r_t: [-899.539 -899.539 -899.539], eps: 1.0})
Step:   30100, Reward: [-490.648 -490.648 -490.648] [97.892], Avg: [-470.238 -470.238 -470.238] (1.0000) ({r_i: None, r_t: [-839.661 -839.661 -839.661], eps: 1.0})
Step:   30200, Reward: [-505.339 -505.339 -505.339] [112.903], Avg: [-470.354 -470.354 -470.354] (1.0000) ({r_i: None, r_t: [-922.720 -922.720 -922.720], eps: 1.0})
Step:   30300, Reward: [-411.590 -411.590 -411.590] [76.416], Avg: [-470.160 -470.160 -470.160] (1.0000) ({r_i: None, r_t: [-874.105 -874.105 -874.105], eps: 1.0})
Step:   30400, Reward: [-475.377 -475.377 -475.377] [107.732], Avg: [-470.177 -470.177 -470.177] (1.0000) ({r_i: None, r_t: [-915.910 -915.910 -915.910], eps: 1.0})
Step:   30500, Reward: [-442.634 -442.634 -442.634] [86.354], Avg: [-470.087 -470.087 -470.087] (1.0000) ({r_i: None, r_t: [-890.888 -890.888 -890.888], eps: 1.0})
Step:   30600, Reward: [-444.455 -444.455 -444.455] [77.053], Avg: [-470.004 -470.004 -470.004] (1.0000) ({r_i: None, r_t: [-852.959 -852.959 -852.959], eps: 1.0})
Step:   30700, Reward: [-471.490 -471.490 -471.490] [107.704], Avg: [-470.009 -470.009 -470.009] (1.0000) ({r_i: None, r_t: [-873.851 -873.851 -873.851], eps: 1.0})
Step:   30800, Reward: [-475.708 -475.708 -475.708] [93.826], Avg: [-470.027 -470.027 -470.027] (1.0000) ({r_i: None, r_t: [-934.368 -934.368 -934.368], eps: 1.0})
Step:   30900, Reward: [-430.859 -430.859 -430.859] [73.710], Avg: [-469.901 -469.901 -469.901] (1.0000) ({r_i: None, r_t: [-922.212 -922.212 -922.212], eps: 1.0})
Step:   31000, Reward: [-476.799 -476.799 -476.799] [104.944], Avg: [-469.923 -469.923 -469.923] (1.0000) ({r_i: None, r_t: [-931.390 -931.390 -931.390], eps: 1.0})
Step:   31100, Reward: [-417.142 -417.142 -417.142] [92.836], Avg: [-469.754 -469.754 -469.754] (1.0000) ({r_i: None, r_t: [-894.888 -894.888 -894.888], eps: 1.0})
Step:   31200, Reward: [-475.364 -475.364 -475.364] [110.857], Avg: [-469.772 -469.772 -469.772] (1.0000) ({r_i: None, r_t: [-868.473 -868.473 -868.473], eps: 1.0})
Step:   31300, Reward: [-454.279 -454.279 -454.279] [94.088], Avg: [-469.722 -469.722 -469.722] (1.0000) ({r_i: None, r_t: [-887.473 -887.473 -887.473], eps: 1.0})
Step:   31400, Reward: [-446.742 -446.742 -446.742] [89.698], Avg: [-469.649 -469.649 -469.649] (1.0000) ({r_i: None, r_t: [-881.800 -881.800 -881.800], eps: 1.0})
Step:   31500, Reward: [-447.741 -447.741 -447.741] [80.015], Avg: [-469.580 -469.580 -469.580] (1.0000) ({r_i: None, r_t: [-944.397 -944.397 -944.397], eps: 1.0})
Step:   31600, Reward: [-434.772 -434.772 -434.772] [72.371], Avg: [-469.470 -469.470 -469.470] (1.0000) ({r_i: None, r_t: [-857.400 -857.400 -857.400], eps: 1.0})
Step:   31700, Reward: [-448.081 -448.081 -448.081] [113.135], Avg: [-469.403 -469.403 -469.403] (1.0000) ({r_i: None, r_t: [-882.752 -882.752 -882.752], eps: 1.0})
Step:   31800, Reward: [-484.309 -484.309 -484.309] [109.667], Avg: [-469.450 -469.450 -469.450] (1.0000) ({r_i: None, r_t: [-890.736 -890.736 -890.736], eps: 1.0})
Step:   31900, Reward: [-440.650 -440.650 -440.650] [68.072], Avg: [-469.360 -469.360 -469.360] (1.0000) ({r_i: None, r_t: [-907.830 -907.830 -907.830], eps: 1.0})
Step:   32000, Reward: [-443.808 -443.808 -443.808] [94.447], Avg: [-469.280 -469.280 -469.280] (1.0000) ({r_i: None, r_t: [-868.846 -868.846 -868.846], eps: 1.0})
Step:   32100, Reward: [-459.427 -459.427 -459.427] [80.007], Avg: [-469.250 -469.250 -469.250] (1.0000) ({r_i: None, r_t: [-951.557 -951.557 -951.557], eps: 1.0})
Step:   32200, Reward: [-432.243 -432.243 -432.243] [84.946], Avg: [-469.135 -469.135 -469.135] (1.0000) ({r_i: None, r_t: [-922.559 -922.559 -922.559], eps: 1.0})
Step:   32300, Reward: [-447.412 -447.412 -447.412] [74.768], Avg: [-469.068 -469.068 -469.068] (1.0000) ({r_i: None, r_t: [-916.650 -916.650 -916.650], eps: 1.0})
Step:   32400, Reward: [-466.969 -466.969 -466.969] [114.661], Avg: [-469.062 -469.062 -469.062] (1.0000) ({r_i: None, r_t: [-858.586 -858.586 -858.586], eps: 1.0})
Step:   32500, Reward: [-447.772 -447.772 -447.772] [113.115], Avg: [-468.996 -468.996 -468.996] (1.0000) ({r_i: None, r_t: [-940.978 -940.978 -940.978], eps: 1.0})
Step:   32600, Reward: [-486.985 -486.985 -486.985] [94.085], Avg: [-469.051 -469.051 -469.051] (1.0000) ({r_i: None, r_t: [-916.223 -916.223 -916.223], eps: 1.0})
Step:   32700, Reward: [-443.209 -443.209 -443.209] [83.530], Avg: [-468.972 -468.972 -468.972] (1.0000) ({r_i: None, r_t: [-917.114 -917.114 -917.114], eps: 1.0})
Step:   32800, Reward: [-441.587 -441.587 -441.587] [92.748], Avg: [-468.889 -468.889 -468.889] (1.0000) ({r_i: None, r_t: [-925.915 -925.915 -925.915], eps: 1.0})
Step:   32900, Reward: [-470.305 -470.305 -470.305] [93.245], Avg: [-468.894 -468.894 -468.894] (1.0000) ({r_i: None, r_t: [-857.160 -857.160 -857.160], eps: 1.0})
Step:   33000, Reward: [-410.663 -410.663 -410.663] [67.858], Avg: [-468.718 -468.718 -468.718] (1.0000) ({r_i: None, r_t: [-874.378 -874.378 -874.378], eps: 1.0})
Step:   33100, Reward: [-442.685 -442.685 -442.685] [59.681], Avg: [-468.639 -468.639 -468.639] (1.0000) ({r_i: None, r_t: [-916.916 -916.916 -916.916], eps: 1.0})
Step:   33200, Reward: [-439.385 -439.385 -439.385] [87.705], Avg: [-468.551 -468.551 -468.551] (1.0000) ({r_i: None, r_t: [-889.249 -889.249 -889.249], eps: 1.0})
Step:   33300, Reward: [-464.269 -464.269 -464.269] [109.612], Avg: [-468.539 -468.539 -468.539] (1.0000) ({r_i: None, r_t: [-829.257 -829.257 -829.257], eps: 1.0})
Step:   33400, Reward: [-404.474 -404.474 -404.474] [60.009], Avg: [-468.347 -468.347 -468.347] (1.0000) ({r_i: None, r_t: [-824.593 -824.593 -824.593], eps: 1.0})
Step:   33500, Reward: [-412.971 -412.971 -412.971] [91.887], Avg: [-468.182 -468.182 -468.182] (1.0000) ({r_i: None, r_t: [-855.180 -855.180 -855.180], eps: 1.0})
Step:   33600, Reward: [-447.052 -447.052 -447.052] [84.631], Avg: [-468.120 -468.120 -468.120] (1.0000) ({r_i: None, r_t: [-895.996 -895.996 -895.996], eps: 1.0})
Step:   33700, Reward: [-482.090 -482.090 -482.090] [110.410], Avg: [-468.161 -468.161 -468.161] (1.0000) ({r_i: None, r_t: [-860.462 -860.462 -860.462], eps: 1.0})
Step:   33800, Reward: [-451.205 -451.205 -451.205] [99.756], Avg: [-468.111 -468.111 -468.111] (1.0000) ({r_i: None, r_t: [-885.917 -885.917 -885.917], eps: 1.0})
Step:   33900, Reward: [-448.601 -448.601 -448.601] [99.590], Avg: [-468.054 -468.054 -468.054] (1.0000) ({r_i: None, r_t: [-827.204 -827.204 -827.204], eps: 1.0})
Step:   34000, Reward: [-416.182 -416.182 -416.182] [83.355], Avg: [-467.902 -467.902 -467.902] (1.0000) ({r_i: None, r_t: [-822.265 -822.265 -822.265], eps: 1.0})
Step:   34100, Reward: [-430.360 -430.360 -430.360] [68.869], Avg: [-467.792 -467.792 -467.792] (1.0000) ({r_i: None, r_t: [-934.327 -934.327 -934.327], eps: 1.0})
Step:   34200, Reward: [-447.016 -447.016 -447.016] [82.797], Avg: [-467.731 -467.731 -467.731] (1.0000) ({r_i: None, r_t: [-866.877 -866.877 -866.877], eps: 1.0})
Step:   34300, Reward: [-448.801 -448.801 -448.801] [122.327], Avg: [-467.676 -467.676 -467.676] (1.0000) ({r_i: None, r_t: [-828.269 -828.269 -828.269], eps: 1.0})
Step:   34400, Reward: [-438.001 -438.001 -438.001] [98.417], Avg: [-467.590 -467.590 -467.590] (1.0000) ({r_i: None, r_t: [-863.571 -863.571 -863.571], eps: 1.0})
Step:   34500, Reward: [-434.314 -434.314 -434.314] [110.915], Avg: [-467.494 -467.494 -467.494] (1.0000) ({r_i: None, r_t: [-897.847 -897.847 -897.847], eps: 1.0})
Step:   34600, Reward: [-516.326 -516.326 -516.326] [120.431], Avg: [-467.635 -467.635 -467.635] (1.0000) ({r_i: None, r_t: [-934.694 -934.694 -934.694], eps: 1.0})
Step:   34700, Reward: [-483.595 -483.595 -483.595] [158.173], Avg: [-467.681 -467.681 -467.681] (1.0000) ({r_i: None, r_t: [-919.696 -919.696 -919.696], eps: 1.0})
Step:   34800, Reward: [-431.797 -431.797 -431.797] [105.952], Avg: [-467.578 -467.578 -467.578] (1.0000) ({r_i: None, r_t: [-846.896 -846.896 -846.896], eps: 1.0})
Step:   34900, Reward: [-442.037 -442.037 -442.037] [59.871], Avg: [-467.505 -467.505 -467.505] (1.0000) ({r_i: None, r_t: [-870.408 -870.408 -870.408], eps: 1.0})
Step:   35000, Reward: [-444.867 -444.867 -444.867] [76.987], Avg: [-467.440 -467.440 -467.440] (1.0000) ({r_i: None, r_t: [-917.420 -917.420 -917.420], eps: 1.0})
Step:   35100, Reward: [-457.258 -457.258 -457.258] [85.471], Avg: [-467.411 -467.411 -467.411] (1.0000) ({r_i: None, r_t: [-954.510 -954.510 -954.510], eps: 1.0})
Step:   35200, Reward: [-467.827 -467.827 -467.827] [108.128], Avg: [-467.413 -467.413 -467.413] (1.0000) ({r_i: None, r_t: [-871.896 -871.896 -871.896], eps: 1.0})
Step:   35300, Reward: [-432.711 -432.711 -432.711] [94.597], Avg: [-467.315 -467.315 -467.315] (1.0000) ({r_i: None, r_t: [-886.622 -886.622 -886.622], eps: 1.0})
Step:   35400, Reward: [-428.443 -428.443 -428.443] [103.663], Avg: [-467.205 -467.205 -467.205] (1.0000) ({r_i: None, r_t: [-929.885 -929.885 -929.885], eps: 1.0})
Step:   35500, Reward: [-440.041 -440.041 -440.041] [88.838], Avg: [-467.129 -467.129 -467.129] (1.0000) ({r_i: None, r_t: [-937.910 -937.910 -937.910], eps: 1.0})
Step:   35600, Reward: [-434.223 -434.223 -434.223] [95.839], Avg: [-467.037 -467.037 -467.037] (1.0000) ({r_i: None, r_t: [-851.951 -851.951 -851.951], eps: 1.0})
Step:   35700, Reward: [-452.263 -452.263 -452.263] [111.407], Avg: [-466.995 -466.995 -466.995] (1.0000) ({r_i: None, r_t: [-873.032 -873.032 -873.032], eps: 1.0})
Step:   35800, Reward: [-444.311 -444.311 -444.311] [105.784], Avg: [-466.932 -466.932 -466.932] (1.0000) ({r_i: None, r_t: [-860.187 -860.187 -860.187], eps: 1.0})
Step:   35900, Reward: [-448.837 -448.837 -448.837] [108.742], Avg: [-466.882 -466.882 -466.882] (1.0000) ({r_i: None, r_t: [-886.513 -886.513 -886.513], eps: 1.0})
Step:   36000, Reward: [-427.051 -427.051 -427.051] [87.164], Avg: [-466.772 -466.772 -466.772] (1.0000) ({r_i: None, r_t: [-897.340 -897.340 -897.340], eps: 1.0})
Step:   36100, Reward: [-450.019 -450.019 -450.019] [46.436], Avg: [-466.725 -466.725 -466.725] (1.0000) ({r_i: None, r_t: [-876.444 -876.444 -876.444], eps: 1.0})
Step:   36200, Reward: [-446.274 -446.274 -446.274] [112.608], Avg: [-466.669 -466.669 -466.669] (1.0000) ({r_i: None, r_t: [-874.772 -874.772 -874.772], eps: 1.0})
Step:   36300, Reward: [-434.390 -434.390 -434.390] [86.542], Avg: [-466.580 -466.580 -466.580] (1.0000) ({r_i: None, r_t: [-880.785 -880.785 -880.785], eps: 1.0})
Step:   36400, Reward: [-462.352 -462.352 -462.352] [99.654], Avg: [-466.569 -466.569 -466.569] (1.0000) ({r_i: None, r_t: [-842.929 -842.929 -842.929], eps: 1.0})
Step:   36500, Reward: [-474.858 -474.858 -474.858] [74.230], Avg: [-466.591 -466.591 -466.591] (1.0000) ({r_i: None, r_t: [-848.493 -848.493 -848.493], eps: 1.0})
Step:   36600, Reward: [-437.280 -437.280 -437.280] [91.335], Avg: [-466.511 -466.511 -466.511] (1.0000) ({r_i: None, r_t: [-889.694 -889.694 -889.694], eps: 1.0})
Step:   36700, Reward: [-467.267 -467.267 -467.267] [76.407], Avg: [-466.513 -466.513 -466.513] (1.0000) ({r_i: None, r_t: [-879.671 -879.671 -879.671], eps: 1.0})
Step:   36800, Reward: [-400.559 -400.559 -400.559] [70.808], Avg: [-466.335 -466.335 -466.335] (1.0000) ({r_i: None, r_t: [-872.781 -872.781 -872.781], eps: 1.0})
Step:   36900, Reward: [-435.842 -435.842 -435.842] [76.059], Avg: [-466.252 -466.252 -466.252] (1.0000) ({r_i: None, r_t: [-867.135 -867.135 -867.135], eps: 1.0})
Step:   37000, Reward: [-445.525 -445.525 -445.525] [82.290], Avg: [-466.196 -466.196 -466.196] (1.0000) ({r_i: None, r_t: [-915.665 -915.665 -915.665], eps: 1.0})
Step:   37100, Reward: [-440.631 -440.631 -440.631] [94.998], Avg: [-466.128 -466.128 -466.128] (1.0000) ({r_i: None, r_t: [-888.007 -888.007 -888.007], eps: 1.0})
Step:   37200, Reward: [-448.064 -448.064 -448.064] [88.184], Avg: [-466.079 -466.079 -466.079] (1.0000) ({r_i: None, r_t: [-820.738 -820.738 -820.738], eps: 1.0})
Step:   37300, Reward: [-422.920 -422.920 -422.920] [95.530], Avg: [-465.964 -465.964 -465.964] (1.0000) ({r_i: None, r_t: [-854.152 -854.152 -854.152], eps: 1.0})
Step:   37400, Reward: [-469.150 -469.150 -469.150] [86.534], Avg: [-465.972 -465.972 -465.972] (1.0000) ({r_i: None, r_t: [-855.274 -855.274 -855.274], eps: 1.0})
Step:   37500, Reward: [-457.178 -457.178 -457.178] [80.728], Avg: [-465.949 -465.949 -465.949] (1.0000) ({r_i: None, r_t: [-907.108 -907.108 -907.108], eps: 1.0})
Step:   37600, Reward: [-441.878 -441.878 -441.878] [100.201], Avg: [-465.885 -465.885 -465.885] (1.0000) ({r_i: None, r_t: [-848.556 -848.556 -848.556], eps: 1.0})
Step:   37700, Reward: [-487.298 -487.298 -487.298] [77.800], Avg: [-465.942 -465.942 -465.942] (1.0000) ({r_i: None, r_t: [-814.582 -814.582 -814.582], eps: 1.0})
Step:   37800, Reward: [-475.879 -475.879 -475.879] [115.178], Avg: [-465.968 -465.968 -465.968] (1.0000) ({r_i: None, r_t: [-934.608 -934.608 -934.608], eps: 1.0})
Step:   37900, Reward: [-447.278 -447.278 -447.278] [94.584], Avg: [-465.919 -465.919 -465.919] (1.0000) ({r_i: None, r_t: [-816.583 -816.583 -816.583], eps: 1.0})
Step:   38000, Reward: [-422.811 -422.811 -422.811] [92.260], Avg: [-465.806 -465.806 -465.806] (1.0000) ({r_i: None, r_t: [-871.341 -871.341 -871.341], eps: 1.0})
Step:   38100, Reward: [-434.854 -434.854 -434.854] [84.340], Avg: [-465.725 -465.725 -465.725] (1.0000) ({r_i: None, r_t: [-880.122 -880.122 -880.122], eps: 1.0})
Step:   38200, Reward: [-463.448 -463.448 -463.448] [99.867], Avg: [-465.719 -465.719 -465.719] (1.0000) ({r_i: None, r_t: [-869.335 -869.335 -869.335], eps: 1.0})
Step:   38300, Reward: [-506.269 -506.269 -506.269] [104.195], Avg: [-465.824 -465.824 -465.824] (1.0000) ({r_i: None, r_t: [-858.176 -858.176 -858.176], eps: 1.0})
Step:   38400, Reward: [-469.277 -469.277 -469.277] [118.961], Avg: [-465.833 -465.833 -465.833] (1.0000) ({r_i: None, r_t: [-846.138 -846.138 -846.138], eps: 1.0})
Step:   38500, Reward: [-434.226 -434.226 -434.226] [74.715], Avg: [-465.751 -465.751 -465.751] (1.0000) ({r_i: None, r_t: [-906.629 -906.629 -906.629], eps: 1.0})
Step:   38600, Reward: [-438.719 -438.719 -438.719] [75.766], Avg: [-465.682 -465.682 -465.682] (1.0000) ({r_i: None, r_t: [-899.759 -899.759 -899.759], eps: 1.0})
Step:   38700, Reward: [-430.795 -430.795 -430.795] [96.215], Avg: [-465.592 -465.592 -465.592] (1.0000) ({r_i: None, r_t: [-851.830 -851.830 -851.830], eps: 1.0})
Step:   38800, Reward: [-395.521 -395.521 -395.521] [68.649], Avg: [-465.412 -465.412 -465.412] (1.0000) ({r_i: None, r_t: [-935.469 -935.469 -935.469], eps: 1.0})
Step:   38900, Reward: [-440.773 -440.773 -440.773] [102.489], Avg: [-465.348 -465.348 -465.348] (1.0000) ({r_i: None, r_t: [-881.594 -881.594 -881.594], eps: 1.0})
Step:   39000, Reward: [-425.866 -425.866 -425.866] [79.259], Avg: [-465.247 -465.247 -465.247] (1.0000) ({r_i: None, r_t: [-890.218 -890.218 -890.218], eps: 1.0})
Step:   39100, Reward: [-401.178 -401.178 -401.178] [76.697], Avg: [-465.084 -465.084 -465.084] (1.0000) ({r_i: None, r_t: [-860.436 -860.436 -860.436], eps: 1.0})
Step:   39200, Reward: [-441.578 -441.578 -441.578] [100.803], Avg: [-465.024 -465.024 -465.024] (1.0000) ({r_i: None, r_t: [-896.000 -896.000 -896.000], eps: 1.0})
Step:   39300, Reward: [-472.762 -472.762 -472.762] [112.981], Avg: [-465.044 -465.044 -465.044] (1.0000) ({r_i: None, r_t: [-863.371 -863.371 -863.371], eps: 1.0})
Step:   39400, Reward: [-444.971 -444.971 -444.971] [85.622], Avg: [-464.993 -464.993 -464.993] (1.0000) ({r_i: None, r_t: [-873.726 -873.726 -873.726], eps: 1.0})
Step:   39500, Reward: [-411.905 -411.905 -411.905] [79.594], Avg: [-464.859 -464.859 -464.859] (1.0000) ({r_i: None, r_t: [-883.521 -883.521 -883.521], eps: 1.0})
Step:   39600, Reward: [-474.688 -474.688 -474.688] [101.841], Avg: [-464.884 -464.884 -464.884] (1.0000) ({r_i: None, r_t: [-905.365 -905.365 -905.365], eps: 1.0})
Step:   39700, Reward: [-446.457 -446.457 -446.457] [107.271], Avg: [-464.837 -464.837 -464.837] (1.0000) ({r_i: None, r_t: [-957.494 -957.494 -957.494], eps: 1.0})
Step:   39800, Reward: [-401.710 -401.710 -401.710] [83.940], Avg: [-464.679 -464.679 -464.679] (1.0000) ({r_i: None, r_t: [-884.244 -884.244 -884.244], eps: 1.0})
Step:   39900, Reward: [-427.635 -427.635 -427.635] [93.379], Avg: [-464.587 -464.587 -464.587] (1.0000) ({r_i: None, r_t: [-908.170 -908.170 -908.170], eps: 1.0})
Step:   40000, Reward: [-479.157 -479.157 -479.157] [102.048], Avg: [-464.623 -464.623 -464.623] (1.0000) ({r_i: None, r_t: [-805.714 -805.714 -805.714], eps: 1.0})
Step:   40100, Reward: [-429.201 -429.201 -429.201] [65.007], Avg: [-464.535 -464.535 -464.535] (1.0000) ({r_i: None, r_t: [-848.561 -848.561 -848.561], eps: 1.0})
Step:   40200, Reward: [-486.410 -486.410 -486.410] [103.482], Avg: [-464.589 -464.589 -464.589] (1.0000) ({r_i: None, r_t: [-906.230 -906.230 -906.230], eps: 1.0})
Step:   40300, Reward: [-397.027 -397.027 -397.027] [77.044], Avg: [-464.422 -464.422 -464.422] (1.0000) ({r_i: None, r_t: [-849.964 -849.964 -849.964], eps: 1.0})
Step:   40400, Reward: [-406.285 -406.285 -406.285] [90.668], Avg: [-464.278 -464.278 -464.278] (1.0000) ({r_i: None, r_t: [-847.700 -847.700 -847.700], eps: 1.0})
Step:   40500, Reward: [-420.275 -420.275 -420.275] [74.883], Avg: [-464.170 -464.170 -464.170] (1.0000) ({r_i: None, r_t: [-844.967 -844.967 -844.967], eps: 1.0})
Step:   40600, Reward: [-443.842 -443.842 -443.842] [102.263], Avg: [-464.120 -464.120 -464.120] (1.0000) ({r_i: None, r_t: [-853.839 -853.839 -853.839], eps: 1.0})
Step:   40700, Reward: [-461.569 -461.569 -461.569] [119.667], Avg: [-464.114 -464.114 -464.114] (1.0000) ({r_i: None, r_t: [-877.048 -877.048 -877.048], eps: 1.0})
Step:   40800, Reward: [-422.637 -422.637 -422.637] [128.488], Avg: [-464.012 -464.012 -464.012] (1.0000) ({r_i: None, r_t: [-913.447 -913.447 -913.447], eps: 1.0})
Step:   40900, Reward: [-472.338 -472.338 -472.338] [91.213], Avg: [-464.033 -464.033 -464.033] (1.0000) ({r_i: None, r_t: [-836.678 -836.678 -836.678], eps: 1.0})
Step:   41000, Reward: [-423.003 -423.003 -423.003] [84.981], Avg: [-463.933 -463.933 -463.933] (1.0000) ({r_i: None, r_t: [-858.593 -858.593 -858.593], eps: 1.0})
Step:   41100, Reward: [-425.974 -425.974 -425.974] [111.480], Avg: [-463.841 -463.841 -463.841] (1.0000) ({r_i: None, r_t: [-833.677 -833.677 -833.677], eps: 1.0})
Step:   41200, Reward: [-419.537 -419.537 -419.537] [117.886], Avg: [-463.733 -463.733 -463.733] (1.0000) ({r_i: None, r_t: [-900.525 -900.525 -900.525], eps: 1.0})
Step:   41300, Reward: [-466.566 -466.566 -466.566] [151.000], Avg: [-463.740 -463.740 -463.740] (1.0000) ({r_i: None, r_t: [-923.192 -923.192 -923.192], eps: 1.0})
Step:   41400, Reward: [-435.845 -435.845 -435.845] [97.352], Avg: [-463.673 -463.673 -463.673] (1.0000) ({r_i: None, r_t: [-890.612 -890.612 -890.612], eps: 1.0})
Step:   41500, Reward: [-458.896 -458.896 -458.896] [80.250], Avg: [-463.661 -463.661 -463.661] (1.0000) ({r_i: None, r_t: [-892.805 -892.805 -892.805], eps: 1.0})
Step:   41600, Reward: [-474.626 -474.626 -474.626] [113.557], Avg: [-463.688 -463.688 -463.688] (1.0000) ({r_i: None, r_t: [-877.577 -877.577 -877.577], eps: 1.0})
Step:   41700, Reward: [-428.112 -428.112 -428.112] [81.742], Avg: [-463.603 -463.603 -463.603] (1.0000) ({r_i: None, r_t: [-813.544 -813.544 -813.544], eps: 1.0})
Step:   41800, Reward: [-438.491 -438.491 -438.491] [95.866], Avg: [-463.543 -463.543 -463.543] (1.0000) ({r_i: None, r_t: [-840.948 -840.948 -840.948], eps: 1.0})
Step:   41900, Reward: [-432.222 -432.222 -432.222] [73.174], Avg: [-463.468 -463.468 -463.468] (1.0000) ({r_i: None, r_t: [-928.495 -928.495 -928.495], eps: 1.0})
Step:   42000, Reward: [-422.701 -422.701 -422.701] [92.202], Avg: [-463.371 -463.371 -463.371] (1.0000) ({r_i: None, r_t: [-877.316 -877.316 -877.316], eps: 1.0})
Step:   42100, Reward: [-401.972 -401.972 -401.972] [83.619], Avg: [-463.226 -463.226 -463.226] (1.0000) ({r_i: None, r_t: [-858.999 -858.999 -858.999], eps: 1.0})
Step:   42200, Reward: [-471.906 -471.906 -471.906] [144.252], Avg: [-463.246 -463.246 -463.246] (1.0000) ({r_i: None, r_t: [-906.112 -906.112 -906.112], eps: 1.0})
Step:   42300, Reward: [-390.545 -390.545 -390.545] [69.428], Avg: [-463.075 -463.075 -463.075] (1.0000) ({r_i: None, r_t: [-890.152 -890.152 -890.152], eps: 1.0})
Step:   42400, Reward: [-470.955 -470.955 -470.955] [114.609], Avg: [-463.093 -463.093 -463.093] (1.0000) ({r_i: None, r_t: [-885.848 -885.848 -885.848], eps: 1.0})
Step:   42500, Reward: [-403.006 -403.006 -403.006] [67.014], Avg: [-462.952 -462.952 -462.952] (1.0000) ({r_i: None, r_t: [-890.344 -890.344 -890.344], eps: 1.0})
Step:   42600, Reward: [-426.929 -426.929 -426.929] [79.845], Avg: [-462.868 -462.868 -462.868] (1.0000) ({r_i: None, r_t: [-864.654 -864.654 -864.654], eps: 1.0})
Step:   42700, Reward: [-425.076 -425.076 -425.076] [93.165], Avg: [-462.780 -462.780 -462.780] (1.0000) ({r_i: None, r_t: [-858.830 -858.830 -858.830], eps: 1.0})
Step:   42800, Reward: [-415.214 -415.214 -415.214] [111.838], Avg: [-462.669 -462.669 -462.669] (1.0000) ({r_i: None, r_t: [-841.618 -841.618 -841.618], eps: 1.0})
Step:   42900, Reward: [-477.551 -477.551 -477.551] [131.109], Avg: [-462.703 -462.703 -462.703] (1.0000) ({r_i: None, r_t: [-870.632 -870.632 -870.632], eps: 1.0})
Step:   43000, Reward: [-424.786 -424.786 -424.786] [75.080], Avg: [-462.615 -462.615 -462.615] (1.0000) ({r_i: None, r_t: [-802.016 -802.016 -802.016], eps: 1.0})
Step:   43100, Reward: [-443.276 -443.276 -443.276] [76.257], Avg: [-462.571 -462.571 -462.571] (1.0000) ({r_i: None, r_t: [-850.746 -850.746 -850.746], eps: 1.0})
Step:   43200, Reward: [-440.659 -440.659 -440.659] [105.576], Avg: [-462.520 -462.520 -462.520] (1.0000) ({r_i: None, r_t: [-889.313 -889.313 -889.313], eps: 1.0})
Step:   43300, Reward: [-424.416 -424.416 -424.416] [76.440], Avg: [-462.432 -462.432 -462.432] (1.0000) ({r_i: None, r_t: [-876.249 -876.249 -876.249], eps: 1.0})
Step:   43400, Reward: [-413.372 -413.372 -413.372] [102.241], Avg: [-462.320 -462.320 -462.320] (1.0000) ({r_i: None, r_t: [-868.754 -868.754 -868.754], eps: 1.0})
Step:   43500, Reward: [-424.021 -424.021 -424.021] [90.111], Avg: [-462.232 -462.232 -462.232] (1.0000) ({r_i: None, r_t: [-836.212 -836.212 -836.212], eps: 1.0})
Step:   43600, Reward: [-410.687 -410.687 -410.687] [94.305], Avg: [-462.114 -462.114 -462.114] (1.0000) ({r_i: None, r_t: [-865.170 -865.170 -865.170], eps: 1.0})
Step:   43700, Reward: [-408.437 -408.437 -408.437] [102.931], Avg: [-461.991 -461.991 -461.991] (1.0000) ({r_i: None, r_t: [-949.667 -949.667 -949.667], eps: 1.0})
Step:   43800, Reward: [-450.514 -450.514 -450.514] [67.112], Avg: [-461.965 -461.965 -461.965] (1.0000) ({r_i: None, r_t: [-918.885 -918.885 -918.885], eps: 1.0})
Step:   43900, Reward: [-439.355 -439.355 -439.355] [81.435], Avg: [-461.914 -461.914 -461.914] (1.0000) ({r_i: None, r_t: [-926.193 -926.193 -926.193], eps: 1.0})
Step:   44000, Reward: [-469.867 -469.867 -469.867] [112.334], Avg: [-461.932 -461.932 -461.932] (1.0000) ({r_i: None, r_t: [-875.500 -875.500 -875.500], eps: 1.0})
Step:   44100, Reward: [-441.612 -441.612 -441.612] [106.393], Avg: [-461.886 -461.886 -461.886] (1.0000) ({r_i: None, r_t: [-886.658 -886.658 -886.658], eps: 1.0})
Step:   44200, Reward: [-437.696 -437.696 -437.696] [97.910], Avg: [-461.831 -461.831 -461.831] (1.0000) ({r_i: None, r_t: [-883.208 -883.208 -883.208], eps: 1.0})
Step:   44300, Reward: [-426.913 -426.913 -426.913] [99.342], Avg: [-461.752 -461.752 -461.752] (1.0000) ({r_i: None, r_t: [-919.179 -919.179 -919.179], eps: 1.0})
Step:   44400, Reward: [-424.587 -424.587 -424.587] [66.355], Avg: [-461.669 -461.669 -461.669] (1.0000) ({r_i: None, r_t: [-911.243 -911.243 -911.243], eps: 1.0})
Step:   44500, Reward: [-490.633 -490.633 -490.633] [106.703], Avg: [-461.734 -461.734 -461.734] (1.0000) ({r_i: None, r_t: [-825.662 -825.662 -825.662], eps: 1.0})
Step:   44600, Reward: [-412.043 -412.043 -412.043] [78.637], Avg: [-461.623 -461.623 -461.623] (1.0000) ({r_i: None, r_t: [-887.342 -887.342 -887.342], eps: 1.0})
Step:   44700, Reward: [-420.794 -420.794 -420.794] [67.395], Avg: [-461.532 -461.532 -461.532] (1.0000) ({r_i: None, r_t: [-824.067 -824.067 -824.067], eps: 1.0})
Step:   44800, Reward: [-463.518 -463.518 -463.518] [113.552], Avg: [-461.536 -461.536 -461.536] (1.0000) ({r_i: None, r_t: [-921.439 -921.439 -921.439], eps: 1.0})
Step:   44900, Reward: [-459.453 -459.453 -459.453] [127.084], Avg: [-461.531 -461.531 -461.531] (1.0000) ({r_i: None, r_t: [-869.360 -869.360 -869.360], eps: 1.0})
Step:   45000, Reward: [-418.632 -418.632 -418.632] [77.517], Avg: [-461.436 -461.436 -461.436] (1.0000) ({r_i: None, r_t: [-910.325 -910.325 -910.325], eps: 1.0})
Step:   45100, Reward: [-462.044 -462.044 -462.044] [95.944], Avg: [-461.438 -461.438 -461.438] (1.0000) ({r_i: None, r_t: [-897.618 -897.618 -897.618], eps: 1.0})
Step:   45200, Reward: [-437.109 -437.109 -437.109] [105.872], Avg: [-461.384 -461.384 -461.384] (1.0000) ({r_i: None, r_t: [-884.891 -884.891 -884.891], eps: 1.0})
Step:   45300, Reward: [-453.199 -453.199 -453.199] [108.500], Avg: [-461.366 -461.366 -461.366] (1.0000) ({r_i: None, r_t: [-882.417 -882.417 -882.417], eps: 1.0})
Step:   45400, Reward: [-392.620 -392.620 -392.620] [75.640], Avg: [-461.215 -461.215 -461.215] (1.0000) ({r_i: None, r_t: [-827.645 -827.645 -827.645], eps: 1.0})
Step:   45500, Reward: [-408.758 -408.758 -408.758] [76.515], Avg: [-461.100 -461.100 -461.100] (1.0000) ({r_i: None, r_t: [-883.264 -883.264 -883.264], eps: 1.0})
Step:   45600, Reward: [-396.467 -396.467 -396.467] [46.587], Avg: [-460.958 -460.958 -460.958] (1.0000) ({r_i: None, r_t: [-874.341 -874.341 -874.341], eps: 1.0})
Step:   45700, Reward: [-445.601 -445.601 -445.601] [97.222], Avg: [-460.925 -460.925 -460.925] (1.0000) ({r_i: None, r_t: [-911.460 -911.460 -911.460], eps: 1.0})
Step:   45800, Reward: [-447.702 -447.702 -447.702] [68.000], Avg: [-460.896 -460.896 -460.896] (1.0000) ({r_i: None, r_t: [-874.901 -874.901 -874.901], eps: 1.0})
Step:   45900, Reward: [-471.823 -471.823 -471.823] [95.526], Avg: [-460.920 -460.920 -460.920] (1.0000) ({r_i: None, r_t: [-885.609 -885.609 -885.609], eps: 1.0})
Step:   46000, Reward: [-513.769 -513.769 -513.769] [121.618], Avg: [-461.034 -461.034 -461.034] (1.0000) ({r_i: None, r_t: [-848.503 -848.503 -848.503], eps: 1.0})
Step:   46100, Reward: [-477.116 -477.116 -477.116] [87.008], Avg: [-461.069 -461.069 -461.069] (1.0000) ({r_i: None, r_t: [-830.325 -830.325 -830.325], eps: 1.0})
Step:   46200, Reward: [-409.337 -409.337 -409.337] [88.415], Avg: [-460.957 -460.957 -460.957] (1.0000) ({r_i: None, r_t: [-873.645 -873.645 -873.645], eps: 1.0})
Step:   46300, Reward: [-480.658 -480.658 -480.658] [99.400], Avg: [-461.000 -461.000 -461.000] (1.0000) ({r_i: None, r_t: [-812.694 -812.694 -812.694], eps: 1.0})
Step:   46400, Reward: [-471.994 -471.994 -471.994] [98.448], Avg: [-461.024 -461.024 -461.024] (1.0000) ({r_i: None, r_t: [-958.889 -958.889 -958.889], eps: 1.0})
Step:   46500, Reward: [-434.067 -434.067 -434.067] [99.375], Avg: [-460.966 -460.966 -460.966] (1.0000) ({r_i: None, r_t: [-851.388 -851.388 -851.388], eps: 1.0})
Step:   46600, Reward: [-423.843 -423.843 -423.843] [111.503], Avg: [-460.886 -460.886 -460.886] (1.0000) ({r_i: None, r_t: [-917.524 -917.524 -917.524], eps: 1.0})
Step:   46700, Reward: [-464.054 -464.054 -464.054] [88.689], Avg: [-460.893 -460.893 -460.893] (1.0000) ({r_i: None, r_t: [-906.448 -906.448 -906.448], eps: 1.0})
Step:   46800, Reward: [-439.940 -439.940 -439.940] [79.626], Avg: [-460.848 -460.848 -460.848] (1.0000) ({r_i: None, r_t: [-867.904 -867.904 -867.904], eps: 1.0})
Step:   46900, Reward: [-459.205 -459.205 -459.205] [110.939], Avg: [-460.845 -460.845 -460.845] (1.0000) ({r_i: None, r_t: [-933.309 -933.309 -933.309], eps: 1.0})
Step:   47000, Reward: [-421.524 -421.524 -421.524] [102.172], Avg: [-460.761 -460.761 -460.761] (1.0000) ({r_i: None, r_t: [-894.980 -894.980 -894.980], eps: 1.0})
Step:   47100, Reward: [-382.824 -382.824 -382.824] [79.884], Avg: [-460.596 -460.596 -460.596] (1.0000) ({r_i: None, r_t: [-899.101 -899.101 -899.101], eps: 1.0})
Step:   47200, Reward: [-452.480 -452.480 -452.480] [80.063], Avg: [-460.579 -460.579 -460.579] (1.0000) ({r_i: None, r_t: [-877.550 -877.550 -877.550], eps: 1.0})
Step:   47300, Reward: [-465.290 -465.290 -465.290] [114.284], Avg: [-460.589 -460.589 -460.589] (1.0000) ({r_i: None, r_t: [-897.946 -897.946 -897.946], eps: 1.0})
Step:   47400, Reward: [-444.456 -444.456 -444.456] [76.893], Avg: [-460.555 -460.555 -460.555] (1.0000) ({r_i: None, r_t: [-867.512 -867.512 -867.512], eps: 1.0})
Step:   47500, Reward: [-454.187 -454.187 -454.187] [111.980], Avg: [-460.542 -460.542 -460.542] (1.0000) ({r_i: None, r_t: [-891.426 -891.426 -891.426], eps: 1.0})
Step:   47600, Reward: [-412.235 -412.235 -412.235] [87.229], Avg: [-460.440 -460.440 -460.440] (1.0000) ({r_i: None, r_t: [-879.679 -879.679 -879.679], eps: 1.0})
Step:   47700, Reward: [-423.933 -423.933 -423.933] [99.943], Avg: [-460.364 -460.364 -460.364] (1.0000) ({r_i: None, r_t: [-886.514 -886.514 -886.514], eps: 1.0})
Step:   47800, Reward: [-441.956 -441.956 -441.956] [106.241], Avg: [-460.326 -460.326 -460.326] (1.0000) ({r_i: None, r_t: [-867.896 -867.896 -867.896], eps: 1.0})
Step:   47900, Reward: [-445.593 -445.593 -445.593] [98.396], Avg: [-460.295 -460.295 -460.295] (1.0000) ({r_i: None, r_t: [-885.411 -885.411 -885.411], eps: 1.0})
Step:   48000, Reward: [-447.750 -447.750 -447.750] [97.092], Avg: [-460.269 -460.269 -460.269] (1.0000) ({r_i: None, r_t: [-879.911 -879.911 -879.911], eps: 1.0})
Step:   48100, Reward: [-421.786 -421.786 -421.786] [94.727], Avg: [-460.189 -460.189 -460.189] (1.0000) ({r_i: None, r_t: [-816.033 -816.033 -816.033], eps: 1.0})
Step:   48200, Reward: [-459.002 -459.002 -459.002] [129.329], Avg: [-460.186 -460.186 -460.186] (1.0000) ({r_i: None, r_t: [-868.673 -868.673 -868.673], eps: 1.0})
Step:   48300, Reward: [-412.823 -412.823 -412.823] [94.422], Avg: [-460.089 -460.089 -460.089] (1.0000) ({r_i: None, r_t: [-843.721 -843.721 -843.721], eps: 1.0})
Step:   48400, Reward: [-446.219 -446.219 -446.219] [121.036], Avg: [-460.060 -460.060 -460.060] (1.0000) ({r_i: None, r_t: [-862.753 -862.753 -862.753], eps: 1.0})
Step:   48500, Reward: [-454.252 -454.252 -454.252] [98.883], Avg: [-460.048 -460.048 -460.048] (1.0000) ({r_i: None, r_t: [-814.411 -814.411 -814.411], eps: 1.0})
Step:   48600, Reward: [-413.352 -413.352 -413.352] [73.674], Avg: [-459.952 -459.952 -459.952] (1.0000) ({r_i: None, r_t: [-879.723 -879.723 -879.723], eps: 1.0})
Step:   48700, Reward: [-447.278 -447.278 -447.278] [84.244], Avg: [-459.926 -459.926 -459.926] (1.0000) ({r_i: None, r_t: [-870.295 -870.295 -870.295], eps: 1.0})
Step:   48800, Reward: [-417.835 -417.835 -417.835] [109.953], Avg: [-459.840 -459.840 -459.840] (1.0000) ({r_i: None, r_t: [-872.928 -872.928 -872.928], eps: 1.0})
Step:   48900, Reward: [-439.964 -439.964 -439.964] [72.501], Avg: [-459.800 -459.800 -459.800] (1.0000) ({r_i: None, r_t: [-945.187 -945.187 -945.187], eps: 1.0})
Step:   49000, Reward: [-444.282 -444.282 -444.282] [106.393], Avg: [-459.768 -459.768 -459.768] (1.0000) ({r_i: None, r_t: [-822.511 -822.511 -822.511], eps: 1.0})
Step:   49100, Reward: [-435.099 -435.099 -435.099] [75.040], Avg: [-459.718 -459.718 -459.718] (1.0000) ({r_i: None, r_t: [-896.507 -896.507 -896.507], eps: 1.0})
Step:   49200, Reward: [-416.172 -416.172 -416.172] [86.550], Avg: [-459.630 -459.630 -459.630] (1.0000) ({r_i: None, r_t: [-939.433 -939.433 -939.433], eps: 1.0})
Step:   49300, Reward: [-426.504 -426.504 -426.504] [95.967], Avg: [-459.562 -459.562 -459.562] (1.0000) ({r_i: None, r_t: [-855.322 -855.322 -855.322], eps: 1.0})
Step:   49400, Reward: [-421.454 -421.454 -421.454] [117.122], Avg: [-459.485 -459.485 -459.485] (1.0000) ({r_i: None, r_t: [-838.907 -838.907 -838.907], eps: 1.0})
Step:   49500, Reward: [-434.446 -434.446 -434.446] [92.419], Avg: [-459.435 -459.435 -459.435] (1.0000) ({r_i: None, r_t: [-850.688 -850.688 -850.688], eps: 1.0})
Step:   49600, Reward: [-468.840 -468.840 -468.840] [93.785], Avg: [-459.454 -459.454 -459.454] (1.0000) ({r_i: None, r_t: [-812.166 -812.166 -812.166], eps: 1.0})
Step:   49700, Reward: [-422.091 -422.091 -422.091] [83.597], Avg: [-459.379 -459.379 -459.379] (1.0000) ({r_i: None, r_t: [-880.346 -880.346 -880.346], eps: 1.0})
Step:   49800, Reward: [-444.506 -444.506 -444.506] [86.964], Avg: [-459.349 -459.349 -459.349] (1.0000) ({r_i: None, r_t: [-883.777 -883.777 -883.777], eps: 1.0})
Step:   49900, Reward: [-407.792 -407.792 -407.792] [37.947], Avg: [-459.246 -459.246 -459.246] (1.0000) ({r_i: None, r_t: [-897.509 -897.509 -897.509], eps: 1.0})
Step:   50000, Reward: [-421.590 -421.590 -421.590] [88.186], Avg: [-459.171 -459.171 -459.171] (1.0000) ({r_i: None, r_t: [-906.629 -906.629 -906.629], eps: 1.0})
Step:   50100, Reward: [-447.098 -447.098 -447.098] [75.482], Avg: [-459.147 -459.147 -459.147] (1.0000) ({r_i: None, r_t: [-874.761 -874.761 -874.761], eps: 1.0})
Step:   50200, Reward: [-464.003 -464.003 -464.003] [105.726], Avg: [-459.156 -459.156 -459.156] (1.0000) ({r_i: None, r_t: [-865.734 -865.734 -865.734], eps: 1.0})
Step:   50300, Reward: [-412.110 -412.110 -412.110] [45.981], Avg: [-459.063 -459.063 -459.063] (1.0000) ({r_i: None, r_t: [-865.452 -865.452 -865.452], eps: 1.0})
Step:   50400, Reward: [-466.958 -466.958 -466.958] [87.012], Avg: [-459.079 -459.079 -459.079] (1.0000) ({r_i: None, r_t: [-844.944 -844.944 -844.944], eps: 1.0})
Step:   50500, Reward: [-426.614 -426.614 -426.614] [76.491], Avg: [-459.015 -459.015 -459.015] (1.0000) ({r_i: None, r_t: [-884.595 -884.595 -884.595], eps: 1.0})
Step:   50600, Reward: [-439.552 -439.552 -439.552] [61.604], Avg: [-458.976 -458.976 -458.976] (1.0000) ({r_i: None, r_t: [-834.626 -834.626 -834.626], eps: 1.0})
Step:   50700, Reward: [-438.623 -438.623 -438.623] [78.302], Avg: [-458.936 -458.936 -458.936] (1.0000) ({r_i: None, r_t: [-867.074 -867.074 -867.074], eps: 1.0})
Step:   50800, Reward: [-474.786 -474.786 -474.786] [105.046], Avg: [-458.967 -458.967 -458.967] (1.0000) ({r_i: None, r_t: [-924.025 -924.025 -924.025], eps: 1.0})
Step:   50900, Reward: [-417.610 -417.610 -417.610] [96.058], Avg: [-458.886 -458.886 -458.886] (1.0000) ({r_i: None, r_t: [-875.082 -875.082 -875.082], eps: 1.0})
Step:   51000, Reward: [-480.456 -480.456 -480.456] [79.793], Avg: [-458.928 -458.928 -458.928] (1.0000) ({r_i: None, r_t: [-844.899 -844.899 -844.899], eps: 1.0})
Step:   51100, Reward: [-447.288 -447.288 -447.288] [113.924], Avg: [-458.906 -458.906 -458.906] (1.0000) ({r_i: None, r_t: [-929.306 -929.306 -929.306], eps: 1.0})
Step:   51200, Reward: [-428.390 -428.390 -428.390] [79.642], Avg: [-458.846 -458.846 -458.846] (1.0000) ({r_i: None, r_t: [-891.388 -891.388 -891.388], eps: 1.0})
Step:   51300, Reward: [-455.320 -455.320 -455.320] [62.168], Avg: [-458.839 -458.839 -458.839] (1.0000) ({r_i: None, r_t: [-892.014 -892.014 -892.014], eps: 1.0})
Step:   51400, Reward: [-445.072 -445.072 -445.072] [108.019], Avg: [-458.813 -458.813 -458.813] (1.0000) ({r_i: None, r_t: [-882.504 -882.504 -882.504], eps: 1.0})
Step:   51500, Reward: [-432.217 -432.217 -432.217] [102.419], Avg: [-458.761 -458.761 -458.761] (1.0000) ({r_i: None, r_t: [-863.489 -863.489 -863.489], eps: 1.0})
Step:   51600, Reward: [-440.719 -440.719 -440.719] [120.319], Avg: [-458.726 -458.726 -458.726] (1.0000) ({r_i: None, r_t: [-827.468 -827.468 -827.468], eps: 1.0})
Step:   51700, Reward: [-410.383 -410.383 -410.383] [79.406], Avg: [-458.633 -458.633 -458.633] (1.0000) ({r_i: None, r_t: [-871.606 -871.606 -871.606], eps: 1.0})
Step:   51800, Reward: [-425.190 -425.190 -425.190] [115.489], Avg: [-458.568 -458.568 -458.568] (1.0000) ({r_i: None, r_t: [-857.997 -857.997 -857.997], eps: 1.0})
Step:   51900, Reward: [-411.286 -411.286 -411.286] [91.033], Avg: [-458.477 -458.477 -458.477] (1.0000) ({r_i: None, r_t: [-876.540 -876.540 -876.540], eps: 1.0})
Step:   52000, Reward: [-428.789 -428.789 -428.789] [98.197], Avg: [-458.420 -458.420 -458.420] (1.0000) ({r_i: None, r_t: [-816.052 -816.052 -816.052], eps: 1.0})
Step:   52100, Reward: [-462.802 -462.802 -462.802] [92.422], Avg: [-458.429 -458.429 -458.429] (1.0000) ({r_i: None, r_t: [-885.160 -885.160 -885.160], eps: 1.0})
Step:   52200, Reward: [-466.227 -466.227 -466.227] [117.617], Avg: [-458.444 -458.444 -458.444] (1.0000) ({r_i: None, r_t: [-882.876 -882.876 -882.876], eps: 1.0})
Step:   52300, Reward: [-437.542 -437.542 -437.542] [67.870], Avg: [-458.404 -458.404 -458.404] (1.0000) ({r_i: None, r_t: [-881.458 -881.458 -881.458], eps: 1.0})
Step:   52400, Reward: [-420.002 -420.002 -420.002] [96.255], Avg: [-458.331 -458.331 -458.331] (1.0000) ({r_i: None, r_t: [-829.727 -829.727 -829.727], eps: 1.0})
Step:   52500, Reward: [-435.827 -435.827 -435.827] [90.523], Avg: [-458.288 -458.288 -458.288] (1.0000) ({r_i: None, r_t: [-818.254 -818.254 -818.254], eps: 1.0})
Step:   52600, Reward: [-424.392 -424.392 -424.392] [83.852], Avg: [-458.224 -458.224 -458.224] (1.0000) ({r_i: None, r_t: [-891.818 -891.818 -891.818], eps: 1.0})
Step:   52700, Reward: [-434.150 -434.150 -434.150] [85.362], Avg: [-458.178 -458.178 -458.178] (1.0000) ({r_i: None, r_t: [-860.591 -860.591 -860.591], eps: 1.0})
Step:   52800, Reward: [-391.403 -391.403 -391.403] [54.691], Avg: [-458.052 -458.052 -458.052] (1.0000) ({r_i: None, r_t: [-796.813 -796.813 -796.813], eps: 1.0})
Step:   52900, Reward: [-447.360 -447.360 -447.360] [78.401], Avg: [-458.032 -458.032 -458.032] (1.0000) ({r_i: None, r_t: [-817.608 -817.608 -817.608], eps: 1.0})
Step:   53000, Reward: [-477.103 -477.103 -477.103] [68.378], Avg: [-458.067 -458.067 -458.067] (1.0000) ({r_i: None, r_t: [-887.911 -887.911 -887.911], eps: 1.0})
Step:   53100, Reward: [-446.355 -446.355 -446.355] [82.576], Avg: [-458.045 -458.045 -458.045] (1.0000) ({r_i: None, r_t: [-872.617 -872.617 -872.617], eps: 1.0})
Step:   53200, Reward: [-406.701 -406.701 -406.701] [78.932], Avg: [-457.949 -457.949 -457.949] (1.0000) ({r_i: None, r_t: [-809.835 -809.835 -809.835], eps: 1.0})
Step:   53300, Reward: [-417.574 -417.574 -417.574] [83.757], Avg: [-457.874 -457.874 -457.874] (1.0000) ({r_i: None, r_t: [-872.892 -872.892 -872.892], eps: 1.0})
Step:   53400, Reward: [-439.079 -439.079 -439.079] [83.390], Avg: [-457.838 -457.838 -457.838] (1.0000) ({r_i: None, r_t: [-869.451 -869.451 -869.451], eps: 1.0})
Step:   53500, Reward: [-416.955 -416.955 -416.955] [96.727], Avg: [-457.762 -457.762 -457.762] (1.0000) ({r_i: None, r_t: [-946.681 -946.681 -946.681], eps: 1.0})
Step:   53600, Reward: [-450.340 -450.340 -450.340] [88.182], Avg: [-457.748 -457.748 -457.748] (1.0000) ({r_i: None, r_t: [-844.364 -844.364 -844.364], eps: 1.0})
Step:   53700, Reward: [-409.547 -409.547 -409.547] [76.102], Avg: [-457.659 -457.659 -457.659] (1.0000) ({r_i: None, r_t: [-857.470 -857.470 -857.470], eps: 1.0})
Step:   53800, Reward: [-431.748 -431.748 -431.748] [79.891], Avg: [-457.611 -457.611 -457.611] (1.0000) ({r_i: None, r_t: [-870.377 -870.377 -870.377], eps: 1.0})
Step:   53900, Reward: [-462.426 -462.426 -462.426] [131.148], Avg: [-457.620 -457.620 -457.620] (1.0000) ({r_i: None, r_t: [-914.372 -914.372 -914.372], eps: 1.0})
Step:   54000, Reward: [-441.765 -441.765 -441.765] [103.915], Avg: [-457.590 -457.590 -457.590] (1.0000) ({r_i: None, r_t: [-877.244 -877.244 -877.244], eps: 1.0})
Step:   54100, Reward: [-443.114 -443.114 -443.114] [82.077], Avg: [-457.564 -457.564 -457.564] (1.0000) ({r_i: None, r_t: [-848.098 -848.098 -848.098], eps: 1.0})
Step:   54200, Reward: [-455.629 -455.629 -455.629] [99.925], Avg: [-457.560 -457.560 -457.560] (1.0000) ({r_i: None, r_t: [-937.106 -937.106 -937.106], eps: 1.0})
Step:   54300, Reward: [-440.612 -440.612 -440.612] [104.206], Avg: [-457.529 -457.529 -457.529] (1.0000) ({r_i: None, r_t: [-867.071 -867.071 -867.071], eps: 1.0})
Step:   54400, Reward: [-410.959 -410.959 -410.959] [77.416], Avg: [-457.443 -457.443 -457.443] (1.0000) ({r_i: None, r_t: [-846.267 -846.267 -846.267], eps: 1.0})
Step:   54500, Reward: [-463.752 -463.752 -463.752] [101.139], Avg: [-457.455 -457.455 -457.455] (1.0000) ({r_i: None, r_t: [-867.517 -867.517 -867.517], eps: 1.0})
Step:   54600, Reward: [-447.083 -447.083 -447.083] [87.767], Avg: [-457.436 -457.436 -457.436] (1.0000) ({r_i: None, r_t: [-842.944 -842.944 -842.944], eps: 1.0})
Step:   54700, Reward: [-442.723 -442.723 -442.723] [94.490], Avg: [-457.409 -457.409 -457.409] (1.0000) ({r_i: None, r_t: [-798.831 -798.831 -798.831], eps: 1.0})
Step:   54800, Reward: [-444.657 -444.657 -444.657] [67.326], Avg: [-457.386 -457.386 -457.386] (1.0000) ({r_i: None, r_t: [-839.466 -839.466 -839.466], eps: 1.0})
Step:   54900, Reward: [-445.493 -445.493 -445.493] [58.451], Avg: [-457.364 -457.364 -457.364] (1.0000) ({r_i: None, r_t: [-944.401 -944.401 -944.401], eps: 1.0})
Step:   55000, Reward: [-429.975 -429.975 -429.975] [71.515], Avg: [-457.315 -457.315 -457.315] (1.0000) ({r_i: None, r_t: [-796.889 -796.889 -796.889], eps: 1.0})
Step:   55100, Reward: [-452.619 -452.619 -452.619] [134.174], Avg: [-457.306 -457.306 -457.306] (1.0000) ({r_i: None, r_t: [-838.775 -838.775 -838.775], eps: 1.0})
Step:   55200, Reward: [-431.207 -431.207 -431.207] [129.038], Avg: [-457.259 -457.259 -457.259] (1.0000) ({r_i: None, r_t: [-930.285 -930.285 -930.285], eps: 1.0})
Step:   55300, Reward: [-455.016 -455.016 -455.016] [79.207], Avg: [-457.255 -457.255 -457.255] (1.0000) ({r_i: None, r_t: [-919.637 -919.637 -919.637], eps: 1.0})
Step:   55400, Reward: [-398.829 -398.829 -398.829] [59.060], Avg: [-457.150 -457.150 -457.150] (1.0000) ({r_i: None, r_t: [-877.622 -877.622 -877.622], eps: 1.0})
Step:   55500, Reward: [-441.573 -441.573 -441.573] [119.820], Avg: [-457.122 -457.122 -457.122] (1.0000) ({r_i: None, r_t: [-823.283 -823.283 -823.283], eps: 1.0})
Step:   55600, Reward: [-425.975 -425.975 -425.975] [72.052], Avg: [-457.066 -457.066 -457.066] (1.0000) ({r_i: None, r_t: [-867.351 -867.351 -867.351], eps: 1.0})
Step:   55700, Reward: [-416.157 -416.157 -416.157] [76.399], Avg: [-456.992 -456.992 -456.992] (1.0000) ({r_i: None, r_t: [-833.439 -833.439 -833.439], eps: 1.0})
Step:   55800, Reward: [-439.183 -439.183 -439.183] [71.756], Avg: [-456.960 -456.960 -456.960] (1.0000) ({r_i: None, r_t: [-884.054 -884.054 -884.054], eps: 1.0})
Step:   55900, Reward: [-490.581 -490.581 -490.581] [121.546], Avg: [-457.020 -457.020 -457.020] (1.0000) ({r_i: None, r_t: [-892.625 -892.625 -892.625], eps: 1.0})
Step:   56000, Reward: [-456.104 -456.104 -456.104] [137.867], Avg: [-457.019 -457.019 -457.019] (1.0000) ({r_i: None, r_t: [-893.730 -893.730 -893.730], eps: 1.0})
Step:   56100, Reward: [-457.100 -457.100 -457.100] [82.592], Avg: [-457.019 -457.019 -457.019] (1.0000) ({r_i: None, r_t: [-858.904 -858.904 -858.904], eps: 1.0})
Step:   56200, Reward: [-496.192 -496.192 -496.192] [112.967], Avg: [-457.089 -457.089 -457.089] (1.0000) ({r_i: None, r_t: [-852.058 -852.058 -852.058], eps: 1.0})
Step:   56300, Reward: [-496.398 -496.398 -496.398] [141.405], Avg: [-457.158 -457.158 -457.158] (1.0000) ({r_i: None, r_t: [-893.306 -893.306 -893.306], eps: 1.0})
Step:   56400, Reward: [-455.103 -455.103 -455.103] [151.215], Avg: [-457.155 -457.155 -457.155] (1.0000) ({r_i: None, r_t: [-880.156 -880.156 -880.156], eps: 1.0})
Step:   56500, Reward: [-418.713 -418.713 -418.713] [69.464], Avg: [-457.087 -457.087 -457.087] (1.0000) ({r_i: None, r_t: [-869.701 -869.701 -869.701], eps: 1.0})
Step:   56600, Reward: [-423.835 -423.835 -423.835] [103.994], Avg: [-457.028 -457.028 -457.028] (1.0000) ({r_i: None, r_t: [-898.286 -898.286 -898.286], eps: 1.0})
Step:   56700, Reward: [-446.089 -446.089 -446.089] [88.396], Avg: [-457.009 -457.009 -457.009] (1.0000) ({r_i: None, r_t: [-852.438 -852.438 -852.438], eps: 1.0})
Step:   56800, Reward: [-430.872 -430.872 -430.872] [89.742], Avg: [-456.963 -456.963 -456.963] (1.0000) ({r_i: None, r_t: [-889.843 -889.843 -889.843], eps: 1.0})
Step:   56900, Reward: [-424.500 -424.500 -424.500] [103.325], Avg: [-456.906 -456.906 -456.906] (1.0000) ({r_i: None, r_t: [-853.643 -853.643 -853.643], eps: 1.0})
Step:   57000, Reward: [-407.214 -407.214 -407.214] [70.300], Avg: [-456.819 -456.819 -456.819] (1.0000) ({r_i: None, r_t: [-854.699 -854.699 -854.699], eps: 1.0})
Step:   57100, Reward: [-453.563 -453.563 -453.563] [127.664], Avg: [-456.813 -456.813 -456.813] (1.0000) ({r_i: None, r_t: [-916.652 -916.652 -916.652], eps: 1.0})
Step:   57200, Reward: [-440.063 -440.063 -440.063] [74.904], Avg: [-456.784 -456.784 -456.784] (1.0000) ({r_i: None, r_t: [-870.960 -870.960 -870.960], eps: 1.0})
Step:   57300, Reward: [-460.668 -460.668 -460.668] [97.438], Avg: [-456.791 -456.791 -456.791] (1.0000) ({r_i: None, r_t: [-856.219 -856.219 -856.219], eps: 1.0})
Step:   57400, Reward: [-444.610 -444.610 -444.610] [93.345], Avg: [-456.770 -456.770 -456.770] (1.0000) ({r_i: None, r_t: [-836.886 -836.886 -836.886], eps: 1.0})
Step:   57500, Reward: [-426.761 -426.761 -426.761] [85.513], Avg: [-456.717 -456.717 -456.717] (1.0000) ({r_i: None, r_t: [-909.019 -909.019 -909.019], eps: 1.0})
Step:   57600, Reward: [-385.063 -385.063 -385.063] [82.765], Avg: [-456.593 -456.593 -456.593] (1.0000) ({r_i: None, r_t: [-820.954 -820.954 -820.954], eps: 1.0})
Step:   57700, Reward: [-438.657 -438.657 -438.657] [94.236], Avg: [-456.562 -456.562 -456.562] (1.0000) ({r_i: None, r_t: [-849.301 -849.301 -849.301], eps: 1.0})
Step:   57800, Reward: [-434.536 -434.536 -434.536] [61.673], Avg: [-456.524 -456.524 -456.524] (1.0000) ({r_i: None, r_t: [-809.842 -809.842 -809.842], eps: 1.0})
Step:   57900, Reward: [-440.649 -440.649 -440.649] [102.208], Avg: [-456.497 -456.497 -456.497] (1.0000) ({r_i: None, r_t: [-829.780 -829.780 -829.780], eps: 1.0})
Step:   58000, Reward: [-434.274 -434.274 -434.274] [70.517], Avg: [-456.459 -456.459 -456.459] (1.0000) ({r_i: None, r_t: [-887.685 -887.685 -887.685], eps: 1.0})
Step:   58100, Reward: [-434.325 -434.325 -434.325] [64.786], Avg: [-456.421 -456.421 -456.421] (1.0000) ({r_i: None, r_t: [-912.442 -912.442 -912.442], eps: 1.0})
Step:   58200, Reward: [-427.443 -427.443 -427.443] [84.410], Avg: [-456.371 -456.371 -456.371] (1.0000) ({r_i: None, r_t: [-839.435 -839.435 -839.435], eps: 1.0})
Step:   58300, Reward: [-415.020 -415.020 -415.020] [79.161], Avg: [-456.300 -456.300 -456.300] (1.0000) ({r_i: None, r_t: [-852.482 -852.482 -852.482], eps: 1.0})
Step:   58400, Reward: [-476.795 -476.795 -476.795] [129.107], Avg: [-456.335 -456.335 -456.335] (1.0000) ({r_i: None, r_t: [-913.404 -913.404 -913.404], eps: 1.0})
Step:   58500, Reward: [-416.049 -416.049 -416.049] [78.945], Avg: [-456.266 -456.266 -456.266] (1.0000) ({r_i: None, r_t: [-816.009 -816.009 -816.009], eps: 1.0})
Step:   58600, Reward: [-440.267 -440.267 -440.267] [106.045], Avg: [-456.239 -456.239 -456.239] (1.0000) ({r_i: None, r_t: [-905.197 -905.197 -905.197], eps: 1.0})
Step:   58700, Reward: [-446.597 -446.597 -446.597] [64.202], Avg: [-456.223 -456.223 -456.223] (1.0000) ({r_i: None, r_t: [-854.054 -854.054 -854.054], eps: 1.0})
Step:   58800, Reward: [-482.756 -482.756 -482.756] [67.499], Avg: [-456.268 -456.268 -456.268] (1.0000) ({r_i: None, r_t: [-864.801 -864.801 -864.801], eps: 1.0})
Step:   58900, Reward: [-435.041 -435.041 -435.041] [116.378], Avg: [-456.232 -456.232 -456.232] (1.0000) ({r_i: None, r_t: [-889.358 -889.358 -889.358], eps: 1.0})
Step:   59000, Reward: [-403.501 -403.501 -403.501] [66.485], Avg: [-456.143 -456.143 -456.143] (1.0000) ({r_i: None, r_t: [-844.765 -844.765 -844.765], eps: 1.0})
Step:   59100, Reward: [-441.096 -441.096 -441.096] [102.565], Avg: [-456.117 -456.117 -456.117] (1.0000) ({r_i: None, r_t: [-902.929 -902.929 -902.929], eps: 1.0})
Step:   59200, Reward: [-458.271 -458.271 -458.271] [53.610], Avg: [-456.121 -456.121 -456.121] (1.0000) ({r_i: None, r_t: [-883.993 -883.993 -883.993], eps: 1.0})
Step:   59300, Reward: [-470.558 -470.558 -470.558] [121.006], Avg: [-456.145 -456.145 -456.145] (1.0000) ({r_i: None, r_t: [-861.184 -861.184 -861.184], eps: 1.0})
Step:   59400, Reward: [-397.447 -397.447 -397.447] [56.106], Avg: [-456.046 -456.046 -456.046] (1.0000) ({r_i: None, r_t: [-852.286 -852.286 -852.286], eps: 1.0})
Step:   59500, Reward: [-449.749 -449.749 -449.749] [91.930], Avg: [-456.036 -456.036 -456.036] (1.0000) ({r_i: None, r_t: [-871.589 -871.589 -871.589], eps: 1.0})
Step:   59600, Reward: [-465.144 -465.144 -465.144] [73.108], Avg: [-456.051 -456.051 -456.051] (1.0000) ({r_i: None, r_t: [-880.322 -880.322 -880.322], eps: 1.0})
Step:   59700, Reward: [-428.607 -428.607 -428.607] [69.431], Avg: [-456.005 -456.005 -456.005] (1.0000) ({r_i: None, r_t: [-812.872 -812.872 -812.872], eps: 1.0})
Step:   59800, Reward: [-462.202 -462.202 -462.202] [92.827], Avg: [-456.016 -456.016 -456.016] (1.0000) ({r_i: None, r_t: [-857.530 -857.530 -857.530], eps: 1.0})
Step:   59900, Reward: [-437.817 -437.817 -437.817] [45.450], Avg: [-455.985 -455.985 -455.985] (1.0000) ({r_i: None, r_t: [-886.986 -886.986 -886.986], eps: 1.0})
Step:   60000, Reward: [-407.716 -407.716 -407.716] [78.913], Avg: [-455.905 -455.905 -455.905] (1.0000) ({r_i: None, r_t: [-832.199 -832.199 -832.199], eps: 1.0})
Step:   60100, Reward: [-449.083 -449.083 -449.083] [117.719], Avg: [-455.894 -455.894 -455.894] (1.0000) ({r_i: None, r_t: [-914.628 -914.628 -914.628], eps: 1.0})
Step:   60200, Reward: [-447.065 -447.065 -447.065] [127.823], Avg: [-455.879 -455.879 -455.879] (1.0000) ({r_i: None, r_t: [-800.697 -800.697 -800.697], eps: 1.0})
Step:   60300, Reward: [-448.645 -448.645 -448.645] [85.384], Avg: [-455.867 -455.867 -455.867] (1.0000) ({r_i: None, r_t: [-895.080 -895.080 -895.080], eps: 1.0})
Step:   60400, Reward: [-445.735 -445.735 -445.735] [122.409], Avg: [-455.850 -455.850 -455.850] (1.0000) ({r_i: None, r_t: [-861.990 -861.990 -861.990], eps: 1.0})
Step:   60500, Reward: [-416.180 -416.180 -416.180] [95.343], Avg: [-455.785 -455.785 -455.785] (1.0000) ({r_i: None, r_t: [-922.214 -922.214 -922.214], eps: 1.0})
Step:   60600, Reward: [-454.257 -454.257 -454.257] [98.036], Avg: [-455.782 -455.782 -455.782] (1.0000) ({r_i: None, r_t: [-903.227 -903.227 -903.227], eps: 1.0})
Step:   60700, Reward: [-433.851 -433.851 -433.851] [84.020], Avg: [-455.746 -455.746 -455.746] (1.0000) ({r_i: None, r_t: [-886.242 -886.242 -886.242], eps: 1.0})
Step:   60800, Reward: [-458.981 -458.981 -458.981] [114.087], Avg: [-455.751 -455.751 -455.751] (1.0000) ({r_i: None, r_t: [-863.587 -863.587 -863.587], eps: 1.0})
Step:   60900, Reward: [-467.281 -467.281 -467.281] [116.443], Avg: [-455.770 -455.770 -455.770] (1.0000) ({r_i: None, r_t: [-866.251 -866.251 -866.251], eps: 1.0})
Step:   61000, Reward: [-450.772 -450.772 -450.772] [112.270], Avg: [-455.762 -455.762 -455.762] (1.0000) ({r_i: None, r_t: [-879.544 -879.544 -879.544], eps: 1.0})
Step:   61100, Reward: [-479.404 -479.404 -479.404] [122.260], Avg: [-455.801 -455.801 -455.801] (1.0000) ({r_i: None, r_t: [-884.304 -884.304 -884.304], eps: 1.0})
Step:   61200, Reward: [-436.540 -436.540 -436.540] [99.986], Avg: [-455.769 -455.769 -455.769] (1.0000) ({r_i: None, r_t: [-882.748 -882.748 -882.748], eps: 1.0})
Step:   61300, Reward: [-447.543 -447.543 -447.543] [97.938], Avg: [-455.756 -455.756 -455.756] (1.0000) ({r_i: None, r_t: [-851.964 -851.964 -851.964], eps: 1.0})
Step:   61400, Reward: [-458.101 -458.101 -458.101] [95.215], Avg: [-455.760 -455.760 -455.760] (1.0000) ({r_i: None, r_t: [-895.426 -895.426 -895.426], eps: 1.0})
Step:   61500, Reward: [-458.189 -458.189 -458.189] [80.655], Avg: [-455.764 -455.764 -455.764] (1.0000) ({r_i: None, r_t: [-875.518 -875.518 -875.518], eps: 1.0})
Step:   61600, Reward: [-430.958 -430.958 -430.958] [68.596], Avg: [-455.724 -455.724 -455.724] (1.0000) ({r_i: None, r_t: [-920.668 -920.668 -920.668], eps: 1.0})
Step:   61700, Reward: [-449.181 -449.181 -449.181] [104.117], Avg: [-455.713 -455.713 -455.713] (1.0000) ({r_i: None, r_t: [-886.798 -886.798 -886.798], eps: 1.0})
Step:   61800, Reward: [-442.893 -442.893 -442.893] [100.797], Avg: [-455.692 -455.692 -455.692] (1.0000) ({r_i: None, r_t: [-843.700 -843.700 -843.700], eps: 1.0})
Step:   61900, Reward: [-419.944 -419.944 -419.944] [92.992], Avg: [-455.635 -455.635 -455.635] (1.0000) ({r_i: None, r_t: [-858.024 -858.024 -858.024], eps: 1.0})
Step:   62000, Reward: [-447.761 -447.761 -447.761] [82.025], Avg: [-455.622 -455.622 -455.622] (1.0000) ({r_i: None, r_t: [-899.875 -899.875 -899.875], eps: 1.0})
Step:   62100, Reward: [-417.931 -417.931 -417.931] [75.269], Avg: [-455.561 -455.561 -455.561] (1.0000) ({r_i: None, r_t: [-873.909 -873.909 -873.909], eps: 1.0})
Step:   62200, Reward: [-397.565 -397.565 -397.565] [80.120], Avg: [-455.468 -455.468 -455.468] (1.0000) ({r_i: None, r_t: [-860.660 -860.660 -860.660], eps: 1.0})
Step:   62300, Reward: [-417.330 -417.330 -417.330] [76.687], Avg: [-455.407 -455.407 -455.407] (1.0000) ({r_i: None, r_t: [-933.758 -933.758 -933.758], eps: 1.0})
Step:   62400, Reward: [-387.537 -387.537 -387.537] [78.688], Avg: [-455.298 -455.298 -455.298] (1.0000) ({r_i: None, r_t: [-896.508 -896.508 -896.508], eps: 1.0})
Step:   62500, Reward: [-434.394 -434.394 -434.394] [74.563], Avg: [-455.265 -455.265 -455.265] (1.0000) ({r_i: None, r_t: [-909.870 -909.870 -909.870], eps: 1.0})
Step:   62600, Reward: [-421.775 -421.775 -421.775] [73.778], Avg: [-455.212 -455.212 -455.212] (1.0000) ({r_i: None, r_t: [-834.601 -834.601 -834.601], eps: 1.0})
Step:   62700, Reward: [-464.876 -464.876 -464.876] [76.702], Avg: [-455.227 -455.227 -455.227] (1.0000) ({r_i: None, r_t: [-891.579 -891.579 -891.579], eps: 1.0})
Step:   62800, Reward: [-426.856 -426.856 -426.856] [90.563], Avg: [-455.182 -455.182 -455.182] (1.0000) ({r_i: None, r_t: [-912.707 -912.707 -912.707], eps: 1.0})
Step:   62900, Reward: [-429.431 -429.431 -429.431] [74.333], Avg: [-455.141 -455.141 -455.141] (1.0000) ({r_i: None, r_t: [-844.868 -844.868 -844.868], eps: 1.0})
Step:   63000, Reward: [-395.389 -395.389 -395.389] [82.269], Avg: [-455.046 -455.046 -455.046] (1.0000) ({r_i: None, r_t: [-840.905 -840.905 -840.905], eps: 1.0})
Step:   63100, Reward: [-428.184 -428.184 -428.184] [102.210], Avg: [-455.004 -455.004 -455.004] (1.0000) ({r_i: None, r_t: [-873.532 -873.532 -873.532], eps: 1.0})
Step:   63200, Reward: [-408.141 -408.141 -408.141] [95.486], Avg: [-454.930 -454.930 -454.930] (1.0000) ({r_i: None, r_t: [-872.709 -872.709 -872.709], eps: 1.0})
Step:   63300, Reward: [-412.534 -412.534 -412.534] [97.150], Avg: [-454.863 -454.863 -454.863] (1.0000) ({r_i: None, r_t: [-909.834 -909.834 -909.834], eps: 1.0})
Step:   63400, Reward: [-463.903 -463.903 -463.903] [120.942], Avg: [-454.877 -454.877 -454.877] (1.0000) ({r_i: None, r_t: [-875.443 -875.443 -875.443], eps: 1.0})
Step:   63500, Reward: [-442.352 -442.352 -442.352] [73.447], Avg: [-454.858 -454.858 -454.858] (1.0000) ({r_i: None, r_t: [-855.005 -855.005 -855.005], eps: 1.0})
Step:   63600, Reward: [-393.890 -393.890 -393.890] [55.731], Avg: [-454.762 -454.762 -454.762] (1.0000) ({r_i: None, r_t: [-862.021 -862.021 -862.021], eps: 1.0})
Step:   63700, Reward: [-434.294 -434.294 -434.294] [78.642], Avg: [-454.730 -454.730 -454.730] (1.0000) ({r_i: None, r_t: [-914.595 -914.595 -914.595], eps: 1.0})
Step:   63800, Reward: [-444.338 -444.338 -444.338] [72.769], Avg: [-454.713 -454.713 -454.713] (1.0000) ({r_i: None, r_t: [-891.164 -891.164 -891.164], eps: 1.0})
Step:   63900, Reward: [-406.951 -406.951 -406.951] [82.553], Avg: [-454.639 -454.639 -454.639] (1.0000) ({r_i: None, r_t: [-976.069 -976.069 -976.069], eps: 1.0})
Step:   64000, Reward: [-372.587 -372.587 -372.587] [87.477], Avg: [-454.511 -454.511 -454.511] (1.0000) ({r_i: None, r_t: [-856.530 -856.530 -856.530], eps: 1.0})
Step:   64100, Reward: [-456.284 -456.284 -456.284] [100.881], Avg: [-454.514 -454.514 -454.514] (1.0000) ({r_i: None, r_t: [-897.825 -897.825 -897.825], eps: 1.0})
Step:   64200, Reward: [-412.929 -412.929 -412.929] [100.900], Avg: [-454.449 -454.449 -454.449] (1.0000) ({r_i: None, r_t: [-908.705 -908.705 -908.705], eps: 1.0})
Step:   64300, Reward: [-434.890 -434.890 -434.890] [76.800], Avg: [-454.419 -454.419 -454.419] (1.0000) ({r_i: None, r_t: [-876.459 -876.459 -876.459], eps: 1.0})
Step:   64400, Reward: [-418.213 -418.213 -418.213] [83.062], Avg: [-454.362 -454.362 -454.362] (1.0000) ({r_i: None, r_t: [-909.751 -909.751 -909.751], eps: 1.0})
Step:   64500, Reward: [-387.125 -387.125 -387.125] [68.391], Avg: [-454.258 -454.258 -454.258] (1.0000) ({r_i: None, r_t: [-952.336 -952.336 -952.336], eps: 1.0})
Step:   64600, Reward: [-427.332 -427.332 -427.332] [101.919], Avg: [-454.217 -454.217 -454.217] (1.0000) ({r_i: None, r_t: [-834.517 -834.517 -834.517], eps: 1.0})
Step:   64700, Reward: [-448.167 -448.167 -448.167] [90.754], Avg: [-454.207 -454.207 -454.207] (1.0000) ({r_i: None, r_t: [-834.810 -834.810 -834.810], eps: 1.0})
Step:   64800, Reward: [-398.220 -398.220 -398.220] [74.292], Avg: [-454.121 -454.121 -454.121] (1.0000) ({r_i: None, r_t: [-856.077 -856.077 -856.077], eps: 1.0})
Step:   64900, Reward: [-452.340 -452.340 -452.340] [95.299], Avg: [-454.118 -454.118 -454.118] (1.0000) ({r_i: None, r_t: [-884.464 -884.464 -884.464], eps: 1.0})
Step:   65000, Reward: [-425.424 -425.424 -425.424] [90.438], Avg: [-454.074 -454.074 -454.074] (1.0000) ({r_i: None, r_t: [-889.438 -889.438 -889.438], eps: 1.0})
Step:   65100, Reward: [-409.310 -409.310 -409.310] [50.609], Avg: [-454.006 -454.006 -454.006] (1.0000) ({r_i: None, r_t: [-861.526 -861.526 -861.526], eps: 1.0})
Step:   65200, Reward: [-427.863 -427.863 -427.863] [81.564], Avg: [-453.966 -453.966 -453.966] (1.0000) ({r_i: None, r_t: [-909.408 -909.408 -909.408], eps: 1.0})
Step:   65300, Reward: [-457.186 -457.186 -457.186] [116.856], Avg: [-453.971 -453.971 -453.971] (1.0000) ({r_i: None, r_t: [-839.933 -839.933 -839.933], eps: 1.0})
Step:   65400, Reward: [-404.290 -404.290 -404.290] [102.090], Avg: [-453.895 -453.895 -453.895] (1.0000) ({r_i: None, r_t: [-855.574 -855.574 -855.574], eps: 1.0})
Step:   65500, Reward: [-436.410 -436.410 -436.410] [100.753], Avg: [-453.868 -453.868 -453.868] (1.0000) ({r_i: None, r_t: [-814.014 -814.014 -814.014], eps: 1.0})
Step:   65600, Reward: [-420.222 -420.222 -420.222] [82.240], Avg: [-453.817 -453.817 -453.817] (1.0000) ({r_i: None, r_t: [-882.615 -882.615 -882.615], eps: 1.0})
Step:   65700, Reward: [-423.044 -423.044 -423.044] [89.586], Avg: [-453.770 -453.770 -453.770] (1.0000) ({r_i: None, r_t: [-884.665 -884.665 -884.665], eps: 1.0})
Step:   65800, Reward: [-452.844 -452.844 -452.844] [88.523], Avg: [-453.769 -453.769 -453.769] (1.0000) ({r_i: None, r_t: [-858.090 -858.090 -858.090], eps: 1.0})
Step:   65900, Reward: [-395.272 -395.272 -395.272] [63.760], Avg: [-453.680 -453.680 -453.680] (1.0000) ({r_i: None, r_t: [-892.155 -892.155 -892.155], eps: 1.0})
Step:   66000, Reward: [-468.258 -468.258 -468.258] [53.080], Avg: [-453.702 -453.702 -453.702] (1.0000) ({r_i: None, r_t: [-883.792 -883.792 -883.792], eps: 1.0})
Step:   66100, Reward: [-431.985 -431.985 -431.985] [112.393], Avg: [-453.669 -453.669 -453.669] (1.0000) ({r_i: None, r_t: [-927.445 -927.445 -927.445], eps: 1.0})
Step:   66200, Reward: [-418.749 -418.749 -418.749] [53.913], Avg: [-453.617 -453.617 -453.617] (1.0000) ({r_i: None, r_t: [-882.251 -882.251 -882.251], eps: 1.0})
Step:   66300, Reward: [-442.684 -442.684 -442.684] [97.855], Avg: [-453.600 -453.600 -453.600] (1.0000) ({r_i: None, r_t: [-901.860 -901.860 -901.860], eps: 1.0})
Step:   66400, Reward: [-490.999 -490.999 -490.999] [102.418], Avg: [-453.656 -453.656 -453.656] (1.0000) ({r_i: None, r_t: [-831.496 -831.496 -831.496], eps: 1.0})
Step:   66500, Reward: [-437.388 -437.388 -437.388] [90.323], Avg: [-453.632 -453.632 -453.632] (1.0000) ({r_i: None, r_t: [-850.013 -850.013 -850.013], eps: 1.0})
Step:   66600, Reward: [-431.664 -431.664 -431.664] [106.541], Avg: [-453.599 -453.599 -453.599] (1.0000) ({r_i: None, r_t: [-851.677 -851.677 -851.677], eps: 1.0})
Step:   66700, Reward: [-451.754 -451.754 -451.754] [89.443], Avg: [-453.596 -453.596 -453.596] (1.0000) ({r_i: None, r_t: [-836.841 -836.841 -836.841], eps: 1.0})
Step:   66800, Reward: [-408.647 -408.647 -408.647] [71.137], Avg: [-453.529 -453.529 -453.529] (1.0000) ({r_i: None, r_t: [-849.826 -849.826 -849.826], eps: 1.0})
Step:   66900, Reward: [-427.993 -427.993 -427.993] [106.401], Avg: [-453.491 -453.491 -453.491] (1.0000) ({r_i: None, r_t: [-934.775 -934.775 -934.775], eps: 1.0})
Step:   67000, Reward: [-479.990 -479.990 -479.990] [95.671], Avg: [-453.530 -453.530 -453.530] (1.0000) ({r_i: None, r_t: [-878.392 -878.392 -878.392], eps: 1.0})
Step:   67100, Reward: [-412.969 -412.969 -412.969] [79.065], Avg: [-453.470 -453.470 -453.470] (1.0000) ({r_i: None, r_t: [-903.752 -903.752 -903.752], eps: 1.0})
Step:   67200, Reward: [-395.485 -395.485 -395.485] [71.055], Avg: [-453.384 -453.384 -453.384] (1.0000) ({r_i: None, r_t: [-847.738 -847.738 -847.738], eps: 1.0})
Step:   67300, Reward: [-447.231 -447.231 -447.231] [97.912], Avg: [-453.375 -453.375 -453.375] (1.0000) ({r_i: None, r_t: [-871.896 -871.896 -871.896], eps: 1.0})
Step:   67400, Reward: [-468.659 -468.659 -468.659] [95.489], Avg: [-453.397 -453.397 -453.397] (1.0000) ({r_i: None, r_t: [-837.331 -837.331 -837.331], eps: 1.0})
Step:   67500, Reward: [-444.202 -444.202 -444.202] [100.533], Avg: [-453.384 -453.384 -453.384] (1.0000) ({r_i: None, r_t: [-832.643 -832.643 -832.643], eps: 1.0})
Step:   67600, Reward: [-443.011 -443.011 -443.011] [101.288], Avg: [-453.369 -453.369 -453.369] (1.0000) ({r_i: None, r_t: [-836.840 -836.840 -836.840], eps: 1.0})
Step:   67700, Reward: [-445.110 -445.110 -445.110] [104.915], Avg: [-453.356 -453.356 -453.356] (1.0000) ({r_i: None, r_t: [-877.860 -877.860 -877.860], eps: 1.0})
Step:   67800, Reward: [-432.962 -432.962 -432.962] [124.850], Avg: [-453.326 -453.326 -453.326] (1.0000) ({r_i: None, r_t: [-860.687 -860.687 -860.687], eps: 1.0})
Step:   67900, Reward: [-429.986 -429.986 -429.986] [75.096], Avg: [-453.292 -453.292 -453.292] (1.0000) ({r_i: None, r_t: [-822.631 -822.631 -822.631], eps: 1.0})
Step:   68000, Reward: [-454.598 -454.598 -454.598] [100.813], Avg: [-453.294 -453.294 -453.294] (1.0000) ({r_i: None, r_t: [-869.862 -869.862 -869.862], eps: 1.0})
Step:   68100, Reward: [-443.830 -443.830 -443.830] [79.757], Avg: [-453.280 -453.280 -453.280] (1.0000) ({r_i: None, r_t: [-868.840 -868.840 -868.840], eps: 1.0})
Step:   68200, Reward: [-448.355 -448.355 -448.355] [113.293], Avg: [-453.273 -453.273 -453.273] (1.0000) ({r_i: None, r_t: [-916.877 -916.877 -916.877], eps: 1.0})
Step:   68300, Reward: [-437.713 -437.713 -437.713] [87.773], Avg: [-453.250 -453.250 -453.250] (1.0000) ({r_i: None, r_t: [-883.117 -883.117 -883.117], eps: 1.0})
Step:   68400, Reward: [-433.129 -433.129 -433.129] [111.171], Avg: [-453.221 -453.221 -453.221] (1.0000) ({r_i: None, r_t: [-844.014 -844.014 -844.014], eps: 1.0})
Step:   68500, Reward: [-415.258 -415.258 -415.258] [76.281], Avg: [-453.165 -453.165 -453.165] (1.0000) ({r_i: None, r_t: [-871.674 -871.674 -871.674], eps: 1.0})
Step:   68600, Reward: [-459.144 -459.144 -459.144] [112.585], Avg: [-453.174 -453.174 -453.174] (1.0000) ({r_i: None, r_t: [-858.632 -858.632 -858.632], eps: 1.0})
Step:   68700, Reward: [-452.284 -452.284 -452.284] [108.751], Avg: [-453.173 -453.173 -453.173] (1.0000) ({r_i: None, r_t: [-851.015 -851.015 -851.015], eps: 1.0})
Step:   68800, Reward: [-413.147 -413.147 -413.147] [110.406], Avg: [-453.115 -453.115 -453.115] (1.0000) ({r_i: None, r_t: [-845.923 -845.923 -845.923], eps: 1.0})
Step:   68900, Reward: [-407.318 -407.318 -407.318] [74.109], Avg: [-453.048 -453.048 -453.048] (1.0000) ({r_i: None, r_t: [-871.255 -871.255 -871.255], eps: 1.0})
Step:   69000, Reward: [-424.759 -424.759 -424.759] [102.608], Avg: [-453.007 -453.007 -453.007] (1.0000) ({r_i: None, r_t: [-838.396 -838.396 -838.396], eps: 1.0})
Step:   69100, Reward: [-408.562 -408.562 -408.562] [79.964], Avg: [-452.943 -452.943 -452.943] (1.0000) ({r_i: None, r_t: [-896.599 -896.599 -896.599], eps: 1.0})
Step:   69200, Reward: [-444.460 -444.460 -444.460] [68.246], Avg: [-452.931 -452.931 -452.931] (1.0000) ({r_i: None, r_t: [-855.697 -855.697 -855.697], eps: 1.0})
Step:   69300, Reward: [-404.975 -404.975 -404.975] [80.352], Avg: [-452.862 -452.862 -452.862] (1.0000) ({r_i: None, r_t: [-882.764 -882.764 -882.764], eps: 1.0})
Step:   69400, Reward: [-452.072 -452.072 -452.072] [86.738], Avg: [-452.861 -452.861 -452.861] (1.0000) ({r_i: None, r_t: [-914.946 -914.946 -914.946], eps: 1.0})
Step:   69500, Reward: [-446.038 -446.038 -446.038] [81.894], Avg: [-452.851 -452.851 -452.851] (1.0000) ({r_i: None, r_t: [-855.819 -855.819 -855.819], eps: 1.0})
Step:   69600, Reward: [-421.062 -421.062 -421.062] [65.493], Avg: [-452.805 -452.805 -452.805] (1.0000) ({r_i: None, r_t: [-919.253 -919.253 -919.253], eps: 1.0})
Step:   69700, Reward: [-424.354 -424.354 -424.354] [99.203], Avg: [-452.764 -452.764 -452.764] (1.0000) ({r_i: None, r_t: [-893.807 -893.807 -893.807], eps: 1.0})
Step:   69800, Reward: [-447.897 -447.897 -447.897] [108.753], Avg: [-452.758 -452.758 -452.758] (1.0000) ({r_i: None, r_t: [-920.994 -920.994 -920.994], eps: 1.0})
Step:   69900, Reward: [-460.407 -460.407 -460.407] [73.520], Avg: [-452.768 -452.768 -452.768] (1.0000) ({r_i: None, r_t: [-856.549 -856.549 -856.549], eps: 1.0})
Step:   70000, Reward: [-432.250 -432.250 -432.250] [75.642], Avg: [-452.739 -452.739 -452.739] (1.0000) ({r_i: None, r_t: [-866.322 -866.322 -866.322], eps: 1.0})
Step:   70100, Reward: [-442.748 -442.748 -442.748] [84.709], Avg: [-452.725 -452.725 -452.725] (1.0000) ({r_i: None, r_t: [-821.307 -821.307 -821.307], eps: 1.0})
Step:   70200, Reward: [-394.878 -394.878 -394.878] [87.569], Avg: [-452.643 -452.643 -452.643] (1.0000) ({r_i: None, r_t: [-870.922 -870.922 -870.922], eps: 1.0})
Step:   70300, Reward: [-384.388 -384.388 -384.388] [69.131], Avg: [-452.546 -452.546 -452.546] (1.0000) ({r_i: None, r_t: [-884.691 -884.691 -884.691], eps: 1.0})
Step:   70400, Reward: [-372.339 -372.339 -372.339] [59.739], Avg: [-452.432 -452.432 -452.432] (1.0000) ({r_i: None, r_t: [-829.702 -829.702 -829.702], eps: 1.0})
Step:   70500, Reward: [-423.822 -423.822 -423.822] [75.996], Avg: [-452.391 -452.391 -452.391] (1.0000) ({r_i: None, r_t: [-852.520 -852.520 -852.520], eps: 1.0})
Step:   70600, Reward: [-439.628 -439.628 -439.628] [96.959], Avg: [-452.373 -452.373 -452.373] (1.0000) ({r_i: None, r_t: [-849.695 -849.695 -849.695], eps: 1.0})
Step:   70700, Reward: [-454.574 -454.574 -454.574] [98.545], Avg: [-452.376 -452.376 -452.376] (1.0000) ({r_i: None, r_t: [-902.822 -902.822 -902.822], eps: 1.0})
Step:   70800, Reward: [-427.781 -427.781 -427.781] [84.246], Avg: [-452.342 -452.342 -452.342] (1.0000) ({r_i: None, r_t: [-933.759 -933.759 -933.759], eps: 1.0})
Step:   70900, Reward: [-460.973 -460.973 -460.973] [109.948], Avg: [-452.354 -452.354 -452.354] (1.0000) ({r_i: None, r_t: [-844.586 -844.586 -844.586], eps: 1.0})
Step:   71000, Reward: [-464.412 -464.412 -464.412] [115.275], Avg: [-452.371 -452.371 -452.371] (1.0000) ({r_i: None, r_t: [-884.691 -884.691 -884.691], eps: 1.0})
Step:   71100, Reward: [-456.477 -456.477 -456.477] [117.540], Avg: [-452.377 -452.377 -452.377] (1.0000) ({r_i: None, r_t: [-875.696 -875.696 -875.696], eps: 1.0})
Step:   71200, Reward: [-458.886 -458.886 -458.886] [134.003], Avg: [-452.386 -452.386 -452.386] (1.0000) ({r_i: None, r_t: [-927.739 -927.739 -927.739], eps: 1.0})
Step:   71300, Reward: [-421.760 -421.760 -421.760] [64.321], Avg: [-452.343 -452.343 -452.343] (1.0000) ({r_i: None, r_t: [-901.933 -901.933 -901.933], eps: 1.0})
Step:   71400, Reward: [-439.125 -439.125 -439.125] [60.200], Avg: [-452.324 -452.324 -452.324] (1.0000) ({r_i: None, r_t: [-872.890 -872.890 -872.890], eps: 1.0})
Step:   71500, Reward: [-442.749 -442.749 -442.749] [99.618], Avg: [-452.311 -452.311 -452.311] (1.0000) ({r_i: None, r_t: [-875.159 -875.159 -875.159], eps: 1.0})
Step:   71600, Reward: [-410.672 -410.672 -410.672] [87.686], Avg: [-452.253 -452.253 -452.253] (1.0000) ({r_i: None, r_t: [-920.073 -920.073 -920.073], eps: 1.0})
Step:   71700, Reward: [-425.956 -425.956 -425.956] [70.376], Avg: [-452.216 -452.216 -452.216] (1.0000) ({r_i: None, r_t: [-863.951 -863.951 -863.951], eps: 1.0})
Step:   71800, Reward: [-468.839 -468.839 -468.839] [94.282], Avg: [-452.239 -452.239 -452.239] (1.0000) ({r_i: None, r_t: [-880.699 -880.699 -880.699], eps: 1.0})
Step:   71900, Reward: [-440.748 -440.748 -440.748] [75.948], Avg: [-452.223 -452.223 -452.223] (1.0000) ({r_i: None, r_t: [-906.181 -906.181 -906.181], eps: 1.0})
Step:   72000, Reward: [-449.136 -449.136 -449.136] [104.353], Avg: [-452.219 -452.219 -452.219] (1.0000) ({r_i: None, r_t: [-878.436 -878.436 -878.436], eps: 1.0})
Step:   72100, Reward: [-413.372 -413.372 -413.372] [89.548], Avg: [-452.165 -452.165 -452.165] (1.0000) ({r_i: None, r_t: [-889.695 -889.695 -889.695], eps: 1.0})
Step:   72200, Reward: [-456.801 -456.801 -456.801] [123.199], Avg: [-452.172 -452.172 -452.172] (1.0000) ({r_i: None, r_t: [-842.674 -842.674 -842.674], eps: 1.0})
Step:   72300, Reward: [-470.263 -470.263 -470.263] [75.123], Avg: [-452.197 -452.197 -452.197] (1.0000) ({r_i: None, r_t: [-819.876 -819.876 -819.876], eps: 1.0})
Step:   72400, Reward: [-474.755 -474.755 -474.755] [79.353], Avg: [-452.228 -452.228 -452.228] (1.0000) ({r_i: None, r_t: [-878.166 -878.166 -878.166], eps: 1.0})
Step:   72500, Reward: [-415.544 -415.544 -415.544] [73.521], Avg: [-452.177 -452.177 -452.177] (1.0000) ({r_i: None, r_t: [-900.097 -900.097 -900.097], eps: 1.0})
Step:   72600, Reward: [-420.246 -420.246 -420.246] [78.151], Avg: [-452.133 -452.133 -452.133] (1.0000) ({r_i: None, r_t: [-883.589 -883.589 -883.589], eps: 1.0})
Step:   72700, Reward: [-429.653 -429.653 -429.653] [76.726], Avg: [-452.103 -452.103 -452.103] (1.0000) ({r_i: None, r_t: [-924.725 -924.725 -924.725], eps: 1.0})
Step:   72800, Reward: [-455.694 -455.694 -455.694] [98.009], Avg: [-452.108 -452.108 -452.108] (1.0000) ({r_i: None, r_t: [-859.267 -859.267 -859.267], eps: 1.0})
Step:   72900, Reward: [-448.181 -448.181 -448.181] [86.648], Avg: [-452.102 -452.102 -452.102] (1.0000) ({r_i: None, r_t: [-942.288 -942.288 -942.288], eps: 1.0})
Step:   73000, Reward: [-438.825 -438.825 -438.825] [81.116], Avg: [-452.084 -452.084 -452.084] (1.0000) ({r_i: None, r_t: [-849.497 -849.497 -849.497], eps: 1.0})
Step:   73100, Reward: [-405.993 -405.993 -405.993] [81.720], Avg: [-452.021 -452.021 -452.021] (1.0000) ({r_i: None, r_t: [-883.606 -883.606 -883.606], eps: 1.0})
Step:   73200, Reward: [-458.225 -458.225 -458.225] [117.843], Avg: [-452.029 -452.029 -452.029] (1.0000) ({r_i: None, r_t: [-909.782 -909.782 -909.782], eps: 1.0})
Step:   73300, Reward: [-449.315 -449.315 -449.315] [108.280], Avg: [-452.026 -452.026 -452.026] (1.0000) ({r_i: None, r_t: [-926.247 -926.247 -926.247], eps: 1.0})
Step:   73400, Reward: [-451.098 -451.098 -451.098] [98.861], Avg: [-452.025 -452.025 -452.025] (1.0000) ({r_i: None, r_t: [-842.932 -842.932 -842.932], eps: 1.0})
Step:   73500, Reward: [-437.080 -437.080 -437.080] [91.902], Avg: [-452.004 -452.004 -452.004] (1.0000) ({r_i: None, r_t: [-873.131 -873.131 -873.131], eps: 1.0})
Step:   73600, Reward: [-488.656 -488.656 -488.656] [91.046], Avg: [-452.054 -452.054 -452.054] (1.0000) ({r_i: None, r_t: [-866.387 -866.387 -866.387], eps: 1.0})
Step:   73700, Reward: [-476.919 -476.919 -476.919] [141.470], Avg: [-452.088 -452.088 -452.088] (1.0000) ({r_i: None, r_t: [-874.479 -874.479 -874.479], eps: 1.0})
Step:   73800, Reward: [-441.793 -441.793 -441.793] [98.583], Avg: [-452.074 -452.074 -452.074] (1.0000) ({r_i: None, r_t: [-864.189 -864.189 -864.189], eps: 1.0})
Step:   73900, Reward: [-426.220 -426.220 -426.220] [103.339], Avg: [-452.039 -452.039 -452.039] (1.0000) ({r_i: None, r_t: [-825.371 -825.371 -825.371], eps: 1.0})
Step:   74000, Reward: [-456.678 -456.678 -456.678] [74.554], Avg: [-452.045 -452.045 -452.045] (1.0000) ({r_i: None, r_t: [-926.507 -926.507 -926.507], eps: 1.0})
Step:   74100, Reward: [-436.818 -436.818 -436.818] [100.323], Avg: [-452.024 -452.024 -452.024] (1.0000) ({r_i: None, r_t: [-890.067 -890.067 -890.067], eps: 1.0})
Step:   74200, Reward: [-505.509 -505.509 -505.509] [84.303], Avg: [-452.096 -452.096 -452.096] (1.0000) ({r_i: None, r_t: [-892.910 -892.910 -892.910], eps: 1.0})
Step:   74300, Reward: [-407.089 -407.089 -407.089] [89.536], Avg: [-452.036 -452.036 -452.036] (1.0000) ({r_i: None, r_t: [-868.970 -868.970 -868.970], eps: 1.0})
Step:   74400, Reward: [-423.367 -423.367 -423.367] [111.086], Avg: [-451.998 -451.998 -451.998] (1.0000) ({r_i: None, r_t: [-889.044 -889.044 -889.044], eps: 1.0})
Step:   74500, Reward: [-456.893 -456.893 -456.893] [101.114], Avg: [-452.004 -452.004 -452.004] (1.0000) ({r_i: None, r_t: [-905.044 -905.044 -905.044], eps: 1.0})
Step:   74600, Reward: [-423.986 -423.986 -423.986] [74.039], Avg: [-451.967 -451.967 -451.967] (1.0000) ({r_i: None, r_t: [-866.860 -866.860 -866.860], eps: 1.0})
Step:   74700, Reward: [-401.967 -401.967 -401.967] [75.877], Avg: [-451.900 -451.900 -451.900] (1.0000) ({r_i: None, r_t: [-832.549 -832.549 -832.549], eps: 1.0})
Step:   74800, Reward: [-453.258 -453.258 -453.258] [65.911], Avg: [-451.902 -451.902 -451.902] (1.0000) ({r_i: None, r_t: [-848.754 -848.754 -848.754], eps: 1.0})
Step:   74900, Reward: [-427.245 -427.245 -427.245] [93.829], Avg: [-451.869 -451.869 -451.869] (1.0000) ({r_i: None, r_t: [-813.997 -813.997 -813.997], eps: 1.0})
Step:   75000, Reward: [-417.742 -417.742 -417.742] [86.359], Avg: [-451.823 -451.823 -451.823] (1.0000) ({r_i: None, r_t: [-864.874 -864.874 -864.874], eps: 1.0})
Step:   75100, Reward: [-431.746 -431.746 -431.746] [105.839], Avg: [-451.797 -451.797 -451.797] (1.0000) ({r_i: None, r_t: [-801.492 -801.492 -801.492], eps: 1.0})
Step:   75200, Reward: [-441.915 -441.915 -441.915] [102.076], Avg: [-451.783 -451.783 -451.783] (1.0000) ({r_i: None, r_t: [-943.650 -943.650 -943.650], eps: 1.0})
Step:   75300, Reward: [-417.031 -417.031 -417.031] [103.422], Avg: [-451.737 -451.737 -451.737] (1.0000) ({r_i: None, r_t: [-865.839 -865.839 -865.839], eps: 1.0})
Step:   75400, Reward: [-436.371 -436.371 -436.371] [90.648], Avg: [-451.717 -451.717 -451.717] (1.0000) ({r_i: None, r_t: [-878.886 -878.886 -878.886], eps: 1.0})
Step:   75500, Reward: [-408.691 -408.691 -408.691] [92.274], Avg: [-451.660 -451.660 -451.660] (1.0000) ({r_i: None, r_t: [-920.656 -920.656 -920.656], eps: 1.0})
Step:   75600, Reward: [-423.443 -423.443 -423.443] [77.520], Avg: [-451.623 -451.623 -451.623] (1.0000) ({r_i: None, r_t: [-838.590 -838.590 -838.590], eps: 1.0})
Step:   75700, Reward: [-474.639 -474.639 -474.639] [133.093], Avg: [-451.653 -451.653 -451.653] (1.0000) ({r_i: None, r_t: [-884.021 -884.021 -884.021], eps: 1.0})
Step:   75800, Reward: [-435.128 -435.128 -435.128] [63.747], Avg: [-451.631 -451.631 -451.631] (1.0000) ({r_i: None, r_t: [-828.340 -828.340 -828.340], eps: 1.0})
Step:   75900, Reward: [-432.328 -432.328 -432.328] [90.725], Avg: [-451.606 -451.606 -451.606] (1.0000) ({r_i: None, r_t: [-837.932 -837.932 -837.932], eps: 1.0})
Step:   76000, Reward: [-436.879 -436.879 -436.879] [97.186], Avg: [-451.587 -451.587 -451.587] (1.0000) ({r_i: None, r_t: [-864.680 -864.680 -864.680], eps: 1.0})
Step:   76100, Reward: [-460.756 -460.756 -460.756] [106.858], Avg: [-451.599 -451.599 -451.599] (1.0000) ({r_i: None, r_t: [-905.201 -905.201 -905.201], eps: 1.0})
Step:   76200, Reward: [-401.673 -401.673 -401.673] [51.088], Avg: [-451.533 -451.533 -451.533] (1.0000) ({r_i: None, r_t: [-852.418 -852.418 -852.418], eps: 1.0})
Step:   76300, Reward: [-424.339 -424.339 -424.339] [72.653], Avg: [-451.498 -451.498 -451.498] (1.0000) ({r_i: None, r_t: [-894.014 -894.014 -894.014], eps: 1.0})
Step:   76400, Reward: [-485.157 -485.157 -485.157] [96.001], Avg: [-451.542 -451.542 -451.542] (1.0000) ({r_i: None, r_t: [-905.537 -905.537 -905.537], eps: 1.0})
Step:   76500, Reward: [-447.107 -447.107 -447.107] [97.512], Avg: [-451.536 -451.536 -451.536] (1.0000) ({r_i: None, r_t: [-871.841 -871.841 -871.841], eps: 1.0})
Step:   76600, Reward: [-490.338 -490.338 -490.338] [98.926], Avg: [-451.586 -451.586 -451.586] (1.0000) ({r_i: None, r_t: [-845.279 -845.279 -845.279], eps: 1.0})
Step:   76700, Reward: [-413.795 -413.795 -413.795] [96.350], Avg: [-451.537 -451.537 -451.537] (1.0000) ({r_i: None, r_t: [-795.030 -795.030 -795.030], eps: 1.0})
Step:   76800, Reward: [-458.493 -458.493 -458.493] [104.862], Avg: [-451.546 -451.546 -451.546] (1.0000) ({r_i: None, r_t: [-930.302 -930.302 -930.302], eps: 1.0})
Step:   76900, Reward: [-436.459 -436.459 -436.459] [134.248], Avg: [-451.527 -451.527 -451.527] (1.0000) ({r_i: None, r_t: [-863.560 -863.560 -863.560], eps: 1.0})
Step:   77000, Reward: [-420.691 -420.691 -420.691] [80.200], Avg: [-451.487 -451.487 -451.487] (1.0000) ({r_i: None, r_t: [-892.928 -892.928 -892.928], eps: 1.0})
Step:   77100, Reward: [-437.126 -437.126 -437.126] [85.871], Avg: [-451.468 -451.468 -451.468] (1.0000) ({r_i: None, r_t: [-848.478 -848.478 -848.478], eps: 1.0})
Step:   77200, Reward: [-431.626 -431.626 -431.626] [81.695], Avg: [-451.442 -451.442 -451.442] (1.0000) ({r_i: None, r_t: [-907.672 -907.672 -907.672], eps: 1.0})
Step:   77300, Reward: [-427.790 -427.790 -427.790] [77.214], Avg: [-451.412 -451.412 -451.412] (1.0000) ({r_i: None, r_t: [-953.550 -953.550 -953.550], eps: 1.0})
Step:   77400, Reward: [-413.444 -413.444 -413.444] [70.716], Avg: [-451.363 -451.363 -451.363] (1.0000) ({r_i: None, r_t: [-862.980 -862.980 -862.980], eps: 1.0})
Step:   77500, Reward: [-446.659 -446.659 -446.659] [126.616], Avg: [-451.357 -451.357 -451.357] (1.0000) ({r_i: None, r_t: [-864.543 -864.543 -864.543], eps: 1.0})
Step:   77600, Reward: [-424.461 -424.461 -424.461] [87.792], Avg: [-451.322 -451.322 -451.322] (1.0000) ({r_i: None, r_t: [-848.797 -848.797 -848.797], eps: 1.0})
Step:   77700, Reward: [-416.129 -416.129 -416.129] [84.142], Avg: [-451.277 -451.277 -451.277] (1.0000) ({r_i: None, r_t: [-845.228 -845.228 -845.228], eps: 1.0})
Step:   77800, Reward: [-486.677 -486.677 -486.677] [83.742], Avg: [-451.322 -451.322 -451.322] (1.0000) ({r_i: None, r_t: [-819.948 -819.948 -819.948], eps: 1.0})
Step:   77900, Reward: [-399.096 -399.096 -399.096] [80.331], Avg: [-451.255 -451.255 -451.255] (1.0000) ({r_i: None, r_t: [-828.176 -828.176 -828.176], eps: 1.0})
Step:   78000, Reward: [-409.929 -409.929 -409.929] [73.584], Avg: [-451.202 -451.202 -451.202] (1.0000) ({r_i: None, r_t: [-895.741 -895.741 -895.741], eps: 1.0})
Step:   78100, Reward: [-470.352 -470.352 -470.352] [137.891], Avg: [-451.227 -451.227 -451.227] (1.0000) ({r_i: None, r_t: [-840.351 -840.351 -840.351], eps: 1.0})
Step:   78200, Reward: [-444.947 -444.947 -444.947] [82.405], Avg: [-451.219 -451.219 -451.219] (1.0000) ({r_i: None, r_t: [-882.019 -882.019 -882.019], eps: 1.0})
Step:   78300, Reward: [-445.517 -445.517 -445.517] [69.787], Avg: [-451.212 -451.212 -451.212] (1.0000) ({r_i: None, r_t: [-871.127 -871.127 -871.127], eps: 1.0})
Step:   78400, Reward: [-452.598 -452.598 -452.598] [112.223], Avg: [-451.213 -451.213 -451.213] (1.0000) ({r_i: None, r_t: [-793.933 -793.933 -793.933], eps: 1.0})
Step:   78500, Reward: [-408.746 -408.746 -408.746] [104.095], Avg: [-451.159 -451.159 -451.159] (1.0000) ({r_i: None, r_t: [-848.434 -848.434 -848.434], eps: 1.0})
Step:   78600, Reward: [-451.754 -451.754 -451.754] [80.854], Avg: [-451.160 -451.160 -451.160] (1.0000) ({r_i: None, r_t: [-840.034 -840.034 -840.034], eps: 1.0})
Step:   78700, Reward: [-414.021 -414.021 -414.021] [86.970], Avg: [-451.113 -451.113 -451.113] (1.0000) ({r_i: None, r_t: [-834.931 -834.931 -834.931], eps: 1.0})
Step:   78800, Reward: [-403.657 -403.657 -403.657] [85.724], Avg: [-451.053 -451.053 -451.053] (1.0000) ({r_i: None, r_t: [-922.707 -922.707 -922.707], eps: 1.0})
Step:   78900, Reward: [-452.593 -452.593 -452.593] [125.839], Avg: [-451.055 -451.055 -451.055] (1.0000) ({r_i: None, r_t: [-856.025 -856.025 -856.025], eps: 1.0})
Step:   79000, Reward: [-418.590 -418.590 -418.590] [68.062], Avg: [-451.014 -451.014 -451.014] (1.0000) ({r_i: None, r_t: [-856.078 -856.078 -856.078], eps: 1.0})
Step:   79100, Reward: [-470.011 -470.011 -470.011] [99.742], Avg: [-451.038 -451.038 -451.038] (1.0000) ({r_i: None, r_t: [-850.518 -850.518 -850.518], eps: 1.0})
Step:   79200, Reward: [-433.683 -433.683 -433.683] [88.898], Avg: [-451.016 -451.016 -451.016] (1.0000) ({r_i: None, r_t: [-863.876 -863.876 -863.876], eps: 1.0})
Step:   79300, Reward: [-434.603 -434.603 -434.603] [92.072], Avg: [-450.995 -450.995 -450.995] (1.0000) ({r_i: None, r_t: [-806.238 -806.238 -806.238], eps: 1.0})
Step:   79400, Reward: [-477.785 -477.785 -477.785] [101.383], Avg: [-451.029 -451.029 -451.029] (1.0000) ({r_i: None, r_t: [-874.301 -874.301 -874.301], eps: 1.0})
Step:   79500, Reward: [-490.123 -490.123 -490.123] [138.254], Avg: [-451.078 -451.078 -451.078] (1.0000) ({r_i: None, r_t: [-883.368 -883.368 -883.368], eps: 1.0})
Step:   79600, Reward: [-433.069 -433.069 -433.069] [100.168], Avg: [-451.055 -451.055 -451.055] (1.0000) ({r_i: None, r_t: [-882.682 -882.682 -882.682], eps: 1.0})
Step:   79700, Reward: [-404.733 -404.733 -404.733] [98.456], Avg: [-450.997 -450.997 -450.997] (1.0000) ({r_i: None, r_t: [-900.208 -900.208 -900.208], eps: 1.0})
Step:   79800, Reward: [-461.469 -461.469 -461.469] [85.842], Avg: [-451.011 -451.011 -451.011] (1.0000) ({r_i: None, r_t: [-877.562 -877.562 -877.562], eps: 1.0})
Step:   79900, Reward: [-429.756 -429.756 -429.756] [76.646], Avg: [-450.984 -450.984 -450.984] (1.0000) ({r_i: None, r_t: [-917.545 -917.545 -917.545], eps: 1.0})
Step:   80000, Reward: [-441.617 -441.617 -441.617] [95.987], Avg: [-450.972 -450.972 -450.972] (1.0000) ({r_i: None, r_t: [-875.952 -875.952 -875.952], eps: 1.0})
Step:   80100, Reward: [-441.243 -441.243 -441.243] [53.513], Avg: [-450.960 -450.960 -450.960] (1.0000) ({r_i: None, r_t: [-891.048 -891.048 -891.048], eps: 1.0})
Step:   80200, Reward: [-422.925 -422.925 -422.925] [92.964], Avg: [-450.925 -450.925 -450.925] (1.0000) ({r_i: None, r_t: [-858.762 -858.762 -858.762], eps: 1.0})
Step:   80300, Reward: [-440.205 -440.205 -440.205] [100.967], Avg: [-450.912 -450.912 -450.912] (1.0000) ({r_i: None, r_t: [-803.031 -803.031 -803.031], eps: 1.0})
Step:   80400, Reward: [-474.146 -474.146 -474.146] [102.507], Avg: [-450.941 -450.941 -450.941] (1.0000) ({r_i: None, r_t: [-958.698 -958.698 -958.698], eps: 1.0})
Step:   80500, Reward: [-441.857 -441.857 -441.857] [97.865], Avg: [-450.929 -450.929 -450.929] (1.0000) ({r_i: None, r_t: [-900.165 -900.165 -900.165], eps: 1.0})
Step:   80600, Reward: [-431.594 -431.594 -431.594] [87.713], Avg: [-450.906 -450.906 -450.906] (1.0000) ({r_i: None, r_t: [-871.610 -871.610 -871.610], eps: 1.0})
Step:   80700, Reward: [-423.420 -423.420 -423.420] [67.125], Avg: [-450.871 -450.871 -450.871] (1.0000) ({r_i: None, r_t: [-840.218 -840.218 -840.218], eps: 1.0})
Step:   80800, Reward: [-411.803 -411.803 -411.803] [74.345], Avg: [-450.823 -450.823 -450.823] (1.0000) ({r_i: None, r_t: [-884.247 -884.247 -884.247], eps: 1.0})
Step:   80900, Reward: [-421.265 -421.265 -421.265] [77.743], Avg: [-450.787 -450.787 -450.787] (1.0000) ({r_i: None, r_t: [-833.580 -833.580 -833.580], eps: 1.0})
Step:   81000, Reward: [-433.363 -433.363 -433.363] [135.112], Avg: [-450.765 -450.765 -450.765] (1.0000) ({r_i: None, r_t: [-885.057 -885.057 -885.057], eps: 1.0})
Step:   81100, Reward: [-458.690 -458.690 -458.690] [97.384], Avg: [-450.775 -450.775 -450.775] (1.0000) ({r_i: None, r_t: [-861.833 -861.833 -861.833], eps: 1.0})
Step:   81200, Reward: [-444.244 -444.244 -444.244] [116.546], Avg: [-450.767 -450.767 -450.767] (1.0000) ({r_i: None, r_t: [-908.658 -908.658 -908.658], eps: 1.0})
Step:   81300, Reward: [-459.579 -459.579 -459.579] [103.318], Avg: [-450.778 -450.778 -450.778] (1.0000) ({r_i: None, r_t: [-857.283 -857.283 -857.283], eps: 1.0})
Step:   81400, Reward: [-445.580 -445.580 -445.580] [86.892], Avg: [-450.771 -450.771 -450.771] (1.0000) ({r_i: None, r_t: [-887.957 -887.957 -887.957], eps: 1.0})
Step:   81500, Reward: [-394.402 -394.402 -394.402] [56.756], Avg: [-450.702 -450.702 -450.702] (1.0000) ({r_i: None, r_t: [-882.375 -882.375 -882.375], eps: 1.0})
Step:   81600, Reward: [-461.277 -461.277 -461.277] [74.407], Avg: [-450.715 -450.715 -450.715] (1.0000) ({r_i: None, r_t: [-874.239 -874.239 -874.239], eps: 1.0})
Step:   81700, Reward: [-460.954 -460.954 -460.954] [97.386], Avg: [-450.728 -450.728 -450.728] (1.0000) ({r_i: None, r_t: [-878.291 -878.291 -878.291], eps: 1.0})
Step:   81800, Reward: [-417.788 -417.788 -417.788] [73.064], Avg: [-450.688 -450.688 -450.688] (1.0000) ({r_i: None, r_t: [-906.901 -906.901 -906.901], eps: 1.0})
Step:   81900, Reward: [-417.582 -417.582 -417.582] [74.035], Avg: [-450.647 -450.647 -450.647] (1.0000) ({r_i: None, r_t: [-885.750 -885.750 -885.750], eps: 1.0})
Step:   82000, Reward: [-469.130 -469.130 -469.130] [94.585], Avg: [-450.670 -450.670 -450.670] (1.0000) ({r_i: None, r_t: [-882.180 -882.180 -882.180], eps: 1.0})
Step:   82100, Reward: [-425.558 -425.558 -425.558] [95.022], Avg: [-450.639 -450.639 -450.639] (1.0000) ({r_i: None, r_t: [-857.324 -857.324 -857.324], eps: 1.0})
Step:   82200, Reward: [-423.212 -423.212 -423.212] [80.791], Avg: [-450.606 -450.606 -450.606] (1.0000) ({r_i: None, r_t: [-869.308 -869.308 -869.308], eps: 1.0})
Step:   82300, Reward: [-425.383 -425.383 -425.383] [82.460], Avg: [-450.575 -450.575 -450.575] (1.0000) ({r_i: None, r_t: [-904.060 -904.060 -904.060], eps: 1.0})
Step:   82400, Reward: [-435.204 -435.204 -435.204] [91.071], Avg: [-450.557 -450.557 -450.557] (1.0000) ({r_i: None, r_t: [-901.418 -901.418 -901.418], eps: 1.0})
Step:   82500, Reward: [-467.298 -467.298 -467.298] [96.626], Avg: [-450.577 -450.577 -450.577] (1.0000) ({r_i: None, r_t: [-891.410 -891.410 -891.410], eps: 1.0})
Step:   82600, Reward: [-428.226 -428.226 -428.226] [93.711], Avg: [-450.550 -450.550 -450.550] (1.0000) ({r_i: None, r_t: [-803.604 -803.604 -803.604], eps: 1.0})
Step:   82700, Reward: [-441.396 -441.396 -441.396] [106.767], Avg: [-450.539 -450.539 -450.539] (1.0000) ({r_i: None, r_t: [-850.874 -850.874 -850.874], eps: 1.0})
Step:   82800, Reward: [-469.223 -469.223 -469.223] [125.184], Avg: [-450.561 -450.561 -450.561] (1.0000) ({r_i: None, r_t: [-823.742 -823.742 -823.742], eps: 1.0})
Step:   82900, Reward: [-433.419 -433.419 -433.419] [74.200], Avg: [-450.541 -450.541 -450.541] (1.0000) ({r_i: None, r_t: [-914.543 -914.543 -914.543], eps: 1.0})
Step:   83000, Reward: [-376.974 -376.974 -376.974] [67.360], Avg: [-450.452 -450.452 -450.452] (1.0000) ({r_i: None, r_t: [-877.265 -877.265 -877.265], eps: 1.0})
Step:   83100, Reward: [-458.956 -458.956 -458.956] [68.726], Avg: [-450.462 -450.462 -450.462] (1.0000) ({r_i: None, r_t: [-871.594 -871.594 -871.594], eps: 1.0})
Step:   83200, Reward: [-445.718 -445.718 -445.718] [100.905], Avg: [-450.457 -450.457 -450.457] (1.0000) ({r_i: None, r_t: [-848.902 -848.902 -848.902], eps: 1.0})
Step:   83300, Reward: [-435.890 -435.890 -435.890] [89.222], Avg: [-450.439 -450.439 -450.439] (1.0000) ({r_i: None, r_t: [-883.807 -883.807 -883.807], eps: 1.0})
Step:   83400, Reward: [-422.397 -422.397 -422.397] [76.286], Avg: [-450.406 -450.406 -450.406] (1.0000) ({r_i: None, r_t: [-900.676 -900.676 -900.676], eps: 1.0})
Step:   83500, Reward: [-463.871 -463.871 -463.871] [96.679], Avg: [-450.422 -450.422 -450.422] (1.0000) ({r_i: None, r_t: [-853.538 -853.538 -853.538], eps: 1.0})
Step:   83600, Reward: [-456.631 -456.631 -456.631] [93.838], Avg: [-450.429 -450.429 -450.429] (1.0000) ({r_i: None, r_t: [-831.023 -831.023 -831.023], eps: 1.0})
Step:   83700, Reward: [-497.409 -497.409 -497.409] [110.196], Avg: [-450.485 -450.485 -450.485] (1.0000) ({r_i: None, r_t: [-908.533 -908.533 -908.533], eps: 1.0})
Step:   83800, Reward: [-411.285 -411.285 -411.285] [70.477], Avg: [-450.438 -450.438 -450.438] (1.0000) ({r_i: None, r_t: [-879.931 -879.931 -879.931], eps: 1.0})
Step:   83900, Reward: [-445.819 -445.819 -445.819] [92.929], Avg: [-450.433 -450.433 -450.433] (1.0000) ({r_i: None, r_t: [-865.713 -865.713 -865.713], eps: 1.0})
Step:   84000, Reward: [-420.129 -420.129 -420.129] [76.890], Avg: [-450.397 -450.397 -450.397] (1.0000) ({r_i: None, r_t: [-895.215 -895.215 -895.215], eps: 1.0})
Step:   84100, Reward: [-450.197 -450.197 -450.197] [93.442], Avg: [-450.397 -450.397 -450.397] (1.0000) ({r_i: None, r_t: [-837.781 -837.781 -837.781], eps: 1.0})
Step:   84200, Reward: [-444.509 -444.509 -444.509] [69.358], Avg: [-450.390 -450.390 -450.390] (1.0000) ({r_i: None, r_t: [-830.809 -830.809 -830.809], eps: 1.0})
Step:   84300, Reward: [-463.737 -463.737 -463.737] [117.795], Avg: [-450.406 -450.406 -450.406] (1.0000) ({r_i: None, r_t: [-850.723 -850.723 -850.723], eps: 1.0})
Step:   84400, Reward: [-453.472 -453.472 -453.472] [54.885], Avg: [-450.409 -450.409 -450.409] (1.0000) ({r_i: None, r_t: [-900.838 -900.838 -900.838], eps: 1.0})
Step:   84500, Reward: [-407.382 -407.382 -407.382] [74.095], Avg: [-450.358 -450.358 -450.358] (1.0000) ({r_i: None, r_t: [-852.081 -852.081 -852.081], eps: 1.0})
Step:   84600, Reward: [-394.450 -394.450 -394.450] [83.604], Avg: [-450.292 -450.292 -450.292] (1.0000) ({r_i: None, r_t: [-883.504 -883.504 -883.504], eps: 1.0})
Step:   84700, Reward: [-480.161 -480.161 -480.161] [89.931], Avg: [-450.328 -450.328 -450.328] (1.0000) ({r_i: None, r_t: [-806.109 -806.109 -806.109], eps: 1.0})
Step:   84800, Reward: [-411.769 -411.769 -411.769] [93.883], Avg: [-450.282 -450.282 -450.282] (1.0000) ({r_i: None, r_t: [-847.901 -847.901 -847.901], eps: 1.0})
Step:   84900, Reward: [-420.417 -420.417 -420.417] [90.422], Avg: [-450.247 -450.247 -450.247] (1.0000) ({r_i: None, r_t: [-852.070 -852.070 -852.070], eps: 1.0})
Step:   85000, Reward: [-482.433 -482.433 -482.433] [98.496], Avg: [-450.285 -450.285 -450.285] (1.0000) ({r_i: None, r_t: [-861.492 -861.492 -861.492], eps: 1.0})
Step:   85100, Reward: [-436.878 -436.878 -436.878] [75.987], Avg: [-450.269 -450.269 -450.269] (1.0000) ({r_i: None, r_t: [-884.654 -884.654 -884.654], eps: 1.0})
Step:   85200, Reward: [-450.432 -450.432 -450.432] [85.173], Avg: [-450.269 -450.269 -450.269] (1.0000) ({r_i: None, r_t: [-853.964 -853.964 -853.964], eps: 1.0})
Step:   85300, Reward: [-481.935 -481.935 -481.935] [83.258], Avg: [-450.306 -450.306 -450.306] (1.0000) ({r_i: None, r_t: [-873.823 -873.823 -873.823], eps: 1.0})
Step:   85400, Reward: [-420.417 -420.417 -420.417] [69.693], Avg: [-450.271 -450.271 -450.271] (1.0000) ({r_i: None, r_t: [-840.019 -840.019 -840.019], eps: 1.0})
Step:   85500, Reward: [-440.465 -440.465 -440.465] [85.907], Avg: [-450.260 -450.260 -450.260] (1.0000) ({r_i: None, r_t: [-870.615 -870.615 -870.615], eps: 1.0})
Step:   85600, Reward: [-447.660 -447.660 -447.660] [82.602], Avg: [-450.257 -450.257 -450.257] (1.0000) ({r_i: None, r_t: [-850.242 -850.242 -850.242], eps: 1.0})
Step:   85700, Reward: [-419.660 -419.660 -419.660] [69.241], Avg: [-450.221 -450.221 -450.221] (1.0000) ({r_i: None, r_t: [-820.534 -820.534 -820.534], eps: 1.0})
Step:   85800, Reward: [-411.624 -411.624 -411.624] [94.449], Avg: [-450.176 -450.176 -450.176] (1.0000) ({r_i: None, r_t: [-878.413 -878.413 -878.413], eps: 1.0})
Step:   85900, Reward: [-438.233 -438.233 -438.233] [85.839], Avg: [-450.162 -450.162 -450.162] (1.0000) ({r_i: None, r_t: [-902.902 -902.902 -902.902], eps: 1.0})
Step:   86000, Reward: [-425.637 -425.637 -425.637] [70.890], Avg: [-450.134 -450.134 -450.134] (1.0000) ({r_i: None, r_t: [-835.127 -835.127 -835.127], eps: 1.0})
Step:   86100, Reward: [-375.743 -375.743 -375.743] [81.953], Avg: [-450.048 -450.048 -450.048] (1.0000) ({r_i: None, r_t: [-828.918 -828.918 -828.918], eps: 1.0})
Step:   86200, Reward: [-461.685 -461.685 -461.685] [110.352], Avg: [-450.061 -450.061 -450.061] (1.0000) ({r_i: None, r_t: [-903.413 -903.413 -903.413], eps: 1.0})
Step:   86300, Reward: [-429.104 -429.104 -429.104] [85.451], Avg: [-450.037 -450.037 -450.037] (1.0000) ({r_i: None, r_t: [-860.281 -860.281 -860.281], eps: 1.0})
Step:   86400, Reward: [-405.877 -405.877 -405.877] [73.306], Avg: [-449.986 -449.986 -449.986] (1.0000) ({r_i: None, r_t: [-937.234 -937.234 -937.234], eps: 1.0})
Step:   86500, Reward: [-416.449 -416.449 -416.449] [109.011], Avg: [-449.947 -449.947 -449.947] (1.0000) ({r_i: None, r_t: [-848.099 -848.099 -848.099], eps: 1.0})
Step:   86600, Reward: [-438.817 -438.817 -438.817] [126.084], Avg: [-449.934 -449.934 -449.934] (1.0000) ({r_i: None, r_t: [-892.734 -892.734 -892.734], eps: 1.0})
Step:   86700, Reward: [-408.376 -408.376 -408.376] [65.081], Avg: [-449.886 -449.886 -449.886] (1.0000) ({r_i: None, r_t: [-810.949 -810.949 -810.949], eps: 1.0})
Step:   86800, Reward: [-449.024 -449.024 -449.024] [74.042], Avg: [-449.885 -449.885 -449.885] (1.0000) ({r_i: None, r_t: [-851.900 -851.900 -851.900], eps: 1.0})
Step:   86900, Reward: [-426.738 -426.738 -426.738] [94.074], Avg: [-449.859 -449.859 -449.859] (1.0000) ({r_i: None, r_t: [-866.829 -866.829 -866.829], eps: 1.0})
Step:   87000, Reward: [-415.119 -415.119 -415.119] [83.809], Avg: [-449.819 -449.819 -449.819] (1.0000) ({r_i: None, r_t: [-916.671 -916.671 -916.671], eps: 1.0})
Step:   87100, Reward: [-425.618 -425.618 -425.618] [84.362], Avg: [-449.791 -449.791 -449.791] (1.0000) ({r_i: None, r_t: [-829.147 -829.147 -829.147], eps: 1.0})
Step:   87200, Reward: [-442.673 -442.673 -442.673] [97.102], Avg: [-449.783 -449.783 -449.783] (1.0000) ({r_i: None, r_t: [-829.433 -829.433 -829.433], eps: 1.0})
Step:   87300, Reward: [-397.867 -397.867 -397.867] [53.995], Avg: [-449.724 -449.724 -449.724] (1.0000) ({r_i: None, r_t: [-858.983 -858.983 -858.983], eps: 1.0})
Step:   87400, Reward: [-418.639 -418.639 -418.639] [93.799], Avg: [-449.688 -449.688 -449.688] (1.0000) ({r_i: None, r_t: [-826.642 -826.642 -826.642], eps: 1.0})
Step:   87500, Reward: [-438.061 -438.061 -438.061] [90.809], Avg: [-449.675 -449.675 -449.675] (1.0000) ({r_i: None, r_t: [-862.838 -862.838 -862.838], eps: 1.0})
Step:   87600, Reward: [-418.004 -418.004 -418.004] [64.623], Avg: [-449.639 -449.639 -449.639] (1.0000) ({r_i: None, r_t: [-880.957 -880.957 -880.957], eps: 1.0})
Step:   87700, Reward: [-485.365 -485.365 -485.365] [64.505], Avg: [-449.679 -449.679 -449.679] (1.0000) ({r_i: None, r_t: [-859.473 -859.473 -859.473], eps: 1.0})
Step:   87800, Reward: [-446.698 -446.698 -446.698] [95.528], Avg: [-449.676 -449.676 -449.676] (1.0000) ({r_i: None, r_t: [-818.701 -818.701 -818.701], eps: 1.0})
Step:   87900, Reward: [-387.544 -387.544 -387.544] [75.839], Avg: [-449.605 -449.605 -449.605] (1.0000) ({r_i: None, r_t: [-840.694 -840.694 -840.694], eps: 1.0})
Step:   88000, Reward: [-446.881 -446.881 -446.881] [78.132], Avg: [-449.602 -449.602 -449.602] (1.0000) ({r_i: None, r_t: [-826.735 -826.735 -826.735], eps: 1.0})
Step:   88100, Reward: [-416.659 -416.659 -416.659] [65.334], Avg: [-449.565 -449.565 -449.565] (1.0000) ({r_i: None, r_t: [-852.667 -852.667 -852.667], eps: 1.0})
Step:   88200, Reward: [-459.158 -459.158 -459.158] [80.963], Avg: [-449.576 -449.576 -449.576] (1.0000) ({r_i: None, r_t: [-831.134 -831.134 -831.134], eps: 1.0})
Step:   88300, Reward: [-436.622 -436.622 -436.622] [100.966], Avg: [-449.561 -449.561 -449.561] (1.0000) ({r_i: None, r_t: [-822.159 -822.159 -822.159], eps: 1.0})
Step:   88400, Reward: [-427.624 -427.624 -427.624] [87.708], Avg: [-449.536 -449.536 -449.536] (1.0000) ({r_i: None, r_t: [-869.388 -869.388 -869.388], eps: 1.0})
Step:   88500, Reward: [-406.162 -406.162 -406.162] [63.143], Avg: [-449.487 -449.487 -449.487] (1.0000) ({r_i: None, r_t: [-855.556 -855.556 -855.556], eps: 1.0})
Step:   88600, Reward: [-438.966 -438.966 -438.966] [91.587], Avg: [-449.475 -449.475 -449.475] (1.0000) ({r_i: None, r_t: [-860.688 -860.688 -860.688], eps: 1.0})
Step:   88700, Reward: [-441.132 -441.132 -441.132] [122.477], Avg: [-449.466 -449.466 -449.466] (1.0000) ({r_i: None, r_t: [-884.434 -884.434 -884.434], eps: 1.0})
Step:   88800, Reward: [-453.851 -453.851 -453.851] [126.726], Avg: [-449.471 -449.471 -449.471] (1.0000) ({r_i: None, r_t: [-820.770 -820.770 -820.770], eps: 1.0})
Step:   88900, Reward: [-475.472 -475.472 -475.472] [113.506], Avg: [-449.500 -449.500 -449.500] (1.0000) ({r_i: None, r_t: [-933.271 -933.271 -933.271], eps: 1.0})
Step:   89000, Reward: [-463.930 -463.930 -463.930] [92.322], Avg: [-449.516 -449.516 -449.516] (1.0000) ({r_i: None, r_t: [-879.626 -879.626 -879.626], eps: 1.0})
Step:   89100, Reward: [-417.623 -417.623 -417.623] [81.761], Avg: [-449.481 -449.481 -449.481] (1.0000) ({r_i: None, r_t: [-886.777 -886.777 -886.777], eps: 1.0})
Step:   89200, Reward: [-418.805 -418.805 -418.805] [81.462], Avg: [-449.446 -449.446 -449.446] (1.0000) ({r_i: None, r_t: [-846.284 -846.284 -846.284], eps: 1.0})
Step:   89300, Reward: [-422.385 -422.385 -422.385] [106.957], Avg: [-449.416 -449.416 -449.416] (1.0000) ({r_i: None, r_t: [-813.542 -813.542 -813.542], eps: 1.0})
Step:   89400, Reward: [-477.530 -477.530 -477.530] [89.463], Avg: [-449.447 -449.447 -449.447] (1.0000) ({r_i: None, r_t: [-854.784 -854.784 -854.784], eps: 1.0})
Step:   89500, Reward: [-448.588 -448.588 -448.588] [95.192], Avg: [-449.447 -449.447 -449.447] (1.0000) ({r_i: None, r_t: [-862.691 -862.691 -862.691], eps: 1.0})
Step:   89600, Reward: [-398.996 -398.996 -398.996] [82.114], Avg: [-449.390 -449.390 -449.390] (1.0000) ({r_i: None, r_t: [-941.088 -941.088 -941.088], eps: 1.0})
Step:   89700, Reward: [-455.943 -455.943 -455.943] [89.876], Avg: [-449.398 -449.398 -449.398] (1.0000) ({r_i: None, r_t: [-865.834 -865.834 -865.834], eps: 1.0})
Step:   89800, Reward: [-437.928 -437.928 -437.928] [88.255], Avg: [-449.385 -449.385 -449.385] (1.0000) ({r_i: None, r_t: [-916.916 -916.916 -916.916], eps: 1.0})
Step:   89900, Reward: [-441.883 -441.883 -441.883] [107.831], Avg: [-449.376 -449.376 -449.376] (1.0000) ({r_i: None, r_t: [-840.729 -840.729 -840.729], eps: 1.0})
Step:   90000, Reward: [-426.712 -426.712 -426.712] [81.189], Avg: [-449.351 -449.351 -449.351] (1.0000) ({r_i: None, r_t: [-880.151 -880.151 -880.151], eps: 1.0})
Step:   90100, Reward: [-423.243 -423.243 -423.243] [78.632], Avg: [-449.322 -449.322 -449.322] (1.0000) ({r_i: None, r_t: [-881.809 -881.809 -881.809], eps: 1.0})
Step:   90200, Reward: [-427.978 -427.978 -427.978] [92.649], Avg: [-449.299 -449.299 -449.299] (1.0000) ({r_i: None, r_t: [-962.599 -962.599 -962.599], eps: 1.0})
Step:   90300, Reward: [-430.492 -430.492 -430.492] [70.672], Avg: [-449.278 -449.278 -449.278] (1.0000) ({r_i: None, r_t: [-865.975 -865.975 -865.975], eps: 1.0})
Step:   90400, Reward: [-398.597 -398.597 -398.597] [85.348], Avg: [-449.222 -449.222 -449.222] (1.0000) ({r_i: None, r_t: [-827.755 -827.755 -827.755], eps: 1.0})
Step:   90500, Reward: [-431.094 -431.094 -431.094] [67.867], Avg: [-449.202 -449.202 -449.202] (1.0000) ({r_i: None, r_t: [-902.044 -902.044 -902.044], eps: 1.0})
Step:   90600, Reward: [-428.520 -428.520 -428.520] [65.613], Avg: [-449.179 -449.179 -449.179] (1.0000) ({r_i: None, r_t: [-892.981 -892.981 -892.981], eps: 1.0})
Step:   90700, Reward: [-425.367 -425.367 -425.367] [86.912], Avg: [-449.153 -449.153 -449.153] (1.0000) ({r_i: None, r_t: [-822.834 -822.834 -822.834], eps: 1.0})
Step:   90800, Reward: [-437.392 -437.392 -437.392] [94.854], Avg: [-449.140 -449.140 -449.140] (1.0000) ({r_i: None, r_t: [-839.845 -839.845 -839.845], eps: 1.0})
Step:   90900, Reward: [-443.233 -443.233 -443.233] [90.191], Avg: [-449.133 -449.133 -449.133] (1.0000) ({r_i: None, r_t: [-891.474 -891.474 -891.474], eps: 1.0})
Step:   91000, Reward: [-421.370 -421.370 -421.370] [86.181], Avg: [-449.103 -449.103 -449.103] (1.0000) ({r_i: None, r_t: [-843.748 -843.748 -843.748], eps: 1.0})
Step:   91100, Reward: [-442.010 -442.010 -442.010] [78.286], Avg: [-449.095 -449.095 -449.095] (1.0000) ({r_i: None, r_t: [-849.365 -849.365 -849.365], eps: 1.0})
Step:   91200, Reward: [-454.576 -454.576 -454.576] [137.747], Avg: [-449.101 -449.101 -449.101] (1.0000) ({r_i: None, r_t: [-895.594 -895.594 -895.594], eps: 1.0})
Step:   91300, Reward: [-426.467 -426.467 -426.467] [59.735], Avg: [-449.076 -449.076 -449.076] (1.0000) ({r_i: None, r_t: [-888.434 -888.434 -888.434], eps: 1.0})
Step:   91400, Reward: [-423.170 -423.170 -423.170] [127.984], Avg: [-449.048 -449.048 -449.048] (1.0000) ({r_i: None, r_t: [-947.045 -947.045 -947.045], eps: 1.0})
Step:   91500, Reward: [-423.259 -423.259 -423.259] [95.334], Avg: [-449.020 -449.020 -449.020] (1.0000) ({r_i: None, r_t: [-893.327 -893.327 -893.327], eps: 1.0})
Step:   91600, Reward: [-432.675 -432.675 -432.675] [59.508], Avg: [-449.002 -449.002 -449.002] (1.0000) ({r_i: None, r_t: [-842.490 -842.490 -842.490], eps: 1.0})
Step:   91700, Reward: [-475.414 -475.414 -475.414] [88.239], Avg: [-449.031 -449.031 -449.031] (1.0000) ({r_i: None, r_t: [-857.439 -857.439 -857.439], eps: 1.0})
Step:   91800, Reward: [-426.558 -426.558 -426.558] [78.552], Avg: [-449.006 -449.006 -449.006] (1.0000) ({r_i: None, r_t: [-872.909 -872.909 -872.909], eps: 1.0})
Step:   91900, Reward: [-481.347 -481.347 -481.347] [121.593], Avg: [-449.042 -449.042 -449.042] (1.0000) ({r_i: None, r_t: [-849.952 -849.952 -849.952], eps: 1.0})
Step:   92000, Reward: [-425.574 -425.574 -425.574] [83.134], Avg: [-449.016 -449.016 -449.016] (1.0000) ({r_i: None, r_t: [-855.005 -855.005 -855.005], eps: 1.0})
Step:   92100, Reward: [-474.650 -474.650 -474.650] [108.651], Avg: [-449.044 -449.044 -449.044] (1.0000) ({r_i: None, r_t: [-845.755 -845.755 -845.755], eps: 1.0})
Step:   92200, Reward: [-461.212 -461.212 -461.212] [97.717], Avg: [-449.057 -449.057 -449.057] (1.0000) ({r_i: None, r_t: [-862.835 -862.835 -862.835], eps: 1.0})
Step:   92300, Reward: [-474.347 -474.347 -474.347] [113.263], Avg: [-449.085 -449.085 -449.085] (1.0000) ({r_i: None, r_t: [-837.525 -837.525 -837.525], eps: 1.0})
Step:   92400, Reward: [-483.594 -483.594 -483.594] [116.331], Avg: [-449.122 -449.122 -449.122] (1.0000) ({r_i: None, r_t: [-915.961 -915.961 -915.961], eps: 1.0})
Step:   92500, Reward: [-472.276 -472.276 -472.276] [125.997], Avg: [-449.147 -449.147 -449.147] (1.0000) ({r_i: None, r_t: [-863.973 -863.973 -863.973], eps: 1.0})
Step:   92600, Reward: [-414.765 -414.765 -414.765] [71.014], Avg: [-449.110 -449.110 -449.110] (1.0000) ({r_i: None, r_t: [-837.749 -837.749 -837.749], eps: 1.0})
Step:   92700, Reward: [-395.282 -395.282 -395.282] [85.803], Avg: [-449.052 -449.052 -449.052] (1.0000) ({r_i: None, r_t: [-823.655 -823.655 -823.655], eps: 1.0})
Step:   92800, Reward: [-459.516 -459.516 -459.516] [116.992], Avg: [-449.063 -449.063 -449.063] (1.0000) ({r_i: None, r_t: [-876.012 -876.012 -876.012], eps: 1.0})
Step:   92900, Reward: [-397.987 -397.987 -397.987] [81.984], Avg: [-449.008 -449.008 -449.008] (1.0000) ({r_i: None, r_t: [-908.310 -908.310 -908.310], eps: 1.0})
Step:   93000, Reward: [-411.814 -411.814 -411.814] [100.593], Avg: [-448.968 -448.968 -448.968] (1.0000) ({r_i: None, r_t: [-881.807 -881.807 -881.807], eps: 1.0})
Step:   93100, Reward: [-431.193 -431.193 -431.193] [80.505], Avg: [-448.949 -448.949 -448.949] (1.0000) ({r_i: None, r_t: [-890.395 -890.395 -890.395], eps: 1.0})
Step:   93200, Reward: [-406.346 -406.346 -406.346] [101.356], Avg: [-448.903 -448.903 -448.903] (1.0000) ({r_i: None, r_t: [-910.325 -910.325 -910.325], eps: 1.0})
Step:   93300, Reward: [-468.195 -468.195 -468.195] [101.584], Avg: [-448.924 -448.924 -448.924] (1.0000) ({r_i: None, r_t: [-857.797 -857.797 -857.797], eps: 1.0})
Step:   93400, Reward: [-419.344 -419.344 -419.344] [96.359], Avg: [-448.892 -448.892 -448.892] (1.0000) ({r_i: None, r_t: [-853.135 -853.135 -853.135], eps: 1.0})
Step:   93500, Reward: [-470.860 -470.860 -470.860] [104.901], Avg: [-448.916 -448.916 -448.916] (1.0000) ({r_i: None, r_t: [-861.850 -861.850 -861.850], eps: 1.0})
Step:   93600, Reward: [-502.845 -502.845 -502.845] [133.878], Avg: [-448.973 -448.973 -448.973] (1.0000) ({r_i: None, r_t: [-856.117 -856.117 -856.117], eps: 1.0})
Step:   93700, Reward: [-421.667 -421.667 -421.667] [94.166], Avg: [-448.944 -448.944 -448.944] (1.0000) ({r_i: None, r_t: [-889.204 -889.204 -889.204], eps: 1.0})
Step:   93800, Reward: [-441.177 -441.177 -441.177] [80.198], Avg: [-448.936 -448.936 -448.936] (1.0000) ({r_i: None, r_t: [-876.078 -876.078 -876.078], eps: 1.0})
Step:   93900, Reward: [-424.860 -424.860 -424.860] [57.235], Avg: [-448.910 -448.910 -448.910] (1.0000) ({r_i: None, r_t: [-890.845 -890.845 -890.845], eps: 1.0})
Step:   94000, Reward: [-432.056 -432.056 -432.056] [76.465], Avg: [-448.893 -448.893 -448.893] (1.0000) ({r_i: None, r_t: [-892.494 -892.494 -892.494], eps: 1.0})
Step:   94100, Reward: [-404.569 -404.569 -404.569] [90.630], Avg: [-448.845 -448.845 -448.845] (1.0000) ({r_i: None, r_t: [-861.980 -861.980 -861.980], eps: 1.0})
Step:   94200, Reward: [-449.053 -449.053 -449.053] [99.622], Avg: [-448.846 -448.846 -448.846] (1.0000) ({r_i: None, r_t: [-849.229 -849.229 -849.229], eps: 1.0})
Step:   94300, Reward: [-434.399 -434.399 -434.399] [101.415], Avg: [-448.830 -448.830 -448.830] (1.0000) ({r_i: None, r_t: [-860.312 -860.312 -860.312], eps: 1.0})
Step:   94400, Reward: [-412.288 -412.288 -412.288] [69.704], Avg: [-448.792 -448.792 -448.792] (1.0000) ({r_i: None, r_t: [-821.145 -821.145 -821.145], eps: 1.0})
Step:   94500, Reward: [-449.862 -449.862 -449.862] [59.322], Avg: [-448.793 -448.793 -448.793] (1.0000) ({r_i: None, r_t: [-940.496 -940.496 -940.496], eps: 1.0})
Step:   94600, Reward: [-493.898 -493.898 -493.898] [104.661], Avg: [-448.840 -448.840 -448.840] (1.0000) ({r_i: None, r_t: [-901.103 -901.103 -901.103], eps: 1.0})
Step:   94700, Reward: [-439.935 -439.935 -439.935] [89.978], Avg: [-448.831 -448.831 -448.831] (1.0000) ({r_i: None, r_t: [-860.736 -860.736 -860.736], eps: 1.0})
Step:   94800, Reward: [-461.626 -461.626 -461.626] [80.634], Avg: [-448.845 -448.845 -448.845] (1.0000) ({r_i: None, r_t: [-895.524 -895.524 -895.524], eps: 1.0})
Step:   94900, Reward: [-451.084 -451.084 -451.084] [133.036], Avg: [-448.847 -448.847 -448.847] (1.0000) ({r_i: None, r_t: [-866.352 -866.352 -866.352], eps: 1.0})
Step:   95000, Reward: [-407.486 -407.486 -407.486] [79.965], Avg: [-448.803 -448.803 -448.803] (1.0000) ({r_i: None, r_t: [-896.556 -896.556 -896.556], eps: 1.0})
Step:   95100, Reward: [-412.104 -412.104 -412.104] [59.441], Avg: [-448.765 -448.765 -448.765] (1.0000) ({r_i: None, r_t: [-905.649 -905.649 -905.649], eps: 1.0})
Step:   95200, Reward: [-371.834 -371.834 -371.834] [58.729], Avg: [-448.684 -448.684 -448.684] (1.0000) ({r_i: None, r_t: [-862.499 -862.499 -862.499], eps: 1.0})
Step:   95300, Reward: [-419.215 -419.215 -419.215] [84.501], Avg: [-448.653 -448.653 -448.653] (1.0000) ({r_i: None, r_t: [-817.715 -817.715 -817.715], eps: 1.0})
Step:   95400, Reward: [-443.386 -443.386 -443.386] [86.565], Avg: [-448.648 -448.648 -448.648] (1.0000) ({r_i: None, r_t: [-887.688 -887.688 -887.688], eps: 1.0})
Step:   95500, Reward: [-437.519 -437.519 -437.519] [83.830], Avg: [-448.636 -448.636 -448.636] (1.0000) ({r_i: None, r_t: [-828.352 -828.352 -828.352], eps: 1.0})
Step:   95600, Reward: [-443.211 -443.211 -443.211] [67.641], Avg: [-448.630 -448.630 -448.630] (1.0000) ({r_i: None, r_t: [-896.259 -896.259 -896.259], eps: 1.0})
Step:   95700, Reward: [-396.395 -396.395 -396.395] [81.053], Avg: [-448.576 -448.576 -448.576] (1.0000) ({r_i: None, r_t: [-898.308 -898.308 -898.308], eps: 1.0})
Step:   95800, Reward: [-448.630 -448.630 -448.630] [93.982], Avg: [-448.576 -448.576 -448.576] (1.0000) ({r_i: None, r_t: [-830.519 -830.519 -830.519], eps: 1.0})
Step:   95900, Reward: [-426.188 -426.188 -426.188] [89.642], Avg: [-448.553 -448.553 -448.553] (1.0000) ({r_i: None, r_t: [-895.339 -895.339 -895.339], eps: 1.0})
Step:   96000, Reward: [-393.077 -393.077 -393.077] [61.658], Avg: [-448.495 -448.495 -448.495] (1.0000) ({r_i: None, r_t: [-920.919 -920.919 -920.919], eps: 1.0})
Step:   96100, Reward: [-424.849 -424.849 -424.849] [73.729], Avg: [-448.470 -448.470 -448.470] (1.0000) ({r_i: None, r_t: [-893.488 -893.488 -893.488], eps: 1.0})
Step:   96200, Reward: [-435.737 -435.737 -435.737] [97.228], Avg: [-448.457 -448.457 -448.457] (1.0000) ({r_i: None, r_t: [-844.987 -844.987 -844.987], eps: 1.0})
Step:   96300, Reward: [-412.230 -412.230 -412.230] [85.911], Avg: [-448.420 -448.420 -448.420] (1.0000) ({r_i: None, r_t: [-933.934 -933.934 -933.934], eps: 1.0})
Step:   96400, Reward: [-434.492 -434.492 -434.492] [81.251], Avg: [-448.405 -448.405 -448.405] (1.0000) ({r_i: None, r_t: [-794.930 -794.930 -794.930], eps: 1.0})
Step:   96500, Reward: [-462.432 -462.432 -462.432] [105.538], Avg: [-448.420 -448.420 -448.420] (1.0000) ({r_i: None, r_t: [-817.876 -817.876 -817.876], eps: 1.0})
Step:   96600, Reward: [-420.018 -420.018 -420.018] [52.988], Avg: [-448.390 -448.390 -448.390] (1.0000) ({r_i: None, r_t: [-854.968 -854.968 -854.968], eps: 1.0})
Step:   96700, Reward: [-383.872 -383.872 -383.872] [52.607], Avg: [-448.324 -448.324 -448.324] (1.0000) ({r_i: None, r_t: [-861.515 -861.515 -861.515], eps: 1.0})
Step:   96800, Reward: [-438.064 -438.064 -438.064] [77.121], Avg: [-448.313 -448.313 -448.313] (1.0000) ({r_i: None, r_t: [-904.295 -904.295 -904.295], eps: 1.0})
Step:   96900, Reward: [-415.479 -415.479 -415.479] [80.491], Avg: [-448.279 -448.279 -448.279] (1.0000) ({r_i: None, r_t: [-896.187 -896.187 -896.187], eps: 1.0})
Step:   97000, Reward: [-491.297 -491.297 -491.297] [84.093], Avg: [-448.323 -448.323 -448.323] (1.0000) ({r_i: None, r_t: [-905.643 -905.643 -905.643], eps: 1.0})
Step:   97100, Reward: [-433.955 -433.955 -433.955] [92.950], Avg: [-448.309 -448.309 -448.309] (1.0000) ({r_i: None, r_t: [-873.788 -873.788 -873.788], eps: 1.0})
Step:   97200, Reward: [-416.868 -416.868 -416.868] [77.471], Avg: [-448.276 -448.276 -448.276] (1.0000) ({r_i: None, r_t: [-828.501 -828.501 -828.501], eps: 1.0})
Step:   97300, Reward: [-418.884 -418.884 -418.884] [81.451], Avg: [-448.246 -448.246 -448.246] (1.0000) ({r_i: None, r_t: [-892.983 -892.983 -892.983], eps: 1.0})
Step:   97400, Reward: [-426.117 -426.117 -426.117] [60.321], Avg: [-448.223 -448.223 -448.223] (1.0000) ({r_i: None, r_t: [-855.855 -855.855 -855.855], eps: 1.0})
Step:   97500, Reward: [-455.874 -455.874 -455.874] [73.462], Avg: [-448.231 -448.231 -448.231] (1.0000) ({r_i: None, r_t: [-861.755 -861.755 -861.755], eps: 1.0})
Step:   97600, Reward: [-466.619 -466.619 -466.619] [121.280], Avg: [-448.250 -448.250 -448.250] (1.0000) ({r_i: None, r_t: [-809.013 -809.013 -809.013], eps: 1.0})
Step:   97700, Reward: [-423.038 -423.038 -423.038] [87.585], Avg: [-448.224 -448.224 -448.224] (1.0000) ({r_i: None, r_t: [-939.973 -939.973 -939.973], eps: 1.0})
Step:   97800, Reward: [-399.551 -399.551 -399.551] [81.838], Avg: [-448.175 -448.175 -448.175] (1.0000) ({r_i: None, r_t: [-828.432 -828.432 -828.432], eps: 1.0})
Step:   97900, Reward: [-405.820 -405.820 -405.820] [73.773], Avg: [-448.131 -448.131 -448.131] (1.0000) ({r_i: None, r_t: [-852.292 -852.292 -852.292], eps: 1.0})
Step:   98000, Reward: [-473.095 -473.095 -473.095] [117.931], Avg: [-448.157 -448.157 -448.157] (1.0000) ({r_i: None, r_t: [-852.894 -852.894 -852.894], eps: 1.0})
Step:   98100, Reward: [-466.784 -466.784 -466.784] [109.385], Avg: [-448.176 -448.176 -448.176] (1.0000) ({r_i: None, r_t: [-880.570 -880.570 -880.570], eps: 1.0})
Step:   98200, Reward: [-435.613 -435.613 -435.613] [83.969], Avg: [-448.163 -448.163 -448.163] (1.0000) ({r_i: None, r_t: [-883.673 -883.673 -883.673], eps: 1.0})
Step:   98300, Reward: [-415.799 -415.799 -415.799] [81.021], Avg: [-448.130 -448.130 -448.130] (1.0000) ({r_i: None, r_t: [-862.876 -862.876 -862.876], eps: 1.0})
Step:   98400, Reward: [-441.700 -441.700 -441.700] [71.473], Avg: [-448.124 -448.124 -448.124] (1.0000) ({r_i: None, r_t: [-906.190 -906.190 -906.190], eps: 1.0})
Step:   98500, Reward: [-435.153 -435.153 -435.153] [81.438], Avg: [-448.110 -448.110 -448.110] (1.0000) ({r_i: None, r_t: [-900.244 -900.244 -900.244], eps: 1.0})
Step:   98600, Reward: [-427.339 -427.339 -427.339] [95.963], Avg: [-448.089 -448.089 -448.089] (1.0000) ({r_i: None, r_t: [-834.854 -834.854 -834.854], eps: 1.0})
Step:   98700, Reward: [-441.255 -441.255 -441.255] [79.840], Avg: [-448.083 -448.083 -448.083] (1.0000) ({r_i: None, r_t: [-908.208 -908.208 -908.208], eps: 1.0})
Step:   98800, Reward: [-427.508 -427.508 -427.508] [85.493], Avg: [-448.062 -448.062 -448.062] (1.0000) ({r_i: None, r_t: [-860.874 -860.874 -860.874], eps: 1.0})
Step:   98900, Reward: [-465.276 -465.276 -465.276] [131.983], Avg: [-448.079 -448.079 -448.079] (1.0000) ({r_i: None, r_t: [-859.783 -859.783 -859.783], eps: 1.0})
Step:   99000, Reward: [-466.144 -466.144 -466.144] [93.789], Avg: [-448.097 -448.097 -448.097] (1.0000) ({r_i: None, r_t: [-833.593 -833.593 -833.593], eps: 1.0})
Step:   99100, Reward: [-459.346 -459.346 -459.346] [91.195], Avg: [-448.109 -448.109 -448.109] (1.0000) ({r_i: None, r_t: [-891.158 -891.158 -891.158], eps: 1.0})
Step:   99200, Reward: [-394.665 -394.665 -394.665] [98.149], Avg: [-448.055 -448.055 -448.055] (1.0000) ({r_i: None, r_t: [-905.189 -905.189 -905.189], eps: 1.0})
Step:   99300, Reward: [-407.164 -407.164 -407.164] [83.778], Avg: [-448.014 -448.014 -448.014] (1.0000) ({r_i: None, r_t: [-918.521 -918.521 -918.521], eps: 1.0})
Step:   99400, Reward: [-420.348 -420.348 -420.348] [59.491], Avg: [-447.986 -447.986 -447.986] (1.0000) ({r_i: None, r_t: [-851.384 -851.384 -851.384], eps: 1.0})
Step:   99500, Reward: [-416.689 -416.689 -416.689] [66.123], Avg: [-447.955 -447.955 -447.955] (1.0000) ({r_i: None, r_t: [-878.813 -878.813 -878.813], eps: 1.0})
Step:   99600, Reward: [-424.621 -424.621 -424.621] [98.930], Avg: [-447.931 -447.931 -447.931] (1.0000) ({r_i: None, r_t: [-910.488 -910.488 -910.488], eps: 1.0})
Step:   99700, Reward: [-428.810 -428.810 -428.810] [101.793], Avg: [-447.912 -447.912 -447.912] (1.0000) ({r_i: None, r_t: [-835.719 -835.719 -835.719], eps: 1.0})
Step:   99800, Reward: [-487.767 -487.767 -487.767] [128.459], Avg: [-447.952 -447.952 -447.952] (1.0000) ({r_i: None, r_t: [-834.050 -834.050 -834.050], eps: 1.0})
Step:   99900, Reward: [-439.000 -439.000 -439.000] [83.430], Avg: [-447.943 -447.943 -447.943] (1.0000) ({r_i: None, r_t: [-832.526 -832.526 -832.526], eps: 1.0})
Step:  100000, Reward: [-452.872 -452.872 -452.872] [97.274], Avg: [-447.948 -447.948 -447.948] (1.0000) ({r_i: None, r_t: [-830.783 -830.783 -830.783], eps: 1.0})
Step:  100100, Reward: [-447.069 -447.069 -447.069] [111.937], Avg: [-447.947 -447.947 -447.947] (1.0000) ({r_i: None, r_t: [-900.655 -900.655 -900.655], eps: 1.0})
Step:  100200, Reward: [-438.092 -438.092 -438.092] [145.843], Avg: [-447.937 -447.937 -447.937] (1.0000) ({r_i: None, r_t: [-870.921 -870.921 -870.921], eps: 1.0})
Step:  100300, Reward: [-385.373 -385.373 -385.373] [74.639], Avg: [-447.875 -447.875 -447.875] (1.0000) ({r_i: None, r_t: [-787.916 -787.916 -787.916], eps: 1.0})
Step:  100400, Reward: [-460.330 -460.330 -460.330] [146.403], Avg: [-447.887 -447.887 -447.887] (1.0000) ({r_i: None, r_t: [-864.389 -864.389 -864.389], eps: 1.0})
Step:  100500, Reward: [-498.819 -498.819 -498.819] [89.519], Avg: [-447.938 -447.938 -447.938] (1.0000) ({r_i: None, r_t: [-836.121 -836.121 -836.121], eps: 1.0})
Step:  100600, Reward: [-415.314 -415.314 -415.314] [77.918], Avg: [-447.905 -447.905 -447.905] (1.0000) ({r_i: None, r_t: [-838.824 -838.824 -838.824], eps: 1.0})
Step:  100700, Reward: [-432.481 -432.481 -432.481] [100.423], Avg: [-447.890 -447.890 -447.890] (1.0000) ({r_i: None, r_t: [-913.168 -913.168 -913.168], eps: 1.0})
Step:  100800, Reward: [-407.928 -407.928 -407.928] [94.608], Avg: [-447.851 -447.851 -447.851] (1.0000) ({r_i: None, r_t: [-824.645 -824.645 -824.645], eps: 1.0})
Step:  100900, Reward: [-401.012 -401.012 -401.012] [114.734], Avg: [-447.804 -447.804 -447.804] (1.0000) ({r_i: None, r_t: [-854.669 -854.669 -854.669], eps: 1.0})
Step:  101000, Reward: [-428.538 -428.538 -428.538] [96.251], Avg: [-447.785 -447.785 -447.785] (1.0000) ({r_i: None, r_t: [-832.474 -832.474 -832.474], eps: 1.0})
Step:  101100, Reward: [-445.101 -445.101 -445.101] [82.985], Avg: [-447.782 -447.782 -447.782] (1.0000) ({r_i: None, r_t: [-884.504 -884.504 -884.504], eps: 1.0})
Step:  101200, Reward: [-436.676 -436.676 -436.676] [83.063], Avg: [-447.771 -447.771 -447.771] (1.0000) ({r_i: None, r_t: [-881.026 -881.026 -881.026], eps: 1.0})
Step:  101300, Reward: [-479.310 -479.310 -479.310] [111.134], Avg: [-447.803 -447.803 -447.803] (1.0000) ({r_i: None, r_t: [-836.728 -836.728 -836.728], eps: 1.0})
Step:  101400, Reward: [-397.488 -397.488 -397.488] [96.950], Avg: [-447.753 -447.753 -447.753] (1.0000) ({r_i: None, r_t: [-890.610 -890.610 -890.610], eps: 1.0})
Step:  101500, Reward: [-441.610 -441.610 -441.610] [109.046], Avg: [-447.747 -447.747 -447.747] (1.0000) ({r_i: None, r_t: [-915.423 -915.423 -915.423], eps: 1.0})
Step:  101600, Reward: [-457.809 -457.809 -457.809] [92.137], Avg: [-447.757 -447.757 -447.757] (1.0000) ({r_i: None, r_t: [-856.210 -856.210 -856.210], eps: 1.0})
Step:  101700, Reward: [-438.376 -438.376 -438.376] [86.821], Avg: [-447.748 -447.748 -447.748] (1.0000) ({r_i: None, r_t: [-868.433 -868.433 -868.433], eps: 1.0})
Step:  101800, Reward: [-429.711 -429.711 -429.711] [102.136], Avg: [-447.730 -447.730 -447.730] (1.0000) ({r_i: None, r_t: [-860.760 -860.760 -860.760], eps: 1.0})
Step:  101900, Reward: [-458.762 -458.762 -458.762] [131.548], Avg: [-447.741 -447.741 -447.741] (1.0000) ({r_i: None, r_t: [-909.906 -909.906 -909.906], eps: 1.0})
Step:  102000, Reward: [-396.337 -396.337 -396.337] [75.235], Avg: [-447.690 -447.690 -447.690] (1.0000) ({r_i: None, r_t: [-874.942 -874.942 -874.942], eps: 1.0})
Step:  102100, Reward: [-392.019 -392.019 -392.019] [68.073], Avg: [-447.636 -447.636 -447.636] (1.0000) ({r_i: None, r_t: [-873.623 -873.623 -873.623], eps: 1.0})
Step:  102200, Reward: [-470.196 -470.196 -470.196] [97.825], Avg: [-447.658 -447.658 -447.658] (1.0000) ({r_i: None, r_t: [-829.873 -829.873 -829.873], eps: 1.0})
Step:  102300, Reward: [-433.765 -433.765 -433.765] [51.102], Avg: [-447.644 -447.644 -447.644] (1.0000) ({r_i: None, r_t: [-816.763 -816.763 -816.763], eps: 1.0})
Step:  102400, Reward: [-424.814 -424.814 -424.814] [79.262], Avg: [-447.622 -447.622 -447.622] (1.0000) ({r_i: None, r_t: [-881.258 -881.258 -881.258], eps: 1.0})
Step:  102500, Reward: [-449.479 -449.479 -449.479] [97.259], Avg: [-447.624 -447.624 -447.624] (1.0000) ({r_i: None, r_t: [-874.530 -874.530 -874.530], eps: 1.0})
Step:  102600, Reward: [-440.349 -440.349 -440.349] [109.822], Avg: [-447.617 -447.617 -447.617] (1.0000) ({r_i: None, r_t: [-866.064 -866.064 -866.064], eps: 1.0})
Step:  102700, Reward: [-478.921 -478.921 -478.921] [76.738], Avg: [-447.647 -447.647 -447.647] (1.0000) ({r_i: None, r_t: [-906.274 -906.274 -906.274], eps: 1.0})
Step:  102800, Reward: [-431.581 -431.581 -431.581] [72.230], Avg: [-447.632 -447.632 -447.632] (1.0000) ({r_i: None, r_t: [-880.128 -880.128 -880.128], eps: 1.0})
Step:  102900, Reward: [-408.135 -408.135 -408.135] [72.435], Avg: [-447.593 -447.593 -447.593] (1.0000) ({r_i: None, r_t: [-874.998 -874.998 -874.998], eps: 1.0})
Step:  103000, Reward: [-451.567 -451.567 -451.567] [62.585], Avg: [-447.597 -447.597 -447.597] (1.0000) ({r_i: None, r_t: [-855.443 -855.443 -855.443], eps: 1.0})
Step:  103100, Reward: [-438.981 -438.981 -438.981] [94.006], Avg: [-447.589 -447.589 -447.589] (1.0000) ({r_i: None, r_t: [-874.523 -874.523 -874.523], eps: 1.0})
Step:  103200, Reward: [-438.706 -438.706 -438.706] [103.716], Avg: [-447.580 -447.580 -447.580] (1.0000) ({r_i: None, r_t: [-882.468 -882.468 -882.468], eps: 1.0})
Step:  103300, Reward: [-429.358 -429.358 -429.358] [85.237], Avg: [-447.563 -447.563 -447.563] (1.0000) ({r_i: None, r_t: [-824.346 -824.346 -824.346], eps: 1.0})
Step:  103400, Reward: [-422.531 -422.531 -422.531] [52.711], Avg: [-447.538 -447.538 -447.538] (1.0000) ({r_i: None, r_t: [-871.768 -871.768 -871.768], eps: 1.0})
Step:  103500, Reward: [-459.877 -459.877 -459.877] [111.047], Avg: [-447.550 -447.550 -447.550] (1.0000) ({r_i: None, r_t: [-864.399 -864.399 -864.399], eps: 1.0})
Step:  103600, Reward: [-385.043 -385.043 -385.043] [78.367], Avg: [-447.490 -447.490 -447.490] (1.0000) ({r_i: None, r_t: [-990.676 -990.676 -990.676], eps: 1.0})
Step:  103700, Reward: [-427.072 -427.072 -427.072] [104.978], Avg: [-447.470 -447.470 -447.470] (1.0000) ({r_i: None, r_t: [-874.358 -874.358 -874.358], eps: 1.0})
Step:  103800, Reward: [-489.428 -489.428 -489.428] [98.816], Avg: [-447.511 -447.511 -447.511] (1.0000) ({r_i: None, r_t: [-877.563 -877.563 -877.563], eps: 1.0})
Step:  103900, Reward: [-409.852 -409.852 -409.852] [75.088], Avg: [-447.475 -447.475 -447.475] (1.0000) ({r_i: None, r_t: [-920.405 -920.405 -920.405], eps: 1.0})
Step:  104000, Reward: [-442.472 -442.472 -442.472] [92.024], Avg: [-447.470 -447.470 -447.470] (1.0000) ({r_i: None, r_t: [-915.164 -915.164 -915.164], eps: 1.0})
Step:  104100, Reward: [-435.493 -435.493 -435.493] [67.430], Avg: [-447.458 -447.458 -447.458] (1.0000) ({r_i: None, r_t: [-869.598 -869.598 -869.598], eps: 1.0})
Step:  104200, Reward: [-396.988 -396.988 -396.988] [78.822], Avg: [-447.410 -447.410 -447.410] (1.0000) ({r_i: None, r_t: [-885.119 -885.119 -885.119], eps: 1.0})
Step:  104300, Reward: [-415.681 -415.681 -415.681] [86.838], Avg: [-447.380 -447.380 -447.380] (1.0000) ({r_i: None, r_t: [-927.327 -927.327 -927.327], eps: 1.0})
Step:  104400, Reward: [-476.035 -476.035 -476.035] [120.859], Avg: [-447.407 -447.407 -447.407] (1.0000) ({r_i: None, r_t: [-858.535 -858.535 -858.535], eps: 1.0})
Step:  104500, Reward: [-441.007 -441.007 -441.007] [75.175], Avg: [-447.401 -447.401 -447.401] (1.0000) ({r_i: None, r_t: [-838.765 -838.765 -838.765], eps: 1.0})
Step:  104600, Reward: [-418.393 -418.393 -418.393] [98.171], Avg: [-447.373 -447.373 -447.373] (1.0000) ({r_i: None, r_t: [-885.320 -885.320 -885.320], eps: 1.0})
Step:  104700, Reward: [-402.279 -402.279 -402.279] [75.840], Avg: [-447.330 -447.330 -447.330] (1.0000) ({r_i: None, r_t: [-848.216 -848.216 -848.216], eps: 1.0})
Step:  104800, Reward: [-418.915 -418.915 -418.915] [95.275], Avg: [-447.303 -447.303 -447.303] (1.0000) ({r_i: None, r_t: [-869.572 -869.572 -869.572], eps: 1.0})
Step:  104900, Reward: [-442.689 -442.689 -442.689] [145.516], Avg: [-447.299 -447.299 -447.299] (1.0000) ({r_i: None, r_t: [-855.976 -855.976 -855.976], eps: 1.0})
Step:  105000, Reward: [-419.095 -419.095 -419.095] [124.634], Avg: [-447.272 -447.272 -447.272] (1.0000) ({r_i: None, r_t: [-879.193 -879.193 -879.193], eps: 1.0})
Step:  105100, Reward: [-408.497 -408.497 -408.497] [80.903], Avg: [-447.235 -447.235 -447.235] (1.0000) ({r_i: None, r_t: [-752.895 -752.895 -752.895], eps: 1.0})
Step:  105200, Reward: [-408.969 -408.969 -408.969] [103.331], Avg: [-447.199 -447.199 -447.199] (1.0000) ({r_i: None, r_t: [-844.353 -844.353 -844.353], eps: 1.0})
Step:  105300, Reward: [-447.936 -447.936 -447.936] [75.445], Avg: [-447.199 -447.199 -447.199] (1.0000) ({r_i: None, r_t: [-894.665 -894.665 -894.665], eps: 1.0})
Step:  105400, Reward: [-450.732 -450.732 -450.732] [79.539], Avg: [-447.203 -447.203 -447.203] (1.0000) ({r_i: None, r_t: [-900.277 -900.277 -900.277], eps: 1.0})
Step:  105500, Reward: [-436.026 -436.026 -436.026] [85.390], Avg: [-447.192 -447.192 -447.192] (1.0000) ({r_i: None, r_t: [-891.672 -891.672 -891.672], eps: 1.0})
Step:  105600, Reward: [-434.482 -434.482 -434.482] [68.033], Avg: [-447.180 -447.180 -447.180] (1.0000) ({r_i: None, r_t: [-888.877 -888.877 -888.877], eps: 1.0})
Step:  105700, Reward: [-422.027 -422.027 -422.027] [100.379], Avg: [-447.156 -447.156 -447.156] (1.0000) ({r_i: None, r_t: [-835.922 -835.922 -835.922], eps: 1.0})
Step:  105800, Reward: [-445.950 -445.950 -445.950] [107.911], Avg: [-447.155 -447.155 -447.155] (1.0000) ({r_i: None, r_t: [-931.234 -931.234 -931.234], eps: 1.0})
Step:  105900, Reward: [-429.445 -429.445 -429.445] [75.367], Avg: [-447.138 -447.138 -447.138] (1.0000) ({r_i: None, r_t: [-887.079 -887.079 -887.079], eps: 1.0})
Step:  106000, Reward: [-413.089 -413.089 -413.089] [105.028], Avg: [-447.106 -447.106 -447.106] (1.0000) ({r_i: None, r_t: [-912.876 -912.876 -912.876], eps: 1.0})
Step:  106100, Reward: [-399.373 -399.373 -399.373] [79.889], Avg: [-447.061 -447.061 -447.061] (1.0000) ({r_i: None, r_t: [-851.490 -851.490 -851.490], eps: 1.0})
Step:  106200, Reward: [-461.016 -461.016 -461.016] [96.653], Avg: [-447.074 -447.074 -447.074] (1.0000) ({r_i: None, r_t: [-904.785 -904.785 -904.785], eps: 1.0})
Step:  106300, Reward: [-408.096 -408.096 -408.096] [59.653], Avg: [-447.038 -447.038 -447.038] (1.0000) ({r_i: None, r_t: [-849.173 -849.173 -849.173], eps: 1.0})
Step:  106400, Reward: [-464.282 -464.282 -464.282] [117.710], Avg: [-447.054 -447.054 -447.054] (1.0000) ({r_i: None, r_t: [-899.978 -899.978 -899.978], eps: 1.0})
Step:  106500, Reward: [-408.627 -408.627 -408.627] [54.150], Avg: [-447.018 -447.018 -447.018] (1.0000) ({r_i: None, r_t: [-875.169 -875.169 -875.169], eps: 1.0})
Step:  106600, Reward: [-409.305 -409.305 -409.305] [64.107], Avg: [-446.983 -446.983 -446.983] (1.0000) ({r_i: None, r_t: [-895.923 -895.923 -895.923], eps: 1.0})
Step:  106700, Reward: [-431.470 -431.470 -431.470] [111.733], Avg: [-446.968 -446.968 -446.968] (1.0000) ({r_i: None, r_t: [-921.002 -921.002 -921.002], eps: 1.0})
Step:  106800, Reward: [-455.970 -455.970 -455.970] [93.546], Avg: [-446.977 -446.977 -446.977] (1.0000) ({r_i: None, r_t: [-872.800 -872.800 -872.800], eps: 1.0})
Step:  106900, Reward: [-433.955 -433.955 -433.955] [85.494], Avg: [-446.964 -446.964 -446.964] (1.0000) ({r_i: None, r_t: [-866.278 -866.278 -866.278], eps: 1.0})
Step:  107000, Reward: [-417.026 -417.026 -417.026] [69.252], Avg: [-446.936 -446.936 -446.936] (1.0000) ({r_i: None, r_t: [-899.017 -899.017 -899.017], eps: 1.0})
Step:  107100, Reward: [-437.059 -437.059 -437.059] [90.891], Avg: [-446.927 -446.927 -446.927] (1.0000) ({r_i: None, r_t: [-791.367 -791.367 -791.367], eps: 1.0})
Step:  107200, Reward: [-421.750 -421.750 -421.750] [106.999], Avg: [-446.904 -446.904 -446.904] (1.0000) ({r_i: None, r_t: [-911.702 -911.702 -911.702], eps: 1.0})
Step:  107300, Reward: [-476.193 -476.193 -476.193] [133.253], Avg: [-446.931 -446.931 -446.931] (1.0000) ({r_i: None, r_t: [-885.786 -885.786 -885.786], eps: 1.0})
Step:  107400, Reward: [-401.406 -401.406 -401.406] [50.158], Avg: [-446.889 -446.889 -446.889] (1.0000) ({r_i: None, r_t: [-857.584 -857.584 -857.584], eps: 1.0})
Step:  107500, Reward: [-453.936 -453.936 -453.936] [113.810], Avg: [-446.895 -446.895 -446.895] (1.0000) ({r_i: None, r_t: [-818.027 -818.027 -818.027], eps: 1.0})
Step:  107600, Reward: [-439.918 -439.918 -439.918] [94.394], Avg: [-446.889 -446.889 -446.889] (1.0000) ({r_i: None, r_t: [-832.733 -832.733 -832.733], eps: 1.0})
Step:  107700, Reward: [-472.773 -472.773 -472.773] [127.084], Avg: [-446.913 -446.913 -446.913] (1.0000) ({r_i: None, r_t: [-853.813 -853.813 -853.813], eps: 1.0})
Step:  107800, Reward: [-423.433 -423.433 -423.433] [81.389], Avg: [-446.891 -446.891 -446.891] (1.0000) ({r_i: None, r_t: [-887.085 -887.085 -887.085], eps: 1.0})
Step:  107900, Reward: [-457.862 -457.862 -457.862] [81.593], Avg: [-446.901 -446.901 -446.901] (1.0000) ({r_i: None, r_t: [-842.261 -842.261 -842.261], eps: 1.0})
Step:  108000, Reward: [-448.288 -448.288 -448.288] [47.053], Avg: [-446.902 -446.902 -446.902] (1.0000) ({r_i: None, r_t: [-991.174 -991.174 -991.174], eps: 1.0})
Step:  108100, Reward: [-412.519 -412.519 -412.519] [78.856], Avg: [-446.871 -446.871 -446.871] (1.0000) ({r_i: None, r_t: [-860.399 -860.399 -860.399], eps: 1.0})
Step:  108200, Reward: [-441.744 -441.744 -441.744] [96.031], Avg: [-446.866 -446.866 -446.866] (1.0000) ({r_i: None, r_t: [-851.177 -851.177 -851.177], eps: 1.0})
Step:  108300, Reward: [-447.859 -447.859 -447.859] [119.375], Avg: [-446.867 -446.867 -446.867] (1.0000) ({r_i: None, r_t: [-897.434 -897.434 -897.434], eps: 1.0})
Step:  108400, Reward: [-399.590 -399.590 -399.590] [72.890], Avg: [-446.823 -446.823 -446.823] (1.0000) ({r_i: None, r_t: [-924.406 -924.406 -924.406], eps: 1.0})
Step:  108500, Reward: [-448.393 -448.393 -448.393] [78.332], Avg: [-446.825 -446.825 -446.825] (1.0000) ({r_i: None, r_t: [-873.601 -873.601 -873.601], eps: 1.0})
Step:  108600, Reward: [-445.207 -445.207 -445.207] [99.557], Avg: [-446.823 -446.823 -446.823] (1.0000) ({r_i: None, r_t: [-838.654 -838.654 -838.654], eps: 1.0})
Step:  108700, Reward: [-400.972 -400.972 -400.972] [95.484], Avg: [-446.781 -446.781 -446.781] (1.0000) ({r_i: None, r_t: [-898.357 -898.357 -898.357], eps: 1.0})
Step:  108800, Reward: [-482.601 -482.601 -482.601] [127.745], Avg: [-446.814 -446.814 -446.814] (1.0000) ({r_i: None, r_t: [-864.926 -864.926 -864.926], eps: 1.0})
Step:  108900, Reward: [-433.238 -433.238 -433.238] [99.316], Avg: [-446.801 -446.801 -446.801] (1.0000) ({r_i: None, r_t: [-917.601 -917.601 -917.601], eps: 1.0})
Step:  109000, Reward: [-397.975 -397.975 -397.975] [59.245], Avg: [-446.757 -446.757 -446.757] (1.0000) ({r_i: None, r_t: [-882.980 -882.980 -882.980], eps: 1.0})
Step:  109100, Reward: [-475.470 -475.470 -475.470] [101.832], Avg: [-446.783 -446.783 -446.783] (1.0000) ({r_i: None, r_t: [-917.678 -917.678 -917.678], eps: 1.0})
Step:  109200, Reward: [-468.874 -468.874 -468.874] [112.675], Avg: [-446.803 -446.803 -446.803] (1.0000) ({r_i: None, r_t: [-859.324 -859.324 -859.324], eps: 1.0})
Step:  109300, Reward: [-434.178 -434.178 -434.178] [93.131], Avg: [-446.792 -446.792 -446.792] (1.0000) ({r_i: None, r_t: [-884.287 -884.287 -884.287], eps: 1.0})
Step:  109400, Reward: [-451.259 -451.259 -451.259] [101.855], Avg: [-446.796 -446.796 -446.796] (1.0000) ({r_i: None, r_t: [-869.000 -869.000 -869.000], eps: 1.0})
Step:  109500, Reward: [-426.551 -426.551 -426.551] [75.940], Avg: [-446.777 -446.777 -446.777] (1.0000) ({r_i: None, r_t: [-894.447 -894.447 -894.447], eps: 1.0})
Step:  109600, Reward: [-429.372 -429.372 -429.372] [55.622], Avg: [-446.761 -446.761 -446.761] (1.0000) ({r_i: None, r_t: [-877.504 -877.504 -877.504], eps: 1.0})
Step:  109700, Reward: [-438.493 -438.493 -438.493] [129.396], Avg: [-446.754 -446.754 -446.754] (1.0000) ({r_i: None, r_t: [-868.252 -868.252 -868.252], eps: 1.0})
Step:  109800, Reward: [-485.726 -485.726 -485.726] [88.857], Avg: [-446.789 -446.789 -446.789] (1.0000) ({r_i: None, r_t: [-905.582 -905.582 -905.582], eps: 1.0})
Step:  109900, Reward: [-448.376 -448.376 -448.376] [88.865], Avg: [-446.791 -446.791 -446.791] (1.0000) ({r_i: None, r_t: [-815.782 -815.782 -815.782], eps: 1.0})
Step:  110000, Reward: [-449.062 -449.062 -449.062] [97.113], Avg: [-446.793 -446.793 -446.793] (1.0000) ({r_i: None, r_t: [-901.133 -901.133 -901.133], eps: 1.0})
Step:  110100, Reward: [-397.708 -397.708 -397.708] [70.915], Avg: [-446.748 -446.748 -446.748] (1.0000) ({r_i: None, r_t: [-869.297 -869.297 -869.297], eps: 1.0})
Step:  110200, Reward: [-444.044 -444.044 -444.044] [101.824], Avg: [-446.746 -446.746 -446.746] (1.0000) ({r_i: None, r_t: [-925.251 -925.251 -925.251], eps: 1.0})
Step:  110300, Reward: [-445.568 -445.568 -445.568] [99.569], Avg: [-446.745 -446.745 -446.745] (1.0000) ({r_i: None, r_t: [-877.520 -877.520 -877.520], eps: 1.0})
Step:  110400, Reward: [-449.417 -449.417 -449.417] [93.170], Avg: [-446.747 -446.747 -446.747] (1.0000) ({r_i: None, r_t: [-798.505 -798.505 -798.505], eps: 1.0})
Step:  110500, Reward: [-413.051 -413.051 -413.051] [79.122], Avg: [-446.717 -446.717 -446.717] (1.0000) ({r_i: None, r_t: [-903.355 -903.355 -903.355], eps: 1.0})
Step:  110600, Reward: [-448.373 -448.373 -448.373] [97.190], Avg: [-446.718 -446.718 -446.718] (1.0000) ({r_i: None, r_t: [-897.579 -897.579 -897.579], eps: 1.0})
Step:  110700, Reward: [-409.695 -409.695 -409.695] [99.542], Avg: [-446.685 -446.685 -446.685] (1.0000) ({r_i: None, r_t: [-762.016 -762.016 -762.016], eps: 1.0})
Step:  110800, Reward: [-439.908 -439.908 -439.908] [83.778], Avg: [-446.679 -446.679 -446.679] (1.0000) ({r_i: None, r_t: [-791.406 -791.406 -791.406], eps: 1.0})
Step:  110900, Reward: [-446.961 -446.961 -446.961] [99.667], Avg: [-446.679 -446.679 -446.679] (1.0000) ({r_i: None, r_t: [-820.088 -820.088 -820.088], eps: 1.0})
Step:  111000, Reward: [-407.777 -407.777 -407.777] [92.776], Avg: [-446.644 -446.644 -446.644] (1.0000) ({r_i: None, r_t: [-913.717 -913.717 -913.717], eps: 1.0})
Step:  111100, Reward: [-478.631 -478.631 -478.631] [93.797], Avg: [-446.673 -446.673 -446.673] (1.0000) ({r_i: None, r_t: [-918.273 -918.273 -918.273], eps: 1.0})
Step:  111200, Reward: [-389.814 -389.814 -389.814] [85.817], Avg: [-446.622 -446.622 -446.622] (1.0000) ({r_i: None, r_t: [-925.730 -925.730 -925.730], eps: 1.0})
Step:  111300, Reward: [-450.453 -450.453 -450.453] [75.425], Avg: [-446.625 -446.625 -446.625] (1.0000) ({r_i: None, r_t: [-871.118 -871.118 -871.118], eps: 1.0})
Step:  111400, Reward: [-443.953 -443.953 -443.953] [108.331], Avg: [-446.623 -446.623 -446.623] (1.0000) ({r_i: None, r_t: [-932.073 -932.073 -932.073], eps: 1.0})
Step:  111500, Reward: [-448.118 -448.118 -448.118] [85.725], Avg: [-446.624 -446.624 -446.624] (1.0000) ({r_i: None, r_t: [-885.706 -885.706 -885.706], eps: 1.0})
Step:  111600, Reward: [-477.279 -477.279 -477.279] [121.242], Avg: [-446.651 -446.651 -446.651] (1.0000) ({r_i: None, r_t: [-925.975 -925.975 -925.975], eps: 1.0})
Step:  111700, Reward: [-430.456 -430.456 -430.456] [70.498], Avg: [-446.637 -446.637 -446.637] (1.0000) ({r_i: None, r_t: [-816.066 -816.066 -816.066], eps: 1.0})
Step:  111800, Reward: [-460.302 -460.302 -460.302] [80.216], Avg: [-446.649 -446.649 -446.649] (1.0000) ({r_i: None, r_t: [-787.933 -787.933 -787.933], eps: 1.0})
Step:  111900, Reward: [-409.367 -409.367 -409.367] [88.835], Avg: [-446.616 -446.616 -446.616] (1.0000) ({r_i: None, r_t: [-846.526 -846.526 -846.526], eps: 1.0})
Step:  112000, Reward: [-463.049 -463.049 -463.049] [102.587], Avg: [-446.631 -446.631 -446.631] (1.0000) ({r_i: None, r_t: [-884.716 -884.716 -884.716], eps: 1.0})
Step:  112100, Reward: [-412.204 -412.204 -412.204] [68.545], Avg: [-446.600 -446.600 -446.600] (1.0000) ({r_i: None, r_t: [-893.107 -893.107 -893.107], eps: 1.0})
Step:  112200, Reward: [-413.565 -413.565 -413.565] [50.649], Avg: [-446.570 -446.570 -446.570] (1.0000) ({r_i: None, r_t: [-845.896 -845.896 -845.896], eps: 1.0})
Step:  112300, Reward: [-432.345 -432.345 -432.345] [63.903], Avg: [-446.558 -446.558 -446.558] (1.0000) ({r_i: None, r_t: [-890.815 -890.815 -890.815], eps: 1.0})
Step:  112400, Reward: [-472.537 -472.537 -472.537] [89.902], Avg: [-446.581 -446.581 -446.581] (1.0000) ({r_i: None, r_t: [-802.205 -802.205 -802.205], eps: 1.0})
Step:  112500, Reward: [-423.507 -423.507 -423.507] [107.759], Avg: [-446.560 -446.560 -446.560] (1.0000) ({r_i: None, r_t: [-833.351 -833.351 -833.351], eps: 1.0})
Step:  112600, Reward: [-478.030 -478.030 -478.030] [92.815], Avg: [-446.588 -446.588 -446.588] (1.0000) ({r_i: None, r_t: [-816.661 -816.661 -816.661], eps: 1.0})
Step:  112700, Reward: [-461.516 -461.516 -461.516] [63.711], Avg: [-446.602 -446.602 -446.602] (1.0000) ({r_i: None, r_t: [-848.292 -848.292 -848.292], eps: 1.0})
Step:  112800, Reward: [-439.070 -439.070 -439.070] [121.781], Avg: [-446.595 -446.595 -446.595] (1.0000) ({r_i: None, r_t: [-912.358 -912.358 -912.358], eps: 1.0})
Step:  112900, Reward: [-441.897 -441.897 -441.897] [131.703], Avg: [-446.591 -446.591 -446.591] (1.0000) ({r_i: None, r_t: [-823.491 -823.491 -823.491], eps: 1.0})
Step:  113000, Reward: [-450.839 -450.839 -450.839] [106.077], Avg: [-446.595 -446.595 -446.595] (1.0000) ({r_i: None, r_t: [-893.796 -893.796 -893.796], eps: 1.0})
Step:  113100, Reward: [-417.093 -417.093 -417.093] [90.646], Avg: [-446.568 -446.568 -446.568] (1.0000) ({r_i: None, r_t: [-925.365 -925.365 -925.365], eps: 1.0})
Step:  113200, Reward: [-414.878 -414.878 -414.878] [85.610], Avg: [-446.540 -446.540 -446.540] (1.0000) ({r_i: None, r_t: [-831.347 -831.347 -831.347], eps: 1.0})
Step:  113300, Reward: [-447.260 -447.260 -447.260] [104.869], Avg: [-446.541 -446.541 -446.541] (1.0000) ({r_i: None, r_t: [-814.978 -814.978 -814.978], eps: 1.0})
Step:  113400, Reward: [-423.524 -423.524 -423.524] [97.937], Avg: [-446.521 -446.521 -446.521] (1.0000) ({r_i: None, r_t: [-879.561 -879.561 -879.561], eps: 1.0})
Step:  113500, Reward: [-416.941 -416.941 -416.941] [82.790], Avg: [-446.495 -446.495 -446.495] (1.0000) ({r_i: None, r_t: [-855.921 -855.921 -855.921], eps: 1.0})
Step:  113600, Reward: [-441.587 -441.587 -441.587] [97.353], Avg: [-446.490 -446.490 -446.490] (1.0000) ({r_i: None, r_t: [-866.551 -866.551 -866.551], eps: 1.0})
Step:  113700, Reward: [-469.610 -469.610 -469.610] [104.394], Avg: [-446.511 -446.511 -446.511] (1.0000) ({r_i: None, r_t: [-881.147 -881.147 -881.147], eps: 1.0})
Step:  113800, Reward: [-423.485 -423.485 -423.485] [93.575], Avg: [-446.491 -446.491 -446.491] (1.0000) ({r_i: None, r_t: [-840.084 -840.084 -840.084], eps: 1.0})
Step:  113900, Reward: [-435.802 -435.802 -435.802] [88.478], Avg: [-446.481 -446.481 -446.481] (1.0000) ({r_i: None, r_t: [-852.658 -852.658 -852.658], eps: 1.0})
Step:  114000, Reward: [-436.665 -436.665 -436.665] [87.910], Avg: [-446.473 -446.473 -446.473] (1.0000) ({r_i: None, r_t: [-870.529 -870.529 -870.529], eps: 1.0})
Step:  114100, Reward: [-436.883 -436.883 -436.883] [90.887], Avg: [-446.464 -446.464 -446.464] (1.0000) ({r_i: None, r_t: [-893.786 -893.786 -893.786], eps: 1.0})
Step:  114200, Reward: [-456.261 -456.261 -456.261] [118.900], Avg: [-446.473 -446.473 -446.473] (1.0000) ({r_i: None, r_t: [-876.257 -876.257 -876.257], eps: 1.0})
Step:  114300, Reward: [-466.367 -466.367 -466.367] [125.917], Avg: [-446.490 -446.490 -446.490] (1.0000) ({r_i: None, r_t: [-863.834 -863.834 -863.834], eps: 1.0})
Step:  114400, Reward: [-419.024 -419.024 -419.024] [119.988], Avg: [-446.466 -446.466 -446.466] (1.0000) ({r_i: None, r_t: [-860.252 -860.252 -860.252], eps: 1.0})
Step:  114500, Reward: [-446.241 -446.241 -446.241] [105.716], Avg: [-446.466 -446.466 -446.466] (1.0000) ({r_i: None, r_t: [-897.388 -897.388 -897.388], eps: 1.0})
Step:  114600, Reward: [-413.925 -413.925 -413.925] [78.654], Avg: [-446.438 -446.438 -446.438] (1.0000) ({r_i: None, r_t: [-869.153 -869.153 -869.153], eps: 1.0})
Step:  114700, Reward: [-467.851 -467.851 -467.851] [137.759], Avg: [-446.456 -446.456 -446.456] (1.0000) ({r_i: None, r_t: [-895.963 -895.963 -895.963], eps: 1.0})
Step:  114800, Reward: [-441.043 -441.043 -441.043] [93.638], Avg: [-446.452 -446.452 -446.452] (1.0000) ({r_i: None, r_t: [-841.868 -841.868 -841.868], eps: 1.0})
Step:  114900, Reward: [-407.626 -407.626 -407.626] [70.802], Avg: [-446.418 -446.418 -446.418] (1.0000) ({r_i: None, r_t: [-875.819 -875.819 -875.819], eps: 1.0})
Step:  115000, Reward: [-411.071 -411.071 -411.071] [67.565], Avg: [-446.387 -446.387 -446.387] (1.0000) ({r_i: None, r_t: [-844.026 -844.026 -844.026], eps: 1.0})
Step:  115100, Reward: [-414.138 -414.138 -414.138] [82.689], Avg: [-446.359 -446.359 -446.359] (1.0000) ({r_i: None, r_t: [-849.033 -849.033 -849.033], eps: 1.0})
Step:  115200, Reward: [-453.964 -453.964 -453.964] [110.431], Avg: [-446.366 -446.366 -446.366] (1.0000) ({r_i: None, r_t: [-893.064 -893.064 -893.064], eps: 1.0})
Step:  115300, Reward: [-425.618 -425.618 -425.618] [65.090], Avg: [-446.348 -446.348 -446.348] (1.0000) ({r_i: None, r_t: [-843.795 -843.795 -843.795], eps: 1.0})
Step:  115400, Reward: [-436.324 -436.324 -436.324] [99.532], Avg: [-446.339 -446.339 -446.339] (1.0000) ({r_i: None, r_t: [-830.823 -830.823 -830.823], eps: 1.0})
Step:  115500, Reward: [-398.603 -398.603 -398.603] [62.288], Avg: [-446.298 -446.298 -446.298] (1.0000) ({r_i: None, r_t: [-874.833 -874.833 -874.833], eps: 1.0})
Step:  115600, Reward: [-422.725 -422.725 -422.725] [80.535], Avg: [-446.277 -446.277 -446.277] (1.0000) ({r_i: None, r_t: [-846.498 -846.498 -846.498], eps: 1.0})
Step:  115700, Reward: [-439.923 -439.923 -439.923] [71.050], Avg: [-446.272 -446.272 -446.272] (1.0000) ({r_i: None, r_t: [-935.691 -935.691 -935.691], eps: 1.0})
Step:  115800, Reward: [-457.768 -457.768 -457.768] [72.073], Avg: [-446.282 -446.282 -446.282] (1.0000) ({r_i: None, r_t: [-876.807 -876.807 -876.807], eps: 1.0})
Step:  115900, Reward: [-392.987 -392.987 -392.987] [79.607], Avg: [-446.236 -446.236 -446.236] (1.0000) ({r_i: None, r_t: [-837.025 -837.025 -837.025], eps: 1.0})
Step:  116000, Reward: [-450.456 -450.456 -450.456] [68.417], Avg: [-446.239 -446.239 -446.239] (1.0000) ({r_i: None, r_t: [-860.302 -860.302 -860.302], eps: 1.0})
Step:  116100, Reward: [-486.023 -486.023 -486.023] [81.143], Avg: [-446.274 -446.274 -446.274] (1.0000) ({r_i: None, r_t: [-908.374 -908.374 -908.374], eps: 1.0})
Step:  116200, Reward: [-406.023 -406.023 -406.023] [97.358], Avg: [-446.239 -446.239 -446.239] (1.0000) ({r_i: None, r_t: [-896.154 -896.154 -896.154], eps: 1.0})
Step:  116300, Reward: [-436.767 -436.767 -436.767] [75.892], Avg: [-446.231 -446.231 -446.231] (1.0000) ({r_i: None, r_t: [-845.623 -845.623 -845.623], eps: 1.0})
Step:  116400, Reward: [-406.598 -406.598 -406.598] [78.856], Avg: [-446.197 -446.197 -446.197] (1.0000) ({r_i: None, r_t: [-878.061 -878.061 -878.061], eps: 1.0})
Step:  116500, Reward: [-409.512 -409.512 -409.512] [77.334], Avg: [-446.165 -446.165 -446.165] (1.0000) ({r_i: None, r_t: [-876.630 -876.630 -876.630], eps: 1.0})
Step:  116600, Reward: [-397.967 -397.967 -397.967] [91.183], Avg: [-446.124 -446.124 -446.124] (1.0000) ({r_i: None, r_t: [-880.943 -880.943 -880.943], eps: 1.0})
Step:  116700, Reward: [-393.861 -393.861 -393.861] [67.889], Avg: [-446.079 -446.079 -446.079] (1.0000) ({r_i: None, r_t: [-877.666 -877.666 -877.666], eps: 1.0})
Step:  116800, Reward: [-443.992 -443.992 -443.992] [89.586], Avg: [-446.078 -446.078 -446.078] (1.0000) ({r_i: None, r_t: [-904.756 -904.756 -904.756], eps: 1.0})
Step:  116900, Reward: [-403.077 -403.077 -403.077] [80.332], Avg: [-446.041 -446.041 -446.041] (1.0000) ({r_i: None, r_t: [-899.104 -899.104 -899.104], eps: 1.0})
Step:  117000, Reward: [-420.476 -420.476 -420.476] [87.267], Avg: [-446.019 -446.019 -446.019] (1.0000) ({r_i: None, r_t: [-834.707 -834.707 -834.707], eps: 1.0})
Step:  117100, Reward: [-412.546 -412.546 -412.546] [54.222], Avg: [-445.991 -445.991 -445.991] (1.0000) ({r_i: None, r_t: [-864.923 -864.923 -864.923], eps: 1.0})
Step:  117200, Reward: [-428.107 -428.107 -428.107] [88.045], Avg: [-445.975 -445.975 -445.975] (1.0000) ({r_i: None, r_t: [-800.176 -800.176 -800.176], eps: 1.0})
Step:  117300, Reward: [-456.582 -456.582 -456.582] [110.964], Avg: [-445.984 -445.984 -445.984] (1.0000) ({r_i: None, r_t: [-872.396 -872.396 -872.396], eps: 1.0})
Step:  117400, Reward: [-430.549 -430.549 -430.549] [92.399], Avg: [-445.971 -445.971 -445.971] (1.0000) ({r_i: None, r_t: [-888.142 -888.142 -888.142], eps: 1.0})
Step:  117500, Reward: [-413.326 -413.326 -413.326] [72.292], Avg: [-445.943 -445.943 -445.943] (1.0000) ({r_i: None, r_t: [-879.272 -879.272 -879.272], eps: 1.0})
Step:  117600, Reward: [-408.353 -408.353 -408.353] [74.012], Avg: [-445.911 -445.911 -445.911] (1.0000) ({r_i: None, r_t: [-856.860 -856.860 -856.860], eps: 1.0})
Step:  117700, Reward: [-443.310 -443.310 -443.310] [98.461], Avg: [-445.909 -445.909 -445.909] (1.0000) ({r_i: None, r_t: [-894.808 -894.808 -894.808], eps: 1.0})
Step:  117800, Reward: [-416.041 -416.041 -416.041] [72.870], Avg: [-445.884 -445.884 -445.884] (1.0000) ({r_i: None, r_t: [-834.850 -834.850 -834.850], eps: 1.0})
Step:  117900, Reward: [-450.063 -450.063 -450.063] [96.359], Avg: [-445.887 -445.887 -445.887] (1.0000) ({r_i: None, r_t: [-898.175 -898.175 -898.175], eps: 1.0})
Step:  118000, Reward: [-428.880 -428.880 -428.880] [86.996], Avg: [-445.873 -445.873 -445.873] (1.0000) ({r_i: None, r_t: [-908.311 -908.311 -908.311], eps: 1.0})
Step:  118100, Reward: [-452.898 -452.898 -452.898] [95.788], Avg: [-445.879 -445.879 -445.879] (1.0000) ({r_i: None, r_t: [-893.574 -893.574 -893.574], eps: 1.0})
Step:  118200, Reward: [-478.654 -478.654 -478.654] [125.724], Avg: [-445.907 -445.907 -445.907] (1.0000) ({r_i: None, r_t: [-825.272 -825.272 -825.272], eps: 1.0})
Step:  118300, Reward: [-413.128 -413.128 -413.128] [81.705], Avg: [-445.879 -445.879 -445.879] (1.0000) ({r_i: None, r_t: [-820.226 -820.226 -820.226], eps: 1.0})
Step:  118400, Reward: [-471.789 -471.789 -471.789] [68.556], Avg: [-445.901 -445.901 -445.901] (1.0000) ({r_i: None, r_t: [-903.868 -903.868 -903.868], eps: 1.0})
Step:  118500, Reward: [-426.050 -426.050 -426.050] [105.957], Avg: [-445.884 -445.884 -445.884] (1.0000) ({r_i: None, r_t: [-921.544 -921.544 -921.544], eps: 1.0})
Step:  118600, Reward: [-428.541 -428.541 -428.541] [64.789], Avg: [-445.870 -445.870 -445.870] (1.0000) ({r_i: None, r_t: [-902.087 -902.087 -902.087], eps: 1.0})
Step:  118700, Reward: [-468.159 -468.159 -468.159] [120.404], Avg: [-445.888 -445.888 -445.888] (1.0000) ({r_i: None, r_t: [-886.795 -886.795 -886.795], eps: 1.0})
Step:  118800, Reward: [-465.253 -465.253 -465.253] [87.622], Avg: [-445.905 -445.905 -445.905] (1.0000) ({r_i: None, r_t: [-906.700 -906.700 -906.700], eps: 1.0})
Step:  118900, Reward: [-440.866 -440.866 -440.866] [104.094], Avg: [-445.900 -445.900 -445.900] (1.0000) ({r_i: None, r_t: [-910.494 -910.494 -910.494], eps: 1.0})
Step:  119000, Reward: [-470.201 -470.201 -470.201] [109.593], Avg: [-445.921 -445.921 -445.921] (1.0000) ({r_i: None, r_t: [-829.945 -829.945 -829.945], eps: 1.0})
Step:  119100, Reward: [-433.319 -433.319 -433.319] [85.674], Avg: [-445.910 -445.910 -445.910] (1.0000) ({r_i: None, r_t: [-872.412 -872.412 -872.412], eps: 1.0})
Step:  119200, Reward: [-467.044 -467.044 -467.044] [107.278], Avg: [-445.928 -445.928 -445.928] (1.0000) ({r_i: None, r_t: [-877.700 -877.700 -877.700], eps: 1.0})
Step:  119300, Reward: [-478.850 -478.850 -478.850] [128.326], Avg: [-445.955 -445.955 -445.955] (1.0000) ({r_i: None, r_t: [-844.087 -844.087 -844.087], eps: 1.0})
Step:  119400, Reward: [-434.391 -434.391 -434.391] [95.928], Avg: [-445.946 -445.946 -445.946] (1.0000) ({r_i: None, r_t: [-861.631 -861.631 -861.631], eps: 1.0})
Step:  119500, Reward: [-424.463 -424.463 -424.463] [66.021], Avg: [-445.928 -445.928 -445.928] (1.0000) ({r_i: None, r_t: [-879.235 -879.235 -879.235], eps: 1.0})
Step:  119600, Reward: [-433.496 -433.496 -433.496] [71.209], Avg: [-445.917 -445.917 -445.917] (1.0000) ({r_i: None, r_t: [-895.160 -895.160 -895.160], eps: 1.0})
Step:  119700, Reward: [-454.761 -454.761 -454.761] [100.113], Avg: [-445.925 -445.925 -445.925] (1.0000) ({r_i: None, r_t: [-880.985 -880.985 -880.985], eps: 1.0})
Step:  119800, Reward: [-458.040 -458.040 -458.040] [75.657], Avg: [-445.935 -445.935 -445.935] (1.0000) ({r_i: None, r_t: [-872.198 -872.198 -872.198], eps: 1.0})
Step:  119900, Reward: [-442.757 -442.757 -442.757] [119.089], Avg: [-445.932 -445.932 -445.932] (1.0000) ({r_i: None, r_t: [-876.587 -876.587 -876.587], eps: 1.0})
Step:  120000, Reward: [-469.557 -469.557 -469.557] [113.089], Avg: [-445.952 -445.952 -445.952] (1.0000) ({r_i: None, r_t: [-892.883 -892.883 -892.883], eps: 1.0})
Step:  120100, Reward: [-447.242 -447.242 -447.242] [143.800], Avg: [-445.953 -445.953 -445.953] (1.0000) ({r_i: None, r_t: [-870.789 -870.789 -870.789], eps: 1.0})
Step:  120200, Reward: [-422.838 -422.838 -422.838] [69.632], Avg: [-445.934 -445.934 -445.934] (1.0000) ({r_i: None, r_t: [-888.391 -888.391 -888.391], eps: 1.0})
Step:  120300, Reward: [-439.558 -439.558 -439.558] [74.814], Avg: [-445.929 -445.929 -445.929] (1.0000) ({r_i: None, r_t: [-951.925 -951.925 -951.925], eps: 1.0})
Step:  120400, Reward: [-456.189 -456.189 -456.189] [119.254], Avg: [-445.937 -445.937 -445.937] (1.0000) ({r_i: None, r_t: [-940.832 -940.832 -940.832], eps: 1.0})
Step:  120500, Reward: [-402.515 -402.515 -402.515] [60.104], Avg: [-445.901 -445.901 -445.901] (1.0000) ({r_i: None, r_t: [-840.465 -840.465 -840.465], eps: 1.0})
Step:  120600, Reward: [-444.910 -444.910 -444.910] [110.451], Avg: [-445.900 -445.900 -445.900] (1.0000) ({r_i: None, r_t: [-877.539 -877.539 -877.539], eps: 1.0})
Step:  120700, Reward: [-457.367 -457.367 -457.367] [68.337], Avg: [-445.910 -445.910 -445.910] (1.0000) ({r_i: None, r_t: [-940.993 -940.993 -940.993], eps: 1.0})
Step:  120800, Reward: [-409.346 -409.346 -409.346] [71.043], Avg: [-445.879 -445.879 -445.879] (1.0000) ({r_i: None, r_t: [-806.540 -806.540 -806.540], eps: 1.0})
Step:  120900, Reward: [-421.050 -421.050 -421.050] [119.469], Avg: [-445.859 -445.859 -445.859] (1.0000) ({r_i: None, r_t: [-845.268 -845.268 -845.268], eps: 1.0})
Step:  121000, Reward: [-410.113 -410.113 -410.113] [67.217], Avg: [-445.829 -445.829 -445.829] (1.0000) ({r_i: None, r_t: [-867.973 -867.973 -867.973], eps: 1.0})
Step:  121100, Reward: [-431.749 -431.749 -431.749] [97.670], Avg: [-445.818 -445.818 -445.818] (1.0000) ({r_i: None, r_t: [-874.239 -874.239 -874.239], eps: 1.0})
Step:  121200, Reward: [-406.380 -406.380 -406.380] [81.425], Avg: [-445.785 -445.785 -445.785] (1.0000) ({r_i: None, r_t: [-885.817 -885.817 -885.817], eps: 1.0})
Step:  121300, Reward: [-450.240 -450.240 -450.240] [70.475], Avg: [-445.789 -445.789 -445.789] (1.0000) ({r_i: None, r_t: [-891.963 -891.963 -891.963], eps: 1.0})
Step:  121400, Reward: [-460.465 -460.465 -460.465] [77.434], Avg: [-445.801 -445.801 -445.801] (1.0000) ({r_i: None, r_t: [-888.360 -888.360 -888.360], eps: 1.0})
Step:  121500, Reward: [-442.105 -442.105 -442.105] [94.224], Avg: [-445.798 -445.798 -445.798] (1.0000) ({r_i: None, r_t: [-839.795 -839.795 -839.795], eps: 1.0})
Step:  121600, Reward: [-410.869 -410.869 -410.869] [85.962], Avg: [-445.769 -445.769 -445.769] (1.0000) ({r_i: None, r_t: [-884.720 -884.720 -884.720], eps: 1.0})
Step:  121700, Reward: [-426.233 -426.233 -426.233] [89.598], Avg: [-445.753 -445.753 -445.753] (1.0000) ({r_i: None, r_t: [-871.141 -871.141 -871.141], eps: 1.0})
Step:  121800, Reward: [-422.862 -422.862 -422.862] [70.241], Avg: [-445.734 -445.734 -445.734] (1.0000) ({r_i: None, r_t: [-855.530 -855.530 -855.530], eps: 1.0})
Step:  121900, Reward: [-433.402 -433.402 -433.402] [88.533], Avg: [-445.724 -445.724 -445.724] (1.0000) ({r_i: None, r_t: [-848.367 -848.367 -848.367], eps: 1.0})
Step:  122000, Reward: [-429.542 -429.542 -429.542] [105.313], Avg: [-445.711 -445.711 -445.711] (1.0000) ({r_i: None, r_t: [-886.236 -886.236 -886.236], eps: 1.0})
Step:  122100, Reward: [-435.945 -435.945 -435.945] [133.022], Avg: [-445.703 -445.703 -445.703] (1.0000) ({r_i: None, r_t: [-885.948 -885.948 -885.948], eps: 1.0})
Step:  122200, Reward: [-466.899 -466.899 -466.899] [109.021], Avg: [-445.720 -445.720 -445.720] (1.0000) ({r_i: None, r_t: [-813.288 -813.288 -813.288], eps: 1.0})
Step:  122300, Reward: [-403.384 -403.384 -403.384] [104.945], Avg: [-445.686 -445.686 -445.686] (1.0000) ({r_i: None, r_t: [-910.527 -910.527 -910.527], eps: 1.0})
Step:  122400, Reward: [-476.646 -476.646 -476.646] [80.906], Avg: [-445.711 -445.711 -445.711] (1.0000) ({r_i: None, r_t: [-900.232 -900.232 -900.232], eps: 1.0})
Step:  122500, Reward: [-439.964 -439.964 -439.964] [69.743], Avg: [-445.706 -445.706 -445.706] (1.0000) ({r_i: None, r_t: [-818.745 -818.745 -818.745], eps: 1.0})
Step:  122600, Reward: [-442.098 -442.098 -442.098] [110.767], Avg: [-445.704 -445.704 -445.704] (1.0000) ({r_i: None, r_t: [-843.308 -843.308 -843.308], eps: 1.0})
Step:  122700, Reward: [-438.244 -438.244 -438.244] [65.505], Avg: [-445.697 -445.697 -445.697] (1.0000) ({r_i: None, r_t: [-842.884 -842.884 -842.884], eps: 1.0})
Step:  122800, Reward: [-483.952 -483.952 -483.952] [97.795], Avg: [-445.729 -445.729 -445.729] (1.0000) ({r_i: None, r_t: [-916.582 -916.582 -916.582], eps: 1.0})
Step:  122900, Reward: [-412.997 -412.997 -412.997] [120.132], Avg: [-445.702 -445.702 -445.702] (1.0000) ({r_i: None, r_t: [-869.063 -869.063 -869.063], eps: 1.0})
Step:  123000, Reward: [-413.562 -413.562 -413.562] [86.236], Avg: [-445.676 -445.676 -445.676] (1.0000) ({r_i: None, r_t: [-886.702 -886.702 -886.702], eps: 1.0})
Step:  123100, Reward: [-398.120 -398.120 -398.120] [91.480], Avg: [-445.637 -445.637 -445.637] (1.0000) ({r_i: None, r_t: [-784.279 -784.279 -784.279], eps: 1.0})
Step:  123200, Reward: [-428.081 -428.081 -428.081] [99.664], Avg: [-445.623 -445.623 -445.623] (1.0000) ({r_i: None, r_t: [-887.634 -887.634 -887.634], eps: 1.0})
Step:  123300, Reward: [-409.730 -409.730 -409.730] [98.463], Avg: [-445.594 -445.594 -445.594] (1.0000) ({r_i: None, r_t: [-861.219 -861.219 -861.219], eps: 1.0})
Step:  123400, Reward: [-419.784 -419.784 -419.784] [44.306], Avg: [-445.573 -445.573 -445.573] (1.0000) ({r_i: None, r_t: [-879.148 -879.148 -879.148], eps: 1.0})
Step:  123500, Reward: [-433.313 -433.313 -433.313] [99.347], Avg: [-445.563 -445.563 -445.563] (1.0000) ({r_i: None, r_t: [-886.658 -886.658 -886.658], eps: 1.0})
Step:  123600, Reward: [-472.466 -472.466 -472.466] [87.539], Avg: [-445.585 -445.585 -445.585] (1.0000) ({r_i: None, r_t: [-887.529 -887.529 -887.529], eps: 1.0})
Step:  123700, Reward: [-421.866 -421.866 -421.866] [71.157], Avg: [-445.566 -445.566 -445.566] (1.0000) ({r_i: None, r_t: [-905.393 -905.393 -905.393], eps: 1.0})
Step:  123800, Reward: [-407.973 -407.973 -407.973] [92.821], Avg: [-445.535 -445.535 -445.535] (1.0000) ({r_i: None, r_t: [-897.415 -897.415 -897.415], eps: 1.0})
Step:  123900, Reward: [-432.771 -432.771 -432.771] [80.999], Avg: [-445.525 -445.525 -445.525] (1.0000) ({r_i: None, r_t: [-901.223 -901.223 -901.223], eps: 1.0})
Step:  124000, Reward: [-429.418 -429.418 -429.418] [83.251], Avg: [-445.512 -445.512 -445.512] (1.0000) ({r_i: None, r_t: [-952.370 -952.370 -952.370], eps: 1.0})
Step:  124100, Reward: [-455.476 -455.476 -455.476] [61.595], Avg: [-445.520 -445.520 -445.520] (1.0000) ({r_i: None, r_t: [-816.903 -816.903 -816.903], eps: 1.0})
Step:  124200, Reward: [-419.883 -419.883 -419.883] [70.968], Avg: [-445.499 -445.499 -445.499] (1.0000) ({r_i: None, r_t: [-826.201 -826.201 -826.201], eps: 1.0})
Step:  124300, Reward: [-462.738 -462.738 -462.738] [109.517], Avg: [-445.513 -445.513 -445.513] (1.0000) ({r_i: None, r_t: [-897.682 -897.682 -897.682], eps: 1.0})
Step:  124400, Reward: [-416.893 -416.893 -416.893] [100.545], Avg: [-445.490 -445.490 -445.490] (1.0000) ({r_i: None, r_t: [-865.276 -865.276 -865.276], eps: 1.0})
Step:  124500, Reward: [-439.483 -439.483 -439.483] [94.740], Avg: [-445.486 -445.486 -445.486] (1.0000) ({r_i: None, r_t: [-917.558 -917.558 -917.558], eps: 1.0})
Step:  124600, Reward: [-468.124 -468.124 -468.124] [92.152], Avg: [-445.504 -445.504 -445.504] (1.0000) ({r_i: None, r_t: [-808.305 -808.305 -808.305], eps: 1.0})
Step:  124700, Reward: [-411.219 -411.219 -411.219] [89.095], Avg: [-445.476 -445.476 -445.476] (1.0000) ({r_i: None, r_t: [-845.695 -845.695 -845.695], eps: 1.0})
Step:  124800, Reward: [-450.781 -450.781 -450.781] [74.865], Avg: [-445.480 -445.480 -445.480] (1.0000) ({r_i: None, r_t: [-899.844 -899.844 -899.844], eps: 1.0})
Step:  124900, Reward: [-464.227 -464.227 -464.227] [134.716], Avg: [-445.495 -445.495 -445.495] (1.0000) ({r_i: None, r_t: [-902.168 -902.168 -902.168], eps: 1.0})
Step:  125000, Reward: [-424.473 -424.473 -424.473] [116.528], Avg: [-445.479 -445.479 -445.479] (1.0000) ({r_i: None, r_t: [-800.764 -800.764 -800.764], eps: 1.0})
Step:  125100, Reward: [-452.622 -452.622 -452.622] [80.153], Avg: [-445.484 -445.484 -445.484] (1.0000) ({r_i: None, r_t: [-852.150 -852.150 -852.150], eps: 1.0})
Step:  125200, Reward: [-454.760 -454.760 -454.760] [76.391], Avg: [-445.492 -445.492 -445.492] (1.0000) ({r_i: None, r_t: [-847.782 -847.782 -847.782], eps: 1.0})
Step:  125300, Reward: [-434.789 -434.789 -434.789] [102.028], Avg: [-445.483 -445.483 -445.483] (1.0000) ({r_i: None, r_t: [-914.829 -914.829 -914.829], eps: 1.0})
Step:  125400, Reward: [-427.803 -427.803 -427.803] [98.308], Avg: [-445.469 -445.469 -445.469] (1.0000) ({r_i: None, r_t: [-846.308 -846.308 -846.308], eps: 1.0})
Step:  125500, Reward: [-443.104 -443.104 -443.104] [81.024], Avg: [-445.467 -445.467 -445.467] (1.0000) ({r_i: None, r_t: [-891.807 -891.807 -891.807], eps: 1.0})
Step:  125600, Reward: [-427.260 -427.260 -427.260] [73.735], Avg: [-445.453 -445.453 -445.453] (1.0000) ({r_i: None, r_t: [-839.873 -839.873 -839.873], eps: 1.0})
Step:  125700, Reward: [-460.283 -460.283 -460.283] [97.951], Avg: [-445.465 -445.465 -445.465] (1.0000) ({r_i: None, r_t: [-830.518 -830.518 -830.518], eps: 1.0})
Step:  125800, Reward: [-403.416 -403.416 -403.416] [58.818], Avg: [-445.431 -445.431 -445.431] (1.0000) ({r_i: None, r_t: [-929.655 -929.655 -929.655], eps: 1.0})
Step:  125900, Reward: [-432.809 -432.809 -432.809] [85.060], Avg: [-445.421 -445.421 -445.421] (1.0000) ({r_i: None, r_t: [-917.874 -917.874 -917.874], eps: 1.0})
Step:  126000, Reward: [-415.033 -415.033 -415.033] [72.966], Avg: [-445.397 -445.397 -445.397] (1.0000) ({r_i: None, r_t: [-887.850 -887.850 -887.850], eps: 1.0})
Step:  126100, Reward: [-445.499 -445.499 -445.499] [107.067], Avg: [-445.397 -445.397 -445.397] (1.0000) ({r_i: None, r_t: [-903.964 -903.964 -903.964], eps: 1.0})
Step:  126200, Reward: [-414.701 -414.701 -414.701] [120.748], Avg: [-445.373 -445.373 -445.373] (1.0000) ({r_i: None, r_t: [-891.495 -891.495 -891.495], eps: 1.0})
Step:  126300, Reward: [-434.755 -434.755 -434.755] [87.011], Avg: [-445.364 -445.364 -445.364] (1.0000) ({r_i: None, r_t: [-861.964 -861.964 -861.964], eps: 1.0})
Step:  126400, Reward: [-418.403 -418.403 -418.403] [104.949], Avg: [-445.343 -445.343 -445.343] (1.0000) ({r_i: None, r_t: [-853.571 -853.571 -853.571], eps: 1.0})
Step:  126500, Reward: [-447.221 -447.221 -447.221] [86.470], Avg: [-445.345 -445.345 -445.345] (1.0000) ({r_i: None, r_t: [-867.453 -867.453 -867.453], eps: 1.0})
Step:  126600, Reward: [-483.119 -483.119 -483.119] [88.743], Avg: [-445.374 -445.374 -445.374] (1.0000) ({r_i: None, r_t: [-863.064 -863.064 -863.064], eps: 1.0})
Step:  126700, Reward: [-458.256 -458.256 -458.256] [94.327], Avg: [-445.385 -445.385 -445.385] (1.0000) ({r_i: None, r_t: [-865.372 -865.372 -865.372], eps: 1.0})
Step:  126800, Reward: [-470.789 -470.789 -470.789] [85.334], Avg: [-445.405 -445.405 -445.405] (1.0000) ({r_i: None, r_t: [-902.721 -902.721 -902.721], eps: 1.0})
Step:  126900, Reward: [-474.537 -474.537 -474.537] [80.654], Avg: [-445.428 -445.428 -445.428] (1.0000) ({r_i: None, r_t: [-778.987 -778.987 -778.987], eps: 1.0})
Step:  127000, Reward: [-441.564 -441.564 -441.564] [93.436], Avg: [-445.424 -445.424 -445.424] (1.0000) ({r_i: None, r_t: [-929.121 -929.121 -929.121], eps: 1.0})
Step:  127100, Reward: [-424.739 -424.739 -424.739] [108.474], Avg: [-445.408 -445.408 -445.408] (1.0000) ({r_i: None, r_t: [-912.880 -912.880 -912.880], eps: 1.0})
Step:  127200, Reward: [-445.215 -445.215 -445.215] [102.537], Avg: [-445.408 -445.408 -445.408] (1.0000) ({r_i: None, r_t: [-883.120 -883.120 -883.120], eps: 1.0})
Step:  127300, Reward: [-404.802 -404.802 -404.802] [75.686], Avg: [-445.376 -445.376 -445.376] (1.0000) ({r_i: None, r_t: [-852.701 -852.701 -852.701], eps: 1.0})
Step:  127400, Reward: [-457.567 -457.567 -457.567] [87.895], Avg: [-445.386 -445.386 -445.386] (1.0000) ({r_i: None, r_t: [-881.722 -881.722 -881.722], eps: 1.0})
Step:  127500, Reward: [-457.418 -457.418 -457.418] [77.271], Avg: [-445.395 -445.395 -445.395] (1.0000) ({r_i: None, r_t: [-875.496 -875.496 -875.496], eps: 1.0})
Step:  127600, Reward: [-443.692 -443.692 -443.692] [96.686], Avg: [-445.394 -445.394 -445.394] (1.0000) ({r_i: None, r_t: [-851.422 -851.422 -851.422], eps: 1.0})
Step:  127700, Reward: [-449.337 -449.337 -449.337] [137.691], Avg: [-445.397 -445.397 -445.397] (1.0000) ({r_i: None, r_t: [-891.884 -891.884 -891.884], eps: 1.0})
Step:  127800, Reward: [-454.120 -454.120 -454.120] [105.805], Avg: [-445.404 -445.404 -445.404] (1.0000) ({r_i: None, r_t: [-912.761 -912.761 -912.761], eps: 1.0})
Step:  127900, Reward: [-425.075 -425.075 -425.075] [69.440], Avg: [-445.388 -445.388 -445.388] (1.0000) ({r_i: None, r_t: [-852.168 -852.168 -852.168], eps: 1.0})
Step:  128000, Reward: [-434.933 -434.933 -434.933] [107.725], Avg: [-445.380 -445.380 -445.380] (1.0000) ({r_i: None, r_t: [-874.996 -874.996 -874.996], eps: 1.0})
Step:  128100, Reward: [-432.723 -432.723 -432.723] [92.624], Avg: [-445.370 -445.370 -445.370] (1.0000) ({r_i: None, r_t: [-891.181 -891.181 -891.181], eps: 1.0})
Step:  128200, Reward: [-447.183 -447.183 -447.183] [96.629], Avg: [-445.371 -445.371 -445.371] (1.0000) ({r_i: None, r_t: [-927.633 -927.633 -927.633], eps: 1.0})
Step:  128300, Reward: [-413.721 -413.721 -413.721] [95.174], Avg: [-445.347 -445.347 -445.347] (1.0000) ({r_i: None, r_t: [-917.617 -917.617 -917.617], eps: 1.0})
Step:  128400, Reward: [-422.342 -422.342 -422.342] [76.888], Avg: [-445.329 -445.329 -445.329] (1.0000) ({r_i: None, r_t: [-914.615 -914.615 -914.615], eps: 1.0})
Step:  128500, Reward: [-417.442 -417.442 -417.442] [73.269], Avg: [-445.307 -445.307 -445.307] (1.0000) ({r_i: None, r_t: [-887.490 -887.490 -887.490], eps: 1.0})
Step:  128600, Reward: [-456.592 -456.592 -456.592] [111.413], Avg: [-445.316 -445.316 -445.316] (1.0000) ({r_i: None, r_t: [-849.081 -849.081 -849.081], eps: 1.0})
Step:  128700, Reward: [-414.703 -414.703 -414.703] [79.497], Avg: [-445.292 -445.292 -445.292] (1.0000) ({r_i: None, r_t: [-919.389 -919.389 -919.389], eps: 1.0})
Step:  128800, Reward: [-391.164 -391.164 -391.164] [58.960], Avg: [-445.250 -445.250 -445.250] (1.0000) ({r_i: None, r_t: [-849.524 -849.524 -849.524], eps: 1.0})
Step:  128900, Reward: [-453.641 -453.641 -453.641] [86.240], Avg: [-445.257 -445.257 -445.257] (1.0000) ({r_i: None, r_t: [-913.521 -913.521 -913.521], eps: 1.0})
Step:  129000, Reward: [-463.595 -463.595 -463.595] [104.225], Avg: [-445.271 -445.271 -445.271] (1.0000) ({r_i: None, r_t: [-917.828 -917.828 -917.828], eps: 1.0})
Step:  129100, Reward: [-414.622 -414.622 -414.622] [66.100], Avg: [-445.247 -445.247 -445.247] (1.0000) ({r_i: None, r_t: [-843.414 -843.414 -843.414], eps: 1.0})
Step:  129200, Reward: [-426.551 -426.551 -426.551] [82.394], Avg: [-445.233 -445.233 -445.233] (1.0000) ({r_i: None, r_t: [-814.072 -814.072 -814.072], eps: 1.0})
Step:  129300, Reward: [-468.433 -468.433 -468.433] [77.089], Avg: [-445.250 -445.250 -445.250] (1.0000) ({r_i: None, r_t: [-843.845 -843.845 -843.845], eps: 1.0})
Step:  129400, Reward: [-470.343 -470.343 -470.343] [91.151], Avg: [-445.270 -445.270 -445.270] (1.0000) ({r_i: None, r_t: [-880.468 -880.468 -880.468], eps: 1.0})
Step:  129500, Reward: [-432.726 -432.726 -432.726] [85.118], Avg: [-445.260 -445.260 -445.260] (1.0000) ({r_i: None, r_t: [-876.252 -876.252 -876.252], eps: 1.0})
Step:  129600, Reward: [-433.510 -433.510 -433.510] [66.609], Avg: [-445.251 -445.251 -445.251] (1.0000) ({r_i: None, r_t: [-919.624 -919.624 -919.624], eps: 1.0})
Step:  129700, Reward: [-384.202 -384.202 -384.202] [67.850], Avg: [-445.204 -445.204 -445.204] (1.0000) ({r_i: None, r_t: [-862.379 -862.379 -862.379], eps: 1.0})
Step:  129800, Reward: [-389.118 -389.118 -389.118] [70.430], Avg: [-445.161 -445.161 -445.161] (1.0000) ({r_i: None, r_t: [-886.500 -886.500 -886.500], eps: 1.0})
Step:  129900, Reward: [-439.144 -439.144 -439.144] [90.341], Avg: [-445.156 -445.156 -445.156] (1.0000) ({r_i: None, r_t: [-900.736 -900.736 -900.736], eps: 1.0})
Step:  130000, Reward: [-387.899 -387.899 -387.899] [75.250], Avg: [-445.112 -445.112 -445.112] (1.0000) ({r_i: None, r_t: [-917.646 -917.646 -917.646], eps: 1.0})
Step:  130100, Reward: [-468.539 -468.539 -468.539] [97.443], Avg: [-445.130 -445.130 -445.130] (1.0000) ({r_i: None, r_t: [-854.883 -854.883 -854.883], eps: 1.0})
Step:  130200, Reward: [-416.923 -416.923 -416.923] [57.569], Avg: [-445.109 -445.109 -445.109] (1.0000) ({r_i: None, r_t: [-862.297 -862.297 -862.297], eps: 1.0})
Step:  130300, Reward: [-415.958 -415.958 -415.958] [82.640], Avg: [-445.086 -445.086 -445.086] (1.0000) ({r_i: None, r_t: [-818.432 -818.432 -818.432], eps: 1.0})
Step:  130400, Reward: [-437.218 -437.218 -437.218] [73.045], Avg: [-445.080 -445.080 -445.080] (1.0000) ({r_i: None, r_t: [-902.297 -902.297 -902.297], eps: 1.0})
Step:  130500, Reward: [-448.756 -448.756 -448.756] [130.784], Avg: [-445.083 -445.083 -445.083] (1.0000) ({r_i: None, r_t: [-858.709 -858.709 -858.709], eps: 1.0})
Step:  130600, Reward: [-437.913 -437.913 -437.913] [96.415], Avg: [-445.078 -445.078 -445.078] (1.0000) ({r_i: None, r_t: [-813.861 -813.861 -813.861], eps: 1.0})
Step:  130700, Reward: [-479.691 -479.691 -479.691] [71.995], Avg: [-445.104 -445.104 -445.104] (1.0000) ({r_i: None, r_t: [-875.249 -875.249 -875.249], eps: 1.0})
Step:  130800, Reward: [-406.410 -406.410 -406.410] [70.744], Avg: [-445.074 -445.074 -445.074] (1.0000) ({r_i: None, r_t: [-872.688 -872.688 -872.688], eps: 1.0})
Step:  130900, Reward: [-429.795 -429.795 -429.795] [73.121], Avg: [-445.063 -445.063 -445.063] (1.0000) ({r_i: None, r_t: [-855.694 -855.694 -855.694], eps: 1.0})
Step:  131000, Reward: [-427.095 -427.095 -427.095] [71.520], Avg: [-445.049 -445.049 -445.049] (1.0000) ({r_i: None, r_t: [-873.906 -873.906 -873.906], eps: 1.0})
Step:  131100, Reward: [-452.864 -452.864 -452.864] [80.597], Avg: [-445.055 -445.055 -445.055] (1.0000) ({r_i: None, r_t: [-896.062 -896.062 -896.062], eps: 1.0})
Step:  131200, Reward: [-428.149 -428.149 -428.149] [72.105], Avg: [-445.042 -445.042 -445.042] (1.0000) ({r_i: None, r_t: [-871.409 -871.409 -871.409], eps: 1.0})
Step:  131300, Reward: [-423.717 -423.717 -423.717] [79.263], Avg: [-445.026 -445.026 -445.026] (1.0000) ({r_i: None, r_t: [-817.309 -817.309 -817.309], eps: 1.0})
Step:  131400, Reward: [-431.560 -431.560 -431.560] [97.779], Avg: [-445.016 -445.016 -445.016] (1.0000) ({r_i: None, r_t: [-897.006 -897.006 -897.006], eps: 1.0})
Step:  131500, Reward: [-419.399 -419.399 -419.399] [78.622], Avg: [-444.996 -444.996 -444.996] (1.0000) ({r_i: None, r_t: [-916.277 -916.277 -916.277], eps: 1.0})
Step:  131600, Reward: [-439.909 -439.909 -439.909] [94.044], Avg: [-444.992 -444.992 -444.992] (1.0000) ({r_i: None, r_t: [-828.372 -828.372 -828.372], eps: 1.0})
Step:  131700, Reward: [-458.836 -458.836 -458.836] [126.934], Avg: [-445.003 -445.003 -445.003] (1.0000) ({r_i: None, r_t: [-877.730 -877.730 -877.730], eps: 1.0})
Step:  131800, Reward: [-405.725 -405.725 -405.725] [84.462], Avg: [-444.973 -444.973 -444.973] (1.0000) ({r_i: None, r_t: [-882.588 -882.588 -882.588], eps: 1.0})
Step:  131900, Reward: [-412.887 -412.887 -412.887] [71.326], Avg: [-444.949 -444.949 -444.949] (1.0000) ({r_i: None, r_t: [-866.173 -866.173 -866.173], eps: 1.0})
Step:  132000, Reward: [-432.440 -432.440 -432.440] [96.378], Avg: [-444.939 -444.939 -444.939] (1.0000) ({r_i: None, r_t: [-856.852 -856.852 -856.852], eps: 1.0})
Step:  132100, Reward: [-469.795 -469.795 -469.795] [90.411], Avg: [-444.958 -444.958 -444.958] (1.0000) ({r_i: None, r_t: [-862.704 -862.704 -862.704], eps: 1.0})
Step:  132200, Reward: [-414.839 -414.839 -414.839] [74.933], Avg: [-444.935 -444.935 -444.935] (1.0000) ({r_i: None, r_t: [-857.853 -857.853 -857.853], eps: 1.0})
Step:  132300, Reward: [-467.769 -467.769 -467.769] [96.277], Avg: [-444.953 -444.953 -444.953] (1.0000) ({r_i: None, r_t: [-888.841 -888.841 -888.841], eps: 1.0})
Step:  132400, Reward: [-436.165 -436.165 -436.165] [57.146], Avg: [-444.946 -444.946 -444.946] (1.0000) ({r_i: None, r_t: [-876.186 -876.186 -876.186], eps: 1.0})
Step:  132500, Reward: [-414.659 -414.659 -414.659] [91.057], Avg: [-444.923 -444.923 -444.923] (1.0000) ({r_i: None, r_t: [-854.341 -854.341 -854.341], eps: 1.0})
Step:  132600, Reward: [-432.072 -432.072 -432.072] [74.281], Avg: [-444.913 -444.913 -444.913] (1.0000) ({r_i: None, r_t: [-910.746 -910.746 -910.746], eps: 1.0})
Step:  132700, Reward: [-420.433 -420.433 -420.433] [62.950], Avg: [-444.895 -444.895 -444.895] (1.0000) ({r_i: None, r_t: [-891.719 -891.719 -891.719], eps: 1.0})
Step:  132800, Reward: [-408.124 -408.124 -408.124] [89.684], Avg: [-444.867 -444.867 -444.867] (1.0000) ({r_i: None, r_t: [-851.255 -851.255 -851.255], eps: 1.0})
Step:  132900, Reward: [-434.738 -434.738 -434.738] [69.847], Avg: [-444.860 -444.860 -444.860] (1.0000) ({r_i: None, r_t: [-854.100 -854.100 -854.100], eps: 1.0})
Step:  133000, Reward: [-446.787 -446.787 -446.787] [83.966], Avg: [-444.861 -444.861 -444.861] (1.0000) ({r_i: None, r_t: [-829.133 -829.133 -829.133], eps: 1.0})
Step:  133100, Reward: [-436.323 -436.323 -436.323] [102.903], Avg: [-444.855 -444.855 -444.855] (1.0000) ({r_i: None, r_t: [-891.943 -891.943 -891.943], eps: 1.0})
Step:  133200, Reward: [-426.725 -426.725 -426.725] [83.611], Avg: [-444.841 -444.841 -444.841] (1.0000) ({r_i: None, r_t: [-880.679 -880.679 -880.679], eps: 1.0})
Step:  133300, Reward: [-455.591 -455.591 -455.591] [153.650], Avg: [-444.849 -444.849 -444.849] (1.0000) ({r_i: None, r_t: [-897.447 -897.447 -897.447], eps: 1.0})
Step:  133400, Reward: [-423.996 -423.996 -423.996] [106.763], Avg: [-444.834 -444.834 -444.834] (1.0000) ({r_i: None, r_t: [-808.866 -808.866 -808.866], eps: 1.0})
Step:  133500, Reward: [-448.775 -448.775 -448.775] [97.437], Avg: [-444.837 -444.837 -444.837] (1.0000) ({r_i: None, r_t: [-868.828 -868.828 -868.828], eps: 1.0})
Step:  133600, Reward: [-468.133 -468.133 -468.133] [89.875], Avg: [-444.854 -444.854 -444.854] (1.0000) ({r_i: None, r_t: [-839.365 -839.365 -839.365], eps: 1.0})
Step:  133700, Reward: [-450.853 -450.853 -450.853] [71.022], Avg: [-444.858 -444.858 -444.858] (1.0000) ({r_i: None, r_t: [-859.000 -859.000 -859.000], eps: 1.0})
Step:  133800, Reward: [-417.368 -417.368 -417.368] [106.680], Avg: [-444.838 -444.838 -444.838] (1.0000) ({r_i: None, r_t: [-815.738 -815.738 -815.738], eps: 1.0})
Step:  133900, Reward: [-437.013 -437.013 -437.013] [108.145], Avg: [-444.832 -444.832 -444.832] (1.0000) ({r_i: None, r_t: [-828.076 -828.076 -828.076], eps: 1.0})
Step:  134000, Reward: [-439.666 -439.666 -439.666] [87.298], Avg: [-444.828 -444.828 -444.828] (1.0000) ({r_i: None, r_t: [-877.292 -877.292 -877.292], eps: 1.0})
Step:  134100, Reward: [-421.049 -421.049 -421.049] [67.849], Avg: [-444.811 -444.811 -444.811] (1.0000) ({r_i: None, r_t: [-854.874 -854.874 -854.874], eps: 1.0})
Step:  134200, Reward: [-408.368 -408.368 -408.368] [62.666], Avg: [-444.783 -444.783 -444.783] (1.0000) ({r_i: None, r_t: [-881.304 -881.304 -881.304], eps: 1.0})
Step:  134300, Reward: [-437.424 -437.424 -437.424] [82.460], Avg: [-444.778 -444.778 -444.778] (1.0000) ({r_i: None, r_t: [-853.540 -853.540 -853.540], eps: 1.0})
Step:  134400, Reward: [-454.590 -454.590 -454.590] [102.116], Avg: [-444.785 -444.785 -444.785] (1.0000) ({r_i: None, r_t: [-897.234 -897.234 -897.234], eps: 1.0})
Step:  134500, Reward: [-441.387 -441.387 -441.387] [87.844], Avg: [-444.783 -444.783 -444.783] (1.0000) ({r_i: None, r_t: [-835.281 -835.281 -835.281], eps: 1.0})
Step:  134600, Reward: [-392.004 -392.004 -392.004] [69.488], Avg: [-444.744 -444.744 -444.744] (1.0000) ({r_i: None, r_t: [-853.526 -853.526 -853.526], eps: 1.0})
Step:  134700, Reward: [-432.557 -432.557 -432.557] [74.337], Avg: [-444.734 -444.734 -444.734] (1.0000) ({r_i: None, r_t: [-874.663 -874.663 -874.663], eps: 1.0})
Step:  134800, Reward: [-449.359 -449.359 -449.359] [92.275], Avg: [-444.738 -444.738 -444.738] (1.0000) ({r_i: None, r_t: [-825.215 -825.215 -825.215], eps: 1.0})
Step:  134900, Reward: [-451.088 -451.088 -451.088] [119.669], Avg: [-444.743 -444.743 -444.743] (1.0000) ({r_i: None, r_t: [-852.777 -852.777 -852.777], eps: 1.0})
Step:  135000, Reward: [-437.287 -437.287 -437.287] [100.024], Avg: [-444.737 -444.737 -444.737] (1.0000) ({r_i: None, r_t: [-882.844 -882.844 -882.844], eps: 1.0})
Step:  135100, Reward: [-435.739 -435.739 -435.739] [96.440], Avg: [-444.730 -444.730 -444.730] (1.0000) ({r_i: None, r_t: [-856.231 -856.231 -856.231], eps: 1.0})
Step:  135200, Reward: [-494.176 -494.176 -494.176] [127.256], Avg: [-444.767 -444.767 -444.767] (1.0000) ({r_i: None, r_t: [-896.525 -896.525 -896.525], eps: 1.0})
Step:  135300, Reward: [-453.401 -453.401 -453.401] [87.357], Avg: [-444.773 -444.773 -444.773] (1.0000) ({r_i: None, r_t: [-896.382 -896.382 -896.382], eps: 1.0})
Step:  135400, Reward: [-405.917 -405.917 -405.917] [107.519], Avg: [-444.745 -444.745 -444.745] (1.0000) ({r_i: None, r_t: [-849.806 -849.806 -849.806], eps: 1.0})
Step:  135500, Reward: [-389.916 -389.916 -389.916] [65.616], Avg: [-444.704 -444.704 -444.704] (1.0000) ({r_i: None, r_t: [-891.781 -891.781 -891.781], eps: 1.0})
Step:  135600, Reward: [-441.503 -441.503 -441.503] [65.034], Avg: [-444.702 -444.702 -444.702] (1.0000) ({r_i: None, r_t: [-867.313 -867.313 -867.313], eps: 1.0})
Step:  135700, Reward: [-410.947 -410.947 -410.947] [75.014], Avg: [-444.677 -444.677 -444.677] (1.0000) ({r_i: None, r_t: [-859.528 -859.528 -859.528], eps: 1.0})
Step:  135800, Reward: [-430.224 -430.224 -430.224] [81.184], Avg: [-444.666 -444.666 -444.666] (1.0000) ({r_i: None, r_t: [-930.235 -930.235 -930.235], eps: 1.0})
Step:  135900, Reward: [-428.478 -428.478 -428.478] [90.471], Avg: [-444.654 -444.654 -444.654] (1.0000) ({r_i: None, r_t: [-871.074 -871.074 -871.074], eps: 1.0})
Step:  136000, Reward: [-411.174 -411.174 -411.174] [75.870], Avg: [-444.630 -444.630 -444.630] (1.0000) ({r_i: None, r_t: [-875.387 -875.387 -875.387], eps: 1.0})
Step:  136100, Reward: [-457.959 -457.959 -457.959] [116.681], Avg: [-444.640 -444.640 -444.640] (1.0000) ({r_i: None, r_t: [-841.093 -841.093 -841.093], eps: 1.0})
Step:  136200, Reward: [-435.762 -435.762 -435.762] [91.808], Avg: [-444.633 -444.633 -444.633] (1.0000) ({r_i: None, r_t: [-899.700 -899.700 -899.700], eps: 1.0})
Step:  136300, Reward: [-441.952 -441.952 -441.952] [75.206], Avg: [-444.631 -444.631 -444.631] (1.0000) ({r_i: None, r_t: [-877.781 -877.781 -877.781], eps: 1.0})
Step:  136400, Reward: [-435.954 -435.954 -435.954] [101.686], Avg: [-444.625 -444.625 -444.625] (1.0000) ({r_i: None, r_t: [-907.546 -907.546 -907.546], eps: 1.0})
Step:  136500, Reward: [-465.644 -465.644 -465.644] [87.494], Avg: [-444.640 -444.640 -444.640] (1.0000) ({r_i: None, r_t: [-877.582 -877.582 -877.582], eps: 1.0})
Step:  136600, Reward: [-457.610 -457.610 -457.610] [109.604], Avg: [-444.650 -444.650 -444.650] (1.0000) ({r_i: None, r_t: [-905.608 -905.608 -905.608], eps: 1.0})
Step:  136700, Reward: [-434.339 -434.339 -434.339] [84.210], Avg: [-444.642 -444.642 -444.642] (1.0000) ({r_i: None, r_t: [-877.451 -877.451 -877.451], eps: 1.0})
Step:  136800, Reward: [-433.879 -433.879 -433.879] [105.930], Avg: [-444.634 -444.634 -444.634] (1.0000) ({r_i: None, r_t: [-833.173 -833.173 -833.173], eps: 1.0})
Step:  136900, Reward: [-426.798 -426.798 -426.798] [102.649], Avg: [-444.621 -444.621 -444.621] (1.0000) ({r_i: None, r_t: [-870.906 -870.906 -870.906], eps: 1.0})
Step:  137000, Reward: [-436.387 -436.387 -436.387] [78.336], Avg: [-444.615 -444.615 -444.615] (1.0000) ({r_i: None, r_t: [-877.282 -877.282 -877.282], eps: 1.0})
Step:  137100, Reward: [-459.584 -459.584 -459.584] [141.811], Avg: [-444.626 -444.626 -444.626] (1.0000) ({r_i: None, r_t: [-804.167 -804.167 -804.167], eps: 1.0})
Step:  137200, Reward: [-424.928 -424.928 -424.928] [62.784], Avg: [-444.612 -444.612 -444.612] (1.0000) ({r_i: None, r_t: [-891.823 -891.823 -891.823], eps: 1.0})
Step:  137300, Reward: [-442.601 -442.601 -442.601] [74.668], Avg: [-444.610 -444.610 -444.610] (1.0000) ({r_i: None, r_t: [-894.967 -894.967 -894.967], eps: 1.0})
Step:  137400, Reward: [-443.625 -443.625 -443.625] [56.378], Avg: [-444.610 -444.610 -444.610] (1.0000) ({r_i: None, r_t: [-852.025 -852.025 -852.025], eps: 1.0})
Step:  137500, Reward: [-477.333 -477.333 -477.333] [100.669], Avg: [-444.633 -444.633 -444.633] (1.0000) ({r_i: None, r_t: [-838.480 -838.480 -838.480], eps: 1.0})
Step:  137600, Reward: [-422.012 -422.012 -422.012] [116.859], Avg: [-444.617 -444.617 -444.617] (1.0000) ({r_i: None, r_t: [-868.805 -868.805 -868.805], eps: 1.0})
Step:  137700, Reward: [-462.894 -462.894 -462.894] [136.231], Avg: [-444.630 -444.630 -444.630] (1.0000) ({r_i: None, r_t: [-920.899 -920.899 -920.899], eps: 1.0})
Step:  137800, Reward: [-423.043 -423.043 -423.043] [65.416], Avg: [-444.615 -444.615 -444.615] (1.0000) ({r_i: None, r_t: [-862.938 -862.938 -862.938], eps: 1.0})
Step:  137900, Reward: [-428.249 -428.249 -428.249] [90.850], Avg: [-444.603 -444.603 -444.603] (1.0000) ({r_i: None, r_t: [-864.417 -864.417 -864.417], eps: 1.0})
Step:  138000, Reward: [-404.187 -404.187 -404.187] [67.084], Avg: [-444.574 -444.574 -444.574] (1.0000) ({r_i: None, r_t: [-848.388 -848.388 -848.388], eps: 1.0})
Step:  138100, Reward: [-415.309 -415.309 -415.309] [90.412], Avg: [-444.552 -444.552 -444.552] (1.0000) ({r_i: None, r_t: [-870.803 -870.803 -870.803], eps: 1.0})
Step:  138200, Reward: [-431.958 -431.958 -431.958] [98.108], Avg: [-444.543 -444.543 -444.543] (1.0000) ({r_i: None, r_t: [-866.016 -866.016 -866.016], eps: 1.0})
Step:  138300, Reward: [-434.549 -434.549 -434.549] [98.728], Avg: [-444.536 -444.536 -444.536] (1.0000) ({r_i: None, r_t: [-845.772 -845.772 -845.772], eps: 1.0})
Step:  138400, Reward: [-473.633 -473.633 -473.633] [88.256], Avg: [-444.557 -444.557 -444.557] (1.0000) ({r_i: None, r_t: [-893.301 -893.301 -893.301], eps: 1.0})
Step:  138500, Reward: [-434.212 -434.212 -434.212] [106.085], Avg: [-444.550 -444.550 -444.550] (1.0000) ({r_i: None, r_t: [-876.993 -876.993 -876.993], eps: 1.0})
Step:  138600, Reward: [-441.328 -441.328 -441.328] [93.127], Avg: [-444.547 -444.547 -444.547] (1.0000) ({r_i: None, r_t: [-907.756 -907.756 -907.756], eps: 1.0})
Step:  138700, Reward: [-467.391 -467.391 -467.391] [94.888], Avg: [-444.564 -444.564 -444.564] (1.0000) ({r_i: None, r_t: [-871.117 -871.117 -871.117], eps: 1.0})
Step:  138800, Reward: [-431.007 -431.007 -431.007] [106.295], Avg: [-444.554 -444.554 -444.554] (1.0000) ({r_i: None, r_t: [-868.960 -868.960 -868.960], eps: 1.0})
Step:  138900, Reward: [-453.468 -453.468 -453.468] [91.785], Avg: [-444.560 -444.560 -444.560] (1.0000) ({r_i: None, r_t: [-950.806 -950.806 -950.806], eps: 1.0})
Step:  139000, Reward: [-463.285 -463.285 -463.285] [84.031], Avg: [-444.574 -444.574 -444.574] (1.0000) ({r_i: None, r_t: [-833.068 -833.068 -833.068], eps: 1.0})
Step:  139100, Reward: [-407.515 -407.515 -407.515] [81.716], Avg: [-444.547 -444.547 -444.547] (1.0000) ({r_i: None, r_t: [-819.978 -819.978 -819.978], eps: 1.0})
Step:  139200, Reward: [-409.457 -409.457 -409.457] [82.632], Avg: [-444.522 -444.522 -444.522] (1.0000) ({r_i: None, r_t: [-869.776 -869.776 -869.776], eps: 1.0})
Step:  139300, Reward: [-457.648 -457.648 -457.648] [96.901], Avg: [-444.531 -444.531 -444.531] (1.0000) ({r_i: None, r_t: [-833.296 -833.296 -833.296], eps: 1.0})
Step:  139400, Reward: [-449.064 -449.064 -449.064] [91.852], Avg: [-444.535 -444.535 -444.535] (1.0000) ({r_i: None, r_t: [-874.626 -874.626 -874.626], eps: 1.0})
