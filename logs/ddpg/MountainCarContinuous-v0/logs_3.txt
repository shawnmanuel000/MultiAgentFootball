Model: <class 'models.ddpg.DDPGAgent'>, Dir: MountainCarContinuous-v0
num_envs: 16, state_size: (2,), action_size: (1,), action_space: Box(1,),

import os
import math
import torch
import random
import numpy as np
from models.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, EPS_DECAY, REPLAY_BATCH_SIZE

class DDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		state = self.layer3(state).relu() 
		action_mu = self.action_mu(state)
		action_sig = self.action_sig(state).exp()
		epsilon = torch.randn_like(action_sig)
		action = action_mu + epsilon.mul(action_sig) if sample else action_mu
		return action.tanh()
	
class DDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.net_state = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.net_action = torch.nn.Linear(*action_size, INPUT_LAYER)
		self.net_layer1 = torch.nn.Linear(2*INPUT_LAYER, CRITIC_HIDDEN)
		self.net_layer2 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = self.net_state(state).relu()
		net_action = self.net_action(action).relu()
		net_layer = torch.cat([state, net_action], dim=-1)
		net_layer = self.net_layer1(net_layer).relu()
		net_layer = self.net_layer2(net_layer).relu()
		q_value = self.q_value(net_layer)
		return q_value

class DDPGNetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None): 
		super().__init__(state_size, action_size, DDPGActor, DDPGCritic, lr=lr, gpu=gpu, load=load)

	def get_action(self, state, use_target=False, numpy=True, sample=True):
		with torch.no_grad():
			actor = self.actor_local if not use_target else self.actor_target
			return actor(state, sample).cpu().numpy() if numpy else actor(state, sample)

	def get_q_value(self, state, action, use_target=False, numpy=True):
		with torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			return critic(state, action).cpu().numpy() if numpy else critic(state, action)
	
	def optimize(self, states, actions, q_targets, importances=1):
		q_values = self.critic_local(states, actions)
		critic_error = q_values - q_targets.detach()
		critic_loss = importances.to(self.device) * critic_error.pow(2)
		self.step(self.critic_optimizer, critic_loss.mean())

		q_actions = self.critic_local(states, self.actor_local(states))
		actor_loss = -(q_actions - q_values.detach())
		self.step(self.actor_optimizer, actor_loss.mean())
		
		self.soft_copy(self.actor_local, self.actor_target)
		self.soft_copy(self.critic_local, self.critic_target)
		return critic_error.cpu().detach().numpy().squeeze(-1)
	
	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ddpg", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ddpg", dirname, name)

class DDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, decay=EPS_DECAY, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, DDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True, e_greedy=False):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if e_greedy and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), sample=sample)
		action = action_greedy if e_greedy else np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if done[0] or len(self.buffer) >= self.update_freq:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			next_state = self.to_tensor(next_state)
			next_action = self.network.get_action(next_state, use_target=True, numpy=False)
			values = self.network.get_q_value(states, actions, use_target=True, numpy=False)
			next_value = self.network.get_q_value(next_state, next_action, use_target=True, numpy=False)
			targets, _ = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values)
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states, actions, targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=False)	
		if len(self.replay_buffer) > 0:
			(states, actions, targets), indices, importances = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)
			errors = self.network.optimize(states, actions, targets, importances**(1-self.eps))
			self.replay_buffer.update_priorities(indices, errors)
			if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[4]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class AsyncAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = AsyncAgent(envs.state_size, envs.action_size, num_envs, model)
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.stack.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0]:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 310, Reward: 39.4456 [59.81], Avg: -20.3642 (0.980)
Step: 803, Reward: 12.7171 [55.91], Avg: -31.7785 (0.960)
Step: 1366, Reward: 13.9975 [54.12], Avg: -34.5597 (0.941)
Step: 2365, Reward: 64.5608 [47.26], Avg: -21.5934 (0.922)
Step: 3364, Reward: 82.5422 [7.33], Avg: -2.2318 (0.904)
Step: 4031, Reward: 67.0512 [44.47], Avg: 1.9030 (0.886)
Step: 5030, Reward: 38.3036 [54.01], Avg: -0.6120 (0.868)
Step: 5359, Reward: 85.6267 [5.64], Avg: 9.4625 (0.851)
Step: 6211, Reward: 79.0948 [5.85], Avg: 16.5500 (0.834)
Step: 7202, Reward: 37.3185 [56.32], Avg: 12.9946 (0.817)
Step: 7385, Reward: -7.0589 [45.70], Avg: 7.0168 (0.801)
Step: 7593, Reward: 33.0266 [58.62], Avg: 4.2990 (0.785)
Step: 7868, Reward: 64.7705 [41.13], Avg: 5.7871 (0.769)
Step: 8560, Reward: 63.6355 [43.27], Avg: 6.8284 (0.754)
Step: 9425, Reward: 61.8014 [44.40], Avg: 7.5332 (0.739)
Step: 9638, Reward: 20.0813 [56.13], Avg: 4.8092 (0.724)
Step: 10637, Reward: 80.5688 [6.58], Avg: 8.8787 (0.709)
Step: 11636, Reward: 30.6335 [59.16], Avg: 6.8008 (0.695)
Step: 12123, Reward: 40.0273 [54.40], Avg: 5.6864 (0.681)
Step: 13122, Reward: 35.8308 [54.98], Avg: 4.4448 (0.668)
Step: 13563, Reward: 64.1293 [44.18], Avg: 5.1830 (0.654)
Step: 14562, Reward: 37.0540 [58.04], Avg: 3.9933 (0.641)
Step: 15183, Reward: 16.6460 [54.99], Avg: 2.1527 (0.628)
Step: 16182, Reward: -9.3317 [47.94], Avg: -0.3232 (0.616)
Step: 16621, Reward: 32.4347 [56.25], Avg: -1.2630 (0.603)
Step: 17620, Reward: 57.8374 [44.96], Avg: -0.7190 (0.591)
Step: 18619, Reward: 81.4436 [8.63], Avg: 2.0045 (0.580)
Step: 19289, Reward: 10.7567 [56.43], Avg: 0.3017 (0.568)
Step: 20241, Reward: 7.5911 [64.13], Avg: -1.6584 (0.557)
Step: 20820, Reward: 32.8458 [53.15], Avg: -2.2801 (0.545)
Step: 21819, Reward: 35.4509 [56.85], Avg: -2.8968 (0.535)
Step: 22330, Reward: -10.2570 [46.42], Avg: -4.5774 (0.524)
Step: 22580, Reward: 33.2099 [53.55], Avg: -5.0551 (0.513)
Step: 23561, Reward: 54.6714 [42.14], Avg: -4.5379 (0.503)
Step: 24109, Reward: 32.9366 [55.90], Avg: -5.0642 (0.493)
Step: 24399, Reward: 6.0911 [56.59], Avg: -6.3265 (0.483)
Step: 24968, Reward: 77.0453 [12.10], Avg: -4.4003 (0.474)
Step: 25967, Reward: 31.5572 [56.44], Avg: -4.9393 (0.464)
Step: 26966, Reward: 4.1167 [61.73], Avg: -6.2899 (0.455)
Step: 27965, Reward: 58.0107 [52.18], Avg: -5.9868 (0.446)
Step: 28964, Reward: 4.4389 [61.42], Avg: -7.2305 (0.437)
Step: 29584, Reward: 9.0485 [56.98], Avg: -8.1995 (0.428)
Step: 30547, Reward: 32.9397 [50.88], Avg: -8.4260 (0.419)
Step: 31546, Reward: 1.9908 [57.82], Avg: -9.5035 (0.411)
Step: 32353, Reward: -36.4047 [4.19], Avg: -10.1945 (0.403)
Step: 33352, Reward: 47.7324 [51.07], Avg: -10.0454 (0.395)
Step: 34351, Reward: 5.7504 [53.92], Avg: -10.8566 (0.387)
Step: 35350, Reward: 29.8791 [58.20], Avg: -11.2205 (0.379)
Step: 36349, Reward: -23.6037 [48.70], Avg: -12.4672 (0.372)
Step: 37348, Reward: -2.3034 [62.30], Avg: -13.5099 (0.364)
Step: 38347, Reward: 14.8875 [49.68], Avg: -13.9271 (0.357)
Step: 38665, Reward: -43.0940 [6.36], Avg: -14.6103 (0.350)
Step: 39320, Reward: -21.3406 [41.55], Avg: -15.5213 (0.343)
Step: 40098, Reward: -42.2187 [5.22], Avg: -16.1123 (0.336)
Step: 41097, Reward: -8.8147 [46.27], Avg: -16.8210 (0.329)
Step: 42096, Reward: -52.4310 [6.98], Avg: -17.5815 (0.323)
Step: 43095, Reward: -18.1901 [42.50], Avg: -18.3378 (0.316)
Step: 44094, Reward: 19.1217 [58.77], Avg: -18.7052 (0.310)
Step: 45093, Reward: -32.2720 [44.72], Avg: -19.6930 (0.304)
Step: 46092, Reward: -24.6695 [49.75], Avg: -20.6052 (0.298)
Step: 47091, Reward: -21.1791 [39.11], Avg: -21.2557 (0.292)
Step: 48090, Reward: -54.5383 [6.02], Avg: -21.8896 (0.286)
Step: 49089, Reward: -53.7191 [10.36], Avg: -22.5593 (0.280)
Step: 50088, Reward: -51.8987 [10.00], Avg: -23.1741 (0.274)
Step: 51087, Reward: -58.8988 [8.35], Avg: -23.8522 (0.269)
Step: 52086, Reward: -59.6925 [10.52], Avg: -24.5547 (0.264)
Step: 53085, Reward: -57.7398 [2.00], Avg: -25.0798 (0.258)
Step: 54084, Reward: -58.8395 [4.33], Avg: -25.6400 (0.253)
Step: 55083, Reward: -52.6099 [8.16], Avg: -26.1491 (0.248)
Step: 56082, Reward: -66.2237 [5.15], Avg: -26.7951 (0.243)
Step: 57081, Reward: -60.8135 [0.93], Avg: -27.2874 (0.238)
Step: 58080, Reward: -64.0215 [5.99], Avg: -27.8808 (0.233)
Step: 59079, Reward: -65.2007 [4.98], Avg: -28.4602 (0.229)
Step: 60078, Reward: -43.5931 [1.94], Avg: -28.6910 (0.224)
Step: 61077, Reward: -6.3245 [2.85], Avg: -28.4307 (0.220)
Step: 62076, Reward: -10.9673 [3.31], Avg: -28.2445 (0.215)
Step: 63075, Reward: -13.0033 [9.67], Avg: -28.1721 (0.211)
Step: 64074, Reward: -36.6578 [6.18], Avg: -28.3602 (0.207)
Step: 64934, Reward: 9.0132 [46.36], Avg: -28.4739 (0.203)
Step: 65517, Reward: 73.6836 [3.30], Avg: -27.2382 (0.199)
Step: 66014, Reward: 81.3791 [1.93], Avg: -25.9210 (0.195)
Step: 66316, Reward: 85.0806 [1.25], Avg: -24.5825 (0.191)
Step: 66647, Reward: 85.3704 [2.30], Avg: -23.2855 (0.187)
Step: 66941, Reward: 92.5376 [1.14], Avg: -21.9202 (0.183)
Step: 67075, Reward: 91.3138 [3.34], Avg: -20.6273 (0.180)
Step: 67189, Reward: 94.0429 [0.97], Avg: -19.3053 (0.176)
Step: 67372, Reward: 92.0713 [2.29], Avg: -18.0513 (0.172)
Step: 67501, Reward: 93.7068 [0.75], Avg: -16.7899 (0.169)
Step: 67604, Reward: 92.4837 [1.55], Avg: -15.5794 (0.166)
Step: 67705, Reward: 92.1100 [1.15], Avg: -14.3957 (0.162)
Step: 67806, Reward: 92.7058 [1.28], Avg: -13.2329 (0.159)
Step: 67968, Reward: 93.4320 [0.37], Avg: -12.0775 (0.156)
Step: 68108, Reward: 94.1339 [0.40], Avg: -10.9397 (0.153)
Step: 68214, Reward: 92.1631 [1.93], Avg: -9.8634 (0.150)
Step: 68319, Reward: 93.3047 [0.70], Avg: -8.7848 (0.147)
Step: 68421, Reward: 92.8523 [0.70], Avg: -7.7334 (0.144)
Step: 68546, Reward: 93.0772 [0.99], Avg: -6.7043 (0.141)
Step: 68651, Reward: 93.6788 [0.47], Avg: -5.6848 (0.138)
Step: 68777, Reward: 92.6267 [0.24], Avg: -4.6942 (0.135)
Step: 68875, Reward: 92.3993 [1.48], Avg: -3.7380 (0.133)
Step: 68972, Reward: 93.0175 [0.73], Avg: -2.7873 (0.130)
Step: 69075, Reward: 92.6205 [0.68], Avg: -1.8587 (0.127)
Step: 69178, Reward: 92.3861 [0.26], Avg: -0.9462 (0.125)
Step: 69280, Reward: 92.5988 [2.01], Avg: -0.0660 (0.122)
Step: 69381, Reward: 92.5635 [1.91], Avg: 0.7980 (0.120)
Step: 69482, Reward: 92.2771 [0.82], Avg: 1.6532 (0.117)
Step: 69583, Reward: 92.2987 [0.49], Avg: 2.4958 (0.115)
Step: 69685, Reward: 92.6394 [0.32], Avg: 3.3275 (0.113)
Step: 69778, Reward: 93.0203 [1.06], Avg: 4.1406 (0.111)
Step: 69874, Reward: 92.5256 [0.35], Avg: 4.9410 (0.108)
Step: 69969, Reward: 92.8292 [0.32], Avg: 5.7299 (0.106)
Step: 70068, Reward: 92.2299 [0.47], Avg: 6.4980 (0.104)
Step: 70173, Reward: 92.4316 [0.40], Avg: 7.2549 (0.102)
Step: 70262, Reward: 92.2246 [0.65], Avg: 7.9946 (0.100)
Step: 70358, Reward: 92.8070 [0.79], Avg: 8.7252 (0.098)
Step: 70455, Reward: 92.6609 [0.55], Avg: 9.4440 (0.096)
Step: 70552, Reward: 91.7794 [1.11], Avg: 10.1382 (0.094)
Step: 70629, Reward: 92.4775 [0.45], Avg: 10.8322 (0.092)
Step: 70721, Reward: 92.4201 [0.28], Avg: 11.5155 (0.090)
Step: 70816, Reward: 92.1152 [0.66], Avg: 12.1817 (0.089)
Step: 70921, Reward: 91.7194 [0.93], Avg: 12.8313 (0.087)
Step: 71014, Reward: 92.0818 [0.64], Avg: 13.4757 (0.085)
Step: 71101, Reward: 92.2826 [0.73], Avg: 14.1105 (0.083)
Step: 71199, Reward: 93.8896 [0.55], Avg: 14.7494 (0.082)
Step: 71295, Reward: 91.9438 [0.43], Avg: 15.3636 (0.080)
Step: 71391, Reward: 92.6473 [0.67], Avg: 15.9716 (0.078)
Step: 71491, Reward: 92.5598 [1.23], Avg: 16.5650 (0.077)
Step: 71616, Reward: 92.1998 [0.83], Avg: 17.1494 (0.075)
Step: 71707, Reward: 92.7892 [1.01], Avg: 17.7279 (0.074)
Step: 71803, Reward: 93.5588 [0.91], Avg: 18.3042 (0.072)
Step: 71872, Reward: 93.3165 [0.94], Avg: 18.8696 (0.071)
Step: 71970, Reward: 91.7083 [0.31], Avg: 19.4191 (0.069)
Step: 72062, Reward: 93.4010 [0.77], Avg: 19.9696 (0.068)
Step: 72135, Reward: 93.2229 [0.96], Avg: 20.5091 (0.067)
Step: 72203, Reward: 92.2418 [0.30], Avg: 21.0382 (0.065)
Step: 72294, Reward: 92.7453 [0.72], Avg: 21.5602 (0.064)
Step: 72389, Reward: 91.8389 [1.72], Avg: 22.0606 (0.063)
Step: 72488, Reward: 92.7772 [0.85], Avg: 22.5669 (0.062)
Step: 72557, Reward: 93.8308 [0.69], Avg: 23.0746 (0.060)
Step: 72648, Reward: 93.4862 [0.90], Avg: 23.5711 (0.059)
Step: 72716, Reward: 91.7988 [0.21], Avg: 24.0535 (0.058)
Step: 72791, Reward: 92.8011 [1.97], Avg: 24.5238 (0.057)
Step: 72914, Reward: 93.3100 [0.80], Avg: 24.9992 (0.056)
Step: 72982, Reward: 93.3910 [1.04], Avg: 25.4670 (0.055)
Step: 73050, Reward: 93.9789 [0.16], Avg: 25.9383 (0.053)
Step: 73117, Reward: 93.9024 [0.11], Avg: 26.4031 (0.052)
Step: 73190, Reward: 92.6885 [0.79], Avg: 26.8486 (0.051)
Step: 73287, Reward: 93.2271 [0.90], Avg: 27.2911 (0.050)
Step: 73355, Reward: 93.6174 [0.76], Avg: 27.7311 (0.049)
Step: 73426, Reward: 93.0046 [0.95], Avg: 28.1599 (0.048)
Step: 73493, Reward: 92.3510 [0.89], Avg: 28.5791 (0.047)
Step: 73561, Reward: 94.0079 [0.21], Avg: 29.0082 (0.046)
Step: 73628, Reward: 93.0273 [0.99], Avg: 29.4202 (0.045)
Step: 73726, Reward: 93.2069 [1.05], Avg: 29.8276 (0.045)
Step: 73821, Reward: 93.2386 [0.88], Avg: 30.2310 (0.044)
Step: 73887, Reward: 93.4361 [0.79], Avg: 30.6311 (0.043)
Step: 73954, Reward: 93.8363 [0.13], Avg: 31.0329 (0.042)
Step: 74026, Reward: 93.4443 [1.01], Avg: 31.4215 (0.041)
Step: 74093, Reward: 93.5857 [0.85], Avg: 31.8072 (0.040)
Step: 74159, Reward: 92.6674 [1.15], Avg: 32.1804 (0.039)
Step: 74255, Reward: 92.3220 [1.19], Avg: 32.5465 (0.039)
Step: 74348, Reward: 93.7497 [0.23], Avg: 32.9229 (0.038)
Step: 74424, Reward: 93.1808 [0.91], Avg: 33.2870 (0.037)
Step: 74520, Reward: 92.8898 [1.06], Avg: 33.6440 (0.036)
Step: 74614, Reward: 93.2949 [0.93], Avg: 33.9999 (0.036)
Step: 74681, Reward: 93.9051 [0.10], Avg: 34.3601 (0.035)
Step: 74750, Reward: 93.8185 [0.14], Avg: 34.7153 (0.034)
Step: 74823, Reward: 93.7830 [0.09], Avg: 35.0664 (0.034)
Step: 74892, Reward: 93.2514 [0.96], Avg: 35.4050 (0.033)
Step: 74958, Reward: 93.6448 [0.07], Avg: 35.7472 (0.032)
Step: 75025, Reward: 93.7648 [0.05], Avg: 36.0862 (0.032)
Step: 75092, Reward: 93.7830 [0.07], Avg: 36.4212 (0.031)
Step: 75159, Reward: 93.8551 [0.05], Avg: 36.7529 (0.030)
Step: 75226, Reward: 93.7994 [0.08], Avg: 37.0803 (0.030)
Step: 75322, Reward: 93.7204 [0.12], Avg: 37.4033 (0.029)
Step: 75388, Reward: 93.7749 [0.08], Avg: 37.7231 (0.029)
Step: 75455, Reward: 92.7957 [1.00], Avg: 38.0286 (0.028)
Step: 75525, Reward: 93.7829 [0.11], Avg: 38.3412 (0.027)
Step: 75591, Reward: 93.7549 [0.08], Avg: 38.6503 (0.027)
Step: 75661, Reward: 93.8029 [0.15], Avg: 38.9559 (0.026)
Step: 75727, Reward: 93.7427 [0.12], Avg: 39.2580 (0.026)
Step: 75794, Reward: 92.2674 [1.11], Avg: 39.5431 (0.025)
Step: 75861, Reward: 93.6902 [0.06], Avg: 39.8387 (0.025)
Step: 75928, Reward: 93.2550 [0.97], Avg: 40.1237 (0.024)
Step: 75994, Reward: 93.6316 [0.08], Avg: 40.4125 (0.024)
Step: 76062, Reward: 93.6254 [0.05], Avg: 40.6983 (0.023)
Step: 76130, Reward: 93.6711 [0.05], Avg: 40.9814 (0.023)
Step: 76198, Reward: 93.6795 [0.05], Avg: 41.2614 (0.022)
Step: 76266, Reward: 93.7063 [0.03], Avg: 41.5387 (0.022)
Step: 76332, Reward: 93.5469 [0.08], Avg: 41.8120 (0.022)
Step: 76399, Reward: 93.6797 [0.07], Avg: 42.0832 (0.021)
Step: 76467, Reward: 93.6876 [0.07], Avg: 42.3516 (0.021)
Step: 76535, Reward: 93.6236 [0.08], Avg: 42.6169 (0.020)
Step: 76602, Reward: 93.6083 [0.05], Avg: 42.8795 (0.020)
Step: 76671, Reward: 93.5360 [0.06], Avg: 43.1389 (0.020)
Step: 76738, Reward: 93.5159 [0.08], Avg: 43.3956 (0.020)
Step: 76805, Reward: 93.6796 [0.08], Avg: 43.6504 (0.020)
Step: 76872, Reward: 93.6717 [0.08], Avg: 43.9026 (0.020)
Step: 76939, Reward: 93.6480 [0.08], Avg: 44.1522 (0.020)
Step: 77006, Reward: 93.5957 [0.08], Avg: 44.3990 (0.020)
Step: 77073, Reward: 93.4958 [0.09], Avg: 44.6428 (0.020)
Step: 77140, Reward: 93.6111 [0.07], Avg: 44.8849 (0.020)
Step: 77209, Reward: 93.6703 [0.07], Avg: 45.1249 (0.020)
Step: 77276, Reward: 93.6870 [0.06], Avg: 45.3627 (0.020)
Step: 77344, Reward: 93.6459 [0.06], Avg: 45.5979 (0.020)
Step: 77411, Reward: 93.6956 [0.02], Avg: 45.8313 (0.020)
Step: 77480, Reward: 93.6010 [0.09], Avg: 46.0617 (0.020)
Step: 77547, Reward: 93.6228 [0.05], Avg: 46.2901 (0.020)
Step: 77614, Reward: 93.6754 [0.06], Avg: 46.5166 (0.020)
Step: 77683, Reward: 93.6160 [0.09], Avg: 46.7404 (0.020)
Step: 77751, Reward: 93.6147 [0.08], Avg: 46.9622 (0.020)
Step: 77818, Reward: 93.6244 [0.07], Avg: 47.1820 (0.020)
Step: 77886, Reward: 93.5398 [0.12], Avg: 47.3990 (0.020)
Step: 77955, Reward: 93.6799 [0.08], Avg: 47.6149 (0.020)
Step: 78023, Reward: 93.6443 [0.04], Avg: 47.8289 (0.020)
Step: 78090, Reward: 93.5557 [0.08], Avg: 48.0402 (0.020)
Step: 78157, Reward: 93.6261 [0.07], Avg: 48.2500 (0.020)
Step: 78224, Reward: 93.5822 [0.08], Avg: 48.4575 (0.020)
Step: 78291, Reward: 93.5710 [0.09], Avg: 48.6631 (0.020)
Step: 78360, Reward: 93.5982 [0.03], Avg: 48.8672 (0.020)
Step: 78429, Reward: 93.6186 [0.05], Avg: 49.0695 (0.020)
Step: 78495, Reward: 93.5756 [0.04], Avg: 49.2698 (0.020)
Step: 78562, Reward: 93.6341 [0.06], Avg: 49.4685 (0.020)
Step: 78629, Reward: 93.6348 [0.09], Avg: 49.6652 (0.020)
Step: 78696, Reward: 93.5938 [0.05], Avg: 49.8602 (0.020)
Step: 78764, Reward: 93.6121 [0.06], Avg: 50.0536 (0.020)
Step: 78832, Reward: 93.6535 [0.07], Avg: 50.2453 (0.020)
Step: 78899, Reward: 93.6411 [0.03], Avg: 50.4355 (0.020)
Step: 78968, Reward: 93.5432 [0.08], Avg: 50.6234 (0.020)
Step: 79035, Reward: 93.5720 [0.04], Avg: 50.8100 (0.020)
Step: 79102, Reward: 93.5637 [0.09], Avg: 50.9947 (0.020)
Step: 79171, Reward: 93.6458 [0.07], Avg: 51.1782 (0.020)
Step: 79238, Reward: 93.5649 [0.06], Avg: 51.3599 (0.020)
Step: 79305, Reward: 93.6188 [0.08], Avg: 51.5401 (0.020)
Step: 79372, Reward: 93.5943 [0.04], Avg: 51.7189 (0.020)
Step: 79439, Reward: 93.6018 [0.04], Avg: 51.8962 (0.020)
Step: 79506, Reward: 93.6659 [0.07], Avg: 52.0722 (0.020)
Step: 79574, Reward: 93.6122 [0.10], Avg: 52.2463 (0.020)
Step: 79644, Reward: 93.6296 [0.05], Avg: 52.4192 (0.020)
Step: 79712, Reward: 93.6434 [0.09], Avg: 52.5906 (0.020)
Step: 79781, Reward: 93.6620 [0.06], Avg: 52.7608 (0.020)
Step: 79848, Reward: 93.5998 [0.07], Avg: 52.9293 (0.020)
Step: 79916, Reward: 93.6426 [0.05], Avg: 53.0966 (0.020)
Step: 79983, Reward: 93.6580 [0.05], Avg: 53.2627 (0.020)
Step: 80051, Reward: 93.6160 [0.04], Avg: 53.4272 (0.020)
Step: 80118, Reward: 93.5270 [0.04], Avg: 53.5900 (0.020)
Step: 80186, Reward: 93.6208 [0.03], Avg: 53.7520 (0.020)
Step: 80252, Reward: 93.5988 [0.04], Avg: 53.9125 (0.020)
Step: 80319, Reward: 93.6018 [0.06], Avg: 54.0716 (0.020)
Step: 80388, Reward: 93.5817 [0.07], Avg: 54.2294 (0.020)
Step: 80456, Reward: 93.6866 [0.05], Avg: 54.3864 (0.020)
Step: 80523, Reward: 93.6542 [0.03], Avg: 54.5421 (0.020)
Step: 80589, Reward: 93.6287 [0.05], Avg: 54.6964 (0.020)
Step: 80657, Reward: 93.6963 [0.06], Avg: 54.8497 (0.020)
Step: 80724, Reward: 93.6017 [0.09], Avg: 55.0013 (0.020)
Step: 80791, Reward: 93.5013 [0.09], Avg: 55.1513 (0.020)
Step: 80860, Reward: 93.6260 [0.07], Avg: 55.3008 (0.020)
Step: 80929, Reward: 93.6408 [0.10], Avg: 55.4490 (0.020)
Step: 80997, Reward: 93.5786 [0.09], Avg: 55.5959 (0.020)
Step: 81064, Reward: 93.5979 [0.06], Avg: 55.7418 (0.020)
Step: 81132, Reward: 93.6714 [0.07], Avg: 55.8869 (0.020)
Step: 81199, Reward: 93.6025 [0.06], Avg: 56.0306 (0.020)
Step: 81266, Reward: 93.6461 [0.03], Avg: 56.1735 (0.020)
Step: 81332, Reward: 93.6568 [0.07], Avg: 56.3152 (0.020)
Step: 81400, Reward: 93.6040 [0.04], Avg: 56.4558 (0.020)
Step: 81466, Reward: 93.7248 [0.04], Avg: 56.5957 (0.020)
Step: 81535, Reward: 93.6767 [0.06], Avg: 56.7344 (0.020)
Step: 81601, Reward: 93.5333 [0.09], Avg: 56.8714 (0.020)
Step: 81669, Reward: 93.7035 [0.09], Avg: 57.0080 (0.020)
Step: 81736, Reward: 93.6261 [0.06], Avg: 57.1434 (0.020)
Step: 81803, Reward: 93.5386 [0.15], Avg: 57.2771 (0.020)
Step: 81870, Reward: 93.7092 [0.07], Avg: 57.4108 (0.020)
Step: 81937, Reward: 93.6037 [0.06], Avg: 57.5432 (0.020)
Step: 82005, Reward: 93.6617 [0.05], Avg: 57.6748 (0.020)
Step: 82071, Reward: 93.6719 [0.08], Avg: 57.8054 (0.020)
Step: 82139, Reward: 93.6706 [0.03], Avg: 57.9352 (0.020)
Step: 82206, Reward: 93.6271 [0.03], Avg: 58.0639 (0.020)
Step: 82274, Reward: 93.7294 [0.09], Avg: 58.1919 (0.020)
Step: 82340, Reward: 93.5359 [0.29], Avg: 58.3176 (0.020)
Step: 82410, Reward: 93.3945 [0.42], Avg: 58.4413 (0.020)
Step: 82481, Reward: 93.6759 [0.03], Avg: 58.5666 (0.020)
Step: 82554, Reward: 93.6059 [0.11], Avg: 58.6905 (0.020)
Step: 82622, Reward: 93.1674 [0.83], Avg: 58.8094 (0.020)
Step: 82690, Reward: 93.5536 [0.12], Avg: 58.9313 (0.020)
Step: 82759, Reward: 93.5873 [0.08], Avg: 59.0526 (0.020)
Step: 82832, Reward: 93.4507 [0.28], Avg: 59.1719 (0.020)
Step: 82898, Reward: 93.6482 [0.09], Avg: 59.2917 (0.020)
Step: 82964, Reward: 93.2744 [0.34], Avg: 59.4086 (0.020)
Step: 83033, Reward: 92.4972 [1.36], Avg: 59.5184 (0.020)
Step: 83101, Reward: 93.6137 [0.14], Avg: 59.6354 (0.020)
Step: 83168, Reward: 93.1380 [0.39], Avg: 59.7492 (0.020)
Step: 83235, Reward: 93.3739 [0.56], Avg: 59.8625 (0.020)
Step: 83305, Reward: 93.6048 [0.11], Avg: 59.9772 (0.020)
Step: 83372, Reward: 92.0910 [1.38], Avg: 60.0818 (0.020)
Step: 83442, Reward: 92.8409 [0.95], Avg: 60.1896 (0.020)
Step: 83508, Reward: 93.3721 [0.27], Avg: 60.3008 (0.020)
Step: 83578, Reward: 93.0655 [1.17], Avg: 60.4071 (0.020)
Step: 83646, Reward: 93.1634 [0.89], Avg: 60.5141 (0.020)
Step: 83720, Reward: 91.9214 [3.16], Avg: 60.6085 (0.020)
Step: 83787, Reward: 93.2895 [0.35], Avg: 60.7163 (0.020)
Step: 83853, Reward: 93.4789 [0.18], Avg: 60.8246 (0.020)
Step: 83946, Reward: 93.7014 [0.09], Avg: 60.9331 (0.020)
Step: 84051, Reward: 93.5777 [0.32], Avg: 61.0398 (0.020)
Step: 84118, Reward: 93.6659 [0.19], Avg: 61.1465 (0.020)
Step: 84185, Reward: 93.0113 [1.08], Avg: 61.2474 (0.020)
Step: 84255, Reward: 92.9928 [1.14], Avg: 61.3475 (0.020)
Step: 84330, Reward: 93.4917 [0.19], Avg: 61.4515 (0.020)
Step: 84399, Reward: 93.5129 [0.18], Avg: 61.5551 (0.020)
Step: 84465, Reward: 93.5970 [0.12], Avg: 61.6583 (0.020)
Step: 84534, Reward: 93.5496 [0.11], Avg: 61.7609 (0.020)
Step: 84602, Reward: 93.5514 [0.11], Avg: 61.8627 (0.020)
Step: 84672, Reward: 93.6680 [0.10], Avg: 61.9644 (0.020)
Step: 84738, Reward: 93.1846 [0.40], Avg: 62.0628 (0.020)
Step: 84809, Reward: 93.5244 [0.20], Avg: 62.1624 (0.020)
Step: 84875, Reward: 93.4136 [0.26], Avg: 62.2608 (0.020)
Step: 84943, Reward: 93.4516 [0.30], Avg: 62.3585 (0.020)
Step: 85010, Reward: 93.3481 [0.34], Avg: 62.4552 (0.020)
Step: 85078, Reward: 93.3269 [0.67], Avg: 62.5502 (0.020)
Step: 85145, Reward: 93.5039 [0.09], Avg: 62.6469 (0.020)
Step: 85214, Reward: 93.4593 [0.52], Avg: 62.7416 (0.020)
Step: 85281, Reward: 93.3340 [0.49], Avg: 62.8353 (0.020)
Step: 85347, Reward: 93.5483 [0.22], Avg: 62.9301 (0.020)
Step: 85413, Reward: 93.5160 [0.19], Avg: 63.0242 (0.020)
Step: 85478, Reward: 93.4169 [0.33], Avg: 63.1170 (0.020)
Step: 85545, Reward: 93.2876 [0.43], Avg: 63.2085 (0.020)
Step: 85626, Reward: 93.6932 [0.06], Avg: 63.3018 (0.020)
Step: 85691, Reward: 93.5097 [0.13], Avg: 63.3938 (0.020)
Step: 85759, Reward: 93.5240 [0.17], Avg: 63.4851 (0.020)
Step: 85828, Reward: 93.5639 [0.21], Avg: 63.5759 (0.020)
Step: 85906, Reward: 93.6337 [0.13], Avg: 63.6666 (0.020)
Step: 85971, Reward: 93.1772 [0.34], Avg: 63.7547 (0.020)
Step: 86037, Reward: 93.6164 [0.10], Avg: 63.8444 (0.020)
Step: 86131, Reward: 93.3076 [0.34], Avg: 63.9318 (0.020)
Step: 86197, Reward: 93.2895 [0.67], Avg: 64.0177 (0.020)
Step: 86263, Reward: 93.4673 [0.25], Avg: 64.1049 (0.020)
Step: 86329, Reward: 93.1735 [0.33], Avg: 64.1904 (0.020)
Step: 86395, Reward: 93.0464 [0.78], Avg: 64.2737 (0.020)
Step: 86463, Reward: 93.4320 [0.16], Avg: 64.3595 (0.020)
Step: 86531, Reward: 93.5532 [0.20], Avg: 64.4450 (0.020)
Step: 86601, Reward: 93.5039 [0.13], Avg: 64.5301 (0.020)
Step: 86669, Reward: 93.5490 [0.25], Avg: 64.6145 (0.020)
Step: 86736, Reward: 93.6019 [0.21], Avg: 64.6986 (0.020)
Step: 86803, Reward: 93.6442 [0.12], Avg: 64.7827 (0.020)
Step: 86871, Reward: 93.6031 [0.09], Avg: 64.8662 (0.020)
Step: 86942, Reward: 93.3696 [0.29], Avg: 64.9480 (0.020)
Step: 87008, Reward: 93.5654 [0.13], Avg: 65.0303 (0.020)
Step: 87075, Reward: 93.3168 [0.31], Avg: 65.1109 (0.020)
Step: 87143, Reward: 93.6169 [0.05], Avg: 65.1927 (0.020)
Step: 87210, Reward: 93.6269 [0.06], Avg: 65.2740 (0.020)
Step: 87281, Reward: 93.5774 [0.26], Avg: 65.3542 (0.020)
Step: 87347, Reward: 93.6423 [0.12], Avg: 65.4344 (0.020)
Step: 87414, Reward: 93.5500 [0.10], Avg: 65.5140 (0.020)
Step: 87482, Reward: 93.5245 [0.09], Avg: 65.5931 (0.020)
Step: 87551, Reward: 93.3044 [0.35], Avg: 65.6704 (0.020)
Step: 87618, Reward: 93.5900 [0.13], Avg: 65.7487 (0.020)
Step: 87687, Reward: 93.7097 [0.11], Avg: 65.8269 (0.020)
Step: 87757, Reward: 93.6645 [0.12], Avg: 65.9045 (0.020)
Step: 87829, Reward: 93.4688 [0.18], Avg: 65.9810 (0.020)
Step: 87899, Reward: 93.5125 [0.20], Avg: 66.0571 (0.020)
Step: 87969, Reward: 93.7358 [0.10], Avg: 66.1337 (0.020)
Step: 88036, Reward: 93.5487 [0.06], Avg: 66.2095 (0.020)
Step: 88106, Reward: 93.6445 [0.10], Avg: 66.2850 (0.020)
Step: 88171, Reward: 93.6921 [0.04], Avg: 66.3604 (0.020)
Step: 88237, Reward: 93.5597 [0.17], Avg: 66.4347 (0.020)
Step: 88303, Reward: 93.4552 [0.16], Avg: 66.5082 (0.020)
Step: 88372, Reward: 93.6442 [0.11], Avg: 66.5821 (0.020)
Step: 88441, Reward: 93.6169 [0.14], Avg: 66.6554 (0.020)
Step: 88508, Reward: 93.5896 [0.10], Avg: 66.7283 (0.020)
Step: 88574, Reward: 93.6776 [0.11], Avg: 66.8010 (0.020)
Step: 88640, Reward: 93.6714 [0.08], Avg: 66.8734 (0.020)
Step: 88706, Reward: 93.6945 [0.16], Avg: 66.9453 (0.020)
Step: 88773, Reward: 93.6138 [0.19], Avg: 67.0165 (0.020)
Step: 88841, Reward: 93.6864 [0.10], Avg: 67.0877 (0.020)
Step: 88907, Reward: 93.6337 [0.08], Avg: 67.1585 (0.020)
Step: 88976, Reward: 93.6676 [0.08], Avg: 67.2290 (0.020)
Step: 89043, Reward: 93.6386 [0.06], Avg: 67.2990 (0.020)
Step: 89110, Reward: 93.6200 [0.20], Avg: 67.3683 (0.020)
Step: 89177, Reward: 93.7497 [0.09], Avg: 67.4379 (0.020)
Step: 89243, Reward: 93.6488 [0.14], Avg: 67.5067 (0.020)
Step: 89310, Reward: 93.4403 [0.15], Avg: 67.5745 (0.020)
Step: 89376, Reward: 93.6305 [0.13], Avg: 67.6425 (0.020)
Step: 89442, Reward: 93.5253 [0.12], Avg: 67.7100 (0.020)
Step: 89508, Reward: 93.6866 [0.02], Avg: 67.7778 (0.020)
Step: 89579, Reward: 93.6011 [0.10], Avg: 67.8447 (0.020)
Step: 89646, Reward: 93.6593 [0.12], Avg: 67.9115 (0.020)
Step: 89711, Reward: 93.7408 [0.04], Avg: 67.9783 (0.020)
Step: 89779, Reward: 93.6465 [0.06], Avg: 68.0445 (0.020)
Step: 89846, Reward: 93.7095 [0.14], Avg: 68.1103 (0.020)
Step: 89912, Reward: 93.6733 [0.07], Avg: 68.1758 (0.020)
Step: 89981, Reward: 93.5785 [0.14], Avg: 68.2406 (0.020)
Step: 90047, Reward: 93.6382 [0.19], Avg: 68.3051 (0.020)
Step: 90114, Reward: 93.5793 [0.06], Avg: 68.3694 (0.020)
Step: 90182, Reward: 93.6005 [0.08], Avg: 68.4334 (0.020)
Step: 90251, Reward: 93.5095 [0.20], Avg: 68.4965 (0.020)
Step: 90317, Reward: 93.6345 [0.11], Avg: 68.5599 (0.020)
Step: 90386, Reward: 93.5430 [0.11], Avg: 68.6227 (0.020)
Step: 90455, Reward: 93.6023 [0.10], Avg: 68.6853 (0.020)
Step: 90524, Reward: 93.5556 [0.13], Avg: 68.7475 (0.020)
Step: 90590, Reward: 93.6429 [0.18], Avg: 68.8094 (0.020)
Step: 90656, Reward: 93.6196 [0.12], Avg: 68.8712 (0.020)
Step: 90725, Reward: 93.6429 [0.06], Avg: 68.9328 (0.020)
Step: 90793, Reward: 93.4951 [0.15], Avg: 68.9935 (0.020)
Step: 90859, Reward: 93.6026 [0.14], Avg: 69.0543 (0.020)
Step: 90927, Reward: 93.5786 [0.03], Avg: 69.1149 (0.020)
Step: 90993, Reward: 93.5904 [0.10], Avg: 69.1751 (0.020)
Step: 91059, Reward: 93.6336 [0.14], Avg: 69.2349 (0.020)
Step: 91126, Reward: 93.5327 [0.21], Avg: 69.2941 (0.020)
Step: 91192, Reward: 93.5662 [0.14], Avg: 69.3533 (0.020)
Step: 91259, Reward: 93.6780 [0.09], Avg: 69.4126 (0.020)
Step: 91328, Reward: 93.5711 [0.09], Avg: 69.4713 (0.020)
Step: 91396, Reward: 93.6368 [0.09], Avg: 69.5298 (0.020)
Step: 91462, Reward: 93.6565 [0.07], Avg: 69.5882 (0.020)
Step: 91529, Reward: 93.6009 [0.11], Avg: 69.6461 (0.020)
Step: 91595, Reward: 93.7014 [0.08], Avg: 69.7040 (0.020)
Step: 91660, Reward: 93.5685 [0.13], Avg: 69.7612 (0.020)
Step: 91728, Reward: 93.6550 [0.12], Avg: 69.8184 (0.020)
Step: 91794, Reward: 93.7018 [0.10], Avg: 69.8754 (0.020)
Step: 91860, Reward: 93.6556 [0.05], Avg: 69.9321 (0.020)
Step: 91926, Reward: 93.6982 [0.05], Avg: 69.9888 (0.020)
Step: 91992, Reward: 93.5860 [0.11], Avg: 70.0447 (0.020)
Step: 92060, Reward: 93.6280 [0.14], Avg: 70.1004 (0.020)
Step: 92126, Reward: 93.6160 [0.06], Avg: 70.1560 (0.020)
Step: 92193, Reward: 93.6437 [0.15], Avg: 70.2111 (0.020)
Step: 92259, Reward: 93.5100 [0.09], Avg: 70.2659 (0.020)
Step: 92328, Reward: 93.6825 [0.09], Avg: 70.3207 (0.020)
Step: 92397, Reward: 93.6252 [0.08], Avg: 70.3753 (0.020)
Step: 92463, Reward: 93.5338 [0.14], Avg: 70.4292 (0.020)
Step: 92532, Reward: 93.5505 [0.13], Avg: 70.4829 (0.020)
Step: 92599, Reward: 93.4999 [0.11], Avg: 70.5363 (0.020)
Step: 92665, Reward: 93.5747 [0.15], Avg: 70.5895 (0.020)
Step: 92733, Reward: 93.6494 [0.12], Avg: 70.6427 (0.020)
Step: 92799, Reward: 93.5034 [0.10], Avg: 70.6954 (0.020)
Step: 92868, Reward: 93.7009 [0.06], Avg: 70.7484 (0.020)
Step: 92939, Reward: 93.6483 [0.13], Avg: 70.8009 (0.020)
Step: 93005, Reward: 93.5482 [0.14], Avg: 70.8529 (0.020)
Step: 93074, Reward: 93.5639 [0.13], Avg: 70.9047 (0.020)
Step: 93143, Reward: 93.7069 [0.07], Avg: 70.9567 (0.020)
Step: 93209, Reward: 93.5305 [0.12], Avg: 71.0079 (0.020)
Step: 93276, Reward: 93.5896 [0.10], Avg: 71.0591 (0.020)
Step: 93346, Reward: 93.6399 [0.05], Avg: 71.1103 (0.020)
Step: 93412, Reward: 93.6430 [0.09], Avg: 71.1612 (0.020)
Step: 93479, Reward: 93.6025 [0.08], Avg: 71.2118 (0.020)
Step: 93548, Reward: 93.6927 [0.10], Avg: 71.2623 (0.020)
Step: 93615, Reward: 93.5950 [0.07], Avg: 71.3125 (0.020)
Step: 93681, Reward: 93.5592 [0.11], Avg: 71.3622 (0.020)
Step: 93749, Reward: 93.6259 [0.08], Avg: 71.4120 (0.020)
Step: 93815, Reward: 93.6086 [0.07], Avg: 71.4615 (0.020)
Step: 93883, Reward: 93.5326 [0.21], Avg: 71.5103 (0.020)
Step: 93951, Reward: 93.6902 [0.09], Avg: 71.5595 (0.020)
Step: 94017, Reward: 93.6001 [0.14], Avg: 71.6081 (0.020)
Step: 94084, Reward: 93.5235 [0.21], Avg: 71.6562 (0.020)
Step: 94150, Reward: 93.5259 [0.16], Avg: 71.7043 (0.020)
Step: 94220, Reward: 93.5497 [0.22], Avg: 71.7520 (0.020)
Step: 94290, Reward: 93.5824 [0.15], Avg: 71.7998 (0.020)
Step: 94356, Reward: 93.5430 [0.10], Avg: 71.8473 (0.020)
Step: 94424, Reward: 93.5742 [0.13], Avg: 71.8947 (0.020)
Step: 94493, Reward: 93.4640 [0.11], Avg: 71.9417 (0.020)
Step: 94562, Reward: 93.6041 [0.07], Avg: 71.9888 (0.020)
Step: 94629, Reward: 93.5846 [0.10], Avg: 72.0356 (0.020)
Step: 94695, Reward: 93.5787 [0.13], Avg: 72.0822 (0.020)
Step: 94761, Reward: 93.4754 [0.15], Avg: 72.1283 (0.020)
Step: 94827, Reward: 93.6743 [0.11], Avg: 72.1747 (0.020)
Step: 94894, Reward: 93.5590 [0.10], Avg: 72.2206 (0.020)
Step: 94960, Reward: 93.6313 [0.15], Avg: 72.2665 (0.020)
Step: 95026, Reward: 93.6050 [0.06], Avg: 72.3122 (0.020)
Step: 95095, Reward: 93.6235 [0.12], Avg: 72.3577 (0.020)
Step: 95165, Reward: 93.6285 [0.14], Avg: 72.4029 (0.020)
Step: 95235, Reward: 93.4791 [0.21], Avg: 72.4475 (0.020)
Step: 95303, Reward: 93.5642 [0.20], Avg: 72.4921 (0.020)
Step: 95370, Reward: 93.6143 [0.14], Avg: 72.5368 (0.020)
Step: 95441, Reward: 93.6876 [0.13], Avg: 72.5814 (0.020)
Step: 95507, Reward: 93.4527 [0.19], Avg: 72.6252 (0.020)
Step: 95576, Reward: 93.6283 [0.03], Avg: 72.6696 (0.020)
Step: 95643, Reward: 93.6487 [0.06], Avg: 72.7137 (0.020)
Step: 95710, Reward: 93.5361 [0.12], Avg: 72.7573 (0.020)
Step: 95780, Reward: 93.6301 [0.11], Avg: 72.8009 (0.020)
Step: 95855, Reward: 93.6772 [0.06], Avg: 72.8445 (0.020)
Step: 95921, Reward: 93.1419 [0.28], Avg: 72.8864 (0.020)
Step: 95987, Reward: 93.5279 [0.17], Avg: 72.9292 (0.020)
Step: 96053, Reward: 93.6404 [0.09], Avg: 72.9721 (0.020)
Step: 96119, Reward: 93.5455 [0.13], Avg: 73.0146 (0.020)
Step: 96185, Reward: 93.6700 [0.09], Avg: 73.0573 (0.020)
Step: 96252, Reward: 93.3946 [0.18], Avg: 73.0990 (0.020)
Step: 96320, Reward: 93.5776 [0.12], Avg: 73.1411 (0.020)
Step: 96387, Reward: 93.6378 [0.15], Avg: 73.1830 (0.020)
Step: 96457, Reward: 93.5234 [0.17], Avg: 73.2245 (0.020)
Step: 96523, Reward: 93.7016 [0.07], Avg: 73.2664 (0.020)
Step: 96589, Reward: 93.7280 [0.13], Avg: 73.3081 (0.020)
Step: 96659, Reward: 93.4826 [0.13], Avg: 73.3491 (0.020)
Step: 96725, Reward: 93.6685 [0.09], Avg: 73.3904 (0.020)
Step: 96794, Reward: 93.6543 [0.12], Avg: 73.4314 (0.020)
Step: 96861, Reward: 93.6033 [0.16], Avg: 73.4721 (0.020)
Step: 96934, Reward: 93.4949 [0.14], Avg: 73.5124 (0.020)
Step: 97004, Reward: 93.6320 [0.13], Avg: 73.5529 (0.020)
Step: 97072, Reward: 93.7132 [0.06], Avg: 73.5935 (0.020)
Step: 97141, Reward: 93.5806 [0.08], Avg: 73.6336 (0.020)
Step: 97207, Reward: 93.5183 [0.21], Avg: 73.6732 (0.020)
Step: 97274, Reward: 93.5749 [0.14], Avg: 73.7129 (0.020)
Step: 97342, Reward: 93.6512 [0.15], Avg: 73.7525 (0.020)
Step: 97410, Reward: 93.5222 [0.27], Avg: 73.7915 (0.020)
Step: 97480, Reward: 93.6250 [0.11], Avg: 73.8309 (0.020)
Step: 97547, Reward: 93.6216 [0.09], Avg: 73.8701 (0.020)
Step: 97613, Reward: 93.6928 [0.09], Avg: 73.9094 (0.020)
Step: 97679, Reward: 93.6852 [0.12], Avg: 73.9484 (0.020)
Step: 97748, Reward: 93.4700 [0.15], Avg: 73.9867 (0.020)
Step: 97814, Reward: 93.5088 [0.18], Avg: 74.0250 (0.020)
Step: 97886, Reward: 93.6010 [0.11], Avg: 74.0634 (0.020)
Step: 97953, Reward: 93.5727 [0.13], Avg: 74.1015 (0.020)
Step: 98021, Reward: 93.3310 [0.16], Avg: 74.1390 (0.020)
Step: 98090, Reward: 93.6281 [0.13], Avg: 74.1769 (0.020)
Step: 98158, Reward: 93.5447 [0.08], Avg: 74.2147 (0.020)
Step: 98224, Reward: 93.6085 [0.11], Avg: 74.2523 (0.020)
Step: 98293, Reward: 93.6025 [0.16], Avg: 74.2898 (0.020)
Step: 98360, Reward: 93.5809 [0.06], Avg: 74.3272 (0.020)
Step: 98426, Reward: 93.6330 [0.05], Avg: 74.3646 (0.020)
Step: 98496, Reward: 93.6434 [0.14], Avg: 74.4017 (0.020)
Step: 98563, Reward: 93.5903 [0.19], Avg: 74.4384 (0.020)
Step: 98629, Reward: 93.4984 [0.10], Avg: 74.4750 (0.020)
Step: 98698, Reward: 93.5258 [0.11], Avg: 74.5115 (0.020)
Step: 98766, Reward: 93.6243 [0.14], Avg: 74.5480 (0.020)
Step: 98834, Reward: 93.5310 [0.14], Avg: 74.5842 (0.020)
Step: 98904, Reward: 93.5169 [0.16], Avg: 74.6201 (0.020)
Step: 98974, Reward: 93.6289 [0.12], Avg: 74.6562 (0.020)
Step: 99043, Reward: 93.5252 [0.16], Avg: 74.6919 (0.020)
Step: 99112, Reward: 93.5233 [0.11], Avg: 74.7276 (0.020)
Step: 99179, Reward: 93.5991 [0.09], Avg: 74.7633 (0.020)
Step: 99250, Reward: 93.6229 [0.13], Avg: 74.7989 (0.020)
Step: 99320, Reward: 93.5777 [0.10], Avg: 74.8342 (0.020)
Step: 99388, Reward: 93.6609 [0.10], Avg: 74.8697 (0.020)
Step: 99456, Reward: 93.7026 [0.09], Avg: 74.9050 (0.020)
Step: 99525, Reward: 93.5883 [0.20], Avg: 74.9398 (0.020)
Step: 99595, Reward: 93.6934 [0.11], Avg: 74.9749 (0.020)
Step: 99663, Reward: 93.6559 [0.06], Avg: 75.0098 (0.020)
Step: 99735, Reward: 93.5559 [0.14], Avg: 75.0443 (0.020)
Step: 99805, Reward: 93.5234 [0.15], Avg: 75.0785 (0.020)
Step: 99874, Reward: 93.5493 [0.21], Avg: 75.1126 (0.020)
Step: 99941, Reward: 93.5742 [0.13], Avg: 75.1468 (0.020)
