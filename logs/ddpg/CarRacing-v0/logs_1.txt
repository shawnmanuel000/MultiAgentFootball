Model: <class 'models.ddpg.DDPGAgent'>, Dir: CarRacing-v0
num_envs: 16,

import os
import math
import torch
import random
import numpy as np
from models.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS

EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.98             	# The rate at which eps decays from EPS_MAX to EPS_MIN
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

class DDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		state = self.layer3(state).relu() 
		action_mu = self.action_mu(state)
		action_sig = self.action_sig(state).exp()
		epsilon = torch.randn_like(action_sig)
		action = action_mu + epsilon.mul(action_sig) if sample else action_mu
		return action.tanh()
	
class DDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.net_state = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.net_action = torch.nn.Linear(*action_size, INPUT_LAYER)
		self.net_layer1 = torch.nn.Linear(2*INPUT_LAYER, CRITIC_HIDDEN)
		self.net_layer2 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = self.net_state(state).relu()
		net_action = self.net_action(action).relu()
		net_layer = torch.cat([state, net_action], dim=-1)
		net_layer = self.net_layer1(net_layer).relu()
		net_layer = self.net_layer2(net_layer).relu()
		q_value = self.q_value(net_layer)
		return q_value

class DDPGNetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None): 
		super().__init__(state_size, action_size, DDPGActor, DDPGCritic, lr=lr, gpu=gpu, load=load)

	def get_action(self, state, use_target=False, numpy=True, sample=True):
		with torch.no_grad():
			actor = self.actor_local if not use_target else self.actor_target
			return actor(state, sample).cpu().numpy() if numpy else actor(state, sample)

	def get_q_value(self, state, action, use_target=False, numpy=True):
		with torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			return critic(state, action).cpu().numpy() if numpy else critic(state, action)
	
	def optimize(self, states, actions, q_targets, importances=1):
		q_values = self.critic_local(states, actions)
		critic_error = q_values - q_targets.detach()
		critic_loss = importances.to(self.device) * critic_error.pow(2)
		self.step(self.critic_optimizer, critic_loss.mean())

		q_actions = self.critic_local(states, self.actor_local(states))
		actor_loss = -(q_actions - q_values.detach())
		self.step(self.actor_optimizer, actor_loss.mean())
		
		self.soft_copy(self.actor_local, self.actor_target)
		self.soft_copy(self.critic_local, self.critic_target)
		return critic_error.cpu().detach().numpy().squeeze(-1)
	
	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ddpg", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ddpg", dirname, name)

class DDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, DDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True, e_greedy=False):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if e_greedy and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), sample=sample)
		action = action_greedy if e_greedy else np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if done[0] or len(self.buffer) >= self.update_freq:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			next_state = self.to_tensor(next_state)
			next_action = self.network.get_action(next_state, use_target=True, numpy=False)
			values = self.network.get_q_value(states, actions, use_target=True, numpy=False)
			next_value = self.network.get_q_value(next_state, next_action, use_target=True, numpy=False)
			targets, _ = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values)
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states, actions, targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=False)	
		if len(self.replay_buffer) > 0:
			(states, actions, targets), indices, importances = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)
			errors = self.network.optimize(states, actions, targets, importances**(1-self.eps))
			self.replay_buffer.update_priorities(indices, errors)
			if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddqn", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "LunarLander-v2"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[5]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class PixelAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	logger = Logger(model, env_name, num_envs=num_envs)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = PixelAgent(envs.state_size, envs.action_size, num_envs, model)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0]:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 999, Reward: -63.1058 [16.24], Avg: -79.3501 (0.980)
Step: 1999, Reward: -58.8509 [21.36], Avg: -79.7799 (0.960)
Step: 2999, Reward: -69.6297 [7.54], Avg: -78.9102 (0.941)
Step: 3999, Reward: -53.0783 [18.95], Avg: -77.1903 (0.922)
Step: 4999, Reward: -56.7878 [22.24], Avg: -77.5584 (0.904)
Step: 5999, Reward: -60.8721 [23.70], Avg: -78.7274 (0.886)
Step: 6999, Reward: -51.0846 [10.97], Avg: -76.3461 (0.868)
Step: 7999, Reward: -47.9898 [7.51], Avg: -73.7409 (0.851)
Step: 8999, Reward: -51.2338 [40.51], Avg: -75.7412 (0.834)
Step: 9999, Reward: -47.9041 [18.27], Avg: -74.7849 (0.817)
Step: 10999, Reward: -63.8825 [15.16], Avg: -75.1719 (0.801)
Step: 11999, Reward: -49.3306 [15.41], Avg: -74.3025 (0.785)
Step: 12999, Reward: -41.3569 [31.35], Avg: -74.1800 (0.769)
Step: 13999, Reward: -45.1150 [38.05], Avg: -74.8221 (0.754)
Step: 14999, Reward: -59.3044 [18.10], Avg: -74.9943 (0.739)
Step: 15999, Reward: -72.0983 [50.66], Avg: -77.9793 (0.724)
Step: 16999, Reward: -51.5918 [15.32], Avg: -77.3282 (0.709)
Step: 17999, Reward: -70.1324 [40.95], Avg: -79.2034 (0.695)
Step: 18999, Reward: -49.9299 [35.39], Avg: -79.5253 (0.681)
Step: 19999, Reward: -47.2448 [24.56], Avg: -79.1394 (0.668)
Step: 20999, Reward: -22.5633 [22.71], Avg: -77.5270 (0.654)
Step: 21999, Reward: -30.7569 [22.66], Avg: -76.4311 (0.641)
Step: 22999, Reward: -57.9385 [25.21], Avg: -76.7232 (0.628)
Step: 23999, Reward: -50.1755 [22.84], Avg: -76.5686 (0.616)
Step: 24999, Reward: -46.6061 [19.87], Avg: -76.1647 (0.603)
Step: 25999, Reward: -46.1445 [25.61], Avg: -75.9952 (0.591)
Step: 26999, Reward: -63.7867 [11.13], Avg: -75.9551 (0.580)
Step: 27999, Reward: -59.5404 [21.03], Avg: -76.1200 (0.568)
Step: 28999, Reward: -79.9106 [32.10], Avg: -77.3577 (0.557)
Step: 29999, Reward: -70.3997 [13.98], Avg: -77.5917 (0.545)
Step: 30999, Reward: -64.6463 [47.64], Avg: -78.7109 (0.535)
Step: 31999, Reward: -67.4464 [10.58], Avg: -78.6895 (0.524)
Step: 32999, Reward: -73.6918 [3.35], Avg: -78.6395 (0.513)
Step: 33999, Reward: -86.0360 [47.02], Avg: -80.2400 (0.503)
Step: 34999, Reward: -63.8795 [17.62], Avg: -80.2761 (0.493)
Step: 35999, Reward: -69.3388 [11.78], Avg: -80.2994 (0.483)
Step: 36999, Reward: -61.7260 [8.06], Avg: -80.0152 (0.474)
Step: 37999, Reward: -69.8881 [10.90], Avg: -80.0354 (0.464)
Step: 38999, Reward: -58.6649 [14.46], Avg: -79.8583 (0.455)
Step: 39999, Reward: -68.3106 [33.86], Avg: -80.4161 (0.446)
Step: 40999, Reward: -54.2636 [6.85], Avg: -79.9452 (0.437)
Step: 41999, Reward: -80.6677 [35.98], Avg: -80.8191 (0.428)
Step: 42999, Reward: -37.7659 [26.45], Avg: -80.4331 (0.419)
Step: 43999, Reward: -37.7693 [22.17], Avg: -79.9674 (0.411)
Step: 44999, Reward: -41.6535 [14.80], Avg: -79.4449 (0.403)
Step: 45999, Reward: -69.0977 [14.22], Avg: -79.5291 (0.395)
Step: 46999, Reward: -68.3075 [10.76], Avg: -79.5193 (0.387)
Step: 47999, Reward: -61.6352 [21.49], Avg: -79.5944 (0.379)
Step: 48999, Reward: -66.0450 [5.55], Avg: -79.4311 (0.372)
Step: 49999, Reward: -65.9029 [14.06], Avg: -79.4418 (0.364)
Step: 50999, Reward: -55.6085 [32.73], Avg: -79.6163 (0.357)
Step: 51999, Reward: -60.6705 [17.84], Avg: -79.5950 (0.350)
Step: 52999, Reward: -60.0977 [11.72], Avg: -79.4483 (0.343)
Step: 53999, Reward: -53.7799 [13.51], Avg: -79.2232 (0.336)
Step: 54999, Reward: -70.3053 [29.32], Avg: -79.5942 (0.329)
Step: 55448, Reward: -77.5520 [19.49], Avg: -79.9058 (0.323)
Step: 56448, Reward: -66.6056 [29.13], Avg: -80.1835 (0.316)
Step: 57448, Reward: -39.1282 [19.84], Avg: -79.8177 (0.310)
Step: 58448, Reward: -82.0637 [28.27], Avg: -80.3349 (0.304)
Step: 59448, Reward: -82.1446 [47.07], Avg: -81.1495 (0.298)
Step: 60448, Reward: -61.3374 [32.10], Avg: -81.3509 (0.292)
Step: 61448, Reward: -72.8746 [29.81], Avg: -81.6950 (0.286)
Step: 62448, Reward: -37.7639 [30.90], Avg: -81.4882 (0.280)
Step: 63448, Reward: -46.4614 [24.23], Avg: -81.3195 (0.274)
Step: 64448, Reward: -50.6360 [39.64], Avg: -81.4572 (0.269)
Step: 65448, Reward: -43.6594 [23.70], Avg: -81.2436 (0.264)
Step: 66448, Reward: -65.4477 [8.91], Avg: -81.1409 (0.258)
Step: 67448, Reward: -43.8865 [18.10], Avg: -80.8591 (0.253)
Step: 68448, Reward: -36.6813 [10.48], Avg: -80.3708 (0.248)
Step: 69448, Reward: -37.4211 [9.13], Avg: -79.8876 (0.243)
Step: 70448, Reward: -44.5254 [9.46], Avg: -79.5228 (0.238)
Step: 71448, Reward: -38.5722 [23.32], Avg: -79.2780 (0.233)
Step: 72448, Reward: -50.9271 [7.82], Avg: -78.9967 (0.229)
Step: 73448, Reward: -39.9662 [8.77], Avg: -78.5878 (0.224)
Step: 74448, Reward: -59.6053 [9.51], Avg: -78.4615 (0.220)
Step: 75448, Reward: -38.8902 [9.91], Avg: -78.0712 (0.215)
Step: 76448, Reward: -40.5633 [8.25], Avg: -77.6913 (0.211)
Step: 77448, Reward: -55.8463 [11.29], Avg: -77.5559 (0.207)
Step: 78448, Reward: -50.6680 [5.83], Avg: -77.2893 (0.203)
Step: 79448, Reward: -48.9323 [13.81], Avg: -77.1074 (0.199)
Step: 80448, Reward: -45.3284 [10.33], Avg: -76.8426 (0.195)
Step: 81448, Reward: -48.2569 [9.50], Avg: -76.6099 (0.191)
Step: 82448, Reward: 12.1391 [34.86], Avg: -75.9606 (0.187)
Step: 83448, Reward: -54.3497 [15.31], Avg: -75.8856 (0.183)
Step: 84448, Reward: -63.4819 [9.52], Avg: -75.8517 (0.180)
Step: 85448, Reward: -50.0954 [56.82], Avg: -76.2129 (0.176)
Step: 86448, Reward: -23.2482 [20.13], Avg: -75.8355 (0.172)
Step: 87016, Reward: -31.5607 [2.59], Avg: -75.3618 (0.169)
Step: 88016, Reward: 151.1152 [168.59], Avg: -74.7115 (0.166)
Step: 89016, Reward: 426.7314 [154.53], Avg: -70.8569 (0.162)
Step: 90016, Reward: 58.1304 [76.19], Avg: -70.2767 (0.159)
Step: 91016, Reward: 417.6345 [242.25], Avg: -67.6065 (0.156)
Step: 92016, Reward: 511.1921 [308.88], Avg: -64.7041 (0.153)
Step: 93016, Reward: 412.7966 [261.27], Avg: -62.4038 (0.150)
Step: 94016, Reward: 183.2710 [111.31], Avg: -60.9894 (0.147)
Step: 95016, Reward: 304.9392 [263.92], Avg: -59.9268 (0.144)
Step: 96016, Reward: 455.4439 [299.12], Avg: -57.6974 (0.141)
Step: 97016, Reward: 211.4221 [188.35], Avg: -56.8733 (0.138)
Step: 97856, Reward: 460.0997 [226.71], Avg: -53.9413 (0.135)
Step: 98856, Reward: 434.9423 [206.20], Avg: -51.1145 (0.133)
Step: 99856, Reward: 554.3191 [171.30], Avg: -46.8161 (0.130)
Step: 100856, Reward: 496.1199 [246.50], Avg: -43.9099 (0.127)
Step: 101856, Reward: 316.2307 [220.28], Avg: -42.5520 (0.125)
Step: 102856, Reward: 274.0591 [138.91], Avg: -40.8433 (0.122)
Step: 103066, Reward: 279.1542 [77.62], Avg: -38.5349 (0.120)
Step: 104066, Reward: 303.7367 [93.53], Avg: -36.1883 (0.117)
Step: 105066, Reward: 196.8637 [172.86], Avg: -35.6258 (0.115)
Step: 106066, Reward: 214.7890 [176.20], Avg: -34.9386 (0.113)
Step: 107066, Reward: 472.8329 [210.56], Avg: -32.2119 (0.111)
Step: 108066, Reward: 447.3360 [145.75], Avg: -29.1774 (0.108)
Step: 109066, Reward: 463.7424 [209.64], Avg: -26.6253 (0.106)
Step: 110066, Reward: 525.9889 [195.04], Avg: -23.4327 (0.104)
Step: 111066, Reward: 670.6389 [192.09], Avg: -18.9904 (0.102)
Step: 112066, Reward: 764.7306 [54.19], Avg: -12.5910 (0.100)
Step: 113066, Reward: 599.0049 [183.07], Avg: -8.8646 (0.098)
Step: 114066, Reward: 517.8322 [299.06], Avg: -6.9022 (0.096)
Step: 115066, Reward: 683.4502 [97.28], Avg: -1.8333 (0.094)
Step: 116066, Reward: 626.3512 [152.31], Avg: 2.1995 (0.092)
Step: 117066, Reward: 642.5727 [172.40], Avg: 6.1321 (0.090)
Step: 118066, Reward: 472.6132 [234.54], Avg: 8.0649 (0.089)
Step: 119066, Reward: 528.6227 [151.83], Avg: 11.1123 (0.087)
Step: 120066, Reward: 398.5692 [223.53], Avg: 12.4559 (0.085)
Step: 121066, Reward: 472.0563 [159.49], Avg: 14.8958 (0.083)
Step: 122066, Reward: 491.7908 [174.67], Avg: 17.3332 (0.082)
Step: 123066, Reward: 443.2206 [163.03], Avg: 19.4361 (0.080)
Step: 124066, Reward: 402.7882 [189.84], Avg: 20.9719 (0.078)
Step: 125066, Reward: 511.1778 [242.52], Avg: 22.9222 (0.077)
Step: 126066, Reward: 755.4839 [152.02], Avg: 27.4577 (0.075)
Step: 127066, Reward: 544.6804 [155.49], Avg: 30.2618 (0.074)
Step: 128066, Reward: 807.9758 [75.35], Avg: 35.6646 (0.072)
Step: 129066, Reward: 226.3088 [79.02], Avg: 36.5167 (0.071)
Step: 130066, Reward: 754.9812 [192.80], Avg: 40.4990 (0.069)
Step: 131066, Reward: 493.4978 [164.36], Avg: 42.6692 (0.068)
Step: 132066, Reward: 750.5344 [116.67], Avg: 47.0811 (0.067)
Step: 133066, Reward: 735.7019 [234.60], Avg: 50.4442 (0.065)
Step: 134066, Reward: 778.3985 [105.43], Avg: 55.0216 (0.064)
Step: 135066, Reward: 844.5408 [22.08], Avg: 60.6233 (0.063)
Step: 136066, Reward: 307.8452 [196.27], Avg: 60.9926 (0.062)
Step: 137066, Reward: 521.7554 [200.16], Avg: 62.8674 (0.060)
Step: 138066, Reward: 475.1262 [168.79], Avg: 64.6065 (0.059)
Step: 139066, Reward: 755.8947 [109.11], Avg: 68.7354 (0.058)
Step: 140066, Reward: 796.1678 [82.35], Avg: 73.2783 (0.057)
Step: 141066, Reward: 701.4178 [194.21], Avg: 76.3127 (0.056)
Step: 142066, Reward: 715.0678 [182.76], Avg: 79.4794 (0.055)
Step: 143066, Reward: 652.7947 [194.02], Avg: 82.0952 (0.053)
Step: 144066, Reward: 692.5371 [182.59], Avg: 85.0257 (0.052)
Step: 145066, Reward: 579.9586 [240.31], Avg: 86.7578 (0.051)
Step: 146066, Reward: 510.3043 [153.62], Avg: 88.5816 (0.050)
Step: 147066, Reward: 458.0811 [108.93], Avg: 90.3304 (0.049)
Step: 148066, Reward: 683.2295 [194.77], Avg: 92.9846 (0.048)
Step: 149066, Reward: 881.9229 [26.79], Avg: 98.0319 (0.047)
Step: 150066, Reward: 793.6189 [26.42], Avg: 102.4344 (0.046)
Step: 151066, Reward: 855.5543 [10.76], Avg: 107.2864 (0.045)
Step: 152066, Reward: 855.4050 [8.74], Avg: 112.0876 (0.045)
Step: 153066, Reward: 871.8819 [32.27], Avg: 116.7813 (0.044)
Step: 154066, Reward: 747.0322 [194.36], Avg: 119.5754 (0.043)
Step: 155066, Reward: 861.9198 [39.01], Avg: 124.0553 (0.042)
Step: 156066, Reward: 788.1794 [145.37], Avg: 127.3386 (0.041)
Step: 157066, Reward: 868.7945 [28.86], Avg: 131.8203 (0.040)
Step: 157897, Reward: 876.8013 [22.08], Avg: 136.3385 (0.039)
Step: 158897, Reward: 861.0733 [41.67], Avg: 140.5811 (0.039)
Step: 159897, Reward: 745.6907 [181.19], Avg: 143.1979 (0.038)
Step: 160897, Reward: 660.4982 [203.47], Avg: 145.1232 (0.037)
Step: 161897, Reward: 774.6004 [134.93], Avg: 148.1388 (0.036)
Step: 162897, Reward: 888.1790 [37.58], Avg: 152.3961 (0.036)
Step: 163897, Reward: 875.2947 [25.68], Avg: 156.5962 (0.035)
Step: 164897, Reward: 817.9636 [52.33], Avg: 160.2431 (0.034)
Step: 165897, Reward: 875.4577 [44.04], Avg: 164.2382 (0.034)
Step: 166897, Reward: 709.7522 [140.68], Avg: 166.6337 (0.033)
Step: 167897, Reward: 820.6920 [26.75], Avg: 170.3238 (0.032)
Step: 168897, Reward: 707.0140 [159.85], Avg: 172.5275 (0.032)
Step: 169897, Reward: 630.9577 [178.26], Avg: 174.1564 (0.031)
Step: 170897, Reward: 801.0196 [114.40], Avg: 177.1186 (0.030)
Step: 171897, Reward: 853.2128 [25.64], Avg: 180.8568 (0.030)
Step: 172897, Reward: 859.7390 [24.28], Avg: 184.5974 (0.029)
Step: 173897, Reward: 864.0686 [13.81], Avg: 188.3796 (0.029)
Step: 174897, Reward: 841.7424 [30.23], Avg: 191.9001 (0.028)
Step: 175897, Reward: 849.5246 [36.40], Avg: 195.3901 (0.027)
Step: 176897, Reward: 759.4358 [51.07], Avg: 198.2559 (0.027)
Step: 177897, Reward: 843.0188 [65.70], Avg: 201.4729 (0.026)
Step: 178897, Reward: 854.8231 [25.54], Avg: 204.9415 (0.026)
Step: 179897, Reward: 867.8527 [19.32], Avg: 208.4777 (0.025)
Step: 180897, Reward: 652.1284 [139.52], Avg: 210.1396 (0.025)
Step: 181897, Reward: 817.5493 [25.35], Avg: 213.3030 (0.024)
Step: 182897, Reward: 796.7902 [41.91], Avg: 216.2304 (0.024)
Step: 183897, Reward: 831.9373 [30.74], Avg: 219.3754 (0.023)
Step: 184897, Reward: 873.3402 [33.85], Avg: 222.6916 (0.023)
Step: 185897, Reward: 838.6080 [31.16], Avg: 225.8020 (0.022)
Step: 186897, Reward: 878.8602 [23.37], Avg: 229.1337 (0.022)
Step: 187897, Reward: 897.4866 [18.39], Avg: 232.5545 (0.022)
Step: 188897, Reward: 882.3595 [29.90], Avg: 235.8001 (0.021)
Step: 189897, Reward: 811.5844 [69.30], Avg: 238.4380 (0.021)
Step: 190897, Reward: 879.1575 [45.23], Avg: 241.5235 (0.020)
Step: 191523, Reward: 814.1559 [85.73], Avg: 244.0333 (0.020)
Step: 192523, Reward: 903.1503 [25.31], Avg: 247.2835 (0.020)
Step: 193523, Reward: 822.5693 [47.49], Avg: 249.9764 (0.020)
Step: 194523, Reward: 629.8595 [181.03], Avg: 250.9858 (0.020)
Step: 195523, Reward: 862.3882 [17.36], Avg: 253.9860 (0.020)
Step: 196523, Reward: 870.5050 [16.24], Avg: 257.0025 (0.020)
Step: 197523, Reward: 734.3267 [104.85], Avg: 258.8648 (0.020)
Step: 198523, Reward: 713.7598 [160.64], Avg: 260.3288 (0.020)
Step: 199523, Reward: 788.2383 [142.52], Avg: 262.2366 (0.020)
Step: 200523, Reward: 795.7925 [78.04], Avg: 264.4806 (0.020)
Step: 201523, Reward: 801.5540 [66.35], Avg: 266.7881 (0.020)
Step: 202523, Reward: 867.6879 [69.94], Avg: 269.3781 (0.020)
Step: 203238, Reward: 898.6940 [25.28], Avg: 272.3103 (0.020)
Step: 204238, Reward: 834.6955 [65.94], Avg: 274.7086 (0.020)
Step: 205238, Reward: 858.1457 [48.06], Avg: 277.2825 (0.020)
Step: 206238, Reward: 882.8943 [31.13], Avg: 280.0313 (0.020)
Step: 207238, Reward: 654.5897 [140.30], Avg: 281.1468 (0.020)
Step: 208238, Reward: 875.2548 [35.27], Avg: 283.7953 (0.020)
Step: 209238, Reward: 902.6957 [31.12], Avg: 286.5679 (0.020)
Step: 210238, Reward: 786.9021 [93.57], Avg: 288.4775 (0.020)
Step: 211238, Reward: 830.9531 [28.63], Avg: 290.8787 (0.020)
Step: 212238, Reward: 668.2521 [231.86], Avg: 291.5555 (0.020)
Step: 213238, Reward: 904.1377 [30.52], Avg: 294.2502 (0.020)
Step: 214238, Reward: 822.4993 [47.78], Avg: 296.4644 (0.020)
Step: 215238, Reward: 724.8227 [151.46], Avg: 297.7345 (0.020)
Step: 216238, Reward: 826.6168 [76.51], Avg: 299.8002 (0.020)
Step: 217238, Reward: 866.2840 [78.56], Avg: 302.0180 (0.020)
Step: 218238, Reward: 828.2829 [51.71], Avg: 304.1653 (0.020)
Step: 219238, Reward: 848.2931 [39.96], Avg: 306.4363 (0.020)
Step: 220238, Reward: -33.3009 [37.46], Avg: 304.7448 (0.020)
Step: 221238, Reward: 177.2397 [103.71], Avg: 303.7126 (0.020)
Step: 222238, Reward: 865.1190 [52.85], Avg: 305.9729 (0.020)
Step: 223238, Reward: 784.9223 [103.62], Avg: 307.6336 (0.020)
Step: 224238, Reward: 707.8771 [156.04], Avg: 308.7094 (0.020)
Step: 225238, Reward: 844.2594 [21.84], Avg: 310.9625 (0.020)
Step: 226238, Reward: 796.5917 [110.05], Avg: 312.6026 (0.020)
Step: 227238, Reward: 805.8198 [79.84], Avg: 314.3999 (0.020)
Step: 228238, Reward: 857.9642 [34.72], Avg: 316.6027 (0.020)
Step: 229238, Reward: 851.9917 [38.16], Avg: 318.7460 (0.020)
Step: 230238, Reward: 866.6120 [41.98], Avg: 320.9171 (0.020)
Step: 231238, Reward: 888.9846 [25.35], Avg: 323.2365 (0.020)
Step: 232238, Reward: 893.5920 [35.52], Avg: 325.5124 (0.020)
Step: 233238, Reward: 839.5643 [29.14], Avg: 327.5671 (0.020)
Step: 234238, Reward: 860.8283 [34.95], Avg: 329.6696 (0.020)
Step: 235238, Reward: 842.1876 [25.61], Avg: 331.7155 (0.020)
Step: 236238, Reward: 889.7191 [30.00], Avg: 333.9247 (0.020)
Step: 237238, Reward: 868.8829 [13.26], Avg: 336.0984 (0.020)
Step: 238238, Reward: 883.2104 [13.92], Avg: 338.3108 (0.020)
Step: 239238, Reward: 822.9705 [20.90], Avg: 340.2272 (0.020)
Step: 240238, Reward: 666.4087 [241.68], Avg: 340.5749 (0.020)
Step: 241238, Reward: 810.4063 [114.46], Avg: 342.0314 (0.020)
Step: 242238, Reward: 830.9985 [26.21], Avg: 343.9202 (0.020)
Step: 243176, Reward: 868.4592 [17.43], Avg: 345.9816 (0.020)
Step: 244176, Reward: 859.5760 [27.96], Avg: 347.9477 (0.020)
Step: 245176, Reward: 807.1612 [41.12], Avg: 349.6336 (0.020)
Step: 246176, Reward: 797.4941 [141.76], Avg: 350.8629 (0.020)
Step: 247176, Reward: 796.2851 [30.03], Avg: 352.5245 (0.020)
Step: 248176, Reward: 761.3457 [142.74], Avg: 353.5845 (0.020)
Step: 249176, Reward: 860.0842 [12.44], Avg: 355.5451 (0.020)
Step: 250176, Reward: 856.1037 [17.40], Avg: 357.4548 (0.020)
Step: 250914, Reward: 895.6918 [32.61], Avg: 359.4454 (0.020)
Step: 251914, Reward: 782.4441 [76.31], Avg: 360.8050 (0.020)
Step: 252715, Reward: 886.6739 [32.28], Avg: 362.7331 (0.020)
Step: 253715, Reward: 856.8753 [52.53], Avg: 364.4514 (0.020)
Step: 254715, Reward: 914.7824 [28.93], Avg: 366.4723 (0.020)
Step: 255715, Reward: 823.9030 [15.23], Avg: 368.1797 (0.020)
Step: 256715, Reward: 852.7390 [21.98], Avg: 369.9588 (0.020)
Step: 257715, Reward: 883.4772 [26.51], Avg: 371.8248 (0.020)
Step: 258715, Reward: 679.0918 [131.20], Avg: 372.4968 (0.020)
Step: 259715, Reward: 883.6652 [23.06], Avg: 374.3527 (0.020)
Step: 260715, Reward: 879.6640 [10.48], Avg: 376.2271 (0.020)
Step: 261715, Reward: 900.4340 [33.83], Avg: 378.0776 (0.020)
Step: 262715, Reward: 888.6245 [29.06], Avg: 379.8877 (0.020)
Step: 263715, Reward: 866.0461 [64.77], Avg: 381.4659 (0.020)
Step: 264715, Reward: 835.9814 [84.34], Avg: 382.8471 (0.020)
Step: 265715, Reward: 882.2996 [34.23], Avg: 384.5766 (0.020)
Step: 266715, Reward: 769.9810 [272.82], Avg: 384.9935 (0.020)
Step: 267715, Reward: 857.4462 [7.45], Avg: 386.7094 (0.020)
Step: 268715, Reward: 860.4421 [21.21], Avg: 388.3731 (0.020)
Step: 269715, Reward: 881.6850 [12.73], Avg: 390.1334 (0.020)
Step: 270715, Reward: 285.8363 [448.33], Avg: 388.1165 (0.020)
Step: 271715, Reward: 438.3968 [387.80], Avg: 386.8892 (0.020)
Step: 272715, Reward: 872.3022 [24.77], Avg: 388.5582 (0.020)
Step: 273715, Reward: 881.4643 [10.73], Avg: 390.2989 (0.020)
Step: 274332, Reward: 886.3412 [29.88], Avg: 391.9758 (0.020)
Step: 275332, Reward: 862.4502 [19.94], Avg: 393.5906 (0.020)
Step: 276332, Reward: 764.6861 [130.05], Avg: 394.4515 (0.020)
Step: 277332, Reward: 832.4873 [45.66], Avg: 395.8478 (0.020)
Step: 278332, Reward: 880.1771 [33.14], Avg: 397.4477 (0.020)
Step: 279071, Reward: 829.6803 [28.55], Avg: 398.8742 (0.020)
Step: 280071, Reward: 824.0201 [1.00], Avg: 400.3677 (0.020)
Step: 281071, Reward: 773.7048 [101.32], Avg: 401.3221 (0.020)
Step: 282071, Reward: 869.9848 [12.75], Avg: 402.9162 (0.020)
Step: 283071, Reward: 481.6159 [194.12], Avg: 402.5141 (0.020)
Step: 284071, Reward: 729.7158 [154.39], Avg: 403.1141 (0.020)
Step: 285071, Reward: 838.6192 [13.81], Avg: 404.5733 (0.020)
Step: 286071, Reward: 903.5376 [30.25], Avg: 406.1895 (0.020)
Step: 287071, Reward: 871.0740 [6.76], Avg: 407.7638 (0.020)
Step: 288071, Reward: 891.2774 [26.19], Avg: 409.3300 (0.020)
Step: 289071, Reward: 863.1344 [12.54], Avg: 410.8360 (0.020)
Step: 290071, Reward: 889.5860 [25.64], Avg: 412.3772 (0.020)
Step: 290726, Reward: 617.3208 [272.82], Avg: 412.1471 (0.020)
Step: 291726, Reward: 863.4374 [27.91], Avg: 413.5774 (0.020)
Step: 292726, Reward: 430.6540 [345.49], Avg: 412.4716 (0.020)
Step: 293726, Reward: 562.3286 [230.17], Avg: 412.2021 (0.020)
Step: 294726, Reward: 880.3176 [15.54], Avg: 413.7158 (0.020)
Step: 295726, Reward: 503.3018 [264.62], Avg: 413.1323 (0.020)
Step: 296726, Reward: 855.8172 [69.49], Avg: 414.3722 (0.020)
Step: 297594, Reward: 719.0029 [71.05], Avg: 415.1456 (0.020)
Step: 298244, Reward: 610.6623 [331.12], Avg: 414.6981 (0.020)
Step: 299244, Reward: 648.5558 [234.73], Avg: 414.6952 (0.020)
Step: 300244, Reward: 843.4379 [22.44], Avg: 416.0274 (0.020)
Step: 301244, Reward: 795.3397 [97.57], Avg: 416.9481 (0.020)
Step: 302244, Reward: 832.4442 [40.01], Avg: 418.1712 (0.020)
Step: 303244, Reward: 820.4208 [72.35], Avg: 419.2423 (0.020)
Step: 303944, Reward: 838.9316 [74.02], Avg: 420.3610 (0.020)
Step: 304944, Reward: 452.4313 [264.74], Avg: 419.6104 (0.020)
Step: 305944, Reward: 742.4094 [260.66], Avg: 419.8102 (0.020)
Step: 306619, Reward: 798.8984 [203.02], Avg: 420.3746 (0.020)
Step: 307619, Reward: 826.6921 [127.80], Avg: 421.2644 (0.020)
Step: 308619, Reward: 590.5680 [243.67], Avg: 421.0275 (0.020)
Step: 309619, Reward: 849.6163 [26.88], Avg: 422.3028 (0.020)
Step: 310619, Reward: 872.7616 [65.95], Avg: 423.5196 (0.020)
Step: 311619, Reward: 853.8255 [81.52], Avg: 424.6199 (0.020)
Step: 312619, Reward: 845.3325 [42.91], Avg: 425.8080 (0.020)
Step: 313619, Reward: 876.2309 [29.68], Avg: 427.1269 (0.020)
Step: 314619, Reward: 797.1203 [73.21], Avg: 428.0544 (0.020)
Step: 315619, Reward: 859.1539 [29.32], Avg: 429.3060 (0.020)
Step: 316619, Reward: 815.9343 [40.81], Avg: 430.3800 (0.020)
Step: 317619, Reward: 834.0825 [35.49], Avg: 431.5200 (0.020)
Step: 318619, Reward: 236.0723 [100.58], Avg: 430.6063 (0.020)
Step: 319619, Reward: 861.3679 [51.64], Avg: 431.7728 (0.020)
Step: 320619, Reward: 868.3195 [11.49], Avg: 433.0767 (0.020)
Step: 321194, Reward: 815.7074 [84.09], Avg: 433.9897 (0.020)
Step: 322194, Reward: 681.1775 [343.33], Avg: 433.6966 (0.020)
Step: 323194, Reward: 887.6338 [40.90], Avg: 434.9520 (0.020)
Step: 323825, Reward: 784.4399 [142.76], Avg: 435.5784 (0.020)
Step: 324825, Reward: 887.3525 [6.33], Avg: 436.9242 (0.020)
Step: 325825, Reward: 824.0915 [97.44], Avg: 437.7969 (0.020)
Step: 326825, Reward: 803.5625 [80.81], Avg: 438.6526 (0.020)
Step: 327516, Reward: 893.0198 [28.16], Avg: 439.9286 (0.020)
Step: 328516, Reward: 911.8051 [26.51], Avg: 441.2581 (0.020)
Step: 329516, Reward: 882.5950 [14.20], Avg: 442.5293 (0.020)
Step: 330516, Reward: 381.4297 [248.26], Avg: 441.6114 (0.020)
Step: 331516, Reward: 708.1964 [216.30], Avg: 441.7601 (0.020)
Step: 332516, Reward: 694.7248 [163.70], Avg: 442.0235 (0.020)
Step: 333098, Reward: 869.1745 [72.13], Avg: 443.0676 (0.020)
Step: 333937, Reward: -55.7256 [14.02], Avg: 441.5638 (0.020)
Step: 334937, Reward: 129.1450 [41.65], Avg: 440.5285 (0.020)
Step: 335937, Reward: 225.8141 [184.21], Avg: 439.3655 (0.020)
Step: 336937, Reward: 337.1638 [81.29], Avg: 438.8321 (0.020)
Step: 337937, Reward: 395.6083 [142.06], Avg: 438.2950 (0.020)
Step: 338937, Reward: 522.7861 [186.82], Avg: 437.9993 (0.020)
Step: 339937, Reward: 912.6210 [19.93], Avg: 439.3096 (0.020)
Step: 340937, Reward: 775.8652 [157.67], Avg: 439.8237 (0.020)
Step: 341937, Reward: 836.9799 [58.75], Avg: 440.7933 (0.020)
Step: 342937, Reward: 869.0865 [49.15], Avg: 441.8766 (0.020)
Step: 343937, Reward: 906.0749 [41.41], Avg: 443.0811 (0.020)
Step: 344937, Reward: 840.3323 [70.34], Avg: 444.0098 (0.020)
Step: 345937, Reward: 617.3283 [234.25], Avg: 443.8372 (0.020)
Step: 346937, Reward: 843.9717 [47.81], Avg: 444.8325 (0.020)
Step: 347937, Reward: 553.8879 [303.81], Avg: 444.2839 (0.020)
Step: 348937, Reward: 365.7937 [209.53], Avg: 443.4748 (0.020)
Step: 349937, Reward: 868.7469 [26.51], Avg: 444.5918 (0.020)
Step: 350937, Reward: 843.8697 [57.68], Avg: 445.5460 (0.020)
Step: 351937, Reward: 877.7951 [31.48], Avg: 446.6623 (0.020)
Step: 352937, Reward: 862.3370 [10.12], Avg: 447.7889 (0.020)
Step: 353937, Reward: 424.8181 [167.99], Avg: 447.2599 (0.020)
Step: 354518, Reward: 752.9766 [139.24], Avg: 447.7198 (0.020)
Step: 355518, Reward: 859.7571 [16.57], Avg: 448.8092 (0.020)
Step: 356518, Reward: 834.8347 [122.72], Avg: 449.5326 (0.020)
Step: 357518, Reward: 891.6822 [20.28], Avg: 450.6884 (0.020)
Step: 358518, Reward: 798.0756 [126.08], Avg: 451.2931 (0.020)
Step: 359518, Reward: 705.8607 [247.70], Avg: 451.3118 (0.020)
Step: 360518, Reward: 846.9308 [32.87], Avg: 452.2975 (0.020)
Step: 361518, Reward: 856.1335 [24.76], Avg: 453.3248 (0.020)
Step: 362518, Reward: 599.8155 [214.63], Avg: 453.1407 (0.020)
Step: 363518, Reward: 809.2624 [113.68], Avg: 453.7941 (0.020)
Step: 364518, Reward: 630.5402 [259.89], Avg: 453.5706 (0.020)
Step: 365518, Reward: 716.0892 [315.58], Avg: 453.4284 (0.020)
Step: 366518, Reward: 771.0082 [169.38], Avg: 453.8246 (0.020)
Step: 367518, Reward: 697.6152 [254.85], Avg: 453.7951 (0.020)
Step: 368518, Reward: 507.2771 [264.85], Avg: 453.2330 (0.020)
Step: 369518, Reward: 854.6067 [57.77], Avg: 454.1444 (0.020)
Step: 370518, Reward: 797.5143 [162.58], Avg: 454.6227 (0.020)
Step: 371518, Reward: 898.1740 [33.75], Avg: 455.7039 (0.020)
Step: 372518, Reward: 856.4458 [102.71], Avg: 456.4882 (0.020)
Step: 373518, Reward: 588.1944 [209.39], Avg: 456.2843 (0.020)
Step: 374518, Reward: 847.3950 [72.28], Avg: 457.1190 (0.020)
Step: 375384, Reward: 879.2221 [16.23], Avg: 458.1787 (0.020)
Step: 376384, Reward: 756.7632 [118.61], Avg: 458.6474 (0.020)
Step: 377384, Reward: 888.4279 [45.05], Avg: 459.6467 (0.020)
Step: 378384, Reward: 867.9599 [14.65], Avg: 460.6666 (0.020)
Step: 379096, Reward: 820.1674 [80.78], Avg: 461.3868 (0.020)
Step: 380096, Reward: 891.4316 [25.25], Avg: 462.4300 (0.020)
Step: 381096, Reward: 825.3815 [77.29], Avg: 463.1644 (0.020)
Step: 382096, Reward: 895.8970 [26.72], Avg: 464.2055 (0.020)
Step: 383096, Reward: 838.9239 [79.98], Avg: 464.9593 (0.020)
Step: 383823, Reward: 395.6331 [99.12], Avg: 464.5296 (0.020)
Step: 384823, Reward: 866.4836 [18.01], Avg: 465.5065 (0.020)
Step: 385823, Reward: 567.4295 [278.81], Avg: 465.0576 (0.020)
Step: 386823, Reward: 542.3026 [262.89], Avg: 464.5876 (0.020)
Step: 387823, Reward: 760.9339 [212.49], Avg: 464.7993 (0.020)
Step: 388823, Reward: 865.4544 [46.24], Avg: 465.6921 (0.020)
Step: 389823, Reward: 886.6613 [29.64], Avg: 466.6753 (0.020)
Step: 390823, Reward: 893.1445 [14.86], Avg: 467.7069 (0.020)
Step: 391823, Reward: 734.3342 [251.43], Avg: 467.7449 (0.020)
Step: 392823, Reward: 836.2309 [88.91], Avg: 468.4421 (0.020)
Step: 393823, Reward: 879.2890 [35.58], Avg: 469.3756 (0.020)
Step: 394437, Reward: 915.7510 [30.05], Avg: 470.4086 (0.020)
Step: 395437, Reward: 862.8008 [16.81], Avg: 471.3383 (0.020)
Step: 396437, Reward: 576.5344 [321.60], Avg: 470.8040 (0.020)
Step: 397437, Reward: 270.7295 [144.81], Avg: 469.9545 (0.020)
Step: 398437, Reward: 786.4167 [60.26], Avg: 470.5840 (0.020)
Step: 399437, Reward: 857.2005 [50.90], Avg: 471.4068 (0.020)
Step: 400437, Reward: 653.9340 [314.85], Avg: 471.0833 (0.020)
Step: 401437, Reward: 395.8063 [239.97], Avg: 470.3144 (0.020)
Step: 402437, Reward: 837.8731 [24.75], Avg: 471.1485 (0.020)
Step: 403437, Reward: 582.3175 [179.66], Avg: 470.9823 (0.020)
Step: 404437, Reward: 901.5797 [31.76], Avg: 471.9480 (0.020)
Step: 405017, Reward: 800.0616 [91.00], Avg: 472.5207 (0.020)
Step: 405637, Reward: 573.5303 [240.44], Avg: 472.1847 (0.020)
Step: 406637, Reward: 859.5568 [15.16], Avg: 473.0795 (0.020)
Step: 407637, Reward: 909.1150 [36.65], Avg: 474.0372 (0.020)
Step: 408637, Reward: 690.5376 [229.08], Avg: 474.0071 (0.020)
Step: 409637, Reward: 862.7811 [23.83], Avg: 474.8781 (0.020)
Step: 410637, Reward: 665.1305 [148.54], Avg: 474.9774 (0.020)
Step: 411637, Reward: 897.6966 [25.54], Avg: 475.9209 (0.020)
Step: 412637, Reward: 891.9032 [37.52], Avg: 476.8177 (0.020)
Step: 413637, Reward: 396.4727 [312.31], Avg: 475.8894 (0.020)
Step: 414637, Reward: 846.9037 [21.82], Avg: 476.7130 (0.020)
Step: 415637, Reward: 810.8194 [45.79], Avg: 477.3914 (0.020)
Step: 416637, Reward: 898.3309 [33.55], Avg: 478.3007 (0.020)
Step: 417637, Reward: 766.5988 [144.48], Avg: 478.6376 (0.020)
Step: 418637, Reward: 737.6620 [153.61], Avg: 478.8839 (0.020)
Step: 419637, Reward: 877.0785 [7.44], Avg: 479.7947 (0.020)
Step: 420637, Reward: 827.3010 [89.18], Avg: 480.3955 (0.020)
Step: 421637, Reward: 671.8604 [176.62], Avg: 480.4299 (0.020)
Step: 422637, Reward: 696.9958 [289.82], Avg: 480.2603 (0.020)
Step: 423637, Reward: 743.7561 [180.35], Avg: 480.4524 (0.020)
Step: 424202, Reward: 895.9742 [20.94], Avg: 481.3615 (0.020)
Step: 425202, Reward: 885.7491 [27.87], Avg: 482.2271 (0.020)
Step: 425812, Reward: 868.8309 [82.19], Avg: 482.9253 (0.020)
Step: 426721, Reward: 848.7189 [59.16], Avg: 483.6269 (0.020)
Step: 427721, Reward: 790.7360 [83.88], Avg: 484.1366 (0.020)
Step: 428721, Reward: 878.9398 [55.25], Avg: 484.9101 (0.020)
Step: 429336, Reward: 716.9167 [328.23], Avg: 484.6914 (0.020)
Step: 430209, Reward: 804.1065 [105.67], Avg: 485.1761 (0.020)
Step: 431209, Reward: 723.3952 [134.78], Avg: 485.4101 (0.020)
Step: 432069, Reward: 765.7180 [110.57], Avg: 485.7932 (0.020)
Step: 433069, Reward: 878.4170 [52.58], Avg: 486.5591 (0.020)
Step: 433984, Reward: 876.7532 [35.86], Avg: 487.3554 (0.020)
Step: 434984, Reward: 885.6404 [44.56], Avg: 488.1485 (0.020)
Step: 435601, Reward: 875.7534 [23.97], Avg: 488.9620 (0.020)
Step: 436601, Reward: 492.3757 [145.16], Avg: 488.6456 (0.020)
Step: 437601, Reward: 738.1131 [200.39], Avg: 488.7549 (0.020)
Step: 438601, Reward: 754.0189 [200.40], Avg: 488.8990 (0.020)
Step: 439601, Reward: 834.9496 [25.95], Avg: 489.6088 (0.020)
Step: 440601, Reward: 862.8546 [15.77], Avg: 490.3997 (0.020)
Step: 441601, Reward: 835.5151 [11.40], Avg: 491.1364 (0.020)
Step: 442240, Reward: 818.0493 [21.32], Avg: 491.8095 (0.020)
Step: 443240, Reward: 878.3718 [30.64], Avg: 492.5917 (0.020)
Step: 444240, Reward: 887.4047 [21.80], Avg: 493.4097 (0.020)
Step: 445240, Reward: 832.9813 [75.65], Avg: 493.9872 (0.020)
Step: 446240, Reward: 874.0208 [24.78], Avg: 494.7629 (0.020)
Step: 447240, Reward: 880.9428 [28.55], Avg: 495.5420 (0.020)
Step: 448240, Reward: 870.5482 [16.38], Avg: 496.3217 (0.020)
Step: 449240, Reward: 868.5176 [16.70], Avg: 497.0928 (0.020)
Step: 450240, Reward: 752.0679 [137.59], Avg: 497.3469 (0.020)
Step: 451240, Reward: 714.2032 [190.72], Avg: 497.4033 (0.020)
Step: 452240, Reward: 875.5809 [9.49], Avg: 498.1979 (0.020)
Step: 453240, Reward: 906.7351 [20.04], Avg: 499.0334 (0.020)
Step: 454240, Reward: 880.1284 [8.47], Avg: 499.8330 (0.020)
Step: 455240, Reward: 802.5740 [179.33], Avg: 500.0973 (0.020)
Step: 456240, Reward: 903.0836 [35.05], Avg: 500.8835 (0.020)
Step: 457240, Reward: 860.3333 [18.78], Avg: 501.6099 (0.020)
Step: 458240, Reward: 765.9207 [185.93], Avg: 501.7766 (0.020)
Step: 459240, Reward: 903.3912 [47.12], Avg: 502.5293 (0.020)
Step: 460240, Reward: 914.7036 [19.05], Avg: 503.3622 (0.020)
Step: 461240, Reward: 845.1039 [67.53], Avg: 503.9419 (0.020)
Step: 462240, Reward: 184.4545 [190.15], Avg: 502.8667 (0.020)
Step: 463155, Reward: 501.6999 [149.87], Avg: 502.5487 (0.020)
Step: 464155, Reward: 770.6718 [88.32], Avg: 502.9265 (0.020)
Step: 465155, Reward: 762.8534 [128.55], Avg: 503.2019 (0.020)
Step: 466155, Reward: 618.1947 [245.57], Avg: 502.9287 (0.020)
Step: 467155, Reward: 864.2403 [90.38], Avg: 503.4943 (0.020)
Step: 468155, Reward: 794.2447 [28.81], Avg: 504.0400 (0.020)
Step: 469155, Reward: 801.2515 [173.62], Avg: 504.2970 (0.020)
Step: 470155, Reward: 842.5352 [18.59], Avg: 504.9601 (0.020)
Step: 471155, Reward: 892.4425 [41.42], Avg: 505.6766 (0.020)
Step: 472155, Reward: 186.6558 [87.39], Avg: 504.8370 (0.020)
Step: 473155, Reward: 277.0490 [76.80], Avg: 504.2089 (0.020)
Step: 474155, Reward: 344.8914 [73.41], Avg: 503.7301 (0.020)
Step: 475155, Reward: 560.0184 [256.51], Avg: 503.3189 (0.020)
Step: 476155, Reward: 450.0117 [214.12], Avg: 502.7709 (0.020)
Step: 477155, Reward: 639.9888 [252.64], Avg: 502.5349 (0.020)
Step: 478155, Reward: 298.4545 [141.72], Avg: 501.8292 (0.020)
Step: 479155, Reward: 816.0979 [86.09], Avg: 502.2939 (0.020)
Step: 480155, Reward: 815.3077 [32.86], Avg: 502.8633 (0.020)
Step: 481155, Reward: 857.3644 [32.81], Avg: 503.5158 (0.020)
Step: 482155, Reward: 419.3927 [94.86], Avg: 503.1535 (0.020)
Step: 483155, Reward: 832.5074 [80.13], Avg: 503.6570 (0.020)
Step: 484155, Reward: 516.8832 [257.31], Avg: 503.1649 (0.020)
Step: 485155, Reward: 531.5650 [280.75], Avg: 502.6571 (0.020)
Step: 486155, Reward: 642.3838 [227.45], Avg: 502.4810 (0.020)
Step: 487155, Reward: 338.1825 [107.86], Avg: 501.9356 (0.020)
Step: 488155, Reward: 409.6249 [399.65], Avg: 500.9517 (0.020)
Step: 489155, Reward: 888.7434 [41.06], Avg: 501.6437 (0.020)
Step: 490155, Reward: 734.5337 [201.95], Avg: 501.7054 (0.020)
Step: 491149, Reward: 866.8503 [19.04], Avg: 502.3935 (0.020)
Step: 492149, Reward: 865.9332 [17.45], Avg: 503.0801 (0.020)
Step: 493149, Reward: 828.1299 [24.92], Avg: 503.6745 (0.020)
Step: 494149, Reward: 512.4486 [273.47], Avg: 503.1514 (0.020)
Step: 495149, Reward: 748.0793 [285.25], Avg: 503.0718 (0.020)
Step: 496149, Reward: 783.7726 [166.68], Avg: 503.2963 (0.020)
Step: 497149, Reward: 856.1237 [15.93], Avg: 503.9582 (0.020)
Step: 498149, Reward: 859.9986 [19.60], Avg: 504.6178 (0.020)
Step: 499149, Reward: 729.0101 [177.61], Avg: 504.7094 (0.020)
