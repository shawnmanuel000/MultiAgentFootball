Model: <class 'models.ddpg.DDPGAgent'>, Dir: BipedalWalker-v2
num_envs: 16, state_size: (24,), action_size: (4,), action_space: Box(4,),

import os
import math
import torch
import random
import numpy as np
from models.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, EPS_DECAY, REPLAY_BATCH_SIZE

class DDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		state = self.layer3(state).relu() 
		action_mu = self.action_mu(state)
		action_sig = self.action_sig(state).exp()
		epsilon = torch.randn_like(action_sig)
		action = action_mu + epsilon.mul(action_sig) if sample else action_mu
		return action.tanh()
	
class DDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.net_state = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.net_action = torch.nn.Linear(*action_size, INPUT_LAYER)
		self.net_layer1 = torch.nn.Linear(2*INPUT_LAYER, CRITIC_HIDDEN)
		self.net_layer2 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = self.net_state(state).relu()
		net_action = self.net_action(action).relu()
		net_layer = torch.cat([state, net_action], dim=-1)
		net_layer = self.net_layer1(net_layer).relu()
		net_layer = self.net_layer2(net_layer).relu()
		q_value = self.q_value(net_layer)
		return q_value

class DDPGNetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None): 
		super().__init__(state_size, action_size, DDPGActor, DDPGCritic, lr=lr, gpu=gpu, load=load)

	def get_action(self, state, use_target=False, numpy=True, sample=True):
		with torch.no_grad():
			actor = self.actor_local if not use_target else self.actor_target
			return actor(state, sample).cpu().numpy() if numpy else actor(state, sample)

	def get_q_value(self, state, action, use_target=False, numpy=True):
		with torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			return critic(state, action).cpu().numpy() if numpy else critic(state, action)
	
	def optimize(self, states, actions, q_targets, importances=1):
		q_values = self.critic_local(states, actions)
		critic_error = q_values - q_targets.detach()
		critic_loss = importances.to(self.device) * critic_error.pow(2)
		self.step(self.critic_optimizer, critic_loss.mean())

		q_actions = self.critic_local(states, self.actor_local(states))
		actor_loss = -(q_actions - q_values.detach())
		self.step(self.actor_optimizer, actor_loss.mean())
		
		self.soft_copy(self.actor_local, self.actor_target)
		self.soft_copy(self.critic_local, self.critic_target)
		return critic_error.cpu().detach().numpy().squeeze(-1)
	
	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ddpg", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ddpg", dirname, name)

class DDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, decay=EPS_DECAY, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, DDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True, e_greedy=False):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if e_greedy and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), sample=sample)
		action = action_greedy if e_greedy else np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if done[0] or len(self.buffer) >= self.update_freq:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			next_state = self.to_tensor(next_state)
			next_action = self.network.get_action(next_state, use_target=True, numpy=False)
			values = self.network.get_q_value(states, actions, use_target=True, numpy=False)
			next_value = self.network.get_q_value(next_state, next_action, use_target=True, numpy=False)
			targets, _ = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values)
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states, actions, targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=False)	
		if len(self.replay_buffer) > 0:
			(states, actions, targets), indices, importances = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)
			errors = self.network.optimize(states, actions, targets, importances**(1-self.eps))
			self.replay_buffer.update_priorities(indices, errors)
			if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[6]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class AsyncAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = AsyncAgent(envs.state_size, envs.action_size, num_envs, model)
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.stack.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0]:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 140, Reward: -112.9908 [11.38], Avg: -124.3721 (0.980)
Step: 202, Reward: -106.7328 [9.16], Avg: -120.1331 (0.960)
Step: 272, Reward: -116.4461 [2.35], Avg: -119.6859 (0.941)
Step: 718, Reward: -112.0051 [5.03], Avg: -119.0234 (0.922)
Step: 781, Reward: -118.5105 [10.15], Avg: -120.9500 (0.904)
Step: 869, Reward: -112.9098 [7.44], Avg: -120.8495 (0.886)
Step: 951, Reward: -107.2865 [3.97], Avg: -119.4788 (0.868)
Step: 1006, Reward: -116.4844 [5.56], Avg: -119.7996 (0.851)
Step: 1068, Reward: -114.9347 [4.41], Avg: -119.7495 (0.834)
Step: 1273, Reward: -117.1572 [7.88], Avg: -120.2783 (0.817)
Step: 1366, Reward: -114.8436 [5.65], Avg: -120.2979 (0.801)
Step: 1436, Reward: -114.0893 [4.47], Avg: -120.1530 (0.785)
Step: 1494, Reward: -106.8835 [6.60], Avg: -119.6398 (0.769)
Step: 1585, Reward: -112.7203 [3.31], Avg: -119.3821 (0.754)
Step: 1711, Reward: -117.9494 [9.44], Avg: -119.9160 (0.739)
Step: 1811, Reward: -113.2017 [9.35], Avg: -120.0808 (0.724)
Step: 1910, Reward: -112.6103 [7.50], Avg: -120.0825 (0.709)
Step: 2021, Reward: -116.3637 [4.06], Avg: -120.1015 (0.695)
Step: 2200, Reward: -101.4949 [18.06], Avg: -120.0727 (0.681)
Step: 3800, Reward: -102.3764 [21.84], Avg: -120.2798 (0.668)
Step: 5400, Reward: -110.1670 [7.13], Avg: -120.1379 (0.654)
Step: 5524, Reward: -93.4549 [18.89], Avg: -119.7836 (0.641)
Step: 5597, Reward: -106.4607 [16.13], Avg: -119.9058 (0.628)
Step: 7197, Reward: -98.3474 [16.84], Avg: -119.7091 (0.616)
Step: 7954, Reward: -110.6127 [5.66], Avg: -119.5717 (0.603)
Step: 8055, Reward: -110.2472 [10.36], Avg: -119.6117 (0.591)
Step: 8122, Reward: -108.8807 [8.86], Avg: -119.5423 (0.580)
Step: 8188, Reward: -106.9148 [6.53], Avg: -119.3244 (0.568)
Step: 9788, Reward: -111.9679 [2.88], Avg: -119.1699 (0.557)
Step: 11388, Reward: -109.6133 [5.79], Avg: -119.0443 (0.545)
Step: 11620, Reward: -116.9603 [10.71], Avg: -119.3224 (0.535)
Step: 13220, Reward: -132.2032 [42.10], Avg: -121.0407 (0.524)
Step: 13359, Reward: -125.0408 [28.68], Avg: -122.0309 (0.513)
Step: 14959, Reward: -127.2253 [31.31], Avg: -123.1045 (0.503)
Step: 16559, Reward: -115.7883 [18.65], Avg: -123.4282 (0.493)
Step: 16801, Reward: -113.5757 [22.93], Avg: -123.7914 (0.483)
Step: 16856, Reward: -142.1198 [24.03], Avg: -124.9361 (0.474)
Step: 16916, Reward: -116.7762 [24.16], Avg: -125.3571 (0.464)
Step: 18516, Reward: -63.9781 [23.84], Avg: -124.3946 (0.455)
Step: 20116, Reward: -70.3728 [12.96], Avg: -123.3681 (0.446)
Step: 20471, Reward: -122.0803 [48.40], Avg: -124.5171 (0.437)
Step: 21894, Reward: -94.6931 [26.00], Avg: -124.4259 (0.428)
Step: 23408, Reward: -48.5021 [4.56], Avg: -122.7662 (0.419)
Step: 24395, Reward: -105.0370 [45.76], Avg: -123.4032 (0.411)
Step: 25995, Reward: -60.6823 [6.17], Avg: -122.1465 (0.403)
Step: 27595, Reward: -59.2962 [31.53], Avg: -121.4657 (0.395)
Step: 29195, Reward: -36.1410 [4.32], Avg: -119.7422 (0.387)
Step: 29300, Reward: -41.9472 [6.77], Avg: -118.2625 (0.379)
Step: 30900, Reward: -70.3610 [19.44], Avg: -117.6817 (0.372)
Step: 32500, Reward: -32.7006 [5.24], Avg: -116.0869 (0.364)
Step: 34100, Reward: -35.1346 [4.41], Avg: -114.5861 (0.357)
Step: 35700, Reward: -43.5747 [32.97], Avg: -113.8544 (0.350)
Step: 35870, Reward: -29.9183 [3.30], Avg: -112.3329 (0.343)
Step: 37470, Reward: -24.1038 [0.95], Avg: -110.7167 (0.336)
Step: 39070, Reward: -26.3671 [3.02], Avg: -109.2379 (0.329)
Step: 40670, Reward: -25.0380 [2.96], Avg: -107.7872 (0.323)
Step: 42270, Reward: -21.3373 [2.36], Avg: -106.3120 (0.316)
Step: 43870, Reward: -44.2424 [32.30], Avg: -105.7988 (0.310)
Step: 45470, Reward: -40.1816 [33.31], Avg: -105.2512 (0.304)
Step: 47070, Reward: -32.0715 [4.41], Avg: -104.1051 (0.298)
Step: 48670, Reward: -46.8785 [2.29], Avg: -103.2045 (0.292)
Step: 50270, Reward: -20.8662 [2.93], Avg: -101.9237 (0.286)
Step: 51870, Reward: -22.5176 [4.24], Avg: -100.7306 (0.280)
Step: 53470, Reward: -22.3830 [2.32], Avg: -99.5426 (0.274)
Step: 55070, Reward: -21.5372 [2.80], Avg: -98.3857 (0.269)
Step: 56670, Reward: -23.4724 [3.31], Avg: -97.3007 (0.264)
Step: 58270, Reward: -17.0385 [1.02], Avg: -96.1180 (0.258)
Step: 59870, Reward: -22.0111 [4.02], Avg: -95.0873 (0.253)
Step: 61470, Reward: -16.7917 [1.96], Avg: -93.9809 (0.248)
Step: 63070, Reward: -14.0247 [3.50], Avg: -92.8887 (0.243)
Step: 64670, Reward: -34.3189 [34.87], Avg: -92.5548 (0.238)
Step: 66270, Reward: -16.9495 [3.55], Avg: -91.5541 (0.233)
Step: 67870, Reward: -16.0614 [2.20], Avg: -90.5501 (0.229)
Step: 69470, Reward: -12.9361 [1.56], Avg: -89.5224 (0.224)
Step: 71070, Reward: -34.9137 [43.58], Avg: -89.3753 (0.220)
Step: 72670, Reward: -12.7021 [1.36], Avg: -88.3843 (0.215)
Step: 74270, Reward: -14.1982 [3.58], Avg: -87.4674 (0.211)
Step: 75870, Reward: -14.5778 [3.28], Avg: -86.5749 (0.207)
Step: 77470, Reward: -13.3991 [2.16], Avg: -85.6760 (0.203)
Step: 79070, Reward: -12.6076 [3.22], Avg: -84.8028 (0.199)
Step: 80670, Reward: -10.2609 [0.90], Avg: -83.8936 (0.195)
Step: 82270, Reward: -11.9006 [1.40], Avg: -83.0327 (0.191)
Step: 83870, Reward: -10.9806 [2.84], Avg: -82.1988 (0.187)
Step: 85470, Reward: -13.3511 [3.23], Avg: -81.4177 (0.183)
Step: 87070, Reward: -11.4204 [3.05], Avg: -80.6300 (0.180)
Step: 88670, Reward: -11.0581 [1.79], Avg: -79.8419 (0.176)
Step: 90270, Reward: -8.6813 [1.35], Avg: -79.0395 (0.172)
Step: 91870, Reward: -11.3157 [2.05], Avg: -78.2932 (0.169)
Step: 93470, Reward: -6.2779 [1.10], Avg: -77.4964 (0.166)
Step: 95070, Reward: -7.1080 [2.03], Avg: -76.7368 (0.162)
Step: 96670, Reward: -10.6343 [1.69], Avg: -76.0290 (0.159)
Step: 98270, Reward: -7.2705 [1.22], Avg: -75.2949 (0.156)
Step: 99870, Reward: -8.2897 [1.19], Avg: -74.5872 (0.153)
Step: 101470, Reward: -7.1561 [1.32], Avg: -73.8838 (0.150)
Step: 103070, Reward: -8.3899 [1.46], Avg: -73.2097 (0.147)
Step: 104670, Reward: -6.4060 [2.03], Avg: -72.5350 (0.144)
Step: 106270, Reward: -5.6772 [1.75], Avg: -71.8637 (0.141)
Step: 107870, Reward: -5.4330 [0.39], Avg: -71.1898 (0.138)
Step: 109470, Reward: -7.3862 [0.73], Avg: -70.5526 (0.135)
Step: 111070, Reward: -6.9478 [1.26], Avg: -69.9291 (0.133)
Step: 112670, Reward: -4.4830 [1.26], Avg: -69.2936 (0.130)
Step: 114270, Reward: -6.9205 [2.15], Avg: -68.7032 (0.127)
Step: 115870, Reward: -5.2792 [1.87], Avg: -68.1056 (0.125)
Step: 117470, Reward: -5.4911 [0.60], Avg: -67.5093 (0.122)
Step: 119070, Reward: -5.4686 [1.13], Avg: -66.9292 (0.120)
Step: 119219, Reward: -8.7673 [1.18], Avg: -66.3916 (0.117)
Step: 120819, Reward: -3.6508 [1.39], Avg: -65.8183 (0.115)
Step: 122419, Reward: -3.7791 [0.72], Avg: -65.2505 (0.113)
Step: 124019, Reward: -4.1525 [0.68], Avg: -64.6962 (0.111)
Step: 125619, Reward: -3.4945 [0.59], Avg: -64.1452 (0.108)
Step: 127219, Reward: -7.9303 [6.85], Avg: -63.7005 (0.106)
Step: 128819, Reward: -3.2133 [0.83], Avg: -63.1678 (0.104)
Step: 130419, Reward: -3.1716 [0.86], Avg: -62.6445 (0.102)
Step: 132019, Reward: -2.6181 [0.43], Avg: -62.1217 (0.100)
Step: 133619, Reward: -1.9036 [1.88], Avg: -61.6145 (0.098)
Step: 135219, Reward: -1.8795 [0.29], Avg: -61.1020 (0.096)
Step: 136819, Reward: -7.0725 [2.00], Avg: -60.6573 (0.094)
Step: 138419, Reward: -2.3652 [1.22], Avg: -60.1736 (0.092)
Step: 140019, Reward: -1.9326 [0.67], Avg: -59.6898 (0.090)
Step: 141619, Reward: -4.8663 [2.74], Avg: -59.2558 (0.089)
Step: 143219, Reward: -5.3450 [3.28], Avg: -58.8373 (0.087)
Step: 144819, Reward: -2.0256 [0.48], Avg: -58.3756 (0.085)
Step: 146419, Reward: -2.2366 [0.38], Avg: -57.9223 (0.083)
Step: 148019, Reward: -2.7022 [0.63], Avg: -57.4820 (0.082)
Step: 149619, Reward: -1.5873 [0.95], Avg: -57.0425 (0.080)
Step: 151219, Reward: -2.1280 [2.44], Avg: -56.6261 (0.078)
Step: 152819, Reward: -1.7316 [0.95], Avg: -56.2013 (0.077)
Step: 154419, Reward: -0.9684 [0.76], Avg: -55.7757 (0.075)
Step: 156019, Reward: -0.2997 [0.97], Avg: -55.3532 (0.074)
Step: 157619, Reward: -0.0734 [0.71], Avg: -54.9335 (0.072)
Step: 159219, Reward: 0.1560 [0.79], Avg: -54.5190 (0.071)
Step: 160819, Reward: 0.1828 [0.62], Avg: -54.1093 (0.069)
Step: 162419, Reward: 0.8845 [0.49], Avg: -53.6995 (0.068)
Step: 164019, Reward: 1.3780 [0.56], Avg: -53.2926 (0.067)
Step: 165619, Reward: 0.1749 [0.54], Avg: -52.9005 (0.065)
Step: 167219, Reward: -2.6400 [6.50], Avg: -52.5788 (0.064)
Step: 167315, Reward: -40.6084 [49.73], Avg: -52.8544 (0.063)
Step: 167412, Reward: -9.9291 [9.81], Avg: -52.6145 (0.062)
Step: 169012, Reward: 1.1014 [1.45], Avg: -52.2385 (0.060)
Step: 170612, Reward: 1.5013 [0.94], Avg: -51.8613 (0.059)
Step: 172212, Reward: 1.0434 [0.38], Avg: -51.4888 (0.058)
Step: 173812, Reward: 1.9988 [0.36], Avg: -51.1147 (0.057)
Step: 175412, Reward: 2.5060 [0.62], Avg: -50.7440 (0.056)
Step: 177012, Reward: 1.2559 [0.76], Avg: -50.3882 (0.055)
Step: 178612, Reward: 1.5533 [0.37], Avg: -50.0326 (0.053)
Step: 180212, Reward: 0.7941 [0.80], Avg: -49.6899 (0.052)
Step: 181812, Reward: 1.4963 [0.83], Avg: -49.3474 (0.051)
Step: 183412, Reward: 1.1393 [0.81], Avg: -49.0117 (0.050)
Step: 185012, Reward: -1.6149 [6.20], Avg: -48.7353 (0.049)
Step: 186612, Reward: 3.2155 [0.36], Avg: -48.3914 (0.048)
Step: 188212, Reward: 2.7703 [0.36], Avg: -48.0549 (0.047)
Step: 189812, Reward: 2.5682 [0.24], Avg: -47.7235 (0.046)
Step: 191412, Reward: 1.8171 [0.26], Avg: -47.4014 (0.045)
Step: 193012, Reward: 2.0843 [0.92], Avg: -47.0860 (0.045)
Step: 194612, Reward: 2.7875 [0.34], Avg: -46.7664 (0.044)
Step: 196212, Reward: 3.7656 [0.30], Avg: -46.4444 (0.043)
Step: 197812, Reward: 3.3438 [0.28], Avg: -46.1291 (0.042)
Step: 199412, Reward: 3.3551 [0.24], Avg: -45.8174 (0.041)
Step: 201012, Reward: 2.8795 [0.56], Avg: -45.5147 (0.040)
Step: 202612, Reward: 1.6140 [0.53], Avg: -45.2235 (0.039)
Step: 204212, Reward: 2.3621 [0.40], Avg: -44.9304 (0.039)
Step: 205812, Reward: 3.7488 [0.34], Avg: -44.6319 (0.038)
Step: 207412, Reward: 3.7311 [0.41], Avg: -44.3378 (0.037)
Step: 209012, Reward: -14.9395 [38.01], Avg: -44.3903 (0.036)
Step: 210612, Reward: -53.0687 [46.62], Avg: -44.7254 (0.036)
Step: 212212, Reward: 0.1665 [0.22], Avg: -44.4563 (0.035)
Step: 213812, Reward: 1.7853 [1.75], Avg: -44.1899 (0.034)
Step: 215412, Reward: -3.8692 [1.33], Avg: -43.9579 (0.034)
Step: 217012, Reward: -14.2341 [0.68], Avg: -43.7860 (0.033)
Step: 218612, Reward: -15.2183 [0.58], Avg: -43.6214 (0.032)
Step: 220212, Reward: -119.7595 [2.13], Avg: -44.0791 (0.032)
Step: 221812, Reward: -30.1318 [15.64], Avg: -44.0889 (0.031)
Step: 223412, Reward: -2.6229 [1.52], Avg: -43.8581 (0.030)
Step: 225012, Reward: 3.2515 [0.16], Avg: -43.5882 (0.030)
Step: 226612, Reward: 3.4751 [0.52], Avg: -43.3223 (0.029)
Step: 228212, Reward: 3.2754 [0.59], Avg: -43.0609 (0.029)
Step: 229812, Reward: -1.0216 [2.72], Avg: -42.8387 (0.028)
Step: 231412, Reward: 1.7635 [0.26], Avg: -42.5896 (0.027)
Step: 233012, Reward: 1.2230 [0.90], Avg: -42.3499 (0.027)
Step: 234612, Reward: -0.8395 [0.66], Avg: -42.1229 (0.026)
Step: 236212, Reward: 3.8023 [0.26], Avg: -41.8706 (0.026)
Step: 237812, Reward: 1.2622 [2.67], Avg: -41.6483 (0.025)
Step: 239412, Reward: -23.6906 [2.41], Avg: -41.5634 (0.025)
Step: 241012, Reward: 1.1923 [0.97], Avg: -41.3363 (0.024)
Step: 242612, Reward: 2.4671 [3.06], Avg: -41.1160 (0.024)
Step: 244212, Reward: 2.3757 [2.49], Avg: -40.8956 (0.023)
Step: 245812, Reward: 2.4295 [0.87], Avg: -40.6686 (0.023)
Step: 247412, Reward: 3.7643 [0.43], Avg: -40.4345 (0.022)
Step: 249012, Reward: 3.0693 [0.50], Avg: -40.2070 (0.022)
Step: 250612, Reward: 3.4999 [0.17], Avg: -39.9778 (0.022)
Step: 252212, Reward: 1.9874 [0.46], Avg: -39.7605 (0.021)
Step: 253812, Reward: 4.6403 [0.17], Avg: -39.5301 (0.021)
Step: 255412, Reward: 4.7126 [0.22], Avg: -39.3021 (0.020)
Step: 257012, Reward: 5.3172 [0.16], Avg: -39.0729 (0.020)
Step: 258612, Reward: 5.2394 [0.23], Avg: -38.8468 (0.020)
Step: 260212, Reward: 5.4404 [0.31], Avg: -38.6224 (0.020)
Step: 261812, Reward: 6.0400 [0.29], Avg: -38.3972 (0.020)
Step: 263412, Reward: 6.0455 [0.47], Avg: -38.1751 (0.020)
Step: 265012, Reward: 5.7409 [0.35], Avg: -37.9562 (0.020)
Step: 266612, Reward: 5.9691 [0.15], Avg: -37.7373 (0.020)
Step: 268212, Reward: 0.8149 [2.14], Avg: -37.5562 (0.020)
Step: 269812, Reward: 6.1647 [0.35], Avg: -37.3415 (0.020)
Step: 271412, Reward: 5.0185 [0.68], Avg: -37.1362 (0.020)
Step: 273012, Reward: 5.7908 [0.23], Avg: -36.9269 (0.020)
Step: 274612, Reward: 6.3822 [0.56], Avg: -36.7183 (0.020)
Step: 276212, Reward: 6.4306 [0.56], Avg: -36.5116 (0.020)
Step: 277812, Reward: 6.1480 [0.63], Avg: -36.3085 (0.020)
Step: 279412, Reward: 4.2100 [2.14], Avg: -36.1240 (0.020)
Step: 281012, Reward: 6.3180 [0.50], Avg: -35.9233 (0.020)
Step: 282612, Reward: 6.0256 [0.13], Avg: -35.7242 (0.020)
Step: 284212, Reward: -0.6403 [0.47], Avg: -35.5601 (0.020)
Step: 285812, Reward: -4.0420 [0.35], Avg: -35.4131 (0.020)
Step: 287412, Reward: 6.4300 [0.45], Avg: -35.2188 (0.020)
Step: 289012, Reward: -14.3743 [16.13], Avg: -35.1967 (0.020)
Step: 290612, Reward: 3.0950 [0.73], Avg: -35.0220 (0.020)
Step: 292212, Reward: 3.2579 [1.32], Avg: -34.8509 (0.020)
Step: 293812, Reward: 4.7345 [2.61], Avg: -34.6805 (0.020)
Step: 295412, Reward: 6.6478 [0.57], Avg: -34.4936 (0.020)
Step: 297012, Reward: 7.5243 [0.93], Avg: -34.3060 (0.020)
Step: 298612, Reward: 5.2626 [1.53], Avg: -34.1331 (0.020)
Step: 300212, Reward: 6.4376 [1.49], Avg: -33.9562 (0.020)
Step: 301812, Reward: 7.2999 [0.32], Avg: -33.7718 (0.020)
Step: 303412, Reward: 6.5645 [0.83], Avg: -33.5947 (0.020)
Step: 305012, Reward: 7.3064 [0.81], Avg: -33.4157 (0.020)
Step: 306612, Reward: 4.6640 [1.78], Avg: -33.2543 (0.020)
Step: 308212, Reward: -0.1591 [12.13], Avg: -33.1616 (0.020)
Step: 309812, Reward: 1.5141 [0.81], Avg: -33.0124 (0.020)
Step: 311412, Reward: 2.4426 [2.30], Avg: -32.8670 (0.020)
Step: 313012, Reward: 3.0181 [3.73], Avg: -32.7265 (0.020)
Step: 314612, Reward: -2.6753 [9.14], Avg: -32.6356 (0.020)
Step: 316212, Reward: 7.1603 [0.60], Avg: -32.4659 (0.020)
Step: 317812, Reward: 1.9518 [10.07], Avg: -32.3610 (0.020)
Step: 319412, Reward: -4.7130 [8.99], Avg: -32.2809 (0.020)
Step: 321012, Reward: -0.4525 [0.62], Avg: -32.1475 (0.020)
Step: 322612, Reward: 6.5715 [0.25], Avg: -31.9838 (0.020)
Step: 324212, Reward: 6.9909 [0.80], Avg: -31.8221 (0.020)
Step: 325812, Reward: 4.4094 [2.26], Avg: -31.6787 (0.020)
Step: 327412, Reward: 1.0698 [8.36], Avg: -31.5762 (0.020)
Step: 329012, Reward: 4.3441 [0.77], Avg: -31.4292 (0.020)
Step: 330612, Reward: 4.5714 [2.85], Avg: -31.2910 (0.020)
Step: 332212, Reward: 3.2458 [2.60], Avg: -31.1585 (0.020)
Step: 333812, Reward: -1.3964 [4.64], Avg: -31.0547 (0.020)
Step: 335412, Reward: -46.7939 [56.57], Avg: -31.3523 (0.020)
Step: 337012, Reward: -49.4495 [12.76], Avg: -31.4787 (0.020)
Step: 338612, Reward: -0.9233 [2.31], Avg: -31.3634 (0.020)
Step: 340212, Reward: -4.0494 [1.14], Avg: -31.2570 (0.020)
Step: 341812, Reward: 5.7043 [0.34], Avg: -31.1088 (0.020)
Step: 343412, Reward: 0.0355 [3.79], Avg: -30.9985 (0.020)
Step: 345012, Reward: 1.9098 [2.62], Avg: -30.8768 (0.020)
Step: 346612, Reward: -68.9732 [55.29], Avg: -31.2504 (0.020)
Step: 348212, Reward: 1.9785 [0.25], Avg: -31.1190 (0.020)
Step: 349812, Reward: 5.0959 [0.41], Avg: -30.9769 (0.020)
Step: 351412, Reward: 4.9750 [0.35], Avg: -30.8362 (0.020)
Step: 353012, Reward: 3.2856 [0.49], Avg: -30.7038 (0.020)
Step: 354612, Reward: 4.1735 [0.95], Avg: -30.5707 (0.020)
Step: 356212, Reward: -1.5093 [10.12], Avg: -30.4967 (0.020)
Step: 357812, Reward: 4.0434 [1.65], Avg: -30.3687 (0.020)
Step: 359412, Reward: 6.2001 [0.74], Avg: -30.2299 (0.020)
Step: 361012, Reward: 6.0166 [0.72], Avg: -30.0927 (0.020)
Step: 362612, Reward: 6.4788 [0.47], Avg: -29.9539 (0.020)
Step: 364212, Reward: 4.8806 [1.57], Avg: -29.8264 (0.020)
Step: 365812, Reward: 6.3726 [0.29], Avg: -29.6894 (0.020)
Step: 367412, Reward: -12.9443 [38.52], Avg: -29.7722 (0.020)
Step: 369012, Reward: 4.3109 [1.84], Avg: -29.6500 (0.020)
Step: 370612, Reward: 7.1344 [0.71], Avg: -29.5139 (0.020)
Step: 372212, Reward: 7.5067 [0.37], Avg: -29.3761 (0.020)
Step: 373812, Reward: -12.8449 [40.86], Avg: -29.4672 (0.020)
Step: 375412, Reward: 4.3086 [2.70], Avg: -29.3513 (0.020)
Step: 377012, Reward: 5.0459 [0.42], Avg: -29.2250 (0.020)
Step: 378612, Reward: 6.3460 [0.44], Avg: -29.0949 (0.020)
Step: 380212, Reward: 5.3655 [0.39], Avg: -28.9692 (0.020)
Step: 381812, Reward: 5.9928 [2.30], Avg: -28.8491 (0.020)
Step: 383412, Reward: -16.9490 [49.32], Avg: -28.9862 (0.020)
Step: 385012, Reward: 5.8271 [3.32], Avg: -28.8712 (0.020)
Step: 386612, Reward: -12.1496 [42.05], Avg: -28.9633 (0.020)
Step: 388212, Reward: 7.7961 [1.72], Avg: -28.8364 (0.020)
Step: 389812, Reward: -13.0339 [3.08], Avg: -28.7904 (0.020)
Step: 391412, Reward: -7.6939 [15.35], Avg: -28.7697 (0.020)
Step: 393012, Reward: 2.6633 [2.24], Avg: -28.6651 (0.020)
Step: 394612, Reward: 3.8185 [1.33], Avg: -28.5539 (0.020)
Step: 396212, Reward: -3.7107 [0.51], Avg: -28.4673 (0.020)
Step: 397812, Reward: 6.2221 [0.59], Avg: -28.3464 (0.020)
Step: 399412, Reward: 6.1533 [0.64], Avg: -28.2267 (0.020)
Step: 401012, Reward: 5.5559 [1.01], Avg: -28.1113 (0.020)
Step: 402612, Reward: 4.9283 [4.15], Avg: -28.0099 (0.020)
Step: 404212, Reward: 2.4373 [4.85], Avg: -27.9204 (0.020)
Step: 405812, Reward: 6.5468 [1.46], Avg: -27.8054 (0.020)
Step: 407412, Reward: 7.3156 [0.41], Avg: -27.6849 (0.020)
Step: 409012, Reward: 6.8692 [0.12], Avg: -27.5658 (0.020)
Step: 410612, Reward: 7.4710 [0.40], Avg: -27.4463 (0.020)
Step: 412212, Reward: 7.1062 [0.35], Avg: -27.3288 (0.020)
Step: 413812, Reward: 6.8692 [1.31], Avg: -27.2162 (0.020)
Step: 415412, Reward: 8.9165 [1.50], Avg: -27.0980 (0.020)
Step: 417012, Reward: 8.7262 [0.97], Avg: -26.9794 (0.020)
Step: 418612, Reward: 5.0057 [0.78], Avg: -26.8736 (0.020)
Step: 420212, Reward: -42.1016 [56.89], Avg: -27.1173 (0.020)
Step: 421812, Reward: -15.5065 [41.64], Avg: -27.2184 (0.020)
Step: 423412, Reward: -10.4368 [2.97], Avg: -27.1720 (0.020)
Step: 425012, Reward: -90.0825 [42.93], Avg: -27.5260 (0.020)
Step: 425071, Reward: -85.1719 [50.01], Avg: -27.8849 (0.020)
Step: 425148, Reward: -59.9216 [55.30], Avg: -28.1750 (0.020)
Step: 425227, Reward: -32.7350 [43.20], Avg: -28.3332 (0.020)
Step: 426827, Reward: -7.9984 [9.74], Avg: -28.2982 (0.020)
Step: 428427, Reward: -19.2738 [14.19], Avg: -28.3152 (0.020)
Step: 430027, Reward: -6.6583 [7.87], Avg: -28.2700 (0.020)
Step: 431627, Reward: -53.9158 [50.07], Avg: -28.5175 (0.020)
Step: 431732, Reward: -80.8028 [37.92], Avg: -28.8113 (0.020)
Step: 431871, Reward: -70.0815 [55.93], Avg: -29.1269 (0.020)
Step: 431971, Reward: -19.2793 [43.58], Avg: -29.2361 (0.020)
Step: 433571, Reward: -8.1459 [2.74], Avg: -29.1769 (0.020)
Step: 435171, Reward: -5.3324 [2.18], Avg: -29.1072 (0.020)
Step: 436771, Reward: -4.5722 [1.11], Avg: -29.0322 (0.020)
Step: 438371, Reward: -1.9181 [2.55], Avg: -28.9537 (0.020)
Step: 439971, Reward: 1.2130 [2.53], Avg: -28.8657 (0.020)
Step: 441571, Reward: 2.8352 [1.93], Avg: -28.7712 (0.020)
Step: 443171, Reward: -1.8703 [0.29], Avg: -28.6870 (0.020)
Step: 444771, Reward: -2.8885 [0.57], Avg: -28.6074 (0.020)
Step: 446371, Reward: -0.0585 [0.93], Avg: -28.5205 (0.020)
Step: 447971, Reward: 0.6734 [0.75], Avg: -28.4314 (0.020)
Step: 449571, Reward: 4.9990 [0.99], Avg: -28.3300 (0.020)
Step: 451171, Reward: 5.1360 [0.68], Avg: -28.2279 (0.020)
Step: 452771, Reward: 2.9910 [2.54], Avg: -28.1388 (0.020)
Step: 454371, Reward: 3.3783 [1.45], Avg: -28.0457 (0.020)
Step: 455971, Reward: 4.5442 [3.77], Avg: -27.9568 (0.020)
Step: 457571, Reward: 3.3303 [2.11], Avg: -27.8670 (0.020)
Step: 459171, Reward: 5.1823 [0.82], Avg: -27.7681 (0.020)
Step: 460771, Reward: 5.3837 [2.14], Avg: -27.6733 (0.020)
Step: 462371, Reward: 6.7101 [7.78], Avg: -27.5922 (0.020)
Step: 463971, Reward: 3.8290 [1.04], Avg: -27.4998 (0.020)
Step: 465571, Reward: 1.7255 [2.19], Avg: -27.4179 (0.020)
Step: 467171, Reward: -2.7275 [2.49], Avg: -27.3508 (0.020)
Step: 468771, Reward: 0.9011 [2.57], Avg: -27.2734 (0.020)
Step: 470371, Reward: 0.7353 [1.07], Avg: -27.1925 (0.020)
Step: 471971, Reward: 4.6985 [3.37], Avg: -27.1071 (0.020)
Step: 473571, Reward: -9.4997 [1.28], Avg: -27.0584 (0.020)
Step: 475171, Reward: -138.0103 [2.24], Avg: -27.3953 (0.020)
Step: 476771, Reward: -3.7104 [2.33], Avg: -27.3319 (0.020)
Step: 478371, Reward: 0.6341 [1.81], Avg: -27.2545 (0.020)
Step: 479971, Reward: -10.5657 [43.47], Avg: -27.3335 (0.020)
Step: 481571, Reward: -74.4124 [43.84], Avg: -27.6010 (0.020)
Step: 483171, Reward: 4.6701 [4.00], Avg: -27.5181 (0.020)
Step: 484771, Reward: 4.3041 [0.94], Avg: -27.4278 (0.020)
Step: 486371, Reward: 2.9598 [1.15], Avg: -27.3425 (0.020)
Step: 487971, Reward: 5.5700 [1.81], Avg: -27.2521 (0.020)
Step: 489571, Reward: 5.1573 [0.51], Avg: -27.1596 (0.020)
Step: 491171, Reward: 6.7380 [1.86], Avg: -27.0670 (0.020)
Step: 492771, Reward: 8.0979 [0.89], Avg: -26.9682 (0.020)
Step: 494371, Reward: 8.9498 [1.86], Avg: -26.8704 (0.020)
Step: 495971, Reward: 6.7583 [0.92], Avg: -26.7766 (0.020)
Step: 497571, Reward: 10.2926 [1.99], Avg: -26.6764 (0.020)
Step: 499171, Reward: 9.2948 [2.28], Avg: -26.5804 (0.020)
Step: 500771, Reward: 10.4191 [1.19], Avg: -26.4787 (0.020)
Step: 502371, Reward: 9.0844 [2.47], Avg: -26.3849 (0.020)
Step: 503971, Reward: 7.1314 [3.12], Avg: -26.2991 (0.020)
Step: 505571, Reward: 7.0674 [1.73], Avg: -26.2100 (0.020)
Step: 507171, Reward: 6.4363 [1.50], Avg: -26.1225 (0.020)
Step: 508771, Reward: 8.3539 [2.47], Avg: -26.0328 (0.020)
Step: 510371, Reward: 5.9454 [1.32], Avg: -25.9472 (0.020)
Step: 511971, Reward: 4.6825 [4.29], Avg: -25.8738 (0.020)
Step: 513571, Reward: 7.5246 [0.50], Avg: -25.7824 (0.020)
Step: 515171, Reward: 9.6683 [0.85], Avg: -25.6866 (0.020)
Step: 516771, Reward: 10.4792 [1.82], Avg: -25.5917 (0.020)
Step: 518371, Reward: 9.0305 [1.91], Avg: -25.5016 (0.020)
Step: 519971, Reward: 7.8885 [1.24], Avg: -25.4133 (0.020)
Step: 521571, Reward: 8.2061 [2.31], Avg: -25.3275 (0.020)
Step: 523171, Reward: 15.7165 [18.60], Avg: -25.2662 (0.020)
Step: 524771, Reward: 11.6136 [1.67], Avg: -25.1702 (0.020)
Step: 526371, Reward: 10.6506 [1.26], Avg: -25.0763 (0.020)
Step: 527971, Reward: 9.3760 [1.32], Avg: -24.9865 (0.020)
Step: 529571, Reward: 6.8034 [1.71], Avg: -24.9052 (0.020)
Step: 531171, Reward: 9.7474 [1.51], Avg: -24.8159 (0.020)
Step: 532771, Reward: 9.4826 [2.03], Avg: -24.7291 (0.020)
Step: 534371, Reward: 14.0819 [3.40], Avg: -24.6342 (0.020)
Step: 535971, Reward: 18.7004 [13.02], Avg: -24.5531 (0.020)
Step: 537571, Reward: -19.4773 [12.06], Avg: -24.5717 (0.020)
Step: 539171, Reward: 6.5974 [2.59], Avg: -24.4957 (0.020)
Step: 540771, Reward: -9.8704 [13.75], Avg: -24.4934 (0.020)
Step: 542371, Reward: 6.5916 [3.51], Avg: -24.4204 (0.020)
Step: 543971, Reward: 5.6641 [2.26], Avg: -24.3470 (0.020)
Step: 545571, Reward: 3.5937 [6.31], Avg: -24.2901 (0.020)
Step: 547171, Reward: 10.7111 [3.34], Avg: -24.2070 (0.020)
Step: 548771, Reward: 8.3970 [4.57], Avg: -24.1337 (0.020)
Step: 550371, Reward: 10.0779 [1.55], Avg: -24.0484 (0.020)
Step: 551971, Reward: 8.3855 [0.70], Avg: -23.9658 (0.020)
Step: 553571, Reward: 10.8360 [2.44], Avg: -23.8817 (0.020)
Step: 555171, Reward: 4.9922 [0.67], Avg: -23.8086 (0.020)
Step: 556771, Reward: -0.6287 [1.38], Avg: -23.7523 (0.020)
Step: 558371, Reward: 1.7410 [1.93], Avg: -23.6916 (0.020)
Step: 559971, Reward: -1.4966 [2.33], Avg: -23.6405 (0.020)
Step: 561571, Reward: 9.8941 [0.44], Avg: -23.5557 (0.020)
Step: 563171, Reward: 16.1270 [8.90], Avg: -23.4770 (0.020)
Step: 564771, Reward: 4.1467 [1.38], Avg: -23.4100 (0.020)
Step: 566371, Reward: -3.6685 [0.41], Avg: -23.3608 (0.020)
Step: 567971, Reward: 13.4382 [3.84], Avg: -23.2772 (0.020)
Step: 569571, Reward: -76.7510 [36.98], Avg: -23.5062 (0.020)
Step: 569720, Reward: -60.5233 [44.77], Avg: -23.7127 (0.020)
Step: 569847, Reward: -1.6400 [1.11], Avg: -23.6599 (0.020)
Step: 571447, Reward: -10.7518 [13.41], Avg: -23.6612 (0.020)
Step: 573047, Reward: 2.9484 [1.58], Avg: -23.5984 (0.020)
Step: 574647, Reward: 4.6085 [0.41], Avg: -23.5289 (0.020)
Step: 576247, Reward: 1.5140 [4.51], Avg: -23.4777 (0.020)
Step: 577847, Reward: 7.9131 [3.73], Avg: -23.4089 (0.020)
Step: 579447, Reward: 2.1175 [4.53], Avg: -23.3568 (0.020)
Step: 581047, Reward: -23.7292 [1.23], Avg: -23.3608 (0.020)
Step: 582647, Reward: -105.9586 [6.08], Avg: -23.5797 (0.020)
Step: 582782, Reward: -107.8071 [0.78], Avg: -23.7891 (0.020)
Step: 583154, Reward: 4.3516 [0.63], Avg: -23.7215 (0.020)
Step: 584754, Reward: 0.2331 [1.92], Avg: -23.6675 (0.020)
Step: 585475, Reward: -120.6858 [2.29], Avg: -23.9103 (0.020)
Step: 585563, Reward: -23.0536 [35.27], Avg: -23.9942 (0.020)
Step: 587163, Reward: -37.8843 [44.39], Avg: -24.1360 (0.020)
Step: 587413, Reward: -1.1601 [1.19], Avg: -24.0831 (0.020)
Step: 589013, Reward: -14.8134 [6.79], Avg: -24.0772 (0.020)
Step: 590613, Reward: -8.3064 [0.09], Avg: -24.0393 (0.020)
Step: 592213, Reward: -8.0039 [0.75], Avg: -24.0025 (0.020)
Step: 593813, Reward: -6.4194 [0.29], Avg: -23.9609 (0.020)
Step: 595413, Reward: -4.4597 [1.34], Avg: -23.9173 (0.020)
Step: 597013, Reward: -4.6437 [2.16], Avg: -23.8764 (0.020)
Step: 598613, Reward: -6.8941 [3.74], Avg: -23.8448 (0.020)
Step: 600213, Reward: -5.4697 [0.52], Avg: -23.8023 (0.020)
Step: 601813, Reward: -17.2521 [7.23], Avg: -23.8039 (0.020)
Step: 603413, Reward: -6.8632 [5.87], Avg: -23.7777 (0.020)
Step: 605013, Reward: -3.3451 [3.41], Avg: -23.7374 (0.020)
Step: 606613, Reward: -12.3412 [7.44], Avg: -23.7281 (0.020)
Step: 608213, Reward: -4.1791 [0.92], Avg: -23.6842 (0.020)
Step: 609813, Reward: -2.5575 [2.70], Avg: -23.6410 (0.020)
Step: 611413, Reward: -3.3295 [0.72], Avg: -23.5951 (0.020)
Step: 613013, Reward: -3.4149 [0.52], Avg: -23.5492 (0.020)
Step: 614613, Reward: 1.5379 [0.25], Avg: -23.4913 (0.020)
Step: 616213, Reward: 2.0291 [2.40], Avg: -23.4375 (0.020)
Step: 617813, Reward: 3.7640 [0.43], Avg: -23.3754 (0.020)
Step: 619413, Reward: 6.4283 [0.73], Avg: -23.3081 (0.020)
Step: 621013, Reward: 7.1759 [0.52], Avg: -23.2389 (0.020)
Step: 622613, Reward: 4.3843 [5.08], Avg: -23.1870 (0.020)
Step: 624213, Reward: -1.8705 [10.02], Avg: -23.1610 (0.020)
Step: 625813, Reward: 6.0838 [0.70], Avg: -23.0955 (0.020)
Step: 627413, Reward: 5.0134 [0.49], Avg: -23.0323 (0.020)
Step: 629013, Reward: -22.3580 [46.84], Avg: -23.1377 (0.020)
Step: 630613, Reward: 6.4557 [0.14], Avg: -23.0706 (0.020)
Step: 632213, Reward: 3.5881 [1.08], Avg: -23.0125 (0.020)
Step: 633813, Reward: 4.0342 [0.50], Avg: -22.9523 (0.020)
Step: 635413, Reward: 3.1593 [0.15], Avg: -22.8936 (0.020)
Step: 637013, Reward: 5.4105 [0.43], Avg: -22.8306 (0.020)
Step: 638613, Reward: 7.3155 [0.38], Avg: -22.7636 (0.020)
Step: 640213, Reward: 4.4248 [1.49], Avg: -22.7059 (0.020)
Step: 641813, Reward: 6.6237 [1.75], Avg: -22.6440 (0.020)
Step: 643413, Reward: 3.2645 [0.47], Avg: -22.5871 (0.020)
Step: 645013, Reward: 4.6713 [0.30], Avg: -22.5269 (0.020)
Step: 646613, Reward: 6.8137 [0.61], Avg: -22.4629 (0.020)
Step: 648213, Reward: 4.6998 [0.81], Avg: -22.4044 (0.020)
Step: 649813, Reward: 6.0991 [0.33], Avg: -22.3419 (0.020)
Step: 651413, Reward: 6.4337 [0.35], Avg: -22.2790 (0.020)
Step: 653013, Reward: 2.2105 [4.99], Avg: -22.2360 (0.020)
Step: 654613, Reward: 2.4897 [5.50], Avg: -22.1936 (0.020)
Step: 656213, Reward: 7.8245 [0.68], Avg: -22.1292 (0.020)
Step: 657813, Reward: 6.8272 [0.65], Avg: -22.0671 (0.020)
Step: 659413, Reward: 8.3569 [0.46], Avg: -22.0015 (0.020)
Step: 661013, Reward: 6.1388 [1.26], Avg: -21.9428 (0.020)
Step: 662613, Reward: 11.4098 [2.99], Avg: -21.8767 (0.020)
Step: 664213, Reward: 6.7411 [5.94], Avg: -21.8274 (0.020)
Step: 665813, Reward: 1.8465 [3.58], Avg: -21.7838 (0.020)
Step: 667413, Reward: 2.9227 [0.68], Avg: -21.7318 (0.020)
Step: 669013, Reward: 5.3611 [0.53], Avg: -21.6745 (0.020)
Step: 670613, Reward: 4.9438 [4.71], Avg: -21.6272 (0.020)
Step: 672213, Reward: 6.6438 [0.65], Avg: -21.5678 (0.020)
Step: 673813, Reward: 5.7394 [0.50], Avg: -21.5103 (0.020)
Step: 675413, Reward: 4.4464 [2.15], Avg: -21.4593 (0.020)
Step: 677013, Reward: 5.0715 [0.83], Avg: -21.4044 (0.020)
Step: 678613, Reward: 11.1730 [4.48], Avg: -21.3445 (0.020)
Step: 678750, Reward: 6.5238 [0.81], Avg: -21.2869 (0.020)
Step: 680350, Reward: 2.1843 [1.18], Avg: -21.2396 (0.020)
Step: 681950, Reward: 5.1858 [0.82], Avg: -21.1853 (0.020)
Step: 683550, Reward: 5.8081 [2.52], Avg: -21.1336 (0.020)
Step: 685150, Reward: 3.6690 [4.46], Avg: -21.0907 (0.020)
Step: 686750, Reward: 1.9859 [4.84], Avg: -21.0523 (0.020)
Step: 688350, Reward: 1.2509 [0.49], Avg: -21.0065 (0.020)
Step: 689950, Reward: -10.4061 [1.39], Avg: -20.9872 (0.020)
Step: 691550, Reward: 1.8644 [0.32], Avg: -20.9400 (0.020)
Step: 693150, Reward: -1.0088 [1.95], Avg: -20.9025 (0.020)
Step: 694750, Reward: -4.3250 [6.84], Avg: -20.8822 (0.020)
Step: 696350, Reward: -2.7776 [4.15], Avg: -20.8532 (0.020)
Step: 697950, Reward: 2.5879 [0.98], Avg: -20.8066 (0.020)
Step: 699550, Reward: -1.9745 [2.26], Avg: -20.7723 (0.020)
Step: 701150, Reward: 3.0181 [0.26], Avg: -20.7237 (0.020)
Step: 702750, Reward: -18.1690 [44.29], Avg: -20.8097 (0.020)
Step: 704350, Reward: -6.0419 [1.78], Avg: -20.7830 (0.020)
Step: 705950, Reward: -3.2004 [2.42], Avg: -20.7519 (0.020)
Step: 706097, Reward: -7.4976 [1.27], Avg: -20.7273 (0.020)
Step: 707697, Reward: -2.4831 [9.50], Avg: -20.7094 (0.020)
Step: 707818, Reward: -7.1386 [11.89], Avg: -20.7060 (0.020)
Step: 709418, Reward: -8.6000 [5.95], Avg: -20.6934 (0.020)
Step: 711018, Reward: -15.9692 [1.47], Avg: -20.6868 (0.020)
Step: 712618, Reward: 3.5072 [6.36], Avg: -20.6507 (0.020)
Step: 714218, Reward: 3.3693 [6.35], Avg: -20.6149 (0.020)
Step: 715818, Reward: -10.0692 [6.61], Avg: -20.6069 (0.020)
Step: 717418, Reward: -114.8213 [2.01], Avg: -20.8009 (0.020)
Step: 719018, Reward: -3.3896 [1.12], Avg: -20.7682 (0.020)
Step: 720618, Reward: -49.5635 [2.47], Avg: -20.8309 (0.020)
Step: 722218, Reward: -0.8582 [0.54], Avg: -20.7920 (0.020)
Step: 723818, Reward: -2.1741 [0.44], Avg: -20.7556 (0.020)
Step: 725418, Reward: 0.1053 [0.63], Avg: -20.7152 (0.020)
Step: 727018, Reward: 2.2642 [1.46], Avg: -20.6724 (0.020)
Step: 728618, Reward: 0.0654 [1.35], Avg: -20.6338 (0.020)
Step: 730218, Reward: -2.7584 [1.51], Avg: -20.6013 (0.020)
Step: 731818, Reward: -5.4588 [0.55], Avg: -20.5725 (0.020)
Step: 733418, Reward: 2.4340 [7.60], Avg: -20.5420 (0.020)
Step: 735018, Reward: 1.9792 [1.96], Avg: -20.5015 (0.020)
Step: 736618, Reward: 7.7961 [3.10], Avg: -20.4519 (0.020)
Step: 738218, Reward: 1.4881 [1.73], Avg: -20.4121 (0.020)
Step: 739818, Reward: -0.7396 [3.45], Avg: -20.3803 (0.020)
Step: 741418, Reward: -1.9606 [1.48], Avg: -20.3472 (0.020)
Step: 743018, Reward: 2.2631 [2.34], Avg: -20.3076 (0.020)
Step: 744618, Reward: 3.5413 [1.47], Avg: -20.2640 (0.020)
Step: 746218, Reward: -3.7306 [1.52], Avg: -20.2348 (0.020)
Step: 747818, Reward: 5.2618 [1.57], Avg: -20.1883 (0.020)
Step: 749418, Reward: 6.4804 [1.43], Avg: -20.1394 (0.020)
Step: 751018, Reward: 9.9142 [1.73], Avg: -20.0846 (0.020)
Step: 752618, Reward: 11.6369 [1.52], Avg: -20.0263 (0.020)
Step: 754218, Reward: -60.2128 [55.92], Avg: -20.2115 (0.020)
Step: 754386, Reward: -13.9541 [42.56], Avg: -20.2813 (0.020)
Step: 755986, Reward: 4.4540 [0.97], Avg: -20.2357 (0.020)
Step: 757586, Reward: 2.8503 [1.00], Avg: -20.1934 (0.020)
Step: 759186, Reward: -22.5999 [7.08], Avg: -20.2115 (0.020)
Step: 760786, Reward: -77.5002 [38.87], Avg: -20.3950 (0.020)
Step: 760884, Reward: -98.6483 [0.70], Avg: -20.5454 (0.020)
Step: 760987, Reward: -101.4214 [1.48], Avg: -20.7020 (0.020)
Step: 761058, Reward: -97.1920 [0.56], Avg: -20.8482 (0.020)
Step: 761119, Reward: -98.3060 [0.37], Avg: -20.9956 (0.020)
Step: 761177, Reward: -98.8876 [0.57], Avg: -21.1439 (0.020)
Step: 761243, Reward: -98.0172 [0.30], Avg: -21.2895 (0.020)
Step: 761311, Reward: -96.9361 [0.20], Avg: -21.4324 (0.020)
Step: 761387, Reward: -97.9954 [0.47], Avg: -21.5772 (0.020)
Step: 761462, Reward: -96.5142 [1.15], Avg: -21.7199 (0.020)
Step: 761567, Reward: -98.1607 [1.33], Avg: -21.8655 (0.020)
Step: 761654, Reward: -97.9206 [0.50], Avg: -22.0086 (0.020)
Step: 761745, Reward: -97.8410 [0.61], Avg: -22.1512 (0.020)
Step: 761832, Reward: -98.7429 [0.60], Avg: -22.2950 (0.020)
Step: 761944, Reward: -97.6477 [0.67], Avg: -22.4363 (0.020)
Step: 762051, Reward: -97.7658 [0.62], Avg: -22.5772 (0.020)
Step: 762179, Reward: -98.2725 [1.19], Avg: -22.7196 (0.020)
Step: 762294, Reward: -98.4811 [0.21], Avg: -22.8600 (0.020)
Step: 762401, Reward: -37.5142 [50.23], Avg: -22.9797 (0.020)
Step: 764001, Reward: -68.4897 [62.13], Avg: -23.1779 (0.020)
Step: 764132, Reward: -40.8438 [61.83], Avg: -23.3241 (0.020)
Step: 765732, Reward: 0.9553 [0.15], Avg: -23.2798 (0.020)
Step: 767332, Reward: 2.6416 [4.04], Avg: -23.2397 (0.020)
Step: 768932, Reward: 0.1298 [0.40], Avg: -23.1977 (0.020)
Step: 770532, Reward: 2.3379 [1.39], Avg: -23.1536 (0.020)
Step: 772132, Reward: 4.4951 [2.73], Avg: -23.1083 (0.020)
Step: 773732, Reward: 4.3367 [2.92], Avg: -23.0637 (0.020)
Step: 775332, Reward: 0.0811 [0.22], Avg: -23.0221 (0.020)
Step: 776932, Reward: 1.1705 [1.68], Avg: -22.9813 (0.020)
Step: 778532, Reward: -5.3475 [2.28], Avg: -22.9535 (0.020)
Step: 780132, Reward: 1.1158 [1.85], Avg: -22.9134 (0.020)
Step: 781732, Reward: 5.1388 [2.25], Avg: -22.8669 (0.020)
Step: 783332, Reward: -2.2949 [3.44], Avg: -22.8361 (0.020)
Step: 783444, Reward: 6.3926 [1.57], Avg: -22.7864 (0.020)
Step: 785044, Reward: -3.8081 [3.23], Avg: -22.7582 (0.020)
Step: 786644, Reward: 5.2243 [2.00], Avg: -22.7117 (0.020)
Step: 788244, Reward: 5.5866 [3.39], Avg: -22.6673 (0.020)
Step: 789844, Reward: 3.6755 [4.50], Avg: -22.6283 (0.020)
Step: 791444, Reward: -3.7892 [5.56], Avg: -22.6047 (0.020)
Step: 793044, Reward: -47.1447 [47.78], Avg: -22.7332 (0.020)
Step: 794644, Reward: -48.1385 [61.93], Avg: -22.8880 (0.020)
Step: 796244, Reward: -0.6927 [2.83], Avg: -22.8537 (0.020)
Step: 797844, Reward: 4.3282 [1.98], Avg: -22.8092 (0.020)
Step: 799444, Reward: 6.3922 [0.84], Avg: -22.7592 (0.020)
Step: 801044, Reward: 4.6571 [5.60], Avg: -22.7208 (0.020)
Step: 802644, Reward: 14.7792 [5.86], Avg: -22.6652 (0.020)
Step: 804244, Reward: 8.2565 [7.85], Avg: -22.6247 (0.020)
Step: 805844, Reward: 0.7215 [0.67], Avg: -22.5850 (0.020)
Step: 807444, Reward: -0.9285 [1.96], Avg: -22.5505 (0.020)
Step: 809044, Reward: 1.3494 [4.20], Avg: -22.5162 (0.020)
Step: 810644, Reward: 8.4378 [3.27], Avg: -22.4679 (0.020)
Step: 812244, Reward: 10.1248 [3.13], Avg: -22.4167 (0.020)
Step: 813844, Reward: 7.9081 [3.35], Avg: -22.3699 (0.020)
Step: 815444, Reward: 12.9604 [3.93], Avg: -22.3155 (0.020)
Step: 817044, Reward: 5.0394 [2.47], Avg: -22.2724 (0.020)
Step: 818644, Reward: 10.2925 [2.64], Avg: -22.2207 (0.020)
Step: 820244, Reward: 9.2796 [3.22], Avg: -22.1720 (0.020)
Step: 821844, Reward: 11.1069 [2.24], Avg: -22.1185 (0.020)
Step: 823444, Reward: 12.8458 [5.33], Avg: -22.0676 (0.020)
Step: 825044, Reward: 1.2525 [2.53], Avg: -22.0320 (0.020)
Step: 826644, Reward: 3.7252 [0.61], Avg: -21.9889 (0.020)
Step: 828244, Reward: 4.6441 [3.34], Avg: -21.9491 (0.020)
Step: 829844, Reward: 2.9354 [1.39], Avg: -21.9090 (0.020)
Step: 831444, Reward: 7.2519 [2.52], Avg: -21.8636 (0.020)
Step: 833044, Reward: 5.9862 [3.23], Avg: -21.8217 (0.020)
Step: 834644, Reward: 13.0090 [5.83], Avg: -21.7725 (0.020)
Step: 836244, Reward: 4.7355 [3.10], Avg: -21.7328 (0.020)
Step: 837844, Reward: -83.8344 [43.10], Avg: -21.9108 (0.020)
Step: 837933, Reward: -89.9753 [43.26], Avg: -22.0989 (0.020)
Step: 838046, Reward: -39.2403 [57.41], Avg: -22.2246 (0.020)
Step: 839646, Reward: -13.4271 [4.12], Avg: -22.2167 (0.020)
Step: 841246, Reward: -2.7004 [3.85], Avg: -22.1904 (0.020)
Step: 842846, Reward: 12.9800 [6.75], Avg: -22.1427 (0.020)
Step: 844446, Reward: 6.6980 [2.27], Avg: -22.0982 (0.020)
Step: 846046, Reward: -8.9233 [0.74], Avg: -22.0774 (0.020)
Step: 847646, Reward: -5.3074 [1.53], Avg: -22.0519 (0.020)
Step: 849246, Reward: 0.0145 [0.72], Avg: -22.0163 (0.020)
Step: 850846, Reward: -1.4173 [0.39], Avg: -21.9827 (0.020)
Step: 852446, Reward: -3.6297 [0.65], Avg: -21.9533 (0.020)
Step: 854046, Reward: -2.7075 [0.15], Avg: -21.9216 (0.020)
Step: 855646, Reward: -0.2802 [0.29], Avg: -21.8863 (0.020)
Step: 857246, Reward: -3.7198 [0.96], Avg: -21.8579 (0.020)
Step: 858846, Reward: -17.9956 [9.95], Avg: -21.8679 (0.020)
Step: 860446, Reward: 5.3757 [2.07], Avg: -21.8264 (0.020)
Step: 862046, Reward: 0.1593 [2.04], Avg: -21.7936 (0.020)
Step: 863646, Reward: -1.7050 [2.20], Avg: -21.7643 (0.020)
Step: 865246, Reward: -1.8876 [1.92], Avg: -21.7348 (0.020)
Step: 866846, Reward: -23.6263 [39.95], Avg: -21.8033 (0.020)
Step: 868446, Reward: 2.9544 [5.23], Avg: -21.7714 (0.020)
Step: 870046, Reward: -2.0662 [11.43], Avg: -21.7579 (0.020)
Step: 871646, Reward: -29.0317 [32.24], Avg: -21.8222 (0.020)
Step: 873246, Reward: 3.6530 [6.32], Avg: -21.7911 (0.020)
Step: 873439, Reward: -9.8828 [35.60], Avg: -21.8295 (0.020)
Step: 875039, Reward: -23.4773 [41.35], Avg: -21.8992 (0.020)
Step: 876639, Reward: -23.1113 [35.89], Avg: -21.9593 (0.020)
Step: 876780, Reward: -62.9750 [50.42], Avg: -22.1070 (0.020)
Step: 877110, Reward: -23.6060 [48.89], Avg: -22.1883 (0.020)
Step: 877326, Reward: -124.1327 [2.61], Avg: -22.3566 (0.020)
Step: 877396, Reward: -119.9904 [1.77], Avg: -22.5164 (0.020)
Step: 877464, Reward: -52.8528 [51.33], Avg: -22.6475 (0.020)
Step: 879064, Reward: -9.4188 [1.47], Avg: -22.6287 (0.020)
Step: 880664, Reward: -38.8315 [29.41], Avg: -22.7017 (0.020)
Step: 882264, Reward: -11.7179 [2.45], Avg: -22.6880 (0.020)
Step: 883864, Reward: -2.6414 [1.59], Avg: -22.6586 (0.020)
Step: 885464, Reward: -9.2244 [2.54], Avg: -22.6413 (0.020)
Step: 887064, Reward: -0.2595 [5.59], Avg: -22.6146 (0.020)
Step: 888664, Reward: 1.2141 [7.04], Avg: -22.5879 (0.020)
Step: 890264, Reward: -5.0014 [6.96], Avg: -22.5711 (0.020)
Step: 891864, Reward: 7.1953 [5.46], Avg: -22.5326 (0.020)
Step: 893464, Reward: -2.1917 [5.10], Avg: -22.5085 (0.020)
Step: 895064, Reward: -18.5111 [32.32], Avg: -22.5532 (0.020)
Step: 896664, Reward: 5.5788 [8.26], Avg: -22.5219 (0.020)
Step: 898264, Reward: -2.5700 [2.00], Avg: -22.4937 (0.020)
Step: 899864, Reward: -53.2750 [0.65], Avg: -22.5430 (0.020)
Step: 901464, Reward: -78.7746 [59.12], Avg: -22.7239 (0.020)
Step: 903064, Reward: -0.8528 [7.92], Avg: -22.7020 (0.020)
Step: 904664, Reward: -2.4511 [2.86], Avg: -22.6748 (0.020)
Step: 906264, Reward: 1.1073 [2.65], Avg: -22.6419 (0.020)
Step: 907864, Reward: 5.6673 [5.10], Avg: -22.6057 (0.020)
Step: 909464, Reward: -0.6240 [5.08], Avg: -22.5794 (0.020)
Step: 911064, Reward: -3.4803 [11.66], Avg: -22.5679 (0.020)
Step: 912664, Reward: -10.5827 [0.77], Avg: -22.5505 (0.020)
Step: 914264, Reward: -17.4529 [0.72], Avg: -22.5437 (0.020)
Step: 915864, Reward: -3.3188 [1.95], Avg: -22.5170 (0.020)
Step: 917464, Reward: 0.6160 [7.01], Avg: -22.4921 (0.020)
Step: 919064, Reward: 8.6690 [3.68], Avg: -22.4498 (0.020)
Step: 920664, Reward: 6.6024 [2.94], Avg: -22.4096 (0.020)
Step: 922264, Reward: 3.5770 [2.85], Avg: -22.3741 (0.020)
Step: 923864, Reward: 4.2956 [2.79], Avg: -22.3374 (0.020)
Step: 925464, Reward: 13.9702 [6.58], Avg: -22.2919 (0.020)
Step: 927064, Reward: 26.2885 [10.70], Avg: -22.2340 (0.020)
Step: 928664, Reward: 7.7348 [5.40], Avg: -22.1965 (0.020)
Step: 930264, Reward: 11.1452 [2.66], Avg: -22.1497 (0.020)
Step: 931864, Reward: 15.1050 [3.83], Avg: -22.0988 (0.020)
Step: 933464, Reward: 14.2414 [2.23], Avg: -22.0470 (0.020)
Step: 935064, Reward: 9.1030 [3.88], Avg: -22.0056 (0.020)
Step: 936664, Reward: 9.8774 [3.31], Avg: -21.9623 (0.020)
Step: 938264, Reward: -10.8784 [37.67], Avg: -22.0026 (0.020)
Step: 939864, Reward: 9.7103 [1.45], Avg: -21.9568 (0.020)
Step: 941464, Reward: 8.5234 [2.78], Avg: -21.9151 (0.020)
Step: 943064, Reward: 7.6977 [1.29], Avg: -21.8724 (0.020)
Step: 944664, Reward: 9.9703 [2.21], Avg: -21.8279 (0.020)
Step: 946264, Reward: 7.9719 [0.55], Avg: -21.7839 (0.020)
Step: 947864, Reward: 2.6738 [8.18], Avg: -21.7595 (0.020)
Step: 949464, Reward: 9.3026 [5.26], Avg: -21.7209 (0.020)
Step: 951064, Reward: -2.4229 [5.76], Avg: -21.7007 (0.020)
Step: 952664, Reward: 3.7536 [3.15], Avg: -21.6674 (0.020)
Step: 954264, Reward: 4.7617 [4.94], Avg: -21.6353 (0.020)
Step: 955864, Reward: 5.9174 [0.83], Avg: -21.5956 (0.020)
Step: 957464, Reward: -0.8398 [4.70], Avg: -21.5717 (0.020)
Step: 959064, Reward: -2.0726 [3.12], Avg: -21.5474 (0.020)
Step: 960664, Reward: -8.6168 [2.80], Avg: -21.5324 (0.020)
Step: 962264, Reward: 15.4378 [2.68], Avg: -21.4817 (0.020)
Step: 963864, Reward: 16.4403 [2.53], Avg: -21.4294 (0.020)
Step: 965464, Reward: 5.9627 [4.07], Avg: -21.3950 (0.020)
Step: 967064, Reward: 9.0252 [2.68], Avg: -21.3541 (0.020)
Step: 968664, Reward: -2.0088 [1.28], Avg: -21.3276 (0.020)
Step: 970264, Reward: 7.3032 [2.08], Avg: -21.2886 (0.020)
Step: 971864, Reward: -82.1422 [10.63], Avg: -21.3934 (0.020)
Step: 973464, Reward: -11.6125 [15.23], Avg: -21.4014 (0.020)
Step: 975064, Reward: -31.2398 [23.53], Avg: -21.4502 (0.020)
Step: 976664, Reward: -35.7447 [4.40], Avg: -21.4775 (0.020)
Step: 978264, Reward: -12.1108 [15.17], Avg: -21.4859 (0.020)
Step: 979864, Reward: -37.0012 [5.34], Avg: -21.5163 (0.020)
Step: 981464, Reward: 5.6744 [5.72], Avg: -21.4851 (0.020)
Step: 983064, Reward: 17.4656 [8.04], Avg: -21.4402 (0.020)
Step: 984664, Reward: -2.2440 [2.34], Avg: -21.4158 (0.020)
Step: 986264, Reward: 3.5858 [3.00], Avg: -21.3840 (0.020)
Step: 987864, Reward: 15.8318 [6.53], Avg: -21.3396 (0.020)
Step: 989464, Reward: 9.1180 [5.71], Avg: -21.3039 (0.020)
Step: 991064, Reward: 16.0355 [5.29], Avg: -21.2577 (0.020)
Step: 992664, Reward: 11.8608 [3.92], Avg: -21.2157 (0.020)
Step: 994264, Reward: 13.9941 [3.88], Avg: -21.1707 (0.020)
Step: 995864, Reward: 13.5286 [3.14], Avg: -21.1254 (0.020)
Step: 997464, Reward: 8.9831 [2.21], Avg: -21.0854 (0.020)
Step: 999064, Reward: 5.8139 [3.22], Avg: -21.0516 (0.020)
