Model: <class 'models.ddpg.DDPGAgent'>, Dir: BipedalWalkerHardcore-v2
num_envs: 16, state_size: (24,), action_size: (4,), action_space: Box(4,),

import os
import math
import torch
import random
import numpy as np
from models.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, EPS_DECAY, REPLAY_BATCH_SIZE

class DDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		state = self.layer3(state).relu() 
		action_mu = self.action_mu(state)
		action_sig = self.action_sig(state).exp()
		epsilon = torch.randn_like(action_sig)
		action = action_mu + epsilon.mul(action_sig) if sample else action_mu
		return action.tanh()
	
class DDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.net_state = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.net_action = torch.nn.Linear(*action_size, INPUT_LAYER)
		self.net_layer1 = torch.nn.Linear(2*INPUT_LAYER, CRITIC_HIDDEN)
		self.net_layer2 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = self.net_state(state).relu()
		net_action = self.net_action(action).relu()
		net_layer = torch.cat([state, net_action], dim=-1)
		net_layer = self.net_layer1(net_layer).relu()
		net_layer = self.net_layer2(net_layer).relu()
		q_value = self.q_value(net_layer)
		return q_value

class DDPGNetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None): 
		super().__init__(state_size, action_size, DDPGActor, DDPGCritic, lr=lr, gpu=gpu, load=load)

	def get_action(self, state, use_target=False, numpy=True, sample=True):
		with torch.no_grad():
			actor = self.actor_local if not use_target else self.actor_target
			return actor(state, sample).cpu().numpy() if numpy else actor(state, sample)

	def get_q_value(self, state, action, use_target=False, numpy=True):
		with torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			return critic(state, action).cpu().numpy() if numpy else critic(state, action)
	
	def optimize(self, states, actions, q_targets, importances=1):
		q_values = self.critic_local(states, actions)
		critic_error = q_values - q_targets.detach()
		critic_loss = importances.to(self.device) * critic_error.pow(2)
		self.step(self.critic_optimizer, critic_loss.mean())

		q_actions = self.critic_local(states, self.actor_local(states))
		actor_loss = -(q_actions - q_values.detach())
		self.step(self.actor_optimizer, actor_loss.mean())
		
		self.soft_copy(self.actor_local, self.actor_target)
		self.soft_copy(self.critic_local, self.critic_target)
		return critic_error.cpu().detach().numpy().squeeze(-1)
	
	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ddpg", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ddpg", dirname, name)

class DDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, decay=EPS_DECAY, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, DDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True, e_greedy=False):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if e_greedy and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), sample=sample)
		action = action_greedy if e_greedy else np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if done[0] or len(self.buffer) >= self.update_freq:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			next_state = self.to_tensor(next_state)
			next_action = self.network.get_action(next_state, use_target=True, numpy=False)
			values = self.network.get_q_value(states, actions, use_target=True, numpy=False)
			next_value = self.network.get_q_value(next_state, next_action, use_target=True, numpy=False)
			targets, _ = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values)
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states, actions, targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=False)	
		if len(self.replay_buffer) > 0:
			(states, actions, targets), indices, importances = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)
			errors = self.network.optimize(states, actions, targets, importances**(1-self.eps))
			self.replay_buffer.update_priorities(indices, errors)
			if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[7]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class AsyncAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = AsyncAgent(envs.state_size, envs.action_size, num_envs, model)
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.stack.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0]:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 233, Reward: -113.4600 [8.76], Avg: -122.2190 (0.980)
Step: 405, Reward: -114.3189 [9.60], Avg: -123.0692 (0.960)
Step: 444, Reward: -112.7116 [3.43], Avg: -120.7587 (0.941)
Step: 875, Reward: -107.6340 [7.26], Avg: -119.2927 (0.922)
Step: 946, Reward: -103.6779 [5.49], Avg: -117.2680 (0.904)
Step: 1018, Reward: -114.4804 [3.90], Avg: -117.4539 (0.886)
Step: 1084, Reward: -112.8433 [4.53], Avg: -117.4428 (0.868)
Step: 1217, Reward: -112.4915 [12.63], Avg: -118.4022 (0.851)
Step: 1281, Reward: -109.7594 [4.72], Avg: -117.9660 (0.834)
Step: 1371, Reward: -112.9004 [5.26], Avg: -117.9855 (0.817)
Step: 1503, Reward: -102.0337 [6.79], Avg: -117.1523 (0.801)
Step: 1645, Reward: -110.0210 [11.54], Avg: -117.5200 (0.785)
Step: 1790, Reward: -106.8008 [12.21], Avg: -117.6349 (0.769)
Step: 1956, Reward: -106.8408 [6.29], Avg: -117.3134 (0.754)
Step: 2026, Reward: -103.6058 [2.92], Avg: -116.5942 (0.739)
Step: 2112, Reward: -112.2912 [9.15], Avg: -116.8968 (0.724)
Step: 2176, Reward: -105.6032 [5.27], Avg: -116.5423 (0.709)
Step: 2264, Reward: -105.3075 [5.92], Avg: -116.2473 (0.695)
Step: 2383, Reward: -106.7008 [8.69], Avg: -116.2021 (0.681)
Step: 2458, Reward: -101.3241 [2.14], Avg: -115.5652 (0.668)
Step: 2601, Reward: -101.2075 [3.81], Avg: -115.0631 (0.654)
Step: 2668, Reward: -101.3215 [2.03], Avg: -114.5308 (0.641)
Step: 2764, Reward: -105.3293 [11.45], Avg: -114.6286 (0.628)
Step: 2839, Reward: -104.7576 [6.18], Avg: -114.4749 (0.616)
Step: 2907, Reward: -101.5346 [2.88], Avg: -114.0727 (0.603)
Step: 2984, Reward: -100.1243 [1.36], Avg: -113.5883 (0.591)
Step: 3034, Reward: -100.3251 [1.85], Avg: -113.1655 (0.580)
Step: 3095, Reward: -112.4186 [12.79], Avg: -113.5954 (0.568)
Step: 3158, Reward: -101.0504 [3.98], Avg: -113.3001 (0.557)
Step: 3206, Reward: -99.9819 [1.70], Avg: -112.9129 (0.545)
Step: 3270, Reward: -111.9390 [15.87], Avg: -113.3934 (0.535)
Step: 3321, Reward: -98.8590 [1.37], Avg: -112.9821 (0.524)
Step: 3398, Reward: -106.9453 [13.29], Avg: -113.2019 (0.513)
Step: 3449, Reward: -100.2757 [2.68], Avg: -112.9007 (0.503)
Step: 3593, Reward: -100.3634 [2.74], Avg: -112.6207 (0.493)
Step: 3654, Reward: -101.0760 [2.98], Avg: -112.3829 (0.483)
Step: 3750, Reward: -101.9768 [1.51], Avg: -112.1425 (0.474)
Step: 3798, Reward: -99.8662 [2.79], Avg: -111.8928 (0.464)
Step: 3862, Reward: -99.8252 [0.88], Avg: -111.6060 (0.455)
Step: 3931, Reward: -100.7494 [0.70], Avg: -111.3522 (0.446)
Step: 3992, Reward: -100.5901 [1.12], Avg: -111.1170 (0.437)
Step: 4056, Reward: -100.2421 [0.60], Avg: -110.8725 (0.428)
Step: 4139, Reward: -99.7265 [1.14], Avg: -110.6398 (0.419)
Step: 4201, Reward: -99.7910 [0.41], Avg: -110.4026 (0.411)
Step: 4264, Reward: -99.8173 [0.39], Avg: -110.1760 (0.403)
Step: 4311, Reward: -100.9668 [2.35], Avg: -110.0269 (0.395)
Step: 4372, Reward: -101.4640 [2.25], Avg: -109.8926 (0.387)
Step: 4432, Reward: -101.6186 [2.59], Avg: -109.7742 (0.379)
Step: 4478, Reward: -102.5492 [2.70], Avg: -109.6819 (0.372)
Step: 4527, Reward: -117.8449 [12.03], Avg: -110.0857 (0.364)
Step: 4666, Reward: -115.7896 [16.84], Avg: -110.5278 (0.357)
Step: 4799, Reward: -125.1289 [19.18], Avg: -111.1775 (0.350)
Step: 5018, Reward: -107.3032 [9.98], Avg: -111.2927 (0.343)
Step: 5124, Reward: -121.1998 [22.86], Avg: -111.8994 (0.336)
Step: 6471, Reward: -144.1952 [18.32], Avg: -112.8197 (0.329)
Step: 8471, Reward: -124.7950 [5.44], Avg: -113.1306 (0.323)
Step: 10471, Reward: -114.7315 [20.46], Avg: -113.5177 (0.316)
Step: 12471, Reward: -123.1390 [17.45], Avg: -113.9845 (0.310)
Step: 12577, Reward: -113.6492 [8.80], Avg: -114.1280 (0.304)
Step: 12633, Reward: -119.3937 [5.96], Avg: -114.3150 (0.298)
Step: 12714, Reward: -118.2121 [3.75], Avg: -114.4404 (0.292)
Step: 14714, Reward: -100.7257 [2.31], Avg: -114.2564 (0.286)
Step: 14869, Reward: -98.2479 [0.44], Avg: -114.0092 (0.280)
Step: 16869, Reward: -98.3409 [6.00], Avg: -113.8582 (0.274)
Step: 18869, Reward: -78.2575 [27.61], Avg: -113.7352 (0.269)
Step: 20869, Reward: -72.0431 [34.04], Avg: -113.6193 (0.264)
Step: 22869, Reward: -68.9746 [42.78], Avg: -113.5915 (0.258)
Step: 22943, Reward: -57.3868 [35.24], Avg: -113.2832 (0.253)
Step: 23039, Reward: -67.6793 [22.50], Avg: -112.9484 (0.248)
Step: 25039, Reward: -103.0148 [17.95], Avg: -113.0630 (0.243)
Step: 25110, Reward: -71.6915 [33.98], Avg: -112.9589 (0.238)
Step: 25214, Reward: -69.6130 [24.05], Avg: -112.6908 (0.233)
Step: 27214, Reward: -33.6075 [3.81], Avg: -111.6597 (0.229)
Step: 29214, Reward: -38.7289 [9.22], Avg: -110.7988 (0.224)
Step: 31214, Reward: -23.0595 [2.61], Avg: -109.6637 (0.220)
Step: 33214, Reward: -23.8919 [3.62], Avg: -108.5827 (0.215)
Step: 35214, Reward: -28.7040 [5.31], Avg: -107.6143 (0.211)
Step: 37214, Reward: -18.3612 [4.61], Avg: -106.5292 (0.207)
Step: 39214, Reward: -24.5320 [4.15], Avg: -105.5437 (0.203)
Step: 41214, Reward: -21.8228 [6.41], Avg: -104.5773 (0.199)
Step: 43214, Reward: -30.1690 [32.86], Avg: -104.0644 (0.195)
Step: 43322, Reward: -64.6289 [39.51], Avg: -104.0653 (0.191)
Step: 45322, Reward: -21.3648 [1.95], Avg: -103.0923 (0.187)
Step: 47322, Reward: -19.7414 [1.72], Avg: -102.1205 (0.183)
Step: 49322, Reward: -12.8120 [2.74], Avg: -101.1021 (0.180)
Step: 51322, Reward: -15.0805 [2.42], Avg: -100.1299 (0.176)
Step: 53322, Reward: -15.3938 [3.10], Avg: -99.1916 (0.172)
Step: 55322, Reward: -57.2092 [40.70], Avg: -99.1771 (0.169)
Step: 57322, Reward: -13.2713 [2.27], Avg: -98.2373 (0.166)
Step: 59322, Reward: -14.8819 [2.49], Avg: -97.3388 (0.162)
Step: 61322, Reward: -16.3981 [3.48], Avg: -96.4876 (0.159)
Step: 63322, Reward: -14.9066 [2.24], Avg: -95.6252 (0.156)
Step: 65322, Reward: -10.4427 [1.13], Avg: -94.7214 (0.153)
Step: 67322, Reward: -8.7286 [0.91], Avg: -93.8163 (0.150)
Step: 69322, Reward: -11.8371 [3.47], Avg: -92.9899 (0.147)
Step: 71322, Reward: -10.1766 [2.55], Avg: -92.1538 (0.144)
Step: 73322, Reward: -6.3590 [2.65], Avg: -91.2966 (0.141)
Step: 75322, Reward: -7.4319 [0.59], Avg: -90.4469 (0.138)
Step: 77322, Reward: -6.2488 [0.77], Avg: -89.6042 (0.135)
Step: 79322, Reward: -9.7588 [1.53], Avg: -88.8210 (0.133)
Step: 81322, Reward: -11.5035 [3.20], Avg: -88.0872 (0.130)
Step: 83322, Reward: -9.3346 [1.12], Avg: -87.3260 (0.127)
Step: 85322, Reward: -7.3840 [0.85], Avg: -86.5582 (0.125)
Step: 87322, Reward: -5.1825 [0.76], Avg: -85.7830 (0.122)
Step: 89322, Reward: -30.1791 [0.70], Avg: -85.2602 (0.120)
Step: 91322, Reward: -9.0475 [0.77], Avg: -84.5484 (0.117)
Step: 93322, Reward: -11.1469 [6.80], Avg: -83.9260 (0.115)
Step: 95322, Reward: -6.5606 [0.58], Avg: -83.2150 (0.113)
Step: 97322, Reward: -7.0058 [0.70], Avg: -82.5222 (0.111)
Step: 99322, Reward: -5.5152 [1.82], Avg: -81.8387 (0.108)
Step: 101322, Reward: -5.0687 [1.09], Avg: -81.1569 (0.106)
Step: 103322, Reward: -8.5713 [3.15], Avg: -80.5370 (0.104)
Step: 105322, Reward: -6.5671 [1.06], Avg: -79.8918 (0.102)
Step: 107322, Reward: -3.7287 [2.10], Avg: -79.2422 (0.100)
Step: 109322, Reward: -6.5089 [2.79], Avg: -78.6340 (0.098)
Step: 111322, Reward: -5.3213 [0.86], Avg: -78.0094 (0.096)
Step: 113322, Reward: -5.6200 [1.17], Avg: -77.4007 (0.094)
Step: 115322, Reward: -3.9724 [1.03], Avg: -76.7871 (0.092)
Step: 117322, Reward: -1.9196 [0.91], Avg: -76.1656 (0.090)
Step: 119322, Reward: -5.0065 [1.65], Avg: -75.5864 (0.089)
Step: 121322, Reward: -3.5249 [2.07], Avg: -75.0079 (0.087)
Step: 123322, Reward: -5.2191 [1.91], Avg: -74.4515 (0.085)
Step: 125322, Reward: -1.4415 [1.16], Avg: -73.8674 (0.083)
Step: 127322, Reward: -1.9524 [1.01], Avg: -73.2956 (0.082)
Step: 129322, Reward: -3.7763 [0.51], Avg: -72.7436 (0.080)
Step: 131322, Reward: -1.4838 [0.74], Avg: -72.1839 (0.078)
Step: 133322, Reward: -1.4640 [0.63], Avg: -71.6321 (0.077)
Step: 135322, Reward: -2.9841 [0.76], Avg: -71.1017 (0.075)
Step: 137322, Reward: -0.4127 [0.74], Avg: -70.5595 (0.074)
Step: 139322, Reward: -0.6450 [0.53], Avg: -70.0258 (0.072)
Step: 141322, Reward: -2.5592 [1.06], Avg: -69.5189 (0.071)
Step: 143322, Reward: -0.3811 [0.83], Avg: -69.0014 (0.069)
Step: 145322, Reward: 0.3559 [0.46], Avg: -68.4834 (0.068)
Step: 145553, Reward: -102.8203 [2.32], Avg: -68.7570 (0.067)
Step: 147553, Reward: -1.8739 [0.67], Avg: -68.2665 (0.065)
Step: 149553, Reward: -3.7012 [0.97], Avg: -67.7989 (0.064)
Step: 151553, Reward: 0.3573 [1.19], Avg: -67.3101 (0.063)
Step: 153553, Reward: 0.0005 [0.74], Avg: -66.8277 (0.062)
Step: 155553, Reward: -23.4714 [11.10], Avg: -66.5956 (0.060)
Step: 157553, Reward: -9.1937 [4.07], Avg: -66.2146 (0.059)
Step: 159553, Reward: -97.3522 [38.71], Avg: -66.7100 (0.058)
Step: 161553, Reward: -0.9146 [1.80], Avg: -66.2593 (0.057)
Step: 163553, Reward: -7.3483 [1.23], Avg: -65.8559 (0.056)
Step: 165553, Reward: -3.7749 [0.43], Avg: -65.4278 (0.055)
Step: 167553, Reward: 1.6666 [0.27], Avg: -64.9669 (0.053)
Step: 169553, Reward: 1.3268 [1.03], Avg: -64.5199 (0.052)
Step: 171553, Reward: 2.5087 [0.54], Avg: -64.0676 (0.051)
Step: 173553, Reward: 2.1349 [0.73], Avg: -63.6253 (0.050)
Step: 175553, Reward: -1.5403 [7.36], Avg: -63.2580 (0.049)
Step: 177553, Reward: 1.2767 [0.85], Avg: -62.8334 (0.048)
Step: 179553, Reward: 1.8460 [0.90], Avg: -62.4111 (0.047)
Step: 181553, Reward: 1.3703 [0.34], Avg: -61.9937 (0.046)
Step: 183553, Reward: 2.0806 [0.65], Avg: -61.5792 (0.045)
Step: 185553, Reward: -26.8223 [35.60], Avg: -61.5846 (0.045)
Step: 187553, Reward: 2.6238 [0.40], Avg: -61.1730 (0.044)
Step: 189553, Reward: -3.6921 [13.16], Avg: -60.8889 (0.043)
Step: 191553, Reward: -0.2941 [0.57], Avg: -60.5066 (0.042)
Step: 193553, Reward: 3.3610 [0.77], Avg: -60.1072 (0.041)
Step: 195553, Reward: 3.1755 [0.57], Avg: -59.7128 (0.040)
Step: 197553, Reward: 2.9393 [0.34], Avg: -59.3234 (0.039)
Step: 199553, Reward: 1.7602 [0.76], Avg: -58.9487 (0.039)
Step: 201553, Reward: 2.3007 [0.21], Avg: -58.5719 (0.038)
Step: 203553, Reward: 1.5866 [1.00], Avg: -58.2090 (0.037)
Step: 205553, Reward: 3.6104 [1.80], Avg: -57.8431 (0.036)
Step: 207553, Reward: -0.0640 [4.91], Avg: -57.5226 (0.036)
Step: 209553, Reward: 1.7388 [3.12], Avg: -57.1844 (0.035)
Step: 211553, Reward: -2.5882 [0.57], Avg: -56.8609 (0.034)
Step: 213553, Reward: 2.5480 [0.67], Avg: -56.5113 (0.034)
Step: 215553, Reward: 4.1684 [0.44], Avg: -56.1549 (0.033)
Step: 217553, Reward: 1.6201 [0.41], Avg: -55.8174 (0.032)
Step: 219553, Reward: 5.0128 [3.17], Avg: -55.4803 (0.032)
Step: 221553, Reward: 3.3080 [0.85], Avg: -55.1434 (0.031)
Step: 223553, Reward: 4.8900 [1.22], Avg: -54.8035 (0.030)
Step: 225553, Reward: 5.1378 [0.72], Avg: -54.4631 (0.030)
Step: 227553, Reward: 5.0886 [2.85], Avg: -54.1391 (0.029)
Step: 229553, Reward: -8.3179 [26.90], Avg: -54.0317 (0.029)
Step: 231553, Reward: -8.3908 [27.18], Avg: -53.9274 (0.028)
Step: 233553, Reward: -5.0580 [23.39], Avg: -53.7842 (0.027)
Step: 235553, Reward: 4.0524 [1.31], Avg: -53.4685 (0.027)
Step: 237553, Reward: 1.5546 [5.70], Avg: -53.1945 (0.026)
Step: 239553, Reward: 2.1617 [15.25], Avg: -52.9729 (0.026)
Step: 241553, Reward: 4.1287 [1.57], Avg: -52.6678 (0.025)
Step: 243553, Reward: 8.9599 [1.12], Avg: -52.3372 (0.025)
Step: 245553, Reward: 2.2843 [0.63], Avg: -52.0437 (0.024)
Step: 247553, Reward: 3.4952 [1.24], Avg: -51.7502 (0.024)
Step: 249553, Reward: 4.9726 [1.76], Avg: -51.4547 (0.023)
Step: 251553, Reward: 7.9855 [1.27], Avg: -51.1436 (0.023)
Step: 253553, Reward: 7.6252 [1.77], Avg: -50.8404 (0.022)
Step: 255553, Reward: 7.8586 [0.99], Avg: -50.5351 (0.022)
Step: 257553, Reward: 2.2813 [2.15], Avg: -50.2684 (0.022)
Step: 259553, Reward: 9.6593 [1.63], Avg: -49.9632 (0.021)
Step: 261553, Reward: 3.8078 [1.73], Avg: -49.6921 (0.021)
Step: 263553, Reward: 9.9942 [0.92], Avg: -49.3876 (0.020)
Step: 265553, Reward: 5.7543 [6.94], Avg: -49.1392 (0.020)
Step: 267553, Reward: 6.6651 [2.55], Avg: -48.8661 (0.020)
Step: 269553, Reward: 4.2953 [11.15], Avg: -48.6518 (0.020)
Step: 271553, Reward: 2.9960 [3.24], Avg: -48.4060 (0.020)
Step: 273553, Reward: 6.5772 [0.82], Avg: -48.1325 (0.020)
Step: 275553, Reward: 9.5286 [2.00], Avg: -47.8528 (0.020)
Step: 277553, Reward: 8.6425 [2.61], Avg: -47.5833 (0.020)
Step: 279553, Reward: 5.8182 [1.45], Avg: -47.3249 (0.020)
Step: 281553, Reward: 9.1085 [2.62], Avg: -47.0585 (0.020)
Step: 283553, Reward: 7.3555 [1.89], Avg: -46.7997 (0.020)
Step: 285553, Reward: 8.1483 [1.70], Avg: -46.5387 (0.020)
Step: 287553, Reward: 7.3597 [2.90], Avg: -46.2900 (0.020)
Step: 289553, Reward: 8.4623 [1.79], Avg: -46.0329 (0.020)
Step: 291553, Reward: 8.2068 [1.26], Avg: -45.7769 (0.020)
Step: 293553, Reward: 8.0530 [1.91], Avg: -45.5273 (0.020)
Step: 295553, Reward: 9.7490 [1.80], Avg: -45.2714 (0.020)
Step: 297553, Reward: 6.7260 [1.27], Avg: -45.0299 (0.020)
Step: 299553, Reward: 10.3631 [1.62], Avg: -44.7750 (0.020)
Step: 301553, Reward: 8.6263 [2.00], Avg: -44.5326 (0.020)
Step: 303553, Reward: 7.0399 [2.33], Avg: -44.3014 (0.020)
Step: 305553, Reward: 10.2382 [0.54], Avg: -44.0491 (0.020)
Step: 307553, Reward: 8.7385 [2.50], Avg: -43.8152 (0.020)
Step: 309553, Reward: 7.1007 [2.28], Avg: -43.5900 (0.020)
Step: 311553, Reward: 6.8809 [1.38], Avg: -43.3638 (0.020)
Step: 313553, Reward: 6.4912 [1.01], Avg: -43.1397 (0.020)
Step: 315553, Reward: 5.8202 [2.57], Avg: -42.9279 (0.020)
Step: 317553, Reward: 10.4229 [1.43], Avg: -42.6919 (0.020)
Step: 319553, Reward: 7.7208 [1.83], Avg: -42.4721 (0.020)
Step: 321553, Reward: 7.2225 [2.04], Avg: -42.2575 (0.020)
Step: 323553, Reward: 6.9621 [1.27], Avg: -42.0424 (0.020)
Step: 325553, Reward: 6.1424 [1.26], Avg: -41.8329 (0.020)
Step: 327553, Reward: 5.0169 [1.66], Avg: -41.6321 (0.020)
Step: 329553, Reward: 8.2899 [3.01], Avg: -41.4245 (0.020)
Step: 331553, Reward: 11.5008 [0.62], Avg: -41.1941 (0.020)
Step: 333553, Reward: 5.7372 [2.26], Avg: -40.9981 (0.020)
Step: 335553, Reward: 7.4873 [2.42], Avg: -40.7970 (0.020)
Step: 337553, Reward: 10.3912 [1.30], Avg: -40.5801 (0.020)
Step: 339553, Reward: 9.0044 [1.45], Avg: -40.3717 (0.020)
Step: 341553, Reward: 6.7547 [1.99], Avg: -40.1772 (0.020)
Step: 343553, Reward: 9.9321 [1.75], Avg: -39.9696 (0.020)
Step: 345553, Reward: 7.1360 [1.68], Avg: -39.7755 (0.020)
Step: 347553, Reward: -10.4746 [43.91], Avg: -39.8377 (0.020)
Step: 349553, Reward: -13.6047 [38.59], Avg: -39.8900 (0.020)
Step: 351553, Reward: -2.7036 [9.05], Avg: -39.7713 (0.020)
Step: 353553, Reward: -95.2605 [0.27], Avg: -40.0056 (0.020)
Step: 353638, Reward: -94.5818 [0.46], Avg: -40.2359 (0.020)
Step: 353719, Reward: -94.9860 [0.41], Avg: -40.4657 (0.020)
Step: 353804, Reward: -94.6068 [1.19], Avg: -40.6953 (0.020)
Step: 353909, Reward: -15.9204 [3.16], Avg: -40.6060 (0.020)
Step: 355909, Reward: -107.3282 [0.47], Avg: -40.8825 (0.020)
Step: 356003, Reward: -108.6555 [1.89], Avg: -41.1680 (0.020)
Step: 356096, Reward: -89.0521 [44.45], Avg: -41.5449 (0.020)
Step: 358096, Reward: -104.9592 [11.92], Avg: -41.8511 (0.020)
Step: 358201, Reward: -114.8700 [17.77], Avg: -42.2187 (0.020)
Step: 359397, Reward: -41.8649 [5.16], Avg: -42.2380 (0.020)
Step: 361397, Reward: -29.5940 [6.85], Avg: -42.2147 (0.020)
Step: 363397, Reward: -26.0314 [3.92], Avg: -42.1657 (0.020)
Step: 365397, Reward: -109.0019 [26.83], Avg: -42.5388 (0.020)
Step: 367397, Reward: -6.8276 [4.64], Avg: -42.4156 (0.020)
Step: 369397, Reward: -7.1689 [2.35], Avg: -42.2855 (0.020)
Step: 371397, Reward: -5.4707 [1.21], Avg: -42.1454 (0.020)
Step: 373397, Reward: -5.2013 [9.18], Avg: -42.0365 (0.020)
Step: 375397, Reward: -5.4972 [0.64], Avg: -41.8963 (0.020)
Step: 377397, Reward: 1.1103 [1.21], Avg: -41.7336 (0.020)
Step: 379397, Reward: 4.7005 [1.35], Avg: -41.5589 (0.020)
Step: 381397, Reward: 3.3925 [3.34], Avg: -41.3982 (0.020)
Step: 383397, Reward: 4.7164 [2.53], Avg: -41.2306 (0.020)
Step: 385397, Reward: -1.3562 [1.76], Avg: -41.0846 (0.020)
Step: 387397, Reward: 4.1439 [1.58], Avg: -40.9180 (0.020)
Step: 389397, Reward: 1.2564 [0.88], Avg: -40.7610 (0.020)
Step: 391397, Reward: 3.8473 [2.81], Avg: -40.6026 (0.020)
Step: 393397, Reward: 6.2960 [1.58], Avg: -40.4316 (0.020)
Step: 395397, Reward: 4.7517 [2.12], Avg: -40.2697 (0.020)
Step: 397397, Reward: 7.6173 [3.67], Avg: -40.1041 (0.020)
Step: 399397, Reward: 3.5805 [1.15], Avg: -39.9454 (0.020)
Step: 401397, Reward: 7.0230 [1.63], Avg: -39.7768 (0.020)
Step: 403397, Reward: 6.5993 [1.64], Avg: -39.6112 (0.020)
Step: 405397, Reward: 4.3350 [0.38], Avg: -39.4504 (0.020)
Step: 407397, Reward: 8.0409 [2.72], Avg: -39.2858 (0.020)
Step: 409397, Reward: 4.7220 [1.27], Avg: -39.1293 (0.020)
Step: 411397, Reward: 3.4126 [0.20], Avg: -38.9747 (0.020)
Step: 413397, Reward: 6.8961 [1.30], Avg: -38.8127 (0.020)
Step: 415397, Reward: 6.1246 [0.76], Avg: -38.6526 (0.020)
Step: 417397, Reward: 8.1674 [1.34], Avg: -38.4884 (0.020)
Step: 419397, Reward: 7.5908 [1.47], Avg: -38.3280 (0.020)
Step: 421397, Reward: 6.1358 [1.99], Avg: -38.1757 (0.020)
Step: 423397, Reward: 5.4413 [3.09], Avg: -38.0310 (0.020)
Step: 425397, Reward: 8.5132 [1.45], Avg: -37.8705 (0.020)
Step: 427397, Reward: -10.1162 [22.27], Avg: -37.8511 (0.020)
Step: 429397, Reward: -8.4941 [29.15], Avg: -37.8504 (0.020)
Step: 431397, Reward: 5.7105 [2.07], Avg: -37.7043 (0.020)
Step: 433397, Reward: 0.4194 [2.93], Avg: -37.5808 (0.020)
Step: 435397, Reward: 9.3650 [1.65], Avg: -37.4224 (0.020)
Step: 437397, Reward: -6.9929 [17.24], Avg: -37.3765 (0.020)
Step: 439285, Reward: -2.4113 [8.80], Avg: -37.2856 (0.020)
Step: 441285, Reward: 4.7316 [1.41], Avg: -37.1451 (0.020)
Step: 443285, Reward: 1.9246 [2.25], Avg: -37.0182 (0.020)
Step: 445285, Reward: 3.9566 [2.64], Avg: -36.8864 (0.020)
Step: 447285, Reward: 1.1756 [2.81], Avg: -36.7657 (0.020)
Step: 449285, Reward: 6.7218 [0.95], Avg: -36.6205 (0.020)
Step: 451285, Reward: 4.8471 [1.18], Avg: -36.4835 (0.020)
Step: 453285, Reward: 5.6775 [1.33], Avg: -36.3451 (0.020)
Step: 455285, Reward: 7.7641 [2.11], Avg: -36.2032 (0.020)
Step: 457285, Reward: 4.8380 [6.33], Avg: -36.0864 (0.020)
Step: 459285, Reward: -20.7362 [38.27], Avg: -36.1632 (0.020)
Step: 461285, Reward: -84.4018 [26.12], Avg: -36.4120 (0.020)
Step: 463285, Reward: -31.1705 [12.07], Avg: -36.4347 (0.020)
Step: 465285, Reward: -12.7542 [14.38], Avg: -36.4038 (0.020)
Step: 467285, Reward: -12.7054 [17.29], Avg: -36.3826 (0.020)
Step: 469285, Reward: 5.4793 [1.60], Avg: -36.2497 (0.020)
Step: 471285, Reward: 0.7788 [10.08], Avg: -36.1611 (0.020)
Step: 473285, Reward: 3.6322 [2.32], Avg: -36.0382 (0.020)
Step: 475285, Reward: 4.8444 [0.37], Avg: -35.9058 (0.020)
Step: 477285, Reward: 4.1087 [0.53], Avg: -35.7772 (0.020)
Step: 479285, Reward: 5.2712 [0.27], Avg: -35.6448 (0.020)
Step: 481285, Reward: 4.1770 [0.55], Avg: -35.5177 (0.020)
Step: 483285, Reward: 1.9218 [10.01], Avg: -35.4292 (0.020)
Step: 485285, Reward: 5.5504 [0.71], Avg: -35.2997 (0.020)
Step: 487285, Reward: 5.5947 [0.64], Avg: -35.1707 (0.020)
Step: 489285, Reward: 5.7774 [1.04], Avg: -35.0432 (0.020)
Step: 491285, Reward: -0.8449 [1.52], Avg: -34.9391 (0.020)
Step: 493285, Reward: 5.4471 [0.77], Avg: -34.8133 (0.020)
Step: 495285, Reward: 4.2835 [1.55], Avg: -34.6945 (0.020)
Step: 497285, Reward: 4.4825 [1.01], Avg: -34.5741 (0.020)
Step: 499285, Reward: 7.1775 [0.93], Avg: -34.4457 (0.020)
Step: 501285, Reward: 4.9859 [0.93], Avg: -34.3250 (0.020)
Step: 503285, Reward: 1.2788 [0.50], Avg: -34.2153 (0.020)
Step: 505285, Reward: 3.6457 [0.47], Avg: -34.0989 (0.020)
Step: 507285, Reward: 1.1966 [1.03], Avg: -33.9924 (0.020)
Step: 507544, Reward: -120.3697 [3.80], Avg: -34.2716 (0.020)
Step: 509544, Reward: -13.3565 [1.99], Avg: -34.2132 (0.020)
Step: 511544, Reward: 0.8943 [1.21], Avg: -34.1089 (0.020)
Step: 513544, Reward: -1.1632 [1.00], Avg: -34.0109 (0.020)
Step: 515544, Reward: 1.1454 [1.37], Avg: -33.9076 (0.020)
Step: 517544, Reward: 3.1684 [0.82], Avg: -33.7970 (0.020)
Step: 519544, Reward: 1.8693 [0.48], Avg: -33.6901 (0.020)
Step: 521544, Reward: 2.0303 [0.25], Avg: -33.5826 (0.020)
Step: 523544, Reward: 2.3332 [0.32], Avg: -33.4751 (0.020)
Step: 525544, Reward: 3.3786 [0.90], Avg: -33.3668 (0.020)
Step: 527544, Reward: 3.6054 [0.37], Avg: -33.2569 (0.020)
Step: 529544, Reward: 3.4267 [1.33], Avg: -33.1510 (0.020)
Step: 531544, Reward: 2.0185 [0.42], Avg: -33.0473 (0.020)
Step: 533544, Reward: 3.2455 [1.40], Avg: -32.9434 (0.020)
Step: 535544, Reward: 5.3940 [1.03], Avg: -32.8327 (0.020)
Step: 537544, Reward: -3.8559 [0.86], Avg: -32.7495 (0.020)
Step: 539544, Reward: -3.9083 [6.07], Avg: -32.6824 (0.020)
Step: 541544, Reward: 2.1852 [0.53], Avg: -32.5814 (0.020)
Step: 543544, Reward: 2.3669 [0.26], Avg: -32.4797 (0.020)
Step: 545544, Reward: 3.2559 [0.25], Avg: -32.3759 (0.020)
Step: 547544, Reward: 3.0398 [1.01], Avg: -32.2756 (0.020)
Step: 549544, Reward: 2.8108 [0.44], Avg: -32.1749 (0.020)
Step: 551544, Reward: 3.8011 [0.10], Avg: -32.0709 (0.020)
Step: 553544, Reward: 1.5334 [1.81], Avg: -31.9790 (0.020)
Step: 555544, Reward: 2.9060 [0.37], Avg: -31.8795 (0.020)
Step: 557544, Reward: 2.8307 [0.66], Avg: -31.7817 (0.020)
Step: 559544, Reward: -47.0877 [40.22], Avg: -31.9408 (0.020)
Step: 561544, Reward: -1.5763 [1.36], Avg: -31.8579 (0.020)
Step: 563544, Reward: 2.8942 [0.70], Avg: -31.7609 (0.020)
Step: 565544, Reward: 0.9230 [0.47], Avg: -31.6694 (0.020)
Step: 567544, Reward: 2.2959 [1.21], Avg: -31.5766 (0.020)
Step: 569544, Reward: 4.9176 [4.60], Avg: -31.4865 (0.020)
Step: 571544, Reward: -11.0344 [18.66], Avg: -31.4814 (0.020)
Step: 573544, Reward: -4.4173 [1.26], Avg: -31.4089 (0.020)
Step: 575544, Reward: -0.0804 [1.54], Avg: -31.3255 (0.020)
Step: 577544, Reward: -5.0022 [18.01], Avg: -31.3023 (0.020)
Step: 579544, Reward: -61.8305 [44.26], Avg: -31.5106 (0.020)
Step: 581544, Reward: -110.3976 [2.84], Avg: -31.7377 (0.020)
Step: 581693, Reward: -58.3087 [45.32], Avg: -31.9368 (0.020)
Step: 583693, Reward: -4.4429 [0.49], Avg: -31.8622 (0.020)
Step: 585693, Reward: -9.0457 [0.87], Avg: -31.8017 (0.020)
Step: 587693, Reward: -7.3806 [1.56], Avg: -31.7389 (0.020)
Step: 589693, Reward: -4.8495 [0.75], Avg: -31.6673 (0.020)
Step: 591693, Reward: -62.9190 [50.40], Avg: -31.8904 (0.020)
Step: 591808, Reward: -52.2193 [37.71], Avg: -32.0485 (0.020)
Step: 593808, Reward: -129.2454 [1.04], Avg: -32.3155 (0.020)
Step: 595808, Reward: -119.2994 [1.58], Avg: -32.5555 (0.020)
Step: 595861, Reward: -111.0337 [1.40], Avg: -32.7713 (0.020)
Step: 595922, Reward: -116.8986 [3.27], Avg: -33.0069 (0.020)
Step: 595986, Reward: -110.5508 [0.91], Avg: -33.2178 (0.020)
Step: 596036, Reward: -112.5023 [1.44], Avg: -33.4342 (0.020)
Step: 596099, Reward: -115.1104 [3.23], Avg: -33.6613 (0.020)
Step: 596163, Reward: -114.1100 [2.01], Avg: -33.8811 (0.020)
Step: 596261, Reward: -115.3985 [3.47], Avg: -34.1072 (0.020)
Step: 596333, Reward: -116.5139 [2.23], Avg: -34.3317 (0.020)
Step: 596460, Reward: -95.9509 [42.04], Avg: -34.6059 (0.020)
Step: 598460, Reward: -73.8572 [16.66], Avg: -34.7534 (0.020)
Step: 600460, Reward: -33.3742 [13.46], Avg: -34.7852 (0.020)
Step: 602460, Reward: -36.5617 [2.50], Avg: -34.7964 (0.020)
Step: 604460, Reward: -35.3142 [4.30], Avg: -34.8091 (0.020)
Step: 606460, Reward: -19.1329 [5.52], Avg: -34.7825 (0.020)
Step: 608460, Reward: -83.8544 [31.12], Avg: -34.9914 (0.020)
Step: 608572, Reward: -9.2626 [6.01], Avg: -34.9402 (0.020)
Step: 610572, Reward: -5.7368 [1.85], Avg: -34.8693 (0.020)
Step: 612572, Reward: -11.0192 [12.21], Avg: -34.8392 (0.020)
Step: 614572, Reward: -4.4300 [1.56], Avg: -34.7649 (0.020)
Step: 616572, Reward: -11.8071 [4.60], Avg: -34.7177 (0.020)
Step: 618572, Reward: -39.7431 [43.61], Avg: -34.8424 (0.020)
Step: 620572, Reward: -13.6244 [9.13], Avg: -34.8115 (0.020)
Step: 622572, Reward: -2.0118 [2.46], Avg: -34.7341 (0.020)
Step: 624572, Reward: -30.8324 [35.25], Avg: -34.8138 (0.020)
Step: 626572, Reward: -24.6704 [52.29], Avg: -34.9208 (0.020)
Step: 628572, Reward: 0.4401 [2.67], Avg: -34.8380 (0.020)
Step: 630572, Reward: 3.5553 [0.73], Avg: -34.7429 (0.020)
Step: 632572, Reward: 0.1568 [1.36], Avg: -34.6584 (0.020)
Step: 634572, Reward: -0.7308 [1.47], Avg: -34.5769 (0.020)
Step: 636572, Reward: 2.2478 [0.52], Avg: -34.4859 (0.020)
Step: 638572, Reward: 0.7269 [2.45], Avg: -34.4040 (0.020)
Step: 640572, Reward: 1.4806 [1.19], Avg: -34.3174 (0.020)
Step: 642572, Reward: -1.0337 [1.92], Avg: -34.2394 (0.020)
Step: 644572, Reward: -0.0104 [0.49], Avg: -34.1557 (0.020)
Step: 646572, Reward: 0.9714 [2.08], Avg: -34.0739 (0.020)
Step: 648572, Reward: -0.7385 [2.93], Avg: -33.9988 (0.020)
Step: 650572, Reward: -11.2758 [10.96], Avg: -33.9698 (0.020)
Step: 652572, Reward: 3.3772 [0.67], Avg: -33.8797 (0.020)
Step: 654572, Reward: 3.6628 [0.93], Avg: -33.7900 (0.020)
Step: 656572, Reward: 4.3487 [0.70], Avg: -33.6985 (0.020)
Step: 658572, Reward: 4.4257 [0.44], Avg: -33.6065 (0.020)
Step: 660572, Reward: 3.3593 [0.40], Avg: -33.5176 (0.020)
Step: 662572, Reward: 2.3743 [0.32], Avg: -33.4312 (0.020)
Step: 664572, Reward: 2.9609 [0.15], Avg: -33.3435 (0.020)
Step: 666572, Reward: 4.6045 [0.25], Avg: -33.2524 (0.020)
Step: 668572, Reward: 3.0932 [1.73], Avg: -33.1690 (0.020)
Step: 670572, Reward: 4.4183 [0.18], Avg: -33.0791 (0.020)
Step: 672572, Reward: 4.5775 [0.16], Avg: -32.9891 (0.020)
Step: 674572, Reward: 3.8171 [0.32], Avg: -32.9018 (0.020)
Step: 676572, Reward: 4.2956 [0.08], Avg: -32.8133 (0.020)
Step: 678572, Reward: 3.9925 [1.48], Avg: -32.7292 (0.020)
Step: 680572, Reward: 1.3060 [1.47], Avg: -32.6518 (0.020)
Step: 682572, Reward: 3.2406 [0.98], Avg: -32.5691 (0.020)
Step: 684572, Reward: 3.9387 [0.64], Avg: -32.4843 (0.020)
Step: 686572, Reward: 3.8936 [0.39], Avg: -32.3994 (0.020)
Step: 688572, Reward: 3.5808 [0.21], Avg: -32.3152 (0.020)
Step: 690572, Reward: 4.4588 [0.38], Avg: -32.2298 (0.020)
Step: 692572, Reward: 4.2754 [0.50], Avg: -32.1455 (0.020)
Step: 694572, Reward: 4.1773 [0.53], Avg: -32.0619 (0.020)
Step: 696572, Reward: 4.2703 [0.43], Avg: -31.9782 (0.020)
Step: 698572, Reward: 5.1503 [0.45], Avg: -31.8929 (0.020)
Step: 700572, Reward: 4.9193 [0.36], Avg: -31.8083 (0.020)
Step: 702572, Reward: 4.5122 [0.56], Avg: -31.7255 (0.020)
Step: 704572, Reward: 4.9787 [0.18], Avg: -31.6412 (0.020)
Step: 706572, Reward: 4.2013 [0.26], Avg: -31.5592 (0.020)
Step: 708572, Reward: 3.7813 [1.78], Avg: -31.4820 (0.020)
Step: 710572, Reward: 4.2363 [1.33], Avg: -31.4031 (0.020)
Step: 712572, Reward: -2.4900 [13.15], Avg: -31.3671 (0.020)
Step: 714572, Reward: 3.3104 [1.16], Avg: -31.2905 (0.020)
Step: 716572, Reward: 5.0024 [0.47], Avg: -31.2089 (0.020)
Step: 718572, Reward: 5.7390 [0.51], Avg: -31.1261 (0.020)
Step: 720572, Reward: 4.1709 [0.43], Avg: -31.0470 (0.020)
Step: 722572, Reward: 6.0261 [0.81], Avg: -30.9650 (0.020)
Step: 724572, Reward: 3.6305 [0.36], Avg: -30.8877 (0.020)
Step: 726572, Reward: 4.1311 [1.30], Avg: -30.8118 (0.020)
Step: 728572, Reward: 2.6233 [1.08], Avg: -30.7391 (0.020)
Step: 730572, Reward: 5.0723 [0.53], Avg: -30.6600 (0.020)
Step: 732572, Reward: 4.9090 [1.00], Avg: -30.5826 (0.020)
Step: 734572, Reward: 5.9228 [1.27], Avg: -30.5040 (0.020)
Step: 736572, Reward: 6.9841 [1.00], Avg: -30.4227 (0.020)
Step: 738572, Reward: 7.4200 [1.88], Avg: -30.3428 (0.020)
Step: 740572, Reward: 5.6949 [4.16], Avg: -30.2721 (0.020)
Step: 742572, Reward: 6.8821 [1.35], Avg: -30.1929 (0.020)
Step: 744572, Reward: -12.4336 [26.23], Avg: -30.2116 (0.020)
Step: 746572, Reward: 2.2068 [7.75], Avg: -30.1573 (0.020)
Step: 748572, Reward: 6.3600 [1.00], Avg: -30.0792 (0.020)
Step: 750572, Reward: 5.4373 [0.98], Avg: -30.0035 (0.020)
Step: 752572, Reward: 6.2042 [1.28], Avg: -29.9270 (0.020)
Step: 754572, Reward: 5.2581 [0.66], Avg: -29.8516 (0.020)
Step: 756572, Reward: 7.5677 [2.81], Avg: -29.7762 (0.020)
Step: 758572, Reward: 6.9180 [1.37], Avg: -29.6994 (0.020)
Step: 760572, Reward: 7.4833 [1.14], Avg: -29.6212 (0.020)
Step: 762572, Reward: 5.5283 [1.04], Avg: -29.5474 (0.020)
Step: 764572, Reward: 7.1800 [2.51], Avg: -29.4735 (0.020)
Step: 766572, Reward: 5.9520 [0.50], Avg: -29.3982 (0.020)
Step: 768572, Reward: 6.7679 [3.64], Avg: -29.3283 (0.020)
Step: 770572, Reward: 6.4508 [0.43], Avg: -29.2525 (0.020)
Step: 772572, Reward: 8.9349 [1.29], Avg: -29.1734 (0.020)
Step: 774572, Reward: 5.5760 [2.09], Avg: -29.1037 (0.020)
Step: 776572, Reward: 6.6124 [2.34], Avg: -29.0325 (0.020)
Step: 778572, Reward: 5.5581 [1.40], Avg: -28.9619 (0.020)
Step: 780572, Reward: 9.3589 [2.39], Avg: -28.8856 (0.020)
Step: 782572, Reward: 6.4026 [0.98], Avg: -28.8129 (0.020)
Step: 784572, Reward: 5.6441 [1.87], Avg: -28.7440 (0.020)
Step: 786572, Reward: 6.8170 [0.87], Avg: -28.6709 (0.020)
Step: 788572, Reward: 7.9528 [2.34], Avg: -28.5987 (0.020)
Step: 790572, Reward: 6.6934 [1.55], Avg: -28.5278 (0.020)
Step: 792572, Reward: 7.1872 [0.90], Avg: -28.4548 (0.020)
Step: 794572, Reward: 6.1046 [1.19], Avg: -28.3850 (0.020)
Step: 796572, Reward: 6.6037 [1.81], Avg: -28.3158 (0.020)
Step: 798572, Reward: 7.8056 [2.02], Avg: -28.2447 (0.020)
Step: 800572, Reward: 8.4654 [1.40], Avg: -28.1713 (0.020)
Step: 802572, Reward: 6.3728 [3.07], Avg: -28.1060 (0.020)
Step: 804572, Reward: 6.7350 [0.78], Avg: -28.0355 (0.020)
Step: 806572, Reward: 8.0964 [2.15], Avg: -27.9653 (0.020)
Step: 808572, Reward: 7.3773 [1.32], Avg: -27.8951 (0.020)
Step: 810572, Reward: 5.6623 [2.76], Avg: -27.8318 (0.020)
Step: 812572, Reward: 6.5018 [1.62], Avg: -27.7646 (0.020)
Step: 814572, Reward: 6.1312 [4.68], Avg: -27.7047 (0.020)
Step: 816572, Reward: 7.6920 [1.45], Avg: -27.6353 (0.020)
Step: 818572, Reward: 4.5316 [7.37], Avg: -27.5847 (0.020)
Step: 820572, Reward: 7.0185 [2.25], Avg: -27.5188 (0.020)
Step: 822572, Reward: 7.7271 [2.43], Avg: -27.4521 (0.020)
Step: 824572, Reward: 8.2776 [2.52], Avg: -27.3847 (0.020)
Step: 826572, Reward: 6.7963 [2.12], Avg: -27.3198 (0.020)
Step: 828572, Reward: 7.9071 [2.84], Avg: -27.2544 (0.020)
Step: 830572, Reward: 10.0425 [2.82], Avg: -27.1849 (0.020)
Step: 832572, Reward: -28.9663 [44.35], Avg: -27.2777 (0.020)
Step: 832927, Reward: -28.9898 [43.11], Avg: -27.3677 (0.020)
Step: 834927, Reward: -0.8381 [1.72], Avg: -27.3180 (0.020)
Step: 836927, Reward: -1.2328 [1.61], Avg: -27.2690 (0.020)
Step: 838927, Reward: 7.1099 [2.24], Avg: -27.2049 (0.020)
Step: 840927, Reward: 2.0165 [0.53], Avg: -27.1477 (0.020)
Step: 842927, Reward: -1.7209 [0.35], Avg: -27.0979 (0.020)
Step: 844927, Reward: 7.3407 [1.18], Avg: -27.0319 (0.020)
Step: 846927, Reward: 6.5364 [3.99], Avg: -26.9733 (0.020)
Step: 848927, Reward: 8.0250 [0.94], Avg: -26.9060 (0.020)
Step: 850927, Reward: 1.4553 [0.73], Avg: -26.8515 (0.020)
Step: 852927, Reward: 4.2563 [6.70], Avg: -26.8035 (0.020)
Step: 854927, Reward: 7.8601 [2.22], Avg: -26.7397 (0.020)
Step: 856927, Reward: 6.3432 [2.87], Avg: -26.6805 (0.020)
Step: 858927, Reward: 6.7649 [2.45], Avg: -26.6198 (0.020)
Step: 860927, Reward: 5.8024 [1.32], Avg: -26.5591 (0.020)
Step: 862927, Reward: 7.6360 [2.16], Avg: -26.4966 (0.020)
Step: 864927, Reward: 8.1713 [2.53], Avg: -26.4341 (0.020)
Step: 866927, Reward: -19.0917 [37.13], Avg: -26.4919 (0.020)
Step: 868927, Reward: -11.2597 [37.89], Avg: -26.5358 (0.020)
Step: 869060, Reward: -10.5305 [38.16], Avg: -26.5787 (0.020)
Step: 871060, Reward: 2.1163 [0.97], Avg: -26.5252 (0.020)
Step: 873060, Reward: 5.2190 [3.43], Avg: -26.4706 (0.020)
Step: 875060, Reward: -8.5150 [4.30], Avg: -26.4443 (0.020)
Step: 877060, Reward: 4.6209 [6.13], Avg: -26.3965 (0.020)
Step: 879060, Reward: 5.5567 [0.81], Avg: -26.3368 (0.020)
Step: 881060, Reward: 5.7329 [1.90], Avg: -26.2791 (0.020)
Step: 883060, Reward: 6.3850 [1.47], Avg: -26.2196 (0.020)
Step: 885060, Reward: 3.7034 [3.29], Avg: -26.1689 (0.020)
Step: 887060, Reward: 7.5797 [1.68], Avg: -26.1079 (0.020)
Step: 889060, Reward: 7.2777 [4.37], Avg: -26.0529 (0.020)
Step: 891060, Reward: 8.0112 [2.53], Avg: -25.9931 (0.020)
Step: 893060, Reward: 0.7517 [9.39], Avg: -25.9603 (0.020)
Step: 895060, Reward: 5.8324 [2.86], Avg: -25.9057 (0.020)
Step: 897060, Reward: -102.2457 [3.76], Avg: -26.0566 (0.020)
Step: 897126, Reward: -80.1315 [44.50], Avg: -26.2419 (0.020)
Step: 899126, Reward: 0.2110 [5.21], Avg: -26.2020 (0.020)
Step: 901126, Reward: 3.4700 [0.40], Avg: -26.1472 (0.020)
Step: 903126, Reward: 5.2227 [0.46], Avg: -26.0894 (0.020)
Step: 905126, Reward: 3.0353 [0.42], Avg: -26.0359 (0.020)
Step: 907126, Reward: 3.7109 [0.59], Avg: -25.9816 (0.020)
Step: 909126, Reward: 5.0531 [1.90], Avg: -25.9274 (0.020)
Step: 911126, Reward: 12.8035 [3.44], Avg: -25.8620 (0.020)
Step: 913126, Reward: 3.8207 [3.76], Avg: -25.8140 (0.020)
Step: 915126, Reward: 4.3985 [1.74], Avg: -25.7613 (0.020)
Step: 917126, Reward: 1.2043 [4.17], Avg: -25.7193 (0.020)
Step: 919126, Reward: 4.6973 [1.24], Avg: -25.6655 (0.020)
Step: 921126, Reward: 7.5896 [6.33], Avg: -25.6160 (0.020)
Step: 923126, Reward: 13.0254 [2.44], Avg: -25.5496 (0.020)
Step: 925126, Reward: -47.0793 [47.44], Avg: -25.6759 (0.020)
Step: 927126, Reward: 4.1094 [1.43], Avg: -25.6241 (0.020)
Step: 929126, Reward: -50.5305 [48.47], Avg: -25.7580 (0.020)
Step: 931126, Reward: 6.7335 [2.76], Avg: -25.7039 (0.020)
Step: 933126, Reward: 6.6571 [1.55], Avg: -25.6478 (0.020)
Step: 935126, Reward: 5.0840 [1.69], Avg: -25.5951 (0.020)
Step: 937126, Reward: 2.1848 [0.86], Avg: -25.5464 (0.020)
Step: 939126, Reward: -13.2993 [6.84], Avg: -25.5366 (0.020)
Step: 941126, Reward: -0.4765 [0.56], Avg: -25.4924 (0.020)
Step: 943126, Reward: -10.6800 [17.54], Avg: -25.4973 (0.020)
Step: 945126, Reward: 4.4345 [1.96], Avg: -25.4470 (0.020)
Step: 947126, Reward: 3.2113 [1.21], Avg: -25.3977 (0.020)
Step: 949126, Reward: 2.7154 [1.12], Avg: -25.3493 (0.020)
Step: 951126, Reward: -11.5890 [37.86], Avg: -25.3924 (0.020)
Step: 953126, Reward: 1.2358 [1.32], Avg: -25.3473 (0.020)
Step: 955126, Reward: 2.8647 [0.89], Avg: -25.2985 (0.020)
Step: 957126, Reward: 0.0321 [0.27], Avg: -25.2539 (0.020)
Step: 959126, Reward: 2.1768 [0.84], Avg: -25.2067 (0.020)
Step: 961126, Reward: 2.8848 [1.07], Avg: -25.1588 (0.020)
Step: 963126, Reward: 3.7782 [0.75], Avg: -25.1089 (0.020)
Step: 965126, Reward: 4.3546 [0.61], Avg: -25.0579 (0.020)
Step: 967126, Reward: 6.1445 [1.76], Avg: -25.0060 (0.020)
Step: 969126, Reward: 5.0673 [0.37], Avg: -24.9537 (0.020)
Step: 971126, Reward: 1.5275 [1.05], Avg: -24.9090 (0.020)
Step: 973126, Reward: 4.7098 [2.03], Avg: -24.8606 (0.020)
Step: 975126, Reward: 3.3286 [0.96], Avg: -24.8130 (0.020)
Step: 977126, Reward: 5.7982 [1.34], Avg: -24.7618 (0.020)
Step: 979126, Reward: 2.3422 [0.44], Avg: -24.7153 (0.020)
Step: 981126, Reward: 0.7119 [2.03], Avg: -24.6745 (0.020)
Step: 983126, Reward: 4.9757 [0.43], Avg: -24.6237 (0.020)
Step: 985126, Reward: 4.9878 [0.14], Avg: -24.5725 (0.020)
Step: 987126, Reward: 5.7770 [1.01], Avg: -24.5217 (0.020)
Step: 989126, Reward: 5.5175 [0.77], Avg: -24.4710 (0.020)
Step: 991126, Reward: 5.8688 [0.70], Avg: -24.4198 (0.020)
Step: 993126, Reward: 5.6261 [0.20], Avg: -24.3684 (0.020)
Step: 995126, Reward: 6.3909 [1.01], Avg: -24.3172 (0.020)
Step: 997126, Reward: 7.1395 [0.73], Avg: -24.2644 (0.020)
Step: 999126, Reward: 6.2385 [0.88], Avg: -24.2136 (0.020)
