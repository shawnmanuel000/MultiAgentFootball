Model: <class 'models.ppo.PPOAgent'>, Dir: Pendulum-v0
num_envs: 16,

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

EPS_MIN = 0.1                	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.997             	# The rate at which eps decays from EPS_MAX to EPS_MIN
BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.1				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) * critic_error.pow(2) * scale
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss.mean())
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		update_freq = int(self.update_freq * (1 - self.eps + EPS_MIN)**2)
		if len(self.buffer) >= update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, scale=16*update_freq/len(self.replay_buffer))
		if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "Acrobot-v1", "Pendulum-v0"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[-1]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class PixelAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	logger = Logger(model, env_name, num_envs=num_envs)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = PixelAgent(envs.state_size, envs.action_size, num_envs, model)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0] or s+1 % envs.env.spec.max_episode_steps == 0:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 199, Reward: -1217.4268 [145.50], Avg: -1362.9288 (0.997)
Step: 399, Reward: -1470.5081 [147.25], Avg: -1490.3454 (0.994)
Step: 599, Reward: -1188.0654 [92.12], Avg: -1420.2918 (0.991)
Step: 799, Reward: -1391.7952 [67.11], Avg: -1429.9451 (0.988)
Step: 999, Reward: -1541.9144 [73.20], Avg: -1466.9794 (0.985)
Step: 1199, Reward: -1462.3313 [41.39], Avg: -1473.1024 (0.982)
Step: 1399, Reward: -1520.3509 [85.92], Avg: -1492.1270 (0.979)
Step: 1599, Reward: -1457.7682 [91.02], Avg: -1499.2091 (0.976)
Step: 1799, Reward: -1453.1564 [54.23], Avg: -1500.1182 (0.973)
Step: 1999, Reward: -1422.5454 [179.04], Avg: -1510.2651 (0.970)
Step: 2199, Reward: -1554.9157 [45.41], Avg: -1518.4523 (0.967)
Step: 2399, Reward: -1405.7957 [110.43], Avg: -1518.2667 (0.965)
Step: 2599, Reward: -1420.3780 [72.27], Avg: -1516.2957 (0.962)
Step: 2799, Reward: -1522.1869 [41.44], Avg: -1519.6768 (0.959)
Step: 2999, Reward: -1411.7515 [92.55], Avg: -1518.6517 (0.956)
Step: 3199, Reward: -1437.6173 [52.04], Avg: -1516.8396 (0.953)
Step: 3399, Reward: -1471.5435 [28.09], Avg: -1515.8275 (0.950)
Step: 3599, Reward: -1393.1054 [44.70], Avg: -1511.4928 (0.947)
Step: 3799, Reward: -1461.7071 [36.09], Avg: -1510.7720 (0.945)
Step: 3999, Reward: -1461.6532 [57.52], Avg: -1511.1922 (0.942)
Step: 4199, Reward: -1421.0228 [41.98], Avg: -1508.8975 (0.939)
Step: 4399, Reward: -1397.4707 [63.47], Avg: -1506.7178 (0.936)
Step: 4599, Reward: -1451.5768 [109.32], Avg: -1509.0733 (0.933)
Step: 4799, Reward: -1445.6657 [99.27], Avg: -1510.5676 (0.930)
Step: 4999, Reward: -1403.8835 [46.43], Avg: -1508.1573 (0.928)
Step: 5199, Reward: -1404.1492 [59.37], Avg: -1506.4404 (0.925)
Step: 5399, Reward: -1392.6062 [77.04], Avg: -1505.0776 (0.922)
Step: 5599, Reward: -1366.3752 [145.52], Avg: -1505.3211 (0.919)
Step: 5799, Reward: -1464.8140 [93.82], Avg: -1507.1594 (0.917)
Step: 5999, Reward: -1419.3761 [95.99], Avg: -1507.4328 (0.914)
Step: 6199, Reward: -1533.3650 [32.01], Avg: -1509.3019 (0.911)
Step: 6399, Reward: -1408.1013 [97.08], Avg: -1509.1730 (0.908)
Step: 6599, Reward: -1399.6543 [221.98], Avg: -1512.5810 (0.906)
Step: 6799, Reward: -1464.8823 [28.59], Avg: -1512.0191 (0.903)
Step: 6999, Reward: -1426.4710 [87.83], Avg: -1512.0842 (0.900)
Step: 7199, Reward: -1494.5525 [45.68], Avg: -1512.8661 (0.897)
Step: 7399, Reward: -1268.6651 [250.28], Avg: -1513.0303 (0.895)
Step: 7599, Reward: -1495.3805 [10.50], Avg: -1512.8422 (0.892)
Step: 7799, Reward: -1415.6031 [119.27], Avg: -1513.4072 (0.889)
Step: 7999, Reward: -1271.6794 [168.87], Avg: -1511.5857 (0.887)
Step: 8199, Reward: -1376.5149 [160.92], Avg: -1512.2162 (0.884)
Step: 8399, Reward: -1216.9127 [217.42], Avg: -1510.3619 (0.881)
Step: 8599, Reward: -1416.9942 [141.08], Avg: -1511.4715 (0.879)
Step: 8799, Reward: -1482.2959 [41.88], Avg: -1511.7602 (0.876)
Step: 8999, Reward: -1412.5585 [96.76], Avg: -1511.7059 (0.874)
Step: 9199, Reward: -1256.7228 [105.85], Avg: -1508.4639 (0.871)
Step: 9399, Reward: -1337.8445 [157.21], Avg: -1508.1786 (0.868)
Step: 9599, Reward: -1297.7377 [139.64], Avg: -1506.7036 (0.866)
Step: 9799, Reward: -1341.4954 [146.95], Avg: -1506.3310 (0.863)
Step: 9999, Reward: -1435.2611 [109.97], Avg: -1507.1090 (0.861)
Step: 10199, Reward: -1345.5687 [90.91], Avg: -1505.7240 (0.858)
Step: 10399, Reward: -1391.4611 [56.14], Avg: -1504.6062 (0.855)
Step: 10599, Reward: -1363.2755 [48.07], Avg: -1502.8465 (0.853)
Step: 10799, Reward: -1435.6087 [65.49], Avg: -1502.8142 (0.850)
Step: 10999, Reward: -1305.8839 [93.30], Avg: -1500.9300 (0.848)
Step: 11199, Reward: -1329.8651 [76.48], Avg: -1499.2410 (0.845)
Step: 11399, Reward: -1348.2623 [40.17], Avg: -1497.2969 (0.843)
Step: 11599, Reward: -1330.9935 [101.74], Avg: -1496.1838 (0.840)
Step: 11799, Reward: -1286.5087 [117.38], Avg: -1494.6194 (0.838)
Step: 11999, Reward: -1316.4069 [80.98], Avg: -1492.9988 (0.835)
Step: 12199, Reward: -1236.1391 [112.99], Avg: -1490.6403 (0.833)
Step: 12399, Reward: -1250.2379 [44.05], Avg: -1487.4733 (0.830)
Step: 12599, Reward: -1230.3944 [111.15], Avg: -1485.1570 (0.828)
Step: 12799, Reward: -1247.4143 [55.97], Avg: -1482.3168 (0.825)
Step: 12999, Reward: -1291.0769 [71.02], Avg: -1480.4674 (0.823)
Step: 13199, Reward: -1303.7907 [70.31], Avg: -1478.8557 (0.820)
Step: 13399, Reward: -1301.9370 [24.40], Avg: -1476.5793 (0.818)
Step: 13599, Reward: -1230.0063 [62.60], Avg: -1473.8738 (0.815)
Step: 13799, Reward: -1201.1905 [50.74], Avg: -1470.6571 (0.813)
Step: 13999, Reward: -1201.5116 [94.02], Avg: -1468.1553 (0.810)
Step: 14199, Reward: -1164.5068 [11.82], Avg: -1464.0450 (0.808)
Step: 14399, Reward: -1094.3422 [104.76], Avg: -1460.3652 (0.805)
Step: 14599, Reward: -1083.1183 [65.49], Avg: -1456.0946 (0.803)
Step: 14799, Reward: -1034.7398 [110.54], Avg: -1451.8945 (0.801)
Step: 14999, Reward: -1070.6316 [49.19], Avg: -1447.4669 (0.798)
Step: 15199, Reward: -1089.1811 [97.09], Avg: -1444.0301 (0.796)
Step: 15399, Reward: -1026.3890 [108.01], Avg: -1440.0089 (0.793)
Step: 15599, Reward: -1031.5380 [80.54], Avg: -1435.8047 (0.791)
Step: 15799, Reward: -1053.2454 [72.48], Avg: -1431.8797 (0.789)
Step: 15999, Reward: -996.4598 [60.55], Avg: -1427.1938 (0.786)
Step: 16199, Reward: -1052.1957 [36.69], Avg: -1423.0172 (0.784)
Step: 16399, Reward: -1105.8169 [60.31], Avg: -1419.8843 (0.782)
Step: 16599, Reward: -1062.5770 [70.75], Avg: -1416.4318 (0.779)
Step: 16799, Reward: -1114.5179 [44.92], Avg: -1413.3724 (0.777)
Step: 16999, Reward: -1093.6790 [96.15], Avg: -1410.7425 (0.775)
Step: 17199, Reward: -1047.6060 [64.21], Avg: -1407.2666 (0.772)
Step: 17399, Reward: -960.6471 [83.53], Avg: -1403.0931 (0.770)
Step: 17599, Reward: -966.7648 [58.63], Avg: -1398.8011 (0.768)
Step: 17799, Reward: -1012.8707 [60.24], Avg: -1395.1417 (0.765)
Step: 17999, Reward: -992.3719 [57.59], Avg: -1391.3064 (0.763)
Step: 18199, Reward: -916.9217 [78.50], Avg: -1386.9560 (0.761)
Step: 18399, Reward: -880.3481 [80.99], Avg: -1382.3297 (0.758)
Step: 18599, Reward: -940.0766 [95.33], Avg: -1378.5994 (0.756)
Step: 18799, Reward: -879.3247 [75.80], Avg: -1374.0943 (0.754)
Step: 18999, Reward: -953.7318 [50.92], Avg: -1370.2054 (0.752)
Step: 19199, Reward: -932.3318 [82.41], Avg: -1366.5027 (0.749)
Step: 19399, Reward: -879.2246 [70.19], Avg: -1362.2028 (0.747)
Step: 19599, Reward: -885.1893 [57.13], Avg: -1357.9183 (0.745)
Step: 19799, Reward: -833.8356 [34.74], Avg: -1352.9755 (0.743)
Step: 19999, Reward: -927.5527 [76.59], Avg: -1349.4871 (0.740)
Step: 20199, Reward: -916.3446 [89.85], Avg: -1346.0882 (0.738)
Step: 20399, Reward: -820.3139 [45.00], Avg: -1341.3747 (0.736)
Step: 20599, Reward: -1030.0475 [62.63], Avg: -1338.9602 (0.734)
Step: 20799, Reward: -856.9382 [80.59], Avg: -1335.1002 (0.732)
Step: 20999, Reward: -981.9292 [103.15], Avg: -1332.7191 (0.729)
Step: 21199, Reward: -964.9086 [70.50], Avg: -1329.9143 (0.727)
Step: 21399, Reward: -869.6693 [27.71], Avg: -1325.8719 (0.725)
Step: 21599, Reward: -889.4473 [43.02], Avg: -1322.2292 (0.723)
Step: 21799, Reward: -867.9336 [73.36], Avg: -1318.7344 (0.721)
Step: 21999, Reward: -883.1687 [106.84], Avg: -1315.7460 (0.719)
Step: 22199, Reward: -889.1046 [76.24], Avg: -1312.5892 (0.716)
Step: 22399, Reward: -859.2822 [59.65], Avg: -1309.0745 (0.714)
Step: 22599, Reward: -1007.5908 [51.73], Avg: -1306.8643 (0.712)
Step: 22799, Reward: -856.6180 [57.37], Avg: -1303.4180 (0.710)
Step: 22999, Reward: -793.3707 [89.53], Avg: -1299.7613 (0.708)
Step: 23199, Reward: -790.6421 [55.02], Avg: -1295.8466 (0.706)
Step: 23399, Reward: -888.3429 [34.71], Avg: -1292.6603 (0.704)
Step: 23599, Reward: -790.4896 [111.36], Avg: -1289.3484 (0.702)
Step: 23799, Reward: -799.0898 [65.98], Avg: -1285.7830 (0.699)
Step: 23999, Reward: -771.1738 [38.08], Avg: -1281.8119 (0.697)
Step: 24199, Reward: -793.1962 [123.84], Avg: -1278.7972 (0.695)
Step: 24399, Reward: -831.4659 [49.25], Avg: -1275.5343 (0.693)
Step: 24599, Reward: -808.6634 [45.91], Avg: -1272.1118 (0.691)
Step: 24799, Reward: -695.3821 [48.95], Avg: -1267.8556 (0.689)
Step: 24999, Reward: -643.6977 [42.93], Avg: -1263.2058 (0.687)
Step: 25199, Reward: -629.4822 [95.88], Avg: -1258.9371 (0.685)
Step: 25399, Reward: -654.4637 [121.48], Avg: -1255.1340 (0.683)
Step: 25599, Reward: -602.7622 [115.52], Avg: -1250.9399 (0.681)
Step: 25799, Reward: -663.3654 [54.35], Avg: -1246.8064 (0.679)
Step: 25999, Reward: -644.4889 [179.68], Avg: -1243.5553 (0.677)
Step: 26199, Reward: -682.3520 [50.59], Avg: -1239.6575 (0.675)
Step: 26399, Reward: -677.7024 [110.13], Avg: -1236.2346 (0.673)
Step: 26599, Reward: -522.6573 [50.59], Avg: -1231.2497 (0.671)
Step: 26799, Reward: -568.1823 [119.91], Avg: -1227.1964 (0.669)
Step: 26999, Reward: -560.3931 [86.07], Avg: -1222.8947 (0.667)
Step: 27199, Reward: -509.3265 [165.72], Avg: -1218.8664 (0.665)
Step: 27399, Reward: -492.3125 [127.50], Avg: -1214.4937 (0.663)
Step: 27599, Reward: -400.0129 [102.05], Avg: -1209.3312 (0.661)
Step: 27799, Reward: -365.7468 [71.65], Avg: -1203.7777 (0.659)
Step: 27999, Reward: -414.6492 [99.02], Avg: -1198.8483 (0.657)
Step: 28199, Reward: -174.7768 [127.07], Avg: -1192.4866 (0.655)
Step: 28399, Reward: -271.7281 [152.13], Avg: -1187.0737 (0.653)
Step: 28599, Reward: -319.7859 [146.27], Avg: -1182.0316 (0.651)
Step: 28799, Reward: -149.2519 [121.21], Avg: -1175.7013 (0.649)
Step: 28999, Reward: -193.8588 [57.04], Avg: -1169.3234 (0.647)
Step: 29199, Reward: -235.3591 [100.89], Avg: -1163.6174 (0.645)
Step: 29399, Reward: -190.1637 [114.95], Avg: -1157.7773 (0.643)
Step: 29599, Reward: -327.6247 [235.14], Avg: -1153.7569 (0.641)
Step: 29799, Reward: -354.2916 [223.78], Avg: -1149.8932 (0.639)
Step: 29999, Reward: -233.2549 [97.82], Avg: -1144.4345 (0.637)
Step: 30199, Reward: -214.9028 [87.92], Avg: -1138.8609 (0.635)
Step: 30399, Reward: -307.3516 [91.71], Avg: -1133.9938 (0.633)
Step: 30599, Reward: -291.3836 [164.88], Avg: -1129.5642 (0.631)
Step: 30799, Reward: -142.3399 [108.93], Avg: -1123.8610 (0.630)
Step: 30999, Reward: -173.7096 [99.65], Avg: -1118.3739 (0.628)
Step: 31199, Reward: -266.1036 [89.33], Avg: -1113.4833 (0.626)
Step: 31399, Reward: -123.9586 [75.66], Avg: -1107.6625 (0.624)
Step: 31599, Reward: -121.7849 [72.65], Avg: -1101.8826 (0.622)
Step: 31799, Reward: -230.3118 [103.59], Avg: -1097.0525 (0.620)
Step: 31999, Reward: -149.8422 [124.56], Avg: -1091.9109 (0.618)
Step: 32199, Reward: -167.7551 [93.08], Avg: -1086.7490 (0.616)
Step: 32399, Reward: -147.5327 [118.90], Avg: -1081.6853 (0.615)
Step: 32599, Reward: -248.3748 [78.86], Avg: -1077.0567 (0.613)
Step: 32799, Reward: -171.3782 [59.70], Avg: -1071.8983 (0.611)
Step: 32999, Reward: -213.1290 [43.81], Avg: -1066.9591 (0.609)
Step: 33199, Reward: -237.4401 [108.14], Avg: -1062.6135 (0.607)
Step: 33399, Reward: -122.5872 [80.28], Avg: -1057.4653 (0.605)
Step: 33599, Reward: -119.2893 [72.10], Avg: -1052.3101 (0.604)
Step: 33799, Reward: -167.7216 [113.75], Avg: -1047.7489 (0.602)
Step: 33999, Reward: -126.6274 [136.07], Avg: -1043.1310 (0.600)
Step: 34199, Reward: -199.5490 [125.86], Avg: -1038.9338 (0.598)
Step: 34399, Reward: -167.5898 [116.92], Avg: -1034.5475 (0.596)
Step: 34599, Reward: -239.7130 [106.42], Avg: -1030.5683 (0.595)
Step: 34799, Reward: -193.0855 [56.28], Avg: -1026.0786 (0.593)
Step: 34999, Reward: -121.4497 [73.31], Avg: -1021.3282 (0.591)
Step: 35199, Reward: -122.5141 [3.03], Avg: -1016.2385 (0.589)
Step: 35399, Reward: -214.6423 [45.96], Avg: -1011.9694 (0.588)
Step: 35599, Reward: -142.2602 [133.45], Avg: -1007.8331 (0.586)
Step: 35799, Reward: -188.3352 [114.96], Avg: -1003.8972 (0.584)
Step: 35999, Reward: -286.6425 [60.50], Avg: -1000.2485 (0.582)
Step: 36199, Reward: -238.1954 [102.98], Avg: -996.6073 (0.581)
Step: 36399, Reward: -167.6165 [119.56], Avg: -992.7093 (0.579)
Step: 36599, Reward: -257.8309 [42.78], Avg: -988.9273 (0.577)
Step: 36799, Reward: -283.9521 [57.95], Avg: -985.4108 (0.575)
Step: 36999, Reward: -147.8532 [89.40], Avg: -981.3667 (0.574)
Step: 37199, Reward: -880.9971 [268.43], Avg: -982.2703 (0.572)
Step: 37399, Reward: -880.9052 [114.84], Avg: -982.3423 (0.570)
Step: 37599, Reward: -969.7875 [65.92], Avg: -982.6262 (0.568)
Step: 37799, Reward: -1101.0362 [273.89], Avg: -984.7018 (0.567)
Step: 37999, Reward: -1295.4671 [240.96], Avg: -987.6056 (0.565)
Step: 38199, Reward: -1277.3649 [274.38], Avg: -990.5592 (0.563)
Step: 38399, Reward: -1230.2933 [343.35], Avg: -993.5961 (0.562)
Step: 38599, Reward: -1133.3032 [298.11], Avg: -995.8646 (0.560)
Step: 38799, Reward: -1229.5740 [251.51], Avg: -998.3657 (0.558)
Step: 38999, Reward: -1302.0844 [269.51], Avg: -1001.3054 (0.557)
Step: 39199, Reward: -1270.9910 [289.75], Avg: -1004.1596 (0.555)
Step: 39399, Reward: -1417.3591 [107.04], Avg: -1006.8004 (0.553)
Step: 39599, Reward: -1315.9864 [287.07], Avg: -1009.8118 (0.552)
Step: 39799, Reward: -1404.2660 [139.38], Avg: -1012.4944 (0.550)
Step: 39999, Reward: -1211.9007 [342.89], Avg: -1015.2058 (0.548)
Step: 40199, Reward: -1176.6975 [355.05], Avg: -1017.7757 (0.547)
Step: 40399, Reward: -1048.0916 [329.77], Avg: -1019.5583 (0.545)
Step: 40599, Reward: -1210.0422 [353.62], Avg: -1022.2386 (0.543)
Step: 40799, Reward: -1282.7987 [221.04], Avg: -1024.5994 (0.542)
Step: 40999, Reward: -1346.5293 [312.62], Avg: -1027.6948 (0.540)
Step: 41199, Reward: -1238.6292 [410.56], Avg: -1030.7117 (0.539)
Step: 41399, Reward: -832.5920 [218.80], Avg: -1030.8116 (0.537)
Step: 41599, Reward: -1297.9556 [290.32], Avg: -1033.4918 (0.535)
Step: 41799, Reward: -1449.9083 [99.41], Avg: -1035.9598 (0.534)
Step: 41999, Reward: -1185.3151 [358.74], Avg: -1038.3793 (0.532)
Step: 42199, Reward: -1566.6110 [56.17], Avg: -1041.1490 (0.530)
Step: 42399, Reward: -1482.4846 [141.71], Avg: -1043.8992 (0.529)
Step: 42599, Reward: -1566.2558 [118.99], Avg: -1046.9102 (0.527)
Step: 42799, Reward: -1219.1255 [363.70], Avg: -1049.4145 (0.526)
Step: 42999, Reward: -1085.5897 [411.42], Avg: -1051.4963 (0.524)
Step: 43199, Reward: -1120.8497 [313.38], Avg: -1053.2682 (0.523)
Step: 43399, Reward: -1559.8562 [98.18], Avg: -1056.0552 (0.521)
Step: 43599, Reward: -1402.6415 [385.02], Avg: -1059.4112 (0.519)
Step: 43799, Reward: -1245.0193 [265.87], Avg: -1061.4727 (0.518)
Step: 43999, Reward: -1349.2346 [323.69], Avg: -1064.2520 (0.516)
Step: 44199, Reward: -1190.8604 [310.61], Avg: -1066.2304 (0.515)
Step: 44399, Reward: -1245.4026 [369.61], Avg: -1068.7024 (0.513)
Step: 44599, Reward: -1472.6746 [129.97], Avg: -1071.0967 (0.512)
Step: 44799, Reward: -1202.7978 [287.43], Avg: -1072.9678 (0.510)
Step: 44999, Reward: -1484.2430 [90.10], Avg: -1075.1962 (0.509)
Step: 45199, Reward: -1356.9903 [318.70], Avg: -1077.8532 (0.507)
Step: 45399, Reward: -1074.5969 [349.64], Avg: -1079.3792 (0.506)
Step: 45599, Reward: -1257.1641 [264.68], Avg: -1081.3198 (0.504)
Step: 45799, Reward: -1225.7741 [330.28], Avg: -1083.3928 (0.503)
Step: 45999, Reward: -1206.0021 [366.63], Avg: -1085.5200 (0.501)
Step: 46199, Reward: -1311.0614 [258.96], Avg: -1087.6174 (0.500)
Step: 46399, Reward: -1423.0893 [106.67], Avg: -1089.5232 (0.498)
Step: 46599, Reward: -1097.5355 [293.60], Avg: -1090.8176 (0.497)
Step: 46799, Reward: -1354.7241 [288.05], Avg: -1093.1764 (0.495)
Step: 46999, Reward: -1517.5018 [95.43], Avg: -1095.3881 (0.494)
Step: 47199, Reward: -1255.4668 [322.63], Avg: -1097.4335 (0.492)
Step: 47399, Reward: -1063.2813 [283.10], Avg: -1098.4839 (0.491)
Step: 47599, Reward: -1522.2700 [15.83], Avg: -1100.3311 (0.489)
Step: 47799, Reward: -1376.4503 [302.26], Avg: -1102.7511 (0.488)
Step: 47999, Reward: -1234.5707 [305.10], Avg: -1104.5716 (0.486)
Step: 48199, Reward: -1388.4988 [258.10], Avg: -1106.8206 (0.485)
Step: 48399, Reward: -1209.2660 [315.84], Avg: -1108.5491 (0.483)
Step: 48599, Reward: -1335.7839 [228.75], Avg: -1110.4255 (0.482)
Step: 48799, Reward: -1362.6449 [300.49], Avg: -1112.6908 (0.480)
Step: 48999, Reward: -1358.8555 [264.93], Avg: -1114.7768 (0.479)
Step: 49199, Reward: -1356.8760 [244.42], Avg: -1116.7545 (0.478)
Step: 49399, Reward: -1214.1715 [303.41], Avg: -1118.3773 (0.476)
Step: 49599, Reward: -1055.1033 [316.05], Avg: -1119.3966 (0.475)
Step: 49799, Reward: -1377.8103 [311.07], Avg: -1121.6837 (0.473)
Step: 49999, Reward: -1391.5704 [263.16], Avg: -1123.8159 (0.472)
Step: 50199, Reward: -1262.8374 [336.25], Avg: -1125.7094 (0.470)
Step: 50399, Reward: -1186.7817 [322.27], Avg: -1127.2306 (0.469)
Step: 50599, Reward: -1186.7421 [348.63], Avg: -1128.8438 (0.468)
Step: 50799, Reward: -1354.5147 [293.54], Avg: -1130.8879 (0.466)
Step: 50999, Reward: -1370.0648 [254.22], Avg: -1132.8228 (0.465)
Step: 51199, Reward: -1245.8652 [327.35], Avg: -1134.5431 (0.463)
Step: 51399, Reward: -1489.6646 [30.92], Avg: -1136.0452 (0.462)
Step: 51599, Reward: -1297.6210 [240.27], Avg: -1137.6027 (0.461)
Step: 51799, Reward: -1336.2093 [241.86], Avg: -1139.3034 (0.459)
Step: 51999, Reward: -961.2578 [195.58], Avg: -1139.3708 (0.458)
Step: 52199, Reward: -1097.9646 [325.93], Avg: -1140.4609 (0.456)
Step: 52399, Reward: -1393.5470 [252.10], Avg: -1142.3891 (0.455)
Step: 52599, Reward: -1265.5582 [316.07], Avg: -1144.0592 (0.454)
Step: 52799, Reward: -1232.8439 [290.72], Avg: -1145.4967 (0.452)
Step: 52999, Reward: -1351.6144 [292.77], Avg: -1147.3793 (0.451)
Step: 53199, Reward: -1461.0150 [74.57], Avg: -1148.8388 (0.450)
Step: 53399, Reward: -1232.6834 [325.64], Avg: -1150.3724 (0.448)
Step: 53599, Reward: -1498.3762 [48.46], Avg: -1151.8518 (0.447)
Step: 53799, Reward: -1221.7166 [270.03], Avg: -1153.1153 (0.446)
Step: 53999, Reward: -1336.9661 [261.11], Avg: -1154.7633 (0.444)
Step: 54199, Reward: -1255.9019 [302.63], Avg: -1156.2532 (0.443)
Step: 54399, Reward: -1381.5334 [249.74], Avg: -1157.9996 (0.442)
Step: 54599, Reward: -1043.0157 [259.11], Avg: -1158.5276 (0.440)
Step: 54799, Reward: -1367.7031 [196.25], Avg: -1160.0072 (0.439)
Step: 54999, Reward: -1252.4020 [252.94], Avg: -1161.2630 (0.438)
Step: 55199, Reward: -1355.1461 [189.57], Avg: -1162.6523 (0.436)
Step: 55399, Reward: -1367.2515 [202.71], Avg: -1164.1227 (0.435)
Step: 55599, Reward: -1388.7912 [242.66], Avg: -1165.8038 (0.434)
Step: 55799, Reward: -1377.1114 [221.83], Avg: -1167.3562 (0.432)
Step: 55999, Reward: -1441.3875 [27.26], Avg: -1168.4323 (0.431)
Step: 56199, Reward: -1235.1274 [245.85], Avg: -1169.5445 (0.430)
Step: 56399, Reward: -1140.5196 [262.41], Avg: -1170.3721 (0.429)
Step: 56599, Reward: -1119.4392 [250.71], Avg: -1171.0781 (0.427)
Step: 56799, Reward: -1380.0947 [235.54], Avg: -1172.6434 (0.426)
Step: 56999, Reward: -1485.4105 [38.25], Avg: -1173.8750 (0.425)
Step: 57199, Reward: -1393.7099 [224.39], Avg: -1175.4283 (0.423)
Step: 57399, Reward: -1138.8306 [297.37], Avg: -1176.3369 (0.422)
Step: 57599, Reward: -1261.4376 [301.85], Avg: -1177.6805 (0.421)
Step: 57799, Reward: -1401.0924 [219.80], Avg: -1179.2141 (0.420)
Step: 57999, Reward: -1348.2183 [217.85], Avg: -1180.5481 (0.418)
Step: 58199, Reward: -1236.4450 [275.41], Avg: -1181.6866 (0.417)
Step: 58399, Reward: -1272.9404 [279.63], Avg: -1182.9567 (0.416)
Step: 58599, Reward: -1498.6663 [37.48], Avg: -1184.1621 (0.415)
Step: 58799, Reward: -1390.0703 [246.78], Avg: -1185.7019 (0.413)
Step: 58999, Reward: -1476.6431 [33.47], Avg: -1186.8016 (0.412)
Step: 59199, Reward: -1390.7290 [246.71], Avg: -1188.3241 (0.411)
Step: 59399, Reward: -1263.3146 [303.70], Avg: -1189.5991 (0.410)
Step: 59599, Reward: -1125.2145 [281.33], Avg: -1190.3271 (0.408)
Step: 59799, Reward: -1277.1312 [293.93], Avg: -1191.6004 (0.407)
Step: 59999, Reward: -1226.8587 [281.64], Avg: -1192.6567 (0.406)
Step: 60199, Reward: -1264.2825 [316.62], Avg: -1193.9466 (0.405)
Step: 60399, Reward: -1137.2796 [306.50], Avg: -1194.7739 (0.404)
Step: 60599, Reward: -1513.2811 [21.15], Avg: -1195.8948 (0.402)
Step: 60799, Reward: -1378.2037 [249.57], Avg: -1197.3155 (0.401)
Step: 60999, Reward: -1242.8907 [277.17], Avg: -1198.3737 (0.400)
Step: 61199, Reward: -1381.4947 [253.75], Avg: -1199.8013 (0.399)
Step: 61399, Reward: -1236.0062 [285.34], Avg: -1200.8487 (0.398)
Step: 61599, Reward: -1201.7536 [262.91], Avg: -1201.7053 (0.396)
Step: 61799, Reward: -1247.8090 [301.44], Avg: -1202.8300 (0.395)
Step: 61999, Reward: -1260.3757 [320.67], Avg: -1204.0501 (0.394)
Step: 62199, Reward: -1364.6687 [216.43], Avg: -1205.2624 (0.393)
Step: 62399, Reward: -1378.6819 [256.43], Avg: -1206.6402 (0.392)
Step: 62599, Reward: -1475.5781 [68.86], Avg: -1207.7194 (0.390)
Step: 62799, Reward: -1399.3196 [255.66], Avg: -1209.1438 (0.389)
Step: 62999, Reward: -1243.8160 [284.06], Avg: -1210.1556 (0.388)
Step: 63199, Reward: -1078.1314 [285.28], Avg: -1210.6406 (0.387)
Step: 63399, Reward: -1368.6899 [293.53], Avg: -1212.0652 (0.386)
Step: 63599, Reward: -1494.5975 [34.14], Avg: -1213.0610 (0.385)
Step: 63799, Reward: -1505.0415 [42.80], Avg: -1214.1105 (0.383)
Step: 63999, Reward: -1329.8290 [231.48], Avg: -1215.1955 (0.382)
Step: 64199, Reward: -1372.8124 [247.53], Avg: -1216.4576 (0.381)
Step: 64399, Reward: -1346.4887 [233.78], Avg: -1217.5875 (0.380)
Step: 64599, Reward: -1361.4415 [235.97], Avg: -1218.7634 (0.379)
Step: 64799, Reward: -1514.6991 [15.68], Avg: -1219.7252 (0.378)
Step: 64999, Reward: -1508.0215 [42.94], Avg: -1220.7444 (0.377)
Step: 65199, Reward: -1346.0683 [242.79], Avg: -1221.8736 (0.376)
Step: 65399, Reward: -1015.6820 [258.99], Avg: -1222.0350 (0.374)
Step: 65599, Reward: -1003.3177 [251.41], Avg: -1222.1347 (0.373)
Step: 65799, Reward: -1364.0695 [238.34], Avg: -1223.2905 (0.372)
Step: 65999, Reward: -1218.9539 [310.76], Avg: -1224.2191 (0.371)
Step: 66199, Reward: -1365.0470 [245.59], Avg: -1225.3865 (0.370)
Step: 66399, Reward: -982.3822 [266.07], Avg: -1225.4560 (0.369)
Step: 66599, Reward: -1237.5290 [333.83], Avg: -1226.4948 (0.368)
Step: 66799, Reward: -1252.2835 [338.33], Avg: -1227.5849 (0.367)
Step: 66999, Reward: -1462.2854 [33.98], Avg: -1228.3870 (0.365)
Step: 67199, Reward: -1219.5192 [325.03], Avg: -1229.3279 (0.364)
Step: 67399, Reward: -1395.9609 [251.35], Avg: -1230.5682 (0.363)
Step: 67599, Reward: -1299.0453 [281.25], Avg: -1231.6029 (0.362)
Step: 67799, Reward: -1363.8661 [250.84], Avg: -1232.7330 (0.361)
Step: 67999, Reward: -1519.8641 [3.41], Avg: -1233.5876 (0.360)
Step: 68199, Reward: -1387.3892 [250.95], Avg: -1234.7745 (0.359)
Step: 68399, Reward: -1516.5233 [5.50], Avg: -1235.6144 (0.358)
Step: 68599, Reward: -1201.5930 [316.53], Avg: -1236.4381 (0.357)
Step: 68799, Reward: -1223.0103 [288.02], Avg: -1237.2363 (0.356)
Step: 68999, Reward: -1090.3376 [268.75], Avg: -1237.5895 (0.355)
Step: 69199, Reward: -1199.8015 [341.91], Avg: -1238.4685 (0.354)
Step: 69399, Reward: -1416.2545 [62.50], Avg: -1239.1610 (0.353)
Step: 69599, Reward: -1328.4507 [284.54], Avg: -1240.2352 (0.351)
Step: 69799, Reward: -1231.0877 [350.88], Avg: -1241.2144 (0.350)
Step: 69999, Reward: -1068.7544 [331.78], Avg: -1241.6696 (0.349)
Step: 70199, Reward: -1360.0332 [297.23], Avg: -1242.8536 (0.348)
Step: 70399, Reward: -1501.9031 [35.58], Avg: -1243.6906 (0.347)
Step: 70599, Reward: -1203.3192 [344.12], Avg: -1244.5511 (0.346)
Step: 70799, Reward: -1506.2144 [26.19], Avg: -1245.3642 (0.345)
Step: 70999, Reward: -1343.6721 [294.29], Avg: -1246.4701 (0.344)
Step: 71199, Reward: -1212.3391 [327.70], Avg: -1247.2948 (0.343)
Step: 71399, Reward: -1386.7870 [265.07], Avg: -1248.4280 (0.342)
Step: 71599, Reward: -1348.7208 [291.71], Avg: -1249.5229 (0.341)
Step: 71799, Reward: -1377.5927 [269.12], Avg: -1250.6293 (0.340)
Step: 71999, Reward: -1512.5077 [18.25], Avg: -1251.4074 (0.339)
Step: 72199, Reward: -1346.1508 [240.57], Avg: -1252.3363 (0.338)
Step: 72399, Reward: -1343.2405 [256.34], Avg: -1253.2955 (0.337)
Step: 72599, Reward: -1367.5550 [304.64], Avg: -1254.4495 (0.336)
Step: 72799, Reward: -1493.2245 [31.80], Avg: -1255.1929 (0.335)
Step: 72999, Reward: -1198.3211 [362.23], Avg: -1256.0295 (0.334)
Step: 73199, Reward: -1503.3754 [21.53], Avg: -1256.7641 (0.333)
Step: 73399, Reward: -1343.4722 [292.19], Avg: -1257.7965 (0.332)
Step: 73599, Reward: -1474.3943 [71.39], Avg: -1258.5791 (0.331)
Step: 73799, Reward: -1325.2596 [276.90], Avg: -1259.5102 (0.330)
Step: 73999, Reward: -1222.0986 [368.05], Avg: -1260.4038 (0.329)
Step: 74199, Reward: -1346.5158 [272.79], Avg: -1261.3712 (0.328)
Step: 74399, Reward: -1377.9078 [256.51], Avg: -1262.3740 (0.327)
Step: 74599, Reward: -1359.5735 [246.58], Avg: -1263.2957 (0.326)
Step: 74799, Reward: -1070.1928 [368.46], Avg: -1263.7645 (0.325)
Step: 74999, Reward: -1075.4677 [381.93], Avg: -1264.2809 (0.324)
Step: 75199, Reward: -1386.3432 [253.26], Avg: -1265.2791 (0.323)
Step: 75399, Reward: -1082.5817 [318.18], Avg: -1265.6384 (0.322)
Step: 75599, Reward: -1206.6086 [319.70], Avg: -1266.3281 (0.321)
Step: 75799, Reward: -1206.7324 [367.18], Avg: -1267.1396 (0.320)
Step: 75999, Reward: -1341.4098 [295.98], Avg: -1268.1140 (0.319)
Step: 76199, Reward: -1230.6174 [337.00], Avg: -1268.9001 (0.318)
Step: 76399, Reward: -1347.4952 [334.48], Avg: -1269.9814 (0.317)
Step: 76599, Reward: -1374.1554 [301.25], Avg: -1271.0400 (0.316)
Step: 76799, Reward: -1468.7685 [58.66], Avg: -1271.7077 (0.315)
Step: 76999, Reward: -1187.9785 [352.77], Avg: -1272.4065 (0.315)
Step: 77199, Reward: -1347.0841 [297.14], Avg: -1273.3697 (0.314)
Step: 77399, Reward: -1359.3470 [303.04], Avg: -1274.3749 (0.313)
Step: 77599, Reward: -1366.2456 [278.29], Avg: -1275.3290 (0.312)
Step: 77799, Reward: -1480.4172 [46.07], Avg: -1275.9746 (0.311)
Step: 77999, Reward: -1510.4742 [19.89], Avg: -1276.6269 (0.310)
Step: 78199, Reward: -1195.6442 [326.47], Avg: -1277.2547 (0.309)
Step: 78399, Reward: -1214.3440 [327.73], Avg: -1277.9303 (0.308)
Step: 78599, Reward: -1364.4474 [254.50], Avg: -1278.7980 (0.307)
Step: 78799, Reward: -1210.6994 [365.74], Avg: -1279.5535 (0.306)
Step: 78999, Reward: -1229.9258 [324.98], Avg: -1280.2506 (0.305)
Step: 79199, Reward: -1229.5897 [316.94], Avg: -1280.9230 (0.304)
Step: 79399, Reward: -1251.3848 [306.17], Avg: -1281.6198 (0.303)
Step: 79599, Reward: -1075.7542 [344.99], Avg: -1281.9693 (0.302)
Step: 79799, Reward: -1184.4505 [346.90], Avg: -1282.5944 (0.302)
Step: 79999, Reward: -1197.7936 [349.10], Avg: -1283.2551 (0.301)
Step: 80199, Reward: -1063.7538 [318.27], Avg: -1283.5014 (0.300)
Step: 80399, Reward: -1380.1760 [254.32], Avg: -1284.3746 (0.299)
Step: 80599, Reward: -1214.5524 [324.62], Avg: -1285.0068 (0.298)
Step: 80799, Reward: -1350.6597 [292.43], Avg: -1285.8931 (0.297)
Step: 80999, Reward: -1366.0485 [249.84], Avg: -1286.7079 (0.296)
Step: 81199, Reward: -1458.7331 [55.64], Avg: -1287.2687 (0.295)
Step: 81399, Reward: -1125.1725 [300.79], Avg: -1287.6095 (0.294)
Step: 81599, Reward: -1455.4026 [64.26], Avg: -1288.1782 (0.294)
Step: 81799, Reward: -1512.8050 [12.73], Avg: -1288.7586 (0.293)
Step: 81999, Reward: -1245.8911 [291.20], Avg: -1289.3643 (0.292)
Step: 82199, Reward: -1506.1677 [15.56], Avg: -1289.9296 (0.291)
Step: 82399, Reward: -1219.3502 [328.26], Avg: -1290.5551 (0.290)
Step: 82599, Reward: -1229.6140 [295.76], Avg: -1291.1236 (0.289)
Step: 82799, Reward: -1126.9746 [297.89], Avg: -1291.4467 (0.288)
Step: 82999, Reward: -1356.6608 [238.27], Avg: -1292.1780 (0.287)
Step: 83199, Reward: -1509.2645 [11.07], Avg: -1292.7264 (0.287)
Step: 83399, Reward: -1357.2965 [244.31], Avg: -1293.4671 (0.286)
Step: 83599, Reward: -1386.3363 [249.45], Avg: -1294.2861 (0.285)
Step: 83799, Reward: -1464.4630 [33.38], Avg: -1294.7719 (0.284)
Step: 83999, Reward: -1451.8017 [94.72], Avg: -1295.3713 (0.283)
Step: 84199, Reward: -1481.9269 [31.24], Avg: -1295.8887 (0.282)
Step: 84399, Reward: -1504.2030 [13.73], Avg: -1296.4148 (0.281)
Step: 84599, Reward: -1324.8218 [225.71], Avg: -1297.0156 (0.281)
Step: 84799, Reward: -1360.2023 [248.80], Avg: -1297.7514 (0.280)
Step: 84999, Reward: -1486.5494 [68.01], Avg: -1298.3556 (0.279)
Step: 85199, Reward: -1450.7872 [55.85], Avg: -1298.8446 (0.278)
Step: 85399, Reward: -1510.2796 [11.43], Avg: -1299.3665 (0.277)
Step: 85599, Reward: -1229.1504 [294.23], Avg: -1299.8899 (0.276)
Step: 85799, Reward: -1365.8797 [245.99], Avg: -1300.6171 (0.276)
Step: 85999, Reward: -1354.8814 [237.21], Avg: -1301.2950 (0.275)
Step: 86199, Reward: -1345.8207 [230.85], Avg: -1301.9339 (0.274)
Step: 86399, Reward: -1202.2928 [324.65], Avg: -1302.4548 (0.273)
Step: 86599, Reward: -1331.4074 [239.74], Avg: -1303.0753 (0.272)
Step: 86799, Reward: -1095.8568 [277.41], Avg: -1303.2370 (0.271)
Step: 86999, Reward: -1128.1496 [296.96], Avg: -1303.5172 (0.271)
Step: 87199, Reward: -1234.6723 [343.70], Avg: -1304.1476 (0.270)
Step: 87399, Reward: -1377.8020 [246.29], Avg: -1304.8797 (0.269)
Step: 87599, Reward: -1361.7930 [246.54], Avg: -1305.5725 (0.268)
Step: 87799, Reward: -1352.6919 [285.41], Avg: -1306.3300 (0.267)
Step: 87999, Reward: -1504.9862 [31.61], Avg: -1306.8533 (0.267)
Step: 88199, Reward: -1106.3044 [329.93], Avg: -1307.1467 (0.266)
Step: 88399, Reward: -1114.1483 [333.57], Avg: -1307.4647 (0.265)
Step: 88599, Reward: -1244.7002 [310.64], Avg: -1308.0243 (0.264)
Step: 88799, Reward: -1091.8042 [300.00], Avg: -1308.2130 (0.263)
Step: 88999, Reward: -1365.1813 [245.49], Avg: -1308.8926 (0.263)
Step: 89199, Reward: -1383.4976 [255.88], Avg: -1309.6336 (0.262)
Step: 89399, Reward: -1202.4659 [289.02], Avg: -1310.0405 (0.261)
Step: 89599, Reward: -1000.3375 [242.09], Avg: -1309.8895 (0.260)
Step: 89799, Reward: -1351.9325 [250.25], Avg: -1310.5405 (0.259)
Step: 89999, Reward: -1268.0895 [320.11], Avg: -1311.1575 (0.259)
Step: 90199, Reward: -1135.8560 [309.82], Avg: -1311.4558 (0.258)
Step: 90399, Reward: -1379.3409 [251.19], Avg: -1312.1617 (0.257)
Step: 90599, Reward: -1360.3892 [249.52], Avg: -1312.8190 (0.256)
Step: 90799, Reward: -1382.6298 [247.65], Avg: -1313.5182 (0.256)
Step: 90999, Reward: -1506.1678 [15.81], Avg: -1313.9764 (0.255)
Step: 91199, Reward: -1258.5236 [312.29], Avg: -1314.5396 (0.254)
Step: 91399, Reward: -1356.8235 [236.76], Avg: -1315.1502 (0.253)
Step: 91599, Reward: -1494.3573 [34.92], Avg: -1315.6177 (0.253)
Step: 91799, Reward: -1350.6486 [239.88], Avg: -1316.2167 (0.252)
Step: 91999, Reward: -1387.8262 [258.33], Avg: -1316.9339 (0.251)
Step: 92199, Reward: -1387.7549 [253.09], Avg: -1317.6366 (0.250)
Step: 92399, Reward: -1014.6663 [257.33], Avg: -1317.5378 (0.250)
Step: 92599, Reward: -1238.2005 [300.25], Avg: -1318.0149 (0.249)
Step: 92799, Reward: -1098.0201 [277.91], Avg: -1318.1397 (0.248)
Step: 92999, Reward: -1376.4731 [246.04], Avg: -1318.7943 (0.247)
Step: 93199, Reward: -1212.0994 [321.99], Avg: -1319.2563 (0.247)
Step: 93399, Reward: -1250.5211 [311.36], Avg: -1319.7759 (0.246)
Step: 93599, Reward: -1456.1155 [59.31], Avg: -1320.1939 (0.245)
Step: 93799, Reward: -1347.9880 [234.51], Avg: -1320.7532 (0.244)
Step: 93999, Reward: -1519.9913 [24.03], Avg: -1321.2282 (0.244)
Step: 94199, Reward: -1090.8600 [368.71], Avg: -1321.5220 (0.243)
Step: 94399, Reward: -1247.1694 [340.74], Avg: -1322.0863 (0.242)
Step: 94599, Reward: -1396.8352 [261.93], Avg: -1322.7981 (0.241)
Step: 94799, Reward: -1220.9778 [327.97], Avg: -1323.2752 (0.241)
Step: 94999, Reward: -1252.2586 [310.57], Avg: -1323.7796 (0.240)
Step: 95199, Reward: -1250.3336 [328.40], Avg: -1324.3152 (0.239)
Step: 95399, Reward: -1219.3867 [330.41], Avg: -1324.7879 (0.239)
Step: 95599, Reward: -1373.1425 [277.41], Avg: -1325.4694 (0.238)
Step: 95799, Reward: -1251.5432 [320.89], Avg: -1325.9850 (0.237)
Step: 95999, Reward: -1232.9547 [357.80], Avg: -1326.5366 (0.236)
Step: 96199, Reward: -1243.1620 [351.68], Avg: -1327.0944 (0.236)
Step: 96399, Reward: -1510.5585 [47.70], Avg: -1327.5740 (0.235)
Step: 96599, Reward: -1236.7438 [299.39], Avg: -1328.0058 (0.234)
Step: 96799, Reward: -1241.6848 [311.80], Avg: -1328.4716 (0.234)
Step: 96999, Reward: -1359.0079 [249.81], Avg: -1329.0497 (0.233)
Step: 97199, Reward: -1391.2658 [257.78], Avg: -1329.7081 (0.232)
Step: 97399, Reward: -1526.6479 [31.18], Avg: -1330.1765 (0.231)
Step: 97599, Reward: -1380.9549 [256.08], Avg: -1330.8053 (0.231)
Step: 97799, Reward: -1058.3610 [309.75], Avg: -1330.8816 (0.230)
Step: 97999, Reward: -1314.4842 [228.26], Avg: -1331.3140 (0.229)
Step: 98199, Reward: -1179.0525 [295.46], Avg: -1331.6056 (0.229)
Step: 98399, Reward: -1198.5859 [302.64], Avg: -1331.9504 (0.228)
Step: 98599, Reward: -1525.9283 [6.20], Avg: -1332.3564 (0.227)
Step: 98799, Reward: -1359.9218 [290.13], Avg: -1332.9995 (0.227)
Step: 98999, Reward: -1361.9833 [248.57], Avg: -1333.5603 (0.226)
Step: 99199, Reward: -1485.6976 [50.15], Avg: -1333.9681 (0.225)
Step: 99399, Reward: -1122.1142 [315.21], Avg: -1334.1760 (0.225)
Step: 99599, Reward: -1367.9194 [259.12], Avg: -1334.7641 (0.224)
Step: 99799, Reward: -1399.8200 [263.61], Avg: -1335.4228 (0.223)
Step: 99999, Reward: -1201.0079 [319.32], Avg: -1335.7926 (0.223)
