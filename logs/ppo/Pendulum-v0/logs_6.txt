Model: <class 'models.ppo.PPOAgent'>, Dir: Pendulum-v0
num_envs: 16,

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

EPS_MIN = 0.1                	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.997             	# The rate at which eps decays from EPS_MAX to EPS_MIN
BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.1				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) * critic_error.pow(2) * scale
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss.mean())
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		update_freq = int(self.update_freq * (1 - self.eps + EPS_MIN)**2)
		if len(self.buffer) >= update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, scale=8*update_freq/len(self.replay_buffer))
		if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddqn", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "LunarLander-v2"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[3]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class PixelAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	logger = Logger(model, env_name, num_envs=num_envs)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = PixelAgent(envs.state_size, envs.action_size, num_envs, model)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0] or s+1 % envs.env.spec.max_episode_steps == 0:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 199, Reward: -1247.7653 [164.20], Avg: -1411.9638 (0.997)
Step: 399, Reward: -1275.6807 [254.72], Avg: -1471.1838 (0.994)
Step: 599, Reward: -1058.5596 [146.03], Avg: -1382.3202 (0.991)
Step: 799, Reward: -1211.7987 [112.22], Avg: -1367.7453 (0.988)
Step: 999, Reward: -1223.7397 [96.92], Avg: -1358.3274 (0.985)
Step: 1199, Reward: -1374.3892 [101.08], Avg: -1377.8511 (0.982)
Step: 1399, Reward: -1325.0692 [66.92], Avg: -1379.8702 (0.979)
Step: 1599, Reward: -1234.7344 [116.94], Avg: -1376.3452 (0.976)
Step: 1799, Reward: -1377.2600 [42.57], Avg: -1381.1763 (0.973)
Step: 1999, Reward: -1386.6543 [64.21], Avg: -1388.1452 (0.970)
Step: 2199, Reward: -1389.1268 [181.90], Avg: -1404.7709 (0.967)
Step: 2399, Reward: -1262.4094 [94.20], Avg: -1400.7576 (0.965)
Step: 2599, Reward: -1272.6239 [121.64], Avg: -1400.2583 (0.962)
Step: 2799, Reward: -1292.3274 [62.01], Avg: -1396.9781 (0.959)
Step: 2999, Reward: -1062.5451 [66.77], Avg: -1379.1337 (0.956)
Step: 3199, Reward: -1238.7025 [29.56], Avg: -1372.2043 (0.953)
Step: 3399, Reward: -1276.0958 [81.21], Avg: -1371.3280 (0.950)
Step: 3599, Reward: -1351.5103 [31.15], Avg: -1371.9575 (0.947)
Step: 3799, Reward: -1360.9069 [65.73], Avg: -1374.8353 (0.945)
Step: 3999, Reward: -1413.3331 [45.19], Avg: -1379.0195 (0.942)
Step: 4199, Reward: -1311.5925 [116.67], Avg: -1381.3643 (0.939)
Step: 4399, Reward: -1336.2790 [84.90], Avg: -1383.1741 (0.936)
Step: 4599, Reward: -1328.6538 [37.63], Avg: -1382.4398 (0.933)
Step: 4799, Reward: -1328.3910 [67.85], Avg: -1383.0149 (0.930)
Step: 4999, Reward: -1305.8595 [76.34], Avg: -1382.9822 (0.928)
Step: 5199, Reward: -1374.6125 [60.72], Avg: -1384.9958 (0.925)
Step: 5399, Reward: -1356.3199 [54.26], Avg: -1385.9433 (0.922)
Step: 5599, Reward: -1339.6016 [44.22], Avg: -1385.8675 (0.919)
Step: 5799, Reward: -1340.1457 [46.40], Avg: -1385.8908 (0.917)
Step: 5999, Reward: -1383.0969 [32.71], Avg: -1386.8880 (0.914)
Step: 6199, Reward: -1386.5628 [39.60], Avg: -1388.1550 (0.911)
Step: 6399, Reward: -1376.2015 [53.32], Avg: -1389.4478 (0.908)
Step: 6599, Reward: -1455.4500 [49.97], Avg: -1392.9622 (0.906)
Step: 6799, Reward: -1347.0294 [139.58], Avg: -1395.7166 (0.903)
Step: 6999, Reward: -1354.4412 [160.33], Avg: -1399.1182 (0.900)
Step: 7199, Reward: -1334.8749 [184.62], Avg: -1402.4621 (0.897)
Step: 7399, Reward: -1529.9245 [25.62], Avg: -1406.5996 (0.895)
Step: 7599, Reward: -1465.6442 [85.35], Avg: -1410.3994 (0.892)
Step: 7799, Reward: -1444.9868 [148.58], Avg: -1415.0959 (0.889)
Step: 7999, Reward: -1386.0258 [198.62], Avg: -1419.3345 (0.887)
Step: 8199, Reward: -1314.8882 [143.47], Avg: -1420.2863 (0.884)
Step: 8399, Reward: -1471.3928 [37.02], Avg: -1422.3845 (0.881)
Step: 8599, Reward: -1324.4855 [159.73], Avg: -1423.8224 (0.879)
Step: 8799, Reward: -1360.2309 [104.70], Avg: -1424.7568 (0.876)
Step: 8999, Reward: -1345.4794 [123.70], Avg: -1425.7440 (0.874)
Step: 9199, Reward: -1363.5998 [115.98], Avg: -1426.9143 (0.871)
Step: 9399, Reward: -1374.4210 [78.74], Avg: -1427.4728 (0.868)
Step: 9599, Reward: -1411.3962 [133.80], Avg: -1429.9253 (0.866)
Step: 9799, Reward: -1244.1032 [185.15], Avg: -1429.9116 (0.863)
Step: 9999, Reward: -1331.6367 [151.18], Avg: -1430.9697 (0.861)
Step: 10199, Reward: -1332.7388 [121.42], Avg: -1431.4244 (0.858)
Step: 10399, Reward: -1365.6821 [112.25], Avg: -1432.3188 (0.855)
Step: 10599, Reward: -1393.8342 [48.02], Avg: -1432.4987 (0.853)
Step: 10799, Reward: -1171.4388 [178.52], Avg: -1430.9701 (0.850)
Step: 10999, Reward: -1301.2698 [65.87], Avg: -1429.8095 (0.848)
Step: 11199, Reward: -1326.2346 [61.57], Avg: -1429.0593 (0.845)
Step: 11399, Reward: -1407.4306 [31.37], Avg: -1429.2303 (0.843)
Step: 11599, Reward: -1240.9842 [165.35], Avg: -1428.8355 (0.840)
Step: 11799, Reward: -1201.3780 [208.33], Avg: -1428.5113 (0.838)
Step: 11999, Reward: -1103.1449 [166.83], Avg: -1425.8690 (0.835)
Step: 12199, Reward: -1136.6188 [116.64], Avg: -1423.0394 (0.833)
Step: 12399, Reward: -1065.4022 [54.50], Avg: -1418.1502 (0.830)
Step: 12599, Reward: -1013.3678 [106.53], Avg: -1413.4159 (0.828)
Step: 12799, Reward: -1049.6329 [83.72], Avg: -1409.0400 (0.825)
Step: 12999, Reward: -902.8758 [96.32], Avg: -1402.7347 (0.823)
Step: 13199, Reward: -901.8704 [66.62], Avg: -1396.1552 (0.820)
Step: 13399, Reward: -968.3568 [48.76], Avg: -1390.4978 (0.818)
Step: 13599, Reward: -947.6635 [98.06], Avg: -1385.4276 (0.815)
Step: 13799, Reward: -830.1030 [65.08], Avg: -1378.3226 (0.813)
Step: 13999, Reward: -929.1645 [91.30], Avg: -1373.2103 (0.810)
Step: 14199, Reward: -970.3946 [115.83], Avg: -1369.1682 (0.808)
Step: 14399, Reward: -923.9249 [84.07], Avg: -1364.1519 (0.805)
Step: 14599, Reward: -992.6573 [53.60], Avg: -1359.7972 (0.803)
Step: 14799, Reward: -966.0437 [91.01], Avg: -1355.7061 (0.801)
Step: 14999, Reward: -1104.7514 [45.60], Avg: -1352.9680 (0.798)
Step: 15199, Reward: -1086.8376 [46.84], Avg: -1350.0825 (0.796)
Step: 15399, Reward: -978.5979 [38.94], Avg: -1345.7637 (0.793)
Step: 15599, Reward: -905.6795 [96.28], Avg: -1341.3559 (0.791)
Step: 15799, Reward: -933.6318 [66.15], Avg: -1337.0322 (0.789)
Step: 15999, Reward: -884.6402 [44.35], Avg: -1331.9316 (0.786)
Step: 16199, Reward: -915.0287 [51.09], Avg: -1327.4154 (0.784)
Step: 16399, Reward: -867.4309 [63.92], Avg: -1322.5853 (0.782)
Step: 16599, Reward: -929.6857 [59.35], Avg: -1318.5666 (0.779)
Step: 16799, Reward: -852.4275 [89.07], Avg: -1314.0777 (0.777)
Step: 16999, Reward: -977.7247 [53.70], Avg: -1310.7524 (0.775)
Step: 17199, Reward: -918.5644 [43.24], Avg: -1306.6949 (0.772)
Step: 17399, Reward: -993.9623 [80.40], Avg: -1304.0244 (0.770)
Step: 17599, Reward: -963.7739 [75.05], Avg: -1301.0108 (0.768)
Step: 17799, Reward: -920.3301 [44.65], Avg: -1297.2351 (0.765)
Step: 17999, Reward: -969.8031 [52.19], Avg: -1294.1768 (0.763)
Step: 18199, Reward: -960.8901 [50.08], Avg: -1291.0647 (0.761)
Step: 18399, Reward: -1025.5496 [101.41], Avg: -1289.2809 (0.758)
Step: 18599, Reward: -1038.7549 [50.23], Avg: -1287.1271 (0.756)
Step: 18799, Reward: -1071.7035 [39.59], Avg: -1285.2565 (0.754)
Step: 18999, Reward: -1146.7784 [30.21], Avg: -1284.1168 (0.752)
Step: 19199, Reward: -1108.1058 [45.04], Avg: -1282.7526 (0.749)
Step: 19399, Reward: -1062.7192 [84.38], Avg: -1281.3541 (0.747)
Step: 19599, Reward: -1152.3507 [19.01], Avg: -1280.2317 (0.745)
Step: 19799, Reward: -1015.9453 [10.62], Avg: -1277.6694 (0.743)
Step: 19999, Reward: -1018.2553 [62.84], Avg: -1275.7037 (0.740)
Step: 20199, Reward: -914.2052 [54.00], Avg: -1272.6592 (0.738)
Step: 20399, Reward: -976.1750 [52.45], Avg: -1270.2667 (0.736)
Step: 20599, Reward: -874.7246 [70.89], Avg: -1267.1147 (0.734)
Step: 20799, Reward: -871.2012 [74.16], Avg: -1264.0209 (0.732)
Step: 20999, Reward: -911.6659 [40.61], Avg: -1261.0519 (0.729)
Step: 21199, Reward: -906.3783 [61.06], Avg: -1258.2819 (0.727)
Step: 21399, Reward: -916.7321 [58.04], Avg: -1255.6323 (0.725)
Step: 21599, Reward: -888.4818 [112.44], Avg: -1253.2739 (0.723)
Step: 21799, Reward: -808.5816 [61.57], Avg: -1249.7590 (0.721)
Step: 21999, Reward: -922.6049 [48.13], Avg: -1247.2224 (0.719)
Step: 22199, Reward: -850.8142 [123.49], Avg: -1244.7637 (0.716)
Step: 22399, Reward: -897.4076 [64.31], Avg: -1242.2366 (0.714)
Step: 22599, Reward: -824.2451 [49.71], Avg: -1238.9774 (0.712)
Step: 22799, Reward: -861.6774 [92.45], Avg: -1236.4787 (0.710)
Step: 22999, Reward: -824.6342 [100.14], Avg: -1233.7682 (0.708)
Step: 23199, Reward: -861.8728 [70.80], Avg: -1231.1726 (0.706)
Step: 23399, Reward: -935.8914 [49.55], Avg: -1229.0723 (0.704)
Step: 23599, Reward: -876.4970 [111.07], Avg: -1227.0256 (0.702)
Step: 23799, Reward: -820.7408 [64.22], Avg: -1224.1511 (0.699)
Step: 23999, Reward: -832.7119 [70.56], Avg: -1221.4771 (0.697)
Step: 24199, Reward: -833.7469 [56.23], Avg: -1218.7374 (0.695)
Step: 24399, Reward: -879.3806 [104.79], Avg: -1216.8147 (0.693)
Step: 24599, Reward: -898.7016 [83.50], Avg: -1214.9073 (0.691)
Step: 24799, Reward: -883.8120 [81.90], Avg: -1212.8977 (0.689)
Step: 24999, Reward: -900.6782 [49.41], Avg: -1210.7952 (0.687)
Step: 25199, Reward: -885.0198 [13.05], Avg: -1208.3133 (0.685)
Step: 25399, Reward: -834.7895 [59.13], Avg: -1205.8377 (0.683)
Step: 25599, Reward: -855.7734 [43.64], Avg: -1203.4438 (0.681)
Step: 25799, Reward: -964.8488 [43.18], Avg: -1201.9289 (0.679)
Step: 25999, Reward: -936.5549 [72.05], Avg: -1200.4418 (0.677)
Step: 26199, Reward: -924.7057 [108.40], Avg: -1199.1644 (0.675)
Step: 26399, Reward: -962.8763 [53.61], Avg: -1197.7805 (0.673)
Step: 26599, Reward: -977.7188 [69.94], Avg: -1196.6517 (0.671)
Step: 26799, Reward: -891.0861 [73.89], Avg: -1194.9228 (0.669)
Step: 26999, Reward: -883.9519 [31.03], Avg: -1192.8491 (0.667)
Step: 27199, Reward: -894.9876 [43.55], Avg: -1190.9792 (0.665)
Step: 27399, Reward: -929.0115 [40.16], Avg: -1189.3602 (0.663)
Step: 27599, Reward: -803.3046 [53.85], Avg: -1186.9529 (0.661)
Step: 27799, Reward: -896.5694 [90.78], Avg: -1185.5169 (0.659)
Step: 27999, Reward: -870.7331 [1.87], Avg: -1183.2819 (0.657)
Step: 28199, Reward: -803.3063 [103.44], Avg: -1181.3206 (0.655)
Step: 28399, Reward: -809.7962 [84.44], Avg: -1179.2989 (0.653)
Step: 28599, Reward: -889.5952 [138.31], Avg: -1178.2402 (0.651)
Step: 28799, Reward: -875.8482 [74.13], Avg: -1176.6551 (0.649)
Step: 28999, Reward: -794.6543 [92.76], Avg: -1174.6603 (0.647)
Step: 29199, Reward: -939.8132 [74.90], Avg: -1173.5648 (0.645)
Step: 29399, Reward: -858.8790 [52.06], Avg: -1171.7782 (0.643)
Step: 29599, Reward: -852.2792 [46.50], Avg: -1169.9336 (0.641)
Step: 29799, Reward: -869.0646 [105.22], Avg: -1168.6205 (0.639)
Step: 29999, Reward: -802.0471 [56.26], Avg: -1166.5518 (0.637)
Step: 30199, Reward: -909.2268 [63.15], Avg: -1165.2659 (0.635)
Step: 30399, Reward: -858.8326 [71.72], Avg: -1163.7217 (0.633)
Step: 30599, Reward: -908.6744 [55.53], Avg: -1162.4177 (0.631)
Step: 30799, Reward: -887.7954 [60.44], Avg: -1161.0269 (0.630)
Step: 30999, Reward: -937.5656 [54.10], Avg: -1159.9343 (0.628)
Step: 31199, Reward: -751.0059 [104.62], Avg: -1157.9836 (0.626)
Step: 31399, Reward: -873.4355 [70.85], Avg: -1156.6224 (0.624)
Step: 31599, Reward: -922.6213 [98.18], Avg: -1155.7628 (0.622)
Step: 31799, Reward: -900.9718 [39.09], Avg: -1154.4062 (0.620)
Step: 31999, Reward: -875.6896 [9.50], Avg: -1152.7236 (0.618)
Step: 32199, Reward: -836.4443 [38.50], Avg: -1150.9983 (0.616)
Step: 32399, Reward: -878.2829 [43.62], Avg: -1149.5841 (0.615)
Step: 32599, Reward: -985.3031 [83.11], Avg: -1149.0861 (0.613)
Step: 32799, Reward: -866.3007 [12.93], Avg: -1147.4407 (0.611)
Step: 32999, Reward: -891.1919 [109.37], Avg: -1146.5505 (0.609)
Step: 33199, Reward: -768.5419 [53.82], Avg: -1144.5976 (0.607)
Step: 33399, Reward: -765.6041 [143.44], Avg: -1143.1871 (0.605)
Step: 33599, Reward: -850.6764 [80.21], Avg: -1141.9234 (0.604)
Step: 33799, Reward: -792.2257 [70.49], Avg: -1140.2713 (0.602)
Step: 33999, Reward: -792.9866 [101.40], Avg: -1138.8249 (0.600)
Step: 34199, Reward: -718.6766 [48.12], Avg: -1136.6493 (0.598)
Step: 34399, Reward: -699.2349 [123.32], Avg: -1134.8232 (0.596)
Step: 34599, Reward: -697.1307 [102.07], Avg: -1132.8832 (0.595)
Step: 34799, Reward: -776.7167 [89.16], Avg: -1131.3486 (0.593)
Step: 34999, Reward: -638.4189 [99.94], Avg: -1129.1030 (0.591)
Step: 35199, Reward: -705.1703 [82.66], Avg: -1127.1639 (0.589)
Step: 35399, Reward: -731.1983 [59.63], Avg: -1125.2637 (0.588)
Step: 35599, Reward: -673.9418 [52.55], Avg: -1123.0234 (0.586)
Step: 35799, Reward: -592.8771 [51.07], Avg: -1120.3470 (0.584)
Step: 35999, Reward: -667.8917 [62.29], Avg: -1118.1794 (0.582)
Step: 36199, Reward: -618.0919 [110.02], Avg: -1116.0244 (0.581)
Step: 36399, Reward: -596.3653 [121.03], Avg: -1113.8341 (0.579)
Step: 36599, Reward: -576.7253 [60.39], Avg: -1111.2291 (0.577)
Step: 36799, Reward: -560.9661 [118.41], Avg: -1108.8821 (0.575)
Step: 36999, Reward: -516.4079 [107.48], Avg: -1106.2605 (0.574)
Step: 37199, Reward: -612.4985 [79.24], Avg: -1104.0319 (0.572)
Step: 37399, Reward: -506.5189 [92.89], Avg: -1101.3334 (0.570)
Step: 37599, Reward: -542.5898 [60.08], Avg: -1098.6809 (0.568)
Step: 37799, Reward: -493.4917 [79.15], Avg: -1095.8976 (0.567)
Step: 37999, Reward: -481.7600 [98.39], Avg: -1093.1832 (0.565)
Step: 38199, Reward: -425.0105 [145.92], Avg: -1090.4488 (0.563)
Step: 38399, Reward: -531.2891 [77.16], Avg: -1087.9384 (0.562)
Step: 38599, Reward: -525.8985 [89.47], Avg: -1085.4899 (0.560)
Step: 38799, Reward: -496.0669 [83.62], Avg: -1082.8826 (0.558)
Step: 38999, Reward: -327.3001 [120.91], Avg: -1079.6279 (0.557)
Step: 39199, Reward: -249.6817 [135.77], Avg: -1076.0862 (0.555)
Step: 39399, Reward: -146.3219 [85.32], Avg: -1071.7997 (0.553)
Step: 39599, Reward: -172.9256 [96.65], Avg: -1067.7480 (0.552)
Step: 39799, Reward: -318.3927 [208.80], Avg: -1065.0317 (0.550)
Step: 39999, Reward: -194.4371 [54.17], Avg: -1060.9496 (0.548)
Step: 40199, Reward: -123.6841 [76.55], Avg: -1056.6674 (0.547)
Step: 40399, Reward: -249.5828 [75.78], Avg: -1053.0471 (0.545)
Step: 40599, Reward: -199.5039 [129.32], Avg: -1049.4795 (0.543)
Step: 40799, Reward: -304.4816 [75.28], Avg: -1046.1965 (0.542)
Step: 40999, Reward: -189.8452 [58.17], Avg: -1042.3030 (0.540)
Step: 41199, Reward: -187.5580 [52.92], Avg: -1038.4106 (0.539)
Step: 41399, Reward: -170.8767 [94.81], Avg: -1034.6776 (0.537)
Step: 41599, Reward: -152.2954 [126.14], Avg: -1031.0419 (0.535)
Step: 41799, Reward: -149.8148 [53.64], Avg: -1027.0821 (0.534)
Step: 41999, Reward: -222.6502 [91.73], Avg: -1023.6883 (0.532)
Step: 42199, Reward: -99.0531 [47.22], Avg: -1019.5299 (0.530)
Step: 42399, Reward: -149.3402 [91.50], Avg: -1015.8569 (0.529)
Step: 42599, Reward: -302.8362 [105.65], Avg: -1013.0053 (0.527)
Step: 42799, Reward: -299.2324 [104.83], Avg: -1010.1598 (0.526)
Step: 42999, Reward: -163.9693 [90.90], Avg: -1006.6469 (0.524)
Step: 43199, Reward: -145.1019 [41.22], Avg: -1002.8491 (0.523)
Step: 43399, Reward: -380.1384 [290.20], Avg: -1001.3168 (0.521)
Step: 43599, Reward: -195.1540 [125.94], Avg: -998.1965 (0.519)
Step: 43799, Reward: -302.4368 [208.98], Avg: -995.9738 (0.518)
Step: 43999, Reward: -285.8021 [92.36], Avg: -993.1655 (0.516)
Step: 44199, Reward: -168.2259 [55.13], Avg: -989.6822 (0.515)
Step: 44399, Reward: -121.9513 [73.54], Avg: -986.1048 (0.513)
Step: 44599, Reward: -219.1759 [89.90], Avg: -983.0688 (0.512)
Step: 44799, Reward: -72.4938 [92.48], Avg: -979.4166 (0.510)
Step: 44999, Reward: -169.5678 [55.05], Avg: -976.0620 (0.509)
Step: 45199, Reward: -189.4968 [55.91], Avg: -972.8290 (0.507)
Step: 45399, Reward: -170.6896 [60.63], Avg: -969.5624 (0.506)
Step: 45599, Reward: -198.1966 [58.33], Avg: -966.4351 (0.504)
Step: 45799, Reward: -240.4779 [72.45], Avg: -963.5813 (0.503)
Step: 45999, Reward: -175.6817 [59.26], Avg: -960.4134 (0.501)
Step: 46199, Reward: -190.1878 [87.53], Avg: -957.4580 (0.500)
Step: 46399, Reward: -198.3127 [99.50], Avg: -954.6147 (0.498)
Step: 46599, Reward: -236.9477 [69.90], Avg: -951.8345 (0.497)
Step: 46799, Reward: -152.1493 [145.29], Avg: -949.0380 (0.495)
Step: 46999, Reward: -122.5366 [103.90], Avg: -945.9631 (0.494)
Step: 47199, Reward: -262.8855 [153.22], Avg: -943.7179 (0.492)
Step: 47399, Reward: -150.4737 [123.22], Avg: -940.8908 (0.491)
Step: 47599, Reward: -171.1593 [123.29], Avg: -938.1747 (0.489)
Step: 47799, Reward: -144.7547 [85.09], Avg: -935.2109 (0.488)
Step: 47999, Reward: -142.0353 [83.11], Avg: -932.2523 (0.486)
Step: 48199, Reward: -120.3872 [126.35], Avg: -929.4078 (0.485)
Step: 48399, Reward: -187.4809 [53.65], Avg: -926.5637 (0.483)
Step: 48599, Reward: -166.8377 [116.30], Avg: -923.9159 (0.482)
Step: 48799, Reward: -213.4117 [45.98], Avg: -921.1924 (0.480)
Step: 48999, Reward: -122.4143 [74.96], Avg: -918.2381 (0.479)
Step: 49199, Reward: -184.9231 [83.07], Avg: -915.5948 (0.478)
Step: 49399, Reward: -240.3042 [128.61], Avg: -913.3815 (0.476)
Step: 49599, Reward: -171.1946 [97.61], Avg: -910.7824 (0.475)
Step: 49799, Reward: -148.4127 [47.27], Avg: -907.9105 (0.473)
Step: 49999, Reward: -215.7567 [86.58], Avg: -905.4882 (0.472)
Step: 50199, Reward: -144.2445 [85.86], Avg: -902.7974 (0.470)
Step: 50399, Reward: -169.7931 [57.42], Avg: -900.1166 (0.469)
Step: 50599, Reward: -174.4856 [99.86], Avg: -897.6432 (0.468)
Step: 50799, Reward: -214.8906 [44.21], Avg: -895.1292 (0.466)
Step: 50999, Reward: -148.0644 [46.12], Avg: -892.3804 (0.465)
Step: 51199, Reward: -118.8422 [123.65], Avg: -889.8418 (0.463)
Step: 51399, Reward: -188.3156 [118.53], Avg: -887.5733 (0.462)
Step: 51599, Reward: -145.0285 [86.43], Avg: -885.0302 (0.461)
Step: 51799, Reward: -168.2788 [60.70], Avg: -882.4972 (0.459)
Step: 51999, Reward: -175.8741 [131.33], Avg: -880.2845 (0.458)
Step: 52199, Reward: -165.5404 [52.89], Avg: -877.7487 (0.456)
Step: 52399, Reward: -194.3890 [56.13], Avg: -875.3547 (0.455)
Step: 52599, Reward: -196.8340 [99.21], Avg: -873.1520 (0.454)
Step: 52799, Reward: -97.7547 [86.28], Avg: -870.5417 (0.452)
Step: 52999, Reward: -215.9299 [86.16], Avg: -868.3966 (0.451)
Step: 53199, Reward: -123.5724 [2.41], Avg: -865.6056 (0.450)
Step: 53399, Reward: -100.5833 [93.79], Avg: -863.0916 (0.448)
Step: 53599, Reward: -99.3293 [89.95], Avg: -860.5774 (0.447)
Step: 53799, Reward: -96.3445 [86.46], Avg: -858.0578 (0.446)
Step: 53999, Reward: -96.2253 [86.16], Avg: -855.5553 (0.444)
Step: 54199, Reward: -145.2029 [114.41], Avg: -853.3562 (0.443)
Step: 54399, Reward: -168.8316 [54.32], Avg: -851.0393 (0.442)
Step: 54599, Reward: -146.6978 [48.97], Avg: -848.6387 (0.440)
Step: 54799, Reward: -96.5442 [88.28], Avg: -846.2160 (0.439)
Step: 54999, Reward: -272.0575 [146.36], Avg: -844.6603 (0.438)
Step: 55199, Reward: -533.4843 [356.31], Avg: -844.8239 (0.436)
Step: 55399, Reward: -323.8352 [346.70], Avg: -844.1947 (0.435)
Step: 55599, Reward: -219.9829 [49.62], Avg: -842.1278 (0.434)
Step: 55799, Reward: -98.9420 [48.92], Avg: -839.6394 (0.432)
Step: 55999, Reward: -299.7476 [189.65], Avg: -838.3885 (0.431)
Step: 56199, Reward: -144.1705 [90.85], Avg: -836.2413 (0.430)
Step: 56399, Reward: -122.0129 [3.62], Avg: -833.7214 (0.429)
Step: 56599, Reward: -145.1948 [91.64], Avg: -831.6123 (0.427)
Step: 56799, Reward: -143.9374 [41.74], Avg: -829.3378 (0.426)
Step: 56999, Reward: -241.7968 [108.75], Avg: -827.6579 (0.425)
Step: 57199, Reward: -247.9010 [252.82], Avg: -826.5148 (0.423)
Step: 57399, Reward: -144.0299 [88.07], Avg: -824.4436 (0.422)
Step: 57599, Reward: -221.8396 [97.48], Avg: -822.6897 (0.421)
Step: 57799, Reward: -248.9894 [117.10], Avg: -821.1098 (0.420)
Step: 57999, Reward: -247.2340 [139.13], Avg: -819.6107 (0.418)
Step: 58199, Reward: -169.5198 [57.95], Avg: -817.5758 (0.417)
Step: 58399, Reward: -215.8792 [85.05], Avg: -815.8065 (0.416)
Step: 58599, Reward: -97.7792 [48.01], Avg: -813.5197 (0.415)
Step: 58799, Reward: -151.0841 [96.34], Avg: -811.5943 (0.413)
Step: 58999, Reward: -49.7516 [59.01], Avg: -809.2118 (0.412)
Step: 59199, Reward: -201.0422 [154.44], Avg: -807.6789 (0.411)
Step: 59399, Reward: -146.9455 [50.68], Avg: -805.6248 (0.410)
Step: 59599, Reward: -141.0723 [105.99], Avg: -803.7504 (0.408)
Step: 59799, Reward: -191.1123 [94.65], Avg: -802.0181 (0.407)
Step: 59999, Reward: -141.6436 [111.86], Avg: -800.1897 (0.406)
Step: 60199, Reward: -240.1557 [78.59], Avg: -798.5902 (0.405)
Step: 60399, Reward: -198.9432 [103.75], Avg: -796.9482 (0.404)
Step: 60599, Reward: -167.8458 [59.50], Avg: -795.0683 (0.402)
Step: 60799, Reward: -72.5588 [57.03], Avg: -792.8792 (0.401)
Step: 60999, Reward: -173.3133 [100.13], Avg: -791.1761 (0.400)
Step: 61199, Reward: -166.3120 [92.76], Avg: -789.4372 (0.399)
Step: 61399, Reward: -97.3421 [86.71], Avg: -787.4653 (0.398)
Step: 61599, Reward: -97.0695 [46.56], Avg: -785.3749 (0.396)
Step: 61799, Reward: -123.1889 [4.38], Avg: -783.2461 (0.395)
Step: 61999, Reward: -194.3386 [102.63], Avg: -781.6775 (0.394)
Step: 62199, Reward: -169.0153 [95.36], Avg: -780.0141 (0.393)
Step: 62399, Reward: -196.4256 [97.57], Avg: -778.4564 (0.392)
Step: 62599, Reward: -99.0288 [49.00], Avg: -776.4422 (0.390)
Step: 62799, Reward: -146.7005 [50.88], Avg: -774.5987 (0.389)
Step: 62999, Reward: -50.5343 [59.05], Avg: -772.4876 (0.388)
Step: 63199, Reward: -175.2239 [100.53], Avg: -770.9156 (0.387)
Step: 63399, Reward: -196.3450 [104.33], Avg: -769.4322 (0.386)
Step: 63599, Reward: -148.9944 [91.35], Avg: -767.7684 (0.385)
Step: 63799, Reward: -145.7566 [88.06], Avg: -766.0946 (0.383)
Step: 63999, Reward: -170.9079 [57.17], Avg: -764.4133 (0.382)
Step: 64199, Reward: -99.0350 [47.66], Avg: -762.4889 (0.381)
Step: 64399, Reward: -216.6293 [85.08], Avg: -761.0580 (0.380)
Step: 64599, Reward: -168.7853 [55.24], Avg: -759.3953 (0.379)
Step: 64799, Reward: -196.4690 [95.79], Avg: -757.9535 (0.378)
Step: 64999, Reward: -26.8200 [45.70], Avg: -755.8445 (0.377)
Step: 65199, Reward: -100.1969 [49.04], Avg: -753.9837 (0.376)
Step: 65399, Reward: -173.6369 [122.59], Avg: -752.5839 (0.374)
Step: 65599, Reward: -146.0962 [86.53], Avg: -750.9986 (0.373)
Step: 65799, Reward: -216.4191 [85.14], Avg: -749.6325 (0.372)
Step: 65999, Reward: -123.3774 [107.99], Avg: -748.0620 (0.371)
Step: 66199, Reward: -166.5841 [88.51], Avg: -746.5727 (0.370)
Step: 66399, Reward: -122.7611 [73.02], Avg: -744.9137 (0.369)
Step: 66599, Reward: -169.3172 [57.34], Avg: -743.3574 (0.368)
Step: 66799, Reward: -145.8268 [48.62], Avg: -741.7139 (0.367)
Step: 66999, Reward: -73.5634 [56.87], Avg: -739.8892 (0.365)
Step: 67199, Reward: -174.7330 [101.54], Avg: -738.5094 (0.364)
Step: 67399, Reward: -212.9047 [80.11], Avg: -737.1875 (0.363)
Step: 67599, Reward: -141.3851 [86.16], Avg: -735.6796 (0.362)
Step: 67799, Reward: -144.6787 [44.72], Avg: -734.0682 (0.361)
Step: 67999, Reward: -163.6803 [55.39], Avg: -732.5535 (0.360)
Step: 68199, Reward: -169.1975 [57.41], Avg: -731.0698 (0.359)
Step: 68399, Reward: -203.4316 [114.09], Avg: -729.8606 (0.358)
Step: 68599, Reward: -48.5930 [57.60], Avg: -728.0423 (0.357)
Step: 68799, Reward: -188.6353 [138.36], Avg: -726.8765 (0.356)
Step: 68999, Reward: -97.3585 [48.25], Avg: -725.1916 (0.355)
Step: 69199, Reward: -213.9504 [88.49], Avg: -723.9698 (0.354)
Step: 69399, Reward: -147.3183 [121.84], Avg: -722.6591 (0.353)
Step: 69599, Reward: -119.6267 [77.96], Avg: -721.1503 (0.351)
Step: 69799, Reward: -138.9073 [130.04], Avg: -719.8546 (0.350)
Step: 69999, Reward: -143.4239 [47.30], Avg: -718.3428 (0.349)
Step: 70199, Reward: -213.3012 [115.24], Avg: -717.2323 (0.348)
Step: 70399, Reward: -167.4905 [55.19], Avg: -715.8273 (0.347)
Step: 70599, Reward: -142.8310 [48.19], Avg: -714.3406 (0.346)
Step: 70799, Reward: -193.8413 [103.94], Avg: -713.1639 (0.345)
Step: 70999, Reward: -168.0988 [94.40], Avg: -711.8944 (0.344)
Step: 71199, Reward: -168.3304 [119.31], Avg: -710.7026 (0.343)
Step: 71399, Reward: -119.2075 [73.75], Avg: -709.2524 (0.342)
Step: 71599, Reward: -210.2211 [77.74], Avg: -708.0756 (0.341)
Step: 71799, Reward: -193.0151 [119.62], Avg: -706.9740 (0.340)
Step: 71999, Reward: -169.3629 [64.86], Avg: -705.6609 (0.339)
Step: 72199, Reward: -168.6738 [87.27], Avg: -704.4151 (0.338)
Step: 72399, Reward: -172.1208 [127.78], Avg: -703.2977 (0.337)
Step: 72599, Reward: -196.9958 [63.34], Avg: -702.0774 (0.336)
Step: 72799, Reward: -164.8483 [137.57], Avg: -700.9794 (0.335)
Step: 72999, Reward: -145.1130 [49.98], Avg: -699.5934 (0.334)
Step: 73199, Reward: -168.9819 [122.19], Avg: -698.4775 (0.333)
Step: 73399, Reward: -169.8454 [94.93], Avg: -697.2958 (0.332)
Step: 73599, Reward: -152.1095 [124.29], Avg: -696.1520 (0.331)
Step: 73799, Reward: -258.2527 [110.34], Avg: -695.2643 (0.330)
Step: 73999, Reward: -187.8335 [54.53], Avg: -694.0403 (0.329)
Step: 74199, Reward: -144.6604 [88.24], Avg: -692.7973 (0.328)
Step: 74399, Reward: -146.4596 [90.42], Avg: -691.5717 (0.327)
Step: 74599, Reward: -247.9233 [76.46], Avg: -690.5873 (0.326)
Step: 74799, Reward: -101.1909 [50.02], Avg: -689.1451 (0.325)
Step: 74999, Reward: -237.2784 [60.98], Avg: -688.1028 (0.324)
Step: 75199, Reward: -184.8413 [85.11], Avg: -686.9907 (0.323)
Step: 75399, Reward: -170.3397 [59.16], Avg: -685.7772 (0.322)
Step: 75599, Reward: -238.3770 [160.69], Avg: -685.0187 (0.321)
Step: 75799, Reward: -145.4280 [46.26], Avg: -683.7170 (0.320)
Step: 75999, Reward: -143.2896 [47.70], Avg: -682.4203 (0.319)
Step: 76199, Reward: -172.2907 [62.61], Avg: -681.2457 (0.318)
Step: 76399, Reward: -120.3045 [74.37], Avg: -679.9720 (0.317)
Step: 76599, Reward: -162.8362 [87.55], Avg: -678.8504 (0.316)
Step: 76799, Reward: -190.5299 [53.40], Avg: -677.7178 (0.315)
Step: 76999, Reward: -171.5454 [97.23], Avg: -676.6556 (0.315)
Step: 77199, Reward: -202.1604 [136.28], Avg: -675.7794 (0.314)
Step: 77399, Reward: -163.8658 [117.97], Avg: -674.7614 (0.313)
Step: 77599, Reward: -197.0726 [97.71], Avg: -673.7821 (0.312)
Step: 77799, Reward: -233.9604 [92.29], Avg: -672.8887 (0.311)
Step: 77999, Reward: -169.8460 [58.55], Avg: -671.7490 (0.310)
Step: 78199, Reward: -216.5757 [119.67], Avg: -670.8909 (0.309)
Step: 78399, Reward: -179.9376 [113.85], Avg: -669.9289 (0.308)
Step: 78599, Reward: -855.1350 [23.93], Avg: -670.4611 (0.307)
Step: 78799, Reward: -840.2399 [39.13], Avg: -670.9913 (0.306)
Step: 78999, Reward: -830.0244 [70.01], Avg: -671.5712 (0.305)
Step: 79199, Reward: -789.8952 [89.53], Avg: -672.0960 (0.304)
Step: 79399, Reward: -798.3321 [61.50], Avg: -672.5689 (0.303)
Step: 79599, Reward: -832.2012 [42.19], Avg: -673.0760 (0.302)
Step: 79799, Reward: -774.5530 [44.75], Avg: -673.4425 (0.302)
Step: 79999, Reward: -785.3845 [36.08], Avg: -673.8125 (0.301)
Step: 80199, Reward: -801.5862 [45.72], Avg: -674.2452 (0.300)
Step: 80399, Reward: -790.7078 [39.40], Avg: -674.6329 (0.299)
Step: 80599, Reward: -780.4720 [42.29], Avg: -675.0005 (0.298)
Step: 80799, Reward: -803.7283 [39.27], Avg: -675.4163 (0.297)
Step: 80999, Reward: -738.6978 [57.39], Avg: -675.7143 (0.296)
Step: 81199, Reward: -783.2841 [72.35], Avg: -676.1574 (0.295)
Step: 81399, Reward: -777.9199 [40.47], Avg: -676.5069 (0.294)
Step: 81599, Reward: -831.1026 [46.31], Avg: -676.9993 (0.294)
Step: 81799, Reward: -731.8153 [48.68], Avg: -677.2524 (0.293)
Step: 81999, Reward: -848.8531 [21.64], Avg: -677.7237 (0.292)
Step: 82199, Reward: -785.4388 [42.03], Avg: -678.0880 (0.291)
Step: 82399, Reward: -839.9069 [54.16], Avg: -678.6122 (0.290)
Step: 82599, Reward: -782.1783 [43.22], Avg: -678.9676 (0.289)
Step: 82799, Reward: -773.6008 [25.75], Avg: -679.2584 (0.288)
Step: 82999, Reward: -771.3490 [33.36], Avg: -679.5607 (0.287)
Step: 83199, Reward: -782.8750 [42.70], Avg: -679.9117 (0.287)
Step: 83399, Reward: -833.4502 [43.26], Avg: -680.3836 (0.286)
Step: 83599, Reward: -810.2009 [35.39], Avg: -680.7789 (0.285)
Step: 83799, Reward: -846.4929 [78.19], Avg: -681.3610 (0.284)
Step: 83999, Reward: -818.5676 [53.11], Avg: -681.8141 (0.283)
Step: 84199, Reward: -807.8698 [54.32], Avg: -682.2426 (0.282)
Step: 84399, Reward: -898.0888 [32.72], Avg: -682.8316 (0.281)
Step: 84599, Reward: -865.4371 [57.85], Avg: -683.4000 (0.281)
Step: 84799, Reward: -830.6522 [37.72], Avg: -683.8363 (0.280)
Step: 84999, Reward: -826.4480 [48.68], Avg: -684.2864 (0.279)
Step: 85199, Reward: -782.6830 [37.79], Avg: -684.6060 (0.278)
Step: 85399, Reward: -819.6599 [45.19], Avg: -685.0282 (0.277)
Step: 85599, Reward: -762.6803 [64.51], Avg: -685.3603 (0.276)
Step: 85799, Reward: -786.1686 [42.00], Avg: -685.6932 (0.276)
Step: 85999, Reward: -805.8212 [60.54], Avg: -686.1134 (0.275)
Step: 86199, Reward: -778.0667 [45.95], Avg: -686.4333 (0.274)
Step: 86399, Reward: -799.4829 [56.72], Avg: -686.8263 (0.273)
Step: 86599, Reward: -801.9303 [43.64], Avg: -687.1930 (0.272)
Step: 86799, Reward: -846.4863 [70.15], Avg: -687.7216 (0.271)
Step: 86999, Reward: -794.2626 [41.24], Avg: -688.0614 (0.271)
Step: 87199, Reward: -839.5706 [48.83], Avg: -688.5209 (0.270)
Step: 87399, Reward: -758.2285 [55.18], Avg: -688.8066 (0.269)
Step: 87599, Reward: -771.5475 [48.52], Avg: -689.1063 (0.268)
Step: 87799, Reward: -745.4792 [71.61], Avg: -689.3978 (0.267)
Step: 87999, Reward: -770.0636 [29.71], Avg: -689.6487 (0.267)
Step: 88199, Reward: -830.5647 [56.50], Avg: -690.0963 (0.266)
Step: 88399, Reward: -773.9189 [41.82], Avg: -690.3806 (0.265)
Step: 88599, Reward: -806.5632 [51.47], Avg: -690.7590 (0.264)
Step: 88799, Reward: -801.3073 [43.06], Avg: -691.1050 (0.263)
Step: 88999, Reward: -792.1425 [45.53], Avg: -691.4344 (0.263)
Step: 89199, Reward: -816.8228 [40.89], Avg: -691.8072 (0.262)
Step: 89399, Reward: -766.4986 [79.57], Avg: -692.1523 (0.261)
Step: 89599, Reward: -764.8353 [33.10], Avg: -692.3884 (0.260)
Step: 89799, Reward: -770.1938 [35.15], Avg: -692.6400 (0.259)
Step: 89999, Reward: -773.0910 [91.46], Avg: -693.0220 (0.259)
Step: 90199, Reward: -772.9177 [84.89], Avg: -693.3874 (0.258)
Step: 90399, Reward: -731.7520 [46.39], Avg: -693.5749 (0.257)
Step: 90599, Reward: -847.4812 [21.04], Avg: -693.9611 (0.256)
Step: 90799, Reward: -788.3816 [48.09], Avg: -694.2750 (0.256)
Step: 90999, Reward: -778.0341 [54.30], Avg: -694.5784 (0.255)
Step: 91199, Reward: -753.6715 [4.80], Avg: -694.7185 (0.254)
Step: 91399, Reward: -720.6914 [79.04], Avg: -694.9483 (0.253)
Step: 91599, Reward: -726.0691 [44.76], Avg: -695.1140 (0.253)
Step: 91799, Reward: -764.5400 [24.33], Avg: -695.3182 (0.252)
Step: 91999, Reward: -686.3218 [62.39], Avg: -695.4343 (0.251)
Step: 92199, Reward: -741.9020 [11.40], Avg: -695.5598 (0.250)
Step: 92399, Reward: -712.0477 [105.32], Avg: -695.8235 (0.250)
Step: 92599, Reward: -761.0462 [43.11], Avg: -696.0575 (0.249)
Step: 92799, Reward: -690.8969 [66.05], Avg: -696.1887 (0.248)
Step: 92999, Reward: -676.3899 [120.67], Avg: -696.4056 (0.247)
Step: 93199, Reward: -684.1119 [68.58], Avg: -696.5264 (0.247)
Step: 93399, Reward: -744.6848 [5.33], Avg: -696.6409 (0.246)
Step: 93599, Reward: -752.4228 [74.91], Avg: -696.9202 (0.245)
Step: 93799, Reward: -742.3859 [21.26], Avg: -697.0625 (0.244)
Step: 93999, Reward: -668.3713 [56.36], Avg: -697.1213 (0.244)
Step: 94199, Reward: -657.2029 [45.80], Avg: -697.1338 (0.243)
Step: 94399, Reward: -724.3919 [81.27], Avg: -697.3638 (0.242)
Step: 94599, Reward: -720.3564 [46.40], Avg: -697.5105 (0.241)
Step: 94799, Reward: -739.3757 [63.87], Avg: -697.7335 (0.241)
Step: 94999, Reward: -647.5198 [74.21], Avg: -697.7841 (0.240)
Step: 95199, Reward: -673.4523 [37.01], Avg: -697.8107 (0.239)
Step: 95399, Reward: -673.7242 [55.24], Avg: -697.8760 (0.239)
Step: 95599, Reward: -662.1779 [81.71], Avg: -697.9723 (0.238)
Step: 95799, Reward: -711.1040 [74.65], Avg: -698.1555 (0.237)
Step: 95999, Reward: -691.1626 [50.81], Avg: -698.2468 (0.236)
Step: 96199, Reward: -682.2463 [58.90], Avg: -698.3360 (0.236)
Step: 96399, Reward: -648.2297 [48.29], Avg: -698.3322 (0.235)
Step: 96599, Reward: -652.7036 [79.02], Avg: -698.4014 (0.234)
Step: 96799, Reward: -667.9156 [51.02], Avg: -698.4438 (0.234)
Step: 96999, Reward: -731.1707 [50.00], Avg: -698.6144 (0.233)
Step: 97199, Reward: -683.9554 [48.14], Avg: -698.6833 (0.232)
Step: 97399, Reward: -710.0717 [54.01], Avg: -698.8176 (0.231)
Step: 97599, Reward: -718.2332 [80.86], Avg: -699.0231 (0.231)
Step: 97799, Reward: -736.5268 [57.38], Avg: -699.2171 (0.230)
Step: 97999, Reward: -626.6189 [3.89], Avg: -699.0769 (0.229)
Step: 98199, Reward: -663.9053 [73.72], Avg: -699.1554 (0.229)
Step: 98399, Reward: -731.1403 [52.00], Avg: -699.3261 (0.228)
Step: 98599, Reward: -671.5292 [42.40], Avg: -699.3557 (0.227)
Step: 98799, Reward: -694.1625 [40.37], Avg: -699.4269 (0.227)
Step: 98999, Reward: -645.0322 [28.60], Avg: -699.3748 (0.226)
Step: 99199, Reward: -686.5224 [113.23], Avg: -699.5772 (0.225)
Step: 99399, Reward: -643.2201 [26.53], Avg: -699.5172 (0.225)
Step: 99599, Reward: -686.9050 [51.25], Avg: -699.5948 (0.224)
Step: 99799, Reward: -624.1197 [105.29], Avg: -699.6545 (0.223)
Step: 99999, Reward: -455.2201 [122.24], Avg: -699.4101 (0.223)
