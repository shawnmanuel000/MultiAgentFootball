Model: <class 'models.ppo.PPOAgent'>, Dir: Pendulum-v0
num_envs: 16,

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

EPS_MIN = 0.1                	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.997             	# The rate at which eps decays from EPS_MAX to EPS_MIN
BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.05				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) * critic_error.pow(2) * scale
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss.mean())
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		update_freq = int(self.update_freq * (1 - self.eps + EPS_MIN)**2)
		if len(self.buffer) >= update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, scale=16*update_freq/len(self.replay_buffer))
		if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "Acrobot-v1", "Pendulum-v0"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[2]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class PixelAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	logger = Logger(model, env_name, num_envs=num_envs)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = PixelAgent(envs.state_size, envs.action_size, num_envs, model)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0] or s+1 % envs.env.spec.max_episode_steps == 0:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 199, Reward: -1183.2996 [65.97], Avg: -1249.2743 (0.997)
Step: 399, Reward: -1213.8153 [175.39], Avg: -1319.2416 (0.994)
Step: 599, Reward: -1389.7002 [214.76], Avg: -1414.3131 (0.991)
Step: 799, Reward: -1169.9465 [282.13], Avg: -1423.7529 (0.988)
Step: 999, Reward: -1267.3230 [76.82], Avg: -1407.8310 (0.985)
Step: 1199, Reward: -1129.9376 [115.05], Avg: -1380.6902 (0.982)
Step: 1399, Reward: -1255.2565 [50.27], Avg: -1369.9521 (0.979)
Step: 1599, Reward: -1352.4263 [114.15], Avg: -1382.0300 (0.976)
Step: 1799, Reward: -1387.7614 [96.36], Avg: -1393.3734 (0.973)
Step: 1999, Reward: -1326.3824 [71.90], Avg: -1393.8640 (0.970)
Step: 2199, Reward: -1239.9788 [51.23], Avg: -1384.5319 (0.967)
Step: 2399, Reward: -1349.6382 [83.79], Avg: -1388.6064 (0.965)
Step: 2599, Reward: -1316.9449 [24.56], Avg: -1384.9836 (0.962)
Step: 2799, Reward: -1323.7195 [77.35], Avg: -1386.1325 (0.959)
Step: 2999, Reward: -1363.0151 [34.81], Avg: -1386.9120 (0.956)
Step: 3199, Reward: -1363.9528 [33.50], Avg: -1387.5706 (0.953)
Step: 3399, Reward: -1360.2045 [56.05], Avg: -1389.2578 (0.950)
Step: 3599, Reward: -1336.0296 [93.47], Avg: -1391.4935 (0.947)
Step: 3799, Reward: -1378.8069 [59.45], Avg: -1393.9548 (0.945)
Step: 3999, Reward: -1431.9525 [81.43], Avg: -1399.9264 (0.942)
Step: 4199, Reward: -1489.4523 [46.05], Avg: -1406.3826 (0.939)
Step: 4399, Reward: -1449.3622 [102.92], Avg: -1413.0145 (0.936)
Step: 4599, Reward: -1487.3796 [80.51], Avg: -1419.7480 (0.933)
Step: 4799, Reward: -1510.6942 [54.06], Avg: -1425.7899 (0.930)
Step: 4999, Reward: -1419.0488 [123.61], Avg: -1430.4647 (0.928)
Step: 5199, Reward: -1500.0165 [72.88], Avg: -1435.9427 (0.925)
Step: 5399, Reward: -1421.5660 [94.81], Avg: -1438.9216 (0.922)
Step: 5599, Reward: -1494.2705 [53.03], Avg: -1442.7922 (0.919)
Step: 5799, Reward: -1537.8732 [46.63], Avg: -1447.6789 (0.917)
Step: 5999, Reward: -1446.7076 [68.55], Avg: -1449.9315 (0.914)
Step: 6199, Reward: -1477.9504 [93.21], Avg: -1453.8421 (0.911)
Step: 6399, Reward: -1398.5799 [149.94], Avg: -1456.8007 (0.908)
Step: 6599, Reward: -1470.7664 [131.45], Avg: -1461.2073 (0.906)
Step: 6799, Reward: -1422.7461 [151.02], Avg: -1464.5177 (0.903)
Step: 6999, Reward: -1424.1281 [119.85], Avg: -1466.7880 (0.900)
Step: 7199, Reward: -1441.3708 [135.52], Avg: -1469.8463 (0.897)
Step: 7399, Reward: -1503.8932 [114.23], Avg: -1473.8537 (0.895)
Step: 7599, Reward: -1450.2462 [133.65], Avg: -1476.7495 (0.892)
Step: 7799, Reward: -1538.3153 [57.99], Avg: -1479.8150 (0.889)
Step: 7999, Reward: -1514.3571 [30.39], Avg: -1481.4382 (0.887)
Step: 8199, Reward: -1382.9593 [195.08], Avg: -1483.7944 (0.884)
Step: 8399, Reward: -1519.2724 [155.08], Avg: -1488.3316 (0.881)
Step: 8599, Reward: -1522.2691 [92.41], Avg: -1491.2700 (0.879)
Step: 8799, Reward: -1442.7098 [150.32], Avg: -1493.5826 (0.876)
Step: 8999, Reward: -1332.3343 [149.13], Avg: -1493.3132 (0.874)
Step: 9199, Reward: -1517.2435 [50.42], Avg: -1494.9296 (0.871)
Step: 9399, Reward: -1508.3896 [20.12], Avg: -1495.6440 (0.868)
Step: 9599, Reward: -1357.1958 [229.92], Avg: -1497.5497 (0.866)
Step: 9799, Reward: -1428.3287 [152.79], Avg: -1499.2553 (0.863)
Step: 9999, Reward: -1582.5933 [52.67], Avg: -1501.9755 (0.861)
Step: 10199, Reward: -1387.9494 [165.90], Avg: -1502.9925 (0.858)
Step: 10399, Reward: -1433.0574 [133.76], Avg: -1504.2200 (0.855)
Step: 10599, Reward: -1477.6121 [215.61], Avg: -1507.7860 (0.853)
Step: 10799, Reward: -1404.7929 [137.70], Avg: -1508.4288 (0.850)
Step: 10999, Reward: -1286.2526 [230.27], Avg: -1508.5759 (0.848)
Step: 11199, Reward: -1464.1697 [96.99], Avg: -1509.5150 (0.845)
Step: 11399, Reward: -1377.6849 [148.87], Avg: -1509.8140 (0.843)
Step: 11599, Reward: -1353.5766 [205.85], Avg: -1510.6694 (0.840)
Step: 11799, Reward: -1443.1255 [133.22], Avg: -1511.7826 (0.838)
Step: 11999, Reward: -1363.2883 [132.07], Avg: -1511.5088 (0.835)
Step: 12199, Reward: -1269.2039 [179.88], Avg: -1510.4854 (0.833)
Step: 12399, Reward: -1469.7229 [140.07], Avg: -1512.0872 (0.830)
Step: 12599, Reward: -1285.9737 [124.30], Avg: -1510.4711 (0.828)
Step: 12799, Reward: -1409.5369 [191.30], Avg: -1511.8831 (0.825)
Step: 12999, Reward: -1350.5409 [156.37], Avg: -1511.8065 (0.823)
Step: 13199, Reward: -1464.5133 [147.44], Avg: -1513.3239 (0.820)
Step: 13399, Reward: -1414.5606 [207.43], Avg: -1514.9457 (0.818)
Step: 13599, Reward: -1546.1406 [28.58], Avg: -1515.8247 (0.815)
Step: 13799, Reward: -1299.4435 [265.58], Avg: -1516.5377 (0.813)
Step: 13999, Reward: -1401.2065 [216.98], Avg: -1517.9898 (0.810)
Step: 14199, Reward: -1383.1956 [210.86], Avg: -1519.0611 (0.808)
Step: 14399, Reward: -1384.7510 [208.45], Avg: -1520.0908 (0.805)
Step: 14599, Reward: -1360.7346 [214.30], Avg: -1520.8435 (0.803)
Step: 14799, Reward: -1427.6523 [187.78], Avg: -1522.1217 (0.801)
Step: 14999, Reward: -1369.4394 [221.70], Avg: -1523.0419 (0.798)
Step: 15199, Reward: -1254.5879 [143.42], Avg: -1521.3966 (0.796)
Step: 15399, Reward: -1434.7444 [215.13], Avg: -1523.0652 (0.793)
Step: 15599, Reward: -1474.4461 [155.46], Avg: -1524.4350 (0.791)
Step: 15799, Reward: -1382.1668 [234.71], Avg: -1525.6051 (0.789)
Step: 15999, Reward: -1490.7983 [128.29], Avg: -1526.7736 (0.786)
Step: 16199, Reward: -1323.5669 [229.05], Avg: -1527.0927 (0.784)
Step: 16399, Reward: -1409.2256 [218.82], Avg: -1528.3238 (0.782)
Step: 16599, Reward: -1330.1841 [191.80], Avg: -1528.2475 (0.779)
Step: 16799, Reward: -1529.3430 [110.30], Avg: -1529.5736 (0.777)
Step: 16999, Reward: -1575.8199 [71.80], Avg: -1530.9623 (0.775)
Step: 17199, Reward: -1392.1042 [184.47], Avg: -1531.4927 (0.772)
Step: 17399, Reward: -1326.1078 [124.32], Avg: -1530.5610 (0.770)
Step: 17599, Reward: -1499.8019 [164.23], Avg: -1532.0777 (0.768)
Step: 17799, Reward: -1334.8948 [180.78], Avg: -1531.8934 (0.765)
Step: 17999, Reward: -1400.4271 [151.79], Avg: -1532.1191 (0.763)
Step: 18199, Reward: -1375.9524 [153.83], Avg: -1532.0935 (0.761)
Step: 18399, Reward: -1484.7626 [87.82], Avg: -1532.5336 (0.758)
Step: 18599, Reward: -1316.4677 [121.64], Avg: -1531.5183 (0.756)
Step: 18799, Reward: -1378.9240 [183.45], Avg: -1531.8465 (0.754)
Step: 18999, Reward: -1502.6345 [143.57], Avg: -1533.0503 (0.752)
Step: 19199, Reward: -1361.4447 [227.89], Avg: -1533.6365 (0.749)
Step: 19399, Reward: -1474.3454 [128.69], Avg: -1534.3520 (0.747)
Step: 19599, Reward: -1470.6727 [151.04], Avg: -1535.2434 (0.745)
Step: 19799, Reward: -1446.6624 [174.80], Avg: -1536.1143 (0.743)
Step: 19999, Reward: -1433.2658 [179.13], Avg: -1536.8771 (0.740)
Step: 20199, Reward: -1555.9196 [24.72], Avg: -1537.3104 (0.738)
Step: 20399, Reward: -1448.6360 [166.09], Avg: -1538.0694 (0.736)
Step: 20599, Reward: -1465.8904 [181.98], Avg: -1539.1354 (0.734)
Step: 20799, Reward: -1252.5581 [153.45], Avg: -1537.8553 (0.732)
Step: 20999, Reward: -1414.4462 [192.96], Avg: -1538.5177 (0.729)
Step: 21199, Reward: -1461.6114 [157.30], Avg: -1539.2762 (0.727)
Step: 21399, Reward: -1313.5697 [237.15], Avg: -1539.3832 (0.725)
Step: 21599, Reward: -1425.0024 [208.99], Avg: -1540.2592 (0.723)
Step: 21799, Reward: -1535.6855 [27.98], Avg: -1540.4740 (0.721)
Step: 21999, Reward: -1268.2894 [279.63], Avg: -1540.5416 (0.719)
Step: 22199, Reward: -1469.1637 [157.74], Avg: -1541.3196 (0.716)
Step: 22399, Reward: -1484.4156 [166.20], Avg: -1542.2955 (0.714)
Step: 22599, Reward: -1376.2192 [228.85], Avg: -1542.8510 (0.712)
Step: 22799, Reward: -1349.4260 [259.91], Avg: -1543.4342 (0.710)
Step: 22999, Reward: -1247.2938 [205.64], Avg: -1542.6472 (0.708)
Step: 23199, Reward: -1421.1436 [176.89], Avg: -1543.1247 (0.706)
Step: 23399, Reward: -1215.6845 [250.44], Avg: -1542.4666 (0.704)
Step: 23599, Reward: -1433.8976 [198.45], Avg: -1543.2283 (0.702)
Step: 23799, Reward: -1335.8877 [219.54], Avg: -1543.3308 (0.699)
Step: 23999, Reward: -1469.8754 [206.33], Avg: -1544.4382 (0.697)
Step: 24199, Reward: -1164.3149 [184.75], Avg: -1542.8235 (0.695)
Step: 24399, Reward: -1260.3558 [241.30], Avg: -1542.4861 (0.693)
Step: 24599, Reward: -1362.8252 [245.58], Avg: -1543.0220 (0.691)
Step: 24799, Reward: -1486.2714 [24.37], Avg: -1542.7609 (0.689)
Step: 24999, Reward: -1258.2884 [212.46], Avg: -1542.1848 (0.687)
Step: 25199, Reward: -1343.1148 [190.35], Avg: -1542.1156 (0.685)
Step: 25399, Reward: -1181.4374 [180.23], Avg: -1540.6948 (0.683)
Step: 25599, Reward: -1330.3713 [245.19], Avg: -1540.9672 (0.681)
Step: 25799, Reward: -1243.8510 [230.89], Avg: -1540.4538 (0.679)
Step: 25999, Reward: -1457.1886 [131.94], Avg: -1540.8282 (0.677)
Step: 26199, Reward: -1364.6188 [153.77], Avg: -1540.6569 (0.675)
Step: 26399, Reward: -1245.8033 [175.71], Avg: -1539.7543 (0.673)
Step: 26599, Reward: -1485.0866 [155.85], Avg: -1540.5151 (0.671)
Step: 26799, Reward: -1351.2069 [171.79], Avg: -1540.3843 (0.669)
Step: 26999, Reward: -1329.1505 [195.54], Avg: -1540.2681 (0.667)
Step: 27199, Reward: -1455.7583 [188.44], Avg: -1541.0323 (0.665)
Step: 27399, Reward: -1289.0810 [279.77], Avg: -1541.2353 (0.663)
Step: 27599, Reward: -1253.1189 [238.46], Avg: -1540.8754 (0.661)
Step: 27799, Reward: -1385.0049 [211.65], Avg: -1541.2767 (0.659)
Step: 27999, Reward: -1319.9970 [254.56], Avg: -1541.5144 (0.657)
Step: 28199, Reward: -1397.8330 [253.56], Avg: -1542.2937 (0.655)
Step: 28399, Reward: -1492.0177 [35.06], Avg: -1542.1866 (0.653)
Step: 28599, Reward: -1220.4429 [302.49], Avg: -1542.0520 (0.651)
Step: 28799, Reward: -1281.2752 [212.85], Avg: -1541.7191 (0.649)
Step: 28999, Reward: -1325.5936 [245.91], Avg: -1541.9246 (0.647)
Step: 29199, Reward: -1343.4614 [192.61], Avg: -1541.8845 (0.645)
Step: 29399, Reward: -1372.6423 [160.15], Avg: -1541.8227 (0.643)
Step: 29599, Reward: -1314.7093 [251.40], Avg: -1541.9868 (0.641)
Step: 29799, Reward: -1359.8228 [164.22], Avg: -1541.8663 (0.639)
Step: 29999, Reward: -1267.4240 [192.06], Avg: -1541.3171 (0.637)
Step: 30199, Reward: -1173.2224 [170.97], Avg: -1540.0116 (0.635)
Step: 30399, Reward: -1328.3184 [239.84], Avg: -1540.1968 (0.633)
Step: 30599, Reward: -1287.8837 [186.46], Avg: -1539.7664 (0.631)
Step: 30799, Reward: -1221.0561 [153.97], Avg: -1538.6966 (0.630)
Step: 30999, Reward: -1194.8614 [125.19], Avg: -1537.2860 (0.628)
Step: 31199, Reward: -1282.3228 [193.36], Avg: -1536.8911 (0.626)
Step: 31399, Reward: -1245.5683 [255.24], Avg: -1536.6613 (0.624)
Step: 31599, Reward: -1273.6081 [249.22], Avg: -1536.5737 (0.622)
Step: 31799, Reward: -1148.8882 [178.31], Avg: -1535.2569 (0.620)
Step: 31999, Reward: -1400.3699 [161.31], Avg: -1535.4220 (0.618)
Step: 32199, Reward: -1278.3264 [194.72], Avg: -1535.0346 (0.616)
Step: 32399, Reward: -1178.9437 [132.97], Avg: -1533.6573 (0.615)
Step: 32599, Reward: -1362.8571 [205.73], Avg: -1533.8716 (0.613)
Step: 32799, Reward: -1220.4041 [265.60], Avg: -1533.5798 (0.611)
Step: 32999, Reward: -1317.5801 [207.69], Avg: -1533.5294 (0.609)
Step: 33199, Reward: -1395.3740 [196.91], Avg: -1533.8833 (0.607)
Step: 33399, Reward: -1519.9021 [63.10], Avg: -1534.1775 (0.605)
Step: 33599, Reward: -1205.5492 [267.97], Avg: -1533.8164 (0.604)
Step: 33799, Reward: -1372.8194 [138.45], Avg: -1533.6830 (0.602)
Step: 33999, Reward: -1315.0165 [263.82], Avg: -1533.9486 (0.600)
Step: 34199, Reward: -1174.0303 [162.07], Avg: -1532.7916 (0.598)
Step: 34399, Reward: -1326.3263 [220.13], Avg: -1532.8710 (0.596)
Step: 34599, Reward: -1149.1406 [196.79], Avg: -1531.7904 (0.595)
Step: 34799, Reward: -1213.4085 [234.19], Avg: -1531.3066 (0.593)
Step: 34999, Reward: -1117.4640 [150.94], Avg: -1529.8043 (0.591)
Step: 35199, Reward: -1122.3480 [132.88], Avg: -1528.2442 (0.589)
Step: 35399, Reward: -1222.5111 [219.59], Avg: -1527.7576 (0.588)
Step: 35599, Reward: -1264.4394 [186.88], Avg: -1527.3281 (0.586)
Step: 35799, Reward: -1294.0289 [185.45], Avg: -1527.0608 (0.584)
Step: 35999, Reward: -1349.7376 [152.92], Avg: -1526.9252 (0.582)
Step: 36199, Reward: -1351.1161 [132.33], Avg: -1526.6850 (0.581)
Step: 36399, Reward: -1115.7573 [121.06], Avg: -1525.0924 (0.579)
Step: 36599, Reward: -1293.9955 [179.86], Avg: -1524.8124 (0.577)
Step: 36799, Reward: -1357.3810 [153.03], Avg: -1524.7341 (0.575)
Step: 36999, Reward: -1162.5683 [176.54], Avg: -1523.7307 (0.574)
Step: 37199, Reward: -1324.6528 [208.71], Avg: -1523.7825 (0.572)
Step: 37399, Reward: -1280.5947 [185.75], Avg: -1523.4754 (0.570)
Step: 37599, Reward: -1192.6437 [158.83], Avg: -1522.5604 (0.568)
Step: 37799, Reward: -1226.4958 [208.18], Avg: -1522.0955 (0.567)
Step: 37999, Reward: -1068.7619 [35.17], Avg: -1519.8946 (0.565)
Step: 38199, Reward: -1354.5260 [112.30], Avg: -1519.6168 (0.563)
Step: 38399, Reward: -1151.3361 [204.84], Avg: -1518.7655 (0.562)
Step: 38599, Reward: -1403.0721 [138.97], Avg: -1518.8861 (0.560)
Step: 38799, Reward: -1373.1241 [173.57], Avg: -1519.0295 (0.558)
Step: 38999, Reward: -1292.5364 [235.04], Avg: -1519.0733 (0.557)
Step: 39199, Reward: -1284.5344 [211.12], Avg: -1518.9538 (0.555)
Step: 39399, Reward: -1127.5819 [152.68], Avg: -1517.7422 (0.553)
Step: 39599, Reward: -1101.9699 [176.98], Avg: -1516.5362 (0.552)
Step: 39799, Reward: -1272.2500 [169.83], Avg: -1516.1620 (0.550)
Step: 39999, Reward: -1213.7569 [210.64], Avg: -1515.7032 (0.548)
Step: 40199, Reward: -1228.5743 [228.94], Avg: -1515.4137 (0.547)
Step: 40399, Reward: -1169.5075 [178.71], Avg: -1514.5860 (0.545)
Step: 40599, Reward: -1205.3571 [269.68], Avg: -1514.3911 (0.543)
Step: 40799, Reward: -1302.9627 [132.15], Avg: -1514.0025 (0.542)
Step: 40999, Reward: -1173.0613 [238.46], Avg: -1513.5026 (0.540)
Step: 41199, Reward: -1032.9740 [196.37], Avg: -1512.1232 (0.539)
Step: 41399, Reward: -1147.3685 [194.78], Avg: -1511.3021 (0.537)
Step: 41599, Reward: -1200.5831 [195.35], Avg: -1510.7474 (0.535)
Step: 41799, Reward: -1071.0967 [173.76], Avg: -1509.4752 (0.534)
Step: 41999, Reward: -924.6542 [85.98], Avg: -1507.0998 (0.532)
Step: 42199, Reward: -1125.0704 [249.78], Avg: -1506.4730 (0.530)
Step: 42399, Reward: -1178.0525 [182.58], Avg: -1505.7851 (0.529)
Step: 42599, Reward: -1054.7972 [65.41], Avg: -1503.9749 (0.527)
Step: 42799, Reward: -1177.2766 [188.57], Avg: -1503.3294 (0.526)
Step: 42999, Reward: -1184.3684 [199.66], Avg: -1502.7745 (0.524)
Step: 43199, Reward: -1100.4337 [159.49], Avg: -1501.6502 (0.523)
Step: 43399, Reward: -1219.4457 [182.07], Avg: -1501.1888 (0.521)
Step: 43599, Reward: -1397.1587 [46.53], Avg: -1500.9250 (0.519)
Step: 43799, Reward: -1234.5525 [201.50], Avg: -1500.6288 (0.518)
Step: 43999, Reward: -1266.2790 [198.53], Avg: -1500.4660 (0.516)
Step: 44199, Reward: -1128.2847 [198.05], Avg: -1499.6780 (0.515)
Step: 44399, Reward: -1116.6397 [176.70], Avg: -1498.7486 (0.513)
Step: 44599, Reward: -1264.7493 [229.87], Avg: -1498.7301 (0.512)
Step: 44799, Reward: -1109.5594 [190.76], Avg: -1497.8443 (0.510)
Step: 44999, Reward: -1088.8012 [156.58], Avg: -1496.7222 (0.509)
Step: 45199, Reward: -1132.0457 [199.47], Avg: -1495.9913 (0.507)
Step: 45399, Reward: -1126.8838 [161.12], Avg: -1495.0750 (0.506)
Step: 45599, Reward: -1105.7250 [177.12], Avg: -1494.1442 (0.504)
Step: 45799, Reward: -1092.1662 [203.96], Avg: -1493.2794 (0.503)
Step: 45999, Reward: -1073.6762 [180.48], Avg: -1492.2398 (0.501)
Step: 46199, Reward: -1096.0075 [150.85], Avg: -1491.1775 (0.500)
Step: 46399, Reward: -1175.3645 [242.02], Avg: -1490.8594 (0.498)
Step: 46599, Reward: -1119.1643 [187.85], Avg: -1490.0704 (0.497)
Step: 46799, Reward: -1214.3368 [216.82], Avg: -1489.8186 (0.495)
Step: 46999, Reward: -1181.4278 [116.74], Avg: -1489.0030 (0.494)
Step: 47199, Reward: -1201.5293 [166.84], Avg: -1488.4919 (0.492)
Step: 47399, Reward: -1237.0768 [157.48], Avg: -1488.0955 (0.491)
Step: 47599, Reward: -1061.0083 [198.81], Avg: -1487.1364 (0.489)
Step: 47799, Reward: -1197.4606 [135.72], Avg: -1486.4922 (0.488)
Step: 47999, Reward: -1131.9626 [153.52], Avg: -1485.6547 (0.486)
Step: 48199, Reward: -1164.6116 [174.27], Avg: -1485.0457 (0.485)
Step: 48399, Reward: -1094.0305 [145.41], Avg: -1484.0308 (0.483)
Step: 48599, Reward: -1091.9758 [124.38], Avg: -1482.9293 (0.482)
Step: 48799, Reward: -1098.2163 [143.46], Avg: -1481.9405 (0.480)
Step: 48999, Reward: -1089.4235 [129.07], Avg: -1480.8652 (0.479)
Step: 49199, Reward: -1167.9047 [122.58], Avg: -1480.0913 (0.478)
Step: 49399, Reward: -1234.5401 [170.66], Avg: -1479.7881 (0.476)
Step: 49599, Reward: -1109.0515 [170.88], Avg: -1478.9822 (0.475)
Step: 49799, Reward: -1057.0608 [133.88], Avg: -1477.8255 (0.473)
Step: 49999, Reward: -1145.2229 [180.06], Avg: -1477.2153 (0.472)
Step: 50199, Reward: -1088.3728 [125.91], Avg: -1476.1678 (0.470)
Step: 50399, Reward: -1213.3813 [179.80], Avg: -1475.8385 (0.469)
Step: 50599, Reward: -1188.4186 [175.76], Avg: -1475.3971 (0.468)
Step: 50799, Reward: -1135.7948 [148.97], Avg: -1474.6466 (0.466)
Step: 50999, Reward: -1086.5817 [168.36], Avg: -1473.7850 (0.465)
Step: 51199, Reward: -1210.1373 [206.30], Avg: -1473.5610 (0.463)
Step: 51399, Reward: -1116.2747 [120.65], Avg: -1472.6402 (0.462)
Step: 51599, Reward: -1226.7250 [177.49], Avg: -1472.3750 (0.461)
Step: 51799, Reward: -1176.6321 [216.30], Avg: -1472.0683 (0.459)
Step: 51999, Reward: -1077.6718 [154.98], Avg: -1471.1475 (0.458)
Step: 52199, Reward: -931.9077 [99.88], Avg: -1469.4641 (0.456)
Step: 52399, Reward: -1002.0869 [187.86], Avg: -1468.3972 (0.455)
Step: 52599, Reward: -1042.4256 [145.40], Avg: -1467.3304 (0.454)
Step: 52799, Reward: -1071.2897 [133.15], Avg: -1466.3346 (0.452)
Step: 52999, Reward: -1231.5966 [181.23], Avg: -1466.1327 (0.451)
Step: 53199, Reward: -1033.5375 [181.31], Avg: -1465.1881 (0.450)
Step: 53399, Reward: -1074.6459 [173.34], Avg: -1464.3746 (0.448)
Step: 53599, Reward: -901.5831 [48.33], Avg: -1462.4549 (0.447)
Step: 53799, Reward: -1063.6512 [128.62], Avg: -1461.4505 (0.446)
Step: 53999, Reward: -946.0032 [218.79], Avg: -1460.3518 (0.444)
Step: 54199, Reward: -977.2348 [180.46], Avg: -1459.2350 (0.443)
Step: 54399, Reward: -1131.6731 [226.59], Avg: -1458.8638 (0.442)
Step: 54599, Reward: -943.5080 [50.48], Avg: -1457.1609 (0.440)
Step: 54799, Reward: -1101.6811 [223.19], Avg: -1456.6781 (0.439)
Step: 54999, Reward: -1037.6530 [260.42], Avg: -1456.1014 (0.438)
Step: 55199, Reward: -1040.6591 [201.89], Avg: -1455.3277 (0.436)
Step: 55399, Reward: -1081.3603 [250.12], Avg: -1454.8806 (0.435)
Step: 55599, Reward: -1145.0745 [266.13], Avg: -1454.7235 (0.434)
Step: 55799, Reward: -946.1449 [54.26], Avg: -1453.0951 (0.432)
Step: 55999, Reward: -998.1588 [113.15], Avg: -1451.8744 (0.431)
Step: 56199, Reward: -1141.4700 [168.16], Avg: -1451.3682 (0.430)
Step: 56399, Reward: -996.8516 [170.13], Avg: -1450.3598 (0.429)
Step: 56599, Reward: -938.6407 [204.88], Avg: -1449.2755 (0.427)
Step: 56799, Reward: -925.3873 [219.91], Avg: -1448.2052 (0.426)
Step: 56999, Reward: -995.9544 [138.39], Avg: -1447.1039 (0.425)
Step: 57199, Reward: -1128.1774 [205.06], Avg: -1446.7058 (0.423)
Step: 57399, Reward: -1098.4308 [196.73], Avg: -1446.1778 (0.422)
Step: 57599, Reward: -961.5213 [140.28], Avg: -1444.9820 (0.421)
Step: 57799, Reward: -970.6122 [164.92], Avg: -1443.9112 (0.420)
Step: 57999, Reward: -965.8179 [167.61], Avg: -1442.8406 (0.418)
Step: 58199, Reward: -957.8687 [189.76], Avg: -1441.8261 (0.417)
Step: 58399, Reward: -1081.1951 [206.38], Avg: -1441.2979 (0.416)
Step: 58599, Reward: -1003.2157 [103.49], Avg: -1440.1559 (0.415)
Step: 58799, Reward: -1019.5399 [188.07], Avg: -1439.3650 (0.413)
Step: 58999, Reward: -1007.7718 [228.93], Avg: -1438.6780 (0.412)
Step: 59199, Reward: -1011.0778 [214.82], Avg: -1437.9591 (0.411)
Step: 59399, Reward: -1041.5559 [206.47], Avg: -1437.3196 (0.410)
Step: 59599, Reward: -933.2847 [176.77], Avg: -1436.2214 (0.408)
Step: 59799, Reward: -847.7139 [107.26], Avg: -1434.6119 (0.407)
Step: 59999, Reward: -953.9157 [159.47], Avg: -1433.5412 (0.406)
Step: 60199, Reward: -852.3945 [113.15], Avg: -1431.9864 (0.405)
Step: 60399, Reward: -885.7772 [62.32], Avg: -1430.3841 (0.404)
Step: 60599, Reward: -864.3083 [16.67], Avg: -1428.5709 (0.402)
Step: 60799, Reward: -869.8347 [61.93], Avg: -1426.9366 (0.401)
Step: 60999, Reward: -844.8100 [79.49], Avg: -1425.2886 (0.400)
Step: 61199, Reward: -753.5363 [6.05], Avg: -1423.1131 (0.399)
Step: 61399, Reward: -1039.8854 [195.54], Avg: -1422.5018 (0.398)
Step: 61599, Reward: -907.2722 [197.60], Avg: -1421.4705 (0.396)
Step: 61799, Reward: -853.6608 [122.27], Avg: -1420.0286 (0.395)
Step: 61999, Reward: -868.2031 [112.38], Avg: -1418.6110 (0.394)
Step: 62199, Reward: -917.0603 [94.24], Avg: -1417.3014 (0.393)
Step: 62399, Reward: -889.4251 [200.24], Avg: -1416.2513 (0.392)
Step: 62599, Reward: -911.3613 [150.48], Avg: -1415.1189 (0.390)
Step: 62799, Reward: -994.5172 [207.41], Avg: -1414.4400 (0.389)
Step: 62999, Reward: -900.7957 [234.66], Avg: -1413.5543 (0.388)
Step: 63199, Reward: -961.6574 [191.30], Avg: -1412.7297 (0.387)
Step: 63399, Reward: -782.8694 [81.42], Avg: -1410.9996 (0.386)
Step: 63599, Reward: -822.2774 [65.24], Avg: -1409.3534 (0.385)
Step: 63799, Reward: -821.2167 [114.63], Avg: -1407.8691 (0.383)
Step: 63999, Reward: -769.8597 [38.73], Avg: -1405.9963 (0.382)
Step: 64199, Reward: -781.5643 [84.32], Avg: -1404.3137 (0.381)
Step: 64399, Reward: -706.5481 [63.06], Avg: -1402.3426 (0.380)
Step: 64599, Reward: -865.0674 [192.51], Avg: -1401.2752 (0.379)
Step: 64799, Reward: -772.6268 [52.66], Avg: -1399.4975 (0.378)
Step: 64999, Reward: -727.8871 [54.92], Avg: -1397.6000 (0.377)
Step: 65199, Reward: -714.3484 [168.65], Avg: -1396.0214 (0.376)
Step: 65399, Reward: -773.4436 [54.98], Avg: -1394.2856 (0.374)
Step: 65599, Reward: -1050.7205 [260.73], Avg: -1394.0331 (0.373)
Step: 65799, Reward: -929.6807 [145.99], Avg: -1393.0654 (0.372)
Step: 65999, Reward: -751.7027 [17.39], Avg: -1391.1746 (0.371)
Step: 66199, Reward: -695.0305 [60.72], Avg: -1389.2549 (0.370)
Step: 66399, Reward: -781.4107 [34.79], Avg: -1387.5288 (0.369)
Step: 66599, Reward: -868.5559 [212.73], Avg: -1386.6092 (0.368)
Step: 66799, Reward: -852.3069 [210.40], Avg: -1385.6394 (0.367)
Step: 66999, Reward: -748.2346 [6.63], Avg: -1383.7565 (0.365)
Step: 67199, Reward: -730.6678 [46.79], Avg: -1381.9520 (0.364)
Step: 67399, Reward: -757.5405 [8.04], Avg: -1380.1230 (0.363)
Step: 67599, Reward: -737.2286 [96.29], Avg: -1378.5058 (0.362)
Step: 67799, Reward: -794.5397 [44.49], Avg: -1376.9145 (0.361)
Step: 67999, Reward: -796.0521 [59.33], Avg: -1375.3805 (0.360)
Step: 68199, Reward: -737.8072 [63.20], Avg: -1373.6962 (0.359)
Step: 68399, Reward: -759.7002 [78.80], Avg: -1372.1313 (0.358)
Step: 68599, Reward: -783.5758 [82.77], Avg: -1370.6567 (0.357)
Step: 68799, Reward: -786.1804 [80.23], Avg: -1369.1908 (0.356)
Step: 68999, Reward: -754.7762 [78.89], Avg: -1367.6386 (0.355)
Step: 69199, Reward: -741.4584 [114.07], Avg: -1366.1585 (0.354)
Step: 69399, Reward: -745.3200 [70.94], Avg: -1364.5738 (0.353)
Step: 69599, Reward: -811.5191 [96.50], Avg: -1363.2618 (0.351)
Step: 69799, Reward: -796.9632 [46.47], Avg: -1361.7724 (0.350)
Step: 69999, Reward: -765.1680 [25.92], Avg: -1360.1418 (0.349)
Step: 70199, Reward: -653.7759 [116.90], Avg: -1358.4624 (0.348)
Step: 70399, Reward: -764.8310 [87.10], Avg: -1357.0234 (0.347)
Step: 70599, Reward: -684.9259 [100.00], Avg: -1355.4027 (0.346)
Step: 70799, Reward: -730.0377 [99.23], Avg: -1353.9165 (0.345)
Step: 70999, Reward: -673.5694 [130.85], Avg: -1352.3686 (0.344)
Step: 71199, Reward: -676.2698 [60.45], Avg: -1350.6392 (0.343)
Step: 71399, Reward: -743.5470 [72.09], Avg: -1349.1406 (0.342)
Step: 71599, Reward: -726.9584 [55.23], Avg: -1347.5570 (0.341)
Step: 71799, Reward: -648.2731 [35.04], Avg: -1345.7067 (0.340)
Step: 71999, Reward: -712.4710 [49.91], Avg: -1344.0863 (0.339)
Step: 72199, Reward: -649.8646 [81.11], Avg: -1342.3880 (0.338)
Step: 72399, Reward: -676.0734 [52.05], Avg: -1340.6911 (0.337)
Step: 72599, Reward: -721.9292 [81.40], Avg: -1339.2108 (0.336)
Step: 72799, Reward: -668.7192 [55.14], Avg: -1337.5202 (0.335)
Step: 72999, Reward: -714.9111 [45.29], Avg: -1335.9386 (0.334)
Step: 73199, Reward: -650.1759 [85.01], Avg: -1334.2972 (0.333)
Step: 73399, Reward: -640.4584 [56.43], Avg: -1332.5604 (0.332)
Step: 73599, Reward: -555.7906 [51.86], Avg: -1330.5905 (0.331)
Step: 73799, Reward: -532.1232 [45.02], Avg: -1328.5486 (0.330)
Step: 73999, Reward: -756.4707 [164.31], Avg: -1327.4465 (0.329)
Step: 74199, Reward: -686.3080 [84.10], Avg: -1325.9451 (0.328)
Step: 74399, Reward: -641.2745 [48.30], Avg: -1324.2344 (0.327)
Step: 74599, Reward: -639.1615 [85.30], Avg: -1322.6265 (0.326)
Step: 74799, Reward: -606.3989 [51.55], Avg: -1320.8493 (0.325)
Step: 74999, Reward: -613.0075 [89.29], Avg: -1319.1998 (0.324)
Step: 75199, Reward: -560.9445 [54.49], Avg: -1317.3281 (0.323)
Step: 75399, Reward: -642.3246 [87.20], Avg: -1315.7689 (0.322)
Step: 75599, Reward: -550.6332 [51.86], Avg: -1313.8820 (0.321)
Step: 75799, Reward: -577.2571 [58.18], Avg: -1312.0919 (0.320)
Step: 75999, Reward: -622.5494 [29.30], Avg: -1310.3544 (0.319)
Step: 76199, Reward: -551.6002 [64.55], Avg: -1308.5323 (0.318)
Step: 76399, Reward: -606.8220 [149.52], Avg: -1307.0868 (0.317)
Step: 76599, Reward: -582.2380 [94.32], Avg: -1305.4405 (0.316)
Step: 76799, Reward: -633.5973 [77.69], Avg: -1303.8932 (0.315)
Step: 76999, Reward: -618.1375 [106.86], Avg: -1302.3896 (0.315)
Step: 77199, Reward: -565.6814 [92.89], Avg: -1300.7217 (0.314)
Step: 77399, Reward: -663.8196 [203.37], Avg: -1299.6015 (0.313)
Step: 77599, Reward: -569.7780 [178.30], Avg: -1298.1800 (0.312)
Step: 77799, Reward: -572.5261 [59.08], Avg: -1296.4664 (0.311)
Step: 77999, Reward: -728.4095 [242.59], Avg: -1295.6319 (0.310)
Step: 78199, Reward: -612.8197 [119.30], Avg: -1294.1907 (0.309)
Step: 78399, Reward: -591.3878 [98.20], Avg: -1292.6483 (0.308)
Step: 78599, Reward: -699.6791 [142.68], Avg: -1291.5025 (0.307)
Step: 78799, Reward: -572.3700 [91.76], Avg: -1289.9102 (0.306)
Step: 78999, Reward: -626.2401 [87.44], Avg: -1288.4514 (0.305)
Step: 79199, Reward: -615.1921 [10.39], Avg: -1286.7775 (0.304)
Step: 79399, Reward: -604.4488 [82.76], Avg: -1285.2673 (0.303)
Step: 79599, Reward: -549.7057 [126.62], Avg: -1283.7373 (0.302)
Step: 79799, Reward: -575.9661 [125.63], Avg: -1282.2783 (0.302)
Step: 79999, Reward: -705.8415 [105.55], Avg: -1281.1011 (0.301)
Step: 80199, Reward: -504.6828 [113.38], Avg: -1279.4476 (0.300)
Step: 80399, Reward: -407.2719 [128.10], Avg: -1277.5966 (0.299)
Step: 80599, Reward: -550.9022 [100.86], Avg: -1276.0437 (0.298)
Step: 80799, Reward: -546.2296 [125.63], Avg: -1274.5482 (0.297)
Step: 80999, Reward: -442.9044 [94.03], Avg: -1272.7269 (0.296)
Step: 81199, Reward: -414.1522 [104.96], Avg: -1270.8707 (0.295)
Step: 81399, Reward: -450.7921 [126.20], Avg: -1269.1659 (0.294)
Step: 81599, Reward: -444.7008 [126.66], Avg: -1267.4556 (0.294)
Step: 81799, Reward: -414.3996 [131.16], Avg: -1265.6905 (0.293)
Step: 81999, Reward: -429.5036 [71.46], Avg: -1263.8253 (0.292)
Step: 82199, Reward: -433.6940 [170.25], Avg: -1262.2198 (0.291)
Step: 82399, Reward: -503.9958 [218.57], Avg: -1260.9099 (0.290)
Step: 82599, Reward: -514.1135 [134.86], Avg: -1259.4282 (0.289)
Step: 82799, Reward: -432.2771 [65.29], Avg: -1257.5880 (0.288)
Step: 82999, Reward: -290.4295 [107.18], Avg: -1255.5158 (0.287)
Step: 83199, Reward: -435.4308 [257.41], Avg: -1254.1632 (0.287)
Step: 83399, Reward: -450.6450 [98.18], Avg: -1252.4717 (0.286)
Step: 83599, Reward: -382.1377 [103.21], Avg: -1250.6365 (0.285)
Step: 83799, Reward: -273.4414 [86.77], Avg: -1248.5114 (0.284)
Step: 83999, Reward: -420.4391 [59.79], Avg: -1246.6822 (0.283)
Step: 84199, Reward: -407.8866 [131.59], Avg: -1245.0023 (0.282)
Step: 84399, Reward: -338.0276 [132.53], Avg: -1243.1672 (0.281)
Step: 84599, Reward: -599.8088 [180.20], Avg: -1242.0722 (0.281)
Step: 84799, Reward: -238.8687 [192.81], Avg: -1240.1609 (0.280)
Step: 84999, Reward: -300.5727 [58.81], Avg: -1238.0885 (0.279)
Step: 85199, Reward: -309.6826 [133.89], Avg: -1236.2234 (0.278)
Step: 85399, Reward: -414.8302 [175.80], Avg: -1234.7115 (0.277)
Step: 85599, Reward: -373.3663 [152.64], Avg: -1233.0557 (0.276)
Step: 85799, Reward: -250.3034 [152.51], Avg: -1231.1204 (0.276)
Step: 85999, Reward: -371.4681 [73.69], Avg: -1229.2925 (0.275)
Step: 86199, Reward: -322.3132 [161.13], Avg: -1227.5620 (0.274)
Step: 86399, Reward: -283.1448 [184.10], Avg: -1225.8020 (0.273)
Step: 86599, Reward: -346.8435 [120.63], Avg: -1224.0507 (0.272)
Step: 86799, Reward: -226.2367 [89.84], Avg: -1221.9586 (0.271)
Step: 86999, Reward: -293.8563 [91.84], Avg: -1220.0362 (0.271)
Step: 87199, Reward: -252.8399 [132.45], Avg: -1218.1216 (0.270)
Step: 87399, Reward: -351.0974 [119.31], Avg: -1216.4106 (0.269)
Step: 87599, Reward: -271.9096 [115.17], Avg: -1214.5171 (0.268)
Step: 87799, Reward: -231.0680 [87.19], Avg: -1212.4755 (0.267)
Step: 87999, Reward: -321.3098 [123.04], Avg: -1210.7298 (0.267)
Step: 88199, Reward: -290.6598 [116.65], Avg: -1208.9080 (0.266)
Step: 88399, Reward: -181.9686 [129.98], Avg: -1206.8786 (0.265)
Step: 88599, Reward: -241.0693 [76.68], Avg: -1204.8716 (0.264)
Step: 88799, Reward: -206.0962 [166.41], Avg: -1202.9969 (0.263)
Step: 88999, Reward: -418.6593 [142.38], Avg: -1201.5543 (0.263)
Step: 89199, Reward: -321.3888 [63.03], Avg: -1199.7221 (0.262)
Step: 89399, Reward: -305.8289 [168.14], Avg: -1198.0985 (0.261)
Step: 89599, Reward: -206.9262 [126.44], Avg: -1196.1683 (0.260)
Step: 89799, Reward: -225.7911 [48.29], Avg: -1194.1147 (0.259)
Step: 89999, Reward: -224.9150 [88.36], Avg: -1192.1573 (0.259)
Step: 90199, Reward: -286.5037 [109.09], Avg: -1190.3910 (0.258)
Step: 90399, Reward: -285.0996 [77.23], Avg: -1188.5590 (0.257)
Step: 90599, Reward: -174.5713 [119.45], Avg: -1186.5843 (0.256)
Step: 90799, Reward: -276.4476 [179.77], Avg: -1184.9756 (0.256)
Step: 90999, Reward: -201.4121 [54.23], Avg: -1182.9331 (0.255)
Step: 91199, Reward: -323.5635 [130.80], Avg: -1181.3354 (0.254)
Step: 91399, Reward: -304.1198 [133.33], Avg: -1179.7076 (0.253)
Step: 91599, Reward: -299.2559 [98.76], Avg: -1178.0009 (0.253)
Step: 91799, Reward: -225.9669 [50.13], Avg: -1176.0359 (0.252)
Step: 91999, Reward: -153.3510 [115.45], Avg: -1174.0637 (0.251)
Step: 92199, Reward: -182.8602 [170.12], Avg: -1172.2826 (0.250)
Step: 92399, Reward: -250.0203 [190.69], Avg: -1170.6991 (0.250)
Step: 92599, Reward: -223.7453 [91.48], Avg: -1168.8514 (0.249)
Step: 92799, Reward: -224.4847 [140.29], Avg: -1167.1185 (0.248)
Step: 92999, Reward: -176.5158 [93.17], Avg: -1165.1885 (0.247)
Step: 93199, Reward: -248.0984 [76.89], Avg: -1163.3855 (0.247)
Step: 93399, Reward: -230.8756 [150.32], Avg: -1161.7106 (0.246)
Step: 93599, Reward: -203.5694 [98.70], Avg: -1159.8742 (0.245)
Step: 93799, Reward: -155.0374 [89.05], Avg: -1157.9216 (0.244)
Step: 93999, Reward: -154.3008 [47.16], Avg: -1155.8866 (0.244)
Step: 94199, Reward: -294.7010 [156.33], Avg: -1154.3901 (0.243)
Step: 94399, Reward: -195.5500 [91.99], Avg: -1152.5535 (0.242)
Step: 94599, Reward: -222.5098 [47.48], Avg: -1150.6876 (0.241)
Step: 94799, Reward: -202.5734 [156.28], Avg: -1149.0171 (0.241)
Step: 94999, Reward: -271.8826 [140.32], Avg: -1147.4659 (0.240)
Step: 95199, Reward: -199.1496 [57.09], Avg: -1145.5936 (0.239)
Step: 95399, Reward: -240.4323 [73.19], Avg: -1143.8494 (0.239)
Step: 95599, Reward: -177.6385 [119.82], Avg: -1142.0787 (0.238)
Step: 95799, Reward: -223.9979 [86.91], Avg: -1140.3435 (0.237)
Step: 95999, Reward: -173.4712 [57.71], Avg: -1138.4494 (0.236)
Step: 96199, Reward: -246.1097 [100.93], Avg: -1136.8040 (0.236)
Step: 96399, Reward: -269.7104 [53.49], Avg: -1135.1161 (0.235)
Step: 96599, Reward: -269.2824 [148.46], Avg: -1133.6308 (0.234)
Step: 96799, Reward: -179.8281 [96.44], Avg: -1131.8594 (0.234)
Step: 96999, Reward: -243.2547 [72.69], Avg: -1130.1771 (0.233)
Step: 97199, Reward: -330.5149 [255.15], Avg: -1129.0567 (0.232)
Step: 97399, Reward: -175.5552 [55.37], Avg: -1127.2125 (0.231)
Step: 97599, Reward: -243.7379 [192.21], Avg: -1125.7960 (0.231)
Step: 97799, Reward: -323.8908 [218.28], Avg: -1124.6025 (0.230)
Step: 97999, Reward: -207.1247 [127.73], Avg: -1122.9908 (0.229)
Step: 98199, Reward: -150.4102 [85.30], Avg: -1121.1837 (0.229)
Step: 98399, Reward: -179.4170 [55.97], Avg: -1119.3833 (0.228)
Step: 98599, Reward: -156.1475 [141.39], Avg: -1117.7163 (0.227)
Step: 98799, Reward: -154.8870 [90.83], Avg: -1115.9511 (0.227)
Step: 98999, Reward: -244.7427 [99.87], Avg: -1114.3928 (0.226)
Step: 99199, Reward: -280.5006 [119.03], Avg: -1112.9516 (0.225)
Step: 99399, Reward: -237.3277 [96.37], Avg: -1111.3836 (0.225)
Step: 99599, Reward: -198.6342 [55.08], Avg: -1109.6614 (0.224)
Step: 99799, Reward: -221.5909 [45.80], Avg: -1107.9735 (0.223)
Step: 99999, Reward: -242.9612 [126.62], Avg: -1106.4967 (0.223)
