Model: <class 'models.ppo.PPOAgent'>, Dir: Pendulum-v0
num_envs: 16,

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

EPS_MIN = 0.1                	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.997             	# The rate at which eps decays from EPS_MAX to EPS_MIN
BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.1				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) * critic_error.pow(2) * scale
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss.mean())
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		update_freq = int(self.update_freq * (1 - self.eps + EPS_MIN)**2)
		if len(self.buffer) >= update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, scale=8*update_freq/len(self.replay_buffer))
		if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddqn", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "LunarLander-v2"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[3]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class PixelAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	logger = Logger(model, env_name, num_envs=num_envs)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = PixelAgent(envs.state_size, envs.action_size, num_envs, model)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0] or s+1 % envs.env.spec.max_episode_steps == 0:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 199, Reward: -1662.8907 [85.78], Avg: -1748.6713 (0.997)
Step: 399, Reward: -1460.7343 [150.78], Avg: -1680.0917 (0.994)
Step: 599, Reward: -1261.8526 [176.88], Avg: -1599.6386 (0.991)
Step: 799, Reward: -1150.0899 [43.37], Avg: -1498.0936 (0.988)
Step: 999, Reward: -1369.2166 [174.09], Avg: -1507.1366 (0.985)
Step: 1199, Reward: -1410.5655 [67.25], Avg: -1502.2500 (0.982)
Step: 1399, Reward: -1490.0791 [17.62], Avg: -1503.0291 (0.979)
Step: 1599, Reward: -1456.5628 [34.39], Avg: -1501.5196 (0.976)
Step: 1799, Reward: -1456.0827 [53.84], Avg: -1502.4536 (0.973)
Step: 1999, Reward: -1410.6570 [65.89], Avg: -1499.8627 (0.970)
Step: 2199, Reward: -1350.4044 [33.05], Avg: -1489.2804 (0.967)
Step: 2399, Reward: -1301.1101 [66.81], Avg: -1479.1673 (0.965)
Step: 2599, Reward: -1286.5750 [88.84], Avg: -1471.1862 (0.962)
Step: 2799, Reward: -1250.3768 [70.73], Avg: -1460.4660 (0.959)
Step: 2999, Reward: -1319.2675 [66.59], Avg: -1455.4918 (0.956)
Step: 3199, Reward: -1392.8798 [55.15], Avg: -1455.0255 (0.953)
Step: 3399, Reward: -1360.3981 [86.73], Avg: -1454.5610 (0.950)
Step: 3599, Reward: -1370.8921 [61.47], Avg: -1453.3275 (0.947)
Step: 3799, Reward: -1399.8053 [49.36], Avg: -1453.1083 (0.945)
Step: 3999, Reward: -1330.9339 [60.10], Avg: -1450.0047 (0.942)
Step: 4199, Reward: -1320.6501 [82.11], Avg: -1447.7550 (0.939)
Step: 4399, Reward: -1408.5601 [86.36], Avg: -1449.8988 (0.936)
Step: 4599, Reward: -1414.8216 [57.80], Avg: -1450.8869 (0.933)
Step: 4799, Reward: -1316.5926 [135.19], Avg: -1450.9241 (0.930)
Step: 4999, Reward: -1322.8216 [76.78], Avg: -1448.8713 (0.928)
Step: 5199, Reward: -1353.7918 [76.20], Avg: -1448.1453 (0.925)
Step: 5399, Reward: -1236.7058 [121.86], Avg: -1444.8277 (0.922)
Step: 5599, Reward: -1312.9474 [53.05], Avg: -1442.0123 (0.919)
Step: 5799, Reward: -1309.0126 [63.62], Avg: -1439.6198 (0.917)
Step: 5999, Reward: -1357.3814 [47.42], Avg: -1438.4590 (0.914)
Step: 6199, Reward: -1201.0930 [58.32], Avg: -1432.6833 (0.911)
Step: 6399, Reward: -1252.4011 [82.78], Avg: -1429.6362 (0.908)
Step: 6599, Reward: -1236.5512 [84.41], Avg: -1426.3430 (0.906)
Step: 6799, Reward: -1213.8645 [63.69], Avg: -1421.9667 (0.903)
Step: 6999, Reward: -1246.6976 [53.14], Avg: -1418.4772 (0.900)
Step: 7199, Reward: -1291.7887 [11.56], Avg: -1415.2791 (0.897)
Step: 7399, Reward: -1181.8861 [48.65], Avg: -1410.2861 (0.895)
Step: 7599, Reward: -1273.4113 [126.50], Avg: -1410.0132 (0.892)
Step: 7799, Reward: -1240.5980 [68.93], Avg: -1407.4367 (0.889)
Step: 7999, Reward: -1303.0616 [54.21], Avg: -1406.1825 (0.887)
Step: 8199, Reward: -1285.9522 [38.61], Avg: -1404.1918 (0.884)
Step: 8399, Reward: -1281.0169 [55.54], Avg: -1402.5815 (0.881)
Step: 8599, Reward: -1283.2567 [69.45], Avg: -1401.4216 (0.879)
Step: 8799, Reward: -1288.1765 [70.13], Avg: -1400.4417 (0.876)
Step: 8999, Reward: -1283.4509 [41.92], Avg: -1398.7734 (0.874)
Step: 9199, Reward: -1253.5030 [52.61], Avg: -1396.7591 (0.871)
Step: 9399, Reward: -1204.0554 [63.20], Avg: -1394.0037 (0.868)
Step: 9599, Reward: -1235.1365 [62.82], Avg: -1392.0028 (0.866)
Step: 9799, Reward: -1223.5665 [63.86], Avg: -1389.8685 (0.863)
Step: 9999, Reward: -1159.0565 [61.19], Avg: -1386.4760 (0.861)
Step: 10199, Reward: -1061.3681 [102.55], Avg: -1382.1121 (0.858)
Step: 10399, Reward: -1133.7297 [60.49], Avg: -1378.4988 (0.855)
Step: 10599, Reward: -1047.2183 [42.84], Avg: -1373.0566 (0.853)
Step: 10799, Reward: -1061.1317 [93.45], Avg: -1369.0108 (0.850)
Step: 10999, Reward: -1167.8564 [82.37], Avg: -1366.8510 (0.848)
Step: 11199, Reward: -1133.4630 [112.01], Avg: -1364.6836 (0.845)
Step: 11399, Reward: -1078.1739 [170.39], Avg: -1362.6463 (0.843)
Step: 11599, Reward: -1082.2594 [62.34], Avg: -1358.8870 (0.840)
Step: 11799, Reward: -993.7572 [88.59], Avg: -1354.1998 (0.838)
Step: 11999, Reward: -1007.2675 [175.95], Avg: -1351.3502 (0.835)
Step: 12199, Reward: -1035.1165 [120.23], Avg: -1348.1370 (0.833)
Step: 12399, Reward: -1044.9535 [47.76], Avg: -1344.0174 (0.830)
Step: 12599, Reward: -1078.9796 [48.36], Avg: -1340.5780 (0.828)
Step: 12799, Reward: -1022.7395 [43.44], Avg: -1336.2905 (0.825)
Step: 12999, Reward: -938.8158 [111.19], Avg: -1331.8861 (0.823)
Step: 13199, Reward: -870.8692 [58.15], Avg: -1325.7821 (0.820)
Step: 13399, Reward: -899.4953 [52.00], Avg: -1320.1957 (0.818)
Step: 13599, Reward: -1042.0378 [79.54], Avg: -1317.2749 (0.815)
Step: 13799, Reward: -1030.0925 [91.93], Avg: -1314.4451 (0.813)
Step: 13999, Reward: -975.3765 [76.75], Avg: -1310.6977 (0.810)
Step: 14199, Reward: -1060.7916 [53.60], Avg: -1307.9328 (0.808)
Step: 14399, Reward: -973.7946 [39.74], Avg: -1303.8440 (0.805)
Step: 14599, Reward: -1005.3498 [32.51], Avg: -1300.2004 (0.803)
Step: 14799, Reward: -962.3080 [58.04], Avg: -1296.4186 (0.801)
Step: 14999, Reward: -1003.5984 [52.38], Avg: -1293.2128 (0.798)
Step: 15199, Reward: -986.2159 [49.83], Avg: -1289.8290 (0.796)
Step: 15399, Reward: -1004.2862 [13.90], Avg: -1286.3012 (0.793)
Step: 15599, Reward: -925.8267 [66.74], Avg: -1282.5353 (0.791)
Step: 15799, Reward: -871.8955 [66.94], Avg: -1278.1847 (0.789)
Step: 15999, Reward: -905.5298 [55.75], Avg: -1274.2234 (0.786)
Step: 16199, Reward: -898.6004 [53.77], Avg: -1270.2500 (0.784)
Step: 16399, Reward: -863.9068 [68.65], Avg: -1266.1318 (0.782)
Step: 16599, Reward: -889.4093 [96.68], Avg: -1262.7578 (0.779)
Step: 16799, Reward: -967.9698 [80.04], Avg: -1260.2013 (0.777)
Step: 16999, Reward: -970.7598 [87.91], Avg: -1257.8303 (0.775)
Step: 17199, Reward: -864.0675 [75.29], Avg: -1254.1271 (0.772)
Step: 17399, Reward: -931.9832 [94.80], Avg: -1251.5140 (0.770)
Step: 17599, Reward: -845.5952 [90.65], Avg: -1247.9314 (0.768)
Step: 17799, Reward: -930.7986 [55.68], Avg: -1244.9937 (0.765)
Step: 17999, Reward: -915.7264 [50.45], Avg: -1241.8958 (0.763)
Step: 18199, Reward: -889.6413 [114.59], Avg: -1239.2840 (0.761)
Step: 18399, Reward: -872.1817 [26.12], Avg: -1235.5777 (0.758)
Step: 18599, Reward: -826.3829 [125.74], Avg: -1232.5298 (0.756)
Step: 18799, Reward: -878.2596 [70.71], Avg: -1229.5132 (0.754)
Step: 18999, Reward: -879.2907 [44.02], Avg: -1226.2900 (0.752)
Step: 19199, Reward: -764.7133 [94.84], Avg: -1222.4698 (0.749)
Step: 19399, Reward: -779.8677 [95.09], Avg: -1218.8872 (0.747)
Step: 19599, Reward: -909.2564 [69.83], Avg: -1216.4403 (0.745)
Step: 19799, Reward: -796.9055 [53.54], Avg: -1212.7433 (0.743)
Step: 19999, Reward: -781.9552 [83.07], Avg: -1209.2662 (0.740)
Step: 20199, Reward: -744.3645 [66.48], Avg: -1205.3213 (0.738)
Step: 20399, Reward: -716.0025 [43.27], Avg: -1200.9483 (0.736)
Step: 20599, Reward: -902.7345 [57.73], Avg: -1198.6134 (0.734)
Step: 20799, Reward: -719.7275 [138.64], Avg: -1195.3419 (0.732)
Step: 20999, Reward: -803.1440 [96.09], Avg: -1192.5218 (0.729)
Step: 21199, Reward: -751.7713 [47.82], Avg: -1188.8149 (0.727)
Step: 21399, Reward: -585.8695 [98.75], Avg: -1184.1028 (0.725)
Step: 21599, Reward: -562.1209 [105.46], Avg: -1179.3202 (0.723)
Step: 21799, Reward: -283.7379 [49.80], Avg: -1171.5607 (0.721)
Step: 21999, Reward: -449.2197 [59.61], Avg: -1165.5359 (0.719)
Step: 22199, Reward: -370.9751 [80.49], Avg: -1159.1028 (0.716)
Step: 22399, Reward: -277.8699 [149.79], Avg: -1152.5720 (0.714)
Step: 22599, Reward: -308.3975 [121.66], Avg: -1146.1781 (0.712)
Step: 22799, Reward: -203.1040 [61.44], Avg: -1138.4444 (0.710)
Step: 22999, Reward: -224.4621 [144.73], Avg: -1131.7553 (0.708)
Step: 23199, Reward: -326.2809 [130.75], Avg: -1125.9386 (0.706)
Step: 23399, Reward: -247.0994 [76.27], Avg: -1119.0790 (0.704)
Step: 23599, Reward: -146.7576 [112.99], Avg: -1111.7966 (0.702)
Step: 23799, Reward: -145.7017 [87.91], Avg: -1104.4169 (0.699)
Step: 23999, Reward: -174.4683 [126.47], Avg: -1097.7213 (0.697)
Step: 24199, Reward: -147.6169 [51.73], Avg: -1090.2967 (0.695)
Step: 24399, Reward: -196.6879 [123.05], Avg: -1083.9806 (0.693)
Step: 24599, Reward: -194.8616 [121.87], Avg: -1077.7428 (0.691)
Step: 24799, Reward: -241.8714 [109.15], Avg: -1071.8821 (0.689)
Step: 24999, Reward: -238.1514 [73.01], Avg: -1065.7964 (0.687)
Step: 25199, Reward: -267.4003 [140.16], Avg: -1060.5723 (0.685)
Step: 25399, Reward: -161.6381 [109.42], Avg: -1054.3556 (0.683)
Step: 25599, Reward: -169.4454 [97.64], Avg: -1048.2051 (0.681)
Step: 25799, Reward: -149.9056 [121.27], Avg: -1042.1816 (0.679)
Step: 25999, Reward: -168.7876 [54.91], Avg: -1035.8856 (0.677)
Step: 26199, Reward: -121.4931 [106.32], Avg: -1029.7170 (0.675)
Step: 26399, Reward: -143.3375 [112.68], Avg: -1023.8557 (0.673)
Step: 26599, Reward: -145.1507 [86.99], Avg: -1017.9030 (0.671)
Step: 26799, Reward: -165.2873 [170.56], Avg: -1012.8130 (0.669)
Step: 26999, Reward: -220.9745 [142.43], Avg: -1008.0026 (0.667)
Step: 27199, Reward: -170.0357 [117.10], Avg: -1002.7021 (0.665)
Step: 27399, Reward: -165.1639 [108.76], Avg: -997.3826 (0.663)
Step: 27599, Reward: -214.8033 [120.26], Avg: -992.5831 (0.661)
Step: 27799, Reward: -170.0730 [55.42], Avg: -987.0645 (0.659)
Step: 27999, Reward: -266.8242 [120.51], Avg: -982.7808 (0.657)
Step: 28199, Reward: -200.7514 [99.48], Avg: -977.9400 (0.655)
Step: 28399, Reward: -228.4608 [127.55], Avg: -973.5602 (0.653)
Step: 28599, Reward: -171.1923 [122.20], Avg: -968.8037 (0.651)
Step: 28799, Reward: -141.2266 [83.87], Avg: -963.6391 (0.649)
Step: 28999, Reward: -222.5601 [165.07], Avg: -959.6666 (0.647)
Step: 29199, Reward: -170.7106 [58.09], Avg: -954.6606 (0.645)
Step: 29399, Reward: -178.2644 [102.72], Avg: -950.0778 (0.643)
Step: 29599, Reward: -197.5878 [129.77], Avg: -945.8702 (0.641)
Step: 29799, Reward: -165.1081 [51.44], Avg: -940.9755 (0.639)
Step: 29999, Reward: -220.5061 [89.64], Avg: -936.7699 (0.637)
Step: 30199, Reward: -237.3032 [68.02], Avg: -932.5882 (0.635)
Step: 30399, Reward: -146.5455 [48.24], Avg: -927.7342 (0.633)
Step: 30599, Reward: -283.1780 [49.85], Avg: -923.8472 (0.631)
Step: 30799, Reward: -195.2932 [103.08], Avg: -919.7857 (0.630)
Step: 30999, Reward: -169.9257 [60.79], Avg: -915.3401 (0.628)
Step: 31199, Reward: -167.8803 [93.78], Avg: -911.1498 (0.626)
Step: 31399, Reward: -121.8101 [72.67], Avg: -906.5850 (0.624)
Step: 31599, Reward: -165.7421 [118.17], Avg: -902.6441 (0.622)
Step: 31799, Reward: -214.0698 [139.07], Avg: -899.1881 (0.620)
Step: 31999, Reward: -121.3148 [72.14], Avg: -894.7772 (0.618)
Step: 32199, Reward: -176.4665 [111.69], Avg: -891.0094 (0.616)
Step: 32399, Reward: -147.2347 [90.41], Avg: -886.9762 (0.615)
Step: 32599, Reward: -148.2300 [116.83], Avg: -883.1608 (0.613)
Step: 32799, Reward: -165.4253 [54.09], Avg: -879.1142 (0.611)
Step: 32999, Reward: -157.9113 [106.47], Avg: -875.3885 (0.609)
Step: 33199, Reward: -124.3002 [110.27], Avg: -871.5282 (0.607)
Step: 33399, Reward: -122.2014 [128.44], Avg: -867.8103 (0.605)
Step: 33599, Reward: -151.9954 [53.13], Avg: -863.8657 (0.604)
Step: 33799, Reward: -169.3353 [59.83], Avg: -860.1101 (0.602)
Step: 33999, Reward: -276.1216 [168.79], Avg: -857.6678 (0.600)
Step: 34199, Reward: -1247.5497 [43.73], Avg: -860.2036 (0.598)
Step: 34399, Reward: -1235.7388 [44.72], Avg: -862.6469 (0.596)
Step: 34599, Reward: -1589.7917 [60.20], Avg: -867.1980 (0.595)
Step: 34799, Reward: -1575.2099 [45.57], Avg: -871.5289 (0.593)
Step: 34999, Reward: -1569.1832 [59.33], Avg: -875.8545 (0.591)
Step: 35199, Reward: -1600.4835 [60.73], Avg: -880.3168 (0.589)
Step: 35399, Reward: -1619.9393 [54.32], Avg: -884.8023 (0.588)
Step: 35599, Reward: -1596.1989 [49.26], Avg: -889.0756 (0.586)
Step: 35799, Reward: -1559.2951 [137.76], Avg: -893.5895 (0.584)
Step: 35999, Reward: -1608.5356 [64.47], Avg: -897.9196 (0.582)
Step: 36199, Reward: -1544.7856 [108.47], Avg: -902.0927 (0.581)
Step: 36399, Reward: -1550.3652 [52.85], Avg: -905.9451 (0.579)
Step: 36599, Reward: -1573.8177 [124.91], Avg: -910.2772 (0.577)
Step: 36799, Reward: -1595.0167 [79.52], Avg: -914.4308 (0.575)
Step: 36999, Reward: -1469.3411 [146.27], Avg: -918.2209 (0.574)
Step: 37199, Reward: -1596.0897 [79.72], Avg: -922.2940 (0.572)
Step: 37399, Reward: -1493.3123 [143.80], Avg: -926.1165 (0.570)
Step: 37599, Reward: -1601.9176 [39.36], Avg: -929.9206 (0.568)
Step: 37799, Reward: -1630.2885 [18.69], Avg: -933.7251 (0.567)
Step: 37999, Reward: -1525.0887 [123.54], Avg: -937.4878 (0.565)
Step: 38199, Reward: -1589.9847 [29.43], Avg: -941.0581 (0.563)
Step: 38399, Reward: -1587.3664 [64.65], Avg: -944.7610 (0.562)
Step: 38599, Reward: -1552.5556 [118.32], Avg: -948.5232 (0.560)
Step: 38799, Reward: -1444.2225 [174.15], Avg: -951.9761 (0.558)
Step: 38999, Reward: -1489.9240 [223.01], Avg: -955.8784 (0.557)
Step: 39199, Reward: -1405.9957 [133.08], Avg: -958.8539 (0.555)
Step: 39399, Reward: -1587.2780 [31.53], Avg: -962.2039 (0.553)
Step: 39599, Reward: -1607.5152 [49.23], Avg: -965.7117 (0.552)
Step: 39799, Reward: -1586.7962 [93.90], Avg: -969.3046 (0.550)
Step: 39999, Reward: -1538.5879 [117.18], Avg: -972.7369 (0.548)
Step: 40199, Reward: -1510.7508 [181.21], Avg: -976.3152 (0.547)
Step: 40399, Reward: -1331.6750 [232.50], Avg: -979.2254 (0.545)
Step: 40599, Reward: -1512.5080 [99.31], Avg: -982.3416 (0.543)
Step: 40799, Reward: -1599.1041 [60.72], Avg: -985.6626 (0.542)
Step: 40999, Reward: -1566.5898 [50.71], Avg: -988.7438 (0.540)
Step: 41199, Reward: -1611.6346 [10.55], Avg: -991.8187 (0.539)
Step: 41399, Reward: -1526.4756 [128.13], Avg: -995.0206 (0.537)
Step: 41599, Reward: -1598.3298 [41.14], Avg: -998.1189 (0.535)
Step: 41799, Reward: -1529.5751 [118.79], Avg: -1001.2301 (0.534)
Step: 41999, Reward: -1624.5136 [17.51], Avg: -1004.2815 (0.532)
Step: 42199, Reward: -1591.5233 [75.91], Avg: -1007.4244 (0.530)
Step: 42399, Reward: -1459.3776 [155.61], Avg: -1010.2903 (0.529)
Step: 42599, Reward: -1540.6248 [99.36], Avg: -1013.2466 (0.527)
Step: 42799, Reward: -1516.9604 [50.50], Avg: -1015.8364 (0.526)
Step: 42999, Reward: -1498.5360 [192.16], Avg: -1018.9753 (0.524)
Step: 43199, Reward: -1617.3554 [23.06], Avg: -1021.8523 (0.523)
Step: 43399, Reward: -1579.1106 [35.07], Avg: -1024.5820 (0.521)
Step: 43599, Reward: -1528.5127 [115.26], Avg: -1027.4223 (0.519)
Step: 43799, Reward: -1529.0279 [140.01], Avg: -1030.3520 (0.518)
Step: 43999, Reward: -1261.8588 [268.07], Avg: -1032.6228 (0.516)
Step: 44199, Reward: -1509.2931 [253.11], Avg: -1035.9250 (0.515)
Step: 44399, Reward: -1464.0119 [162.18], Avg: -1038.5839 (0.513)
Step: 44599, Reward: -1542.7749 [137.52], Avg: -1041.4615 (0.512)
Step: 44799, Reward: -1635.6576 [19.56], Avg: -1044.2015 (0.510)
Step: 44999, Reward: -1480.3190 [128.40], Avg: -1046.7104 (0.509)
Step: 45199, Reward: -1595.8826 [32.07], Avg: -1049.2823 (0.507)
Step: 45399, Reward: -1559.2046 [54.28], Avg: -1051.7678 (0.506)
Step: 45599, Reward: -1479.1833 [186.54], Avg: -1054.4606 (0.504)
Step: 45799, Reward: -1448.5327 [190.55], Avg: -1057.0135 (0.503)
Step: 45999, Reward: -1438.0089 [225.09], Avg: -1059.6487 (0.501)
Step: 46199, Reward: -1605.2014 [31.15], Avg: -1062.1452 (0.500)
Step: 46399, Reward: -1614.5145 [9.83], Avg: -1064.5685 (0.498)
Step: 46599, Reward: -1578.0694 [73.11], Avg: -1067.0861 (0.497)
Step: 46799, Reward: -1639.5282 [12.30], Avg: -1069.5850 (0.495)
Step: 46999, Reward: -1523.0848 [75.02], Avg: -1071.8340 (0.494)
Step: 47199, Reward: -1503.3470 [174.88], Avg: -1074.4035 (0.492)
Step: 47399, Reward: -1424.4286 [135.60], Avg: -1076.4526 (0.491)
Step: 47599, Reward: -1419.9165 [232.65], Avg: -1078.8732 (0.489)
Step: 47799, Reward: -1626.0243 [26.94], Avg: -1081.2753 (0.488)
Step: 47999, Reward: -1577.6212 [47.30], Avg: -1083.5405 (0.486)
Step: 48199, Reward: -1477.0191 [167.26], Avg: -1085.8672 (0.485)
Step: 48399, Reward: -1559.7667 [41.01], Avg: -1087.9949 (0.483)
Step: 48599, Reward: -1618.6304 [10.48], Avg: -1090.2217 (0.482)
Step: 48799, Reward: -1573.0608 [54.48], Avg: -1092.4238 (0.480)
Step: 48999, Reward: -1544.6422 [87.40], Avg: -1094.6264 (0.479)
Step: 49199, Reward: -1625.1317 [45.83], Avg: -1096.9692 (0.478)
Step: 49399, Reward: -1423.2560 [211.74], Avg: -1099.1474 (0.476)
Step: 49599, Reward: -1406.2274 [177.10], Avg: -1101.0998 (0.475)
Step: 49799, Reward: -1459.3481 [223.05], Avg: -1103.4343 (0.473)
Step: 49999, Reward: -1557.2967 [122.45], Avg: -1105.7396 (0.472)
Step: 50199, Reward: -1559.6884 [125.79], Avg: -1108.0493 (0.470)
Step: 50399, Reward: -1619.8578 [26.87], Avg: -1110.1869 (0.469)
Step: 50599, Reward: -1630.1612 [24.73], Avg: -1112.3399 (0.468)
Step: 50799, Reward: -1623.7795 [14.48], Avg: -1114.4104 (0.466)
Step: 50999, Reward: -1586.9336 [64.47], Avg: -1116.5163 (0.465)
Step: 51199, Reward: -1563.1507 [96.05], Avg: -1118.6362 (0.463)
Step: 51399, Reward: -1415.5844 [323.67], Avg: -1121.0510 (0.462)
Step: 51599, Reward: -1637.9006 [16.24], Avg: -1123.1172 (0.461)
Step: 51799, Reward: -1590.4187 [42.64], Avg: -1125.0861 (0.459)
Step: 51999, Reward: -1544.2068 [166.45], Avg: -1127.3383 (0.458)
Step: 52199, Reward: -1587.3454 [107.29], Avg: -1129.5118 (0.456)
Step: 52399, Reward: -1405.9615 [315.07], Avg: -1131.7695 (0.455)
Step: 52599, Reward: -1553.7169 [44.63], Avg: -1133.5436 (0.454)
Step: 52799, Reward: -1605.8784 [54.85], Avg: -1135.5405 (0.452)
Step: 52999, Reward: -1604.8760 [20.19], Avg: -1137.3878 (0.451)
Step: 53199, Reward: -1596.4574 [52.64], Avg: -1139.3115 (0.450)
Step: 53399, Reward: -1634.1208 [16.57], Avg: -1141.2268 (0.448)
Step: 53599, Reward: -1370.1887 [261.48], Avg: -1143.0568 (0.447)
Step: 53799, Reward: -1507.7584 [98.35], Avg: -1144.7781 (0.446)
Step: 53999, Reward: -1566.2938 [98.92], Avg: -1146.7057 (0.444)
Step: 54199, Reward: -1498.8311 [221.61], Avg: -1148.8228 (0.443)
Step: 54399, Reward: -1626.9303 [26.70], Avg: -1150.6787 (0.442)
Step: 54599, Reward: -1529.3261 [134.02], Avg: -1152.5566 (0.440)
Step: 54799, Reward: -1606.3081 [51.55], Avg: -1154.4008 (0.439)
Step: 54999, Reward: -1575.1210 [60.37], Avg: -1156.1502 (0.438)
Step: 55199, Reward: -1576.9189 [60.50], Avg: -1157.8940 (0.436)
Step: 55399, Reward: -1391.3743 [286.06], Avg: -1159.7695 (0.435)
Step: 55599, Reward: -1373.3432 [276.13], Avg: -1161.5311 (0.434)
Step: 55799, Reward: -1575.1495 [64.06], Avg: -1163.2432 (0.432)
Step: 55999, Reward: -1452.2055 [235.35], Avg: -1165.1157 (0.431)
Step: 56199, Reward: -1351.8492 [315.48], Avg: -1166.9029 (0.430)
Step: 56399, Reward: -1612.8171 [50.46], Avg: -1168.6631 (0.429)
Step: 56599, Reward: -1513.8306 [183.32], Avg: -1170.5306 (0.427)
Step: 56799, Reward: -1488.0609 [241.46], Avg: -1172.4989 (0.426)
Step: 56999, Reward: -1428.3258 [235.78], Avg: -1174.2238 (0.425)
Step: 57199, Reward: -1527.3061 [247.02], Avg: -1176.3220 (0.423)
Step: 57399, Reward: -1558.2114 [53.44], Avg: -1177.8389 (0.422)
Step: 57599, Reward: -1609.6408 [68.17], Avg: -1179.5749 (0.421)
Step: 57799, Reward: -1450.6921 [273.59], Avg: -1181.4597 (0.420)
Step: 57999, Reward: -1512.3888 [138.04], Avg: -1183.0768 (0.418)
Step: 58199, Reward: -1360.1702 [237.15], Avg: -1184.5003 (0.417)
Step: 58399, Reward: -1487.3263 [85.96], Avg: -1185.8318 (0.416)
Step: 58599, Reward: -1330.8725 [261.46], Avg: -1187.2192 (0.415)
Step: 58799, Reward: -1598.5500 [44.55], Avg: -1188.7698 (0.413)
Step: 58999, Reward: -1037.9725 [47.37], Avg: -1188.4192 (0.412)
Step: 59199, Reward: -1559.8321 [59.94], Avg: -1189.8765 (0.411)
Step: 59399, Reward: -1576.0640 [24.86], Avg: -1191.2605 (0.410)
Step: 59599, Reward: -1509.8315 [106.99], Avg: -1192.6885 (0.408)
Step: 59799, Reward: -1467.8364 [252.19], Avg: -1194.4522 (0.407)
Step: 59999, Reward: -1591.1109 [58.01], Avg: -1195.9678 (0.406)
Step: 60199, Reward: -1289.5034 [246.51], Avg: -1197.0975 (0.405)
Step: 60399, Reward: -1582.3604 [58.73], Avg: -1198.5677 (0.404)
Step: 60599, Reward: -1548.1603 [110.89], Avg: -1200.0874 (0.402)
Step: 60799, Reward: -1354.5385 [259.12], Avg: -1201.4479 (0.401)
Step: 60999, Reward: -1397.5551 [298.79], Avg: -1203.0705 (0.400)
Step: 61199, Reward: -1400.6292 [298.11], Avg: -1204.6903 (0.399)
Step: 61399, Reward: -1321.2959 [245.74], Avg: -1205.8706 (0.398)
Step: 61599, Reward: -1591.2927 [57.48], Avg: -1207.3086 (0.396)
Step: 61799, Reward: -1377.3686 [235.83], Avg: -1208.6222 (0.395)
Step: 61999, Reward: -1472.6949 [216.97], Avg: -1210.1739 (0.394)
Step: 62199, Reward: -1461.6504 [203.86], Avg: -1211.6380 (0.393)
Step: 62399, Reward: -1470.9503 [223.27], Avg: -1213.1848 (0.392)
Step: 62599, Reward: -1491.0598 [235.21], Avg: -1214.8240 (0.390)
Step: 62799, Reward: -1362.1588 [283.33], Avg: -1216.1956 (0.389)
Step: 62999, Reward: -1490.5855 [196.15], Avg: -1217.6893 (0.388)
Step: 63199, Reward: -1471.0409 [281.58], Avg: -1219.3822 (0.387)
Step: 63399, Reward: -1405.6961 [262.16], Avg: -1220.7969 (0.386)
Step: 63599, Reward: -1548.2104 [124.41], Avg: -1222.2177 (0.385)
Step: 63799, Reward: -1553.5735 [112.23], Avg: -1223.6083 (0.383)
Step: 63999, Reward: -1604.5965 [49.49], Avg: -1224.9535 (0.382)
Step: 64199, Reward: -1355.9991 [266.25], Avg: -1226.1912 (0.381)
Step: 64399, Reward: -1507.2503 [193.41], Avg: -1227.6647 (0.380)
Step: 64599, Reward: -1633.1046 [18.45], Avg: -1228.9771 (0.379)
Step: 64799, Reward: -1290.5665 [197.42], Avg: -1229.7765 (0.378)
Step: 64999, Reward: -1290.9892 [268.82], Avg: -1230.7920 (0.377)
Step: 65199, Reward: -1242.0952 [215.57], Avg: -1231.4879 (0.376)
Step: 65399, Reward: -1408.9496 [223.69], Avg: -1232.7147 (0.374)
Step: 65599, Reward: -1572.1994 [55.23], Avg: -1233.9181 (0.373)
Step: 65799, Reward: -1540.9530 [214.76], Avg: -1235.5041 (0.372)
Step: 65999, Reward: -1384.1149 [260.80], Avg: -1236.7447 (0.371)
Step: 66199, Reward: -1559.7657 [107.69], Avg: -1238.0460 (0.370)
Step: 66399, Reward: -1582.8826 [62.75], Avg: -1239.2736 (0.369)
Step: 66599, Reward: -1439.9559 [211.26], Avg: -1240.5107 (0.368)
Step: 66799, Reward: -1497.8248 [215.97], Avg: -1241.9277 (0.367)
Step: 66999, Reward: -1391.9339 [163.15], Avg: -1242.8625 (0.365)
Step: 67199, Reward: -1477.8800 [171.17], Avg: -1244.0714 (0.364)
Step: 67399, Reward: -1495.6231 [225.28], Avg: -1245.4863 (0.363)
Step: 67599, Reward: -1354.5571 [308.51], Avg: -1246.7218 (0.362)
Step: 67799, Reward: -1476.3160 [241.92], Avg: -1248.1127 (0.361)
Step: 67999, Reward: -1580.2918 [56.73], Avg: -1249.2565 (0.360)
Step: 68199, Reward: -1347.8573 [291.92], Avg: -1250.4017 (0.359)
Step: 68399, Reward: -1355.9561 [266.23], Avg: -1251.4888 (0.358)
Step: 68599, Reward: -1373.2523 [289.35], Avg: -1252.6874 (0.357)
Step: 68799, Reward: -1510.3431 [208.59], Avg: -1254.0427 (0.356)
Step: 68999, Reward: -1581.8980 [57.83], Avg: -1255.1607 (0.355)
Step: 69199, Reward: -1481.7996 [292.66], Avg: -1256.6616 (0.354)
Step: 69399, Reward: -1578.1353 [47.62], Avg: -1257.7252 (0.353)
Step: 69599, Reward: -1204.6862 [333.84], Avg: -1258.5321 (0.351)
Step: 69799, Reward: -1466.2099 [260.14], Avg: -1259.8726 (0.350)
Step: 69999, Reward: -1617.4155 [33.27], Avg: -1260.9892 (0.349)
Step: 70199, Reward: -1240.8396 [223.82], Avg: -1261.5695 (0.348)
Step: 70399, Reward: -1552.2812 [169.48], Avg: -1262.8768 (0.347)
Step: 70599, Reward: -1594.3287 [86.87], Avg: -1264.0619 (0.346)
Step: 70799, Reward: -1588.0223 [48.30], Avg: -1265.1134 (0.345)
Step: 70999, Reward: -1397.9723 [266.68], Avg: -1266.2389 (0.344)
Step: 71199, Reward: -1412.7750 [247.05], Avg: -1267.3445 (0.343)
Step: 71399, Reward: -1346.5925 [283.62], Avg: -1268.3609 (0.342)
Step: 71599, Reward: -1603.4803 [53.14], Avg: -1269.4455 (0.341)
Step: 71799, Reward: -1439.1976 [219.79], Avg: -1270.5305 (0.340)
Step: 71999, Reward: -1427.5471 [240.74], Avg: -1271.6354 (0.339)
Step: 72199, Reward: -1295.6241 [259.54], Avg: -1272.4208 (0.338)
Step: 72399, Reward: -1490.6855 [232.85], Avg: -1273.6669 (0.337)
Step: 72599, Reward: -1606.0959 [66.67], Avg: -1274.7664 (0.336)
Step: 72799, Reward: -1519.4086 [242.19], Avg: -1276.1038 (0.335)
Step: 72999, Reward: -1374.6666 [265.11], Avg: -1277.1002 (0.334)
Step: 73199, Reward: -1485.8376 [234.82], Avg: -1278.3121 (0.333)
Step: 73399, Reward: -1244.6441 [285.29], Avg: -1278.9977 (0.332)
Step: 73599, Reward: -1532.0908 [185.56], Avg: -1280.1897 (0.331)
Step: 73799, Reward: -1335.6606 [240.46], Avg: -1280.9917 (0.330)
Step: 73999, Reward: -1373.7122 [280.47], Avg: -1282.0003 (0.329)
Step: 74199, Reward: -1409.9417 [258.12], Avg: -1283.0409 (0.328)
Step: 74399, Reward: -1623.4132 [30.69], Avg: -1284.0384 (0.327)
Step: 74599, Reward: -1375.5283 [329.91], Avg: -1285.1681 (0.326)
Step: 74799, Reward: -1626.6800 [31.44], Avg: -1286.1653 (0.325)
Step: 74999, Reward: -1407.5287 [268.75], Avg: -1287.2056 (0.324)
Step: 75199, Reward: -1356.0827 [281.81], Avg: -1288.1383 (0.323)
Step: 75399, Reward: -1221.3860 [258.61], Avg: -1288.6472 (0.322)
Step: 75599, Reward: -1461.2117 [225.60], Avg: -1289.7005 (0.321)
Step: 75799, Reward: -1625.9835 [24.78], Avg: -1290.6532 (0.320)
Step: 75999, Reward: -1556.8357 [95.22], Avg: -1291.6043 (0.319)
Step: 76199, Reward: -1566.6119 [110.57], Avg: -1292.6163 (0.318)
Step: 76399, Reward: -1229.0629 [272.81], Avg: -1293.1641 (0.317)
Step: 76599, Reward: -1382.2362 [310.44], Avg: -1294.2072 (0.316)
Step: 76799, Reward: -1070.5881 [275.35], Avg: -1294.3419 (0.315)
Step: 76999, Reward: -1543.4564 [89.40], Avg: -1295.2211 (0.315)
Step: 77199, Reward: -1217.8394 [329.26], Avg: -1295.8737 (0.314)
Step: 77399, Reward: -1043.2555 [285.56], Avg: -1295.9588 (0.313)
Step: 77599, Reward: -1213.3634 [331.36], Avg: -1296.5999 (0.312)
Step: 77799, Reward: -1393.0636 [289.33], Avg: -1297.5917 (0.311)
Step: 77999, Reward: -1368.8333 [340.17], Avg: -1298.6466 (0.310)
Step: 78199, Reward: -1622.3450 [35.81], Avg: -1299.5660 (0.309)
Step: 78399, Reward: -1474.4409 [119.60], Avg: -1300.3173 (0.308)
Step: 78599, Reward: -1582.0642 [67.51], Avg: -1301.2059 (0.307)
Step: 78799, Reward: -1424.0215 [271.00], Avg: -1302.2055 (0.306)
Step: 78999, Reward: -1394.5251 [250.59], Avg: -1303.0736 (0.305)
Step: 79199, Reward: -1489.7118 [246.24], Avg: -1304.1668 (0.304)
Step: 79399, Reward: -1450.8164 [229.39], Avg: -1305.1140 (0.303)
Step: 79599, Reward: -1416.6073 [264.27], Avg: -1306.0581 (0.302)
Step: 79799, Reward: -1356.7370 [303.53], Avg: -1306.9458 (0.302)
Step: 79999, Reward: -1327.8005 [352.15], Avg: -1307.8784 (0.301)
Step: 80199, Reward: -1469.1070 [221.74], Avg: -1308.8334 (0.300)
Step: 80399, Reward: -1490.7641 [227.10], Avg: -1309.8509 (0.299)
Step: 80599, Reward: -1467.0239 [289.41], Avg: -1310.9591 (0.298)
Step: 80799, Reward: -1605.4138 [36.39], Avg: -1311.7780 (0.297)
Step: 80999, Reward: -1416.6040 [291.27], Avg: -1312.7560 (0.296)
Step: 81199, Reward: -1403.5805 [218.72], Avg: -1313.5184 (0.295)
Step: 81399, Reward: -1447.9220 [238.15], Avg: -1314.4338 (0.294)
Step: 81599, Reward: -1352.1436 [274.95], Avg: -1315.2001 (0.294)
Step: 81799, Reward: -1290.2643 [295.41], Avg: -1315.8614 (0.293)
Step: 81999, Reward: -1507.7130 [263.11], Avg: -1316.9711 (0.292)
Step: 82199, Reward: -1399.3964 [296.89], Avg: -1317.8940 (0.291)
Step: 82399, Reward: -1481.9107 [228.26], Avg: -1318.8461 (0.290)
Step: 82599, Reward: -1466.4771 [247.42], Avg: -1319.8026 (0.289)
Step: 82799, Reward: -1117.1906 [270.99], Avg: -1319.9678 (0.288)
Step: 82999, Reward: -1430.0311 [250.86], Avg: -1320.8375 (0.287)
Step: 83199, Reward: -1483.2441 [261.67], Avg: -1321.8569 (0.287)
Step: 83399, Reward: -1607.2708 [33.67], Avg: -1322.6221 (0.286)
Step: 83599, Reward: -1481.5011 [230.61], Avg: -1323.5539 (0.285)
Step: 83799, Reward: -1410.7119 [294.69], Avg: -1324.4652 (0.284)
Step: 83999, Reward: -1440.5788 [230.88], Avg: -1325.2914 (0.283)
Step: 84199, Reward: -1341.1017 [311.46], Avg: -1326.0688 (0.282)
Step: 84399, Reward: -1348.3384 [271.40], Avg: -1326.7647 (0.281)
Step: 84599, Reward: -1499.2957 [233.15], Avg: -1327.7237 (0.281)
Step: 84799, Reward: -1238.5941 [220.44], Avg: -1328.0334 (0.280)
Step: 84999, Reward: -1385.5246 [270.99], Avg: -1328.8063 (0.279)
Step: 85199, Reward: -1503.9286 [274.22], Avg: -1329.8611 (0.278)
Step: 85399, Reward: -1388.2121 [299.59], Avg: -1330.6994 (0.277)
Step: 85599, Reward: -1620.7298 [45.41], Avg: -1331.4831 (0.276)
Step: 85799, Reward: -1337.5508 [339.45], Avg: -1332.2885 (0.276)
Step: 85999, Reward: -1310.3216 [337.93], Avg: -1333.0233 (0.275)
Step: 86199, Reward: -1512.6577 [244.99], Avg: -1334.0085 (0.274)
Step: 86399, Reward: -1263.4219 [301.21], Avg: -1334.5424 (0.273)
Step: 86599, Reward: -1092.9855 [215.91], Avg: -1334.4831 (0.272)
Step: 86799, Reward: -1439.7021 [237.34], Avg: -1335.2724 (0.271)
Step: 86999, Reward: -1328.1494 [329.93], Avg: -1336.0145 (0.271)
Step: 87199, Reward: -1090.1671 [270.06], Avg: -1336.0701 (0.270)
Step: 87399, Reward: -1517.1626 [257.06], Avg: -1337.0727 (0.269)
Step: 87599, Reward: -1298.4376 [255.08], Avg: -1337.5669 (0.268)
Step: 87799, Reward: -1472.6985 [230.80], Avg: -1338.4004 (0.267)
Step: 87999, Reward: -1485.7633 [226.68], Avg: -1339.2505 (0.267)
Step: 88199, Reward: -1474.7706 [237.86], Avg: -1340.0972 (0.266)
Step: 88399, Reward: -1346.1220 [315.92], Avg: -1340.8256 (0.265)
Step: 88599, Reward: -1370.9288 [279.96], Avg: -1341.5255 (0.264)
Step: 88799, Reward: -1459.4534 [243.33], Avg: -1342.3391 (0.263)
Step: 88999, Reward: -1472.0575 [227.88], Avg: -1343.1427 (0.263)
Step: 89199, Reward: -1476.6840 [234.99], Avg: -1343.9690 (0.262)
Step: 89399, Reward: -1353.5009 [264.11], Avg: -1344.5812 (0.261)
Step: 89599, Reward: -1455.6813 [276.58], Avg: -1345.4465 (0.260)
Step: 89799, Reward: -1254.5385 [288.97], Avg: -1345.8877 (0.259)
Step: 89999, Reward: -1117.7161 [268.17], Avg: -1345.9765 (0.259)
Step: 90199, Reward: -1601.6898 [54.43], Avg: -1346.6642 (0.258)
Step: 90399, Reward: -1359.6536 [328.31], Avg: -1347.4193 (0.257)
Step: 90599, Reward: -1358.7997 [280.84], Avg: -1348.0644 (0.256)
Step: 90799, Reward: -1243.7394 [324.55], Avg: -1348.5494 (0.256)
Step: 90999, Reward: -1391.8474 [281.50], Avg: -1349.2633 (0.255)
Step: 91199, Reward: -1348.3817 [303.66], Avg: -1349.9273 (0.254)
Step: 91399, Reward: -1576.3798 [96.39], Avg: -1350.6337 (0.253)
Step: 91599, Reward: -1493.5911 [254.78], Avg: -1351.5021 (0.253)
Step: 91799, Reward: -1291.9159 [315.27], Avg: -1352.0592 (0.252)
Step: 91999, Reward: -1242.9734 [301.01], Avg: -1352.4764 (0.251)
Step: 92199, Reward: -1503.6878 [241.41], Avg: -1353.3280 (0.250)
Step: 92399, Reward: -1052.6825 [279.56], Avg: -1353.2824 (0.250)
Step: 92599, Reward: -1359.6452 [332.64], Avg: -1354.0146 (0.249)
Step: 92799, Reward: -1330.1417 [342.83], Avg: -1354.7020 (0.248)
Step: 92999, Reward: -1356.3851 [323.87], Avg: -1355.4021 (0.247)
Step: 93199, Reward: -1616.7386 [28.33], Avg: -1356.0237 (0.247)
Step: 93399, Reward: -1233.9131 [335.56], Avg: -1356.4808 (0.246)
Step: 93599, Reward: -1391.1218 [302.04], Avg: -1357.2002 (0.245)
Step: 93799, Reward: -1379.7099 [298.53], Avg: -1357.8847 (0.244)
Step: 93999, Reward: -1314.4117 [345.67], Avg: -1358.5277 (0.244)
Step: 94199, Reward: -1274.1482 [312.84], Avg: -1359.0128 (0.243)
Step: 94399, Reward: -1425.4175 [361.94], Avg: -1359.9203 (0.242)
Step: 94599, Reward: -1205.9384 [324.47], Avg: -1360.2807 (0.241)
Step: 94799, Reward: -1321.1504 [385.71], Avg: -1361.0119 (0.241)
Step: 94999, Reward: -1342.0780 [301.40], Avg: -1361.6066 (0.240)
Step: 95199, Reward: -1455.6109 [307.95], Avg: -1362.4510 (0.239)
Step: 95399, Reward: -1461.8789 [348.04], Avg: -1363.3891 (0.239)
Step: 95599, Reward: -1622.0792 [49.13], Avg: -1364.0331 (0.238)
Step: 95799, Reward: -1333.6019 [306.71], Avg: -1364.6098 (0.237)
Step: 95999, Reward: -1560.7332 [173.43], Avg: -1365.3797 (0.236)
Step: 96199, Reward: -1037.1832 [294.63], Avg: -1365.3099 (0.236)
Step: 96399, Reward: -1289.7682 [279.77], Avg: -1365.7337 (0.235)
Step: 96599, Reward: -1133.1854 [350.73], Avg: -1365.9783 (0.234)
Step: 96799, Reward: -1447.4473 [342.83], Avg: -1366.8550 (0.234)
Step: 96999, Reward: -1298.7159 [355.92], Avg: -1367.4484 (0.233)
Step: 97199, Reward: -1331.8922 [360.24], Avg: -1368.1164 (0.232)
Step: 97399, Reward: -1616.3110 [34.95], Avg: -1368.6978 (0.231)
Step: 97599, Reward: -1437.9975 [304.07], Avg: -1369.4629 (0.231)
Step: 97799, Reward: -1162.9569 [347.88], Avg: -1369.7520 (0.230)
Step: 97999, Reward: -1178.1464 [329.34], Avg: -1370.0331 (0.229)
Step: 98199, Reward: -1365.7839 [334.56], Avg: -1370.7059 (0.229)
Step: 98399, Reward: -1334.2486 [313.81], Avg: -1371.2696 (0.228)
Step: 98599, Reward: -1363.5575 [337.48], Avg: -1371.9385 (0.227)
Step: 98799, Reward: -1234.0739 [326.22], Avg: -1372.3198 (0.227)
Step: 98999, Reward: -1341.6384 [362.34], Avg: -1372.9898 (0.226)
Step: 99199, Reward: -1491.2898 [306.04], Avg: -1373.8453 (0.225)
Step: 99399, Reward: -1268.1132 [300.97], Avg: -1374.2382 (0.225)
Step: 99599, Reward: -1443.8234 [280.92], Avg: -1374.9420 (0.224)
Step: 99799, Reward: -1440.2892 [226.17], Avg: -1375.5262 (0.223)
Step: 99999, Reward: -1327.0400 [319.18], Avg: -1376.0676 (0.223)
