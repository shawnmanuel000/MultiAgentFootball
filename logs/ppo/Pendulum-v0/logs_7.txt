Model: <class 'models.ppo.PPOAgent'>, Dir: Pendulum-v0
num_envs: 16,

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

EPS_MIN = 0.1                	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.997             	# The rate at which eps decays from EPS_MAX to EPS_MIN
BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.05				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) * critic_error.pow(2) * scale
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss.mean())
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		update_freq = int(self.update_freq * (1 - self.eps + EPS_MIN)**2)
		if done[0]:#len(self.buffer) >= update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, scale=16*dones.size(0)/len(self.replay_buffer))
		if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddqn", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "LunarLander-v2"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[3]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class PixelAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	logger = Logger(model, env_name, num_envs=num_envs)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = PixelAgent(envs.state_size, envs.action_size, num_envs, model)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0]:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 199, Reward: -1425.1266 [155.43], Avg: -1580.5603 (0.997)
Step: 399, Reward: -1364.8937 [275.37], Avg: -1610.4103 (0.994)
Step: 599, Reward: -1348.9748 [308.02], Avg: -1625.9372 (0.991)
Step: 799, Reward: -1183.9083 [197.56], Avg: -1564.8209 (0.988)
Step: 999, Reward: -1204.0269 [201.96], Avg: -1533.0537 (0.985)
Step: 1199, Reward: -1286.4643 [223.78], Avg: -1529.2522 (0.982)
Step: 1399, Reward: -1284.9230 [272.94], Avg: -1533.3401 (0.979)
Step: 1599, Reward: -1436.7500 [167.83], Avg: -1542.2451 (0.976)
Step: 1799, Reward: -1413.0690 [192.68], Avg: -1549.3015 (0.973)
Step: 1999, Reward: -1210.0787 [127.11], Avg: -1528.0898 (0.970)
Step: 2199, Reward: -1113.3880 [180.47], Avg: -1506.7957 (0.967)
Step: 2399, Reward: -1168.3009 [186.45], Avg: -1494.1253 (0.965)
Step: 2599, Reward: -1174.7942 [206.28], Avg: -1485.4289 (0.962)
Step: 2799, Reward: -1328.1045 [216.02], Avg: -1489.6217 (0.959)
Step: 2999, Reward: -1055.5600 [134.14], Avg: -1469.6271 (0.956)
Step: 3199, Reward: -1388.8768 [208.30], Avg: -1477.5989 (0.953)
Step: 3399, Reward: -1139.6829 [252.41], Avg: -1472.5690 (0.950)
Step: 3599, Reward: -1248.0316 [197.66], Avg: -1471.0759 (0.947)
Step: 3799, Reward: -1157.9615 [224.83], Avg: -1466.4292 (0.945)
Step: 3999, Reward: -1001.1949 [191.13], Avg: -1452.7241 (0.942)
Step: 4199, Reward: -1080.6051 [229.00], Avg: -1445.9090 (0.939)
Step: 4399, Reward: -1160.9109 [203.90], Avg: -1442.2228 (0.936)
Step: 4599, Reward: -1286.0217 [212.35], Avg: -1444.6639 (0.933)
Step: 4799, Reward: -1103.4275 [279.20], Avg: -1442.0790 (0.930)
Step: 4999, Reward: -1248.7910 [285.53], Avg: -1445.7686 (0.928)
Step: 5199, Reward: -1011.2692 [98.82], Avg: -1432.8577 (0.925)
Step: 5399, Reward: -1036.4947 [89.65], Avg: -1421.4981 (0.922)
Step: 5599, Reward: -1033.5986 [71.71], Avg: -1410.2056 (0.919)
Step: 5799, Reward: -1085.1056 [103.66], Avg: -1402.5698 (0.917)
Step: 5999, Reward: -1081.3578 [93.09], Avg: -1394.9658 (0.914)
Step: 6199, Reward: -1049.7144 [20.51], Avg: -1384.4903 (0.911)
Step: 6399, Reward: -1197.0961 [76.66], Avg: -1381.0299 (0.908)
Step: 6599, Reward: -1047.3982 [92.53], Avg: -1373.7238 (0.906)
Step: 6799, Reward: -1020.2544 [117.42], Avg: -1366.7813 (0.903)
Step: 6999, Reward: -999.9143 [48.03], Avg: -1357.6717 (0.900)
Step: 7199, Reward: -1187.3151 [109.76], Avg: -1355.9885 (0.897)
Step: 7399, Reward: -1147.9386 [72.79], Avg: -1352.3329 (0.895)
Step: 7599, Reward: -1053.6294 [41.03], Avg: -1345.5519 (0.892)
Step: 7799, Reward: -1058.7073 [55.34], Avg: -1339.6160 (0.889)
Step: 7999, Reward: -1075.6983 [43.04], Avg: -1334.0941 (0.887)
Step: 8199, Reward: -1055.7158 [40.80], Avg: -1328.2993 (0.884)
Step: 8399, Reward: -1040.5520 [141.77], Avg: -1324.8238 (0.881)
Step: 8599, Reward: -1083.4607 [72.01], Avg: -1320.8852 (0.879)
Step: 8799, Reward: -1034.3602 [21.08], Avg: -1314.8524 (0.876)
Step: 8999, Reward: -971.3441 [45.43], Avg: -1308.2284 (0.874)
Step: 9199, Reward: -975.5880 [65.35], Avg: -1302.4177 (0.871)
Step: 9399, Reward: -973.7016 [23.80], Avg: -1295.9301 (0.868)
Step: 9599, Reward: -964.6279 [37.48], Avg: -1289.8088 (0.866)
Step: 9799, Reward: -982.3356 [54.26], Avg: -1284.6412 (0.863)
Step: 9999, Reward: -890.7750 [142.63], Avg: -1279.6165 (0.861)
Step: 10199, Reward: -970.6291 [85.85], Avg: -1275.2413 (0.858)
Step: 10399, Reward: -1039.3140 [40.41], Avg: -1271.4813 (0.855)
Step: 10599, Reward: -977.3707 [97.36], Avg: -1267.7691 (0.853)
Step: 10799, Reward: -914.8797 [65.39], Avg: -1262.4451 (0.850)
Step: 10999, Reward: -977.9925 [38.47], Avg: -1257.9727 (0.848)
Step: 11199, Reward: -924.3478 [46.10], Avg: -1252.8384 (0.845)
Step: 11399, Reward: -998.5301 [32.17], Avg: -1248.9412 (0.843)
Step: 11599, Reward: -925.0251 [74.96], Avg: -1244.6488 (0.840)
Step: 11799, Reward: -887.6222 [153.53], Avg: -1241.1998 (0.838)
Step: 11999, Reward: -864.4408 [78.75], Avg: -1236.2329 (0.835)
Step: 12199, Reward: -939.3144 [102.90], Avg: -1233.0523 (0.833)
Step: 12399, Reward: -1013.7955 [67.23], Avg: -1230.6002 (0.830)
Step: 12599, Reward: -1000.8104 [48.50], Avg: -1227.7225 (0.828)
Step: 12799, Reward: -957.5629 [71.55], Avg: -1224.6192 (0.825)
Step: 12999, Reward: -921.4814 [66.01], Avg: -1220.9710 (0.823)
Step: 13199, Reward: -997.4878 [69.78], Avg: -1218.6422 (0.820)
Step: 13399, Reward: -915.0210 [133.31], Avg: -1216.1002 (0.818)
Step: 13599, Reward: -918.6358 [46.55], Avg: -1212.4103 (0.815)
Step: 13799, Reward: -888.3754 [88.82], Avg: -1209.0014 (0.813)
Step: 13999, Reward: -844.6811 [54.00], Avg: -1204.5683 (0.810)
Step: 14199, Reward: -916.6434 [84.10], Avg: -1201.6976 (0.808)
Step: 14399, Reward: -944.4578 [79.12], Avg: -1199.2237 (0.805)
Step: 14599, Reward: -867.6330 [7.93], Avg: -1194.7900 (0.803)
Step: 14799, Reward: -899.7239 [52.71], Avg: -1191.5150 (0.801)
Step: 14999, Reward: -819.2795 [68.37], Avg: -1187.4635 (0.798)
Step: 15199, Reward: -933.1214 [57.72], Avg: -1184.8764 (0.796)
Step: 15399, Reward: -834.2124 [85.72], Avg: -1181.4356 (0.793)
Step: 15599, Reward: -833.9854 [47.63], Avg: -1177.5917 (0.791)
Step: 15799, Reward: -887.2873 [34.98], Avg: -1174.3598 (0.789)
Step: 15999, Reward: -850.3334 [77.24], Avg: -1171.2749 (0.786)
Step: 16199, Reward: -880.4786 [82.72], Avg: -1168.7061 (0.784)
Step: 16399, Reward: -849.7438 [52.81], Avg: -1165.4603 (0.782)
Step: 16599, Reward: -855.7813 [98.18], Avg: -1162.9122 (0.779)
Step: 16799, Reward: -811.7815 [50.93], Avg: -1159.3383 (0.777)
Step: 16999, Reward: -854.2888 [73.08], Avg: -1156.6093 (0.775)
Step: 17199, Reward: -804.8226 [46.39], Avg: -1153.0582 (0.772)
Step: 17399, Reward: -838.7335 [82.17], Avg: -1150.3897 (0.770)
Step: 17599, Reward: -840.8233 [59.96], Avg: -1147.5533 (0.768)
Step: 17799, Reward: -787.9687 [61.35], Avg: -1144.2024 (0.765)
Step: 17999, Reward: -788.4177 [107.58], Avg: -1141.4445 (0.763)
Step: 18199, Reward: -849.7003 [103.33], Avg: -1139.3740 (0.761)
Step: 18399, Reward: -798.6872 [108.69], Avg: -1136.8523 (0.758)
Step: 18599, Reward: -733.8666 [100.60], Avg: -1133.6008 (0.756)
Step: 18799, Reward: -724.1363 [49.82], Avg: -1129.7748 (0.754)
Step: 18999, Reward: -780.2269 [93.85], Avg: -1127.0833 (0.752)
Step: 19199, Reward: -764.6707 [103.66], Avg: -1124.3879 (0.749)
Step: 19399, Reward: -779.9898 [36.00], Avg: -1121.2085 (0.747)
Step: 19599, Reward: -820.9254 [53.70], Avg: -1118.6924 (0.745)
Step: 19799, Reward: -785.1874 [143.63], Avg: -1116.7744 (0.743)
Step: 19999, Reward: -773.0958 [88.26], Avg: -1114.2203 (0.740)
Step: 20199, Reward: -787.9990 [60.22], Avg: -1111.5866 (0.738)
Step: 20399, Reward: -727.3988 [116.80], Avg: -1108.9652 (0.736)
Step: 20599, Reward: -771.9497 [88.84], Avg: -1106.5557 (0.734)
Step: 20799, Reward: -817.9566 [64.67], Avg: -1104.4025 (0.732)
Step: 20999, Reward: -832.8131 [77.22], Avg: -1102.5513 (0.729)
Step: 21199, Reward: -724.4220 [53.00], Avg: -1099.4841 (0.727)
Step: 21399, Reward: -745.2365 [58.07], Avg: -1096.7161 (0.725)
Step: 21599, Reward: -835.4343 [109.27], Avg: -1095.3086 (0.723)
Step: 21799, Reward: -773.5226 [119.24], Avg: -1093.4504 (0.721)
Step: 21999, Reward: -850.1801 [89.75], Avg: -1092.0548 (0.719)
Step: 22199, Reward: -736.5457 [127.50], Avg: -1090.0007 (0.716)
Step: 22399, Reward: -689.5426 [141.02], Avg: -1087.6842 (0.714)
Step: 22599, Reward: -718.2262 [82.66], Avg: -1085.1462 (0.712)
Step: 22799, Reward: -813.3792 [90.94], Avg: -1083.5600 (0.710)
Step: 22999, Reward: -705.3471 [51.25], Avg: -1080.7168 (0.708)
Step: 23199, Reward: -701.6186 [185.21], Avg: -1079.0453 (0.706)
Step: 23399, Reward: -713.9707 [94.43], Avg: -1076.7321 (0.704)
Step: 23599, Reward: -809.7611 [84.98], Avg: -1075.1898 (0.702)
Step: 23799, Reward: -728.2018 [145.32], Avg: -1073.4952 (0.699)
Step: 23999, Reward: -776.9480 [131.22], Avg: -1072.1175 (0.697)
Step: 24199, Reward: -834.7891 [105.16], Avg: -1071.0252 (0.695)
Step: 24399, Reward: -747.0162 [75.99], Avg: -1068.9922 (0.693)
Step: 24599, Reward: -713.9916 [134.26], Avg: -1067.1976 (0.691)
Step: 24799, Reward: -691.6132 [133.10], Avg: -1065.2420 (0.689)
Step: 24999, Reward: -700.4494 [101.62], Avg: -1063.1366 (0.687)
Step: 25199, Reward: -687.5368 [153.28], Avg: -1061.3722 (0.685)
Step: 25399, Reward: -676.5823 [124.52], Avg: -1059.3228 (0.683)
Step: 25599, Reward: -647.7746 [106.59], Avg: -1056.9403 (0.681)
Step: 25799, Reward: -602.6534 [135.39], Avg: -1054.4682 (0.679)
Step: 25999, Reward: -546.0393 [119.00], Avg: -1051.4727 (0.677)
Step: 26199, Reward: -789.9779 [123.20], Avg: -1050.4170 (0.675)
Step: 26399, Reward: -511.0870 [137.17], Avg: -1047.3703 (0.673)
Step: 26599, Reward: -566.8751 [141.19], Avg: -1044.8191 (0.671)
Step: 26799, Reward: -317.3573 [166.07], Avg: -1040.6296 (0.669)
Step: 26999, Reward: -452.6741 [222.13], Avg: -1037.9198 (0.667)
Step: 27199, Reward: -356.8179 [167.30], Avg: -1034.1418 (0.665)
Step: 27399, Reward: -319.5832 [164.30], Avg: -1030.1253 (0.663)
Step: 27599, Reward: -174.9177 [104.71], Avg: -1024.6870 (0.661)
Step: 27799, Reward: -227.3673 [95.17], Avg: -1019.6355 (0.659)
Step: 27999, Reward: -306.9850 [137.10], Avg: -1015.5244 (0.657)
Step: 28199, Reward: -269.9882 [116.84], Avg: -1011.0656 (0.655)
Step: 28399, Reward: -249.2777 [159.54], Avg: -1006.8244 (0.653)
Step: 28599, Reward: -228.6917 [105.03], Avg: -1002.1174 (0.651)
Step: 28799, Reward: -122.8217 [2.97], Avg: -996.0318 (0.649)
Step: 28999, Reward: -195.3916 [95.19], Avg: -991.1667 (0.647)
Step: 29199, Reward: -217.4384 [113.25], Avg: -986.6429 (0.645)
Step: 29399, Reward: -169.2575 [95.08], Avg: -981.7292 (0.643)
Step: 29599, Reward: -226.5743 [108.03], Avg: -977.3568 (0.641)
Step: 29799, Reward: -241.4763 [108.96], Avg: -973.1492 (0.639)
Step: 29999, Reward: -200.9468 [64.41], Avg: -968.4306 (0.637)
Step: 30199, Reward: -121.1422 [3.62], Avg: -962.8434 (0.635)
Step: 30399, Reward: -196.2146 [98.70], Avg: -958.4491 (0.633)
Step: 30599, Reward: -168.7372 [121.05], Avg: -954.0788 (0.631)
Step: 30799, Reward: -145.2395 [47.96], Avg: -949.1380 (0.630)
Step: 30999, Reward: -165.3207 [116.45], Avg: -944.8325 (0.628)
Step: 31199, Reward: -222.3722 [96.77], Avg: -940.8216 (0.626)
Step: 31399, Reward: -194.5601 [96.86], Avg: -936.6853 (0.624)
Step: 31599, Reward: -124.9686 [1.64], Avg: -931.5582 (0.622)
Step: 31799, Reward: -95.2963 [85.72], Avg: -926.8379 (0.620)
Step: 31999, Reward: -99.4862 [49.03], Avg: -921.9734 (0.618)
Step: 32199, Reward: -143.8162 [86.77], Avg: -917.6791 (0.616)
Step: 32399, Reward: -98.6130 [48.88], Avg: -912.9248 (0.615)
Step: 32599, Reward: -144.6188 [48.62], Avg: -908.5096 (0.613)
Step: 32799, Reward: -163.7706 [92.80], Avg: -904.5344 (0.611)
Step: 32999, Reward: -121.1795 [75.44], Avg: -900.2440 (0.609)
Step: 33199, Reward: -182.6347 [128.74], Avg: -896.6965 (0.607)
Step: 33399, Reward: -73.9181 [96.87], Avg: -892.3498 (0.605)
Step: 33599, Reward: -190.4009 [59.60], Avg: -888.5263 (0.604)
Step: 33799, Reward: -146.8210 [48.67], Avg: -884.4255 (0.602)
Step: 33999, Reward: -235.8967 [100.52], Avg: -881.2019 (0.600)
Step: 34199, Reward: -190.8771 [89.25], Avg: -877.6868 (0.598)
Step: 34399, Reward: -187.9922 [95.08], Avg: -874.2298 (0.596)
Step: 34599, Reward: -124.4445 [76.48], Avg: -870.3378 (0.595)
Step: 34799, Reward: -143.8217 [45.98], Avg: -866.4267 (0.593)
Step: 34999, Reward: -96.8847 [47.99], Avg: -862.3036 (0.591)
Step: 35199, Reward: -142.2463 [84.64], Avg: -858.6932 (0.589)
Step: 35399, Reward: -200.3426 [57.96], Avg: -855.3012 (0.588)
Step: 35599, Reward: -198.7745 [64.58], Avg: -851.9757 (0.586)
Step: 35799, Reward: -275.8624 [92.96], Avg: -849.2765 (0.584)
Step: 35999, Reward: -208.8199 [170.81], Avg: -846.6673 (0.582)
Step: 36199, Reward: -244.9548 [168.05], Avg: -844.2714 (0.581)
Step: 36399, Reward: -171.6997 [55.73], Avg: -840.8822 (0.579)
Step: 36599, Reward: -78.6025 [58.40], Avg: -837.0358 (0.577)
Step: 36799, Reward: -125.8873 [74.31], Avg: -833.5747 (0.575)
Step: 36999, Reward: -126.3529 [72.41], Avg: -830.1433 (0.574)
Step: 37199, Reward: -149.4628 [116.43], Avg: -827.1097 (0.572)
Step: 37399, Reward: -171.5669 [55.25], Avg: -823.8996 (0.570)
Step: 37599, Reward: -149.6343 [42.99], Avg: -820.5417 (0.568)
Step: 37799, Reward: -148.5052 [88.82], Avg: -817.4560 (0.567)
Step: 37999, Reward: -205.8194 [116.03], Avg: -814.8475 (0.565)
Step: 38199, Reward: -204.3939 [122.39], Avg: -812.2922 (0.563)
Step: 38399, Reward: -101.6061 [48.30], Avg: -808.8423 (0.562)
Step: 38599, Reward: -215.0441 [85.66], Avg: -806.2095 (0.560)
Step: 38799, Reward: -243.1004 [104.04], Avg: -803.8431 (0.558)
Step: 38999, Reward: -152.0946 [48.90], Avg: -800.7516 (0.557)
Step: 39199, Reward: -148.8637 [48.95], Avg: -797.6754 (0.555)
Step: 39399, Reward: -148.2582 [116.91], Avg: -794.9723 (0.553)
Step: 39599, Reward: -175.6382 [61.35], Avg: -792.1542 (0.552)
Step: 39799, Reward: -188.4775 [112.62], Avg: -789.6866 (0.550)
Step: 39999, Reward: -76.0395 [56.41], Avg: -786.4004 (0.548)
Step: 40199, Reward: -212.8068 [81.04], Avg: -783.9499 (0.547)
Step: 40399, Reward: -231.8691 [123.40], Avg: -781.8277 (0.545)
Step: 40599, Reward: -98.1105 [47.86], Avg: -778.6954 (0.543)
Step: 40799, Reward: -209.8330 [80.72], Avg: -776.3025 (0.542)
Step: 40999, Reward: -218.7290 [91.85], Avg: -774.0306 (0.540)
Step: 41199, Reward: -118.2480 [144.90], Avg: -771.5507 (0.539)
Step: 41399, Reward: -150.0397 [48.95], Avg: -768.7847 (0.537)
Step: 41599, Reward: -143.9136 [43.78], Avg: -765.9910 (0.535)
Step: 41799, Reward: -121.4626 [74.67], Avg: -763.2644 (0.534)
Step: 41999, Reward: -149.8839 [57.92], Avg: -760.6194 (0.532)
Step: 42199, Reward: -197.3905 [59.25], Avg: -758.2308 (0.530)
Step: 42399, Reward: -145.2169 [43.66], Avg: -755.5452 (0.529)
Step: 42599, Reward: -76.9896 [59.34], Avg: -752.6381 (0.527)
Step: 42799, Reward: -154.0516 [125.24], Avg: -750.4261 (0.526)
Step: 42999, Reward: -101.3160 [49.27], Avg: -747.6362 (0.524)
Step: 43199, Reward: -196.1798 [58.09], Avg: -745.3521 (0.523)
Step: 43399, Reward: -125.4272 [1.72], Avg: -742.5032 (0.521)
Step: 43599, Reward: -170.5037 [56.55], Avg: -740.1388 (0.519)
Step: 43799, Reward: -170.4193 [50.59], Avg: -737.7684 (0.518)
Step: 43999, Reward: -352.2944 [352.15], Avg: -737.6169 (0.516)
Step: 44199, Reward: -168.9159 [120.17], Avg: -735.5874 (0.515)
Step: 44399, Reward: -922.2928 [699.46], Avg: -739.5791 (0.513)
Step: 44599, Reward: -225.4463 [96.50], Avg: -737.7063 (0.512)
Step: 44799, Reward: -251.2061 [138.73], Avg: -736.1537 (0.510)
Step: 44999, Reward: -172.4466 [97.26], Avg: -734.0806 (0.509)
Step: 45199, Reward: -122.6571 [3.85], Avg: -731.3922 (0.507)
Step: 45399, Reward: -123.1520 [76.66], Avg: -729.0505 (0.506)
Step: 45599, Reward: -150.2696 [47.19], Avg: -726.7190 (0.504)
Step: 45799, Reward: -308.1832 [114.13], Avg: -725.3897 (0.503)
Step: 45999, Reward: -236.6755 [123.94], Avg: -723.8037 (0.501)
Step: 46199, Reward: -147.0477 [92.52], Avg: -721.7074 (0.500)
Step: 46399, Reward: -220.9090 [181.84], Avg: -720.3326 (0.498)
Step: 46599, Reward: -195.1145 [92.46], Avg: -718.4753 (0.497)
Step: 46799, Reward: -170.8691 [95.98], Avg: -716.5452 (0.495)
Step: 46999, Reward: -167.1760 [118.07], Avg: -714.7099 (0.494)
Step: 47199, Reward: -195.5365 [60.91], Avg: -712.7681 (0.492)
Step: 47399, Reward: -179.7680 [195.40], Avg: -711.3436 (0.491)
Step: 47599, Reward: -149.1563 [92.32], Avg: -709.3694 (0.489)
Step: 47799, Reward: -195.9793 [126.03], Avg: -707.7487 (0.488)
Step: 47999, Reward: -200.6318 [126.33], Avg: -706.1621 (0.486)
Step: 48199, Reward: -173.1858 [96.93], Avg: -704.3527 (0.485)
Step: 48399, Reward: -120.6733 [128.61], Avg: -702.4723 (0.483)
Step: 48599, Reward: -170.4849 [121.29], Avg: -700.7822 (0.482)
Step: 48799, Reward: -100.1106 [48.61], Avg: -698.5196 (0.480)
Step: 48999, Reward: -73.8580 [59.57], Avg: -696.2131 (0.479)
Step: 49199, Reward: -153.0907 [127.32], Avg: -694.5229 (0.478)
Step: 49399, Reward: -147.6675 [141.88], Avg: -692.8833 (0.476)
Step: 49599, Reward: -97.2877 [47.84], Avg: -690.6746 (0.475)
Step: 49799, Reward: -211.9500 [177.62], Avg: -689.4654 (0.473)
Step: 49999, Reward: -144.4556 [45.22], Avg: -687.4662 (0.472)
Step: 50199, Reward: -245.3452 [201.39], Avg: -686.5071 (0.470)
Step: 50399, Reward: -150.2688 [49.25], Avg: -684.5746 (0.469)
Step: 50599, Reward: -234.9505 [96.44], Avg: -683.1786 (0.468)
Step: 50799, Reward: -171.5698 [59.74], Avg: -681.3996 (0.466)
Step: 50999, Reward: -97.1582 [47.73], Avg: -679.2957 (0.465)
Step: 51199, Reward: -100.6187 [48.96], Avg: -677.2265 (0.463)
Step: 51399, Reward: -246.8385 [138.41], Avg: -676.0904 (0.462)
Step: 51599, Reward: -147.4639 [51.30], Avg: -674.2403 (0.461)
Step: 51799, Reward: -172.8337 [98.96], Avg: -672.6864 (0.459)
Step: 51999, Reward: -99.1662 [48.75], Avg: -670.6681 (0.458)
Step: 52199, Reward: -174.3436 [127.47], Avg: -669.2549 (0.456)
Step: 52399, Reward: -168.5352 [62.72], Avg: -667.5831 (0.455)
Step: 52599, Reward: -177.3973 [131.55], Avg: -666.2195 (0.454)
Step: 52799, Reward: -175.9948 [101.70], Avg: -664.7478 (0.452)
Step: 52999, Reward: -98.9955 [49.20], Avg: -662.7986 (0.451)
Step: 53199, Reward: -99.3785 [94.86], Avg: -661.0371 (0.450)
Step: 53399, Reward: -143.6780 [89.42], Avg: -659.4343 (0.448)
Step: 53599, Reward: -149.4055 [52.41], Avg: -657.7268 (0.447)
Step: 53799, Reward: -175.8424 [66.81], Avg: -656.1837 (0.446)
Step: 53999, Reward: -148.7376 [43.65], Avg: -654.4660 (0.444)
Step: 54199, Reward: -147.9810 [54.22], Avg: -652.7971 (0.443)
Step: 54399, Reward: -144.9922 [89.23], Avg: -651.2582 (0.442)
Step: 54599, Reward: -173.1539 [59.75], Avg: -649.7258 (0.440)
Step: 54799, Reward: -255.9949 [125.34], Avg: -648.7463 (0.439)
Step: 54999, Reward: -123.7695 [78.49], Avg: -647.1226 (0.438)
Step: 55199, Reward: -191.5650 [58.72], Avg: -645.6848 (0.436)
Step: 55399, Reward: -147.3849 [56.86], Avg: -644.0912 (0.435)
Step: 55599, Reward: -50.9201 [58.35], Avg: -642.1674 (0.434)
Step: 55799, Reward: -170.5699 [59.81], Avg: -640.6914 (0.432)
Step: 55999, Reward: -173.8087 [60.68], Avg: -639.2407 (0.431)
Step: 56199, Reward: -97.4250 [47.97], Avg: -637.4832 (0.430)
Step: 56399, Reward: -121.6217 [1.56], Avg: -635.6595 (0.429)
Step: 56599, Reward: -141.8610 [42.08], Avg: -634.0633 (0.427)
Step: 56799, Reward: -100.3658 [48.77], Avg: -632.3558 (0.426)
Step: 56999, Reward: -170.8621 [121.57], Avg: -631.1631 (0.425)
Step: 57199, Reward: -121.8537 [3.01], Avg: -629.3928 (0.423)
Step: 57399, Reward: -122.5803 [76.93], Avg: -627.8949 (0.422)
Step: 57599, Reward: -145.4411 [117.84], Avg: -626.6289 (0.421)
Step: 57799, Reward: -121.9167 [76.19], Avg: -625.1461 (0.420)
Step: 57999, Reward: -97.0013 [87.78], Avg: -623.6276 (0.418)
Step: 58199, Reward: -218.6814 [50.86], Avg: -622.4108 (0.417)
Step: 58399, Reward: -171.3040 [56.82], Avg: -621.0606 (0.416)
Step: 58599, Reward: -122.3999 [75.37], Avg: -619.6159 (0.415)
Step: 58799, Reward: -166.9814 [56.08], Avg: -618.2671 (0.413)
Step: 58999, Reward: -260.2535 [87.02], Avg: -617.3484 (0.412)
Step: 59199, Reward: -146.9707 [88.68], Avg: -616.0589 (0.411)
Step: 59399, Reward: -185.4204 [129.80], Avg: -615.0460 (0.410)
Step: 59599, Reward: -217.4711 [45.86], Avg: -613.8657 (0.408)
Step: 59799, Reward: -124.4348 [78.02], Avg: -612.4898 (0.407)
Step: 59999, Reward: -120.3322 [74.81], Avg: -611.0986 (0.406)
Step: 60199, Reward: -169.6343 [56.07], Avg: -609.8182 (0.405)
Step: 60399, Reward: -142.5575 [88.25], Avg: -608.5632 (0.404)
Step: 60599, Reward: -146.6067 [49.50], Avg: -607.2020 (0.402)
Step: 60799, Reward: -190.0197 [60.96], Avg: -606.0302 (0.401)
Step: 60999, Reward: -97.5643 [90.61], Avg: -604.6602 (0.400)
Step: 61199, Reward: -121.2477 [131.97], Avg: -603.5117 (0.399)
Step: 61399, Reward: -146.7547 [49.89], Avg: -602.1864 (0.398)
Step: 61599, Reward: -198.6530 [65.46], Avg: -601.0887 (0.396)
Step: 61799, Reward: -118.5083 [71.48], Avg: -599.7583 (0.395)
Step: 61999, Reward: -121.3610 [76.12], Avg: -598.4607 (0.394)
Step: 62199, Reward: -123.1263 [2.16], Avg: -596.9392 (0.393)
Step: 62399, Reward: -185.3323 [79.15], Avg: -595.8736 (0.392)
Step: 62599, Reward: -121.2582 [75.03], Avg: -594.5970 (0.390)
Step: 62799, Reward: -169.9084 [61.36], Avg: -593.4399 (0.389)
Step: 62999, Reward: -96.7384 [48.07], Avg: -592.0157 (0.388)
Step: 63199, Reward: -98.7616 [48.96], Avg: -590.6097 (0.387)
Step: 63399, Reward: -170.3199 [122.40], Avg: -589.6700 (0.386)
Step: 63599, Reward: -125.0509 [3.85], Avg: -588.2210 (0.385)
Step: 63799, Reward: -200.9386 [95.22], Avg: -587.3054 (0.383)
Step: 63999, Reward: -170.2551 [59.24], Avg: -586.1873 (0.382)
Step: 64199, Reward: -97.5536 [47.42], Avg: -584.8128 (0.381)
Step: 64399, Reward: -238.3641 [99.25], Avg: -584.0451 (0.380)
Step: 64599, Reward: -97.6948 [47.59], Avg: -582.6867 (0.379)
Step: 64799, Reward: -120.6429 [74.19], Avg: -581.4897 (0.378)
Step: 64999, Reward: -147.0440 [90.86], Avg: -580.4325 (0.377)
Step: 65199, Reward: -146.1765 [44.22], Avg: -579.2361 (0.376)
Step: 65399, Reward: -198.8514 [102.15], Avg: -578.3852 (0.374)
Step: 65599, Reward: -99.1128 [48.38], Avg: -577.0715 (0.373)
Step: 65799, Reward: -235.4572 [126.43], Avg: -576.4174 (0.372)
Step: 65999, Reward: -249.0255 [115.14], Avg: -575.7742 (0.371)
Step: 66199, Reward: -120.7346 [75.61], Avg: -574.6279 (0.370)
Step: 66399, Reward: -145.8431 [48.97], Avg: -573.4839 (0.369)
Step: 66599, Reward: -121.6321 [70.23], Avg: -572.3379 (0.368)
Step: 66799, Reward: -167.3952 [86.77], Avg: -571.3853 (0.367)
Step: 66999, Reward: -188.9370 [93.42], Avg: -570.5225 (0.365)
Step: 67199, Reward: -123.2537 [78.31], Avg: -569.4244 (0.364)
Step: 67399, Reward: -175.7118 [71.35], Avg: -568.4678 (0.363)
Step: 67599, Reward: -237.6528 [68.93], Avg: -567.6930 (0.362)
Step: 67799, Reward: -236.8443 [102.65], Avg: -567.0199 (0.361)
Step: 67999, Reward: -119.6788 [73.28], Avg: -565.9197 (0.360)
Step: 68199, Reward: -140.1450 [104.31], Avg: -564.9770 (0.359)
Step: 68399, Reward: -174.6721 [98.71], Avg: -564.1243 (0.358)
Step: 68599, Reward: -144.9535 [49.55], Avg: -563.0467 (0.357)
Step: 68799, Reward: -166.5485 [55.46], Avg: -562.0554 (0.356)
Step: 68999, Reward: -140.1562 [109.33], Avg: -561.1494 (0.355)
Step: 69199, Reward: -123.5429 [77.42], Avg: -560.1083 (0.354)
Step: 69399, Reward: -153.0919 [63.50], Avg: -559.1184 (0.353)
Step: 69599, Reward: -95.5435 [46.65], Avg: -557.9203 (0.351)
Step: 69799, Reward: -74.5094 [59.68], Avg: -556.7062 (0.350)
Step: 69999, Reward: -119.0527 [125.74], Avg: -555.8150 (0.349)
Step: 70199, Reward: -103.8040 [98.01], Avg: -554.8065 (0.348)
Step: 70399, Reward: -178.6834 [100.53], Avg: -554.0235 (0.347)
Step: 70599, Reward: -171.5568 [59.75], Avg: -553.1093 (0.346)
Step: 70799, Reward: -121.3764 [73.09], Avg: -552.0962 (0.345)
Step: 70999, Reward: -98.3250 [89.53], Avg: -551.0701 (0.344)
Step: 71199, Reward: -143.4660 [90.17], Avg: -550.1785 (0.343)
Step: 71399, Reward: -95.7864 [47.10], Avg: -549.0376 (0.342)
Step: 71599, Reward: -168.7082 [54.52], Avg: -548.1275 (0.341)
Step: 71799, Reward: -48.4979 [57.31], Avg: -546.8954 (0.340)
Step: 71999, Reward: -147.2556 [44.25], Avg: -545.9082 (0.339)
Step: 72199, Reward: -99.8388 [48.84], Avg: -544.8079 (0.338)
Step: 72399, Reward: -169.4302 [142.52], Avg: -544.1646 (0.337)
Step: 72599, Reward: -222.8679 [49.05], Avg: -543.4147 (0.336)
Step: 72799, Reward: -172.5387 [97.47], Avg: -542.6635 (0.335)
Step: 72999, Reward: -143.1697 [133.67], Avg: -541.9353 (0.334)
Step: 73199, Reward: -226.7019 [191.07], Avg: -541.5960 (0.333)
Step: 73399, Reward: -123.3562 [133.16], Avg: -540.8193 (0.332)
Step: 73599, Reward: -126.5200 [80.12], Avg: -539.9111 (0.331)
Step: 73799, Reward: -272.2799 [74.41], Avg: -539.3875 (0.330)
Step: 73999, Reward: -147.0912 [44.47], Avg: -538.4475 (0.329)
Step: 74199, Reward: -174.7255 [152.47], Avg: -537.8781 (0.328)
Step: 74399, Reward: -121.9538 [106.56], Avg: -537.0464 (0.327)
Step: 74599, Reward: -133.3271 [74.85], Avg: -536.1647 (0.326)
Step: 74799, Reward: -211.7762 [75.68], Avg: -535.4997 (0.325)
Step: 74999, Reward: -169.0086 [85.86], Avg: -534.7514 (0.324)
Step: 75199, Reward: -241.4695 [130.60], Avg: -534.3187 (0.323)
Step: 75399, Reward: -127.7764 [3.53], Avg: -533.2497 (0.322)
Step: 75599, Reward: -174.9462 [56.06], Avg: -532.4501 (0.321)
Step: 75799, Reward: -168.5218 [119.98], Avg: -531.8065 (0.320)
Step: 75999, Reward: -180.3895 [132.26], Avg: -531.2298 (0.319)
Step: 76199, Reward: -242.4174 [73.11], Avg: -530.6636 (0.318)
Step: 76399, Reward: -79.7693 [61.49], Avg: -529.6442 (0.317)
Step: 76599, Reward: -151.0321 [51.01], Avg: -528.7889 (0.316)
Step: 76799, Reward: -224.0731 [93.54], Avg: -528.2389 (0.315)
Step: 76999, Reward: -232.5135 [96.38], Avg: -527.7211 (0.315)
Step: 77199, Reward: -164.7712 [109.48], Avg: -527.0645 (0.314)
Step: 77399, Reward: -171.6760 [57.92], Avg: -526.2958 (0.313)
Step: 77599, Reward: -197.4905 [58.51], Avg: -525.5992 (0.312)
Step: 77799, Reward: -172.3648 [121.24], Avg: -525.0028 (0.311)
Step: 77999, Reward: -148.5182 [137.77], Avg: -524.3907 (0.310)
Step: 78199, Reward: -240.2514 [77.61], Avg: -523.8625 (0.309)
Step: 78399, Reward: -308.8784 [92.04], Avg: -523.5489 (0.308)
Step: 78599, Reward: -169.7643 [59.48], Avg: -522.8000 (0.307)
Step: 78799, Reward: -230.4743 [69.39], Avg: -522.2342 (0.306)
Step: 78999, Reward: -167.6629 [93.37], Avg: -521.5729 (0.305)
Step: 79199, Reward: -165.1168 [146.88], Avg: -521.0437 (0.304)
Step: 79399, Reward: -212.2129 [131.89], Avg: -520.5979 (0.303)
Step: 79599, Reward: -121.1538 [104.97], Avg: -519.8581 (0.302)
Step: 79799, Reward: -174.4415 [126.25], Avg: -519.3088 (0.302)
Step: 79999, Reward: -169.0605 [119.49], Avg: -518.7319 (0.301)
Step: 80199, Reward: -144.7385 [44.42], Avg: -517.9100 (0.300)
Step: 80399, Reward: -170.7564 [57.85], Avg: -517.1903 (0.299)
Step: 80599, Reward: -233.8554 [66.62], Avg: -516.6526 (0.298)
Step: 80799, Reward: -209.4815 [83.65], Avg: -516.0993 (0.297)
Step: 80999, Reward: -149.6749 [46.90], Avg: -515.3104 (0.296)
Step: 81199, Reward: -205.8470 [69.07], Avg: -514.7183 (0.295)
Step: 81399, Reward: -169.2808 [86.41], Avg: -514.0818 (0.294)
Step: 81599, Reward: -211.7541 [80.35], Avg: -513.5377 (0.294)
Step: 81799, Reward: -76.2402 [60.60], Avg: -512.6167 (0.293)
Step: 81999, Reward: -170.1975 [95.16], Avg: -512.0136 (0.292)
Step: 82199, Reward: -125.1042 [77.85], Avg: -511.2617 (0.291)
Step: 82399, Reward: -193.9120 [57.56], Avg: -510.6311 (0.290)
Step: 82599, Reward: -119.1151 [122.45], Avg: -509.9796 (0.289)
Step: 82799, Reward: -164.6626 [52.20], Avg: -509.2716 (0.288)
Step: 82999, Reward: -165.5825 [86.66], Avg: -508.6523 (0.287)
Step: 83199, Reward: -192.0902 [87.67], Avg: -508.1020 (0.287)
Step: 83399, Reward: -143.6470 [86.96], Avg: -507.4366 (0.286)
Step: 83599, Reward: -97.6419 [45.62], Avg: -506.5653 (0.285)
Step: 83799, Reward: -196.6734 [98.51], Avg: -506.0609 (0.284)
Step: 83999, Reward: -169.2001 [58.60], Avg: -505.3983 (0.283)
Step: 84199, Reward: -98.3723 [89.25], Avg: -504.6435 (0.282)
Step: 84399, Reward: -192.5195 [58.18], Avg: -504.0418 (0.281)
Step: 84599, Reward: -189.3787 [91.46], Avg: -503.5141 (0.281)
Step: 84799, Reward: -170.7976 [59.46], Avg: -502.8696 (0.280)
Step: 84999, Reward: -145.5195 [116.39], Avg: -502.3027 (0.279)
Step: 85199, Reward: -250.4848 [119.00], Avg: -501.9909 (0.278)
Step: 85399, Reward: -166.5947 [117.74], Avg: -501.4812 (0.277)
Step: 85599, Reward: -144.6819 [136.25], Avg: -500.9659 (0.276)
Step: 85799, Reward: -75.7700 [60.61], Avg: -500.1160 (0.276)
Step: 85999, Reward: -170.1033 [58.59], Avg: -499.4848 (0.275)
Step: 86199, Reward: -137.7136 [124.54], Avg: -498.9344 (0.274)
Step: 86399, Reward: -122.7884 [75.85], Avg: -498.2392 (0.273)
Step: 86599, Reward: -142.0577 [41.99], Avg: -497.5136 (0.272)
Step: 86799, Reward: -122.4990 [74.61], Avg: -496.8215 (0.271)
Step: 86999, Reward: -197.3970 [61.91], Avg: -496.2755 (0.271)
Step: 87199, Reward: -145.0180 [46.04], Avg: -495.5754 (0.270)
Step: 87399, Reward: -214.8802 [47.07], Avg: -495.0408 (0.269)
Step: 87599, Reward: -120.0557 [129.43], Avg: -494.4802 (0.268)
Step: 87799, Reward: -149.0368 [92.21], Avg: -493.9033 (0.267)
Step: 87999, Reward: -222.7659 [84.60], Avg: -493.4794 (0.267)
Step: 88199, Reward: -148.1267 [48.09], Avg: -492.8053 (0.266)
Step: 88399, Reward: -97.4784 [88.94], Avg: -492.1122 (0.265)
Step: 88599, Reward: -239.0083 [62.55], Avg: -491.6820 (0.264)
Step: 88799, Reward: -100.9319 [92.32], Avg: -491.0099 (0.263)
Step: 88999, Reward: -124.2544 [77.46], Avg: -490.3598 (0.263)
Step: 89199, Reward: -74.7195 [59.40], Avg: -489.5610 (0.262)
Step: 89399, Reward: -149.7624 [48.47], Avg: -488.9093 (0.261)
Step: 89599, Reward: -75.7480 [97.66], Avg: -488.2050 (0.260)
Step: 89799, Reward: -157.7215 [105.52], Avg: -487.7040 (0.259)
Step: 89999, Reward: -193.3043 [58.58], Avg: -487.1800 (0.259)
Step: 90199, Reward: -173.9076 [101.51], Avg: -486.7104 (0.258)
Step: 90399, Reward: -144.5786 [50.68], Avg: -486.0656 (0.257)
Step: 90599, Reward: -145.1225 [90.19], Avg: -485.5121 (0.256)
Step: 90799, Reward: -140.5858 [129.47], Avg: -485.0375 (0.256)
Step: 90999, Reward: -95.5517 [47.04], Avg: -484.2849 (0.255)
Step: 91199, Reward: -131.8706 [94.61], Avg: -483.7195 (0.254)
Step: 91399, Reward: -148.0577 [49.14], Avg: -483.0926 (0.253)
Step: 91599, Reward: -76.0862 [60.49], Avg: -482.3360 (0.253)
Step: 91799, Reward: -176.7068 [66.80], Avg: -481.8157 (0.252)
Step: 91999, Reward: -124.7847 [78.89], Avg: -481.2110 (0.251)
Step: 92199, Reward: -143.5733 [88.79], Avg: -480.6712 (0.250)
Step: 92399, Reward: -188.3134 [84.68], Avg: -480.2217 (0.250)
Step: 92599, Reward: -99.3638 [48.94], Avg: -479.5048 (0.249)
Step: 92799, Reward: -195.7068 [120.18], Avg: -479.1522 (0.248)
Step: 92999, Reward: -122.7200 [3.82], Avg: -478.3939 (0.247)
Step: 93199, Reward: -121.1580 [105.62], Avg: -477.8539 (0.247)
Step: 93399, Reward: -121.8736 [73.03], Avg: -477.2480 (0.246)
Step: 93599, Reward: -94.6577 [46.20], Avg: -476.5292 (0.245)
Step: 93799, Reward: -218.1575 [91.38], Avg: -476.1732 (0.244)
Step: 93999, Reward: -147.5070 [49.55], Avg: -475.5793 (0.244)
Step: 94199, Reward: -124.1216 [3.22], Avg: -474.8400 (0.243)
Step: 94399, Reward: -121.8016 [76.34], Avg: -474.2537 (0.242)
Step: 94599, Reward: -143.1023 [110.57], Avg: -473.7874 (0.241)
Step: 94799, Reward: -145.5600 [89.51], Avg: -473.2838 (0.241)
Step: 94999, Reward: -97.1963 [46.48], Avg: -472.5899 (0.240)
Step: 95199, Reward: -216.4993 [83.23], Avg: -472.2267 (0.239)
Step: 95399, Reward: -144.2226 [89.68], Avg: -471.7271 (0.239)
Step: 95599, Reward: -220.4396 [48.35], Avg: -471.3025 (0.238)
Step: 95799, Reward: -163.9855 [86.99], Avg: -470.8426 (0.237)
Step: 95999, Reward: -143.7135 [47.92], Avg: -470.2609 (0.236)
Step: 96199, Reward: -74.9076 [57.97], Avg: -469.5595 (0.236)
Step: 96399, Reward: -97.9666 [48.29], Avg: -468.8887 (0.235)
Step: 96599, Reward: -146.9824 [89.81], Avg: -468.4082 (0.234)
Step: 96799, Reward: -148.1742 [50.79], Avg: -467.8515 (0.234)
Step: 96999, Reward: -96.0901 [47.50], Avg: -467.1829 (0.233)
Step: 97199, Reward: -170.1392 [64.85], Avg: -466.7051 (0.232)
Step: 97399, Reward: -140.5138 [114.02], Avg: -466.2694 (0.231)
Step: 97599, Reward: -119.6653 [74.44], Avg: -465.7117 (0.231)
Step: 97799, Reward: -101.6781 [50.34], Avg: -465.0702 (0.230)
Step: 97999, Reward: -194.1413 [56.86], Avg: -464.6333 (0.229)
Step: 98199, Reward: -97.5812 [48.15], Avg: -463.9838 (0.229)
Step: 98399, Reward: -121.0317 [3.50], Avg: -463.2939 (0.228)
Step: 98599, Reward: -242.5097 [104.50], Avg: -463.0580 (0.227)
Step: 98799, Reward: -120.9726 [4.44], Avg: -462.3745 (0.227)
Step: 98999, Reward: -181.3303 [108.11], Avg: -462.0252 (0.226)
Step: 99199, Reward: -124.2468 [75.65], Avg: -461.4967 (0.225)
Step: 99399, Reward: -169.8759 [55.63], Avg: -461.0218 (0.225)
Step: 99599, Reward: -98.7490 [48.95], Avg: -460.3927 (0.224)
Step: 99799, Reward: -192.2304 [56.57], Avg: -459.9686 (0.223)
Step: 99999, Reward: -174.1269 [98.19], Avg: -459.5933 (0.223)
