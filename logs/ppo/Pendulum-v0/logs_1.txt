Model: <class 'models.ppo.PPOAgent'>, Dir: Pendulum-v0
num_envs: 16,

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

EPS_MIN = 0.1                	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.997             	# The rate at which eps decays from EPS_MAX to EPS_MIN
BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.05				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) * critic_error.pow(2) * scale
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss.mean())
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		update_freq = int(self.update_freq * (1 - self.eps + EPS_MIN)**2)
		if len(self.buffer) >= update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, scale=8*update_freq/len(self.replay_buffer))
		if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "Acrobot-v1", "Pendulum-v0"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[2]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class PixelAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	logger = Logger(model, env_name, num_envs=num_envs)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = PixelAgent(envs.state_size, envs.action_size, num_envs, model)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0]:# or s % envs.env.spec.max_episode_steps == 0:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 199, Reward: -1516.9675 [87.27], Avg: -1604.2423 (0.997)
Step: 399, Reward: -1263.5898 [72.06], Avg: -1469.9457 (0.994)
Step: 599, Reward: -1404.2390 [82.78], Avg: -1475.6360 (0.991)
Step: 799, Reward: -1481.0104 [76.13], Avg: -1496.0110 (0.988)
Step: 999, Reward: -1537.4265 [60.39], Avg: -1516.3724 (0.985)
Step: 1199, Reward: -1522.4526 [25.49], Avg: -1521.6335 (0.982)
Step: 1399, Reward: -1551.5130 [28.42], Avg: -1529.9624 (0.979)
Step: 1599, Reward: -1563.8300 [81.05], Avg: -1544.3275 (0.976)
Step: 1799, Reward: -1593.0396 [44.27], Avg: -1554.6591 (0.973)
Step: 1999, Reward: -1459.9967 [50.62], Avg: -1550.2550 (0.970)
Step: 2199, Reward: -1486.2434 [160.64], Avg: -1559.0390 (0.967)
Step: 2399, Reward: -1511.7411 [123.81], Avg: -1565.4148 (0.965)
Step: 2599, Reward: -1598.3007 [63.88], Avg: -1572.8581 (0.962)
Step: 2799, Reward: -1515.6791 [106.34], Avg: -1576.3699 (0.959)
Step: 2999, Reward: -1419.1493 [101.91], Avg: -1572.6826 (0.956)
Step: 3199, Reward: -1485.5609 [153.61], Avg: -1576.8383 (0.953)
Step: 3399, Reward: -1398.5829 [71.93], Avg: -1570.5840 (0.950)
Step: 3599, Reward: -1493.6821 [103.63], Avg: -1572.0691 (0.947)
Step: 3799, Reward: -1522.6267 [94.82], Avg: -1574.4573 (0.945)
Step: 3999, Reward: -1526.2258 [136.72], Avg: -1578.8818 (0.942)
Step: 4199, Reward: -1504.4971 [78.74], Avg: -1579.0895 (0.939)
Step: 4399, Reward: -1494.6582 [103.92], Avg: -1579.9753 (0.936)
Step: 4599, Reward: -1439.5927 [129.42], Avg: -1579.4987 (0.933)
Step: 4799, Reward: -1523.9311 [76.42], Avg: -1580.3676 (0.930)
Step: 4999, Reward: -1465.9814 [71.01], Avg: -1578.6326 (0.928)
Step: 5199, Reward: -1496.0602 [82.08], Avg: -1578.6135 (0.925)
Step: 5399, Reward: -1519.8126 [29.92], Avg: -1577.5437 (0.922)
Step: 5599, Reward: -1489.3263 [65.18], Avg: -1576.7211 (0.919)
Step: 5799, Reward: -1465.9537 [93.50], Avg: -1576.1255 (0.917)
Step: 5999, Reward: -1567.5470 [56.61], Avg: -1577.7267 (0.914)
Step: 6199, Reward: -1509.9433 [67.88], Avg: -1577.7299 (0.911)
Step: 6399, Reward: -1473.7565 [55.65], Avg: -1576.2198 (0.908)
Step: 6599, Reward: -1513.6891 [63.68], Avg: -1576.2546 (0.906)
Step: 6799, Reward: -1418.2397 [23.97], Avg: -1572.3120 (0.903)
Step: 6999, Reward: -1539.9409 [38.65], Avg: -1572.4915 (0.900)
Step: 7199, Reward: -1504.6361 [93.56], Avg: -1573.2054 (0.897)
Step: 7399, Reward: -1488.3562 [41.81], Avg: -1572.0423 (0.895)
Step: 7599, Reward: -1466.3122 [88.09], Avg: -1571.5782 (0.892)
Step: 7799, Reward: -1435.8449 [83.93], Avg: -1570.2500 (0.889)
Step: 7999, Reward: -1442.7041 [68.17], Avg: -1568.7657 (0.887)
Step: 8199, Reward: -1472.1012 [69.68], Avg: -1568.1076 (0.884)
Step: 8399, Reward: -1508.6407 [69.45], Avg: -1568.3452 (0.881)
Step: 8599, Reward: -1387.5126 [143.56], Avg: -1567.4784 (0.879)
Step: 8799, Reward: -1424.8060 [82.96], Avg: -1566.1213 (0.876)
Step: 8999, Reward: -1487.3611 [28.88], Avg: -1565.0129 (0.874)
Step: 9199, Reward: -1502.5201 [39.84], Avg: -1564.5204 (0.871)
Step: 9399, Reward: -1466.4399 [60.95], Avg: -1563.7303 (0.868)
Step: 9599, Reward: -1477.2205 [38.64], Avg: -1562.7330 (0.866)
Step: 9799, Reward: -1443.7269 [93.97], Avg: -1562.2220 (0.863)
Step: 9999, Reward: -1430.2935 [76.86], Avg: -1561.1206 (0.861)
Step: 10199, Reward: -1417.9977 [64.86], Avg: -1559.5860 (0.858)
Step: 10399, Reward: -1488.9834 [17.18], Avg: -1558.5586 (0.855)
Step: 10599, Reward: -1437.6265 [66.50], Avg: -1557.5315 (0.853)
Step: 10799, Reward: -1366.0687 [113.29], Avg: -1556.0838 (0.850)
Step: 10999, Reward: -1449.9093 [91.87], Avg: -1555.8237 (0.848)
Step: 11199, Reward: -1429.4121 [37.22], Avg: -1554.2311 (0.845)
Step: 11399, Reward: -1467.1065 [33.45], Avg: -1553.2895 (0.843)
Step: 11599, Reward: -1444.3024 [51.22], Avg: -1552.2935 (0.840)
Step: 11799, Reward: -1479.4100 [22.92], Avg: -1551.4466 (0.838)
Step: 11999, Reward: -1471.6936 [53.74], Avg: -1551.0131 (0.835)
Step: 12199, Reward: -1438.0381 [79.48], Avg: -1550.4640 (0.833)
Step: 12399, Reward: -1437.9515 [57.14], Avg: -1549.5708 (0.830)
Step: 12599, Reward: -1391.8803 [38.44], Avg: -1547.6781 (0.828)
Step: 12799, Reward: -1445.0759 [56.12], Avg: -1546.9518 (0.825)
Step: 12999, Reward: -1435.4109 [62.11], Avg: -1546.1914 (0.823)
Step: 13199, Reward: -1403.5867 [60.44], Avg: -1544.9464 (0.820)
Step: 13399, Reward: -1472.1874 [63.44], Avg: -1544.8073 (0.818)
Step: 13599, Reward: -1401.9782 [53.43], Avg: -1543.4927 (0.815)
Step: 13799, Reward: -1427.7605 [67.80], Avg: -1542.7981 (0.813)
Step: 13999, Reward: -1486.1345 [44.59], Avg: -1542.6256 (0.810)
Step: 14199, Reward: -1415.1097 [57.04], Avg: -1541.6330 (0.808)
Step: 14399, Reward: -1470.0309 [21.48], Avg: -1540.9368 (0.805)
Step: 14599, Reward: -1442.8517 [62.51], Avg: -1540.4495 (0.803)
Step: 14799, Reward: -1462.5750 [17.91], Avg: -1539.6391 (0.801)
Step: 14999, Reward: -1456.1229 [28.86], Avg: -1538.9103 (0.798)
Step: 15199, Reward: -1478.5076 [20.65], Avg: -1538.3873 (0.796)
Step: 15399, Reward: -1445.4660 [56.78], Avg: -1537.9179 (0.793)
Step: 15599, Reward: -1465.4574 [23.67], Avg: -1537.2924 (0.791)
Step: 15799, Reward: -1472.3981 [24.11], Avg: -1536.7761 (0.789)
Step: 15999, Reward: -1450.9882 [53.54], Avg: -1536.3730 (0.786)
Step: 16199, Reward: -1467.5155 [56.07], Avg: -1536.2152 (0.784)
Step: 16399, Reward: -1504.0329 [42.19], Avg: -1536.3372 (0.782)
Step: 16599, Reward: -1505.5660 [23.10], Avg: -1536.2447 (0.779)
Step: 16799, Reward: -1468.4580 [55.00], Avg: -1536.0925 (0.777)
Step: 16999, Reward: -1404.0945 [67.18], Avg: -1535.3299 (0.775)
Step: 17199, Reward: -1451.1629 [11.24], Avg: -1534.4819 (0.772)
Step: 17399, Reward: -1449.7254 [35.53], Avg: -1533.9161 (0.770)
Step: 17599, Reward: -1488.8236 [18.69], Avg: -1533.6160 (0.768)
Step: 17799, Reward: -1482.4368 [17.74], Avg: -1533.2403 (0.765)
Step: 17999, Reward: -1464.5847 [54.82], Avg: -1533.0866 (0.763)
Step: 18199, Reward: -1475.4929 [30.50], Avg: -1532.7889 (0.761)
Step: 18399, Reward: -1476.2443 [15.65], Avg: -1532.3444 (0.758)
Step: 18599, Reward: -1485.0534 [21.44], Avg: -1532.0665 (0.756)
Step: 18799, Reward: -1466.6215 [35.47], Avg: -1531.7477 (0.754)
Step: 18999, Reward: -1470.2005 [29.53], Avg: -1531.4106 (0.752)
Step: 19199, Reward: -1480.4382 [48.01], Avg: -1531.3798 (0.749)
Step: 19399, Reward: -1483.1317 [50.41], Avg: -1531.4020 (0.747)
Step: 19599, Reward: -1468.9496 [40.23], Avg: -1531.1753 (0.745)
Step: 19799, Reward: -1475.9312 [23.99], Avg: -1530.8596 (0.743)
Step: 19999, Reward: -1439.7562 [41.73], Avg: -1530.3658 (0.740)
Step: 20199, Reward: -1489.6836 [28.18], Avg: -1530.2421 (0.738)
Step: 20399, Reward: -1477.2989 [25.90], Avg: -1529.9769 (0.736)
Step: 20599, Reward: -1415.8291 [62.79], Avg: -1529.4783 (0.734)
Step: 20799, Reward: -1444.9713 [59.74], Avg: -1529.2401 (0.732)
Step: 20999, Reward: -1436.0488 [61.83], Avg: -1528.9414 (0.729)
Step: 21199, Reward: -1459.0799 [40.36], Avg: -1528.6630 (0.727)
Step: 21399, Reward: -1408.4033 [57.20], Avg: -1528.0737 (0.725)
Step: 21599, Reward: -1465.6142 [55.40], Avg: -1528.0083 (0.723)
Step: 21799, Reward: -1470.2652 [74.76], Avg: -1528.1644 (0.721)
Step: 21999, Reward: -1398.0897 [91.74], Avg: -1527.8159 (0.719)
Step: 22199, Reward: -1390.3553 [57.31], Avg: -1527.0938 (0.716)
Step: 22399, Reward: -1400.4068 [147.23], Avg: -1527.2773 (0.714)
Step: 22599, Reward: -1349.1453 [70.14], Avg: -1526.3215 (0.712)
Step: 22799, Reward: -1420.9066 [57.50], Avg: -1525.9013 (0.710)
Step: 22999, Reward: -1336.2707 [90.78], Avg: -1525.0417 (0.708)
Step: 23199, Reward: -1404.1959 [72.14], Avg: -1524.6219 (0.706)
Step: 23399, Reward: -1383.0267 [91.77], Avg: -1524.1961 (0.704)
Step: 23599, Reward: -1375.0762 [103.15], Avg: -1523.8064 (0.702)
Step: 23799, Reward: -1402.4876 [86.61], Avg: -1523.5148 (0.699)
Step: 23999, Reward: -1385.5827 [90.19], Avg: -1523.1169 (0.697)
Step: 24199, Reward: -1385.4378 [106.86], Avg: -1522.8622 (0.695)
Step: 24399, Reward: -1449.7862 [60.98], Avg: -1522.7631 (0.693)
Step: 24599, Reward: -1325.6393 [49.71], Avg: -1521.5646 (0.691)
Step: 24799, Reward: -1375.1808 [100.53], Avg: -1521.1948 (0.689)
Step: 24999, Reward: -1392.8698 [109.92], Avg: -1521.0476 (0.687)
Step: 25199, Reward: -1402.3280 [103.36], Avg: -1520.9257 (0.685)
Step: 25399, Reward: -1390.9332 [78.21], Avg: -1520.5180 (0.683)
Step: 25599, Reward: -1405.6545 [90.35], Avg: -1520.3265 (0.681)
Step: 25799, Reward: -1388.0701 [54.21], Avg: -1519.7215 (0.679)
Step: 25999, Reward: -1406.9564 [44.63], Avg: -1519.1974 (0.677)
Step: 26199, Reward: -1354.5476 [47.80], Avg: -1518.3054 (0.675)
Step: 26399, Reward: -1422.3684 [59.42], Avg: -1518.0287 (0.673)
Step: 26599, Reward: -1417.7804 [59.06], Avg: -1517.7190 (0.671)
Step: 26799, Reward: -1376.1597 [61.23], Avg: -1517.1196 (0.669)
Step: 26999, Reward: -1393.6964 [68.02], Avg: -1516.7091 (0.667)
Step: 27199, Reward: -1426.3176 [42.17], Avg: -1516.3545 (0.665)
Step: 27399, Reward: -1403.8201 [52.78], Avg: -1515.9184 (0.663)
Step: 27599, Reward: -1414.3925 [72.52], Avg: -1515.7082 (0.661)
Step: 27799, Reward: -1422.7546 [30.74], Avg: -1515.2606 (0.659)
Step: 27999, Reward: -1414.1398 [59.10], Avg: -1514.9605 (0.657)
Step: 28199, Reward: -1433.7426 [72.32], Avg: -1514.8974 (0.655)
Step: 28399, Reward: -1437.2342 [53.62], Avg: -1514.7281 (0.653)
Step: 28599, Reward: -1418.0157 [61.28], Avg: -1514.4803 (0.651)
Step: 28799, Reward: -1371.8190 [56.89], Avg: -1513.8847 (0.649)
Step: 28999, Reward: -1452.9041 [38.94], Avg: -1513.7327 (0.647)
Step: 29199, Reward: -1437.1024 [26.46], Avg: -1513.3891 (0.645)
Step: 29399, Reward: -1437.1537 [49.57], Avg: -1513.2077 (0.643)
Step: 29599, Reward: -1430.0490 [33.46], Avg: -1512.8718 (0.641)
Step: 29799, Reward: -1455.0341 [20.52], Avg: -1512.6214 (0.639)
Step: 29999, Reward: -1416.3894 [33.43], Avg: -1512.2027 (0.637)
Step: 30199, Reward: -1453.4123 [41.23], Avg: -1512.0864 (0.635)
Step: 30399, Reward: -1446.0027 [38.25], Avg: -1511.9033 (0.633)
Step: 30599, Reward: -1374.3852 [42.82], Avg: -1511.2844 (0.631)
Step: 30799, Reward: -1411.5399 [50.82], Avg: -1510.9667 (0.630)
Step: 30999, Reward: -1429.7301 [42.69], Avg: -1510.7180 (0.628)
Step: 31199, Reward: -1429.9338 [59.99], Avg: -1510.5847 (0.626)
Step: 31399, Reward: -1400.4978 [48.82], Avg: -1510.1944 (0.624)
Step: 31599, Reward: -1446.1473 [71.00], Avg: -1510.2385 (0.622)
Step: 31799, Reward: -1456.3985 [31.34], Avg: -1510.0969 (0.620)
Step: 31999, Reward: -1406.5383 [66.64], Avg: -1509.8662 (0.618)
Step: 32199, Reward: -1413.3900 [73.78], Avg: -1509.7252 (0.616)
Step: 32399, Reward: -1395.3198 [56.59], Avg: -1509.3683 (0.615)
Step: 32599, Reward: -1414.2533 [59.80], Avg: -1509.1517 (0.613)
Step: 32799, Reward: -1414.0619 [26.10], Avg: -1508.7310 (0.611)
Step: 32999, Reward: -1383.9619 [26.23], Avg: -1508.1338 (0.609)
Step: 33199, Reward: -1365.5126 [3.67], Avg: -1507.2968 (0.607)
Step: 33399, Reward: -1391.6523 [58.86], Avg: -1506.9567 (0.605)
Step: 33599, Reward: -1361.8579 [38.88], Avg: -1506.3245 (0.604)
Step: 33799, Reward: -1363.8480 [76.49], Avg: -1505.9340 (0.602)
Step: 33999, Reward: -1406.1161 [63.63], Avg: -1505.7212 (0.600)
Step: 34199, Reward: -1422.7696 [40.83], Avg: -1505.4749 (0.598)
Step: 34399, Reward: -1435.5905 [51.22], Avg: -1505.3664 (0.596)
Step: 34599, Reward: -1418.1034 [58.01], Avg: -1505.1973 (0.595)
Step: 34799, Reward: -1421.1202 [62.23], Avg: -1505.0717 (0.593)
Step: 34999, Reward: -1401.9168 [55.36], Avg: -1504.7986 (0.591)
Step: 35199, Reward: -1401.8639 [62.61], Avg: -1504.5694 (0.589)
Step: 35399, Reward: -1424.1718 [58.05], Avg: -1504.4432 (0.588)
Step: 35599, Reward: -1404.8152 [60.03], Avg: -1504.2207 (0.586)
Step: 35799, Reward: -1403.8911 [47.39], Avg: -1503.9250 (0.584)
Step: 35999, Reward: -1410.2466 [59.43], Avg: -1503.7347 (0.582)
Step: 36199, Reward: -1392.5892 [61.71], Avg: -1503.4616 (0.581)
Step: 36399, Reward: -1389.0216 [88.18], Avg: -1503.3173 (0.579)
Step: 36599, Reward: -1391.6514 [50.66], Avg: -1502.9839 (0.577)
Step: 36799, Reward: -1396.7204 [47.17], Avg: -1502.6627 (0.575)
Step: 36999, Reward: -1433.9629 [32.48], Avg: -1502.4670 (0.574)
Step: 37199, Reward: -1355.8096 [62.64], Avg: -1502.0152 (0.572)
Step: 37399, Reward: -1366.2519 [46.78], Avg: -1501.5394 (0.570)
Step: 37599, Reward: -1386.9071 [21.09], Avg: -1501.0418 (0.568)
Step: 37799, Reward: -1407.1177 [52.96], Avg: -1500.8251 (0.567)
Step: 37999, Reward: -1431.5055 [54.27], Avg: -1500.7459 (0.565)
Step: 38199, Reward: -1388.5855 [44.18], Avg: -1500.3900 (0.563)
Step: 38399, Reward: -1337.1443 [33.35], Avg: -1499.7134 (0.562)
Step: 38599, Reward: -1395.1374 [48.00], Avg: -1499.4203 (0.560)
Step: 38799, Reward: -1423.2679 [56.15], Avg: -1499.3172 (0.558)
Step: 38999, Reward: -1381.0822 [64.57], Avg: -1499.0420 (0.557)
Step: 39199, Reward: -1443.0233 [47.35], Avg: -1498.9978 (0.555)
Step: 39399, Reward: -1382.8582 [78.90], Avg: -1498.8088 (0.553)
Step: 39599, Reward: -1417.6482 [65.07], Avg: -1498.7275 (0.552)
Step: 39799, Reward: -1424.4759 [37.96], Avg: -1498.5451 (0.550)
Step: 39999, Reward: -1414.5073 [47.94], Avg: -1498.3647 (0.548)
Step: 40199, Reward: -1360.9702 [58.39], Avg: -1497.9716 (0.547)
Step: 40399, Reward: -1395.9653 [88.50], Avg: -1497.9047 (0.545)
Step: 40599, Reward: -1415.3291 [73.74], Avg: -1497.8612 (0.543)
Step: 40799, Reward: -1395.3298 [65.66], Avg: -1497.6805 (0.542)
Step: 40999, Reward: -1345.9493 [19.61], Avg: -1497.0360 (0.540)
Step: 41199, Reward: -1412.0328 [73.38], Avg: -1496.9795 (0.539)
Step: 41399, Reward: -1355.2301 [64.94], Avg: -1496.6085 (0.537)
Step: 41599, Reward: -1414.3443 [56.74], Avg: -1496.4858 (0.535)
Step: 41799, Reward: -1405.5397 [66.00], Avg: -1496.3664 (0.534)
Step: 41999, Reward: -1448.6035 [38.89], Avg: -1496.3242 (0.532)
Step: 42199, Reward: -1390.9226 [105.01], Avg: -1496.3223 (0.530)
Step: 42399, Reward: -1374.2864 [36.37], Avg: -1495.9183 (0.529)
Step: 42599, Reward: -1421.2243 [44.00], Avg: -1495.7742 (0.527)
Step: 42799, Reward: -1390.3648 [84.90], Avg: -1495.6783 (0.526)
Step: 42999, Reward: -1332.4077 [66.60], Avg: -1495.2287 (0.524)
Step: 43199, Reward: -1406.9921 [76.56], Avg: -1495.1746 (0.523)
Step: 43399, Reward: -1380.0116 [27.42], Avg: -1494.7703 (0.521)
Step: 43599, Reward: -1363.0611 [80.25], Avg: -1494.5342 (0.519)
Step: 43799, Reward: -1377.6875 [82.40], Avg: -1494.3769 (0.518)
Step: 43999, Reward: -1365.0542 [51.32], Avg: -1494.0224 (0.516)
Step: 44199, Reward: -1391.9794 [63.72], Avg: -1493.8490 (0.515)
Step: 44399, Reward: -1369.7615 [28.94], Avg: -1493.4204 (0.513)
Step: 44599, Reward: -1383.8797 [57.56], Avg: -1493.1873 (0.512)
Step: 44799, Reward: -1373.8431 [59.36], Avg: -1492.9195 (0.510)
Step: 44999, Reward: -1320.3548 [69.92], Avg: -1492.4633 (0.509)
Step: 45199, Reward: -1425.9969 [61.62], Avg: -1492.4419 (0.507)
Step: 45399, Reward: -1405.0498 [65.35], Avg: -1492.3448 (0.506)
Step: 45599, Reward: -1366.1696 [56.11], Avg: -1492.0375 (0.504)
Step: 45799, Reward: -1409.8893 [72.64], Avg: -1491.9959 (0.503)
Step: 45999, Reward: -1401.3647 [79.13], Avg: -1491.9459 (0.501)
Step: 46199, Reward: -1398.3518 [65.22], Avg: -1491.8231 (0.500)
Step: 46399, Reward: -1337.4894 [50.82], Avg: -1491.3769 (0.498)
Step: 46599, Reward: -1350.0706 [120.85], Avg: -1491.2891 (0.497)
Step: 46799, Reward: -1270.7185 [81.06], Avg: -1490.6929 (0.495)
Step: 46999, Reward: -1300.7496 [79.18], Avg: -1490.2215 (0.494)
Step: 47199, Reward: -1398.1184 [70.42], Avg: -1490.1297 (0.492)
Step: 47399, Reward: -1369.1408 [90.69], Avg: -1490.0018 (0.491)
Step: 47599, Reward: -1321.7860 [88.73], Avg: -1489.6679 (0.489)
Step: 47799, Reward: -1313.8551 [69.87], Avg: -1489.2246 (0.488)
Step: 47999, Reward: -1414.8303 [60.41], Avg: -1489.1663 (0.486)
Step: 48199, Reward: -1345.0433 [91.06], Avg: -1488.9461 (0.485)
Step: 48399, Reward: -1237.6148 [89.97], Avg: -1488.2793 (0.483)
Step: 48599, Reward: -1326.3323 [57.74], Avg: -1487.8505 (0.482)
Step: 48799, Reward: -1405.0698 [34.49], Avg: -1487.6526 (0.480)
Step: 48999, Reward: -1296.7325 [102.80], Avg: -1487.2929 (0.479)
Step: 49199, Reward: -1330.9670 [88.60], Avg: -1487.0176 (0.478)
Step: 49399, Reward: -1335.3126 [101.45], Avg: -1486.8142 (0.476)
Step: 49599, Reward: -1297.8807 [95.98], Avg: -1486.4394 (0.475)
Step: 49799, Reward: -1279.3216 [62.78], Avg: -1485.8597 (0.473)
Step: 49999, Reward: -1365.9779 [38.55], Avg: -1485.5343 (0.472)
Step: 50199, Reward: -1317.4694 [28.87], Avg: -1484.9798 (0.470)
Step: 50399, Reward: -1338.6440 [16.61], Avg: -1484.4650 (0.469)
Step: 50599, Reward: -1345.5908 [40.35], Avg: -1484.0756 (0.468)
Step: 50799, Reward: -1345.7466 [21.56], Avg: -1483.6159 (0.466)
Step: 50999, Reward: -1294.3645 [64.80], Avg: -1483.1278 (0.465)
Step: 51199, Reward: -1331.1874 [23.64], Avg: -1482.6267 (0.463)
Step: 51399, Reward: -1338.9925 [66.83], Avg: -1482.3278 (0.462)
Step: 51599, Reward: -1272.6303 [45.46], Avg: -1481.6912 (0.461)
Step: 51799, Reward: -1279.1980 [81.05], Avg: -1481.2223 (0.459)
Step: 51999, Reward: -1350.1403 [44.47], Avg: -1480.8892 (0.458)
Step: 52199, Reward: -1304.1156 [70.99], Avg: -1480.4839 (0.456)
Step: 52399, Reward: -1325.0187 [26.90], Avg: -1479.9932 (0.455)
Step: 52599, Reward: -1264.0732 [87.46], Avg: -1479.5048 (0.454)
Step: 52799, Reward: -1259.8309 [119.91], Avg: -1479.1268 (0.452)
Step: 52999, Reward: -1313.2734 [44.69], Avg: -1478.6696 (0.451)
Step: 53199, Reward: -1279.0018 [60.55], Avg: -1478.1466 (0.450)
Step: 53399, Reward: -1351.6338 [35.94], Avg: -1477.8074 (0.448)
Step: 53599, Reward: -1293.1351 [29.24], Avg: -1477.2274 (0.447)
Step: 53799, Reward: -1312.4308 [57.31], Avg: -1476.8279 (0.446)
Step: 53999, Reward: -1242.5644 [64.21], Avg: -1476.1980 (0.444)
Step: 54199, Reward: -1329.0662 [62.22], Avg: -1475.8847 (0.443)
Step: 54399, Reward: -1292.8036 [45.64], Avg: -1475.3794 (0.442)
Step: 54599, Reward: -1272.6006 [62.56], Avg: -1474.8658 (0.440)
Step: 54799, Reward: -1240.9292 [53.60], Avg: -1474.2076 (0.439)
Step: 54999, Reward: -1296.4025 [105.05], Avg: -1473.9430 (0.438)
Step: 55199, Reward: -1256.0476 [68.98], Avg: -1473.4035 (0.436)
Step: 55399, Reward: -1267.7898 [118.87], Avg: -1473.0903 (0.435)
Step: 55599, Reward: -1223.6806 [85.41], Avg: -1472.5004 (0.434)
Step: 55799, Reward: -1291.7221 [109.88], Avg: -1472.2463 (0.432)
Step: 55999, Reward: -1256.8225 [60.83], Avg: -1471.6942 (0.431)
Step: 56199, Reward: -1225.8014 [53.43], Avg: -1471.0093 (0.430)
Step: 56399, Reward: -1262.8797 [67.48], Avg: -1470.5105 (0.429)
Step: 56599, Reward: -1244.5589 [121.93], Avg: -1470.1429 (0.427)
Step: 56799, Reward: -1235.3505 [66.77], Avg: -1469.5513 (0.426)
Step: 56999, Reward: -1194.3551 [163.18], Avg: -1469.1583 (0.425)
Step: 57199, Reward: -1200.8146 [83.46], Avg: -1468.5118 (0.423)
Step: 57399, Reward: -1182.0166 [32.20], Avg: -1467.6258 (0.422)
Step: 57599, Reward: -1241.8847 [103.16], Avg: -1467.2001 (0.421)
Step: 57799, Reward: -1239.1483 [87.32], Avg: -1466.7132 (0.420)
Step: 57999, Reward: -1219.6240 [64.68], Avg: -1466.0842 (0.418)
Step: 58199, Reward: -1285.9662 [75.82], Avg: -1465.7258 (0.417)
Step: 58399, Reward: -1206.2240 [99.94], Avg: -1465.1793 (0.416)
Step: 58599, Reward: -1179.5333 [69.58], Avg: -1464.4419 (0.415)
Step: 58799, Reward: -1232.7072 [59.66], Avg: -1463.8566 (0.413)
Step: 58999, Reward: -1202.4680 [148.25], Avg: -1463.4731 (0.412)
Step: 59199, Reward: -1227.7388 [80.68], Avg: -1462.9493 (0.411)
Step: 59399, Reward: -1204.7301 [138.80], Avg: -1462.5472 (0.410)
Step: 59599, Reward: -1252.8504 [99.68], Avg: -1462.1780 (0.408)
Step: 59799, Reward: -1213.2519 [146.20], Avg: -1461.8345 (0.407)
Step: 59999, Reward: -1119.6234 [99.16], Avg: -1461.0243 (0.406)
Step: 60199, Reward: -1245.9665 [120.36], Avg: -1460.7097 (0.405)
Step: 60399, Reward: -1156.5792 [130.49], Avg: -1460.1347 (0.404)
Step: 60599, Reward: -1155.3721 [147.58], Avg: -1459.6159 (0.402)
Step: 60799, Reward: -1297.0663 [57.90], Avg: -1459.2717 (0.401)
Step: 60999, Reward: -1152.3978 [130.79], Avg: -1458.6944 (0.400)
Step: 61199, Reward: -1215.7639 [121.63], Avg: -1458.2980 (0.399)
Step: 61399, Reward: -1190.3245 [155.08], Avg: -1457.9303 (0.398)
Step: 61599, Reward: -1203.9141 [156.30], Avg: -1457.6130 (0.396)
Step: 61799, Reward: -1184.4820 [85.38], Avg: -1457.0054 (0.395)
Step: 61999, Reward: -1096.8377 [77.53], Avg: -1456.0937 (0.394)
Step: 62199, Reward: -1228.2654 [49.40], Avg: -1455.5199 (0.393)
Step: 62399, Reward: -1111.9827 [54.13], Avg: -1454.5924 (0.392)
Step: 62599, Reward: -1176.7240 [91.96], Avg: -1453.9984 (0.390)
Step: 62799, Reward: -1181.8453 [111.18], Avg: -1453.4858 (0.389)
Step: 62999, Reward: -1206.5650 [126.53], Avg: -1453.1036 (0.388)
Step: 63199, Reward: -1237.6519 [116.47], Avg: -1452.7903 (0.387)
Step: 63399, Reward: -1155.2877 [173.91], Avg: -1452.4005 (0.386)
Step: 63599, Reward: -1102.1918 [144.85], Avg: -1451.7547 (0.385)
Step: 63799, Reward: -1120.2088 [136.98], Avg: -1451.1448 (0.383)
Step: 63999, Reward: -1090.3850 [108.38], Avg: -1450.3561 (0.382)
Step: 64199, Reward: -1125.5471 [63.75], Avg: -1449.5428 (0.381)
Step: 64399, Reward: -1096.6035 [125.85], Avg: -1448.8376 (0.380)
Step: 64599, Reward: -1176.4022 [128.23], Avg: -1448.3911 (0.379)
Step: 64799, Reward: -1146.7954 [111.41], Avg: -1447.8041 (0.378)
Step: 64999, Reward: -1115.8416 [114.73], Avg: -1447.1357 (0.377)
Step: 65199, Reward: -1079.7421 [131.46], Avg: -1446.4120 (0.376)
Step: 65399, Reward: -1121.5776 [148.88], Avg: -1445.8739 (0.374)
Step: 65599, Reward: -1055.1087 [161.23], Avg: -1445.1741 (0.373)
Step: 65799, Reward: -1073.8059 [115.52], Avg: -1444.3964 (0.372)
Step: 65999, Reward: -1223.3483 [62.68], Avg: -1443.9165 (0.371)
Step: 66199, Reward: -1064.5749 [58.29], Avg: -1442.9465 (0.370)
Step: 66399, Reward: -1197.2766 [97.80], Avg: -1442.5011 (0.369)
Step: 66599, Reward: -1080.4062 [65.82], Avg: -1441.6114 (0.368)
Step: 66799, Reward: -1037.4491 [154.07], Avg: -1440.8626 (0.367)
Step: 66999, Reward: -967.9160 [52.69], Avg: -1439.6081 (0.365)
Step: 67199, Reward: -1018.2824 [100.71], Avg: -1438.6539 (0.364)
Step: 67399, Reward: -1078.0982 [110.58], Avg: -1437.9121 (0.363)
Step: 67599, Reward: -1166.5612 [87.94], Avg: -1437.3695 (0.362)
Step: 67799, Reward: -1030.5761 [80.51], Avg: -1436.4070 (0.361)
Step: 67999, Reward: -1008.6447 [162.71], Avg: -1435.6275 (0.360)
Step: 68199, Reward: -1079.5764 [126.03], Avg: -1434.9529 (0.359)
Step: 68399, Reward: -1150.3921 [160.40], Avg: -1434.5899 (0.358)
Step: 68599, Reward: -1177.3332 [34.30], Avg: -1433.9398 (0.357)
Step: 68799, Reward: -1008.9438 [125.14], Avg: -1433.0681 (0.356)
Step: 68999, Reward: -1053.1327 [134.90], Avg: -1432.3579 (0.355)
Step: 69199, Reward: -1174.4031 [82.33], Avg: -1431.8503 (0.354)
Step: 69399, Reward: -1080.8686 [130.93], Avg: -1431.2162 (0.353)
Step: 69599, Reward: -1031.7986 [89.89], Avg: -1430.3267 (0.351)
Step: 69799, Reward: -1161.6981 [85.19], Avg: -1429.8011 (0.350)
Step: 69999, Reward: -1108.6859 [95.31], Avg: -1429.1560 (0.349)
Step: 70199, Reward: -1125.0840 [136.27], Avg: -1428.6779 (0.348)
Step: 70399, Reward: -1033.6074 [136.05], Avg: -1427.9420 (0.347)
Step: 70599, Reward: -998.4695 [132.77], Avg: -1427.1015 (0.346)
Step: 70799, Reward: -1022.4831 [155.45], Avg: -1426.3976 (0.345)
Step: 70999, Reward: -1013.4929 [114.78], Avg: -1425.5579 (0.344)
Step: 71199, Reward: -1001.1390 [149.66], Avg: -1424.7861 (0.343)
Step: 71399, Reward: -1092.1500 [129.28], Avg: -1424.2164 (0.342)
Step: 71599, Reward: -1119.2771 [189.07], Avg: -1423.8928 (0.341)
Step: 71799, Reward: -1012.3027 [128.72], Avg: -1423.1049 (0.340)
Step: 71999, Reward: -954.7545 [134.25], Avg: -1422.1768 (0.339)
Step: 72199, Reward: -1062.5976 [154.70], Avg: -1421.6092 (0.338)
Step: 72399, Reward: -913.8138 [126.91], Avg: -1420.5571 (0.337)
Step: 72599, Reward: -996.7353 [60.50], Avg: -1419.5562 (0.336)
Step: 72799, Reward: -1083.7782 [131.32], Avg: -1418.9945 (0.335)
Step: 72999, Reward: -928.9598 [147.55], Avg: -1418.0562 (0.334)
Step: 73199, Reward: -933.7275 [133.50], Avg: -1417.0976 (0.333)
Step: 73399, Reward: -1038.9878 [155.48], Avg: -1416.4910 (0.332)
Step: 73599, Reward: -951.1364 [184.22], Avg: -1415.7271 (0.331)
Step: 73799, Reward: -819.5475 [193.55], Avg: -1414.6359 (0.330)
Step: 73999, Reward: -963.2892 [184.11], Avg: -1413.9137 (0.329)
Step: 74199, Reward: -1023.5630 [167.34], Avg: -1413.3126 (0.328)
Step: 74399, Reward: -1055.4036 [83.52], Avg: -1412.5750 (0.327)
Step: 74599, Reward: -1009.5374 [126.43], Avg: -1411.8334 (0.326)
Step: 74799, Reward: -963.7480 [131.37], Avg: -1410.9866 (0.325)
Step: 74999, Reward: -1022.4335 [113.57], Avg: -1410.2533 (0.324)
Step: 75199, Reward: -1091.4827 [59.80], Avg: -1409.5645 (0.323)
Step: 75399, Reward: -1002.3515 [156.95], Avg: -1408.9007 (0.322)
Step: 75599, Reward: -955.4642 [253.82], Avg: -1408.3726 (0.321)
Step: 75799, Reward: -1139.0758 [77.61], Avg: -1407.8668 (0.320)
Step: 75999, Reward: -1031.7366 [111.15], Avg: -1407.1695 (0.319)
Step: 76199, Reward: -1030.4269 [77.22], Avg: -1406.3834 (0.318)
Step: 76399, Reward: -954.1683 [112.61], Avg: -1405.4943 (0.317)
Step: 76599, Reward: -907.7487 [150.87], Avg: -1404.5887 (0.316)
Step: 76799, Reward: -1007.3476 [137.44], Avg: -1403.9121 (0.315)
Step: 76999, Reward: -880.4492 [185.04], Avg: -1403.0331 (0.315)
Step: 77199, Reward: -1024.4612 [87.08], Avg: -1402.2779 (0.314)
Step: 77399, Reward: -919.3203 [194.82], Avg: -1401.5334 (0.313)
Step: 77599, Reward: -905.9593 [175.47], Avg: -1400.7084 (0.312)
Step: 77799, Reward: -915.5839 [178.17], Avg: -1399.9193 (0.311)
Step: 77999, Reward: -961.6800 [97.23], Avg: -1399.0449 (0.310)
Step: 78199, Reward: -917.6046 [172.16], Avg: -1398.2539 (0.309)
Step: 78399, Reward: -945.0565 [83.18], Avg: -1397.3100 (0.308)
Step: 78599, Reward: -1010.2702 [93.91], Avg: -1396.5641 (0.307)
Step: 78799, Reward: -846.1054 [186.56], Avg: -1395.6405 (0.306)
Step: 78999, Reward: -1043.3773 [137.93], Avg: -1395.0979 (0.305)
Step: 79199, Reward: -1004.0552 [168.06], Avg: -1394.5348 (0.304)
Step: 79399, Reward: -1004.3841 [191.13], Avg: -1394.0335 (0.303)
Step: 79599, Reward: -884.7063 [144.21], Avg: -1393.1161 (0.302)
Step: 79799, Reward: -856.8951 [135.65], Avg: -1392.1122 (0.302)
Step: 79999, Reward: -689.7606 [175.80], Avg: -1390.7958 (0.301)
Step: 80199, Reward: -865.5128 [142.64], Avg: -1389.8416 (0.300)
Step: 80399, Reward: -957.5337 [134.97], Avg: -1389.1019 (0.299)
Step: 80599, Reward: -844.3424 [176.50], Avg: -1388.1881 (0.298)
Step: 80799, Reward: -715.1696 [241.75], Avg: -1387.1206 (0.297)
Step: 80999, Reward: -772.5819 [129.40], Avg: -1385.9228 (0.296)
Step: 81199, Reward: -896.0409 [165.18], Avg: -1385.1230 (0.295)
Step: 81399, Reward: -770.6338 [243.81], Avg: -1384.2122 (0.294)
Step: 81599, Reward: -861.8797 [185.37], Avg: -1383.3863 (0.294)
Step: 81799, Reward: -719.6798 [245.02], Avg: -1382.3626 (0.293)
Step: 81999, Reward: -778.7978 [194.26], Avg: -1381.3644 (0.292)
Step: 82199, Reward: -683.1918 [217.75], Avg: -1380.1954 (0.291)
Step: 82399, Reward: -733.8354 [211.88], Avg: -1379.1409 (0.290)
Step: 82599, Reward: -587.7359 [234.02], Avg: -1377.7913 (0.289)
Step: 82799, Reward: -605.8013 [251.92], Avg: -1376.5351 (0.288)
Step: 82999, Reward: -529.5602 [82.15], Avg: -1374.6921 (0.287)
Step: 83199, Reward: -486.0031 [158.95], Avg: -1372.9379 (0.287)
Step: 83399, Reward: -682.1454 [208.67], Avg: -1371.7818 (0.286)
Step: 83599, Reward: -703.9935 [262.32], Avg: -1370.8117 (0.285)
Step: 83799, Reward: -678.4706 [142.13], Avg: -1369.4986 (0.284)
Step: 83999, Reward: -695.5999 [237.61], Avg: -1368.4598 (0.283)
Step: 84199, Reward: -608.1990 [166.25], Avg: -1367.0488 (0.282)
Step: 84399, Reward: -499.3952 [79.80], Avg: -1365.1819 (0.281)
Step: 84599, Reward: -537.7110 [182.68], Avg: -1363.6576 (0.281)
Step: 84799, Reward: -473.6957 [50.41], Avg: -1361.6775 (0.280)
Step: 84999, Reward: -420.9232 [125.53], Avg: -1359.7593 (0.279)
Step: 85199, Reward: -431.7323 [140.98], Avg: -1357.9118 (0.278)
Step: 85399, Reward: -468.1372 [112.28], Avg: -1356.0909 (0.277)
Step: 85599, Reward: -599.5666 [196.41], Avg: -1354.7822 (0.276)
Step: 85799, Reward: -438.4822 [90.96], Avg: -1352.8584 (0.276)
Step: 85999, Reward: -540.6256 [122.46], Avg: -1351.2542 (0.275)
Step: 86199, Reward: -523.0413 [222.92], Avg: -1349.8499 (0.274)
Step: 86399, Reward: -399.0890 [132.18], Avg: -1347.9550 (0.273)
Step: 86599, Reward: -452.1845 [94.72], Avg: -1346.1050 (0.272)
Step: 86799, Reward: -480.1611 [95.37], Avg: -1344.3295 (0.271)
Step: 86999, Reward: -419.2903 [98.93], Avg: -1342.4304 (0.271)
Step: 87199, Reward: -444.2423 [61.53], Avg: -1340.5114 (0.270)
Step: 87399, Reward: -370.2678 [80.06], Avg: -1338.4744 (0.269)
Step: 87599, Reward: -411.7950 [95.77], Avg: -1336.5773 (0.268)
Step: 87799, Reward: -270.5956 [91.11], Avg: -1334.3567 (0.267)
Step: 87999, Reward: -365.5902 [165.91], Avg: -1332.5320 (0.267)
Step: 88199, Reward: -303.5209 [102.56], Avg: -1330.4312 (0.266)
Step: 88399, Reward: -236.8555 [80.37], Avg: -1328.1389 (0.265)
Step: 88599, Reward: -343.7935 [144.02], Avg: -1326.2420 (0.264)
Step: 88799, Reward: -286.5107 [157.80], Avg: -1324.2557 (0.263)
Step: 88999, Reward: -197.9100 [124.99], Avg: -1322.0054 (0.263)
Step: 89199, Reward: -266.0200 [97.40], Avg: -1319.8561 (0.262)
Step: 89399, Reward: -174.4336 [97.18], Avg: -1317.5111 (0.261)
Step: 89599, Reward: -222.7802 [96.16], Avg: -1315.2821 (0.260)
Step: 89799, Reward: -216.9151 [130.09], Avg: -1313.1256 (0.259)
Step: 89999, Reward: -291.8930 [103.37], Avg: -1311.0859 (0.259)
Step: 90199, Reward: -195.2573 [90.90], Avg: -1308.8133 (0.258)
Step: 90399, Reward: -124.5735 [2.48], Avg: -1306.1988 (0.257)
Step: 90599, Reward: -101.2287 [91.72], Avg: -1303.7413 (0.256)
Step: 90799, Reward: -123.9484 [77.95], Avg: -1301.3143 (0.256)
Step: 90999, Reward: -205.0710 [67.97], Avg: -1299.0544 (0.255)
Step: 91199, Reward: -271.3262 [91.01], Avg: -1297.0002 (0.254)
Step: 91399, Reward: -302.4034 [192.09], Avg: -1295.2442 (0.253)
Step: 91599, Reward: -169.6699 [56.75], Avg: -1292.9105 (0.253)
Step: 91799, Reward: -187.8447 [82.66], Avg: -1290.6830 (0.252)
Step: 91999, Reward: -172.5989 [62.85], Avg: -1288.3890 (0.251)
Step: 92199, Reward: -172.4669 [96.90], Avg: -1286.1786 (0.250)
Step: 92399, Reward: -169.1012 [81.47], Avg: -1283.9370 (0.250)
Step: 92599, Reward: -242.2994 [110.87], Avg: -1281.9267 (0.249)
Step: 92799, Reward: -235.3109 [65.44], Avg: -1279.8121 (0.248)
Step: 92999, Reward: -149.2569 [49.85], Avg: -1277.4880 (0.247)
Step: 93199, Reward: -170.5736 [89.75], Avg: -1275.3052 (0.247)
Step: 93399, Reward: -77.7954 [60.70], Avg: -1272.8710 (0.246)
Step: 93599, Reward: -126.6478 [78.42], Avg: -1270.5893 (0.245)
Step: 93799, Reward: -121.9279 [72.73], Avg: -1268.2952 (0.244)
Step: 93999, Reward: -149.8779 [91.45], Avg: -1266.1102 (0.244)
Step: 94199, Reward: -218.8700 [46.14], Avg: -1263.9847 (0.243)
Step: 94399, Reward: -170.6918 [58.19], Avg: -1261.7917 (0.242)
Step: 94599, Reward: -209.7979 [108.59], Avg: -1259.7972 (0.241)
Step: 94799, Reward: -217.1673 [130.97], Avg: -1257.8739 (0.241)
Step: 94999, Reward: -148.0406 [48.73], Avg: -1255.6400 (0.240)
Step: 95199, Reward: -151.3882 [50.46], Avg: -1253.4261 (0.239)
Step: 95399, Reward: -129.1321 [87.81], Avg: -1251.2532 (0.239)
Step: 95599, Reward: -273.8451 [87.22], Avg: -1249.3909 (0.238)
Step: 95799, Reward: -222.2649 [94.11], Avg: -1247.4430 (0.237)
Step: 95999, Reward: -102.3036 [93.28], Avg: -1245.2516 (0.236)
Step: 96199, Reward: -98.1811 [48.14], Avg: -1242.9670 (0.236)
Step: 96399, Reward: -120.2908 [71.88], Avg: -1240.7869 (0.235)
Step: 96599, Reward: -96.6321 [47.23], Avg: -1238.5158 (0.234)
Step: 96799, Reward: -170.9633 [121.02], Avg: -1236.5602 (0.234)
Step: 96999, Reward: -198.3487 [96.19], Avg: -1234.6179 (0.233)
Step: 97199, Reward: -168.3701 [90.45], Avg: -1232.6101 (0.232)
Step: 97399, Reward: -151.0481 [123.64], Avg: -1230.6431 (0.231)
Step: 97599, Reward: -191.4908 [91.35], Avg: -1228.7009 (0.231)
Step: 97799, Reward: -235.3629 [100.68], Avg: -1226.8754 (0.230)
Step: 97999, Reward: -152.5265 [60.12], Avg: -1224.8055 (0.229)
Step: 98199, Reward: -197.2662 [61.08], Avg: -1222.8372 (0.229)
Step: 98399, Reward: -146.1174 [46.83], Avg: -1220.7439 (0.228)
Step: 98599, Reward: -194.0128 [60.10], Avg: -1218.7832 (0.227)
Step: 98799, Reward: -168.3392 [57.48], Avg: -1216.7732 (0.227)
Step: 98999, Reward: -49.8454 [58.40], Avg: -1214.5337 (0.226)
Step: 99199, Reward: -142.8965 [134.27], Avg: -1212.6439 (0.225)
Step: 99399, Reward: -168.8367 [60.82], Avg: -1210.6660 (0.225)
Step: 99599, Reward: -174.5422 [60.98], Avg: -1208.7079 (0.224)
Step: 99799, Reward: -100.7715 [49.40], Avg: -1206.5866 (0.223)
Step: 99999, Reward: -145.4843 [89.53], Avg: -1204.6434 (0.223)
