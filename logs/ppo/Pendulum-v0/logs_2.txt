Model: <class 'models.ppo.PPOAgent'>, Dir: Pendulum-v0
num_envs: 16,

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

EPS_MIN = 0.1                	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.997             	# The rate at which eps decays from EPS_MAX to EPS_MIN
BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.1				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) * critic_error.pow(2) * scale
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss.mean())
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		update_freq = int(self.update_freq * (1 - self.eps + EPS_MIN)**2)
		if len(self.buffer) >= update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, scale=16*update_freq/len(self.replay_buffer))
		if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "Acrobot-v1", "Pendulum-v0"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[2]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class PixelAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	logger = Logger(model, env_name, num_envs=num_envs)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = PixelAgent(envs.state_size, envs.action_size, num_envs, model)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0] or s+1 % envs.env.spec.max_episode_steps == 0:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 199, Reward: -961.0007 [166.00], Avg: -1127.0033 (0.997)
Step: 399, Reward: -1076.9000 [231.28], Avg: -1217.5921 (0.994)
Step: 599, Reward: -1114.5928 [184.79], Avg: -1244.8568 (0.991)
Step: 799, Reward: -1206.7473 [53.03], Avg: -1248.5858 (0.988)
Step: 999, Reward: -1208.8492 [98.45], Avg: -1260.3291 (0.985)
Step: 1199, Reward: -1409.9099 [121.87], Avg: -1305.5707 (0.982)
Step: 1399, Reward: -1160.4773 [123.66], Avg: -1302.5089 (0.979)
Step: 1599, Reward: -1173.1872 [212.75], Avg: -1312.9372 (0.976)
Step: 1799, Reward: -1332.3024 [59.66], Avg: -1321.7174 (0.973)
Step: 1999, Reward: -1288.4180 [118.61], Avg: -1330.2486 (0.970)
Step: 2199, Reward: -1257.7538 [112.26], Avg: -1333.8638 (0.967)
Step: 2399, Reward: -1216.5071 [63.34], Avg: -1329.3622 (0.965)
Step: 2599, Reward: -1355.9448 [95.11], Avg: -1338.7233 (0.962)
Step: 2799, Reward: -1312.2476 [22.99], Avg: -1338.4743 (0.959)
Step: 2999, Reward: -1322.2424 [82.35], Avg: -1342.8825 (0.956)
Step: 3199, Reward: -1311.9113 [97.62], Avg: -1347.0478 (0.953)
Step: 3399, Reward: -1327.9879 [62.45], Avg: -1349.6005 (0.950)
Step: 3599, Reward: -1130.5236 [129.73], Avg: -1344.6367 (0.947)
Step: 3799, Reward: -1230.1826 [59.47], Avg: -1341.7430 (0.945)
Step: 3999, Reward: -1283.4860 [37.23], Avg: -1340.6915 (0.942)
Step: 4199, Reward: -1195.8970 [117.70], Avg: -1339.4012 (0.939)
Step: 4399, Reward: -1320.2023 [29.65], Avg: -1339.8760 (0.936)
Step: 4599, Reward: -1353.4281 [81.89], Avg: -1344.0256 (0.933)
Step: 4799, Reward: -1378.4716 [38.96], Avg: -1347.0842 (0.930)
Step: 4999, Reward: -1398.9043 [83.63], Avg: -1352.5020 (0.928)
Step: 5199, Reward: -1321.5430 [130.28], Avg: -1356.3221 (0.925)
Step: 5399, Reward: -1375.8248 [58.24], Avg: -1359.2014 (0.922)
Step: 5599, Reward: -1406.0117 [82.69], Avg: -1363.8263 (0.919)
Step: 5799, Reward: -1424.4912 [36.80], Avg: -1367.1872 (0.917)
Step: 5999, Reward: -1375.7174 [27.70], Avg: -1368.3947 (0.914)
Step: 6199, Reward: -1349.0147 [48.73], Avg: -1369.3416 (0.911)
Step: 6399, Reward: -1304.5642 [97.30], Avg: -1370.3580 (0.908)
Step: 6599, Reward: -1248.3349 [58.00], Avg: -1368.4181 (0.906)
Step: 6799, Reward: -1297.9932 [48.88], Avg: -1367.7843 (0.903)
Step: 6999, Reward: -1253.1500 [82.98], Avg: -1366.8798 (0.900)
Step: 7199, Reward: -1285.7501 [55.92], Avg: -1366.1795 (0.897)
Step: 7399, Reward: -1224.4390 [104.07], Avg: -1365.1614 (0.895)
Step: 7599, Reward: -1116.2353 [50.04], Avg: -1359.9276 (0.892)
Step: 7799, Reward: -1193.2903 [73.43], Avg: -1357.5378 (0.889)
Step: 7999, Reward: -1167.0208 [17.68], Avg: -1353.2170 (0.887)
Step: 8199, Reward: -1198.1476 [39.77], Avg: -1350.4047 (0.884)
Step: 8399, Reward: -1206.7201 [119.82], Avg: -1349.8365 (0.881)
Step: 8599, Reward: -1139.6623 [139.43], Avg: -1348.1912 (0.879)
Step: 8799, Reward: -1146.8564 [73.54], Avg: -1345.2869 (0.876)
Step: 8999, Reward: -1067.7770 [103.24], Avg: -1341.4143 (0.874)
Step: 9199, Reward: -1161.5700 [89.27], Avg: -1339.4454 (0.871)
Step: 9399, Reward: -1042.9265 [82.93], Avg: -1334.9009 (0.868)
Step: 9599, Reward: -1049.1682 [93.14], Avg: -1330.8885 (0.866)
Step: 9799, Reward: -1026.9269 [97.23], Avg: -1326.6695 (0.863)
Step: 9999, Reward: -1157.3725 [57.25], Avg: -1324.4286 (0.861)
Step: 10199, Reward: -973.3537 [73.37], Avg: -1318.9834 (0.858)
Step: 10399, Reward: -925.2500 [65.33], Avg: -1312.6680 (0.855)
Step: 10599, Reward: -1010.9966 [71.41], Avg: -1308.3235 (0.853)
Step: 10799, Reward: -993.1077 [63.12], Avg: -1303.6549 (0.850)
Step: 10999, Reward: -945.4290 [52.61], Avg: -1298.0983 (0.848)
Step: 11199, Reward: -933.2260 [77.14], Avg: -1292.9602 (0.845)
Step: 11399, Reward: -946.6051 [63.65], Avg: -1288.0003 (0.843)
Step: 11599, Reward: -908.4993 [138.04], Avg: -1283.8372 (0.840)
Step: 11799, Reward: -931.4964 [112.07], Avg: -1279.7649 (0.838)
Step: 11999, Reward: -1010.4807 [75.58], Avg: -1276.5364 (0.835)
Step: 12199, Reward: -1007.2993 [80.27], Avg: -1273.4385 (0.833)
Step: 12399, Reward: -1050.8253 [68.03], Avg: -1270.9452 (0.830)
Step: 12599, Reward: -968.1020 [44.56], Avg: -1266.8455 (0.828)
Step: 12799, Reward: -933.7824 [93.37], Avg: -1263.1003 (0.825)
Step: 12999, Reward: -885.8708 [56.84], Avg: -1258.1712 (0.823)
Step: 13199, Reward: -960.0190 [90.08], Avg: -1255.0186 (0.820)
Step: 13399, Reward: -871.1007 [59.82], Avg: -1250.1813 (0.818)
Step: 13599, Reward: -843.1272 [64.40], Avg: -1245.1424 (0.815)
Step: 13799, Reward: -841.7426 [48.90], Avg: -1240.0046 (0.813)
Step: 13999, Reward: -819.6965 [180.76], Avg: -1236.5825 (0.810)
Step: 14199, Reward: -921.8836 [114.39], Avg: -1233.7613 (0.808)
Step: 14399, Reward: -876.9429 [61.24], Avg: -1229.6561 (0.805)
Step: 14599, Reward: -846.5598 [82.82], Avg: -1225.5428 (0.803)
Step: 14799, Reward: -884.0720 [88.98], Avg: -1222.1309 (0.801)
Step: 14999, Reward: -904.1664 [87.91], Avg: -1219.0634 (0.798)
Step: 15199, Reward: -908.7907 [53.77], Avg: -1215.6884 (0.796)
Step: 15399, Reward: -874.3558 [113.87], Avg: -1212.7344 (0.793)
Step: 15599, Reward: -880.4798 [110.67], Avg: -1209.8936 (0.791)
Step: 15799, Reward: -874.9084 [68.79], Avg: -1206.5240 (0.789)
Step: 15999, Reward: -891.4168 [38.85], Avg: -1203.0708 (0.786)
Step: 16199, Reward: -829.4019 [54.04], Avg: -1199.1247 (0.784)
Step: 16399, Reward: -862.9516 [94.77], Avg: -1196.1808 (0.782)
Step: 16599, Reward: -932.7144 [64.49], Avg: -1193.7836 (0.779)
Step: 16799, Reward: -879.1305 [68.66], Avg: -1190.8551 (0.777)
Step: 16999, Reward: -892.2692 [64.64], Avg: -1188.1028 (0.775)
Step: 17199, Reward: -836.1913 [64.69], Avg: -1184.7631 (0.772)
Step: 17399, Reward: -886.3268 [87.29], Avg: -1182.3361 (0.770)
Step: 17599, Reward: -854.1280 [36.72], Avg: -1179.0237 (0.768)
Step: 17799, Reward: -876.8278 [25.51], Avg: -1175.9150 (0.765)
Step: 17999, Reward: -834.2553 [78.34], Avg: -1172.9892 (0.763)
Step: 18199, Reward: -755.6750 [110.82], Avg: -1169.6211 (0.761)
Step: 18399, Reward: -831.9991 [51.03], Avg: -1166.5060 (0.758)
Step: 18599, Reward: -813.6235 [107.34], Avg: -1163.8657 (0.756)
Step: 18799, Reward: -799.0630 [50.05], Avg: -1160.5173 (0.754)
Step: 18999, Reward: -729.0245 [108.79], Avg: -1157.1204 (0.752)
Step: 19199, Reward: -751.3978 [75.41], Avg: -1153.6796 (0.749)
Step: 19399, Reward: -726.0017 [44.65], Avg: -1149.7309 (0.747)
Step: 19599, Reward: -703.1260 [59.39], Avg: -1145.7798 (0.745)
Step: 19799, Reward: -729.9831 [37.15], Avg: -1141.9551 (0.743)
Step: 19999, Reward: -711.0606 [51.76], Avg: -1138.1638 (0.740)
Step: 20199, Reward: -806.2662 [174.12], Avg: -1136.6017 (0.738)
Step: 20399, Reward: -762.1502 [55.30], Avg: -1133.4727 (0.736)
Step: 20599, Reward: -690.5324 [102.38], Avg: -1130.1663 (0.734)
Step: 20799, Reward: -742.9868 [66.78], Avg: -1127.0855 (0.732)
Step: 20999, Reward: -712.7024 [52.59], Avg: -1123.6399 (0.729)
Step: 21199, Reward: -718.1675 [118.19], Avg: -1120.9297 (0.727)
Step: 21399, Reward: -707.3144 [126.94], Avg: -1118.2505 (0.725)
Step: 21599, Reward: -736.2176 [118.37], Avg: -1115.8092 (0.723)
Step: 21799, Reward: -734.8652 [65.54], Avg: -1112.9155 (0.721)
Step: 21999, Reward: -637.9255 [84.74], Avg: -1109.3678 (0.719)
Step: 22199, Reward: -616.6135 [107.64], Avg: -1105.8983 (0.716)
Step: 22399, Reward: -661.1514 [95.92], Avg: -1102.7838 (0.714)
Step: 22599, Reward: -593.0528 [156.62], Avg: -1099.6588 (0.712)
Step: 22799, Reward: -555.7807 [93.44], Avg: -1095.7077 (0.710)
Step: 22999, Reward: -482.0054 [90.04], Avg: -1091.1541 (0.708)
Step: 23199, Reward: -499.2486 [71.74], Avg: -1086.6699 (0.706)
Step: 23399, Reward: -506.6548 [79.00], Avg: -1082.3878 (0.704)
Step: 23599, Reward: -504.5850 [10.80], Avg: -1077.5827 (0.702)
Step: 23799, Reward: -401.3814 [123.43], Avg: -1072.9375 (0.699)
Step: 23999, Reward: -451.3794 [49.80], Avg: -1068.1728 (0.697)
Step: 24199, Reward: -318.5536 [126.45], Avg: -1063.0227 (0.695)
Step: 24399, Reward: -402.9388 [92.24], Avg: -1058.3682 (0.693)
Step: 24599, Reward: -261.2713 [97.02], Avg: -1052.6765 (0.691)
Step: 24799, Reward: -326.6061 [125.85], Avg: -1047.8360 (0.689)
Step: 24999, Reward: -189.9614 [196.70], Avg: -1042.5466 (0.687)
Step: 25199, Reward: -309.3072 [164.87], Avg: -1038.0358 (0.685)
Step: 25399, Reward: -173.5515 [56.18], Avg: -1031.6712 (0.683)
Step: 25599, Reward: -129.3976 [80.41], Avg: -1025.2503 (0.681)
Step: 25799, Reward: -279.1643 [202.24], Avg: -1021.0345 (0.679)
Step: 25999, Reward: -153.7124 [50.23], Avg: -1014.7492 (0.677)
Step: 26199, Reward: -153.9639 [92.50], Avg: -1008.8844 (0.675)
Step: 26399, Reward: -190.4957 [79.33], Avg: -1003.2854 (0.673)
Step: 26599, Reward: -229.7015 [106.37], Avg: -998.2688 (0.671)
Step: 26799, Reward: -240.1653 [101.24], Avg: -993.3668 (0.669)
Step: 26999, Reward: -175.3554 [121.71], Avg: -988.2091 (0.667)
Step: 27199, Reward: -157.4724 [63.10], Avg: -982.5647 (0.665)
Step: 27399, Reward: -174.0785 [56.21], Avg: -977.0736 (0.663)
Step: 27599, Reward: -248.5904 [78.26], Avg: -972.3618 (0.661)
Step: 27799, Reward: -101.1921 [49.24], Avg: -966.4487 (0.659)
Step: 27999, Reward: -123.6159 [72.91], Avg: -960.9492 (0.657)
Step: 28199, Reward: -224.1348 [120.74], Avg: -956.5799 (0.655)
Step: 28399, Reward: -193.2356 [57.82], Avg: -951.6114 (0.653)
Step: 28599, Reward: -200.8647 [58.67], Avg: -946.7717 (0.651)
Step: 28799, Reward: -245.8789 [110.23], Avg: -942.6699 (0.649)
Step: 28999, Reward: -194.6869 [140.34], Avg: -938.4793 (0.647)
Step: 29199, Reward: -195.1860 [95.03], Avg: -934.0391 (0.645)
Step: 29399, Reward: -167.4556 [93.58], Avg: -929.4608 (0.643)
Step: 29599, Reward: -237.0142 [100.86], Avg: -925.4637 (0.641)
Step: 29799, Reward: -196.7693 [56.66], Avg: -920.9534 (0.639)
Step: 29999, Reward: -123.2218 [72.86], Avg: -916.1209 (0.637)
Step: 30199, Reward: -220.1988 [118.67], Avg: -912.2980 (0.635)
Step: 30399, Reward: -129.0793 [137.95], Avg: -908.0528 (0.633)
Step: 30599, Reward: -125.3429 [77.31], Avg: -903.4423 (0.631)
Step: 30799, Reward: -151.6498 [143.19], Avg: -899.4904 (0.630)
Step: 30999, Reward: -165.3693 [111.62], Avg: -895.4742 (0.628)
Step: 31199, Reward: -183.2231 [117.61], Avg: -891.6624 (0.626)
Step: 31399, Reward: -220.7016 [89.48], Avg: -887.9587 (0.624)
Step: 31599, Reward: -124.1838 [77.29], Avg: -883.6139 (0.622)
Step: 31799, Reward: -175.2359 [58.18], Avg: -879.5246 (0.620)
Step: 31999, Reward: -237.7282 [124.39], Avg: -876.2909 (0.618)
Step: 32199, Reward: -198.6707 [124.35], Avg: -872.8544 (0.616)
Step: 32399, Reward: -151.4001 [93.67], Avg: -868.9792 (0.615)
Step: 32599, Reward: -228.7374 [149.72], Avg: -865.9698 (0.613)
Step: 32799, Reward: -222.5306 [95.72], Avg: -862.6301 (0.611)
Step: 32999, Reward: -121.4617 [70.99], Avg: -858.5684 (0.609)
Step: 33199, Reward: -237.1874 [115.14], Avg: -855.5187 (0.607)
Step: 33399, Reward: -169.6938 [122.34], Avg: -852.1446 (0.605)
Step: 33599, Reward: -149.5340 [48.49], Avg: -848.2510 (0.604)
Step: 33799, Reward: -101.6188 [49.13], Avg: -844.1238 (0.602)
Step: 33999, Reward: -104.1927 [49.92], Avg: -840.0649 (0.600)
Step: 34199, Reward: -187.9938 [135.99], Avg: -837.0469 (0.598)
Step: 34399, Reward: -240.4281 [71.57], Avg: -833.9943 (0.596)
Step: 34599, Reward: -514.4540 [297.85], Avg: -833.8689 (0.595)
Step: 34799, Reward: -607.9614 [315.89], Avg: -834.3861 (0.593)
Step: 34999, Reward: -348.7881 [271.06], Avg: -833.1602 (0.591)
Step: 35199, Reward: -347.6135 [229.10], Avg: -831.7031 (0.589)
Step: 35399, Reward: -217.7882 [133.71], Avg: -828.9900 (0.588)
Step: 35599, Reward: -214.7824 [45.93], Avg: -825.7975 (0.586)
Step: 35799, Reward: -148.5488 [92.35], Avg: -822.5299 (0.584)
Step: 35999, Reward: -195.6320 [161.90], Avg: -819.9465 (0.582)
Step: 36199, Reward: -179.4936 [107.22], Avg: -817.0005 (0.581)
Step: 36399, Reward: -259.6942 [84.97], Avg: -814.4053 (0.579)
Step: 36599, Reward: -191.2437 [79.56], Avg: -811.4348 (0.577)
Step: 36799, Reward: -224.0647 [141.14], Avg: -809.0096 (0.575)
Step: 36999, Reward: -98.4357 [90.66], Avg: -805.6587 (0.574)
Step: 37199, Reward: -180.1596 [70.49], Avg: -802.6748 (0.572)
Step: 37399, Reward: -98.7996 [90.89], Avg: -799.3968 (0.570)
Step: 37599, Reward: -125.3119 [78.68], Avg: -796.2297 (0.568)
Step: 37799, Reward: -124.6998 [2.25], Avg: -792.6885 (0.567)
Step: 37999, Reward: -155.9176 [132.33], Avg: -790.0336 (0.565)
Step: 38199, Reward: -223.2102 [93.60], Avg: -787.5560 (0.563)
Step: 38399, Reward: -150.0004 [48.07], Avg: -784.4857 (0.562)
Step: 38599, Reward: -120.0771 [103.73], Avg: -781.5807 (0.560)
Step: 38799, Reward: -198.3220 [62.19], Avg: -778.8948 (0.558)
Step: 38999, Reward: -74.2188 [57.78], Avg: -775.5773 (0.557)
Step: 39199, Reward: -280.5617 [56.39], Avg: -773.3395 (0.555)
Step: 39399, Reward: -247.9055 [128.34], Avg: -771.3238 (0.553)
Step: 39599, Reward: -160.5977 [81.43], Avg: -768.6506 (0.552)
Step: 39799, Reward: -123.8106 [77.33], Avg: -765.7988 (0.550)
Step: 39999, Reward: -121.1749 [72.14], Avg: -762.9363 (0.548)
Step: 40199, Reward: -124.7202 [5.26], Avg: -759.7873 (0.547)
Step: 40399, Reward: -203.0047 [100.29], Avg: -757.5275 (0.545)
Step: 40599, Reward: -49.6529 [58.56], Avg: -754.3289 (0.543)
Step: 40799, Reward: -153.1571 [58.36], Avg: -751.6680 (0.542)
Step: 40999, Reward: -273.4774 [62.01], Avg: -749.6379 (0.540)
Step: 41199, Reward: -167.0067 [56.53], Avg: -747.0840 (0.539)
Step: 41399, Reward: -175.1763 [106.15], Avg: -744.8340 (0.537)
Step: 41599, Reward: -171.3645 [62.45], Avg: -742.3772 (0.535)
Step: 41799, Reward: -223.3356 [91.74], Avg: -740.3327 (0.534)
Step: 41999, Reward: -146.7404 [42.68], Avg: -737.7093 (0.532)
Step: 42199, Reward: -256.2053 [328.89], Avg: -736.9860 (0.530)
Step: 42399, Reward: -367.4800 [261.37], Avg: -736.4759 (0.529)
Step: 42599, Reward: -534.4615 [311.16], Avg: -736.9884 (0.527)
Step: 42799, Reward: -322.3144 [102.75], Avg: -735.5308 (0.526)
Step: 42999, Reward: -476.3603 [167.23], Avg: -735.1032 (0.524)
Step: 43199, Reward: -261.2972 [90.09], Avg: -733.3267 (0.523)
Step: 43399, Reward: -77.4115 [61.13], Avg: -730.5858 (0.521)
Step: 43599, Reward: -98.2374 [87.82], Avg: -728.0880 (0.519)
Step: 43799, Reward: -168.7194 [58.79], Avg: -725.8022 (0.518)
Step: 43999, Reward: -169.5790 [56.64], Avg: -723.5314 (0.516)
Step: 44199, Reward: -240.4324 [113.51], Avg: -721.8590 (0.515)
Step: 44399, Reward: -181.9351 [186.56], Avg: -720.2673 (0.513)
Step: 44599, Reward: -220.6376 [143.31], Avg: -718.6694 (0.512)
Step: 44799, Reward: -217.2382 [114.50], Avg: -716.9421 (0.510)
Step: 44999, Reward: -149.9775 [51.52], Avg: -714.6512 (0.509)
Step: 45199, Reward: -201.3857 [103.73], Avg: -712.8391 (0.507)
Step: 45399, Reward: -145.2697 [46.49], Avg: -710.5436 (0.506)
Step: 45599, Reward: -151.2775 [119.36], Avg: -708.6141 (0.504)
Step: 45799, Reward: -149.6109 [52.41], Avg: -706.4019 (0.503)
Step: 45999, Reward: -100.7064 [92.32], Avg: -704.1699 (0.501)
Step: 46199, Reward: -145.0706 [46.96], Avg: -701.9528 (0.500)
Step: 46399, Reward: -225.5484 [102.50], Avg: -700.3412 (0.498)
Step: 46599, Reward: -125.0612 [78.11], Avg: -698.2074 (0.497)
Step: 46799, Reward: -199.0717 [63.32], Avg: -696.3449 (0.495)
Step: 46999, Reward: -122.7500 [1.76], Avg: -693.9116 (0.494)
Step: 47199, Reward: -169.7797 [61.48], Avg: -691.9512 (0.492)
Step: 47399, Reward: -99.4274 [49.20], Avg: -689.6587 (0.491)
Step: 47599, Reward: -121.6098 [75.97], Avg: -687.5911 (0.489)
Step: 47799, Reward: -98.2256 [88.25], Avg: -685.4944 (0.488)
Step: 47999, Reward: -147.3015 [118.55], Avg: -683.7459 (0.486)
Step: 48199, Reward: -219.8121 [50.08], Avg: -682.0286 (0.485)
Step: 48399, Reward: -98.8555 [92.10], Avg: -679.9994 (0.483)
Step: 48599, Reward: -475.0086 [477.62], Avg: -681.1213 (0.482)
Step: 48799, Reward: -320.4109 [402.96], Avg: -681.2945 (0.480)
Step: 48999, Reward: -172.3894 [97.98], Avg: -679.6172 (0.479)
Step: 49199, Reward: -118.5787 [102.16], Avg: -677.7518 (0.478)
Step: 49399, Reward: -100.5798 [141.63], Avg: -675.9885 (0.476)
Step: 49599, Reward: -74.7372 [95.95], Avg: -673.9510 (0.475)
Step: 49799, Reward: -248.6528 [105.18], Avg: -672.6654 (0.473)
Step: 49999, Reward: -172.2193 [97.12], Avg: -671.0520 (0.472)
Step: 50199, Reward: -221.6919 [46.59], Avg: -669.4474 (0.470)
Step: 50399, Reward: -246.9660 [81.45], Avg: -668.0941 (0.469)
Step: 50599, Reward: -244.3264 [172.56], Avg: -667.1012 (0.468)
Step: 50799, Reward: -217.0657 [45.48], Avg: -665.5084 (0.466)
Step: 50999, Reward: -175.6288 [98.92], Avg: -663.9753 (0.465)
Step: 51199, Reward: -238.5515 [12.98], Avg: -662.3641 (0.463)
Step: 51399, Reward: -174.7871 [123.51], Avg: -660.9476 (0.462)
Step: 51599, Reward: -166.8280 [92.88], Avg: -659.3923 (0.461)
Step: 51799, Reward: -148.8377 [90.98], Avg: -657.7724 (0.459)
Step: 51999, Reward: -271.3852 [94.25], Avg: -656.6487 (0.458)
Step: 52199, Reward: -264.1772 [92.75], Avg: -655.5004 (0.456)
Step: 52399, Reward: -99.6634 [90.76], Avg: -653.7253 (0.455)
Step: 52599, Reward: -226.4900 [148.47], Avg: -652.6654 (0.454)
Step: 52799, Reward: -250.0467 [115.22], Avg: -651.5767 (0.452)
Step: 52999, Reward: -169.8737 [144.69], Avg: -650.3050 (0.451)
Step: 53199, Reward: -245.8333 [83.60], Avg: -649.0987 (0.450)
Step: 53399, Reward: -164.9573 [112.54], Avg: -647.7069 (0.448)
Step: 53599, Reward: -197.5398 [56.73], Avg: -646.2389 (0.447)
Step: 53799, Reward: -189.8703 [87.05], Avg: -644.8659 (0.446)
Step: 53999, Reward: -242.2021 [110.68], Avg: -643.7845 (0.444)
Step: 54199, Reward: -146.3416 [48.24], Avg: -642.1269 (0.443)
Step: 54399, Reward: -169.2079 [94.69], Avg: -640.7364 (0.442)
Step: 54599, Reward: -194.6076 [59.38], Avg: -639.3197 (0.440)
Step: 54799, Reward: -248.1360 [133.55], Avg: -638.3795 (0.439)
Step: 54999, Reward: -133.7205 [95.99], Avg: -636.8934 (0.438)
Step: 55199, Reward: -195.9394 [122.29], Avg: -635.7388 (0.436)
Step: 55399, Reward: -144.4578 [136.73], Avg: -634.4589 (0.435)
Step: 55599, Reward: -200.2414 [67.62], Avg: -633.1402 (0.434)
Step: 55799, Reward: -100.3332 [49.50], Avg: -631.4079 (0.432)
Step: 55999, Reward: -238.5118 [105.37], Avg: -630.3810 (0.431)
Step: 56199, Reward: -122.1969 [77.80], Avg: -628.8494 (0.430)
Step: 56399, Reward: -123.6681 [80.80], Avg: -627.3445 (0.429)
Step: 56599, Reward: -265.7711 [77.15], Avg: -626.3395 (0.427)
Step: 56799, Reward: -129.7328 [85.70], Avg: -624.8926 (0.426)
Step: 56999, Reward: -96.4181 [88.37], Avg: -623.3484 (0.425)
Step: 57199, Reward: -245.2159 [75.27], Avg: -622.2894 (0.423)
Step: 57399, Reward: -164.3850 [85.65], Avg: -620.9924 (0.422)
Step: 57599, Reward: -119.7649 [72.21], Avg: -619.5027 (0.421)
Step: 57799, Reward: -147.8215 [49.62], Avg: -618.0423 (0.420)
Step: 57999, Reward: -160.6867 [110.43], Avg: -616.8460 (0.418)
Step: 58199, Reward: -195.6499 [98.43], Avg: -615.7369 (0.417)
Step: 58399, Reward: -209.5694 [168.78], Avg: -614.9239 (0.416)
Step: 58599, Reward: -97.8350 [90.64], Avg: -613.4684 (0.415)
Step: 58799, Reward: -143.4641 [43.90], Avg: -612.0191 (0.413)
Step: 58999, Reward: -119.2402 [73.95], Avg: -610.5993 (0.412)
Step: 59199, Reward: -161.7729 [147.81], Avg: -609.5824 (0.411)
Step: 59399, Reward: -174.0903 [71.76], Avg: -608.3577 (0.410)
Step: 59599, Reward: -192.3976 [92.48], Avg: -607.2722 (0.408)
Step: 59799, Reward: -267.1706 [116.43], Avg: -606.5242 (0.407)
Step: 59999, Reward: -171.8193 [97.32], Avg: -605.3996 (0.406)
Step: 60199, Reward: -142.6938 [87.97], Avg: -604.1546 (0.405)
Step: 60399, Reward: -121.2470 [76.67], Avg: -602.8094 (0.404)
Step: 60599, Reward: -155.7839 [104.82], Avg: -601.6800 (0.402)
Step: 60799, Reward: -100.2637 [49.41], Avg: -600.1932 (0.401)
Step: 60999, Reward: -272.6863 [68.42], Avg: -599.3437 (0.400)
Step: 61199, Reward: -77.6221 [60.95], Avg: -597.8379 (0.399)
Step: 61399, Reward: -141.5998 [85.63], Avg: -596.6307 (0.398)
Step: 61599, Reward: -214.2680 [86.50], Avg: -595.6701 (0.396)
Step: 61799, Reward: -118.7332 [3.02], Avg: -594.1364 (0.395)
Step: 61999, Reward: -119.9499 [73.94], Avg: -592.8453 (0.394)
Step: 62199, Reward: -97.2064 [47.85], Avg: -591.4055 (0.393)
Step: 62399, Reward: -217.8477 [116.84], Avg: -590.5827 (0.392)
Step: 62599, Reward: -155.4073 [71.71], Avg: -589.4215 (0.390)
Step: 62799, Reward: -145.5183 [116.70], Avg: -588.3794 (0.389)
Step: 62999, Reward: -146.1826 [88.77], Avg: -587.2574 (0.388)
Step: 63199, Reward: -219.2794 [87.84], Avg: -586.3709 (0.387)
Step: 63399, Reward: -194.4023 [94.30], Avg: -585.4319 (0.386)
Step: 63599, Reward: -148.0190 [90.23], Avg: -584.3401 (0.385)
Step: 63799, Reward: -425.3119 [279.92], Avg: -584.7191 (0.383)
Step: 63999, Reward: -578.9550 [348.27], Avg: -585.7894 (0.382)
Step: 64199, Reward: -171.4288 [121.38], Avg: -584.8767 (0.381)
Step: 64399, Reward: -174.5153 [59.60], Avg: -583.7874 (0.380)
Step: 64599, Reward: -124.3395 [76.21], Avg: -582.6009 (0.379)
Step: 64799, Reward: -196.5309 [61.19], Avg: -581.5982 (0.378)
Step: 64999, Reward: -213.1039 [214.61], Avg: -581.1247 (0.377)
Step: 65199, Reward: -213.3880 [132.49], Avg: -580.4031 (0.376)
Step: 65399, Reward: -128.6836 [113.47], Avg: -579.3687 (0.374)
Step: 65599, Reward: -170.9029 [59.58], Avg: -578.3050 (0.373)
Step: 65799, Reward: -99.5094 [90.07], Avg: -577.1235 (0.372)
Step: 65999, Reward: -199.1941 [101.04], Avg: -576.2844 (0.371)
Step: 66199, Reward: -172.1250 [59.16], Avg: -575.2421 (0.370)
Step: 66399, Reward: -196.7100 [58.24], Avg: -574.2774 (0.369)
Step: 66599, Reward: -75.4293 [59.24], Avg: -572.9573 (0.368)
Step: 66799, Reward: -173.9786 [63.36], Avg: -571.9524 (0.367)
Step: 66999, Reward: -124.0225 [153.50], Avg: -571.0735 (0.365)
Step: 67199, Reward: -98.7440 [48.32], Avg: -569.8116 (0.364)
Step: 67399, Reward: -99.6359 [93.07], Avg: -568.6926 (0.363)
Step: 67599, Reward: -141.2015 [85.59], Avg: -567.6810 (0.362)
Step: 67799, Reward: -172.7060 [63.12], Avg: -566.7021 (0.361)
Step: 67999, Reward: -197.5124 [121.33], Avg: -565.9731 (0.360)
Step: 68199, Reward: -173.2788 [60.68], Avg: -564.9995 (0.359)
Step: 68399, Reward: -97.1496 [89.08], Avg: -563.8920 (0.358)
Step: 68599, Reward: -167.8442 [56.44], Avg: -562.9018 (0.357)
Step: 68799, Reward: -131.3194 [87.49], Avg: -561.9016 (0.356)
Step: 68999, Reward: -169.7414 [88.96], Avg: -561.0227 (0.355)
Step: 69199, Reward: -237.5543 [4.45], Avg: -560.1007 (0.354)
Step: 69399, Reward: -218.3637 [95.77], Avg: -559.3919 (0.353)
Step: 69599, Reward: -99.6289 [49.14], Avg: -558.2119 (0.351)
Step: 69799, Reward: -86.7168 [117.70], Avg: -557.1982 (0.350)
Step: 69999, Reward: -98.3979 [89.55], Avg: -556.1432 (0.349)
Step: 70199, Reward: -147.3984 [92.67], Avg: -555.2427 (0.348)
Step: 70399, Reward: -224.5622 [119.57], Avg: -554.6430 (0.347)
Step: 70599, Reward: -240.4534 [70.20], Avg: -553.9518 (0.346)
Step: 70799, Reward: -330.1864 [70.25], Avg: -553.5181 (0.345)
Step: 70999, Reward: -194.0856 [91.05], Avg: -552.7621 (0.344)
Step: 71199, Reward: -178.3735 [148.36], Avg: -552.1272 (0.343)
Step: 71399, Reward: -154.5233 [93.38], Avg: -551.2750 (0.342)
Step: 71599, Reward: -132.1361 [112.80], Avg: -550.4193 (0.341)
Step: 71799, Reward: -201.3408 [62.99], Avg: -549.6224 (0.340)
Step: 71999, Reward: -238.7010 [97.98], Avg: -549.0309 (0.339)
Step: 72199, Reward: -155.2159 [91.94], Avg: -548.1947 (0.338)
Step: 72399, Reward: -537.6431 [530.64], Avg: -549.6314 (0.337)
Step: 72599, Reward: -733.7546 [478.11], Avg: -551.4558 (0.336)
Step: 72799, Reward: -431.6544 [432.28], Avg: -552.3142 (0.335)
Step: 72999, Reward: -512.6212 [412.78], Avg: -553.3364 (0.334)
Step: 73199, Reward: -831.2948 [528.11], Avg: -555.5387 (0.333)
Step: 73399, Reward: -535.8153 [399.14], Avg: -556.5726 (0.332)
Step: 73599, Reward: -604.9193 [510.25], Avg: -558.0905 (0.331)
Step: 73799, Reward: -438.1977 [455.24], Avg: -558.9993 (0.330)
Step: 73999, Reward: -1067.1526 [360.45], Avg: -561.3469 (0.329)
Step: 74199, Reward: -627.6645 [519.73], Avg: -562.9265 (0.328)
Step: 74399, Reward: -385.7555 [481.38], Avg: -563.7443 (0.327)
Step: 74599, Reward: -195.9462 [96.70], Avg: -563.0175 (0.326)
Step: 74799, Reward: -418.9355 [432.81], Avg: -563.7895 (0.325)
Step: 74999, Reward: -687.8855 [463.70], Avg: -565.3570 (0.324)
Step: 75199, Reward: -616.4962 [547.19], Avg: -566.9482 (0.323)
Step: 75399, Reward: -662.6497 [512.89], Avg: -568.5626 (0.322)
Step: 75599, Reward: -321.3708 [60.88], Avg: -568.0697 (0.321)
Step: 75799, Reward: -599.8726 [541.79], Avg: -569.5831 (0.320)
Step: 75999, Reward: -843.0436 [592.62], Avg: -571.8623 (0.319)
Step: 76199, Reward: -216.5333 [113.97], Avg: -571.2288 (0.318)
Step: 76399, Reward: -546.8086 [356.78], Avg: -572.0988 (0.317)
Step: 76599, Reward: -252.8649 [141.39], Avg: -571.6345 (0.316)
Step: 76799, Reward: -440.4975 [454.21], Avg: -572.4758 (0.315)
Step: 76999, Reward: -385.7900 [480.46], Avg: -573.2389 (0.315)
Step: 77199, Reward: -409.8984 [469.44], Avg: -574.0319 (0.314)
Step: 77399, Reward: -549.8984 [373.85], Avg: -574.9355 (0.313)
Step: 77599, Reward: -623.6358 [526.54], Avg: -576.4181 (0.312)
Step: 77799, Reward: -349.8541 [403.91], Avg: -576.8740 (0.311)
Step: 77999, Reward: -194.8150 [122.16], Avg: -576.2076 (0.310)
Step: 78199, Reward: -512.4451 [358.30], Avg: -576.9609 (0.309)
Step: 78399, Reward: -605.5017 [547.70], Avg: -578.4309 (0.308)
Step: 78599, Reward: -197.6617 [166.24], Avg: -577.8850 (0.307)
Step: 78799, Reward: -453.2143 [368.41], Avg: -578.5036 (0.306)
Step: 78999, Reward: -242.3513 [77.19], Avg: -577.8480 (0.305)
Step: 79199, Reward: -461.4038 [438.21], Avg: -578.6606 (0.304)
Step: 79399, Reward: -124.8536 [109.73], Avg: -577.7939 (0.303)
Step: 79599, Reward: -413.4904 [493.80], Avg: -578.6218 (0.302)
Step: 79799, Reward: -577.3114 [509.82], Avg: -579.8962 (0.302)
Step: 79999, Reward: -362.8600 [387.58], Avg: -580.3226 (0.301)
Step: 80199, Reward: -490.9245 [410.10], Avg: -581.1224 (0.300)
Step: 80399, Reward: -232.1845 [401.56], Avg: -581.2533 (0.299)
Step: 80599, Reward: -250.6453 [163.74], Avg: -580.8392 (0.298)
Step: 80799, Reward: -250.4872 [154.32], Avg: -580.4035 (0.297)
Step: 80999, Reward: -198.8883 [127.76], Avg: -579.7769 (0.296)
Step: 81199, Reward: -380.2363 [415.60], Avg: -580.3091 (0.295)
Step: 81399, Reward: -197.3899 [97.25], Avg: -579.6072 (0.294)
Step: 81599, Reward: -383.4819 [354.53], Avg: -579.9954 (0.294)
Step: 81799, Reward: -243.9460 [75.99], Avg: -579.3596 (0.293)
Step: 81999, Reward: -336.8021 [376.63], Avg: -579.6866 (0.292)
Step: 82199, Reward: -285.3337 [302.29], Avg: -579.7059 (0.291)
Step: 82399, Reward: -244.4720 [10.47], Avg: -578.9177 (0.290)
Step: 82599, Reward: -198.2648 [101.73], Avg: -578.2423 (0.289)
Step: 82799, Reward: -285.6300 [49.19], Avg: -577.6543 (0.288)
Step: 82999, Reward: -244.5753 [75.92], Avg: -577.0347 (0.287)
Step: 83199, Reward: -292.1920 [159.42], Avg: -576.7332 (0.287)
Step: 83399, Reward: -100.7959 [120.01], Avg: -575.8796 (0.286)
Step: 83599, Reward: -224.7513 [97.20], Avg: -575.2721 (0.285)
Step: 83799, Reward: -216.6378 [118.61], Avg: -574.6993 (0.284)
Step: 83999, Reward: -204.5995 [174.90], Avg: -574.2345 (0.283)
Step: 84199, Reward: -239.8946 [75.83], Avg: -573.6205 (0.282)
Step: 84399, Reward: -169.0354 [96.67], Avg: -572.8908 (0.281)
Step: 84599, Reward: -165.7939 [91.80], Avg: -572.1454 (0.281)
Step: 84799, Reward: -248.5334 [77.77], Avg: -571.5656 (0.280)
Step: 84999, Reward: -193.5790 [60.28], Avg: -570.8181 (0.279)
Step: 85199, Reward: -323.9205 [122.90], Avg: -570.5270 (0.278)
Step: 85399, Reward: -236.2486 [74.45], Avg: -569.9185 (0.277)
Step: 85599, Reward: -177.3267 [152.77], Avg: -569.3582 (0.276)
Step: 85799, Reward: -289.8782 [162.11], Avg: -569.0846 (0.276)
Step: 85999, Reward: -147.4692 [89.54], Avg: -568.3123 (0.275)
Step: 86199, Reward: -171.1316 [97.76], Avg: -567.6176 (0.274)
Step: 86399, Reward: -209.0360 [124.83], Avg: -567.0765 (0.273)
Step: 86599, Reward: -172.9776 [96.29], Avg: -566.3887 (0.272)
Step: 86799, Reward: -117.5668 [124.04], Avg: -565.6404 (0.271)
Step: 86999, Reward: -211.4559 [109.42], Avg: -565.0777 (0.271)
Step: 87199, Reward: -122.6200 [75.52], Avg: -564.2361 (0.270)
Step: 87399, Reward: -144.8831 [88.32], Avg: -563.4786 (0.269)
Step: 87599, Reward: -143.6581 [46.34], Avg: -562.6259 (0.268)
Step: 87799, Reward: -179.4145 [126.06], Avg: -562.0401 (0.267)
Step: 87999, Reward: -307.2851 [87.70], Avg: -561.6604 (0.267)
Step: 88199, Reward: -241.3086 [74.93], Avg: -561.1039 (0.266)
Step: 88399, Reward: -264.4822 [88.50], Avg: -560.6331 (0.265)
Step: 88599, Reward: -207.2614 [132.71], Avg: -560.1350 (0.264)
Step: 88799, Reward: -221.4488 [113.63], Avg: -559.6281 (0.263)
Step: 88999, Reward: -170.0856 [163.08], Avg: -559.1192 (0.263)
Step: 89199, Reward: -169.5839 [96.84], Avg: -558.4629 (0.262)
Step: 89399, Reward: -194.6717 [59.94], Avg: -557.7832 (0.261)
Step: 89599, Reward: -100.1433 [91.98], Avg: -556.9670 (0.260)
Step: 89799, Reward: -128.2966 [197.69], Avg: -556.4525 (0.259)
Step: 89999, Reward: -266.2519 [91.09], Avg: -556.0100 (0.259)
Step: 90199, Reward: -214.3559 [45.19], Avg: -555.3527 (0.258)
Step: 90399, Reward: -194.9908 [145.26], Avg: -554.8768 (0.257)
Step: 90599, Reward: -149.8368 [92.01], Avg: -554.1858 (0.256)
Step: 90799, Reward: -211.7468 [132.66], Avg: -553.7237 (0.256)
Step: 90999, Reward: -238.2485 [104.36], Avg: -553.2597 (0.255)
Step: 91199, Reward: -265.2618 [90.46], Avg: -552.8265 (0.254)
Step: 91399, Reward: -125.7787 [77.05], Avg: -552.0607 (0.253)
Step: 91599, Reward: -192.1525 [120.57], Avg: -551.5381 (0.253)
Step: 91799, Reward: -198.3023 [130.10], Avg: -551.0520 (0.252)
Step: 91999, Reward: -241.8672 [74.96], Avg: -550.5428 (0.251)
Step: 92199, Reward: -192.7296 [57.87], Avg: -549.8921 (0.250)
Step: 92399, Reward: -219.7419 [119.46], Avg: -549.4361 (0.250)
Step: 92599, Reward: -244.1342 [74.59], Avg: -548.9378 (0.249)
Step: 92799, Reward: -120.0052 [124.77], Avg: -548.2823 (0.248)
Step: 92999, Reward: -146.0964 [90.25], Avg: -547.6114 (0.247)
Step: 93199, Reward: -150.3709 [119.32], Avg: -547.0150 (0.247)
Step: 93399, Reward: -266.3918 [87.88], Avg: -546.6023 (0.246)
Step: 93599, Reward: -244.5979 [78.09], Avg: -546.1239 (0.245)
Step: 93799, Reward: -122.2109 [106.93], Avg: -545.4480 (0.244)
Step: 93999, Reward: -249.7176 [134.87], Avg: -545.1057 (0.244)
Step: 94199, Reward: -148.2047 [90.94], Avg: -544.4561 (0.243)
Step: 94399, Reward: -286.2456 [92.78], Avg: -544.1056 (0.242)
Step: 94599, Reward: -220.3380 [51.37], Avg: -543.5298 (0.241)
Step: 94799, Reward: -161.5839 [149.77], Avg: -543.0399 (0.241)
Step: 94999, Reward: -221.7012 [143.48], Avg: -542.6655 (0.240)
Step: 95199, Reward: -217.0363 [137.04], Avg: -542.2693 (0.239)
Step: 95399, Reward: -274.4677 [98.52], Avg: -541.9144 (0.239)
Step: 95599, Reward: -102.2513 [90.19], Avg: -541.1833 (0.238)
Step: 95799, Reward: -209.3301 [109.25], Avg: -540.7186 (0.237)
Step: 95999, Reward: -234.6981 [125.08], Avg: -540.3416 (0.236)
Step: 96199, Reward: -215.1789 [116.52], Avg: -539.9078 (0.236)
Step: 96399, Reward: -197.0206 [124.16], Avg: -539.4541 (0.235)
Step: 96599, Reward: -198.4997 [97.12], Avg: -538.9492 (0.234)
Step: 96799, Reward: -119.9522 [104.37], Avg: -538.2992 (0.234)
Step: 96999, Reward: -146.7006 [90.16], Avg: -537.6777 (0.233)
Step: 97199, Reward: -170.0994 [55.33], Avg: -537.0352 (0.232)
Step: 97399, Reward: -171.8180 [94.63], Avg: -536.4796 (0.231)
Step: 97599, Reward: -247.6167 [73.92], Avg: -536.0391 (0.231)
Step: 97799, Reward: -215.2022 [150.93], Avg: -535.6916 (0.230)
Step: 97999, Reward: -174.9448 [144.09], Avg: -535.2495 (0.229)
Step: 98199, Reward: -317.3592 [61.67], Avg: -534.9313 (0.229)
Step: 98399, Reward: -177.1905 [104.03], Avg: -534.4157 (0.228)
Step: 98599, Reward: -194.5999 [95.48], Avg: -533.9200 (0.227)
Step: 98799, Reward: -315.2925 [92.92], Avg: -533.6656 (0.227)
Step: 98999, Reward: -149.1751 [51.72], Avg: -532.9933 (0.226)
Step: 99199, Reward: -238.9287 [57.15], Avg: -532.5157 (0.225)
Step: 99399, Reward: -172.3504 [56.25], Avg: -531.9042 (0.225)
Step: 99599, Reward: -173.9719 [97.76], Avg: -531.3817 (0.224)
Step: 99799, Reward: -266.2969 [153.51], Avg: -531.1581 (0.223)
Step: 99999, Reward: -146.7108 [134.81], Avg: -530.6589 (0.223)
