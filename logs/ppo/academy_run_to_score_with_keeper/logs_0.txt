Model: <class 'models.ppo.PPOAgent'>, Dir: academy_run_to_score_with_keeper
num_envs: 16, state_size: (115,), action_size: [19], action_space: Discrete(19),

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.05				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) * critic_error.pow(2) * scale
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss.mean())
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		if done[0] or len(self.buffer) >= self.update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, scale=16*dones.size(0)/len(self.replay_buffer))

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "1_vs_1_easy", "5_vs_5", "11_vs_11_stochastic"]
env_name = gfb_envs[3]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.unwrapped.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class AsyncAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000, checkpoint=False):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = AsyncAgent(envs.state_size, envs.action_size, num_envs, model)
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.stack.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0]:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 399, Reward: -0.2000 [0.40], Avg: -0.6000 (1.000)
Step: 538, Reward: 0.0000 [0.00], Avg: -0.3000 (1.000)
Step: 603, Reward: 0.0000 [0.00], Avg: -0.2000 (1.000)
Step: 853, Reward: 0.0000 [0.00], Avg: -0.1500 (1.000)
Step: 1031, Reward: 0.0000 [0.00], Avg: -0.1200 (1.000)
Step: 1107, Reward: -0.2000 [0.40], Avg: -0.2000 (1.000)
Step: 1164, Reward: 0.0000 [0.00], Avg: -0.1714 (1.000)
Step: 1512, Reward: -0.2000 [0.40], Avg: -0.2250 (1.000)
Step: 1609, Reward: -0.2000 [0.40], Avg: -0.2667 (1.000)
Step: 1624, Reward: 0.0000 [0.00], Avg: -0.2400 (1.000)
Step: 1704, Reward: -0.2000 [0.40], Avg: -0.2727 (1.000)
Step: 2070, Reward: 0.0000 [0.00], Avg: -0.2500 (1.000)
Step: 2155, Reward: 0.0000 [0.00], Avg: -0.2308 (1.000)
Step: 2283, Reward: 0.0000 [0.00], Avg: -0.2143 (1.000)
Step: 2455, Reward: -0.2000 [0.40], Avg: -0.2400 (1.000)
Step: 2533, Reward: -0.2000 [0.40], Avg: -0.2625 (1.000)
Step: 2651, Reward: 0.0000 [0.00], Avg: -0.2471 (1.000)
Step: 2735, Reward: -0.2000 [0.40], Avg: -0.2667 (1.000)
Step: 2788, Reward: 0.0000 [0.00], Avg: -0.2526 (1.000)
Step: 2893, Reward: -0.2000 [0.40], Avg: -0.2700 (1.000)
Step: 3034, Reward: -0.2000 [0.40], Avg: -0.2857 (1.000)
Step: 3171, Reward: -0.2000 [0.40], Avg: -0.3000 (1.000)
Step: 3392, Reward: 0.0000 [0.00], Avg: -0.2870 (1.000)
Step: 3468, Reward: -0.4000 [0.49], Avg: -0.3121 (1.000)
Step: 3481, Reward: 0.0000 [0.00], Avg: -0.2996 (1.000)
Step: 3564, Reward: -0.4000 [0.49], Avg: -0.3223 (1.000)
Step: 3693, Reward: 0.0000 [0.00], Avg: -0.3104 (1.000)
Step: 4093, Reward: -0.4000 [0.49], Avg: -0.3311 (1.000)
Step: 4176, Reward: 0.0000 [0.00], Avg: -0.3196 (1.000)
Step: 4293, Reward: -0.2000 [0.40], Avg: -0.3290 (1.000)
Step: 4357, Reward: -0.2000 [0.40], Avg: -0.3377 (1.000)
Step: 4552, Reward: 0.0000 [0.00], Avg: -0.3272 (1.000)
Step: 4702, Reward: -0.2000 [0.40], Avg: -0.3354 (1.000)
Step: 4846, Reward: 0.0000 [0.00], Avg: -0.3256 (1.000)
Step: 4907, Reward: -0.2000 [0.40], Avg: -0.3334 (1.000)
Step: 4978, Reward: 0.0000 [0.00], Avg: -0.3242 (1.000)
Step: 5111, Reward: -0.4000 [0.49], Avg: -0.3394 (1.000)
Step: 5511, Reward: 0.0000 [0.00], Avg: -0.3305 (1.000)
Step: 5540, Reward: -0.2000 [0.40], Avg: -0.3374 (1.000)
Step: 5940, Reward: 0.0000 [0.00], Avg: -0.3290 (1.000)
Step: 6032, Reward: 0.0000 [0.00], Avg: -0.3210 (1.000)
Step: 6084, Reward: 0.0000 [0.00], Avg: -0.3133 (1.000)
Step: 6145, Reward: 0.0000 [0.00], Avg: -0.3060 (1.000)
Step: 6295, Reward: 0.0000 [0.00], Avg: -0.2991 (1.000)
Step: 6371, Reward: 0.0000 [0.00], Avg: -0.2924 (1.000)
Step: 6449, Reward: -0.2000 [0.40], Avg: -0.2991 (1.000)
Step: 6761, Reward: 0.0000 [0.00], Avg: -0.2928 (1.000)
Step: 6884, Reward: -0.2000 [0.40], Avg: -0.2992 (1.000)
Step: 7284, Reward: 0.0000 [0.00], Avg: -0.2931 (1.000)
Step: 7347, Reward: 0.0000 [0.00], Avg: -0.2872 (1.000)
Step: 7487, Reward: -0.2000 [0.40], Avg: -0.2933 (1.000)
Step: 7537, Reward: 0.0000 [0.00], Avg: -0.2877 (1.000)
Step: 7623, Reward: 0.0000 [0.00], Avg: -0.2823 (1.000)
Step: 7811, Reward: 0.0000 [0.00], Avg: -0.2770 (1.000)
Step: 8211, Reward: -0.2000 [0.40], Avg: -0.2829 (1.000)
Step: 8280, Reward: -0.2000 [0.40], Avg: -0.2886 (1.000)
Step: 8388, Reward: -0.2000 [0.40], Avg: -0.2940 (1.000)
Step: 8500, Reward: 0.0000 [0.00], Avg: -0.2890 (1.000)
Step: 8552, Reward: 0.0000 [0.00], Avg: -0.2841 (1.000)
Step: 8717, Reward: -0.2000 [0.40], Avg: -0.2893 (1.000)
Step: 8801, Reward: -0.2000 [0.40], Avg: -0.2944 (1.000)
Step: 8856, Reward: -0.2000 [0.40], Avg: -0.2993 (1.000)
Step: 9057, Reward: -0.2000 [0.40], Avg: -0.3041 (1.000)
Step: 9116, Reward: -0.2000 [0.40], Avg: -0.3087 (1.000)
Step: 9516, Reward: 0.0000 [0.00], Avg: -0.3040 (1.000)
Step: 9567, Reward: -0.2000 [0.40], Avg: -0.3085 (1.000)
Step: 9642, Reward: -0.2000 [0.40], Avg: -0.3128 (1.000)
Step: 9869, Reward: 0.0000 [0.00], Avg: -0.3082 (1.000)
Step: 9928, Reward: -0.2000 [0.40], Avg: -0.3125 (1.000)
Step: 10236, Reward: 0.0000 [0.00], Avg: -0.3080 (1.000)
Step: 10297, Reward: -0.2000 [0.40], Avg: -0.3121 (1.000)
Step: 10365, Reward: -0.2000 [0.40], Avg: -0.3161 (1.000)
Step: 10439, Reward: -0.2000 [0.40], Avg: -0.3200 (1.000)
Step: 10506, Reward: 0.0000 [0.00], Avg: -0.3157 (1.000)
Step: 10568, Reward: 0.0000 [0.00], Avg: -0.3115 (1.000)
Step: 10648, Reward: -0.2000 [0.40], Avg: -0.3153 (1.000)
Step: 11048, Reward: 0.0000 [0.00], Avg: -0.3112 (1.000)
Step: 11096, Reward: 0.0000 [0.00], Avg: -0.3072 (1.000)
Step: 11185, Reward: -0.2000 [0.40], Avg: -0.3109 (1.000)
Step: 11255, Reward: -0.2000 [0.40], Avg: -0.3145 (1.000)
Step: 11468, Reward: 0.0000 [0.00], Avg: -0.3106 (1.000)
Step: 11868, Reward: 0.0000 [0.00], Avg: -0.3068 (1.000)
Step: 11942, Reward: -0.4000 [0.49], Avg: -0.3138 (1.000)
Step: 12006, Reward: -0.2000 [0.40], Avg: -0.3173 (1.000)
Step: 12110, Reward: 0.0000 [0.00], Avg: -0.3135 (1.000)
Step: 12180, Reward: 0.0000 [0.00], Avg: -0.3099 (1.000)
Step: 12252, Reward: 0.0000 [0.00], Avg: -0.3063 (1.000)
Step: 12360, Reward: 0.0000 [0.00], Avg: -0.3028 (1.000)
Step: 12403, Reward: -0.2000 [0.40], Avg: -0.3062 (1.000)
Step: 12467, Reward: 0.0000 [0.00], Avg: -0.3028 (1.000)
Step: 12735, Reward: -0.4000 [0.49], Avg: -0.3092 (1.000)
Step: 13010, Reward: 0.0000 [0.00], Avg: -0.3059 (1.000)
Step: 13058, Reward: -0.2000 [0.40], Avg: -0.3090 (1.000)
Step: 13458, Reward: 0.0000 [0.00], Avg: -0.3057 (1.000)
Step: 13521, Reward: 0.0000 [0.00], Avg: -0.3025 (1.000)
Step: 13579, Reward: -0.2000 [0.40], Avg: -0.3056 (1.000)
Step: 13696, Reward: -0.2000 [0.40], Avg: -0.3087 (1.000)
Step: 14001, Reward: 0.0000 [0.00], Avg: -0.3055 (1.000)
Step: 14200, Reward: -0.2000 [0.40], Avg: -0.3085 (1.000)
Step: 14269, Reward: -0.4000 [0.49], Avg: -0.3143 (1.000)
Step: 14423, Reward: 0.0000 [0.00], Avg: -0.3112 (1.000)
Step: 14823, Reward: 0.0000 [0.00], Avg: -0.3081 (1.000)
Step: 15223, Reward: 0.0000 [0.00], Avg: -0.3051 (1.000)
Step: 15272, Reward: -0.2000 [0.40], Avg: -0.3080 (1.000)
Step: 15315, Reward: 0.0000 [0.00], Avg: -0.3050 (1.000)
Step: 15358, Reward: 0.0000 [0.00], Avg: -0.3022 (1.000)
Step: 15412, Reward: -0.2000 [0.40], Avg: -0.3049 (1.000)
Step: 15588, Reward: 0.0000 [0.00], Avg: -0.3021 (1.000)
Step: 15673, Reward: 0.0000 [0.00], Avg: -0.2994 (1.000)
Step: 16073, Reward: 0.0000 [0.00], Avg: -0.2966 (1.000)
Step: 16153, Reward: 0.0000 [0.00], Avg: -0.2940 (1.000)
Step: 16240, Reward: 0.0000 [0.00], Avg: -0.2913 (1.000)
Step: 16347, Reward: 0.0000 [0.00], Avg: -0.2888 (1.000)
Step: 16395, Reward: 0.0000 [0.00], Avg: -0.2862 (1.000)
Step: 16440, Reward: 0.0000 [0.00], Avg: -0.2837 (1.000)
Step: 16636, Reward: -0.2000 [0.40], Avg: -0.2865 (1.000)
Step: 16689, Reward: 0.0000 [0.00], Avg: -0.2840 (1.000)
Step: 16779, Reward: 0.0000 [0.00], Avg: -0.2816 (1.000)
Step: 16879, Reward: -0.2000 [0.40], Avg: -0.2843 (1.000)
Step: 16994, Reward: 0.0000 [0.00], Avg: -0.2819 (1.000)
Step: 17115, Reward: 0.0000 [0.00], Avg: -0.2796 (1.000)
Step: 17206, Reward: -0.2000 [0.40], Avg: -0.2822 (1.000)
Step: 17462, Reward: -0.4000 [0.49], Avg: -0.2871 (1.000)
Step: 17519, Reward: -0.2000 [0.40], Avg: -0.2897 (1.000)
Step: 17650, Reward: 0.0000 [0.00], Avg: -0.2874 (1.000)
Step: 17824, Reward: 0.0000 [0.00], Avg: -0.2851 (1.000)
Step: 17897, Reward: -0.2000 [0.40], Avg: -0.2876 (1.000)
Step: 17976, Reward: 0.0000 [0.00], Avg: -0.2853 (1.000)
Step: 18073, Reward: 0.0000 [0.00], Avg: -0.2831 (1.000)
Step: 18473, Reward: -0.4000 [0.49], Avg: -0.2878 (1.000)
Step: 18544, Reward: 0.0000 [0.00], Avg: -0.2856 (1.000)
Step: 18944, Reward: 0.0000 [0.00], Avg: -0.2834 (1.000)
Step: 19172, Reward: 0.0000 [0.00], Avg: -0.2813 (1.000)
Step: 19230, Reward: 0.0000 [0.00], Avg: -0.2792 (1.000)
Step: 19309, Reward: 0.0000 [0.00], Avg: -0.2771 (1.000)
Step: 19375, Reward: 0.0000 [0.00], Avg: -0.2751 (1.000)
Step: 19668, Reward: 0.0000 [0.00], Avg: -0.2731 (1.000)
Step: 19736, Reward: 0.0000 [0.00], Avg: -0.2711 (1.000)
Step: 19845, Reward: -0.2000 [0.40], Avg: -0.2734 (1.000)
Step: 19896, Reward: -0.4000 [0.49], Avg: -0.2778 (1.000)
Step: 20024, Reward: 0.0000 [0.00], Avg: -0.2759 (1.000)
Step: 20151, Reward: 0.0000 [0.00], Avg: -0.2739 (1.000)
Step: 20342, Reward: 0.0000 [0.00], Avg: -0.2720 (1.000)
Step: 20447, Reward: 0.0000 [0.00], Avg: -0.2701 (1.000)
Step: 20458, Reward: -0.2000 [0.40], Avg: -0.2724 (1.000)
Step: 20515, Reward: 0.0000 [0.00], Avg: -0.2705 (1.000)
Step: 20626, Reward: 0.0000 [0.00], Avg: -0.2687 (1.000)
Step: 20840, Reward: 0.0000 [0.00], Avg: -0.2669 (1.000)
Step: 20958, Reward: 0.0000 [0.00], Avg: -0.2651 (1.000)
Step: 21120, Reward: 0.0000 [0.00], Avg: -0.2633 (1.000)
Step: 21174, Reward: 0.0000 [0.00], Avg: -0.2616 (1.000)
Step: 21199, Reward: 0.0000 [0.00], Avg: -0.2599 (1.000)
Step: 21255, Reward: 0.0000 [0.00], Avg: -0.2582 (1.000)
Step: 21366, Reward: -0.2000 [0.40], Avg: -0.2604 (1.000)
Step: 21467, Reward: 0.0000 [0.00], Avg: -0.2587 (1.000)
Step: 21515, Reward: 0.0000 [0.00], Avg: -0.2570 (1.000)
Step: 21623, Reward: 0.0000 [0.00], Avg: -0.2554 (1.000)
Step: 21654, Reward: 0.0000 [0.00], Avg: -0.2538 (1.000)
Step: 21717, Reward: 0.0000 [0.00], Avg: -0.2522 (1.000)
Step: 21815, Reward: 0.0000 [0.00], Avg: -0.2506 (1.000)
Step: 22049, Reward: 0.0000 [0.00], Avg: -0.2491 (1.000)
Step: 22116, Reward: 0.0000 [0.00], Avg: -0.2475 (1.000)
Step: 22245, Reward: 0.0000 [0.00], Avg: -0.2460 (1.000)
Step: 22645, Reward: 0.0000 [0.00], Avg: -0.2445 (1.000)
Step: 23045, Reward: -0.2000 [0.40], Avg: -0.2467 (1.000)
Step: 23445, Reward: -0.2000 [0.40], Avg: -0.2488 (1.000)
Step: 23754, Reward: 0.0000 [0.00], Avg: -0.2473 (1.000)
Step: 23824, Reward: 0.0000 [0.00], Avg: -0.2458 (1.000)
Step: 23903, Reward: -0.2000 [0.40], Avg: -0.2479 (1.000)
Step: 23989, Reward: -0.2000 [0.40], Avg: -0.2500 (1.000)
Step: 24192, Reward: -0.2000 [0.40], Avg: -0.2520 (1.000)
Step: 24376, Reward: 0.0000 [0.00], Avg: -0.2506 (1.000)
Step: 24541, Reward: -0.2000 [0.40], Avg: -0.2526 (1.000)
Step: 24638, Reward: 0.0000 [0.00], Avg: -0.2511 (1.000)
Step: 24690, Reward: 0.0000 [0.00], Avg: -0.2497 (1.000)
Step: 24764, Reward: 0.0000 [0.00], Avg: -0.2483 (1.000)
Step: 24869, Reward: 0.0000 [0.00], Avg: -0.2469 (1.000)
Step: 25269, Reward: -0.2000 [0.40], Avg: -0.2489 (1.000)
Step: 25334, Reward: -0.2000 [0.40], Avg: -0.2508 (1.000)
Step: 25431, Reward: 0.0000 [0.00], Avg: -0.2494 (1.000)
Step: 25552, Reward: 0.0000 [0.00], Avg: -0.2481 (1.000)
Step: 25600, Reward: 0.0000 [0.00], Avg: -0.2467 (1.000)
Step: 25747, Reward: 0.0000 [0.00], Avg: -0.2453 (1.000)
Step: 25920, Reward: 0.0000 [0.00], Avg: -0.2440 (1.000)
Step: 26061, Reward: 0.0000 [0.00], Avg: -0.2427 (1.000)
Step: 26277, Reward: -0.2000 [0.40], Avg: -0.2446 (1.000)
Step: 26342, Reward: -0.2000 [0.40], Avg: -0.2465 (1.000)
Step: 26445, Reward: 0.0000 [0.00], Avg: -0.2452 (1.000)
Step: 26552, Reward: 0.0000 [0.00], Avg: -0.2439 (1.000)
Step: 26605, Reward: 0.0000 [0.00], Avg: -0.2426 (1.000)
Step: 26663, Reward: 0.0000 [0.00], Avg: -0.2414 (1.000)
Step: 26752, Reward: -0.2000 [0.40], Avg: -0.2432 (1.000)
Step: 27152, Reward: 0.0000 [0.00], Avg: -0.2420 (1.000)
Step: 27291, Reward: 0.0000 [0.00], Avg: -0.2407 (1.000)
Step: 27415, Reward: 0.0000 [0.00], Avg: -0.2395 (1.000)
Step: 27552, Reward: 0.0000 [0.00], Avg: -0.2383 (1.000)
Step: 27620, Reward: -0.2000 [0.40], Avg: -0.2401 (1.000)
Step: 27693, Reward: 0.0000 [0.00], Avg: -0.2389 (1.000)
Step: 27707, Reward: -0.4000 [0.49], Avg: -0.2422 (1.000)
Step: 27747, Reward: 0.0000 [0.00], Avg: -0.2409 (1.000)
Step: 27764, Reward: 0.0000 [0.00], Avg: -0.2397 (1.000)
Step: 28164, Reward: 0.0000 [0.00], Avg: -0.2386 (1.000)
Step: 28564, Reward: -0.2000 [0.40], Avg: -0.2403 (1.000)
Step: 28683, Reward: 0.0000 [0.00], Avg: -0.2392 (1.000)
Step: 29083, Reward: -0.2000 [0.40], Avg: -0.2409 (1.000)
Step: 29120, Reward: 0.0000 [0.00], Avg: -0.2398 (1.000)
Step: 29152, Reward: 0.0000 [0.00], Avg: -0.2386 (1.000)
Step: 29277, Reward: 0.0000 [0.00], Avg: -0.2374 (1.000)
Step: 29411, Reward: 0.0000 [0.00], Avg: -0.2363 (1.000)
Step: 29431, Reward: 0.0000 [0.00], Avg: -0.2352 (1.000)
Step: 29551, Reward: 0.0000 [0.00], Avg: -0.2341 (1.000)
Step: 29623, Reward: 0.0000 [0.00], Avg: -0.2330 (1.000)
Step: 29675, Reward: 0.0000 [0.00], Avg: -0.2319 (1.000)
Step: 29804, Reward: 0.0000 [0.00], Avg: -0.2308 (1.000)
Step: 29869, Reward: 0.0000 [0.00], Avg: -0.2297 (1.000)
Step: 29980, Reward: 0.0000 [0.00], Avg: -0.2287 (1.000)
Step: 30059, Reward: 0.0000 [0.00], Avg: -0.2276 (1.000)
Step: 30167, Reward: 0.0000 [0.00], Avg: -0.2266 (1.000)
Step: 30354, Reward: 0.0000 [0.00], Avg: -0.2255 (1.000)
Step: 30597, Reward: 0.0000 [0.00], Avg: -0.2245 (1.000)
Step: 30750, Reward: 0.0000 [0.00], Avg: -0.2235 (1.000)
Step: 31062, Reward: 0.0000 [0.00], Avg: -0.2225 (1.000)
Step: 31219, Reward: 0.0000 [0.00], Avg: -0.2215 (1.000)
Step: 31345, Reward: -0.2000 [0.40], Avg: -0.2232 (1.000)
Step: 31374, Reward: -0.2000 [0.40], Avg: -0.2248 (1.000)
Step: 31433, Reward: 0.0000 [0.00], Avg: -0.2238 (1.000)
Step: 31575, Reward: 0.0000 [0.00], Avg: -0.2229 (1.000)
Step: 31637, Reward: 0.0000 [0.00], Avg: -0.2219 (1.000)
Step: 31694, Reward: -0.2000 [0.40], Avg: -0.2235 (1.000)
Step: 31803, Reward: 0.0000 [0.00], Avg: -0.2226 (1.000)
Step: 31867, Reward: 0.0000 [0.00], Avg: -0.2216 (1.000)
Step: 31880, Reward: 0.0000 [0.00], Avg: -0.2206 (1.000)
Step: 32025, Reward: 0.0000 [0.00], Avg: -0.2197 (1.000)
Step: 32115, Reward: 0.0000 [0.00], Avg: -0.2188 (1.000)
Step: 32145, Reward: 0.0000 [0.00], Avg: -0.2178 (1.000)
Step: 32545, Reward: 0.0000 [0.00], Avg: -0.2169 (1.000)
Step: 32719, Reward: 0.0000 [0.00], Avg: -0.2160 (1.000)
Step: 32799, Reward: 0.0000 [0.00], Avg: -0.2151 (1.000)
Step: 32928, Reward: 0.0000 [0.00], Avg: -0.2142 (1.000)
Step: 33080, Reward: 0.0000 [0.00], Avg: -0.2133 (1.000)
Step: 33096, Reward: 0.0000 [0.00], Avg: -0.2124 (1.000)
Step: 33147, Reward: 0.0000 [0.00], Avg: -0.2115 (1.000)
Step: 33205, Reward: 0.0000 [0.00], Avg: -0.2107 (1.000)
Step: 33276, Reward: -0.2000 [0.40], Avg: -0.2122 (1.000)
Step: 33416, Reward: 0.0000 [0.00], Avg: -0.2114 (1.000)
Step: 33816, Reward: 0.0000 [0.00], Avg: -0.2105 (1.000)
Step: 33967, Reward: 0.0000 [0.00], Avg: -0.2097 (1.000)
Step: 34050, Reward: 0.0000 [0.00], Avg: -0.2088 (1.000)
Step: 34133, Reward: 0.0000 [0.00], Avg: -0.2080 (1.000)
Step: 34220, Reward: -0.2000 [0.40], Avg: -0.2096 (1.000)
Step: 34423, Reward: 0.0000 [0.00], Avg: -0.2087 (1.000)
Step: 34633, Reward: 0.0000 [0.00], Avg: -0.2079 (1.000)
Step: 34704, Reward: 0.0000 [0.00], Avg: -0.2071 (1.000)
Step: 34776, Reward: 0.0000 [0.00], Avg: -0.2063 (1.000)
Step: 34959, Reward: 0.0000 [0.00], Avg: -0.2054 (1.000)
Step: 35092, Reward: 0.0000 [0.00], Avg: -0.2046 (1.000)
Step: 35196, Reward: 0.0000 [0.00], Avg: -0.2038 (1.000)
Step: 35240, Reward: 0.0000 [0.00], Avg: -0.2031 (1.000)
Step: 35307, Reward: 0.0000 [0.00], Avg: -0.2023 (1.000)
Step: 35374, Reward: 0.0000 [0.00], Avg: -0.2015 (1.000)
Step: 35498, Reward: -0.2000 [0.40], Avg: -0.2030 (1.000)
Step: 35511, Reward: 0.0000 [0.00], Avg: -0.2022 (1.000)
Step: 35911, Reward: -0.2000 [0.40], Avg: -0.2038 (1.000)
Step: 35993, Reward: 0.0000 [0.00], Avg: -0.2030 (1.000)
Step: 36022, Reward: -0.2000 [0.40], Avg: -0.2045 (1.000)
Step: 36162, Reward: 0.0000 [0.00], Avg: -0.2037 (1.000)
Step: 36562, Reward: -0.2000 [0.40], Avg: -0.2052 (1.000)
Step: 36652, Reward: 0.0000 [0.00], Avg: -0.2044 (1.000)
Step: 36688, Reward: -0.2000 [0.40], Avg: -0.2059 (1.000)
Step: 36768, Reward: 0.0000 [0.00], Avg: -0.2051 (1.000)
Step: 36843, Reward: -0.2000 [0.40], Avg: -0.2066 (1.000)
Step: 36889, Reward: -0.2000 [0.40], Avg: -0.2080 (1.000)
Step: 36905, Reward: -0.2000 [0.40], Avg: -0.2095 (1.000)
Step: 37064, Reward: 0.0000 [0.00], Avg: -0.2087 (1.000)
Step: 37464, Reward: -0.2000 [0.40], Avg: -0.2101 (1.000)
Step: 37526, Reward: -0.2000 [0.40], Avg: -0.2116 (1.000)
Step: 37584, Reward: -0.2000 [0.40], Avg: -0.2130 (1.000)
Step: 37984, Reward: 0.0000 [0.00], Avg: -0.2122 (1.000)
Step: 38384, Reward: 0.0000 [0.00], Avg: -0.2114 (1.000)
Step: 38784, Reward: -0.2000 [0.40], Avg: -0.2128 (1.000)
Step: 38969, Reward: 0.0000 [0.00], Avg: -0.2121 (1.000)
Step: 39116, Reward: 0.0000 [0.00], Avg: -0.2113 (1.000)
Step: 39177, Reward: 0.0000 [0.00], Avg: -0.2106 (1.000)
Step: 39225, Reward: 0.0000 [0.00], Avg: -0.2098 (1.000)
Step: 39286, Reward: 0.0000 [0.00], Avg: -0.2091 (1.000)
Step: 39340, Reward: 0.0000 [0.00], Avg: -0.2084 (1.000)
Step: 39509, Reward: 0.0000 [0.00], Avg: -0.2076 (1.000)
Step: 39737, Reward: 0.0000 [0.00], Avg: -0.2069 (1.000)
Step: 39812, Reward: 0.0000 [0.00], Avg: -0.2062 (1.000)
Step: 39826, Reward: 0.0000 [0.00], Avg: -0.2055 (1.000)
Step: 39934, Reward: 0.0000 [0.00], Avg: -0.2048 (1.000)
Step: 40020, Reward: 0.0000 [0.00], Avg: -0.2041 (1.000)
Step: 40068, Reward: 0.0000 [0.00], Avg: -0.2034 (1.000)
Step: 40121, Reward: -0.2000 [0.40], Avg: -0.2047 (1.000)
Step: 40210, Reward: 0.0000 [0.00], Avg: -0.2040 (1.000)
Step: 40254, Reward: 0.0000 [0.00], Avg: -0.2033 (1.000)
Step: 40268, Reward: -0.2000 [0.40], Avg: -0.2047 (1.000)
Step: 40291, Reward: 0.0000 [0.00], Avg: -0.2040 (1.000)
Step: 40335, Reward: 0.0000 [0.00], Avg: -0.2033 (1.000)
Step: 40390, Reward: 0.0000 [0.00], Avg: -0.2026 (1.000)
Step: 40437, Reward: 0.0000 [0.00], Avg: -0.2020 (1.000)
Step: 40532, Reward: 0.0000 [0.00], Avg: -0.2013 (1.000)
Step: 40609, Reward: 0.0000 [0.00], Avg: -0.2006 (1.000)
Step: 40748, Reward: -0.2000 [0.40], Avg: -0.2019 (1.000)
Step: 40809, Reward: -0.2000 [0.40], Avg: -0.2032 (1.000)
Step: 40954, Reward: 0.0000 [0.00], Avg: -0.2026 (1.000)
Step: 40972, Reward: 0.0000 [0.00], Avg: -0.2019 (1.000)
Step: 41039, Reward: 0.0000 [0.00], Avg: -0.2013 (1.000)
Step: 41138, Reward: 0.0000 [0.00], Avg: -0.2006 (1.000)
Step: 41157, Reward: 0.0000 [0.00], Avg: -0.2000 (1.000)
Step: 41243, Reward: -0.2000 [0.40], Avg: -0.2013 (1.000)
Step: 41303, Reward: 0.0000 [0.00], Avg: -0.2006 (1.000)
Step: 41368, Reward: -0.2000 [0.40], Avg: -0.2019 (1.000)
Step: 41449, Reward: -0.2000 [0.40], Avg: -0.2031 (1.000)
Step: 41849, Reward: 0.0000 [0.00], Avg: -0.2025 (1.000)
Step: 41908, Reward: 0.0000 [0.00], Avg: -0.2019 (1.000)
Step: 42169, Reward: -0.2000 [0.40], Avg: -0.2031 (1.000)
Step: 42569, Reward: 0.0000 [0.00], Avg: -0.2025 (1.000)
Step: 42641, Reward: -0.2000 [0.40], Avg: -0.2037 (1.000)
Step: 42922, Reward: 0.0000 [0.00], Avg: -0.2031 (1.000)
Step: 42983, Reward: 0.0000 [0.00], Avg: -0.2025 (1.000)
Step: 43048, Reward: 0.0000 [0.00], Avg: -0.2018 (1.000)
Step: 43108, Reward: 0.0000 [0.00], Avg: -0.2012 (1.000)
Step: 43155, Reward: 0.0000 [0.00], Avg: -0.2006 (1.000)
Step: 43280, Reward: 0.0000 [0.00], Avg: -0.2000 (1.000)
Step: 43354, Reward: 0.0000 [0.00], Avg: -0.1994 (1.000)
Step: 43371, Reward: 0.0000 [0.00], Avg: -0.1987 (1.000)
Step: 43449, Reward: -0.2000 [0.40], Avg: -0.2000 (1.000)
Step: 43573, Reward: 0.0000 [0.00], Avg: -0.1994 (1.000)
Step: 43632, Reward: -0.2000 [0.40], Avg: -0.2006 (1.000)
Step: 44032, Reward: 0.0000 [0.00], Avg: -0.2000 (1.000)
Step: 44268, Reward: -0.2000 [0.40], Avg: -0.2012 (1.000)
Step: 44321, Reward: 0.0000 [0.00], Avg: -0.2006 (1.000)
Step: 44490, Reward: 0.0000 [0.00], Avg: -0.2000 (1.000)
Step: 44566, Reward: 0.0000 [0.00], Avg: -0.1994 (1.000)
Step: 44635, Reward: -0.4000 [0.49], Avg: -0.2014 (1.000)
Step: 44689, Reward: -0.2000 [0.40], Avg: -0.2026 (1.000)
Step: 44752, Reward: 0.0000 [0.00], Avg: -0.2020 (1.000)
Step: 44819, Reward: 0.0000 [0.00], Avg: -0.2014 (1.000)
Step: 44932, Reward: 0.0000 [0.00], Avg: -0.2008 (1.000)
Step: 45211, Reward: 0.0000 [0.00], Avg: -0.2002 (1.000)
Step: 45306, Reward: 0.0000 [0.00], Avg: -0.1996 (1.000)
Step: 45360, Reward: 0.0000 [0.00], Avg: -0.1991 (1.000)
Step: 45428, Reward: 0.0000 [0.00], Avg: -0.1985 (1.000)
Step: 45510, Reward: 0.0000 [0.00], Avg: -0.1979 (1.000)
Step: 45596, Reward: 0.0000 [0.00], Avg: -0.1973 (1.000)
Step: 45646, Reward: 0.0000 [0.00], Avg: -0.1968 (1.000)
Step: 45720, Reward: 0.0000 [0.00], Avg: -0.1962 (1.000)
Step: 45801, Reward: 0.0000 [0.00], Avg: -0.1956 (1.000)
Step: 45995, Reward: 0.0000 [0.00], Avg: -0.1951 (1.000)
Step: 46065, Reward: 0.0000 [0.00], Avg: -0.1945 (1.000)
Step: 46243, Reward: -0.2000 [0.40], Avg: -0.1957 (1.000)
Step: 46294, Reward: -0.2000 [0.40], Avg: -0.1968 (1.000)
Step: 46353, Reward: -0.4000 [0.49], Avg: -0.1988 (1.000)
Step: 46470, Reward: 0.0000 [0.00], Avg: -0.1982 (1.000)
Step: 46644, Reward: 0.0000 [0.00], Avg: -0.1977 (1.000)
Step: 46706, Reward: 0.0000 [0.00], Avg: -0.1971 (1.000)
Step: 46858, Reward: 0.0000 [0.00], Avg: -0.1966 (1.000)
Step: 46942, Reward: 0.0000 [0.00], Avg: -0.1960 (1.000)
Step: 47024, Reward: 0.0000 [0.00], Avg: -0.1955 (1.000)
Step: 47070, Reward: 0.0000 [0.00], Avg: -0.1949 (1.000)
Step: 47470, Reward: 0.0000 [0.00], Avg: -0.1944 (1.000)
Step: 47533, Reward: 0.0000 [0.00], Avg: -0.1939 (1.000)
Step: 47636, Reward: 0.0000 [0.00], Avg: -0.1933 (1.000)
Step: 47647, Reward: 0.0000 [0.00], Avg: -0.1928 (1.000)
Step: 47702, Reward: 0.0000 [0.00], Avg: -0.1923 (1.000)
Step: 47970, Reward: 0.0000 [0.00], Avg: -0.1917 (1.000)
Step: 48144, Reward: 0.0000 [0.00], Avg: -0.1912 (1.000)
Step: 48286, Reward: 0.0000 [0.00], Avg: -0.1907 (1.000)
Step: 48344, Reward: 0.0000 [0.00], Avg: -0.1902 (1.000)
Step: 48388, Reward: -0.2000 [0.40], Avg: -0.1913 (1.000)
Step: 48571, Reward: 0.0000 [0.00], Avg: -0.1908 (1.000)
Step: 48613, Reward: 0.0000 [0.00], Avg: -0.1903 (1.000)
Step: 48787, Reward: -0.4000 [0.49], Avg: -0.1921 (1.000)
Step: 48895, Reward: -0.2000 [0.40], Avg: -0.1932 (1.000)
Step: 48965, Reward: 0.0000 [0.00], Avg: -0.1927 (1.000)
Step: 49058, Reward: 0.0000 [0.00], Avg: -0.1922 (1.000)
Step: 49222, Reward: 0.0000 [0.00], Avg: -0.1917 (1.000)
Step: 49285, Reward: 0.0000 [0.00], Avg: -0.1912 (1.000)
Step: 49297, Reward: 0.0000 [0.00], Avg: -0.1907 (1.000)
Step: 49451, Reward: 0.0000 [0.00], Avg: -0.1902 (1.000)
Step: 49479, Reward: 0.0000 [0.00], Avg: -0.1897 (1.000)
Step: 49545, Reward: 0.0000 [0.00], Avg: -0.1892 (1.000)
Step: 49945, Reward: 0.0000 [0.00], Avg: -0.1887 (1.000)
Step: 50015, Reward: 0.0000 [0.00], Avg: -0.1882 (1.000)
Step: 50208, Reward: 0.0000 [0.00], Avg: -0.1877 (1.000)
Step: 50297, Reward: 0.0000 [0.00], Avg: -0.1872 (1.000)
Step: 50369, Reward: 0.0000 [0.00], Avg: -0.1867 (1.000)
Step: 50414, Reward: -0.2000 [0.40], Avg: -0.1878 (1.000)
Step: 50464, Reward: 0.0000 [0.00], Avg: -0.1873 (1.000)
Step: 50864, Reward: 0.0000 [0.00], Avg: -0.1869 (1.000)
Step: 50924, Reward: 0.0000 [0.00], Avg: -0.1864 (1.000)
Step: 51324, Reward: 0.0000 [0.00], Avg: -0.1859 (1.000)
Step: 51380, Reward: 0.0000 [0.00], Avg: -0.1854 (1.000)
Step: 51502, Reward: -0.2000 [0.40], Avg: -0.1865 (1.000)
Step: 51666, Reward: 0.0000 [0.00], Avg: -0.1860 (1.000)
Step: 52066, Reward: -0.2000 [0.40], Avg: -0.1870 (1.000)
Step: 52466, Reward: 0.0000 [0.00], Avg: -0.1866 (1.000)
Step: 52510, Reward: -0.2000 [0.40], Avg: -0.1876 (1.000)
Step: 52599, Reward: 0.0000 [0.00], Avg: -0.1871 (1.000)
Step: 52886, Reward: -0.2000 [0.40], Avg: -0.1882 (1.000)
Step: 53142, Reward: 0.0000 [0.00], Avg: -0.1877 (1.000)
Step: 53542, Reward: -0.2000 [0.40], Avg: -0.1887 (1.000)
Step: 53597, Reward: 0.0000 [0.00], Avg: -0.1883 (1.000)
Step: 53852, Reward: -0.2000 [0.40], Avg: -0.1893 (1.000)
Step: 53909, Reward: 0.0000 [0.00], Avg: -0.1888 (1.000)
Step: 54050, Reward: 0.0000 [0.00], Avg: -0.1884 (1.000)
Step: 54120, Reward: 0.0000 [0.00], Avg: -0.1879 (1.000)
Step: 54173, Reward: 0.0000 [0.00], Avg: -0.1874 (1.000)
Step: 54187, Reward: 0.0000 [0.00], Avg: -0.1870 (1.000)
Step: 54376, Reward: 0.0000 [0.00], Avg: -0.1865 (1.000)
Step: 54454, Reward: 0.0000 [0.00], Avg: -0.1861 (1.000)
Step: 54526, Reward: 0.0000 [0.00], Avg: -0.1856 (1.000)
Step: 54574, Reward: 0.0000 [0.00], Avg: -0.1852 (1.000)
Step: 54686, Reward: 0.0000 [0.00], Avg: -0.1847 (1.000)
Step: 54743, Reward: 0.0000 [0.00], Avg: -0.1843 (1.000)
Step: 54761, Reward: 0.0000 [0.00], Avg: -0.1838 (1.000)
Step: 54822, Reward: 0.0000 [0.00], Avg: -0.1834 (1.000)
Step: 54881, Reward: 0.0000 [0.00], Avg: -0.1830 (1.000)
Step: 54936, Reward: 0.0000 [0.00], Avg: -0.1825 (1.000)
Step: 55006, Reward: -0.2000 [0.40], Avg: -0.1835 (1.000)
Step: 55280, Reward: 0.0000 [0.00], Avg: -0.1831 (1.000)
Step: 55680, Reward: -0.2000 [0.40], Avg: -0.1841 (1.000)
Step: 55898, Reward: 0.0000 [0.00], Avg: -0.1836 (1.000)
Step: 56068, Reward: 0.0000 [0.00], Avg: -0.1832 (1.000)
Step: 56108, Reward: 0.0000 [0.00], Avg: -0.1828 (1.000)
Step: 56508, Reward: 0.0000 [0.00], Avg: -0.1823 (1.000)
Step: 56802, Reward: 0.0000 [0.00], Avg: -0.1819 (1.000)
Step: 56859, Reward: -0.4000 [0.49], Avg: -0.1836 (1.000)
Step: 56966, Reward: 0.0000 [0.00], Avg: -0.1831 (1.000)
Step: 57036, Reward: 0.0000 [0.00], Avg: -0.1827 (1.000)
Step: 57117, Reward: 0.0000 [0.00], Avg: -0.1823 (1.000)
Step: 57325, Reward: 0.0000 [0.00], Avg: -0.1819 (1.000)
Step: 57424, Reward: -0.2000 [0.40], Avg: -0.1828 (1.000)
Step: 57471, Reward: 0.0000 [0.00], Avg: -0.1824 (1.000)
Step: 57530, Reward: 0.0000 [0.00], Avg: -0.1820 (1.000)
Step: 57614, Reward: -0.2000 [0.40], Avg: -0.1829 (1.000)
Step: 57777, Reward: -0.2000 [0.40], Avg: -0.1839 (1.000)
Step: 57848, Reward: 0.0000 [0.00], Avg: -0.1835 (1.000)
Step: 57921, Reward: 0.0000 [0.00], Avg: -0.1831 (1.000)
Step: 57981, Reward: 0.0000 [0.00], Avg: -0.1826 (1.000)
Step: 58082, Reward: -0.2000 [0.40], Avg: -0.1836 (1.000)
Step: 58348, Reward: 0.0000 [0.00], Avg: -0.1832 (1.000)
Step: 58427, Reward: 0.0000 [0.00], Avg: -0.1828 (1.000)
Step: 58632, Reward: -0.2000 [0.40], Avg: -0.1837 (1.000)
Step: 58751, Reward: 0.0000 [0.00], Avg: -0.1833 (1.000)
Step: 58817, Reward: 0.0000 [0.00], Avg: -0.1829 (1.000)
Step: 58880, Reward: 0.0000 [0.00], Avg: -0.1825 (1.000)
Step: 58897, Reward: 0.0000 [0.00], Avg: -0.1821 (1.000)
Step: 58985, Reward: -0.2000 [0.40], Avg: -0.1830 (1.000)
Step: 58998, Reward: 0.0000 [0.00], Avg: -0.1826 (1.000)
Step: 59146, Reward: 0.0000 [0.00], Avg: -0.1822 (1.000)
Step: 59250, Reward: 0.0000 [0.00], Avg: -0.1818 (1.000)
Step: 59353, Reward: -0.2000 [0.40], Avg: -0.1827 (1.000)
Step: 59508, Reward: 0.0000 [0.00], Avg: -0.1823 (1.000)
Step: 59615, Reward: 0.0000 [0.00], Avg: -0.1819 (1.000)
Step: 59627, Reward: -0.2000 [0.40], Avg: -0.1828 (1.000)
Step: 59677, Reward: 0.0000 [0.00], Avg: -0.1824 (1.000)
Step: 59840, Reward: 0.0000 [0.00], Avg: -0.1820 (1.000)
Step: 59913, Reward: 0.0000 [0.00], Avg: -0.1816 (1.000)
Step: 60048, Reward: 0.0000 [0.00], Avg: -0.1812 (1.000)
Step: 60137, Reward: 0.0000 [0.00], Avg: -0.1808 (1.000)
Step: 60164, Reward: 0.0000 [0.00], Avg: -0.1805 (1.000)
Step: 60284, Reward: 0.0000 [0.00], Avg: -0.1801 (1.000)
Step: 60348, Reward: 0.0000 [0.00], Avg: -0.1797 (1.000)
Step: 60516, Reward: 0.0000 [0.00], Avg: -0.1793 (1.000)
Step: 60566, Reward: 0.0000 [0.00], Avg: -0.1789 (1.000)
Step: 60623, Reward: 0.0000 [0.00], Avg: -0.1785 (1.000)
Step: 60698, Reward: -0.2000 [0.40], Avg: -0.1794 (1.000)
Step: 60714, Reward: -0.2000 [0.40], Avg: -0.1803 (1.000)
Step: 60815, Reward: 0.0000 [0.00], Avg: -0.1799 (1.000)
Step: 60858, Reward: 0.0000 [0.00], Avg: -0.1796 (1.000)
Step: 60916, Reward: 0.0000 [0.00], Avg: -0.1792 (1.000)
Step: 61041, Reward: 0.0000 [0.00], Avg: -0.1788 (1.000)
Step: 61156, Reward: -0.2000 [0.40], Avg: -0.1797 (1.000)
Step: 61230, Reward: 0.0000 [0.00], Avg: -0.1793 (1.000)
Step: 61299, Reward: -0.2000 [0.40], Avg: -0.1802 (1.000)
Step: 61366, Reward: -0.2000 [0.40], Avg: -0.1811 (1.000)
Step: 61539, Reward: 0.0000 [0.00], Avg: -0.1807 (1.000)
Step: 61704, Reward: 0.0000 [0.00], Avg: -0.1803 (1.000)
Step: 61732, Reward: 0.0000 [0.00], Avg: -0.1799 (1.000)
Step: 62132, Reward: -0.2000 [0.40], Avg: -0.1808 (1.000)
Step: 62268, Reward: 0.0000 [0.00], Avg: -0.1804 (1.000)
Step: 62409, Reward: 0.0000 [0.00], Avg: -0.1801 (1.000)
Step: 62809, Reward: 0.0000 [0.00], Avg: -0.1797 (1.000)
Step: 62901, Reward: 0.0000 [0.00], Avg: -0.1793 (1.000)
Step: 62914, Reward: -0.4000 [0.49], Avg: -0.1808 (1.000)
Step: 63003, Reward: 0.0000 [0.00], Avg: -0.1804 (1.000)
Step: 63071, Reward: 0.0000 [0.00], Avg: -0.1800 (1.000)
Step: 63156, Reward: 0.0000 [0.00], Avg: -0.1797 (1.000)
Step: 63204, Reward: 0.0000 [0.00], Avg: -0.1793 (1.000)
Step: 63276, Reward: 0.0000 [0.00], Avg: -0.1789 (1.000)
Step: 63332, Reward: -0.2000 [0.40], Avg: -0.1798 (1.000)
Step: 63406, Reward: 0.0000 [0.00], Avg: -0.1794 (1.000)
Step: 63457, Reward: 0.0000 [0.00], Avg: -0.1791 (1.000)
Step: 63531, Reward: -0.2000 [0.40], Avg: -0.1799 (1.000)
Step: 63626, Reward: 0.0000 [0.00], Avg: -0.1796 (1.000)
Step: 63683, Reward: 0.0000 [0.00], Avg: -0.1792 (1.000)
Step: 64083, Reward: 0.0000 [0.00], Avg: -0.1788 (1.000)
Step: 64118, Reward: 0.0000 [0.00], Avg: -0.1785 (1.000)
Step: 64173, Reward: 0.0000 [0.00], Avg: -0.1781 (1.000)
Step: 64359, Reward: 0.0000 [0.00], Avg: -0.1778 (1.000)
Step: 64413, Reward: -0.2000 [0.40], Avg: -0.1786 (1.000)
Step: 64490, Reward: 0.0000 [0.00], Avg: -0.1783 (1.000)
Step: 64568, Reward: -0.2000 [0.40], Avg: -0.1791 (1.000)
Step: 64845, Reward: 0.0000 [0.00], Avg: -0.1787 (1.000)
Step: 64858, Reward: 0.0000 [0.00], Avg: -0.1784 (1.000)
Step: 64928, Reward: 0.0000 [0.00], Avg: -0.1780 (1.000)
Step: 65142, Reward: 0.0000 [0.00], Avg: -0.1777 (1.000)
Step: 65195, Reward: -0.4000 [0.49], Avg: -0.1791 (1.000)
Step: 65323, Reward: 0.0000 [0.00], Avg: -0.1787 (1.000)
Step: 65379, Reward: 0.0000 [0.00], Avg: -0.1784 (1.000)
Step: 65427, Reward: 0.0000 [0.00], Avg: -0.1780 (1.000)
Step: 65511, Reward: -0.2000 [0.40], Avg: -0.1788 (1.000)
Step: 65571, Reward: 0.0000 [0.00], Avg: -0.1785 (1.000)
Step: 65971, Reward: 0.0000 [0.00], Avg: -0.1782 (1.000)
Step: 66023, Reward: -0.4000 [0.49], Avg: -0.1795 (1.000)
Step: 66079, Reward: -0.2000 [0.40], Avg: -0.1803 (1.000)
Step: 66155, Reward: -0.4000 [0.49], Avg: -0.1817 (1.000)
Step: 66257, Reward: 0.0000 [0.00], Avg: -0.1814 (1.000)
Step: 66322, Reward: -0.4000 [0.49], Avg: -0.1827 (1.000)
Step: 66546, Reward: 0.0000 [0.00], Avg: -0.1824 (1.000)
Step: 66663, Reward: 0.0000 [0.00], Avg: -0.1820 (1.000)
Step: 66719, Reward: -0.2000 [0.40], Avg: -0.1828 (1.000)
Step: 66771, Reward: 0.0000 [0.00], Avg: -0.1825 (1.000)
Step: 66851, Reward: -0.2000 [0.40], Avg: -0.1833 (1.000)
Step: 67074, Reward: 0.0000 [0.00], Avg: -0.1829 (1.000)
Step: 67139, Reward: 0.0000 [0.00], Avg: -0.1826 (1.000)
Step: 67210, Reward: 0.0000 [0.00], Avg: -0.1822 (1.000)
Step: 67283, Reward: -0.2000 [0.40], Avg: -0.1830 (1.000)
Step: 67360, Reward: 0.0000 [0.00], Avg: -0.1827 (1.000)
Step: 67522, Reward: 0.0000 [0.00], Avg: -0.1823 (1.000)
Step: 67603, Reward: 0.0000 [0.00], Avg: -0.1820 (1.000)
Step: 67663, Reward: 0.0000 [0.00], Avg: -0.1816 (1.000)
Step: 67761, Reward: 0.0000 [0.00], Avg: -0.1813 (1.000)
Step: 67904, Reward: 0.0000 [0.00], Avg: -0.1810 (1.000)
Step: 67961, Reward: 0.0000 [0.00], Avg: -0.1806 (1.000)
Step: 68061, Reward: 0.0000 [0.00], Avg: -0.1803 (1.000)
Step: 68089, Reward: -0.2000 [0.40], Avg: -0.1811 (1.000)
Step: 68146, Reward: 0.0000 [0.00], Avg: -0.1807 (1.000)
Step: 68278, Reward: 0.0000 [0.00], Avg: -0.1804 (1.000)
Step: 68398, Reward: 0.0000 [0.00], Avg: -0.1801 (1.000)
Step: 68524, Reward: 0.0000 [0.00], Avg: -0.1797 (1.000)
Step: 68924, Reward: 0.0000 [0.00], Avg: -0.1794 (1.000)
Step: 69027, Reward: -0.2000 [0.40], Avg: -0.1802 (1.000)
Step: 69134, Reward: 0.0000 [0.00], Avg: -0.1798 (1.000)
Step: 69196, Reward: 0.0000 [0.00], Avg: -0.1795 (1.000)
Step: 69247, Reward: 0.0000 [0.00], Avg: -0.1792 (1.000)
Step: 69312, Reward: 0.0000 [0.00], Avg: -0.1789 (1.000)
Step: 69378, Reward: -0.2000 [0.40], Avg: -0.1796 (1.000)
Step: 69444, Reward: -0.2000 [0.40], Avg: -0.1804 (1.000)
Step: 69549, Reward: -0.2000 [0.40], Avg: -0.1812 (1.000)
Step: 69721, Reward: -0.2000 [0.40], Avg: -0.1819 (1.000)
Step: 69848, Reward: -0.2000 [0.40], Avg: -0.1827 (1.000)
Step: 70248, Reward: 0.0000 [0.00], Avg: -0.1823 (1.000)
Step: 70325, Reward: 0.0000 [0.00], Avg: -0.1820 (1.000)
Step: 70390, Reward: 0.0000 [0.00], Avg: -0.1817 (1.000)
Step: 70550, Reward: -0.2000 [0.40], Avg: -0.1824 (1.000)
Step: 70687, Reward: 0.0000 [0.00], Avg: -0.1821 (1.000)
Step: 70800, Reward: -0.2000 [0.40], Avg: -0.1829 (1.000)
Step: 70889, Reward: 0.0000 [0.00], Avg: -0.1825 (1.000)
Step: 70961, Reward: 0.0000 [0.00], Avg: -0.1822 (1.000)
Step: 70979, Reward: 0.0000 [0.00], Avg: -0.1819 (1.000)
Step: 70992, Reward: 0.0000 [0.00], Avg: -0.1816 (1.000)
Step: 71135, Reward: 0.0000 [0.00], Avg: -0.1812 (1.000)
Step: 71192, Reward: 0.0000 [0.00], Avg: -0.1809 (1.000)
Step: 71314, Reward: -0.2000 [0.40], Avg: -0.1817 (1.000)
Step: 71379, Reward: 0.0000 [0.00], Avg: -0.1813 (1.000)
Step: 71430, Reward: 0.0000 [0.00], Avg: -0.1810 (1.000)
Step: 71483, Reward: -0.2000 [0.40], Avg: -0.1818 (1.000)
Step: 71588, Reward: 0.0000 [0.00], Avg: -0.1814 (1.000)
Step: 71651, Reward: 0.0000 [0.00], Avg: -0.1811 (1.000)
Step: 71770, Reward: 0.0000 [0.00], Avg: -0.1808 (1.000)
Step: 71787, Reward: 0.0000 [0.00], Avg: -0.1805 (1.000)
Step: 71912, Reward: 0.0000 [0.00], Avg: -0.1802 (1.000)
Step: 72025, Reward: 0.0000 [0.00], Avg: -0.1799 (1.000)
Step: 72037, Reward: 0.0000 [0.00], Avg: -0.1795 (1.000)
Step: 72116, Reward: -0.2000 [0.40], Avg: -0.1803 (1.000)
Step: 72207, Reward: 0.0000 [0.00], Avg: -0.1800 (1.000)
Step: 72287, Reward: 0.0000 [0.00], Avg: -0.1797 (1.000)
Step: 72438, Reward: 0.0000 [0.00], Avg: -0.1793 (1.000)
Step: 72485, Reward: 0.0000 [0.00], Avg: -0.1790 (1.000)
Step: 72626, Reward: 0.0000 [0.00], Avg: -0.1787 (1.000)
Step: 72781, Reward: 0.0000 [0.00], Avg: -0.1784 (1.000)
Step: 72866, Reward: 0.0000 [0.00], Avg: -0.1781 (1.000)
Step: 72959, Reward: 0.0000 [0.00], Avg: -0.1778 (1.000)
Step: 73011, Reward: -0.2000 [0.40], Avg: -0.1785 (1.000)
Step: 73083, Reward: 0.0000 [0.00], Avg: -0.1782 (1.000)
Step: 73176, Reward: 0.0000 [0.00], Avg: -0.1779 (1.000)
Step: 73270, Reward: -0.2000 [0.40], Avg: -0.1786 (1.000)
Step: 73323, Reward: 0.0000 [0.00], Avg: -0.1783 (1.000)
Step: 73723, Reward: 0.0000 [0.00], Avg: -0.1780 (1.000)
Step: 73817, Reward: 0.0000 [0.00], Avg: -0.1777 (1.000)
Step: 73888, Reward: 0.0000 [0.00], Avg: -0.1774 (1.000)
Step: 74000, Reward: 0.0000 [0.00], Avg: -0.1771 (1.000)
Step: 74081, Reward: 0.0000 [0.00], Avg: -0.1768 (1.000)
Step: 74207, Reward: 0.0000 [0.00], Avg: -0.1765 (1.000)
Step: 74607, Reward: 0.0000 [0.00], Avg: -0.1763 (1.000)
Step: 74633, Reward: 0.0000 [0.00], Avg: -0.1760 (1.000)
Step: 74691, Reward: -0.2000 [0.40], Avg: -0.1767 (1.000)
Step: 74756, Reward: 0.0000 [0.00], Avg: -0.1764 (1.000)
Step: 74857, Reward: -0.4000 [0.49], Avg: -0.1776 (1.000)
Step: 74912, Reward: 0.0000 [0.00], Avg: -0.1773 (1.000)
Step: 74932, Reward: 0.0000 [0.00], Avg: -0.1770 (1.000)
Step: 74999, Reward: 0.0000 [0.00], Avg: -0.1767 (1.000)
Step: 75316, Reward: -0.2000 [0.40], Avg: -0.1774 (1.000)
Step: 75356, Reward: 0.0000 [0.00], Avg: -0.1771 (1.000)
Step: 75417, Reward: 0.0000 [0.00], Avg: -0.1768 (1.000)
Step: 75817, Reward: 0.0000 [0.00], Avg: -0.1765 (1.000)
Step: 75884, Reward: -0.2000 [0.40], Avg: -0.1772 (1.000)
Step: 75920, Reward: 0.0000 [0.00], Avg: -0.1769 (1.000)
Step: 76320, Reward: 0.0000 [0.00], Avg: -0.1766 (1.000)
Step: 76401, Reward: 0.0000 [0.00], Avg: -0.1763 (1.000)
Step: 76438, Reward: 0.0000 [0.00], Avg: -0.1760 (1.000)
Step: 76625, Reward: 0.0000 [0.00], Avg: -0.1758 (1.000)
Step: 76639, Reward: -0.2000 [0.40], Avg: -0.1764 (1.000)
Step: 76712, Reward: 0.0000 [0.00], Avg: -0.1762 (1.000)
Step: 76760, Reward: -0.2000 [0.40], Avg: -0.1768 (1.000)
Step: 76846, Reward: -0.2000 [0.40], Avg: -0.1775 (1.000)
Step: 76935, Reward: -0.2000 [0.40], Avg: -0.1782 (1.000)
Step: 76955, Reward: 0.0000 [0.00], Avg: -0.1779 (1.000)
Step: 77023, Reward: 0.0000 [0.00], Avg: -0.1776 (1.000)
Step: 77156, Reward: 0.0000 [0.00], Avg: -0.1773 (1.000)
Step: 77167, Reward: 0.0000 [0.00], Avg: -0.1771 (1.000)
Step: 77267, Reward: 0.0000 [0.00], Avg: -0.1768 (1.000)
Step: 77426, Reward: 0.0000 [0.00], Avg: -0.1765 (1.000)
Step: 77469, Reward: 0.0000 [0.00], Avg: -0.1762 (1.000)
Step: 77516, Reward: -0.2000 [0.40], Avg: -0.1769 (1.000)
Step: 77570, Reward: -0.2000 [0.40], Avg: -0.1776 (1.000)
Step: 77653, Reward: 0.0000 [0.00], Avg: -0.1773 (1.000)
Step: 77827, Reward: 0.0000 [0.00], Avg: -0.1770 (1.000)
Step: 77844, Reward: 0.0000 [0.00], Avg: -0.1767 (1.000)
Step: 77949, Reward: 0.0000 [0.00], Avg: -0.1764 (1.000)
Step: 78003, Reward: 0.0000 [0.00], Avg: -0.1762 (1.000)
Step: 78083, Reward: 0.0000 [0.00], Avg: -0.1759 (1.000)
Step: 78191, Reward: -0.2000 [0.40], Avg: -0.1766 (1.000)
Step: 78253, Reward: 0.0000 [0.00], Avg: -0.1763 (1.000)
Step: 78335, Reward: -0.2000 [0.40], Avg: -0.1769 (1.000)
Step: 78483, Reward: -0.2000 [0.40], Avg: -0.1776 (1.000)
Step: 78550, Reward: 0.0000 [0.00], Avg: -0.1773 (1.000)
Step: 78565, Reward: 0.0000 [0.00], Avg: -0.1770 (1.000)
Step: 78858, Reward: 0.0000 [0.00], Avg: -0.1768 (1.000)
Step: 78870, Reward: 0.0000 [0.00], Avg: -0.1765 (1.000)
Step: 78953, Reward: -0.2000 [0.40], Avg: -0.1772 (1.000)
Step: 79006, Reward: -0.2000 [0.40], Avg: -0.1778 (1.000)
Step: 79088, Reward: 0.0000 [0.00], Avg: -0.1775 (1.000)
Step: 79145, Reward: -0.2000 [0.40], Avg: -0.1782 (1.000)
Step: 79545, Reward: 0.0000 [0.00], Avg: -0.1779 (1.000)
Step: 79607, Reward: 0.0000 [0.00], Avg: -0.1776 (1.000)
Step: 79731, Reward: 0.0000 [0.00], Avg: -0.1774 (1.000)
Step: 79795, Reward: 0.0000 [0.00], Avg: -0.1771 (1.000)
Step: 79810, Reward: 0.0000 [0.00], Avg: -0.1768 (1.000)
Step: 79954, Reward: 0.0000 [0.00], Avg: -0.1766 (1.000)
Step: 80000, Reward: -0.2000 [0.40], Avg: -0.1772 (1.000)
Step: 80065, Reward: 0.0000 [0.00], Avg: -0.1769 (1.000)
Step: 80138, Reward: 0.0000 [0.00], Avg: -0.1767 (1.000)
Step: 80363, Reward: -0.2000 [0.40], Avg: -0.1773 (1.000)
Step: 80763, Reward: 0.0000 [0.00], Avg: -0.1770 (1.000)
Step: 80796, Reward: 0.0000 [0.00], Avg: -0.1768 (1.000)
Step: 80884, Reward: 0.0000 [0.00], Avg: -0.1765 (1.000)
Step: 80957, Reward: 0.0000 [0.00], Avg: -0.1762 (1.000)
Step: 81093, Reward: 0.0000 [0.00], Avg: -0.1760 (1.000)
Step: 81144, Reward: 0.0000 [0.00], Avg: -0.1757 (1.000)
Step: 81544, Reward: -0.2000 [0.40], Avg: -0.1763 (1.000)
Step: 81597, Reward: -0.2000 [0.40], Avg: -0.1770 (1.000)
Step: 81728, Reward: 0.0000 [0.00], Avg: -0.1767 (1.000)
Step: 81823, Reward: 0.0000 [0.00], Avg: -0.1764 (1.000)
Step: 81881, Reward: 0.0000 [0.00], Avg: -0.1762 (1.000)
Step: 82023, Reward: 0.0000 [0.00], Avg: -0.1759 (1.000)
Step: 82162, Reward: 0.0000 [0.00], Avg: -0.1757 (1.000)
Step: 82297, Reward: -0.2000 [0.40], Avg: -0.1763 (1.000)
Step: 82411, Reward: 0.0000 [0.00], Avg: -0.1760 (1.000)
Step: 82483, Reward: -0.2000 [0.40], Avg: -0.1767 (1.000)
Step: 82557, Reward: 0.0000 [0.00], Avg: -0.1764 (1.000)
Step: 82643, Reward: 0.0000 [0.00], Avg: -0.1761 (1.000)
Step: 82704, Reward: 0.0000 [0.00], Avg: -0.1759 (1.000)
Step: 82819, Reward: 0.0000 [0.00], Avg: -0.1756 (1.000)
Step: 82849, Reward: 0.0000 [0.00], Avg: -0.1754 (1.000)
Step: 82971, Reward: 0.0000 [0.00], Avg: -0.1751 (1.000)
Step: 82992, Reward: 0.0000 [0.00], Avg: -0.1748 (1.000)
Step: 83392, Reward: 0.0000 [0.00], Avg: -0.1746 (1.000)
Step: 83560, Reward: 0.0000 [0.00], Avg: -0.1743 (1.000)
Step: 83842, Reward: -0.2000 [0.40], Avg: -0.1749 (1.000)
Step: 83930, Reward: 0.0000 [0.00], Avg: -0.1747 (1.000)
Step: 84330, Reward: 0.0000 [0.00], Avg: -0.1744 (1.000)
Step: 84437, Reward: 0.0000 [0.00], Avg: -0.1742 (1.000)
Step: 84837, Reward: -0.2000 [0.40], Avg: -0.1748 (1.000)
Step: 84858, Reward: 0.0000 [0.00], Avg: -0.1745 (1.000)
Step: 84944, Reward: 0.0000 [0.00], Avg: -0.1743 (1.000)
Step: 85140, Reward: -0.2000 [0.40], Avg: -0.1749 (1.000)
Step: 85255, Reward: 0.0000 [0.00], Avg: -0.1747 (1.000)
Step: 85318, Reward: 0.0000 [0.00], Avg: -0.1744 (1.000)
Step: 85718, Reward: -0.2000 [0.40], Avg: -0.1750 (1.000)
Step: 85745, Reward: 0.0000 [0.00], Avg: -0.1748 (1.000)
Step: 85822, Reward: 0.0000 [0.00], Avg: -0.1745 (1.000)
Step: 86014, Reward: 0.0000 [0.00], Avg: -0.1743 (1.000)
Step: 86078, Reward: 0.0000 [0.00], Avg: -0.1740 (1.000)
Step: 86102, Reward: 0.0000 [0.00], Avg: -0.1738 (1.000)
Step: 86278, Reward: -0.2000 [0.40], Avg: -0.1744 (1.000)
Step: 86383, Reward: 0.0000 [0.00], Avg: -0.1741 (1.000)
Step: 86473, Reward: -0.2000 [0.40], Avg: -0.1747 (1.000)
Step: 86524, Reward: 0.0000 [0.00], Avg: -0.1745 (1.000)
Step: 86716, Reward: 0.0000 [0.00], Avg: -0.1742 (1.000)
Step: 86790, Reward: 0.0000 [0.00], Avg: -0.1740 (1.000)
Step: 86850, Reward: -0.2000 [0.40], Avg: -0.1746 (1.000)
Step: 87073, Reward: 0.0000 [0.00], Avg: -0.1743 (1.000)
Step: 87127, Reward: 0.0000 [0.00], Avg: -0.1741 (1.000)
Step: 87187, Reward: 0.0000 [0.00], Avg: -0.1739 (1.000)
Step: 87254, Reward: 0.0000 [0.00], Avg: -0.1736 (1.000)
Step: 87331, Reward: 0.0000 [0.00], Avg: -0.1734 (1.000)
Step: 87403, Reward: 0.0000 [0.00], Avg: -0.1731 (1.000)
Step: 87475, Reward: 0.0000 [0.00], Avg: -0.1729 (1.000)
Step: 87592, Reward: 0.0000 [0.00], Avg: -0.1726 (1.000)
Step: 87787, Reward: 0.0000 [0.00], Avg: -0.1724 (1.000)
Step: 87844, Reward: 0.0000 [0.00], Avg: -0.1722 (1.000)
Step: 87925, Reward: -0.2000 [0.40], Avg: -0.1727 (1.000)
Step: 88001, Reward: 0.0000 [0.00], Avg: -0.1725 (1.000)
Step: 88106, Reward: -0.2000 [0.40], Avg: -0.1731 (1.000)
Step: 88397, Reward: -0.2000 [0.40], Avg: -0.1737 (1.000)
Step: 88461, Reward: 0.0000 [0.00], Avg: -0.1735 (1.000)
Step: 88509, Reward: 0.0000 [0.00], Avg: -0.1732 (1.000)
Step: 88612, Reward: 0.0000 [0.00], Avg: -0.1730 (1.000)
Step: 88912, Reward: 0.0000 [0.00], Avg: -0.1727 (1.000)
Step: 88969, Reward: 0.0000 [0.00], Avg: -0.1725 (1.000)
Step: 89034, Reward: -0.2000 [0.40], Avg: -0.1731 (1.000)
Step: 89078, Reward: 0.0000 [0.00], Avg: -0.1728 (1.000)
Step: 89248, Reward: 0.0000 [0.00], Avg: -0.1726 (1.000)
Step: 89309, Reward: 0.0000 [0.00], Avg: -0.1724 (1.000)
Step: 89392, Reward: 0.0000 [0.00], Avg: -0.1721 (1.000)
Step: 89476, Reward: -0.2000 [0.40], Avg: -0.1727 (1.000)
Step: 89559, Reward: -0.2000 [0.40], Avg: -0.1733 (1.000)
Step: 89693, Reward: 0.0000 [0.00], Avg: -0.1731 (1.000)
Step: 89772, Reward: 0.0000 [0.00], Avg: -0.1728 (1.000)
Step: 89784, Reward: 0.0000 [0.00], Avg: -0.1726 (1.000)
Step: 89851, Reward: 0.0000 [0.00], Avg: -0.1724 (1.000)
Step: 89950, Reward: 0.0000 [0.00], Avg: -0.1721 (1.000)
Step: 90027, Reward: 0.0000 [0.00], Avg: -0.1719 (1.000)
Step: 90117, Reward: 0.0000 [0.00], Avg: -0.1717 (1.000)
Step: 90239, Reward: 0.0000 [0.00], Avg: -0.1714 (1.000)
Step: 90295, Reward: 0.0000 [0.00], Avg: -0.1712 (1.000)
Step: 90375, Reward: 0.0000 [0.00], Avg: -0.1710 (1.000)
Step: 90422, Reward: 0.0000 [0.00], Avg: -0.1707 (1.000)
Step: 90530, Reward: 0.0000 [0.00], Avg: -0.1705 (1.000)
Step: 90601, Reward: 0.0000 [0.00], Avg: -0.1703 (1.000)
Step: 90678, Reward: 0.0000 [0.00], Avg: -0.1701 (1.000)
Step: 90748, Reward: 0.0000 [0.00], Avg: -0.1698 (1.000)
Step: 90792, Reward: 0.0000 [0.00], Avg: -0.1696 (1.000)
Step: 90922, Reward: 0.0000 [0.00], Avg: -0.1694 (1.000)
Step: 90953, Reward: 0.0000 [0.00], Avg: -0.1691 (1.000)
Step: 91324, Reward: 0.0000 [0.00], Avg: -0.1689 (1.000)
Step: 91339, Reward: 0.0000 [0.00], Avg: -0.1687 (1.000)
Step: 91357, Reward: 0.0000 [0.00], Avg: -0.1685 (1.000)
Step: 91476, Reward: 0.0000 [0.00], Avg: -0.1682 (1.000)
Step: 91876, Reward: 0.0000 [0.00], Avg: -0.1680 (1.000)
Step: 91990, Reward: 0.0000 [0.00], Avg: -0.1678 (1.000)
Step: 92068, Reward: 0.0000 [0.00], Avg: -0.1676 (1.000)
Step: 92181, Reward: 0.0000 [0.00], Avg: -0.1674 (1.000)
Step: 92225, Reward: -0.2000 [0.40], Avg: -0.1679 (1.000)
Step: 92263, Reward: 0.0000 [0.00], Avg: -0.1677 (1.000)
Step: 92307, Reward: 0.0000 [0.00], Avg: -0.1675 (1.000)
Step: 92465, Reward: 0.0000 [0.00], Avg: -0.1673 (1.000)
Step: 92622, Reward: 0.0000 [0.00], Avg: -0.1670 (1.000)
Step: 92689, Reward: 0.0000 [0.00], Avg: -0.1668 (1.000)
Step: 92876, Reward: -0.2000 [0.40], Avg: -0.1674 (1.000)
Step: 93016, Reward: -0.2000 [0.40], Avg: -0.1680 (1.000)
Step: 93089, Reward: -0.2000 [0.40], Avg: -0.1685 (1.000)
Step: 93169, Reward: 0.0000 [0.00], Avg: -0.1683 (1.000)
Step: 93241, Reward: 0.0000 [0.00], Avg: -0.1681 (1.000)
Step: 93272, Reward: 0.0000 [0.00], Avg: -0.1679 (1.000)
Step: 93328, Reward: 0.0000 [0.00], Avg: -0.1676 (1.000)
Step: 93405, Reward: 0.0000 [0.00], Avg: -0.1674 (1.000)
Step: 93550, Reward: 0.0000 [0.00], Avg: -0.1672 (1.000)
Step: 93657, Reward: -0.2000 [0.40], Avg: -0.1678 (1.000)
Step: 93722, Reward: 0.0000 [0.00], Avg: -0.1676 (1.000)
Step: 93848, Reward: 0.0000 [0.00], Avg: -0.1673 (1.000)
Step: 94019, Reward: 0.0000 [0.00], Avg: -0.1671 (1.000)
Step: 94120, Reward: -0.2000 [0.40], Avg: -0.1677 (1.000)
Step: 94185, Reward: 0.0000 [0.00], Avg: -0.1675 (1.000)
Step: 94198, Reward: 0.0000 [0.00], Avg: -0.1673 (1.000)
Step: 94296, Reward: 0.0000 [0.00], Avg: -0.1670 (1.000)
Step: 94390, Reward: 0.0000 [0.00], Avg: -0.1668 (1.000)
Step: 94457, Reward: 0.0000 [0.00], Avg: -0.1666 (1.000)
Step: 94612, Reward: 0.0000 [0.00], Avg: -0.1664 (1.000)
Step: 94624, Reward: 0.0000 [0.00], Avg: -0.1662 (1.000)
Step: 94705, Reward: 0.0000 [0.00], Avg: -0.1660 (1.000)
Step: 94748, Reward: 0.0000 [0.00], Avg: -0.1658 (1.000)
Step: 95023, Reward: 0.0000 [0.00], Avg: -0.1656 (1.000)
Step: 95049, Reward: 0.0000 [0.00], Avg: -0.1653 (1.000)
Step: 95129, Reward: 0.0000 [0.00], Avg: -0.1651 (1.000)
Step: 95280, Reward: 0.0000 [0.00], Avg: -0.1649 (1.000)
Step: 95413, Reward: -0.2000 [0.40], Avg: -0.1655 (1.000)
Step: 95485, Reward: 0.0000 [0.00], Avg: -0.1653 (1.000)
Step: 95501, Reward: 0.0000 [0.00], Avg: -0.1651 (1.000)
Step: 95557, Reward: 0.0000 [0.00], Avg: -0.1648 (1.000)
Step: 95629, Reward: 0.0000 [0.00], Avg: -0.1646 (1.000)
Step: 95794, Reward: 0.0000 [0.00], Avg: -0.1644 (1.000)
Step: 95932, Reward: 0.0000 [0.00], Avg: -0.1642 (1.000)
Step: 95991, Reward: 0.0000 [0.00], Avg: -0.1640 (1.000)
Step: 96251, Reward: 0.0000 [0.00], Avg: -0.1638 (1.000)
Step: 96284, Reward: 0.0000 [0.00], Avg: -0.1636 (1.000)
Step: 96584, Reward: 0.0000 [0.00], Avg: -0.1634 (1.000)
Step: 96661, Reward: 0.0000 [0.00], Avg: -0.1632 (1.000)
Step: 96788, Reward: 0.0000 [0.00], Avg: -0.1630 (1.000)
Step: 96881, Reward: 0.0000 [0.00], Avg: -0.1628 (1.000)
Step: 97006, Reward: 0.0000 [0.00], Avg: -0.1626 (1.000)
Step: 97103, Reward: 0.0000 [0.00], Avg: -0.1624 (1.000)
Step: 97120, Reward: 0.0000 [0.00], Avg: -0.1622 (1.000)
Step: 97200, Reward: -0.2000 [0.40], Avg: -0.1627 (1.000)
Step: 97500, Reward: 0.0000 [0.00], Avg: -0.1625 (1.000)
Step: 97900, Reward: 0.0000 [0.00], Avg: -0.1623 (1.000)
Step: 98269, Reward: -0.2000 [0.40], Avg: -0.1629 (1.000)
Step: 98342, Reward: 0.0000 [0.00], Avg: -0.1627 (1.000)
Step: 98456, Reward: 0.0000 [0.00], Avg: -0.1625 (1.000)
Step: 98468, Reward: 0.0000 [0.00], Avg: -0.1623 (1.000)
Step: 98482, Reward: 0.0000 [0.00], Avg: -0.1621 (1.000)
Step: 98502, Reward: 0.0000 [0.00], Avg: -0.1619 (1.000)
Step: 98622, Reward: 0.0000 [0.00], Avg: -0.1617 (1.000)
Step: 98636, Reward: 0.0000 [0.00], Avg: -0.1615 (1.000)
Step: 98997, Reward: 0.0000 [0.00], Avg: -0.1613 (1.000)
Step: 99397, Reward: 0.0000 [0.00], Avg: -0.1611 (1.000)
Step: 99458, Reward: 0.0000 [0.00], Avg: -0.1609 (1.000)
Step: 99520, Reward: 0.0000 [0.00], Avg: -0.1607 (1.000)
Step: 99697, Reward: -0.2000 [0.40], Avg: -0.1612 (1.000)
Step: 99825, Reward: 0.0000 [0.00], Avg: -0.1610 (1.000)
Step: 99948, Reward: 0.0000 [0.00], Avg: -0.1608 (1.000)
