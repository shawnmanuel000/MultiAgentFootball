Model: <class 'models.ppo.PPOAgent'>, Dir: BipedalWalker-v2
num_envs: 16, state_size: (24,), action_size: (4,), action_space: Box(4,),

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.05				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) * critic_error.pow(2) * scale
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss.mean())
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		if done[0] or len(self.buffer) >= self.update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, scale=16*dones.size(0)/len(self.replay_buffer))

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[6]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class AsyncAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = AsyncAgent(envs.state_size, envs.action_size, num_envs, model)
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.stack.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0]:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 99, Reward: -108.0130 [7.44], Avg: -115.4483 (1.000)
Step: 1699, Reward: -115.2992 [6.61], Avg: -118.6779 (1.000)
Step: 1794, Reward: -110.1577 [9.07], Avg: -118.8600 (1.000)
Step: 3394, Reward: -101.5580 [10.52], Avg: -117.1651 (1.000)
Step: 4994, Reward: -100.8474 [13.19], Avg: -116.5402 (1.000)
Step: 5095, Reward: -101.3734 [8.27], Avg: -115.3916 (1.000)
Step: 5212, Reward: -97.2530 [4.63], Avg: -113.4615 (1.000)
Step: 5285, Reward: -103.0692 [7.25], Avg: -113.0683 (1.000)
Step: 5344, Reward: -91.8284 [7.38], Avg: -111.5282 (1.000)
Step: 6944, Reward: -101.1652 [15.32], Avg: -112.0236 (1.000)
Step: 7064, Reward: -97.6566 [10.59], Avg: -111.6799 (1.000)
Step: 7138, Reward: -98.4999 [5.71], Avg: -111.0577 (1.000)
Step: 7200, Reward: -88.4652 [5.75], Avg: -109.7624 (1.000)
Step: 8800, Reward: -98.9877 [10.53], Avg: -109.7448 (1.000)
Step: 8864, Reward: -103.8351 [8.17], Avg: -109.8953 (1.000)
Step: 10464, Reward: -101.7869 [11.78], Avg: -110.1248 (1.000)
Step: 12064, Reward: -100.6488 [13.06], Avg: -110.3358 (1.000)
Step: 12146, Reward: -88.7492 [9.92], Avg: -109.6874 (1.000)
Step: 13746, Reward: -86.5357 [13.81], Avg: -109.1959 (1.000)
Step: 15346, Reward: -77.4140 [3.85], Avg: -107.7992 (1.000)
Step: 15410, Reward: -74.5891 [4.20], Avg: -106.4177 (1.000)
Step: 17010, Reward: -77.1853 [17.28], Avg: -105.8743 (1.000)
Step: 17119, Reward: -73.8431 [15.17], Avg: -105.1411 (1.000)
Step: 18719, Reward: -72.5406 [6.25], Avg: -104.0430 (1.000)
Step: 20319, Reward: -63.4852 [3.64], Avg: -102.5664 (1.000)
Step: 21919, Reward: -60.4092 [4.97], Avg: -101.1361 (1.000)
Step: 21995, Reward: -56.4846 [3.44], Avg: -99.6097 (1.000)
Step: 23595, Reward: -76.8631 [25.40], Avg: -99.7044 (1.000)
Step: 25195, Reward: -47.6146 [2.26], Avg: -97.9860 (1.000)
Step: 26795, Reward: -58.1449 [24.30], Avg: -97.4678 (1.000)
Step: 26882, Reward: -69.6871 [36.69], Avg: -97.7552 (1.000)
Step: 28482, Reward: -35.7382 [6.34], Avg: -96.0151 (1.000)
Step: 30082, Reward: -23.6170 [4.55], Avg: -93.9590 (1.000)
Step: 31682, Reward: -12.9860 [5.53], Avg: -91.7402 (1.000)
Step: 33282, Reward: -27.8002 [44.50], Avg: -91.1848 (1.000)
Step: 34882, Reward: 15.4252 [8.10], Avg: -88.4485 (1.000)
Step: 36482, Reward: 35.3528 [12.85], Avg: -85.4497 (1.000)
Step: 38082, Reward: 60.3007 [4.48], Avg: -81.7321 (1.000)
Step: 39682, Reward: 55.9468 [10.94], Avg: -78.4824 (1.000)
Step: 41282, Reward: 87.1995 [9.89], Avg: -74.5875 (1.000)
Step: 42882, Reward: 90.6389 [9.49], Avg: -70.7890 (1.000)
Step: 44482, Reward: 92.9410 [12.04], Avg: -67.1773 (1.000)
Step: 45108, Reward: 89.5381 [12.30], Avg: -63.8188 (1.000)
Step: 46708, Reward: 51.7443 [81.71], Avg: -63.0493 (1.000)
Step: 48308, Reward: 114.5002 [9.39], Avg: -59.3124 (1.000)
Step: 48372, Reward: 76.5515 [73.08], Avg: -57.9476 (1.000)
Step: 49972, Reward: 116.9949 [8.74], Avg: -54.4115 (1.000)
Step: 51572, Reward: 87.1992 [94.81], Avg: -53.4365 (1.000)
Step: 53172, Reward: 114.7426 [5.74], Avg: -50.1215 (1.000)
Step: 54772, Reward: 116.5607 [5.07], Avg: -46.8893 (1.000)
Step: 56372, Reward: 118.6756 [12.96], Avg: -43.8971 (1.000)
Step: 57972, Reward: 137.4584 [9.38], Avg: -40.5899 (1.000)
Step: 59572, Reward: 124.2516 [3.72], Avg: -37.5499 (1.000)
Step: 61172, Reward: 131.1634 [48.21], Avg: -35.3183 (1.000)
Step: 62772, Reward: 121.2916 [61.76], Avg: -33.5938 (1.000)
Step: 64372, Reward: 115.2296 [114.86], Avg: -32.9873 (1.000)
Step: 65913, Reward: 38.8288 [97.77], Avg: -33.4425 (1.000)
Step: 67513, Reward: 144.6794 [10.01], Avg: -30.5441 (1.000)
Step: 69113, Reward: 114.3851 [90.89], Avg: -29.6282 (1.000)
Step: 70713, Reward: 176.4080 [5.34], Avg: -26.2833 (1.000)
Step: 72313, Reward: 160.3584 [14.54], Avg: -23.4619 (1.000)
Step: 73913, Reward: 116.1292 [102.13], Avg: -22.8577 (1.000)
Step: 75513, Reward: 173.7009 [5.99], Avg: -19.8328 (1.000)
Step: 76622, Reward: 184.0712 [9.26], Avg: -16.7915 (1.000)
Step: 78222, Reward: 127.7978 [85.78], Avg: -15.8866 (1.000)
Step: 79822, Reward: 175.2297 [8.92], Avg: -13.1261 (1.000)
Step: 81422, Reward: 131.0976 [112.51], Avg: -12.6527 (1.000)
Step: 82001, Reward: 143.6978 [78.28], Avg: -11.5046 (1.000)
Step: 83601, Reward: 188.5529 [7.60], Avg: -8.7154 (1.000)
Step: 85201, Reward: 128.5004 [87.52], Avg: -8.0054 (1.000)
Step: 85255, Reward: 119.7514 [120.98], Avg: -7.9100 (1.000)
Step: 86855, Reward: 172.7934 [11.29], Avg: -5.5571 (1.000)
Step: 88455, Reward: 201.3808 [3.02], Avg: -2.7638 (1.000)
Step: 90055, Reward: 199.8640 [16.49], Avg: -0.2484 (1.000)
Step: 91655, Reward: 210.4650 [4.51], Avg: 2.5010 (1.000)
Step: 93255, Reward: 203.0383 [3.25], Avg: 5.0968 (1.000)
Step: 94855, Reward: 207.3063 [11.99], Avg: 7.5672 (1.000)
Step: 96455, Reward: 217.6915 [6.87], Avg: 10.1729 (1.000)
Step: 98055, Reward: 153.1363 [132.97], Avg: 10.2994 (1.000)
Step: 99655, Reward: 219.5104 [8.79], Avg: 12.8047 (1.000)
Step: 99730, Reward: 207.6792 [7.21], Avg: 15.1215 (1.000)
Step: 101330, Reward: 215.9177 [8.68], Avg: 17.4645 (1.000)
Step: 102712, Reward: 212.5124 [13.78], Avg: 19.6484 (1.000)
Step: 104312, Reward: 218.8998 [8.35], Avg: 21.9211 (1.000)
Step: 105912, Reward: 166.0028 [139.56], Avg: 21.9743 (1.000)
Step: 107512, Reward: 159.0519 [148.72], Avg: 21.8390 (1.000)
Step: 109039, Reward: 212.8092 [63.22], Avg: 23.3074 (1.000)
Step: 110639, Reward: 233.6284 [7.03], Avg: 25.6176 (1.000)
Step: 112223, Reward: 243.9176 [7.61], Avg: 27.9849 (1.000)
Step: 113823, Reward: 244.4608 [5.58], Avg: 30.3281 (1.000)
Step: 113922, Reward: 164.8350 [142.28], Avg: 30.2427 (1.000)
Step: 115522, Reward: 242.0138 [9.16], Avg: 32.4451 (1.000)
Step: 117122, Reward: 152.5411 [100.90], Avg: 32.6514 (1.000)
Step: 118705, Reward: 208.6720 [85.93], Avg: 33.6098 (1.000)
Step: 120296, Reward: 154.3773 [121.56], Avg: 33.6014 (1.000)
Step: 121853, Reward: 252.0459 [4.80], Avg: 35.8269 (1.000)
Step: 123240, Reward: 255.6682 [1.48], Avg: 38.0781 (1.000)
Step: 124625, Reward: 117.4499 [171.65], Avg: 37.1365 (1.000)
Step: 126059, Reward: 259.8285 [1.19], Avg: 39.3739 (1.000)
Step: 127177, Reward: 260.4798 [2.44], Avg: 41.5605 (1.000)
Step: 127274, Reward: 204.8577 [67.01], Avg: 42.5139 (1.000)
Step: 128694, Reward: 142.6759 [156.58], Avg: 41.9608 (1.000)
Step: 130151, Reward: 259.7119 [2.49], Avg: 44.0506 (1.000)
Step: 131616, Reward: 193.0430 [130.35], Avg: 44.2298 (1.000)
Step: 133029, Reward: 207.8012 [107.58], Avg: 44.7631 (1.000)
Step: 133985, Reward: 260.9568 [4.61], Avg: 46.7592 (1.000)
Step: 135547, Reward: 261.2805 [3.05], Avg: 48.7356 (1.000)
Step: 136897, Reward: 145.9004 [144.44], Avg: 48.2979 (1.000)
Step: 137321, Reward: 201.8745 [124.28], Avg: 48.5667 (1.000)
Step: 138619, Reward: 222.1893 [91.83], Avg: 49.3102 (1.000)
Step: 139567, Reward: 266.0280 [3.91], Avg: 51.2274 (1.000)
Step: 140919, Reward: 267.2789 [2.68], Avg: 53.1325 (1.000)
Step: 142197, Reward: 267.7425 [4.00], Avg: 54.9963 (1.000)
Step: 143482, Reward: 266.0936 [3.77], Avg: 56.8150 (1.000)
Step: 144749, Reward: 162.7524 [126.42], Avg: 56.6369 (1.000)
Step: 146032, Reward: 242.2584 [48.88], Avg: 57.8156 (1.000)
Step: 147357, Reward: 269.3185 [2.73], Avg: 59.6000 (1.000)
Step: 148644, Reward: 155.7222 [156.23], Avg: 59.0906 (1.000)
Step: 149949, Reward: 206.4949 [127.43], Avg: 59.2584 (1.000)
Step: 151178, Reward: 270.0773 [2.97], Avg: 60.9905 (1.000)
Step: 152544, Reward: 269.7906 [2.05], Avg: 62.6993 (1.000)
Step: 153787, Reward: 267.3687 [2.71], Avg: 64.3547 (1.000)
Step: 155065, Reward: 268.3892 [3.06], Avg: 65.9886 (1.000)
Step: 156309, Reward: 267.4465 [1.57], Avg: 67.6006 (1.000)
Step: 157577, Reward: 265.5760 [2.23], Avg: 69.1666 (1.000)
Step: 158839, Reward: 266.8254 [3.13], Avg: 70.7105 (1.000)
Step: 160096, Reward: 268.5630 [4.19], Avg: 72.2354 (1.000)
Step: 161366, Reward: 270.5656 [3.39], Avg: 73.7583 (1.000)
Step: 162591, Reward: 268.8491 [3.60], Avg: 75.2428 (1.000)
Step: 163808, Reward: 163.4673 [133.22], Avg: 74.8967 (1.000)
Step: 165014, Reward: 210.1511 [120.34], Avg: 75.0105 (1.000)
Step: 166307, Reward: 272.5990 [2.91], Avg: 76.4854 (1.000)
Step: 167518, Reward: 271.1283 [2.84], Avg: 77.9275 (1.000)
Step: 168791, Reward: 268.5577 [4.72], Avg: 79.3148 (1.000)
Step: 169987, Reward: 271.0854 [0.64], Avg: 80.7306 (1.000)
Step: 170451, Reward: 272.3616 [1.93], Avg: 82.1255 (1.000)
Step: 170544, Reward: 197.2311 [150.60], Avg: 81.8664 (1.000)
Step: 171179, Reward: 269.4970 [2.18], Avg: 83.2102 (1.000)
Step: 172379, Reward: 270.1546 [2.14], Avg: 84.5397 (1.000)
Step: 173593, Reward: 270.6073 [2.40], Avg: 85.8517 (1.000)
Step: 174761, Reward: 273.3242 [0.92], Avg: 87.1747 (1.000)
Step: 175963, Reward: 272.8339 [2.60], Avg: 88.4639 (1.000)
Step: 177187, Reward: 272.8842 [3.11], Avg: 89.7318 (1.000)
Step: 177511, Reward: 273.5241 [1.77], Avg: 90.9958 (1.000)
Step: 178683, Reward: 270.8487 [2.42], Avg: 92.2195 (1.000)
Step: 179877, Reward: 272.6622 [0.98], Avg: 93.4488 (1.000)
Step: 181062, Reward: 275.7668 [1.23], Avg: 94.6806 (1.000)
Step: 181422, Reward: 181.6096 [130.73], Avg: 94.3847 (1.000)
Step: 182635, Reward: 273.6212 [4.39], Avg: 95.5582 (1.000)
Step: 183787, Reward: 274.6104 [1.48], Avg: 96.7420 (1.000)
Step: 184917, Reward: 272.6671 [1.53], Avg: 97.8969 (1.000)
Step: 186082, Reward: 272.7216 [2.34], Avg: 99.0317 (1.000)
Step: 187275, Reward: 272.9085 [1.79], Avg: 100.1564 (1.000)
Step: 188444, Reward: 241.2589 [60.45], Avg: 100.6801 (1.000)
Step: 189648, Reward: 270.6423 [2.21], Avg: 101.7624 (1.000)
Step: 190909, Reward: 272.5061 [2.44], Avg: 102.8412 (1.000)
Step: 192062, Reward: 272.5468 [1.87], Avg: 103.9103 (1.000)
Step: 193317, Reward: 276.7716 [3.01], Avg: 104.9853 (1.000)
Step: 194440, Reward: 274.3715 [2.20], Avg: 106.0367 (1.000)
Step: 195611, Reward: 275.9277 [1.13], Avg: 107.0915 (1.000)
Step: 196019, Reward: 276.8529 [3.60], Avg: 108.1236 (1.000)
Step: 197167, Reward: 253.0465 [51.23], Avg: 108.7019 (1.000)
Step: 198266, Reward: 276.0753 [3.36], Avg: 109.7081 (1.000)
Step: 199400, Reward: 275.6816 [1.55], Avg: 110.7107 (1.000)
Step: 200547, Reward: 275.7669 [2.08], Avg: 111.6984 (1.000)
Step: 201684, Reward: 276.6720 [1.59], Avg: 112.6826 (1.000)
Step: 202816, Reward: 279.9151 [1.24], Avg: 113.6766 (1.000)
Step: 203884, Reward: 279.9723 [0.77], Avg: 114.6619 (1.000)
Step: 204980, Reward: 277.7933 [2.63], Avg: 115.6116 (1.000)
Step: 206084, Reward: 222.7274 [110.79], Avg: 115.5900 (1.000)
Step: 207148, Reward: 278.8384 [4.06], Avg: 116.5209 (1.000)
Step: 207842, Reward: 278.2148 [3.16], Avg: 117.4426 (1.000)
Step: 209001, Reward: 223.7031 [106.20], Avg: 117.4429 (1.000)
Step: 210110, Reward: 170.9437 [128.42], Avg: 117.0124 (1.000)
Step: 211239, Reward: 275.9134 [2.58], Avg: 117.9056 (1.000)
Step: 212353, Reward: 276.5324 [1.92], Avg: 118.7960 (1.000)
Step: 213457, Reward: 276.8755 [0.95], Avg: 119.6837 (1.000)
Step: 214568, Reward: 239.4236 [71.49], Avg: 119.9548 (1.000)
Step: 215412, Reward: 276.4021 [2.02], Avg: 120.8175 (1.000)
Step: 216536, Reward: 277.2836 [1.93], Avg: 121.6761 (1.000)
Step: 217641, Reward: 277.9279 [1.40], Avg: 122.5316 (1.000)
Step: 218767, Reward: 276.6260 [1.84], Avg: 123.3681 (1.000)
Step: 219568, Reward: 276.0746 [1.63], Avg: 124.1937 (1.000)
Step: 220615, Reward: 274.4526 [2.91], Avg: 124.9945 (1.000)
Step: 221730, Reward: 196.9929 [98.81], Avg: 124.8496 (1.000)
Step: 222825, Reward: 277.6432 [0.74], Avg: 125.6671 (1.000)
Step: 223360, Reward: 273.1530 [2.39], Avg: 126.4430 (1.000)
Step: 224446, Reward: 274.3354 [0.81], Avg: 127.2254 (1.000)
Step: 225562, Reward: 276.9285 [2.25], Avg: 128.0056 (1.000)
Step: 226726, Reward: 274.4796 [2.30], Avg: 128.7644 (1.000)
Step: 227870, Reward: 275.3654 [0.89], Avg: 129.5273 (1.000)
Step: 228989, Reward: 276.5182 [2.59], Avg: 130.2794 (1.000)
Step: 230095, Reward: 245.4600 [64.11], Avg: 130.5440 (1.000)
Step: 231180, Reward: 278.3140 [1.83], Avg: 131.2963 (1.000)
Step: 232017, Reward: 277.8240 [1.56], Avg: 132.0397 (1.000)
Step: 232977, Reward: 104.1369 [143.04], Avg: 131.1675 (1.000)
Step: 234130, Reward: 204.1921 [89.55], Avg: 131.0836 (1.000)
Step: 234640, Reward: 215.4790 [116.86], Avg: 130.9196 (1.000)
Step: 235757, Reward: 227.6009 [89.30], Avg: 130.9567 (1.000)
Step: 236918, Reward: 275.2613 [2.69], Avg: 131.6648 (1.000)
Step: 238148, Reward: 216.1459 [115.10], Avg: 131.5125 (1.000)
Step: 239354, Reward: 272.7135 [1.39], Avg: 132.2046 (1.000)
Step: 240547, Reward: 270.2667 [1.18], Avg: 132.8790 (1.000)
Step: 241706, Reward: 214.4271 [72.24], Avg: 132.9246 (1.000)
Step: 242933, Reward: 272.5400 [1.74], Avg: 133.5972 (1.000)
Step: 244107, Reward: 274.9405 [2.88], Avg: 134.2693 (1.000)
Step: 244506, Reward: 275.2267 [2.28], Avg: 134.9393 (1.000)
Step: 245659, Reward: 275.9187 [1.82], Avg: 135.6083 (1.000)
Step: 246828, Reward: 275.3034 [1.77], Avg: 136.2682 (1.000)
Step: 247999, Reward: 275.7051 [0.98], Avg: 136.9275 (1.000)
Step: 249135, Reward: 170.3553 [133.61], Avg: 136.4527 (1.000)
Step: 250250, Reward: 275.7701 [3.02], Avg: 137.0956 (1.000)
Step: 251494, Reward: 275.2528 [1.71], Avg: 137.7362 (1.000)
Step: 252445, Reward: 273.9649 [1.32], Avg: 138.3666 (1.000)
Step: 253629, Reward: 273.3355 [3.26], Avg: 138.9792 (1.000)
Step: 254744, Reward: 275.7373 [1.73], Avg: 139.6043 (1.000)
Step: 255892, Reward: 275.8979 [1.69], Avg: 140.2246 (1.000)
Step: 256966, Reward: 277.4997 [2.09], Avg: 140.8447 (1.000)
Step: 258085, Reward: 275.8525 [0.78], Avg: 141.4577 (1.000)
Step: 259231, Reward: 275.3328 [3.41], Avg: 142.0507 (1.000)
Step: 260360, Reward: 274.1558 [1.72], Avg: 142.6407 (1.000)
Step: 261491, Reward: 276.5212 [1.56], Avg: 143.2367 (1.000)
Step: 262618, Reward: 274.3920 [2.53], Avg: 143.8135 (1.000)
Step: 263767, Reward: 250.1273 [51.25], Avg: 144.0594 (1.000)
Step: 264858, Reward: 216.1956 [121.92], Avg: 143.8381 (1.000)
Step: 265919, Reward: 276.0678 [1.15], Avg: 144.4181 (1.000)
Step: 266993, Reward: 277.7653 [3.01], Avg: 144.9923 (1.000)
Step: 268089, Reward: 277.2187 [1.00], Avg: 145.5679 (1.000)
Step: 268932, Reward: 140.9546 [169.17], Avg: 144.8090 (1.000)
Step: 269456, Reward: 171.9561 [131.83], Avg: 144.3539 (1.000)
Step: 270077, Reward: 275.5955 [1.08], Avg: 144.9173 (1.000)
Step: 271146, Reward: 229.1694 [91.29], Avg: 144.8870 (1.000)
Step: 272251, Reward: 277.5363 [1.91], Avg: 145.4481 (1.000)
Step: 273281, Reward: 171.0017 [146.81], Avg: 144.9299 (1.000)
Step: 274346, Reward: 209.0588 [131.90], Avg: 144.6415 (1.000)
Step: 274744, Reward: 160.0042 [154.23], Avg: 144.0531 (1.000)
Step: 275837, Reward: 278.4520 [1.72], Avg: 144.6129 (1.000)
Step: 276893, Reward: 279.5853 [0.46], Avg: 145.1781 (1.000)
Step: 277968, Reward: 277.3308 [1.66], Avg: 145.7241 (1.000)
Step: 279049, Reward: 277.1883 [2.03], Avg: 146.2634 (1.000)
Step: 280086, Reward: 276.6666 [1.65], Avg: 146.7976 (1.000)
Step: 281144, Reward: 230.9375 [88.55], Avg: 146.7794 (1.000)
Step: 282188, Reward: 275.4053 [0.95], Avg: 147.3048 (1.000)
Step: 283259, Reward: 276.0926 [2.95], Avg: 147.8205 (1.000)
Step: 283424, Reward: 245.4757 [60.34], Avg: 147.9728 (1.000)
Step: 284472, Reward: 208.8966 [139.52], Avg: 147.6533 (1.000)
Step: 285535, Reward: 278.2800 [2.34], Avg: 148.1727 (1.000)
Step: 286596, Reward: 238.7980 [79.23], Avg: 148.2187 (1.000)
Step: 287498, Reward: 153.4571 [150.13], Avg: 147.6368 (1.000)
Step: 288556, Reward: 230.1701 [95.70], Avg: 147.5841 (1.000)
Step: 289637, Reward: 275.7565 [1.36], Avg: 148.0894 (1.000)
Step: 290683, Reward: 275.4758 [2.00], Avg: 148.5869 (1.000)
Step: 291711, Reward: 275.0038 [2.09], Avg: 149.0783 (1.000)
Step: 292796, Reward: 277.0935 [1.89], Avg: 149.5749 (1.000)
Step: 293894, Reward: 274.6640 [1.44], Avg: 150.0598 (1.000)
Step: 294998, Reward: 278.4764 [1.56], Avg: 150.5554 (1.000)
Step: 296080, Reward: 277.3004 [2.03], Avg: 151.0406 (1.000)
Step: 297177, Reward: 278.6895 [1.02], Avg: 151.5315 (1.000)
Step: 298298, Reward: 279.8777 [0.93], Avg: 152.0234 (1.000)
Step: 299324, Reward: 278.1040 [2.55], Avg: 152.4985 (1.000)
Step: 300402, Reward: 277.7297 [0.79], Avg: 152.9753 (1.000)
Step: 301452, Reward: 278.9963 [1.30], Avg: 153.4514 (1.000)
Step: 302529, Reward: 277.9989 [0.70], Avg: 153.9223 (1.000)
Step: 303543, Reward: 238.8769 [80.85], Avg: 153.9378 (1.000)
Step: 304578, Reward: 221.4114 [111.32], Avg: 153.7724 (1.000)
Step: 305599, Reward: 277.3065 [1.73], Avg: 154.2303 (1.000)
Step: 306639, Reward: 152.3962 [155.68], Avg: 153.6403 (1.000)
Step: 307706, Reward: 239.3669 [75.96], Avg: 153.6768 (1.000)
Step: 308771, Reward: 277.6410 [0.82], Avg: 154.1346 (1.000)
Step: 309786, Reward: 279.4299 [0.74], Avg: 154.5959 (1.000)
Step: 310788, Reward: 279.7758 [1.00], Avg: 155.0541 (1.000)
Step: 311809, Reward: 278.9927 [1.65], Avg: 155.5037 (1.000)
Step: 312846, Reward: 280.1142 [0.74], Avg: 155.9575 (1.000)
Step: 313909, Reward: 279.2085 [1.74], Avg: 156.4009 (1.000)
Step: 314931, Reward: 280.7437 [0.97], Avg: 156.8496 (1.000)
Step: 315955, Reward: 279.7675 [1.68], Avg: 157.2888 (1.000)
Step: 317045, Reward: 282.0141 [0.97], Avg: 157.7356 (1.000)
Step: 318021, Reward: 206.4504 [153.76], Avg: 157.3577 (1.000)
Step: 319079, Reward: 282.8747 [2.88], Avg: 157.7973 (1.000)
Step: 320149, Reward: 282.9986 [1.41], Avg: 158.2394 (1.000)
Step: 321165, Reward: 281.4954 [1.69], Avg: 158.6720 (1.000)
Step: 321644, Reward: 281.9843 [1.10], Avg: 159.1054 (1.000)
Step: 322660, Reward: 282.6900 [1.27], Avg: 159.5376 (1.000)
Step: 323649, Reward: 232.1369 [100.22], Avg: 159.4403 (1.000)
Step: 324666, Reward: 282.0218 [1.71], Avg: 159.8645 (1.000)
Step: 325630, Reward: 281.6549 [2.53], Avg: 160.2815 (1.000)
Step: 326640, Reward: 280.2113 [1.61], Avg: 160.6937 (1.000)
Step: 327635, Reward: 241.7357 [76.78], Avg: 160.7085 (1.000)
Step: 328654, Reward: 281.1531 [2.59], Avg: 161.1163 (1.000)
Step: 329644, Reward: 282.0438 [1.18], Avg: 161.5292 (1.000)
Step: 330694, Reward: 283.7023 [0.54], Avg: 161.9472 (1.000)
Step: 331693, Reward: 282.2183 [1.41], Avg: 162.3543 (1.000)
Step: 332691, Reward: 280.7795 [1.11], Avg: 162.7547 (1.000)
Step: 333701, Reward: 279.1182 [2.27], Avg: 163.1428 (1.000)
Step: 334717, Reward: 282.0904 [1.50], Avg: 163.5409 (1.000)
Step: 335730, Reward: 281.9520 [1.81], Avg: 163.9348 (1.000)
Step: 336754, Reward: 245.3976 [75.91], Avg: 163.9535 (1.000)
Step: 337745, Reward: 281.0672 [1.23], Avg: 164.3424 (1.000)
Step: 338733, Reward: 283.2686 [1.33], Avg: 164.7356 (1.000)
Step: 339736, Reward: 280.7462 [2.34], Avg: 165.1145 (1.000)
Step: 340690, Reward: 281.5267 [1.10], Avg: 165.4976 (1.000)
Step: 341660, Reward: 285.4144 [2.44], Avg: 165.8866 (1.000)
Step: 342664, Reward: 282.8890 [1.98], Avg: 166.2662 (1.000)
Step: 343669, Reward: 282.2616 [0.57], Avg: 166.6459 (1.000)
Step: 344666, Reward: 280.8869 [0.80], Avg: 167.0178 (1.000)
Step: 345706, Reward: 281.3595 [2.19], Avg: 167.3843 (1.000)
Step: 346703, Reward: 282.9775 [1.55], Avg: 167.7558 (1.000)
Step: 347081, Reward: 281.5663 [2.32], Avg: 168.1178 (1.000)
Step: 348075, Reward: 282.3657 [2.50], Avg: 168.4794 (1.000)
Step: 349132, Reward: 284.7237 [2.05], Avg: 168.8478 (1.000)
Step: 350105, Reward: 283.3858 [0.89], Avg: 169.2132 (1.000)
Step: 351126, Reward: 285.0417 [1.40], Avg: 169.5800 (1.000)
Step: 352151, Reward: 282.0458 [5.46], Avg: 169.9218 (1.000)
Step: 353172, Reward: 284.3531 [1.10], Avg: 170.2828 (1.000)
Step: 354124, Reward: 284.0830 [1.56], Avg: 170.6391 (1.000)
Step: 355119, Reward: 283.8063 [0.62], Avg: 170.9952 (1.000)
Step: 356119, Reward: 214.1653 [138.37], Avg: 170.6949 (1.000)
Step: 357129, Reward: 284.8494 [0.98], Avg: 171.0508 (1.000)
Step: 358108, Reward: 283.7246 [1.67], Avg: 171.3988 (1.000)
Step: 359093, Reward: 148.9468 [171.98], Avg: 170.7912 (1.000)
Step: 360091, Reward: 286.9141 [1.56], Avg: 171.1481 (1.000)
Step: 360706, Reward: 284.7321 [1.08], Avg: 171.4975 (1.000)
Step: 361724, Reward: 284.9362 [1.67], Avg: 171.8435 (1.000)
Step: 362710, Reward: 282.4441 [1.29], Avg: 172.1809 (1.000)
Step: 363702, Reward: 284.9948 [0.94], Avg: 172.5251 (1.000)
Step: 363764, Reward: 282.4844 [1.82], Avg: 172.8569 (1.000)
Step: 364768, Reward: 283.6783 [1.30], Avg: 173.1918 (1.000)
Step: 365785, Reward: 283.4176 [2.13], Avg: 173.5213 (1.000)
Step: 366791, Reward: 283.4078 [1.37], Avg: 173.8512 (1.000)
Step: 367780, Reward: 284.1255 [1.90], Avg: 174.1796 (1.000)
Step: 368831, Reward: 283.5714 [1.57], Avg: 174.5053 (1.000)
Step: 369827, Reward: 282.8613 [1.17], Avg: 174.8282 (1.000)
Step: 370835, Reward: 282.2128 [1.40], Avg: 175.1464 (1.000)
Step: 371880, Reward: 283.9588 [1.57], Avg: 175.4675 (1.000)
Step: 372929, Reward: 283.2828 [0.95], Avg: 175.7865 (1.000)
Step: 373951, Reward: 283.2994 [2.08], Avg: 176.1003 (1.000)
Step: 374980, Reward: 284.4878 [1.46], Avg: 176.4176 (1.000)
Step: 375992, Reward: 282.3948 [1.50], Avg: 176.7267 (1.000)
Step: 377013, Reward: 283.8550 [0.82], Avg: 177.0403 (1.000)
Step: 378008, Reward: 283.6524 [1.18], Avg: 177.3504 (1.000)
Step: 379003, Reward: 284.8370 [1.87], Avg: 177.6601 (1.000)
Step: 379983, Reward: 284.9376 [1.56], Avg: 177.9692 (1.000)
Step: 380975, Reward: 248.1587 [72.31], Avg: 177.9630 (1.000)
Step: 381957, Reward: 283.6152 [1.61], Avg: 178.2655 (1.000)
Step: 382944, Reward: 285.1183 [1.57], Avg: 178.5706 (1.000)
Step: 383913, Reward: 284.0708 [1.54], Avg: 178.8711 (1.000)
Step: 384924, Reward: 282.8387 [1.17], Avg: 179.1674 (1.000)
Step: 385877, Reward: 283.9861 [1.78], Avg: 179.4635 (1.000)
Step: 386860, Reward: 284.4996 [0.95], Avg: 179.7617 (1.000)
Step: 387842, Reward: 282.7886 [2.02], Avg: 180.0503 (1.000)
Step: 388864, Reward: 285.3645 [1.74], Avg: 180.3454 (1.000)
Step: 389838, Reward: 241.7151 [88.53], Avg: 180.2682 (1.000)
Step: 390805, Reward: 285.0871 [1.71], Avg: 180.5603 (1.000)
Step: 391817, Reward: 284.4406 [1.86], Avg: 180.8485 (1.000)
Step: 392814, Reward: 286.4452 [0.54], Avg: 181.1444 (1.000)
Step: 393773, Reward: 286.5615 [1.28], Avg: 181.4369 (1.000)
Step: 394737, Reward: 287.0589 [1.27], Avg: 181.7292 (1.000)
Step: 395734, Reward: 229.0500 [116.34], Avg: 181.5364 (1.000)
Step: 396685, Reward: 285.8389 [1.49], Avg: 181.8228 (1.000)
Step: 397670, Reward: 248.4236 [80.08], Avg: 181.7854 (1.000)
Step: 398641, Reward: 236.1504 [64.51], Avg: 181.7573 (1.000)
Step: 399642, Reward: 285.1726 [0.57], Avg: 182.0414 (1.000)
Step: 400628, Reward: 285.3260 [1.02], Avg: 182.3231 (1.000)
Step: 401624, Reward: 286.4156 [0.93], Avg: 182.6065 (1.000)
Step: 402590, Reward: 220.3969 [134.64], Avg: 182.3412 (1.000)
Step: 403562, Reward: 285.8763 [1.36], Avg: 182.6203 (1.000)
Step: 404533, Reward: 229.7943 [111.64], Avg: 182.4447 (1.000)
Step: 405509, Reward: 231.2188 [110.88], Avg: 182.2759 (1.000)
Step: 406492, Reward: 210.5947 [104.05], Avg: 182.0707 (1.000)
Step: 407501, Reward: 284.3228 [1.76], Avg: 182.3423 (1.000)
Step: 408451, Reward: 207.6628 [156.53], Avg: 181.9886 (1.000)
Step: 409449, Reward: 286.3377 [1.37], Avg: 182.2655 (1.000)
Step: 410449, Reward: 231.1146 [114.76], Avg: 182.0887 (1.000)
Step: 411387, Reward: 286.1184 [1.36], Avg: 182.3633 (1.000)
Step: 412395, Reward: 182.4204 [133.23], Avg: 182.0081 (1.000)
Step: 412640, Reward: 285.9334 [1.09], Avg: 182.2816 (1.000)
Step: 413597, Reward: 163.8450 [149.79], Avg: 181.8354 (1.000)
Step: 414544, Reward: 286.5011 [1.32], Avg: 182.1088 (1.000)
Step: 415545, Reward: 285.9901 [1.80], Avg: 182.3782 (1.000)
Step: 416516, Reward: 287.2438 [0.61], Avg: 182.6525 (1.000)
Step: 417471, Reward: 251.9128 [65.35], Avg: 182.6628 (1.000)
Step: 418421, Reward: 219.4492 [133.93], Avg: 182.4085 (1.000)
Step: 419087, Reward: 260.7673 [52.47], Avg: 182.4761 (1.000)
Step: 420055, Reward: 287.4912 [3.03], Avg: 182.7417 (1.000)
Step: 421067, Reward: 287.6102 [1.92], Avg: 183.0091 (1.000)
Step: 422054, Reward: 287.4100 [2.29], Avg: 183.2736 (1.000)
Step: 423051, Reward: 244.2801 [82.57], Avg: 183.2179 (1.000)
Step: 424083, Reward: 284.9173 [0.95], Avg: 183.4776 (1.000)
Step: 425111, Reward: 229.0814 [113.58], Avg: 183.3028 (1.000)
Step: 426126, Reward: 246.5033 [76.97], Avg: 183.2675 (1.000)
Step: 427105, Reward: 285.9990 [1.17], Avg: 183.5273 (1.000)
Step: 428087, Reward: 286.0049 [1.24], Avg: 183.7855 (1.000)
Step: 429110, Reward: 286.1325 [0.94], Avg: 184.0436 (1.000)
Step: 430084, Reward: 283.9115 [0.72], Avg: 184.2952 (1.000)
Step: 431073, Reward: 285.2431 [2.66], Avg: 184.5440 (1.000)
Step: 432090, Reward: 261.8743 [49.55], Avg: 184.6142 (1.000)
Step: 433120, Reward: 284.7609 [1.59], Avg: 184.8624 (1.000)
Step: 434106, Reward: 285.1746 [1.18], Avg: 185.1115 (1.000)
Step: 435082, Reward: 284.7102 [1.86], Avg: 185.3565 (1.000)
Step: 436085, Reward: 208.4404 [152.36], Avg: 185.0333 (1.000)
Step: 437113, Reward: 283.9586 [1.81], Avg: 185.2755 (1.000)
Step: 438095, Reward: 284.9911 [1.77], Avg: 185.5191 (1.000)
Step: 439128, Reward: 287.1985 [1.14], Avg: 185.7686 (1.000)
Step: 440126, Reward: 288.0027 [0.93], Avg: 186.0193 (1.000)
Step: 441102, Reward: 284.9320 [1.60], Avg: 186.2596 (1.000)
Step: 442098, Reward: 156.1773 [160.22], Avg: 185.7909 (1.000)
Step: 443082, Reward: 286.3376 [1.14], Avg: 186.0351 (1.000)
Step: 444094, Reward: 288.1528 [1.53], Avg: 186.2817 (1.000)
Step: 445057, Reward: 288.6796 [2.15], Avg: 186.5268 (1.000)
Step: 445998, Reward: 289.4991 [0.57], Avg: 186.7765 (1.000)
Step: 446948, Reward: 288.3885 [1.29], Avg: 187.0206 (1.000)
Step: 447850, Reward: 288.1589 [1.54], Avg: 187.2624 (1.000)
Step: 448874, Reward: 287.5297 [0.59], Avg: 187.5037 (1.000)
Step: 449813, Reward: 288.7171 [2.00], Avg: 187.7434 (1.000)
Step: 450674, Reward: 288.9320 [0.91], Avg: 187.9850 (1.000)
Step: 451674, Reward: 287.4478 [1.35], Avg: 188.2209 (1.000)
Step: 452637, Reward: 285.2476 [1.38], Avg: 188.4502 (1.000)
Step: 453608, Reward: 286.2747 [2.01], Avg: 188.6794 (1.000)
Step: 454594, Reward: 286.7296 [1.82], Avg: 188.9091 (1.000)
Step: 455569, Reward: 285.9860 [1.28], Avg: 189.1372 (1.000)
Step: 456544, Reward: 238.9153 [95.71], Avg: 189.0281 (1.000)
Step: 457504, Reward: 285.4215 [2.53], Avg: 189.2505 (1.000)
Step: 458472, Reward: 288.4223 [0.81], Avg: 189.4830 (1.000)
Step: 459442, Reward: 287.0236 [1.65], Avg: 189.7092 (1.000)
Step: 460418, Reward: 287.7781 [1.14], Avg: 189.9373 (1.000)
Step: 461380, Reward: 287.0969 [0.99], Avg: 190.1630 (1.000)
Step: 462353, Reward: 289.3723 [1.11], Avg: 190.3928 (1.000)
Step: 463333, Reward: 288.4534 [1.52], Avg: 190.6183 (1.000)
Step: 464304, Reward: 288.6592 [1.27], Avg: 190.8439 (1.000)
Step: 465287, Reward: 289.1542 [1.24], Avg: 191.0697 (1.000)
Step: 466291, Reward: 288.1131 [2.12], Avg: 191.2899 (1.000)
Step: 467302, Reward: 287.4530 [0.57], Avg: 191.5112 (1.000)
Step: 468086, Reward: 288.8611 [0.61], Avg: 191.7346 (1.000)
Step: 469077, Reward: 288.4565 [0.49], Avg: 191.9563 (1.000)
Step: 470058, Reward: 287.3583 [2.80], Avg: 192.1692 (1.000)
Step: 471030, Reward: 286.3911 [1.41], Avg: 192.3821 (1.000)
Step: 472103, Reward: 285.7320 [0.64], Avg: 192.5943 (1.000)
Step: 473081, Reward: 286.0234 [2.35], Avg: 192.8022 (1.000)
Step: 474069, Reward: 286.3271 [2.21], Avg: 193.0102 (1.000)
Step: 475059, Reward: 285.9213 [2.06], Avg: 193.2167 (1.000)
Step: 476040, Reward: 286.4458 [1.70], Avg: 193.4242 (1.000)
Step: 477057, Reward: 284.6768 [1.34], Avg: 193.6277 (1.000)
Step: 478049, Reward: 285.3551 [0.99], Avg: 193.8325 (1.000)
Step: 479021, Reward: 285.5538 [1.64], Avg: 194.0354 (1.000)
Step: 479687, Reward: 284.7210 [1.46], Avg: 194.2359 (1.000)
Step: 480700, Reward: 285.7683 [2.07], Avg: 194.4365 (1.000)
Step: 481727, Reward: 283.0770 [3.18], Avg: 194.6276 (1.000)
Step: 482706, Reward: 284.7365 [1.76], Avg: 194.8249 (1.000)
Step: 483721, Reward: 283.9924 [1.84], Avg: 195.0193 (1.000)
Step: 484710, Reward: 284.7781 [0.84], Avg: 195.2169 (1.000)
Step: 485735, Reward: 285.5790 [1.76], Avg: 195.4134 (1.000)
Step: 486711, Reward: 284.3777 [3.34], Avg: 195.6028 (1.000)
Step: 487735, Reward: 284.3642 [1.80], Avg: 195.7948 (1.000)
Step: 488753, Reward: 285.5584 [2.23], Avg: 195.9876 (1.000)
Step: 489797, Reward: 286.2684 [0.48], Avg: 196.1849 (1.000)
Step: 490807, Reward: 285.1061 [1.64], Avg: 196.3763 (1.000)
Step: 491865, Reward: 202.5189 [114.42], Avg: 196.1394 (1.000)
Step: 492894, Reward: 285.9437 [1.33], Avg: 196.3326 (1.000)
Step: 493898, Reward: 286.6542 [1.88], Avg: 196.5253 (1.000)
Step: 494983, Reward: 286.1159 [1.08], Avg: 196.7177 (1.000)
Step: 495984, Reward: 285.6469 [2.17], Avg: 196.9059 (1.000)
Step: 496988, Reward: 285.9948 [0.42], Avg: 197.0978 (1.000)
Step: 498006, Reward: 285.7705 [2.33], Avg: 197.2843 (1.000)
Step: 499032, Reward: 289.1863 [1.89], Avg: 197.4783 (1.000)
