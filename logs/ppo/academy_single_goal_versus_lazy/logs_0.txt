Model: <class 'models.ppo.PPOAgent'>, Dir: academy_single_goal_versus_lazy
num_envs: 16, state_size: (115,), action_size: [19], action_space: Discrete(19),

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.05				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) * critic_error.pow(2) * scale
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss.mean())
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, update_freq=NUM_STEPS, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		if done[0] or len(self.buffer) >= self.update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, scale=16*dones.size(0)/len(self.replay_buffer))

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "1_vs_1_easy", "5_vs_5", "11_vs_11_stochastic"]
env_name = gfb_envs[4]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.unwrapped.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class AsyncAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000, checkpoint=False):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = AsyncAgent(envs.state_size, envs.action_size, num_envs, model)
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.stack.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0]:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 165, Reward: -0.2000 [0.40], Avg: -0.6000 (1.000)
Step: 251, Reward: 0.0000 [0.00], Avg: -0.3000 (1.000)
Step: 421, Reward: 0.0000 [0.00], Avg: -0.2000 (1.000)
Step: 506, Reward: 0.0000 [0.00], Avg: -0.1500 (1.000)
Step: 553, Reward: 0.0000 [0.00], Avg: -0.1200 (1.000)
Step: 614, Reward: 0.0000 [0.00], Avg: -0.1000 (1.000)
Step: 735, Reward: 0.2000 [0.40], Avg: -0.1143 (1.000)
Step: 797, Reward: 0.0000 [0.00], Avg: -0.1000 (1.000)
Step: 880, Reward: 0.0000 [0.00], Avg: -0.0889 (1.000)
Step: 996, Reward: 0.0000 [0.00], Avg: -0.0800 (1.000)
Step: 1050, Reward: 0.0000 [0.00], Avg: -0.0727 (1.000)
Step: 1191, Reward: 0.2000 [0.40], Avg: -0.0833 (1.000)
Step: 1268, Reward: 0.0000 [0.00], Avg: -0.0769 (1.000)
Step: 1309, Reward: 0.0000 [0.00], Avg: -0.0714 (1.000)
Step: 1537, Reward: 0.0000 [0.00], Avg: -0.0667 (1.000)
Step: 1606, Reward: 0.0000 [0.00], Avg: -0.0625 (1.000)
Step: 1897, Reward: 0.0000 [0.00], Avg: -0.0588 (1.000)
Step: 1966, Reward: 0.0000 [0.00], Avg: -0.0556 (1.000)
Step: 2176, Reward: 0.0000 [0.00], Avg: -0.0526 (1.000)
Step: 2238, Reward: 0.0000 [0.00], Avg: -0.0500 (1.000)
Step: 2289, Reward: 0.0000 [0.00], Avg: -0.0476 (1.000)
Step: 2373, Reward: 0.0000 [0.00], Avg: -0.0455 (1.000)
Step: 2534, Reward: 0.0000 [0.00], Avg: -0.0435 (1.000)
Step: 2870, Reward: 0.0000 [0.00], Avg: -0.0417 (1.000)
Step: 3068, Reward: -0.2000 [0.40], Avg: -0.0640 (1.000)
Step: 3101, Reward: 0.0000 [0.00], Avg: -0.0615 (1.000)
Step: 3207, Reward: 0.0000 [0.00], Avg: -0.0593 (1.000)
Step: 3485, Reward: 0.0000 [0.00], Avg: -0.0571 (1.000)
Step: 3545, Reward: 0.0000 [0.00], Avg: -0.0552 (1.000)
Step: 3656, Reward: 0.2000 [0.40], Avg: -0.0600 (1.000)
Step: 3731, Reward: 0.0000 [0.00], Avg: -0.0581 (1.000)
Step: 3999, Reward: 0.0000 [0.00], Avg: -0.0563 (1.000)
Step: 4308, Reward: 0.0000 [0.00], Avg: -0.0545 (1.000)
Step: 4602, Reward: 0.0000 [0.00], Avg: -0.0529 (1.000)
Step: 4721, Reward: 0.0000 [0.00], Avg: -0.0514 (1.000)
Step: 4973, Reward: 0.0000 [0.00], Avg: -0.0500 (1.000)
Step: 5170, Reward: 0.0000 [0.00], Avg: -0.0486 (1.000)
Step: 5675, Reward: 0.0000 [0.00], Avg: -0.0474 (1.000)
Step: 5713, Reward: 0.0000 [0.00], Avg: -0.0462 (1.000)
Step: 5985, Reward: 0.0000 [0.00], Avg: -0.0450 (1.000)
Step: 6385, Reward: 0.0000 [0.00], Avg: -0.0439 (1.000)
Step: 6546, Reward: 0.2000 [0.40], Avg: -0.0476 (1.000)
Step: 6602, Reward: 0.0000 [0.00], Avg: -0.0465 (1.000)
Step: 7099, Reward: 0.0000 [0.00], Avg: -0.0455 (1.000)
Step: 7158, Reward: 0.0000 [0.00], Avg: -0.0444 (1.000)
Step: 7239, Reward: 0.0000 [0.00], Avg: -0.0435 (1.000)
Step: 7317, Reward: 0.0000 [0.00], Avg: -0.0426 (1.000)
Step: 7469, Reward: 0.0000 [0.00], Avg: -0.0417 (1.000)
Step: 7767, Reward: 0.0000 [0.00], Avg: -0.0408 (1.000)
Step: 7964, Reward: 0.0000 [0.00], Avg: -0.0400 (1.000)
Step: 8235, Reward: 0.2000 [0.40], Avg: -0.0431 (1.000)
Step: 8326, Reward: -0.2000 [0.40], Avg: -0.0538 (1.000)
Step: 8439, Reward: 0.0000 [0.00], Avg: -0.0528 (1.000)
Step: 8670, Reward: 0.0000 [0.00], Avg: -0.0519 (1.000)
Step: 8754, Reward: 0.0000 [0.00], Avg: -0.0509 (1.000)
Step: 8896, Reward: 0.0000 [0.00], Avg: -0.0500 (1.000)
Step: 8990, Reward: -0.2000 [0.40], Avg: -0.0596 (1.000)
Step: 9126, Reward: -0.2000 [0.40], Avg: -0.0690 (1.000)
Step: 9239, Reward: 0.0000 [0.00], Avg: -0.0678 (1.000)
Step: 9368, Reward: 0.0000 [0.00], Avg: -0.0667 (1.000)
Step: 9619, Reward: 0.0000 [0.00], Avg: -0.0656 (1.000)
Step: 9844, Reward: 0.0000 [0.00], Avg: -0.0645 (1.000)
Step: 9955, Reward: 0.0000 [0.00], Avg: -0.0635 (1.000)
Step: 10159, Reward: 0.0000 [0.00], Avg: -0.0625 (1.000)
Step: 10698, Reward: 0.0000 [0.00], Avg: -0.0615 (1.000)
Step: 10737, Reward: 0.0000 [0.00], Avg: -0.0606 (1.000)
Step: 10924, Reward: 0.0000 [0.00], Avg: -0.0597 (1.000)
Step: 11263, Reward: 0.0000 [0.00], Avg: -0.0588 (1.000)
Step: 11312, Reward: 0.0000 [0.00], Avg: -0.0580 (1.000)
Step: 11504, Reward: 0.0000 [0.00], Avg: -0.0571 (1.000)
Step: 11660, Reward: 0.0000 [0.00], Avg: -0.0563 (1.000)
Step: 11904, Reward: 0.0000 [0.00], Avg: -0.0556 (1.000)
Step: 12056, Reward: 0.0000 [0.00], Avg: -0.0548 (1.000)
Step: 12164, Reward: 0.0000 [0.00], Avg: -0.0541 (1.000)
Step: 12199, Reward: -0.2000 [0.40], Avg: -0.0613 (1.000)
Step: 12328, Reward: 0.0000 [0.00], Avg: -0.0605 (1.000)
Step: 12445, Reward: 0.0000 [0.00], Avg: -0.0597 (1.000)
Step: 12538, Reward: 0.0000 [0.00], Avg: -0.0590 (1.000)
Step: 12637, Reward: 0.0000 [0.00], Avg: -0.0582 (1.000)
Step: 12819, Reward: 0.0000 [0.00], Avg: -0.0575 (1.000)
Step: 12900, Reward: 0.0000 [0.00], Avg: -0.0568 (1.000)
Step: 12968, Reward: -0.2000 [0.40], Avg: -0.0634 (1.000)
Step: 13030, Reward: 0.0000 [0.00], Avg: -0.0627 (1.000)
Step: 13497, Reward: 0.0000 [0.00], Avg: -0.0619 (1.000)
Step: 13830, Reward: 0.0000 [0.00], Avg: -0.0612 (1.000)
Step: 13959, Reward: 0.0000 [0.00], Avg: -0.0605 (1.000)
Step: 14209, Reward: 0.0000 [0.00], Avg: -0.0598 (1.000)
Step: 14416, Reward: 0.0000 [0.00], Avg: -0.0591 (1.000)
Step: 14579, Reward: 0.0000 [0.00], Avg: -0.0584 (1.000)
Step: 14781, Reward: 0.0000 [0.00], Avg: -0.0578 (1.000)
Step: 14884, Reward: -0.2000 [0.40], Avg: -0.0637 (1.000)
Step: 15015, Reward: 0.0000 [0.00], Avg: -0.0630 (1.000)
Step: 15171, Reward: 0.2000 [0.40], Avg: -0.0645 (1.000)
Step: 15304, Reward: 0.0000 [0.00], Avg: -0.0638 (1.000)
Step: 15423, Reward: 0.0000 [0.00], Avg: -0.0632 (1.000)
Step: 15545, Reward: 0.0000 [0.00], Avg: -0.0625 (1.000)
Step: 15589, Reward: -0.2000 [0.40], Avg: -0.0680 (1.000)
Step: 15711, Reward: 0.0000 [0.00], Avg: -0.0673 (1.000)
Step: 15882, Reward: 0.0000 [0.00], Avg: -0.0667 (1.000)
Step: 15933, Reward: 0.0000 [0.00], Avg: -0.0660 (1.000)
Step: 16005, Reward: 0.0000 [0.00], Avg: -0.0653 (1.000)
Step: 16115, Reward: 0.2000 [0.40], Avg: -0.0667 (1.000)
Step: 16161, Reward: 0.0000 [0.00], Avg: -0.0660 (1.000)
Step: 16420, Reward: -0.2000 [0.40], Avg: -0.0712 (1.000)
Step: 16559, Reward: 0.0000 [0.00], Avg: -0.0705 (1.000)
Step: 16783, Reward: 0.0000 [0.00], Avg: -0.0698 (1.000)
Step: 16830, Reward: 0.2000 [0.40], Avg: -0.0710 (1.000)
Step: 17000, Reward: 0.2000 [0.40], Avg: -0.0722 (1.000)
Step: 17560, Reward: 0.0000 [0.00], Avg: -0.0716 (1.000)
Step: 17654, Reward: 0.0000 [0.63], Avg: -0.0767 (1.000)
Step: 17791, Reward: 0.0000 [0.00], Avg: -0.0760 (1.000)
Step: 17845, Reward: 0.0000 [0.00], Avg: -0.0753 (1.000)
Step: 17933, Reward: 0.0000 [0.00], Avg: -0.0746 (1.000)
Step: 18262, Reward: 0.0000 [0.00], Avg: -0.0740 (1.000)
Step: 18318, Reward: -0.2000 [0.40], Avg: -0.0785 (1.000)
Step: 18458, Reward: 0.0000 [0.00], Avg: -0.0779 (1.000)
Step: 18611, Reward: 0.0000 [0.00], Avg: -0.0772 (1.000)
Step: 18679, Reward: 0.0000 [0.00], Avg: -0.0765 (1.000)
Step: 18828, Reward: 0.0000 [0.00], Avg: -0.0759 (1.000)
Step: 18957, Reward: 0.0000 [0.00], Avg: -0.0753 (1.000)
Step: 19049, Reward: 0.0000 [0.00], Avg: -0.0746 (1.000)
Step: 19070, Reward: 0.0000 [0.00], Avg: -0.0740 (1.000)
Step: 19136, Reward: 0.0000 [0.00], Avg: -0.0734 (1.000)
Step: 19260, Reward: 0.0000 [0.00], Avg: -0.0728 (1.000)
Step: 19469, Reward: 0.0000 [0.00], Avg: -0.0723 (1.000)
Step: 19537, Reward: 0.0000 [0.00], Avg: -0.0717 (1.000)
Step: 19602, Reward: 0.0000 [0.00], Avg: -0.0711 (1.000)
Step: 19844, Reward: 0.0000 [0.00], Avg: -0.0706 (1.000)
Step: 20286, Reward: 0.0000 [0.00], Avg: -0.0700 (1.000)
Step: 20385, Reward: 0.0000 [0.00], Avg: -0.0695 (1.000)
Step: 20637, Reward: 0.0000 [0.00], Avg: -0.0690 (1.000)
Step: 20675, Reward: 0.0000 [0.00], Avg: -0.0684 (1.000)
Step: 20724, Reward: 0.0000 [0.00], Avg: -0.0679 (1.000)
Step: 20836, Reward: 0.0000 [0.00], Avg: -0.0674 (1.000)
Step: 21018, Reward: 0.0000 [0.00], Avg: -0.0669 (1.000)
Step: 21123, Reward: 0.0000 [0.00], Avg: -0.0664 (1.000)
Step: 21275, Reward: 0.0000 [0.00], Avg: -0.0659 (1.000)
Step: 21407, Reward: 0.0000 [0.00], Avg: -0.0655 (1.000)
Step: 21457, Reward: 0.0000 [0.00], Avg: -0.0650 (1.000)
Step: 21503, Reward: -0.2000 [0.40], Avg: -0.0688 (1.000)
Step: 21533, Reward: 0.0000 [0.00], Avg: -0.0683 (1.000)
Step: 21702, Reward: 0.0000 [0.00], Avg: -0.0678 (1.000)
Step: 21797, Reward: 0.0000 [0.63], Avg: -0.0718 (1.000)
Step: 21971, Reward: 0.0000 [0.00], Avg: -0.0713 (1.000)
Step: 22161, Reward: 0.0000 [0.00], Avg: -0.0708 (1.000)
Step: 22229, Reward: 0.0000 [0.00], Avg: -0.0703 (1.000)
Step: 22372, Reward: 0.0000 [0.00], Avg: -0.0698 (1.000)
Step: 22508, Reward: 0.0000 [0.00], Avg: -0.0694 (1.000)
Step: 22663, Reward: 0.0000 [0.00], Avg: -0.0689 (1.000)
Step: 22940, Reward: 0.2000 [0.40], Avg: -0.0698 (1.000)
Step: 22993, Reward: 0.0000 [0.00], Avg: -0.0693 (1.000)
Step: 23132, Reward: 0.0000 [0.00], Avg: -0.0688 (1.000)
Step: 23294, Reward: 0.0000 [0.00], Avg: -0.0684 (1.000)
Step: 23462, Reward: 0.0000 [0.00], Avg: -0.0680 (1.000)
Step: 23542, Reward: 0.0000 [0.00], Avg: -0.0675 (1.000)
Step: 23639, Reward: 0.0000 [0.00], Avg: -0.0671 (1.000)
Step: 23710, Reward: 0.0000 [0.00], Avg: -0.0667 (1.000)
Step: 23775, Reward: 0.0000 [0.00], Avg: -0.0662 (1.000)
Step: 23851, Reward: 0.0000 [0.00], Avg: -0.0658 (1.000)
Step: 23971, Reward: 0.0000 [0.00], Avg: -0.0654 (1.000)
Step: 24031, Reward: 0.0000 [0.00], Avg: -0.0650 (1.000)
Step: 24121, Reward: 0.0000 [0.00], Avg: -0.0646 (1.000)
Step: 24295, Reward: 0.0000 [0.00], Avg: -0.0642 (1.000)
Step: 24345, Reward: 0.0000 [0.00], Avg: -0.0638 (1.000)
Step: 24425, Reward: 0.0000 [0.00], Avg: -0.0634 (1.000)
Step: 24590, Reward: 0.0000 [0.00], Avg: -0.0630 (1.000)
Step: 24692, Reward: 0.0000 [0.00], Avg: -0.0627 (1.000)
Step: 24825, Reward: 0.0000 [0.00], Avg: -0.0623 (1.000)
Step: 24915, Reward: 0.0000 [0.00], Avg: -0.0619 (1.000)
Step: 25038, Reward: 0.0000 [0.00], Avg: -0.0616 (1.000)
Step: 25259, Reward: 0.2000 [0.40], Avg: -0.0624 (1.000)
Step: 25375, Reward: 0.0000 [0.00], Avg: -0.0620 (1.000)
Step: 25491, Reward: 0.0000 [0.00], Avg: -0.0616 (1.000)
Step: 25636, Reward: 0.0000 [0.00], Avg: -0.0613 (1.000)
Step: 25745, Reward: 0.0000 [0.00], Avg: -0.0609 (1.000)
Step: 25852, Reward: 0.0000 [0.00], Avg: -0.0606 (1.000)
Step: 25903, Reward: 0.0000 [0.00], Avg: -0.0603 (1.000)
Step: 26035, Reward: 0.0000 [0.00], Avg: -0.0599 (1.000)
Step: 26211, Reward: 0.2000 [0.40], Avg: -0.0607 (1.000)
Step: 26266, Reward: 0.0000 [0.00], Avg: -0.0604 (1.000)
Step: 26403, Reward: 0.0000 [0.00], Avg: -0.0600 (1.000)
Step: 26432, Reward: 0.0000 [0.00], Avg: -0.0597 (1.000)
Step: 26465, Reward: 0.0000 [0.00], Avg: -0.0594 (1.000)
Step: 26630, Reward: 0.0000 [0.00], Avg: -0.0590 (1.000)
Step: 26763, Reward: 0.0000 [0.00], Avg: -0.0587 (1.000)
Step: 26879, Reward: 0.0000 [0.00], Avg: -0.0584 (1.000)
Step: 26982, Reward: 0.2000 [0.40], Avg: -0.0592 (1.000)
Step: 27043, Reward: 0.0000 [0.00], Avg: -0.0589 (1.000)
Step: 27079, Reward: 0.0000 [0.00], Avg: -0.0585 (1.000)
Step: 27118, Reward: 0.0000 [0.00], Avg: -0.0582 (1.000)
Step: 27181, Reward: 0.0000 [0.00], Avg: -0.0579 (1.000)
Step: 27213, Reward: 0.0000 [0.00], Avg: -0.0576 (1.000)
Step: 27253, Reward: 0.2000 [0.40], Avg: -0.0584 (1.000)
Step: 27356, Reward: 0.0000 [0.00], Avg: -0.0581 (1.000)
Step: 27448, Reward: 0.2000 [0.40], Avg: -0.0588 (1.000)
Step: 28017, Reward: 0.0000 [0.00], Avg: -0.0585 (1.000)
Step: 28129, Reward: 0.0000 [0.00], Avg: -0.0582 (1.000)
Step: 28184, Reward: 0.2000 [0.40], Avg: -0.0589 (1.000)
Step: 28265, Reward: 0.0000 [0.00], Avg: -0.0586 (1.000)
Step: 28637, Reward: 0.0000 [0.00], Avg: -0.0583 (1.000)
Step: 28700, Reward: 0.0000 [0.00], Avg: -0.0580 (1.000)
Step: 28796, Reward: 0.0000 [0.00], Avg: -0.0577 (1.000)
Step: 28935, Reward: 0.0000 [0.00], Avg: -0.0575 (1.000)
Step: 29131, Reward: 0.0000 [0.00], Avg: -0.0572 (1.000)
Step: 29191, Reward: 0.0000 [0.00], Avg: -0.0569 (1.000)
Step: 29319, Reward: -0.2000 [0.40], Avg: -0.0595 (1.000)
Step: 29413, Reward: 0.0000 [0.00], Avg: -0.0593 (1.000)
Step: 29552, Reward: -0.2000 [0.40], Avg: -0.0619 (1.000)
Step: 29652, Reward: 0.0000 [0.00], Avg: -0.0616 (1.000)
Step: 29839, Reward: 0.0000 [0.00], Avg: -0.0613 (1.000)
Step: 29954, Reward: 0.2000 [0.40], Avg: -0.0619 (1.000)
Step: 30065, Reward: 0.0000 [0.00], Avg: -0.0616 (1.000)
Step: 30116, Reward: 0.0000 [0.00], Avg: -0.0613 (1.000)
Step: 30244, Reward: 0.0000 [0.00], Avg: -0.0611 (1.000)
Step: 30388, Reward: 0.0000 [0.00], Avg: -0.0608 (1.000)
Step: 30597, Reward: 0.0000 [0.00], Avg: -0.0605 (1.000)
Step: 30737, Reward: 0.0000 [0.00], Avg: -0.0602 (1.000)
Step: 30813, Reward: 0.0000 [0.00], Avg: -0.0599 (1.000)
Step: 30884, Reward: 0.0000 [0.00], Avg: -0.0597 (1.000)
Step: 31086, Reward: 0.2000 [0.40], Avg: -0.0603 (1.000)
Step: 31280, Reward: 0.0000 [0.00], Avg: -0.0600 (1.000)
Step: 31331, Reward: 0.0000 [0.00], Avg: -0.0598 (1.000)
Step: 31361, Reward: 0.0000 [0.00], Avg: -0.0595 (1.000)
Step: 31603, Reward: 0.0000 [0.00], Avg: -0.0592 (1.000)
Step: 31658, Reward: 0.0000 [0.00], Avg: -0.0590 (1.000)
Step: 31747, Reward: 0.0000 [0.00], Avg: -0.0587 (1.000)
Step: 31992, Reward: 0.0000 [0.00], Avg: -0.0584 (1.000)
Step: 32085, Reward: 0.0000 [0.00], Avg: -0.0582 (1.000)
Step: 32149, Reward: 0.0000 [0.00], Avg: -0.0579 (1.000)
Step: 32260, Reward: 0.0000 [0.00], Avg: -0.0577 (1.000)
Step: 32332, Reward: 0.0000 [0.00], Avg: -0.0574 (1.000)
Step: 32578, Reward: 0.2000 [0.40], Avg: -0.0580 (1.000)
Step: 32819, Reward: 0.0000 [0.00], Avg: -0.0578 (1.000)
Step: 32885, Reward: 0.0000 [0.00], Avg: -0.0575 (1.000)
Step: 32998, Reward: 0.0000 [0.00], Avg: -0.0573 (1.000)
Step: 33319, Reward: 0.0000 [0.00], Avg: -0.0571 (1.000)
Step: 33373, Reward: 0.2000 [0.40], Avg: -0.0577 (1.000)
Step: 33400, Reward: -0.2000 [0.40], Avg: -0.0599 (1.000)
Step: 33495, Reward: 0.0000 [0.00], Avg: -0.0597 (1.000)
Step: 33524, Reward: 0.0000 [0.00], Avg: -0.0594 (1.000)
Step: 33642, Reward: 0.0000 [0.00], Avg: -0.0592 (1.000)
Step: 33688, Reward: 0.0000 [0.00], Avg: -0.0589 (1.000)
Step: 33853, Reward: 0.0000 [0.00], Avg: -0.0587 (1.000)
Step: 34017, Reward: 0.0000 [0.00], Avg: -0.0585 (1.000)
Step: 34135, Reward: 0.0000 [0.00], Avg: -0.0582 (1.000)
Step: 34401, Reward: 0.0000 [0.00], Avg: -0.0580 (1.000)
Step: 34710, Reward: 0.0000 [0.00], Avg: -0.0578 (1.000)
Step: 34749, Reward: 0.0000 [0.00], Avg: -0.0575 (1.000)
Step: 34947, Reward: 0.0000 [0.00], Avg: -0.0573 (1.000)
Step: 35168, Reward: 0.0000 [0.00], Avg: -0.0571 (1.000)
Step: 35220, Reward: 0.0000 [0.00], Avg: -0.0568 (1.000)
Step: 35352, Reward: 0.0000 [0.00], Avg: -0.0566 (1.000)
Step: 35442, Reward: 0.0000 [0.00], Avg: -0.0564 (1.000)
Step: 35631, Reward: 0.0000 [0.00], Avg: -0.0562 (1.000)
Step: 35677, Reward: 0.0000 [0.00], Avg: -0.0559 (1.000)
Step: 35823, Reward: 0.0000 [0.00], Avg: -0.0557 (1.000)
Step: 35885, Reward: 0.0000 [0.00], Avg: -0.0555 (1.000)
Step: 35925, Reward: 0.0000 [0.00], Avg: -0.0553 (1.000)
Step: 36123, Reward: 0.0000 [0.00], Avg: -0.0551 (1.000)
Step: 36224, Reward: 0.0000 [0.00], Avg: -0.0549 (1.000)
Step: 36339, Reward: 0.0000 [0.00], Avg: -0.0547 (1.000)
Step: 36418, Reward: 0.0000 [0.00], Avg: -0.0544 (1.000)
Step: 36472, Reward: 0.0000 [0.00], Avg: -0.0542 (1.000)
Step: 36824, Reward: 0.0000 [0.00], Avg: -0.0540 (1.000)
Step: 37223, Reward: 0.0000 [0.00], Avg: -0.0538 (1.000)
Step: 37337, Reward: 0.0000 [0.00], Avg: -0.0536 (1.000)
Step: 37541, Reward: 0.0000 [0.00], Avg: -0.0534 (1.000)
Step: 37609, Reward: 0.0000 [0.00], Avg: -0.0532 (1.000)
Step: 37674, Reward: 0.0000 [0.00], Avg: -0.0530 (1.000)
Step: 37765, Reward: 0.0000 [0.00], Avg: -0.0528 (1.000)
Step: 37857, Reward: 0.0000 [0.00], Avg: -0.0526 (1.000)
Step: 37903, Reward: 0.0000 [0.00], Avg: -0.0524 (1.000)
Step: 37989, Reward: 0.0000 [0.00], Avg: -0.0523 (1.000)
Step: 38194, Reward: 0.0000 [0.00], Avg: -0.0521 (1.000)
Step: 38294, Reward: 0.0000 [0.00], Avg: -0.0519 (1.000)
Step: 38476, Reward: 0.0000 [0.00], Avg: -0.0517 (1.000)
Step: 38691, Reward: 0.0000 [0.00], Avg: -0.0515 (1.000)
Step: 38821, Reward: 0.0000 [0.00], Avg: -0.0513 (1.000)
Step: 38944, Reward: 0.0000 [0.00], Avg: -0.0511 (1.000)
Step: 39142, Reward: 0.0000 [0.00], Avg: -0.0509 (1.000)
Step: 39325, Reward: -0.2000 [0.40], Avg: -0.0529 (1.000)
Step: 39372, Reward: 0.0000 [0.00], Avg: -0.0527 (1.000)
Step: 39478, Reward: 0.0000 [0.00], Avg: -0.0525 (1.000)
Step: 39659, Reward: 0.0000 [0.00], Avg: -0.0523 (1.000)
Step: 39728, Reward: -0.2000 [0.40], Avg: -0.0543 (1.000)
Step: 39848, Reward: -0.2000 [0.40], Avg: -0.0562 (1.000)
Step: 39941, Reward: -0.2000 [0.40], Avg: -0.0581 (1.000)
Step: 40032, Reward: 0.0000 [0.00], Avg: -0.0579 (1.000)
Step: 40110, Reward: 0.0000 [0.00], Avg: -0.0577 (1.000)
Step: 40258, Reward: 0.0000 [0.00], Avg: -0.0575 (1.000)
Step: 40533, Reward: 0.0000 [0.00], Avg: -0.0573 (1.000)
Step: 40805, Reward: 0.0000 [0.00], Avg: -0.0571 (1.000)
Step: 40856, Reward: 0.0000 [0.00], Avg: -0.0569 (1.000)
Step: 40994, Reward: 0.0000 [0.00], Avg: -0.0567 (1.000)
Step: 41040, Reward: 0.0000 [0.00], Avg: -0.0565 (1.000)
Step: 41131, Reward: 0.0000 [0.00], Avg: -0.0563 (1.000)
Step: 41215, Reward: 0.0000 [0.00], Avg: -0.0561 (1.000)
Step: 41397, Reward: 0.0000 [0.00], Avg: -0.0559 (1.000)
Step: 41537, Reward: -0.2000 [0.40], Avg: -0.0577 (1.000)
Step: 41938, Reward: 0.0000 [0.00], Avg: -0.0575 (1.000)
Step: 42025, Reward: 0.0000 [0.00], Avg: -0.0574 (1.000)
Step: 42186, Reward: 0.0000 [0.00], Avg: -0.0572 (1.000)
Step: 42261, Reward: 0.2000 [0.40], Avg: -0.0576 (1.000)
Step: 42705, Reward: 0.0000 [0.00], Avg: -0.0575 (1.000)
Step: 42895, Reward: 0.0000 [0.00], Avg: -0.0573 (1.000)
Step: 43107, Reward: 0.0000 [0.00], Avg: -0.0571 (1.000)
Step: 43350, Reward: 0.0000 [0.00], Avg: -0.0569 (1.000)
Step: 43831, Reward: 0.2000 [0.40], Avg: -0.0574 (1.000)
Step: 43999, Reward: 0.0000 [0.00], Avg: -0.0572 (1.000)
Step: 44096, Reward: 0.0000 [0.00], Avg: -0.0570 (1.000)
Step: 44214, Reward: 0.0000 [0.00], Avg: -0.0568 (1.000)
Step: 44301, Reward: 0.0000 [0.00], Avg: -0.0566 (1.000)
Step: 44441, Reward: 0.0000 [0.00], Avg: -0.0564 (1.000)
Step: 44538, Reward: 0.0000 [0.00], Avg: -0.0563 (1.000)
Step: 44681, Reward: 0.0000 [0.00], Avg: -0.0561 (1.000)
Step: 44771, Reward: 0.0000 [0.00], Avg: -0.0559 (1.000)
Step: 44917, Reward: 0.0000 [0.00], Avg: -0.0557 (1.000)
Step: 45090, Reward: 0.0000 [0.00], Avg: -0.0556 (1.000)
Step: 45170, Reward: 0.0000 [0.00], Avg: -0.0554 (1.000)
Step: 45433, Reward: 0.0000 [0.00], Avg: -0.0552 (1.000)
Step: 45626, Reward: 0.0000 [0.00], Avg: -0.0550 (1.000)
Step: 45654, Reward: -0.2000 [0.40], Avg: -0.0567 (1.000)
Step: 45786, Reward: 0.0000 [0.00], Avg: -0.0565 (1.000)
Step: 46046, Reward: 0.0000 [0.00], Avg: -0.0564 (1.000)
Step: 46138, Reward: 0.0000 [0.00], Avg: -0.0562 (1.000)
Step: 46348, Reward: 0.0000 [0.00], Avg: -0.0560 (1.000)
Step: 46431, Reward: 0.0000 [0.00], Avg: -0.0559 (1.000)
Step: 46554, Reward: 0.2000 [0.40], Avg: -0.0563 (1.000)
Step: 46782, Reward: 0.0000 [0.00], Avg: -0.0561 (1.000)
Step: 46961, Reward: -0.2000 [0.40], Avg: -0.0578 (1.000)
Step: 47184, Reward: 0.0000 [0.00], Avg: -0.0576 (1.000)
Step: 47730, Reward: 0.0000 [0.00], Avg: -0.0574 (1.000)
Step: 47919, Reward: 0.0000 [0.00], Avg: -0.0573 (1.000)
Step: 48222, Reward: 0.0000 [0.00], Avg: -0.0571 (1.000)
Step: 48402, Reward: 0.0000 [0.00], Avg: -0.0569 (1.000)
Step: 48440, Reward: 0.0000 [0.00], Avg: -0.0567 (1.000)
Step: 48530, Reward: 0.0000 [0.00], Avg: -0.0566 (1.000)
Step: 48638, Reward: 0.0000 [0.00], Avg: -0.0564 (1.000)
Step: 48828, Reward: 0.0000 [0.00], Avg: -0.0562 (1.000)
Step: 48946, Reward: 0.0000 [0.00], Avg: -0.0561 (1.000)
Step: 49198, Reward: 0.0000 [0.00], Avg: -0.0559 (1.000)
Step: 49392, Reward: -0.2000 [0.40], Avg: -0.0575 (1.000)
Step: 49554, Reward: -0.2000 [0.40], Avg: -0.0591 (1.000)
Step: 49620, Reward: 0.0000 [0.00], Avg: -0.0589 (1.000)
Step: 49719, Reward: 0.0000 [0.00], Avg: -0.0587 (1.000)
Step: 49896, Reward: 0.0000 [0.00], Avg: -0.0586 (1.000)
Step: 50242, Reward: 0.0000 [0.00], Avg: -0.0584 (1.000)
Step: 50327, Reward: 0.0000 [0.00], Avg: -0.0582 (1.000)
Step: 50577, Reward: -0.2000 [0.40], Avg: -0.0598 (1.000)
Step: 50736, Reward: 0.0000 [0.00], Avg: -0.0596 (1.000)
Step: 50842, Reward: 0.0000 [0.00], Avg: -0.0594 (1.000)
Step: 51135, Reward: 0.0000 [0.00], Avg: -0.0593 (1.000)
Step: 51353, Reward: 0.0000 [0.00], Avg: -0.0591 (1.000)
Step: 51438, Reward: 0.0000 [0.00], Avg: -0.0589 (1.000)
Step: 51724, Reward: 0.0000 [0.00], Avg: -0.0588 (1.000)
Step: 51862, Reward: -0.2000 [0.40], Avg: -0.0603 (1.000)
Step: 51980, Reward: 0.0000 [0.00], Avg: -0.0601 (1.000)
Step: 52129, Reward: 0.0000 [0.00], Avg: -0.0600 (1.000)
Step: 52170, Reward: 0.0000 [0.00], Avg: -0.0598 (1.000)
Step: 52592, Reward: 0.0000 [0.00], Avg: -0.0596 (1.000)
Step: 53023, Reward: -0.2000 [0.40], Avg: -0.0611 (1.000)
Step: 53101, Reward: 0.0000 [0.00], Avg: -0.0610 (1.000)
Step: 53175, Reward: 0.0000 [0.00], Avg: -0.0608 (1.000)
Step: 53219, Reward: -0.2000 [0.40], Avg: -0.0623 (1.000)
Step: 53560, Reward: 0.0000 [0.00], Avg: -0.0621 (1.000)
Step: 53646, Reward: 0.0000 [0.00], Avg: -0.0619 (1.000)
Step: 53698, Reward: 0.0000 [0.00], Avg: -0.0618 (1.000)
Step: 53790, Reward: 0.0000 [0.00], Avg: -0.0616 (1.000)
Step: 53961, Reward: 0.2000 [0.40], Avg: -0.0620 (1.000)
Step: 54164, Reward: 0.0000 [0.00], Avg: -0.0618 (1.000)
Step: 54351, Reward: 0.0000 [0.00], Avg: -0.0616 (1.000)
Step: 54394, Reward: 0.0000 [0.00], Avg: -0.0615 (1.000)
Step: 55061, Reward: 0.0000 [0.00], Avg: -0.0613 (1.000)
Step: 55191, Reward: -0.2000 [0.40], Avg: -0.0627 (1.000)
Step: 55271, Reward: 0.0000 [0.00], Avg: -0.0626 (1.000)
Step: 55466, Reward: 0.0000 [0.00], Avg: -0.0624 (1.000)
Step: 55852, Reward: 0.0000 [0.00], Avg: -0.0622 (1.000)
Step: 55942, Reward: 0.0000 [0.00], Avg: -0.0621 (1.000)
Step: 56188, Reward: -0.2000 [0.40], Avg: -0.0635 (1.000)
Step: 56608, Reward: 0.0000 [0.00], Avg: -0.0633 (1.000)
Step: 56816, Reward: 0.0000 [0.00], Avg: -0.0632 (1.000)
Step: 56972, Reward: 0.0000 [0.00], Avg: -0.0630 (1.000)
Step: 57072, Reward: 0.0000 [0.00], Avg: -0.0628 (1.000)
Step: 57265, Reward: 0.0000 [0.00], Avg: -0.0627 (1.000)
Step: 57732, Reward: 0.0000 [0.00], Avg: -0.0625 (1.000)
Step: 57841, Reward: 0.0000 [0.00], Avg: -0.0623 (1.000)
Step: 59012, Reward: -0.4000 [0.49], Avg: -0.0645 (1.000)
Step: 59361, Reward: 0.0000 [0.00], Avg: -0.0643 (1.000)
Step: 59457, Reward: 0.0000 [0.00], Avg: -0.0642 (1.000)
Step: 59690, Reward: -0.2000 [0.40], Avg: -0.0655 (1.000)
Step: 60072, Reward: 0.0000 [0.00], Avg: -0.0654 (1.000)
Step: 60277, Reward: 0.0000 [0.00], Avg: -0.0652 (1.000)
Step: 60485, Reward: -0.2000 [0.40], Avg: -0.0666 (1.000)
Step: 60575, Reward: 0.0000 [0.00], Avg: -0.0664 (1.000)
Step: 61012, Reward: 0.0000 [0.00], Avg: -0.0662 (1.000)
Step: 61086, Reward: 0.0000 [0.00], Avg: -0.0660 (1.000)
Step: 61169, Reward: -0.2000 [0.40], Avg: -0.0674 (1.000)
Step: 61419, Reward: -0.4000 [0.49], Avg: -0.0695 (1.000)
Step: 62195, Reward: 0.0000 [0.00], Avg: -0.0693 (1.000)
Step: 62442, Reward: -0.2000 [0.40], Avg: -0.0706 (1.000)
Step: 62689, Reward: 0.0000 [0.00], Avg: -0.0704 (1.000)
Step: 62836, Reward: 0.0000 [0.00], Avg: -0.0703 (1.000)
Step: 63044, Reward: 0.0000 [0.00], Avg: -0.0701 (1.000)
Step: 63298, Reward: 0.0000 [0.00], Avg: -0.0699 (1.000)
Step: 63779, Reward: 0.0000 [0.00], Avg: -0.0697 (1.000)
Step: 63895, Reward: 0.0000 [0.00], Avg: -0.0696 (1.000)
Step: 64532, Reward: 0.0000 [0.00], Avg: -0.0694 (1.000)
Step: 64627, Reward: 0.0000 [0.00], Avg: -0.0692 (1.000)
Step: 64957, Reward: -0.2000 [0.40], Avg: -0.0705 (1.000)
Step: 65128, Reward: 0.0000 [0.00], Avg: -0.0704 (1.000)
Step: 66999, Reward: 0.0000 [0.00], Avg: -0.0702 (1.000)
Step: 67206, Reward: -0.2000 [0.40], Avg: -0.0715 (1.000)
Step: 67322, Reward: -0.2000 [0.40], Avg: -0.0727 (1.000)
Step: 67984, Reward: 0.0000 [0.00], Avg: -0.0726 (1.000)
Step: 68230, Reward: 0.0000 [0.00], Avg: -0.0724 (1.000)
Step: 68564, Reward: 0.0000 [0.00], Avg: -0.0722 (1.000)
Step: 68964, Reward: 0.0000 [0.00], Avg: -0.0720 (1.000)
Step: 69420, Reward: 0.0000 [0.00], Avg: -0.0719 (1.000)
Step: 69695, Reward: 0.0000 [0.00], Avg: -0.0717 (1.000)
Step: 69884, Reward: 0.0000 [0.00], Avg: -0.0715 (1.000)
Step: 70038, Reward: 0.0000 [0.00], Avg: -0.0714 (1.000)
Step: 70338, Reward: 0.0000 [0.00], Avg: -0.0712 (1.000)
Step: 70465, Reward: 0.0000 [0.00], Avg: -0.0710 (1.000)
Step: 71155, Reward: 0.0000 [0.00], Avg: -0.0709 (1.000)
Step: 71972, Reward: 0.0000 [0.00], Avg: -0.0707 (1.000)
Step: 72140, Reward: 0.0000 [0.00], Avg: -0.0705 (1.000)
Step: 72517, Reward: -0.2000 [0.40], Avg: -0.0718 (1.000)
Step: 72702, Reward: 0.0000 [0.00], Avg: -0.0716 (1.000)
Step: 72873, Reward: -0.2000 [0.40], Avg: -0.0728 (1.000)
Step: 72979, Reward: 0.0000 [0.00], Avg: -0.0727 (1.000)
Step: 73132, Reward: 0.0000 [0.00], Avg: -0.0725 (1.000)
Step: 73236, Reward: 0.0000 [0.00], Avg: -0.0723 (1.000)
Step: 73908, Reward: -0.2000 [0.40], Avg: -0.0735 (1.000)
Step: 74073, Reward: 0.0000 [0.00], Avg: -0.0734 (1.000)
Step: 74490, Reward: 0.0000 [0.00], Avg: -0.0732 (1.000)
Step: 74836, Reward: 0.0000 [0.00], Avg: -0.0730 (1.000)
Step: 75246, Reward: 0.0000 [0.00], Avg: -0.0729 (1.000)
Step: 75369, Reward: 0.0000 [0.00], Avg: -0.0727 (1.000)
Step: 75526, Reward: 0.0000 [0.00], Avg: -0.0725 (1.000)
Step: 75635, Reward: 0.0000 [0.00], Avg: -0.0724 (1.000)
Step: 75730, Reward: 0.0000 [0.00], Avg: -0.0722 (1.000)
Step: 75965, Reward: 0.0000 [0.00], Avg: -0.0720 (1.000)
Step: 76074, Reward: 0.0000 [0.00], Avg: -0.0719 (1.000)
Step: 76190, Reward: 0.0000 [0.00], Avg: -0.0717 (1.000)
Step: 76666, Reward: 0.0000 [0.00], Avg: -0.0716 (1.000)
Step: 76757, Reward: 0.0000 [0.00], Avg: -0.0714 (1.000)
Step: 77119, Reward: 0.0000 [0.00], Avg: -0.0712 (1.000)
Step: 77378, Reward: 0.0000 [0.00], Avg: -0.0711 (1.000)
Step: 77574, Reward: 0.0000 [0.00], Avg: -0.0709 (1.000)
Step: 77745, Reward: 0.0000 [0.00], Avg: -0.0708 (1.000)
Step: 77874, Reward: 0.0000 [0.00], Avg: -0.0706 (1.000)
Step: 78246, Reward: 0.0000 [0.00], Avg: -0.0705 (1.000)
Step: 78452, Reward: 0.0000 [0.00], Avg: -0.0703 (1.000)
Step: 78712, Reward: -0.2000 [0.40], Avg: -0.0715 (1.000)
Step: 78884, Reward: 0.0000 [0.00], Avg: -0.0713 (1.000)
Step: 79245, Reward: 0.0000 [0.00], Avg: -0.0712 (1.000)
Step: 79409, Reward: -0.2000 [0.40], Avg: -0.0723 (1.000)
Step: 79521, Reward: 0.0000 [0.00], Avg: -0.0722 (1.000)
Step: 79686, Reward: 0.0000 [0.00], Avg: -0.0720 (1.000)
Step: 79749, Reward: -0.2000 [0.40], Avg: -0.0731 (1.000)
Step: 79912, Reward: 0.0000 [0.00], Avg: -0.0730 (1.000)
Step: 80074, Reward: 0.0000 [0.00], Avg: -0.0728 (1.000)
Step: 80202, Reward: -0.2000 [0.40], Avg: -0.0740 (1.000)
Step: 80394, Reward: 0.0000 [0.00], Avg: -0.0738 (1.000)
Step: 80680, Reward: 0.0000 [0.00], Avg: -0.0736 (1.000)
Step: 80821, Reward: 0.0000 [0.00], Avg: -0.0735 (1.000)
Step: 80991, Reward: 0.0000 [0.00], Avg: -0.0733 (1.000)
Step: 81122, Reward: 0.0000 [0.00], Avg: -0.0732 (1.000)
Step: 81369, Reward: 0.0000 [0.00], Avg: -0.0730 (1.000)
Step: 81532, Reward: -0.2000 [0.40], Avg: -0.0741 (1.000)
Step: 81657, Reward: -0.2000 [0.40], Avg: -0.0753 (1.000)
Step: 82139, Reward: 0.0000 [0.00], Avg: -0.0751 (1.000)
Step: 82280, Reward: -0.4000 [0.49], Avg: -0.0768 (1.000)
Step: 82458, Reward: 0.0000 [0.00], Avg: -0.0767 (1.000)
Step: 82738, Reward: 0.0000 [0.00], Avg: -0.0765 (1.000)
Step: 82841, Reward: 0.0000 [0.00], Avg: -0.0763 (1.000)
Step: 82951, Reward: -0.2000 [0.40], Avg: -0.0774 (1.000)
Step: 83210, Reward: 0.0000 [0.00], Avg: -0.0773 (1.000)
Step: 83314, Reward: 0.0000 [0.00], Avg: -0.0771 (1.000)
Step: 83427, Reward: 0.0000 [0.00], Avg: -0.0769 (1.000)
Step: 83620, Reward: 0.0000 [0.00], Avg: -0.0768 (1.000)
Step: 83759, Reward: 0.0000 [0.00], Avg: -0.0766 (1.000)
Step: 83861, Reward: 0.0000 [0.00], Avg: -0.0765 (1.000)
Step: 84042, Reward: 0.0000 [0.00], Avg: -0.0763 (1.000)
Step: 84169, Reward: 0.0000 [0.00], Avg: -0.0762 (1.000)
Step: 84234, Reward: 0.0000 [0.00], Avg: -0.0760 (1.000)
Step: 84305, Reward: 0.0000 [0.00], Avg: -0.0758 (1.000)
Step: 84627, Reward: 0.0000 [0.00], Avg: -0.0757 (1.000)
Step: 84828, Reward: 0.0000 [0.00], Avg: -0.0755 (1.000)
Step: 85015, Reward: 0.0000 [0.00], Avg: -0.0754 (1.000)
Step: 85164, Reward: 0.0000 [0.00], Avg: -0.0752 (1.000)
Step: 85484, Reward: 0.0000 [0.00], Avg: -0.0751 (1.000)
Step: 85672, Reward: 0.0000 [0.00], Avg: -0.0749 (1.000)
Step: 85908, Reward: 0.0000 [0.00], Avg: -0.0748 (1.000)
Step: 85990, Reward: -0.2000 [0.40], Avg: -0.0758 (1.000)
Step: 86144, Reward: 0.0000 [0.00], Avg: -0.0757 (1.000)
Step: 86383, Reward: 0.0000 [0.00], Avg: -0.0755 (1.000)
Step: 86654, Reward: 0.0000 [0.00], Avg: -0.0754 (1.000)
Step: 86871, Reward: 0.0000 [0.00], Avg: -0.0752 (1.000)
Step: 87011, Reward: 0.0000 [0.00], Avg: -0.0751 (1.000)
Step: 87152, Reward: 0.0000 [0.00], Avg: -0.0749 (1.000)
Step: 87298, Reward: 0.0000 [0.00], Avg: -0.0748 (1.000)
Step: 87445, Reward: 0.0000 [0.00], Avg: -0.0746 (1.000)
Step: 87567, Reward: 0.0000 [0.00], Avg: -0.0745 (1.000)
Step: 87852, Reward: 0.0000 [0.00], Avg: -0.0743 (1.000)
Step: 87939, Reward: 0.0000 [0.00], Avg: -0.0742 (1.000)
Step: 88093, Reward: 0.0000 [0.00], Avg: -0.0740 (1.000)
Step: 88308, Reward: 0.0000 [0.00], Avg: -0.0739 (1.000)
Step: 88525, Reward: 0.0000 [0.00], Avg: -0.0737 (1.000)
Step: 88667, Reward: 0.0000 [0.00], Avg: -0.0736 (1.000)
Step: 88848, Reward: 0.0000 [0.00], Avg: -0.0735 (1.000)
Step: 89122, Reward: 0.0000 [0.00], Avg: -0.0733 (1.000)
Step: 89268, Reward: 0.0000 [0.00], Avg: -0.0732 (1.000)
Step: 89497, Reward: 0.0000 [0.00], Avg: -0.0730 (1.000)
Step: 89727, Reward: -0.2000 [0.40], Avg: -0.0740 (1.000)
Step: 89862, Reward: 0.0000 [0.00], Avg: -0.0739 (1.000)
Step: 90003, Reward: 0.0000 [0.00], Avg: -0.0738 (1.000)
Step: 90229, Reward: -0.2000 [0.40], Avg: -0.0748 (1.000)
Step: 90406, Reward: 0.0000 [0.00], Avg: -0.0746 (1.000)
Step: 90569, Reward: 0.0000 [0.00], Avg: -0.0745 (1.000)
Step: 90707, Reward: 0.0000 [0.00], Avg: -0.0743 (1.000)
Step: 90855, Reward: 0.0000 [0.00], Avg: -0.0742 (1.000)
Step: 91031, Reward: 0.0000 [0.00], Avg: -0.0741 (1.000)
Step: 91187, Reward: -0.2000 [0.40], Avg: -0.0751 (1.000)
Step: 91495, Reward: -0.2000 [0.40], Avg: -0.0761 (1.000)
Step: 91848, Reward: 0.0000 [0.00], Avg: -0.0759 (1.000)
Step: 91997, Reward: 0.0000 [0.00], Avg: -0.0758 (1.000)
Step: 92117, Reward: 0.0000 [0.00], Avg: -0.0756 (1.000)
Step: 92200, Reward: 0.0000 [0.00], Avg: -0.0755 (1.000)
Step: 92335, Reward: 0.0000 [0.00], Avg: -0.0753 (1.000)
Step: 92476, Reward: -0.4000 [0.49], Avg: -0.0769 (1.000)
Step: 92535, Reward: 0.0000 [0.00], Avg: -0.0767 (1.000)
Step: 92782, Reward: 0.0000 [0.00], Avg: -0.0766 (1.000)
Step: 92930, Reward: 0.0000 [0.00], Avg: -0.0765 (1.000)
Step: 93100, Reward: 0.0000 [0.00], Avg: -0.0763 (1.000)
Step: 93295, Reward: 0.0000 [0.00], Avg: -0.0762 (1.000)
Step: 93418, Reward: 0.0000 [0.00], Avg: -0.0760 (1.000)
Step: 93570, Reward: 0.0000 [0.00], Avg: -0.0759 (1.000)
Step: 93749, Reward: 0.0000 [0.00], Avg: -0.0757 (1.000)
Step: 93905, Reward: 0.0000 [0.00], Avg: -0.0756 (1.000)
Step: 94030, Reward: 0.0000 [0.00], Avg: -0.0755 (1.000)
Step: 94123, Reward: 0.0000 [0.00], Avg: -0.0753 (1.000)
Step: 94298, Reward: 0.0000 [0.00], Avg: -0.0752 (1.000)
Step: 94426, Reward: 0.0000 [0.00], Avg: -0.0750 (1.000)
Step: 94546, Reward: 0.0000 [0.00], Avg: -0.0749 (1.000)
Step: 94669, Reward: 0.0000 [0.00], Avg: -0.0748 (1.000)
Step: 94865, Reward: 0.0000 [0.00], Avg: -0.0746 (1.000)
Step: 95000, Reward: 0.0000 [0.00], Avg: -0.0745 (1.000)
Step: 95106, Reward: 0.0000 [0.00], Avg: -0.0744 (1.000)
Step: 95193, Reward: 0.0000 [0.00], Avg: -0.0742 (1.000)
Step: 95395, Reward: 0.0000 [0.00], Avg: -0.0741 (1.000)
Step: 95604, Reward: 0.0000 [0.00], Avg: -0.0740 (1.000)
Step: 95760, Reward: 0.0000 [0.00], Avg: -0.0738 (1.000)
Step: 95892, Reward: 0.0000 [0.00], Avg: -0.0737 (1.000)
Step: 96041, Reward: 0.0000 [0.00], Avg: -0.0736 (1.000)
Step: 96179, Reward: 0.0000 [0.00], Avg: -0.0734 (1.000)
Step: 96421, Reward: 0.0000 [0.00], Avg: -0.0733 (1.000)
Step: 96578, Reward: -0.2000 [0.40], Avg: -0.0742 (1.000)
Step: 96703, Reward: 0.0000 [0.00], Avg: -0.0741 (1.000)
Step: 96874, Reward: 0.0000 [0.00], Avg: -0.0740 (1.000)
Step: 97103, Reward: 0.0000 [0.00], Avg: -0.0738 (1.000)
Step: 97252, Reward: 0.0000 [0.00], Avg: -0.0737 (1.000)
Step: 97435, Reward: 0.0000 [0.00], Avg: -0.0736 (1.000)
Step: 97677, Reward: 0.0000 [0.00], Avg: -0.0734 (1.000)
Step: 97724, Reward: 0.0000 [0.00], Avg: -0.0733 (1.000)
Step: 97911, Reward: 0.0000 [0.00], Avg: -0.0732 (1.000)
Step: 98129, Reward: 0.0000 [0.00], Avg: -0.0731 (1.000)
Step: 98324, Reward: 0.0000 [0.00], Avg: -0.0729 (1.000)
Step: 98510, Reward: 0.0000 [0.00], Avg: -0.0728 (1.000)
Step: 98672, Reward: 0.0000 [0.00], Avg: -0.0727 (1.000)
Step: 98790, Reward: 0.0000 [0.00], Avg: -0.0725 (1.000)
Step: 98964, Reward: 0.0000 [0.00], Avg: -0.0724 (1.000)
Step: 99109, Reward: 0.0000 [0.00], Avg: -0.0723 (1.000)
Step: 99226, Reward: 0.0000 [0.00], Avg: -0.0722 (1.000)
Step: 99438, Reward: 0.0000 [0.00], Avg: -0.0720 (1.000)
Step: 99631, Reward: 0.0000 [0.00], Avg: -0.0719 (1.000)
Step: 99827, Reward: 0.0000 [0.00], Avg: -0.0718 (1.000)
Step: 99947, Reward: 0.0000 [0.00], Avg: -0.0717 (1.000)
