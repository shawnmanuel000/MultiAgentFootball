Model: <class 'multiagent.maddpg.MADDPGAgent'>, Dir: simple_spread
num_envs: 1, state_size: [(1, 18), (1, 18), (1, 18)], action_size: [[1, 5], [1, 5], [1, 5]], action_space: [<gym.spaces.multi_discrete.MultiDiscrete object at 0x7f4c3b8ef358>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f4c3b8ef400>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f4c3b8ef470>],

import torch
import random
import numpy as np
from models.rand import MultiagentReplayBuffer
from models.ddpg import DDPGActor, DDPGCritic, DDPGNetwork
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACAgent, LEARN_RATE, NUM_STEPS, EPS_MIN, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, MAX_BUFFER_SIZE, gsoftmax, one_hot

REPLAY_BATCH_SIZE = 1024
ENTROPY_WEIGHT = 0.001			# The weight for the entropy term of the Actor loss
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
NUM_STEPS = 50					# The number of steps to collect experience in sequence for each GAE calculation
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64
LEARN_RATE = 0.01
TARGET_UPDATE_RATE = 0.01

class MADDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		action_mu = self.action_mu(state)
		return action_mu
	
class MADDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1]+action_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = torch.cat([state, action], -1)
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		q_value = self.q_value(state)
		return q_value

class MADDPGNetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=True, load=None):
		super().__init__(tau=tau, gpu=gpu)
		self.state_size = state_size
		self.action_size = action_size
		self.critic = MADDPGCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.models = [DDPGNetwork(s_size, a_size, MADDPGActor, lambda s,a: self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		
	def get_action_probs(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [model.get_action(s, use_target, grad, numpy, sample) for s,model in zip(state, self.models)]
			return action

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_value = [model.get_q_value(state, action, use_target, grad, numpy) for model in self.models]
			return q_value

	def optimize(self, states, actions, states_joint, actions_joint, q_targets, e_weight=ENTROPY_WEIGHT):
		for (i,model),state,q_target in zip(enumerate(self.models), states, q_targets):
			q_values = model.get_q_value(states_joint, actions_joint, grad=True, numpy=False)
			critic_error = q_values[:q_target.size(0)] - q_target.detach()
			critic_loss = critic_error.pow(2)
			model.step(model.critic_optimizer, critic_loss.mean(), param_norm=model.critic_local.parameters())
			model.soft_copy(model.critic_local, model.critic_target)

			actor_action = model.get_action(state, grad=True, numpy=False)
			critic_action = [actor_action if j==i else other.get_action(states[j], numpy=False) for j,other in enumerate(self.models)]
			action_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(critic_action, self.action_size)], dim=-1)
			q_actions = model.critic_local(states_joint, action_joint)
			actor_loss = -q_actions.mean() + e_weight*actor_action.pow(2).mean()
			model.step(model.actor_optimizer, actor_loss.mean(), param_norm=model.actor_local.parameters())
			model.soft_copy(model.actor_local, model.actor_target)

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class MADDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, MADDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.replay_buffer = MultiagentReplayBuffer(10000, state_size, action_size)
		self.agent = MADDPG(state_size, action_size)

	def get_action(self, state, eps=None, sample=True, numpy=True):
		action = self.agent.get_action_probs(self.to_tensor(state), sample=sample, numpy=numpy)
		return action

	def train(self, state, action, next_state, reward, done):
		self.t = 0 if not hasattr(self, "t") else self.t + 1
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.update_freq:
			states, actions, rewards, dones = map(lambda x: self.to_tensor(x), zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, next_state)]
			actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.agent.get_action_probs(next_state))]
			states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			actions_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions, self.action_size)], dim=-1)
			q_values = self.agent.get_q_value(states_joint, actions_joint, use_target=True)
			q_targets = [self.compute_gae(q_value[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_value[:-1], gamma=0.95)[0].squeeze(-1) for q_value,reward,done in zip(q_values, rewards, dones)]

			states, actions = map(lambda items: [x[:-1] for x in items], [states, actions])
			states, actions, q_targets = map(lambda items: [x.view(-1, *x.shape[2:]).cpu().numpy() for x in items], [states, actions, q_targets])
			self.replay_buffer.push(states, actions, q_targets)

		if (len(self.replay_buffer) >= REPLAY_BATCH_SIZE and (self.t % 100)==0):
			states, actions, q_targets = self.replay_buffer.sample(REPLAY_BATCH_SIZE, to_gpu=False)
			self.agent.update(states, actions, q_targets)

class MADDPG(PTNetwork):
	def __init__(self, state_size, action_size, gamma=0.95, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=False, load=None):
		super().__init__(tau=tau, gpu=gpu)
		self.gamma = gamma
		self.state_size = state_size
		self.action_size = action_size
		self.critic = lambda s,a: MADDPGCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.agents = [DDPGNetwork(s_size, a_size, MADDPGActor, self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]

	def get_action_probs(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [gsoftmax(model.get_action(s, use_target, grad, numpy=False), hard=True) for s,model in zip(state, self.agents)]
			return [a.cpu().numpy() if numpy else a for a in action]

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_value = [model.get_q_value(state, action, use_target, grad, numpy) for model in self.agents]
			return q_value

	def update(self, states, actions, q_targets):
		for agent_i, curr_agent in enumerate(self.agents):
			target_value = q_targets[agent_i]
			# next_actions = [one_hot(agent.get_action(nobs, numpy=False)) for agent, nobs in zip(self.agents, next_states)]
			# next_states_joint = torch.cat([*next_states], dim=-1)
			# next_actions_joint = torch.cat([*next_actions], dim=-1)
			# next_value = curr_agent.get_q_value(next_states_joint, next_actions_joint, use_target=True, numpy=False)
			# target_value = (rewards[agent_i].view(-1, 1, 1) + self.gamma * next_value * (1 - dones[agent_i].view(-1, 1, 1)))

			states_joint = torch.cat([*states], dim=-1)
			actions_joint = torch.cat([*actions], dim=-1)
			actual_value = curr_agent.get_q_value(states_joint, actions_joint, grad=True, numpy=False)
			vf_loss = (actual_value - target_value.detach()).pow(2).mean()
			curr_agent.step(curr_agent.critic_optimizer, vf_loss, param_norm=curr_agent.critic_local.parameters())
			curr_agent.soft_copy(curr_agent.critic_local, curr_agent.critic_target)

			curr_pol_out = curr_agent.get_action(states[agent_i], grad=True, numpy=False)
			curr_pol_vf_in = gsoftmax(curr_pol_out, hard=True)
			action = [curr_pol_vf_in if i==agent_i else one_hot(agent.get_action(ob, numpy=False)) for (i,agent), ob in zip(enumerate(self.agents), states)]
			action_joint = torch.cat([*action], dim=-1)
			pol_loss = -curr_agent.critic_local(states_joint, action_joint).mean() + 0.001*curr_pol_out.pow(2).mean() 
			curr_agent.step(curr_agent.actor_optimizer, pol_loss, param_norm=curr_agent.actor_local.parameters())
			curr_agent.soft_copy(curr_agent.actor_local, curr_agent.actor_target)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.900             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)
# np.random.seed(1)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return gym.make(env_name)
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":0} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env)

def run(model, steps=10000, ports=16, env_name=env_name, eval_at=1000, checkpoint=False, save_best=False, log=True, render=True):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports, render=False, env_name=env_name)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, num_envs=num_envs, gpu=False, agent2=RandomAgent) 
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if np.any(dones[0]):
			rollouts = [rollout(envs.env, agent.reset(1), render=render) for _ in range(1)]
			test_reward = np.mean(rollouts, axis=0) - np.std(rollouts, axis=0)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if save_best and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts, axis=0)} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")
			agent.reset(num_envs)

def trial(model):
	envs = EnsembleEnv(make_env, 0, log=True, render=True)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, load=f"{env_name}")
	print(f"Reward: {rollout(envs.env, agent, eps=0.02, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[1], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="maddpg", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--test", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.test:
		trial(model)
	elif args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		run(model, args.steps, args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)

Step: 49, Reward: [-547.792 -547.792 -547.792] [0.0000], Avg: [-547.792 -547.792 -547.792] (1.000)
Step: 99, Reward: [-380.304 -380.304 -380.304] [0.0000], Avg: [-464.048 -464.048 -464.048] (1.000)
Step: 149, Reward: [-375.701 -375.701 -375.701] [0.0000], Avg: [-434.599 -434.599 -434.599] (1.000)
Step: 199, Reward: [-413.665 -413.665 -413.665] [0.0000], Avg: [-429.365 -429.365 -429.365] (1.000)
Step: 249, Reward: [-501.668 -501.668 -501.668] [0.0000], Avg: [-443.826 -443.826 -443.826] (1.000)
Step: 299, Reward: [-584.656 -584.656 -584.656] [0.0000], Avg: [-467.298 -467.298 -467.298] (1.000)
Step: 349, Reward: [-717.983 -717.983 -717.983] [0.0000], Avg: [-503.11 -503.11 -503.11] (1.000)
Step: 399, Reward: [-412.081 -412.081 -412.081] [0.0000], Avg: [-491.731 -491.731 -491.731] (1.000)
Step: 449, Reward: [-424.883 -424.883 -424.883] [0.0000], Avg: [-484.304 -484.304 -484.304] (1.000)
Step: 499, Reward: [-480.146 -480.146 -480.146] [0.0000], Avg: [-483.888 -483.888 -483.888] (1.000)
Step: 549, Reward: [-450.925 -450.925 -450.925] [0.0000], Avg: [-480.891 -480.891 -480.891] (1.000)
Step: 599, Reward: [-541.371 -541.371 -541.371] [0.0000], Avg: [-485.931 -485.931 -485.931] (1.000)
Step: 649, Reward: [-538.931 -538.931 -538.931] [0.0000], Avg: [-490.008 -490.008 -490.008] (1.000)
Step: 699, Reward: [-407.874 -407.874 -407.874] [0.0000], Avg: [-484.141 -484.141 -484.141] (1.000)
Step: 749, Reward: [-670.099 -670.099 -670.099] [0.0000], Avg: [-496.539 -496.539 -496.539] (1.000)
Step: 799, Reward: [-458.296 -458.296 -458.296] [0.0000], Avg: [-494.148 -494.148 -494.148] (1.000)
Step: 849, Reward: [-694.064 -694.064 -694.064] [0.0000], Avg: [-505.908 -505.908 -505.908] (1.000)
Step: 899, Reward: [-508.38 -508.38 -508.38] [0.0000], Avg: [-506.046 -506.046 -506.046] (1.000)
Step: 949, Reward: [-446.136 -446.136 -446.136] [0.0000], Avg: [-502.892 -502.892 -502.892] (1.000)
Step: 999, Reward: [-670.085 -670.085 -670.085] [0.0000], Avg: [-511.252 -511.252 -511.252] (1.000)
Step: 1049, Reward: [-432.443 -432.443 -432.443] [0.0000], Avg: [-507.499 -507.499 -507.499] (1.000)
Step: 1099, Reward: [-409.395 -409.395 -409.395] [0.0000], Avg: [-503.04 -503.04 -503.04] (1.000)
Step: 1149, Reward: [-455.524 -455.524 -455.524] [0.0000], Avg: [-500.974 -500.974 -500.974] (1.000)
Step: 1199, Reward: [-391.895 -391.895 -391.895] [0.0000], Avg: [-496.429 -496.429 -496.429] (1.000)
Step: 1249, Reward: [-455.581 -455.581 -455.581] [0.0000], Avg: [-494.795 -494.795 -494.795] (1.000)
Step: 1299, Reward: [-503.572 -503.572 -503.572] [0.0000], Avg: [-495.133 -495.133 -495.133] (1.000)
Step: 1349, Reward: [-389.786 -389.786 -389.786] [0.0000], Avg: [-491.231 -491.231 -491.231] (1.000)
Step: 1399, Reward: [-802.298 -802.298 -802.298] [0.0000], Avg: [-502.341 -502.341 -502.341] (1.000)
Step: 1449, Reward: [-631.929 -631.929 -631.929] [0.0000], Avg: [-506.809 -506.809 -506.809] (1.000)
Step: 1499, Reward: [-692.167 -692.167 -692.167] [0.0000], Avg: [-512.988 -512.988 -512.988] (1.000)
Step: 1549, Reward: [-857.828 -857.828 -857.828] [0.0000], Avg: [-524.112 -524.112 -524.112] (1.000)
Step: 1599, Reward: [-693.195 -693.195 -693.195] [0.0000], Avg: [-529.395 -529.395 -529.395] (1.000)
Step: 1649, Reward: [-643.334 -643.334 -643.334] [0.0000], Avg: [-532.848 -532.848 -532.848] (1.000)
Step: 1699, Reward: [-424.367 -424.367 -424.367] [0.0000], Avg: [-529.658 -529.658 -529.658] (1.000)
Step: 1749, Reward: [-1521.424 -1521.424 -1521.424] [0.0000], Avg: [-557.994 -557.994 -557.994] (1.000)
Step: 1799, Reward: [-1760.296 -1760.296 -1760.296] [0.0000], Avg: [-591.391 -591.391 -591.391] (1.000)
Step: 1849, Reward: [-1733.007 -1733.007 -1733.007] [0.0000], Avg: [-622.245 -622.245 -622.245] (1.000)
Step: 1899, Reward: [-438.766 -438.766 -438.766] [0.0000], Avg: [-617.417 -617.417 -617.417] (1.000)
Step: 1949, Reward: [-2102.329 -2102.329 -2102.329] [0.0000], Avg: [-655.492 -655.492 -655.492] (1.000)
Step: 1999, Reward: [-2066.469 -2066.469 -2066.469] [0.0000], Avg: [-690.766 -690.766 -690.766] (1.000)
Step: 2049, Reward: [-1907.198 -1907.198 -1907.198] [0.0000], Avg: [-720.435 -720.435 -720.435] (1.000)
Step: 2099, Reward: [-1226.334 -1226.334 -1226.334] [0.0000], Avg: [-732.48 -732.48 -732.48] (1.000)
Step: 2149, Reward: [-2123.087 -2123.087 -2123.087] [0.0000], Avg: [-764.82 -764.82 -764.82] (1.000)
Step: 2199, Reward: [-1901.536 -1901.536 -1901.536] [0.0000], Avg: [-790.655 -790.655 -790.655] (1.000)
Step: 2249, Reward: [-2198.358 -2198.358 -2198.358] [0.0000], Avg: [-821.937 -821.937 -821.937] (1.000)
Step: 2299, Reward: [-702.339 -702.339 -702.339] [0.0000], Avg: [-819.337 -819.337 -819.337] (1.000)
Step: 2349, Reward: [-1497.382 -1497.382 -1497.382] [0.0000], Avg: [-833.763 -833.763 -833.763] (1.000)
Step: 2399, Reward: [-1819.444 -1819.444 -1819.444] [0.0000], Avg: [-854.298 -854.298 -854.298] (1.000)
Step: 2449, Reward: [-1596.585 -1596.585 -1596.585] [0.0000], Avg: [-869.447 -869.447 -869.447] (1.000)
Step: 2499, Reward: [-991.767 -991.767 -991.767] [0.0000], Avg: [-871.894 -871.894 -871.894] (1.000)
Step: 2549, Reward: [-1510.728 -1510.728 -1510.728] [0.0000], Avg: [-884.42 -884.42 -884.42] (1.000)
Step: 2599, Reward: [-1927.852 -1927.852 -1927.852] [0.0000], Avg: [-904.486 -904.486 -904.486] (1.000)
Step: 2649, Reward: [-2012.6 -2012.6 -2012.6] [0.0000], Avg: [-925.394 -925.394 -925.394] (1.000)
Step: 2699, Reward: [-609.473 -609.473 -609.473] [0.0000], Avg: [-919.543 -919.543 -919.543] (1.000)
Step: 2749, Reward: [-615.767 -615.767 -615.767] [0.0000], Avg: [-914.02 -914.02 -914.02] (1.000)
Step: 2799, Reward: [-2095.039 -2095.039 -2095.039] [0.0000], Avg: [-935.11 -935.11 -935.11] (1.000)
Step: 2849, Reward: [-1889.069 -1889.069 -1889.069] [0.0000], Avg: [-951.846 -951.846 -951.846] (1.000)
Step: 2899, Reward: [-2064.717 -2064.717 -2064.717] [0.0000], Avg: [-971.033 -971.033 -971.033] (1.000)
Step: 2949, Reward: [-1885.596 -1885.596 -1885.596] [0.0000], Avg: [-986.534 -986.534 -986.534] (1.000)
Step: 2999, Reward: [-942.309 -942.309 -942.309] [0.0000], Avg: [-985.797 -985.797 -985.797] (1.000)
Step: 3049, Reward: [-1639.005 -1639.005 -1639.005] [0.0000], Avg: [-996.505 -996.505 -996.505] (1.000)
Step: 3099, Reward: [-1858.248 -1858.248 -1858.248] [0.0000], Avg: [-1010.405 -1010.405 -1010.405] (1.000)
Step: 3149, Reward: [-2068.067 -2068.067 -2068.067] [0.0000], Avg: [-1027.193 -1027.193 -1027.193] (1.000)
Step: 3199, Reward: [-1939.892 -1939.892 -1939.892] [0.0000], Avg: [-1041.454 -1041.454 -1041.454] (1.000)
Step: 3249, Reward: [-466.826 -466.826 -466.826] [0.0000], Avg: [-1032.613 -1032.613 -1032.613] (1.000)
Step: 3299, Reward: [-1909.665 -1909.665 -1909.665] [0.0000], Avg: [-1045.902 -1045.902 -1045.902] (1.000)
Step: 3349, Reward: [-2049.022 -2049.022 -2049.022] [0.0000], Avg: [-1060.874 -1060.874 -1060.874] (1.000)
Step: 3399, Reward: [-1491.324 -1491.324 -1491.324] [0.0000], Avg: [-1067.204 -1067.204 -1067.204] (1.000)
Step: 3449, Reward: [-1906.044 -1906.044 -1906.044] [0.0000], Avg: [-1079.361 -1079.361 -1079.361] (1.000)
Step: 3499, Reward: [-2056.284 -2056.284 -2056.284] [0.0000], Avg: [-1093.317 -1093.317 -1093.317] (1.000)
Step: 3549, Reward: [-1792.085 -1792.085 -1792.085] [0.0000], Avg: [-1103.159 -1103.159 -1103.159] (1.000)
Step: 3599, Reward: [-2145.542 -2145.542 -2145.542] [0.0000], Avg: [-1117.637 -1117.637 -1117.637] (1.000)
Step: 3649, Reward: [-2167.67 -2167.67 -2167.67] [0.0000], Avg: [-1132.021 -1132.021 -1132.021] (1.000)
Step: 3699, Reward: [-1634.829 -1634.829 -1634.829] [0.0000], Avg: [-1138.815 -1138.815 -1138.815] (1.000)
Step: 3749, Reward: [-2139.815 -2139.815 -2139.815] [0.0000], Avg: [-1152.162 -1152.162 -1152.162] (1.000)
Step: 3799, Reward: [-2107.327 -2107.327 -2107.327] [0.0000], Avg: [-1164.73 -1164.73 -1164.73] (1.000)
Step: 3849, Reward: [-1917.674 -1917.674 -1917.674] [0.0000], Avg: [-1174.508 -1174.508 -1174.508] (1.000)
Step: 3899, Reward: [-1968.288 -1968.288 -1968.288] [0.0000], Avg: [-1184.685 -1184.685 -1184.685] (1.000)
Step: 3949, Reward: [-1695.903 -1695.903 -1695.903] [0.0000], Avg: [-1191.156 -1191.156 -1191.156] (1.000)
Step: 3999, Reward: [-1926.641 -1926.641 -1926.641] [0.0000], Avg: [-1200.35 -1200.35 -1200.35] (1.000)
Step: 4049, Reward: [-1859.741 -1859.741 -1859.741] [0.0000], Avg: [-1208.49 -1208.49 -1208.49] (1.000)
Step: 4099, Reward: [-1751.139 -1751.139 -1751.139] [0.0000], Avg: [-1215.108 -1215.108 -1215.108] (1.000)
Step: 4149, Reward: [-1145.459 -1145.459 -1145.459] [0.0000], Avg: [-1214.269 -1214.269 -1214.269] (1.000)
Step: 4199, Reward: [-1426.162 -1426.162 -1426.162] [0.0000], Avg: [-1216.791 -1216.791 -1216.791] (1.000)
Step: 4249, Reward: [-958.932 -958.932 -958.932] [0.0000], Avg: [-1213.758 -1213.758 -1213.758] (1.000)
Step: 4299, Reward: [-729.667 -729.667 -729.667] [0.0000], Avg: [-1208.129 -1208.129 -1208.129] (1.000)
Step: 4349, Reward: [-1206.98 -1206.98 -1206.98] [0.0000], Avg: [-1208.116 -1208.116 -1208.116] (1.000)
Step: 4399, Reward: [-859.875 -859.875 -859.875] [0.0000], Avg: [-1204.158 -1204.158 -1204.158] (1.000)
Step: 4449, Reward: [-1016.681 -1016.681 -1016.681] [0.0000], Avg: [-1202.052 -1202.052 -1202.052] (1.000)
Step: 4499, Reward: [-1383.476 -1383.476 -1383.476] [0.0000], Avg: [-1204.068 -1204.068 -1204.068] (1.000)
Step: 4549, Reward: [-1380.905 -1380.905 -1380.905] [0.0000], Avg: [-1206.011 -1206.011 -1206.011] (1.000)
Step: 4599, Reward: [-1144.921 -1144.921 -1144.921] [0.0000], Avg: [-1205.347 -1205.347 -1205.347] (1.000)
Step: 4649, Reward: [-1201.3 -1201.3 -1201.3] [0.0000], Avg: [-1205.303 -1205.303 -1205.303] (1.000)
Step: 4699, Reward: [-2215.381 -2215.381 -2215.381] [0.0000], Avg: [-1216.049 -1216.049 -1216.049] (1.000)
Step: 4749, Reward: [-1768.296 -1768.296 -1768.296] [0.0000], Avg: [-1221.862 -1221.862 -1221.862] (1.000)
Step: 4799, Reward: [-1736.748 -1736.748 -1736.748] [0.0000], Avg: [-1227.225 -1227.225 -1227.225] (1.000)
Step: 4849, Reward: [-2004.347 -2004.347 -2004.347] [0.0000], Avg: [-1235.237 -1235.237 -1235.237] (1.000)
Step: 4899, Reward: [-2017.179 -2017.179 -2017.179] [0.0000], Avg: [-1243.216 -1243.216 -1243.216] (1.000)
Step: 4949, Reward: [-1798.831 -1798.831 -1798.831] [0.0000], Avg: [-1248.828 -1248.828 -1248.828] (1.000)
Step: 4999, Reward: [-1232.333 -1232.333 -1232.333] [0.0000], Avg: [-1248.663 -1248.663 -1248.663] (1.000)
Step: 5049, Reward: [-1415.122 -1415.122 -1415.122] [0.0000], Avg: [-1250.311 -1250.311 -1250.311] (1.000)
Step: 5099, Reward: [-2023.461 -2023.461 -2023.461] [0.0000], Avg: [-1257.891 -1257.891 -1257.891] (1.000)
Step: 5149, Reward: [-1815.361 -1815.361 -1815.361] [0.0000], Avg: [-1263.304 -1263.304 -1263.304] (1.000)
Step: 5199, Reward: [-1592.175 -1592.175 -1592.175] [0.0000], Avg: [-1266.466 -1266.466 -1266.466] (1.000)
Step: 5249, Reward: [-1325.166 -1325.166 -1325.166] [0.0000], Avg: [-1267.025 -1267.025 -1267.025] (1.000)
Step: 5299, Reward: [-1429.398 -1429.398 -1429.398] [0.0000], Avg: [-1268.557 -1268.557 -1268.557] (1.000)
Step: 5349, Reward: [-1203.908 -1203.908 -1203.908] [0.0000], Avg: [-1267.953 -1267.953 -1267.953] (1.000)
Step: 5399, Reward: [-1143.578 -1143.578 -1143.578] [0.0000], Avg: [-1266.801 -1266.801 -1266.801] (1.000)
Step: 5449, Reward: [-701.053 -701.053 -701.053] [0.0000], Avg: [-1261.611 -1261.611 -1261.611] (1.000)
Step: 5499, Reward: [-905.143 -905.143 -905.143] [0.0000], Avg: [-1258.37 -1258.37 -1258.37] (1.000)
Step: 5549, Reward: [-704.088 -704.088 -704.088] [0.0000], Avg: [-1253.376 -1253.376 -1253.376] (1.000)
Step: 5599, Reward: [-886.068 -886.068 -886.068] [0.0000], Avg: [-1250.097 -1250.097 -1250.097] (1.000)
Step: 5649, Reward: [-945.379 -945.379 -945.379] [0.0000], Avg: [-1247.4 -1247.4 -1247.4] (1.000)
Step: 5699, Reward: [-1056.699 -1056.699 -1056.699] [0.0000], Avg: [-1245.727 -1245.727 -1245.727] (1.000)
Step: 5749, Reward: [-857.304 -857.304 -857.304] [0.0000], Avg: [-1242.35 -1242.35 -1242.35] (1.000)
Step: 5799, Reward: [-646.649 -646.649 -646.649] [0.0000], Avg: [-1237.215 -1237.215 -1237.215] (1.000)
Step: 5849, Reward: [-588.312 -588.312 -588.312] [0.0000], Avg: [-1231.668 -1231.668 -1231.668] (1.000)
Step: 5899, Reward: [-745.458 -745.458 -745.458] [0.0000], Avg: [-1227.548 -1227.548 -1227.548] (1.000)
Step: 5949, Reward: [-674.215 -674.215 -674.215] [0.0000], Avg: [-1222.898 -1222.898 -1222.898] (1.000)
Step: 5999, Reward: [-657.063 -657.063 -657.063] [0.0000], Avg: [-1218.183 -1218.183 -1218.183] (1.000)
Step: 6049, Reward: [-472.817 -472.817 -472.817] [0.0000], Avg: [-1212.023 -1212.023 -1212.023] (1.000)
Step: 6099, Reward: [-780.699 -780.699 -780.699] [0.0000], Avg: [-1208.487 -1208.487 -1208.487] (1.000)
Step: 6149, Reward: [-670.089 -670.089 -670.089] [0.0000], Avg: [-1204.11 -1204.11 -1204.11] (1.000)
Step: 6199, Reward: [-723.988 -723.988 -723.988] [0.0000], Avg: [-1200.238 -1200.238 -1200.238] (1.000)
Step: 6249, Reward: [-766.636 -766.636 -766.636] [0.0000], Avg: [-1196.769 -1196.769 -1196.769] (1.000)
Step: 6299, Reward: [-788.876 -788.876 -788.876] [0.0000], Avg: [-1193.532 -1193.532 -1193.532] (1.000)
Step: 6349, Reward: [-1076.28 -1076.28 -1076.28] [0.0000], Avg: [-1192.609 -1192.609 -1192.609] (1.000)
Step: 6399, Reward: [-1010.993 -1010.993 -1010.993] [0.0000], Avg: [-1191.19 -1191.19 -1191.19] (1.000)
Step: 6449, Reward: [-1438.346 -1438.346 -1438.346] [0.0000], Avg: [-1193.106 -1193.106 -1193.106] (1.000)
Step: 6499, Reward: [-1567.683 -1567.683 -1567.683] [0.0000], Avg: [-1195.987 -1195.987 -1195.987] (1.000)
Step: 6549, Reward: [-1814.166 -1814.166 -1814.166] [0.0000], Avg: [-1200.706 -1200.706 -1200.706] (1.000)
Step: 6599, Reward: [-1498.292 -1498.292 -1498.292] [0.0000], Avg: [-1202.961 -1202.961 -1202.961] (1.000)
Step: 6649, Reward: [-1731.83 -1731.83 -1731.83] [0.0000], Avg: [-1206.937 -1206.937 -1206.937] (1.000)
Step: 6699, Reward: [-1845.376 -1845.376 -1845.376] [0.0000], Avg: [-1211.702 -1211.702 -1211.702] (1.000)
Step: 6749, Reward: [-1837.351 -1837.351 -1837.351] [0.0000], Avg: [-1216.336 -1216.336 -1216.336] (1.000)
Step: 6799, Reward: [-1708.763 -1708.763 -1708.763] [0.0000], Avg: [-1219.957 -1219.957 -1219.957] (1.000)
Step: 6849, Reward: [-1733.988 -1733.988 -1733.988] [0.0000], Avg: [-1223.709 -1223.709 -1223.709] (1.000)
Step: 6899, Reward: [-2025.747 -2025.747 -2025.747] [0.0000], Avg: [-1229.521 -1229.521 -1229.521] (1.000)
Step: 6949, Reward: [-1954.877 -1954.877 -1954.877] [0.0000], Avg: [-1234.739 -1234.739 -1234.739] (1.000)
Step: 6999, Reward: [-1800.799 -1800.799 -1800.799] [0.0000], Avg: [-1238.782 -1238.782 -1238.782] (1.000)
Step: 7049, Reward: [-804.367 -804.367 -804.367] [0.0000], Avg: [-1235.701 -1235.701 -1235.701] (1.000)
Step: 7099, Reward: [-989.94 -989.94 -989.94] [0.0000], Avg: [-1233.971 -1233.971 -1233.971] (1.000)
Step: 7149, Reward: [-865.35 -865.35 -865.35] [0.0000], Avg: [-1231.393 -1231.393 -1231.393] (1.000)
Step: 7199, Reward: [-831.839 -831.839 -831.839] [0.0000], Avg: [-1228.618 -1228.618 -1228.618] (1.000)
Step: 7249, Reward: [-524.268 -524.268 -524.268] [0.0000], Avg: [-1223.761 -1223.761 -1223.761] (1.000)
Step: 7299, Reward: [-901.706 -901.706 -901.706] [0.0000], Avg: [-1221.555 -1221.555 -1221.555] (1.000)
Step: 7349, Reward: [-407.755 -407.755 -407.755] [0.0000], Avg: [-1216.019 -1216.019 -1216.019] (1.000)
Step: 7399, Reward: [-672.976 -672.976 -672.976] [0.0000], Avg: [-1212.35 -1212.35 -1212.35] (1.000)
Step: 7449, Reward: [-485.927 -485.927 -485.927] [0.0000], Avg: [-1207.474 -1207.474 -1207.474] (1.000)
Step: 7499, Reward: [-606.028 -606.028 -606.028] [0.0000], Avg: [-1203.465 -1203.465 -1203.465] (1.000)
Step: 7549, Reward: [-696.355 -696.355 -696.355] [0.0000], Avg: [-1200.106 -1200.106 -1200.106] (1.000)
Step: 7599, Reward: [-818.588 -818.588 -818.588] [0.0000], Avg: [-1197.596 -1197.596 -1197.596] (1.000)
Step: 7649, Reward: [-625.768 -625.768 -625.768] [0.0000], Avg: [-1193.859 -1193.859 -1193.859] (1.000)
Step: 7699, Reward: [-379.658 -379.658 -379.658] [0.0000], Avg: [-1188.572 -1188.572 -1188.572] (1.000)
Step: 7749, Reward: [-516.681 -516.681 -516.681] [0.0000], Avg: [-1184.237 -1184.237 -1184.237] (1.000)
Step: 7799, Reward: [-375.687 -375.687 -375.687] [0.0000], Avg: [-1179.054 -1179.054 -1179.054] (1.000)
Step: 7849, Reward: [-574.606 -574.606 -574.606] [0.0000], Avg: [-1175.204 -1175.204 -1175.204] (1.000)
Step: 7899, Reward: [-479.502 -479.502 -479.502] [0.0000], Avg: [-1170.801 -1170.801 -1170.801] (1.000)
Step: 7949, Reward: [-746.095 -746.095 -746.095] [0.0000], Avg: [-1168.13 -1168.13 -1168.13] (1.000)
Step: 7999, Reward: [-630.995 -630.995 -630.995] [0.0000], Avg: [-1164.773 -1164.773 -1164.773] (1.000)
Step: 8049, Reward: [-348.308 -348.308 -348.308] [0.0000], Avg: [-1159.701 -1159.701 -1159.701] (1.000)
Step: 8099, Reward: [-493.847 -493.847 -493.847] [0.0000], Avg: [-1155.591 -1155.591 -1155.591] (1.000)
Step: 8149, Reward: [-573.677 -573.677 -573.677] [0.0000], Avg: [-1152.021 -1152.021 -1152.021] (1.000)
Step: 8199, Reward: [-846.271 -846.271 -846.271] [0.0000], Avg: [-1150.157 -1150.157 -1150.157] (1.000)
Step: 8249, Reward: [-493.019 -493.019 -493.019] [0.0000], Avg: [-1146.174 -1146.174 -1146.174] (1.000)
Step: 8299, Reward: [-663.145 -663.145 -663.145] [0.0000], Avg: [-1143.264 -1143.264 -1143.264] (1.000)
Step: 8349, Reward: [-596.937 -596.937 -596.937] [0.0000], Avg: [-1139.993 -1139.993 -1139.993] (1.000)
Step: 8399, Reward: [-679.739 -679.739 -679.739] [0.0000], Avg: [-1137.253 -1137.253 -1137.253] (1.000)
Step: 8449, Reward: [-590.488 -590.488 -590.488] [0.0000], Avg: [-1134.018 -1134.018 -1134.018] (1.000)
Step: 8499, Reward: [-551.62 -551.62 -551.62] [0.0000], Avg: [-1130.592 -1130.592 -1130.592] (1.000)
Step: 8549, Reward: [-725.426 -725.426 -725.426] [0.0000], Avg: [-1128.223 -1128.223 -1128.223] (1.000)
Step: 8599, Reward: [-720.214 -720.214 -720.214] [0.0000], Avg: [-1125.851 -1125.851 -1125.851] (1.000)
Step: 8649, Reward: [-481.981 -481.981 -481.981] [0.0000], Avg: [-1122.129 -1122.129 -1122.129] (1.000)
Step: 8699, Reward: [-771.067 -771.067 -771.067] [0.0000], Avg: [-1120.111 -1120.111 -1120.111] (1.000)
Step: 8749, Reward: [-523.184 -523.184 -523.184] [0.0000], Avg: [-1116.7 -1116.7 -1116.7] (1.000)
Step: 8799, Reward: [-764.559 -764.559 -764.559] [0.0000], Avg: [-1114.699 -1114.699 -1114.699] (1.000)
Step: 8849, Reward: [-591.896 -591.896 -591.896] [0.0000], Avg: [-1111.746 -1111.746 -1111.746] (1.000)
Step: 8899, Reward: [-445.048 -445.048 -445.048] [0.0000], Avg: [-1108. -1108. -1108.] (1.000)
Step: 8949, Reward: [-748.64 -748.64 -748.64] [0.0000], Avg: [-1105.993 -1105.993 -1105.993] (1.000)
Step: 8999, Reward: [-391.716 -391.716 -391.716] [0.0000], Avg: [-1102.024 -1102.024 -1102.024] (1.000)
Step: 9049, Reward: [-799.977 -799.977 -799.977] [0.0000], Avg: [-1100.356 -1100.356 -1100.356] (1.000)
Step: 9099, Reward: [-424.177 -424.177 -424.177] [0.0000], Avg: [-1096.64 -1096.64 -1096.64] (1.000)
Step: 9149, Reward: [-454.388 -454.388 -454.388] [0.0000], Avg: [-1093.131 -1093.131 -1093.131] (1.000)
Step: 9199, Reward: [-445.055 -445.055 -445.055] [0.0000], Avg: [-1089.609 -1089.609 -1089.609] (1.000)
Step: 9249, Reward: [-464.171 -464.171 -464.171] [0.0000], Avg: [-1086.228 -1086.228 -1086.228] (1.000)
Step: 9299, Reward: [-591.714 -591.714 -591.714] [0.0000], Avg: [-1083.569 -1083.569 -1083.569] (1.000)
Step: 9349, Reward: [-394.81 -394.81 -394.81] [0.0000], Avg: [-1079.886 -1079.886 -1079.886] (1.000)
Step: 9399, Reward: [-490.853 -490.853 -490.853] [0.0000], Avg: [-1076.753 -1076.753 -1076.753] (1.000)
Step: 9449, Reward: [-439.915 -439.915 -439.915] [0.0000], Avg: [-1073.383 -1073.383 -1073.383] (1.000)
Step: 9499, Reward: [-494.926 -494.926 -494.926] [0.0000], Avg: [-1070.339 -1070.339 -1070.339] (1.000)
Step: 9549, Reward: [-630.443 -630.443 -630.443] [0.0000], Avg: [-1068.036 -1068.036 -1068.036] (1.000)
Step: 9599, Reward: [-498.915 -498.915 -498.915] [0.0000], Avg: [-1065.072 -1065.072 -1065.072] (1.000)
Step: 9649, Reward: [-459.426 -459.426 -459.426] [0.0000], Avg: [-1061.934 -1061.934 -1061.934] (1.000)
Step: 9699, Reward: [-443.04 -443.04 -443.04] [0.0000], Avg: [-1058.743 -1058.743 -1058.743] (1.000)
Step: 9749, Reward: [-459.579 -459.579 -459.579] [0.0000], Avg: [-1055.671 -1055.671 -1055.671] (1.000)
Step: 9799, Reward: [-466.627 -466.627 -466.627] [0.0000], Avg: [-1052.665 -1052.665 -1052.665] (1.000)
Step: 9849, Reward: [-592.634 -592.634 -592.634] [0.0000], Avg: [-1050.33 -1050.33 -1050.33] (1.000)
Step: 9899, Reward: [-589.599 -589.599 -589.599] [0.0000], Avg: [-1048.003 -1048.003 -1048.003] (1.000)
Step: 9949, Reward: [-752.623 -752.623 -752.623] [0.0000], Avg: [-1046.519 -1046.519 -1046.519] (1.000)
Step: 9999, Reward: [-568.962 -568.962 -568.962] [0.0000], Avg: [-1044.131 -1044.131 -1044.131] (1.000)
Step: 10049, Reward: [-738.446 -738.446 -738.446] [0.0000], Avg: [-1042.61 -1042.61 -1042.61] (1.000)
Step: 10099, Reward: [-780.964 -780.964 -780.964] [0.0000], Avg: [-1041.315 -1041.315 -1041.315] (1.000)
Step: 10149, Reward: [-681.13 -681.13 -681.13] [0.0000], Avg: [-1039.541 -1039.541 -1039.541] (1.000)
Step: 10199, Reward: [-609.888 -609.888 -609.888] [0.0000], Avg: [-1037.435 -1037.435 -1037.435] (1.000)
Step: 10249, Reward: [-1048.474 -1048.474 -1048.474] [0.0000], Avg: [-1037.488 -1037.488 -1037.488] (1.000)
Step: 10299, Reward: [-942.717 -942.717 -942.717] [0.0000], Avg: [-1037.028 -1037.028 -1037.028] (1.000)
Step: 10349, Reward: [-2145.848 -2145.848 -2145.848] [0.0000], Avg: [-1042.385 -1042.385 -1042.385] (1.000)
Step: 10399, Reward: [-1734.43 -1734.43 -1734.43] [0.0000], Avg: [-1045.712 -1045.712 -1045.712] (1.000)
Step: 10449, Reward: [-2153.123 -2153.123 -2153.123] [0.0000], Avg: [-1051.011 -1051.011 -1051.011] (1.000)
Step: 10499, Reward: [-1229.618 -1229.618 -1229.618] [0.0000], Avg: [-1051.861 -1051.861 -1051.861] (1.000)
Step: 10549, Reward: [-557.991 -557.991 -557.991] [0.0000], Avg: [-1049.521 -1049.521 -1049.521] (1.000)
Step: 10599, Reward: [-2157.299 -2157.299 -2157.299] [0.0000], Avg: [-1054.746 -1054.746 -1054.746] (1.000)
Step: 10649, Reward: [-1084.484 -1084.484 -1084.484] [0.0000], Avg: [-1054.886 -1054.886 -1054.886] (1.000)
Step: 10699, Reward: [-1517.422 -1517.422 -1517.422] [0.0000], Avg: [-1057.047 -1057.047 -1057.047] (1.000)
Step: 10749, Reward: [-574.455 -574.455 -574.455] [0.0000], Avg: [-1054.802 -1054.802 -1054.802] (1.000)
Step: 10799, Reward: [-2024.403 -2024.403 -2024.403] [0.0000], Avg: [-1059.291 -1059.291 -1059.291] (1.000)
Step: 10849, Reward: [-1667.31 -1667.31 -1667.31] [0.0000], Avg: [-1062.093 -1062.093 -1062.093] (1.000)
Step: 10899, Reward: [-1674.407 -1674.407 -1674.407] [0.0000], Avg: [-1064.902 -1064.902 -1064.902] (1.000)
Step: 10949, Reward: [-1938.017 -1938.017 -1938.017] [0.0000], Avg: [-1068.889 -1068.889 -1068.889] (1.000)
Step: 10999, Reward: [-1465.416 -1465.416 -1465.416] [0.0000], Avg: [-1070.691 -1070.691 -1070.691] (1.000)
Step: 11049, Reward: [-1648.953 -1648.953 -1648.953] [0.0000], Avg: [-1073.308 -1073.308 -1073.308] (1.000)
Step: 11099, Reward: [-1322.05 -1322.05 -1322.05] [0.0000], Avg: [-1074.428 -1074.428 -1074.428] (1.000)
Step: 11149, Reward: [-1586.889 -1586.889 -1586.889] [0.0000], Avg: [-1076.726 -1076.726 -1076.726] (1.000)
Step: 11199, Reward: [-1618.856 -1618.856 -1618.856] [0.0000], Avg: [-1079.147 -1079.147 -1079.147] (1.000)
Step: 11249, Reward: [-1998.423 -1998.423 -1998.423] [0.0000], Avg: [-1083.232 -1083.232 -1083.232] (1.000)
Step: 11299, Reward: [-1640.913 -1640.913 -1640.913] [0.0000], Avg: [-1085.7 -1085.7 -1085.7] (1.000)
Step: 11349, Reward: [-1956.716 -1956.716 -1956.716] [0.0000], Avg: [-1089.537 -1089.537 -1089.537] (1.000)
Step: 11399, Reward: [-1972.548 -1972.548 -1972.548] [0.0000], Avg: [-1093.41 -1093.41 -1093.41] (1.000)
Step: 11449, Reward: [-1733.26 -1733.26 -1733.26] [0.0000], Avg: [-1096.204 -1096.204 -1096.204] (1.000)
Step: 11499, Reward: [-1685.65 -1685.65 -1685.65] [0.0000], Avg: [-1098.767 -1098.767 -1098.767] (1.000)
Step: 11549, Reward: [-2133.132 -2133.132 -2133.132] [0.0000], Avg: [-1103.244 -1103.244 -1103.244] (1.000)
Step: 11599, Reward: [-1937.789 -1937.789 -1937.789] [0.0000], Avg: [-1106.842 -1106.842 -1106.842] (1.000)
Step: 11649, Reward: [-1482.154 -1482.154 -1482.154] [0.0000], Avg: [-1108.452 -1108.452 -1108.452] (1.000)
Step: 11699, Reward: [-1794.499 -1794.499 -1794.499] [0.0000], Avg: [-1111.384 -1111.384 -1111.384] (1.000)
Step: 11749, Reward: [-1639.126 -1639.126 -1639.126] [0.0000], Avg: [-1113.63 -1113.63 -1113.63] (1.000)
Step: 11799, Reward: [-1723.434 -1723.434 -1723.434] [0.0000], Avg: [-1116.214 -1116.214 -1116.214] (1.000)
Step: 11849, Reward: [-1950.806 -1950.806 -1950.806] [0.0000], Avg: [-1119.735 -1119.735 -1119.735] (1.000)
Step: 11899, Reward: [-1377.341 -1377.341 -1377.341] [0.0000], Avg: [-1120.818 -1120.818 -1120.818] (1.000)
Step: 11949, Reward: [-1213.659 -1213.659 -1213.659] [0.0000], Avg: [-1121.206 -1121.206 -1121.206] (1.000)
Step: 11999, Reward: [-1440.333 -1440.333 -1440.333] [0.0000], Avg: [-1122.536 -1122.536 -1122.536] (1.000)
Step: 12049, Reward: [-1621.273 -1621.273 -1621.273] [0.0000], Avg: [-1124.605 -1124.605 -1124.605] (1.000)
Step: 12099, Reward: [-1930.731 -1930.731 -1930.731] [0.0000], Avg: [-1127.936 -1127.936 -1127.936] (1.000)
Step: 12149, Reward: [-1633.573 -1633.573 -1633.573] [0.0000], Avg: [-1130.017 -1130.017 -1130.017] (1.000)
Step: 12199, Reward: [-1789.837 -1789.837 -1789.837] [0.0000], Avg: [-1132.721 -1132.721 -1132.721] (1.000)
Step: 12249, Reward: [-1571.547 -1571.547 -1571.547] [0.0000], Avg: [-1134.513 -1134.513 -1134.513] (1.000)
Step: 12299, Reward: [-1545.196 -1545.196 -1545.196] [0.0000], Avg: [-1136.182 -1136.182 -1136.182] (1.000)
Step: 12349, Reward: [-1986.839 -1986.839 -1986.839] [0.0000], Avg: [-1139.626 -1139.626 -1139.626] (1.000)
Step: 12399, Reward: [-1895.582 -1895.582 -1895.582] [0.0000], Avg: [-1142.674 -1142.674 -1142.674] (1.000)
Step: 12449, Reward: [-2049.176 -2049.176 -2049.176] [0.0000], Avg: [-1146.315 -1146.315 -1146.315] (1.000)
Step: 12499, Reward: [-1460.405 -1460.405 -1460.405] [0.0000], Avg: [-1147.571 -1147.571 -1147.571] (1.000)
Step: 12549, Reward: [-1953.342 -1953.342 -1953.342] [0.0000], Avg: [-1150.781 -1150.781 -1150.781] (1.000)
Step: 12599, Reward: [-1919.402 -1919.402 -1919.402] [0.0000], Avg: [-1153.831 -1153.831 -1153.831] (1.000)
Step: 12649, Reward: [-2103.548 -2103.548 -2103.548] [0.0000], Avg: [-1157.585 -1157.585 -1157.585] (1.000)
Step: 12699, Reward: [-1872.627 -1872.627 -1872.627] [0.0000], Avg: [-1160.4 -1160.4 -1160.4] (1.000)
Step: 12749, Reward: [-1842.411 -1842.411 -1842.411] [0.0000], Avg: [-1163.075 -1163.075 -1163.075] (1.000)
Step: 12799, Reward: [-2145.434 -2145.434 -2145.434] [0.0000], Avg: [-1166.912 -1166.912 -1166.912] (1.000)
Step: 12849, Reward: [-1930.209 -1930.209 -1930.209] [0.0000], Avg: [-1169.882 -1169.882 -1169.882] (1.000)
Step: 12899, Reward: [-1946.648 -1946.648 -1946.648] [0.0000], Avg: [-1172.893 -1172.893 -1172.893] (1.000)
Step: 12949, Reward: [-1888.683 -1888.683 -1888.683] [0.0000], Avg: [-1175.657 -1175.657 -1175.657] (1.000)
Step: 12999, Reward: [-1700.746 -1700.746 -1700.746] [0.0000], Avg: [-1177.676 -1177.676 -1177.676] (1.000)
Step: 13049, Reward: [-1869.481 -1869.481 -1869.481] [0.0000], Avg: [-1180.327 -1180.327 -1180.327] (1.000)
Step: 13099, Reward: [-1645.667 -1645.667 -1645.667] [0.0000], Avg: [-1182.103 -1182.103 -1182.103] (1.000)
Step: 13149, Reward: [-1884.624 -1884.624 -1884.624] [0.0000], Avg: [-1184.774 -1184.774 -1184.774] (1.000)
Step: 13199, Reward: [-1881.574 -1881.574 -1881.574] [0.0000], Avg: [-1187.413 -1187.413 -1187.413] (1.000)
Step: 13249, Reward: [-1904.067 -1904.067 -1904.067] [0.0000], Avg: [-1190.118 -1190.118 -1190.118] (1.000)
Step: 13299, Reward: [-2034.348 -2034.348 -2034.348] [0.0000], Avg: [-1193.292 -1193.292 -1193.292] (1.000)
Step: 13349, Reward: [-2143.742 -2143.742 -2143.742] [0.0000], Avg: [-1196.851 -1196.851 -1196.851] (1.000)
Step: 13399, Reward: [-1919.195 -1919.195 -1919.195] [0.0000], Avg: [-1199.547 -1199.547 -1199.547] (1.000)
Step: 13449, Reward: [-2148.847 -2148.847 -2148.847] [0.0000], Avg: [-1203.076 -1203.076 -1203.076] (1.000)
Step: 13499, Reward: [-1946.26 -1946.26 -1946.26] [0.0000], Avg: [-1205.828 -1205.828 -1205.828] (1.000)
Step: 13549, Reward: [-1811.138 -1811.138 -1811.138] [0.0000], Avg: [-1208.062 -1208.062 -1208.062] (1.000)
Step: 13599, Reward: [-2290.143 -2290.143 -2290.143] [0.0000], Avg: [-1212.04 -1212.04 -1212.04] (1.000)
Step: 13649, Reward: [-2012.114 -2012.114 -2012.114] [0.0000], Avg: [-1214.971 -1214.971 -1214.971] (1.000)
Step: 13699, Reward: [-1711.489 -1711.489 -1711.489] [0.0000], Avg: [-1216.783 -1216.783 -1216.783] (1.000)
Step: 13749, Reward: [-1864.754 -1864.754 -1864.754] [0.0000], Avg: [-1219.139 -1219.139 -1219.139] (1.000)
Step: 13799, Reward: [-2209.965 -2209.965 -2209.965] [0.0000], Avg: [-1222.729 -1222.729 -1222.729] (1.000)
Step: 13849, Reward: [-1825.866 -1825.866 -1825.866] [0.0000], Avg: [-1224.906 -1224.906 -1224.906] (1.000)
Step: 13899, Reward: [-1609.872 -1609.872 -1609.872] [0.0000], Avg: [-1226.291 -1226.291 -1226.291] (1.000)
Step: 13949, Reward: [-1945.119 -1945.119 -1945.119] [0.0000], Avg: [-1228.868 -1228.868 -1228.868] (1.000)
Step: 13999, Reward: [-1685.045 -1685.045 -1685.045] [0.0000], Avg: [-1230.497 -1230.497 -1230.497] (1.000)
Step: 14049, Reward: [-1635.102 -1635.102 -1635.102] [0.0000], Avg: [-1231.937 -1231.937 -1231.937] (1.000)
Step: 14099, Reward: [-1941.933 -1941.933 -1941.933] [0.0000], Avg: [-1234.454 -1234.454 -1234.454] (1.000)
Step: 14149, Reward: [-1542.239 -1542.239 -1542.239] [0.0000], Avg: [-1235.542 -1235.542 -1235.542] (1.000)
Step: 14199, Reward: [-1070.638 -1070.638 -1070.638] [0.0000], Avg: [-1234.961 -1234.961 -1234.961] (1.000)
Step: 14249, Reward: [-1614.899 -1614.899 -1614.899] [0.0000], Avg: [-1236.295 -1236.295 -1236.295] (1.000)
Step: 14299, Reward: [-1803.908 -1803.908 -1803.908] [0.0000], Avg: [-1238.279 -1238.279 -1238.279] (1.000)
Step: 14349, Reward: [-1530.826 -1530.826 -1530.826] [0.0000], Avg: [-1239.299 -1239.299 -1239.299] (1.000)
Step: 14399, Reward: [-1534.442 -1534.442 -1534.442] [0.0000], Avg: [-1240.323 -1240.323 -1240.323] (1.000)
Step: 14449, Reward: [-996.857 -996.857 -996.857] [0.0000], Avg: [-1239.481 -1239.481 -1239.481] (1.000)
Step: 14499, Reward: [-1102.309 -1102.309 -1102.309] [0.0000], Avg: [-1239.008 -1239.008 -1239.008] (1.000)
Step: 14549, Reward: [-906.572 -906.572 -906.572] [0.0000], Avg: [-1237.865 -1237.865 -1237.865] (1.000)
Step: 14599, Reward: [-1494.547 -1494.547 -1494.547] [0.0000], Avg: [-1238.745 -1238.745 -1238.745] (1.000)
Step: 14649, Reward: [-829.374 -829.374 -829.374] [0.0000], Avg: [-1237.347 -1237.347 -1237.347] (1.000)
Step: 14699, Reward: [-785.053 -785.053 -785.053] [0.0000], Avg: [-1235.809 -1235.809 -1235.809] (1.000)
Step: 14749, Reward: [-1152.675 -1152.675 -1152.675] [0.0000], Avg: [-1235.527 -1235.527 -1235.527] (1.000)
Step: 14799, Reward: [-1283.853 -1283.853 -1283.853] [0.0000], Avg: [-1235.69 -1235.69 -1235.69] (1.000)
Step: 14849, Reward: [-658.128 -658.128 -658.128] [0.0000], Avg: [-1233.746 -1233.746 -1233.746] (1.000)
Step: 14899, Reward: [-1218.693 -1218.693 -1218.693] [0.0000], Avg: [-1233.695 -1233.695 -1233.695] (1.000)
Step: 14949, Reward: [-467.807 -467.807 -467.807] [0.0000], Avg: [-1231.134 -1231.134 -1231.134] (1.000)
Step: 14999, Reward: [-438.557 -438.557 -438.557] [0.0000], Avg: [-1228.492 -1228.492 -1228.492] (1.000)
Step: 15049, Reward: [-996.394 -996.394 -996.394] [0.0000], Avg: [-1227.721 -1227.721 -1227.721] (1.000)
Step: 15099, Reward: [-678.69 -678.69 -678.69] [0.0000], Avg: [-1225.903 -1225.903 -1225.903] (1.000)
Step: 15149, Reward: [-540.985 -540.985 -540.985] [0.0000], Avg: [-1223.642 -1223.642 -1223.642] (1.000)
Step: 15199, Reward: [-476.19 -476.19 -476.19] [0.0000], Avg: [-1221.184 -1221.184 -1221.184] (1.000)
Step: 15249, Reward: [-561.968 -561.968 -561.968] [0.0000], Avg: [-1219.022 -1219.022 -1219.022] (1.000)
Step: 15299, Reward: [-886.258 -886.258 -886.258] [0.0000], Avg: [-1217.935 -1217.935 -1217.935] (1.000)
Step: 15349, Reward: [-804.714 -804.714 -804.714] [0.0000], Avg: [-1216.589 -1216.589 -1216.589] (1.000)
Step: 15399, Reward: [-667.592 -667.592 -667.592] [0.0000], Avg: [-1214.806 -1214.806 -1214.806] (1.000)
Step: 15449, Reward: [-645.345 -645.345 -645.345] [0.0000], Avg: [-1212.963 -1212.963 -1212.963] (1.000)
Step: 15499, Reward: [-680.106 -680.106 -680.106] [0.0000], Avg: [-1211.244 -1211.244 -1211.244] (1.000)
Step: 15549, Reward: [-685.689 -685.689 -685.689] [0.0000], Avg: [-1209.555 -1209.555 -1209.555] (1.000)
Step: 15599, Reward: [-405.962 -405.962 -405.962] [0.0000], Avg: [-1206.979 -1206.979 -1206.979] (1.000)
Step: 15649, Reward: [-644.793 -644.793 -644.793] [0.0000], Avg: [-1205.183 -1205.183 -1205.183] (1.000)
Step: 15699, Reward: [-744.402 -744.402 -744.402] [0.0000], Avg: [-1203.715 -1203.715 -1203.715] (1.000)
Step: 15749, Reward: [-831.992 -831.992 -831.992] [0.0000], Avg: [-1202.535 -1202.535 -1202.535] (1.000)
Step: 15799, Reward: [-628.466 -628.466 -628.466] [0.0000], Avg: [-1200.719 -1200.719 -1200.719] (1.000)
Step: 15849, Reward: [-522.085 -522.085 -522.085] [0.0000], Avg: [-1198.578 -1198.578 -1198.578] (1.000)
Step: 15899, Reward: [-580.235 -580.235 -580.235] [0.0000], Avg: [-1196.633 -1196.633 -1196.633] (1.000)
Step: 15949, Reward: [-716.802 -716.802 -716.802] [0.0000], Avg: [-1195.129 -1195.129 -1195.129] (1.000)
Step: 15999, Reward: [-583.969 -583.969 -583.969] [0.0000], Avg: [-1193.219 -1193.219 -1193.219] (1.000)
Step: 16049, Reward: [-611.222 -611.222 -611.222] [0.0000], Avg: [-1191.406 -1191.406 -1191.406] (1.000)
Step: 16099, Reward: [-478.118 -478.118 -478.118] [0.0000], Avg: [-1189.191 -1189.191 -1189.191] (1.000)
Step: 16149, Reward: [-608.622 -608.622 -608.622] [0.0000], Avg: [-1187.394 -1187.394 -1187.394] (1.000)
Step: 16199, Reward: [-637.299 -637.299 -637.299] [0.0000], Avg: [-1185.696 -1185.696 -1185.696] (1.000)
Step: 16249, Reward: [-571.256 -571.256 -571.256] [0.0000], Avg: [-1183.805 -1183.805 -1183.805] (1.000)
Step: 16299, Reward: [-751.32 -751.32 -751.32] [0.0000], Avg: [-1182.479 -1182.479 -1182.479] (1.000)
Step: 16349, Reward: [-605.531 -605.531 -605.531] [0.0000], Avg: [-1180.714 -1180.714 -1180.714] (1.000)
Step: 16399, Reward: [-542.96 -542.96 -542.96] [0.0000], Avg: [-1178.77 -1178.77 -1178.77] (1.000)
Step: 16449, Reward: [-536.144 -536.144 -536.144] [0.0000], Avg: [-1176.817 -1176.817 -1176.817] (1.000)
Step: 16499, Reward: [-627.57 -627.57 -627.57] [0.0000], Avg: [-1175.152 -1175.152 -1175.152] (1.000)
Step: 16549, Reward: [-695.893 -695.893 -695.893] [0.0000], Avg: [-1173.704 -1173.704 -1173.704] (1.000)
Step: 16599, Reward: [-467.623 -467.623 -467.623] [0.0000], Avg: [-1171.578 -1171.578 -1171.578] (1.000)
Step: 16649, Reward: [-430.591 -430.591 -430.591] [0.0000], Avg: [-1169.352 -1169.352 -1169.352] (1.000)
Step: 16699, Reward: [-607.419 -607.419 -607.419] [0.0000], Avg: [-1167.67 -1167.67 -1167.67] (1.000)
Step: 16749, Reward: [-380.209 -380.209 -380.209] [0.0000], Avg: [-1165.319 -1165.319 -1165.319] (1.000)
Step: 16799, Reward: [-630.179 -630.179 -630.179] [0.0000], Avg: [-1163.727 -1163.727 -1163.727] (1.000)
Step: 16849, Reward: [-540.403 -540.403 -540.403] [0.0000], Avg: [-1161.877 -1161.877 -1161.877] (1.000)
Step: 16899, Reward: [-831.863 -831.863 -831.863] [0.0000], Avg: [-1160.901 -1160.901 -1160.901] (1.000)
Step: 16949, Reward: [-391.061 -391.061 -391.061] [0.0000], Avg: [-1158.63 -1158.63 -1158.63] (1.000)
Step: 16999, Reward: [-534.766 -534.766 -534.766] [0.0000], Avg: [-1156.795 -1156.795 -1156.795] (1.000)
Step: 17049, Reward: [-507.46 -507.46 -507.46] [0.0000], Avg: [-1154.891 -1154.891 -1154.891] (1.000)
Step: 17099, Reward: [-870.88 -870.88 -870.88] [0.0000], Avg: [-1154.06 -1154.06 -1154.06] (1.000)
Step: 17149, Reward: [-469.013 -469.013 -469.013] [0.0000], Avg: [-1152.063 -1152.063 -1152.063] (1.000)
Step: 17199, Reward: [-458.68 -458.68 -458.68] [0.0000], Avg: [-1150.047 -1150.047 -1150.047] (1.000)
Step: 17249, Reward: [-501.115 -501.115 -501.115] [0.0000], Avg: [-1148.166 -1148.166 -1148.166] (1.000)
Step: 17299, Reward: [-660.546 -660.546 -660.546] [0.0000], Avg: [-1146.757 -1146.757 -1146.757] (1.000)
Step: 17349, Reward: [-540.037 -540.037 -540.037] [0.0000], Avg: [-1145.009 -1145.009 -1145.009] (1.000)
Step: 17399, Reward: [-442.047 -442.047 -442.047] [0.0000], Avg: [-1142.989 -1142.989 -1142.989] (1.000)
Step: 17449, Reward: [-505.006 -505.006 -505.006] [0.0000], Avg: [-1141.16 -1141.16 -1141.16] (1.000)
Step: 17499, Reward: [-496.991 -496.991 -496.991] [0.0000], Avg: [-1139.32 -1139.32 -1139.32] (1.000)
Step: 17549, Reward: [-398.752 -398.752 -398.752] [0.0000], Avg: [-1137.21 -1137.21 -1137.21] (1.000)
Step: 17599, Reward: [-612.425 -612.425 -612.425] [0.0000], Avg: [-1135.719 -1135.719 -1135.719] (1.000)
Step: 17649, Reward: [-497.163 -497.163 -497.163] [0.0000], Avg: [-1133.91 -1133.91 -1133.91] (1.000)
Step: 17699, Reward: [-699.64 -699.64 -699.64] [0.0000], Avg: [-1132.684 -1132.684 -1132.684] (1.000)
Step: 17749, Reward: [-756.243 -756.243 -756.243] [0.0000], Avg: [-1131.623 -1131.623 -1131.623] (1.000)
Step: 17799, Reward: [-794.647 -794.647 -794.647] [0.0000], Avg: [-1130.677 -1130.677 -1130.677] (1.000)
Step: 17849, Reward: [-904.127 -904.127 -904.127] [0.0000], Avg: [-1130.042 -1130.042 -1130.042] (1.000)
Step: 17899, Reward: [-840.561 -840.561 -840.561] [0.0000], Avg: [-1129.233 -1129.233 -1129.233] (1.000)
Step: 17949, Reward: [-592.281 -592.281 -592.281] [0.0000], Avg: [-1127.738 -1127.738 -1127.738] (1.000)
Step: 17999, Reward: [-576.384 -576.384 -576.384] [0.0000], Avg: [-1126.206 -1126.206 -1126.206] (1.000)
Step: 18049, Reward: [-532.821 -532.821 -532.821] [0.0000], Avg: [-1124.562 -1124.562 -1124.562] (1.000)
Step: 18099, Reward: [-463.909 -463.909 -463.909] [0.0000], Avg: [-1122.737 -1122.737 -1122.737] (1.000)
Step: 18149, Reward: [-611.173 -611.173 -611.173] [0.0000], Avg: [-1121.328 -1121.328 -1121.328] (1.000)
Step: 18199, Reward: [-560.045 -560.045 -560.045] [0.0000], Avg: [-1119.786 -1119.786 -1119.786] (1.000)
Step: 18249, Reward: [-610.169 -610.169 -610.169] [0.0000], Avg: [-1118.39 -1118.39 -1118.39] (1.000)
Step: 18299, Reward: [-1558.18 -1558.18 -1558.18] [0.0000], Avg: [-1119.592 -1119.592 -1119.592] (1.000)
Step: 18349, Reward: [-475.961 -475.961 -475.961] [0.0000], Avg: [-1117.838 -1117.838 -1117.838] (1.000)
Step: 18399, Reward: [-616.217 -616.217 -616.217] [0.0000], Avg: [-1116.475 -1116.475 -1116.475] (1.000)
Step: 18449, Reward: [-1854.892 -1854.892 -1854.892] [0.0000], Avg: [-1118.476 -1118.476 -1118.476] (1.000)
Step: 18499, Reward: [-667.574 -667.574 -667.574] [0.0000], Avg: [-1117.257 -1117.257 -1117.257] (1.000)
Step: 18549, Reward: [-752.777 -752.777 -752.777] [0.0000], Avg: [-1116.275 -1116.275 -1116.275] (1.000)
Step: 18599, Reward: [-498.488 -498.488 -498.488] [0.0000], Avg: [-1114.614 -1114.614 -1114.614] (1.000)
Step: 18649, Reward: [-1855.836 -1855.836 -1855.836] [0.0000], Avg: [-1116.601 -1116.601 -1116.601] (1.000)
Step: 18699, Reward: [-627.493 -627.493 -627.493] [0.0000], Avg: [-1115.293 -1115.293 -1115.293] (1.000)
Step: 18749, Reward: [-1933.386 -1933.386 -1933.386] [0.0000], Avg: [-1117.475 -1117.475 -1117.475] (1.000)
Step: 18799, Reward: [-1680.16 -1680.16 -1680.16] [0.0000], Avg: [-1118.972 -1118.972 -1118.972] (1.000)
Step: 18849, Reward: [-2058.415 -2058.415 -2058.415] [0.0000], Avg: [-1121.463 -1121.463 -1121.463] (1.000)
Step: 18899, Reward: [-1630.473 -1630.473 -1630.473] [0.0000], Avg: [-1122.81 -1122.81 -1122.81] (1.000)
Step: 18949, Reward: [-1827.63 -1827.63 -1827.63] [0.0000], Avg: [-1124.67 -1124.67 -1124.67] (1.000)
Step: 18999, Reward: [-2035.57 -2035.57 -2035.57] [0.0000], Avg: [-1127.067 -1127.067 -1127.067] (1.000)
Step: 19049, Reward: [-517.359 -517.359 -517.359] [0.0000], Avg: [-1125.467 -1125.467 -1125.467] (1.000)
Step: 19099, Reward: [-949.31 -949.31 -949.31] [0.0000], Avg: [-1125.005 -1125.005 -1125.005] (1.000)
Step: 19149, Reward: [-456.442 -456.442 -456.442] [0.0000], Avg: [-1123.26 -1123.26 -1123.26] (1.000)
Step: 19199, Reward: [-765.367 -765.367 -765.367] [0.0000], Avg: [-1122.328 -1122.328 -1122.328] (1.000)
Step: 19249, Reward: [-503.556 -503.556 -503.556] [0.0000], Avg: [-1120.721 -1120.721 -1120.721] (1.000)
Step: 19299, Reward: [-742.215 -742.215 -742.215] [0.0000], Avg: [-1119.74 -1119.74 -1119.74] (1.000)
Step: 19349, Reward: [-885.933 -885.933 -885.933] [0.0000], Avg: [-1119.136 -1119.136 -1119.136] (1.000)
Step: 19399, Reward: [-653.787 -653.787 -653.787] [0.0000], Avg: [-1117.936 -1117.936 -1117.936] (1.000)
Step: 19449, Reward: [-1364.062 -1364.062 -1364.062] [0.0000], Avg: [-1118.569 -1118.569 -1118.569] (1.000)
Step: 19499, Reward: [-582.413 -582.413 -582.413] [0.0000], Avg: [-1117.194 -1117.194 -1117.194] (1.000)
Step: 19549, Reward: [-1802.511 -1802.511 -1802.511] [0.0000], Avg: [-1118.947 -1118.947 -1118.947] (1.000)
Step: 19599, Reward: [-780.175 -780.175 -780.175] [0.0000], Avg: [-1118.083 -1118.083 -1118.083] (1.000)
Step: 19649, Reward: [-1386.541 -1386.541 -1386.541] [0.0000], Avg: [-1118.766 -1118.766 -1118.766] (1.000)
Step: 19699, Reward: [-1890.861 -1890.861 -1890.861] [0.0000], Avg: [-1120.726 -1120.726 -1120.726] (1.000)
Step: 19749, Reward: [-2172.547 -2172.547 -2172.547] [0.0000], Avg: [-1123.389 -1123.389 -1123.389] (1.000)
Step: 19799, Reward: [-1985.249 -1985.249 -1985.249] [0.0000], Avg: [-1125.565 -1125.565 -1125.565] (1.000)
Step: 19849, Reward: [-2048.883 -2048.883 -2048.883] [0.0000], Avg: [-1127.891 -1127.891 -1127.891] (1.000)
Step: 19899, Reward: [-2210.312 -2210.312 -2210.312] [0.0000], Avg: [-1130.61 -1130.61 -1130.61] (1.000)
Step: 19949, Reward: [-1832.407 -1832.407 -1832.407] [0.0000], Avg: [-1132.369 -1132.369 -1132.369] (1.000)
Step: 19999, Reward: [-2120.87 -2120.87 -2120.87] [0.0000], Avg: [-1134.84 -1134.84 -1134.84] (1.000)
Step: 20049, Reward: [-2168.412 -2168.412 -2168.412] [0.0000], Avg: [-1137.418 -1137.418 -1137.418] (1.000)
Step: 20099, Reward: [-1991.625 -1991.625 -1991.625] [0.0000], Avg: [-1139.543 -1139.543 -1139.543] (1.000)
Step: 20149, Reward: [-2123.868 -2123.868 -2123.868] [0.0000], Avg: [-1141.985 -1141.985 -1141.985] (1.000)
Step: 20199, Reward: [-1887.928 -1887.928 -1887.928] [0.0000], Avg: [-1143.832 -1143.832 -1143.832] (1.000)
Step: 20249, Reward: [-1879.056 -1879.056 -1879.056] [0.0000], Avg: [-1145.647 -1145.647 -1145.647] (1.000)
Step: 20299, Reward: [-1943.181 -1943.181 -1943.181] [0.0000], Avg: [-1147.611 -1147.611 -1147.611] (1.000)
Step: 20349, Reward: [-1849.274 -1849.274 -1849.274] [0.0000], Avg: [-1149.335 -1149.335 -1149.335] (1.000)
Step: 20399, Reward: [-1974.757 -1974.757 -1974.757] [0.0000], Avg: [-1151.359 -1151.359 -1151.359] (1.000)
Step: 20449, Reward: [-1973.204 -1973.204 -1973.204] [0.0000], Avg: [-1153.368 -1153.368 -1153.368] (1.000)
Step: 20499, Reward: [-1719.682 -1719.682 -1719.682] [0.0000], Avg: [-1154.749 -1154.749 -1154.749] (1.000)
Step: 20549, Reward: [-2040.907 -2040.907 -2040.907] [0.0000], Avg: [-1156.905 -1156.905 -1156.905] (1.000)
Step: 20599, Reward: [-1968.105 -1968.105 -1968.105] [0.0000], Avg: [-1158.874 -1158.874 -1158.874] (1.000)
Step: 20649, Reward: [-1771.686 -1771.686 -1771.686] [0.0000], Avg: [-1160.358 -1160.358 -1160.358] (1.000)
Step: 20699, Reward: [-1893.647 -1893.647 -1893.647] [0.0000], Avg: [-1162.129 -1162.129 -1162.129] (1.000)
Step: 20749, Reward: [-1933.648 -1933.648 -1933.648] [0.0000], Avg: [-1163.988 -1163.988 -1163.988] (1.000)
Step: 20799, Reward: [-2287.484 -2287.484 -2287.484] [0.0000], Avg: [-1166.689 -1166.689 -1166.689] (1.000)
Step: 20849, Reward: [-2117.896 -2117.896 -2117.896] [0.0000], Avg: [-1168.97 -1168.97 -1168.97] (1.000)
Step: 20899, Reward: [-1847.73 -1847.73 -1847.73] [0.0000], Avg: [-1170.594 -1170.594 -1170.594] (1.000)
Step: 20949, Reward: [-1895.803 -1895.803 -1895.803] [0.0000], Avg: [-1172.325 -1172.325 -1172.325] (1.000)
Step: 20999, Reward: [-1961.322 -1961.322 -1961.322] [0.0000], Avg: [-1174.203 -1174.203 -1174.203] (1.000)
Step: 21049, Reward: [-2029.059 -2029.059 -2029.059] [0.0000], Avg: [-1176.234 -1176.234 -1176.234] (1.000)
Step: 21099, Reward: [-1818.839 -1818.839 -1818.839] [0.0000], Avg: [-1177.757 -1177.757 -1177.757] (1.000)
Step: 21149, Reward: [-1992.138 -1992.138 -1992.138] [0.0000], Avg: [-1179.682 -1179.682 -1179.682] (1.000)
Step: 21199, Reward: [-1874.731 -1874.731 -1874.731] [0.0000], Avg: [-1181.321 -1181.321 -1181.321] (1.000)
Step: 21249, Reward: [-1893.833 -1893.833 -1893.833] [0.0000], Avg: [-1182.998 -1182.998 -1182.998] (1.000)
Step: 21299, Reward: [-1974.085 -1974.085 -1974.085] [0.0000], Avg: [-1184.855 -1184.855 -1184.855] (1.000)
Step: 21349, Reward: [-2000.981 -2000.981 -2000.981] [0.0000], Avg: [-1186.766 -1186.766 -1186.766] (1.000)
Step: 21399, Reward: [-2096.392 -2096.392 -2096.392] [0.0000], Avg: [-1188.891 -1188.891 -1188.891] (1.000)
Step: 21449, Reward: [-2118.413 -2118.413 -2118.413] [0.0000], Avg: [-1191.058 -1191.058 -1191.058] (1.000)
Step: 21499, Reward: [-1987.679 -1987.679 -1987.679] [0.0000], Avg: [-1192.911 -1192.911 -1192.911] (1.000)
Step: 21549, Reward: [-1801.879 -1801.879 -1801.879] [0.0000], Avg: [-1194.324 -1194.324 -1194.324] (1.000)
Step: 21599, Reward: [-2308.861 -2308.861 -2308.861] [0.0000], Avg: [-1196.903 -1196.903 -1196.903] (1.000)
Step: 21649, Reward: [-1900.999 -1900.999 -1900.999] [0.0000], Avg: [-1198.53 -1198.53 -1198.53] (1.000)
Step: 21699, Reward: [-1712.413 -1712.413 -1712.413] [0.0000], Avg: [-1199.714 -1199.714 -1199.714] (1.000)
Step: 21749, Reward: [-1438.985 -1438.985 -1438.985] [0.0000], Avg: [-1200.264 -1200.264 -1200.264] (1.000)
Step: 21799, Reward: [-1529.609 -1529.609 -1529.609] [0.0000], Avg: [-1201.019 -1201.019 -1201.019] (1.000)
Step: 21849, Reward: [-1742.458 -1742.458 -1742.458] [0.0000], Avg: [-1202.258 -1202.258 -1202.258] (1.000)
Step: 21899, Reward: [-1672.251 -1672.251 -1672.251] [0.0000], Avg: [-1203.331 -1203.331 -1203.331] (1.000)
Step: 21949, Reward: [-1771.888 -1771.888 -1771.888] [0.0000], Avg: [-1204.626 -1204.626 -1204.626] (1.000)
Step: 21999, Reward: [-1952.523 -1952.523 -1952.523] [0.0000], Avg: [-1206.326 -1206.326 -1206.326] (1.000)
Step: 22049, Reward: [-1601.722 -1601.722 -1601.722] [0.0000], Avg: [-1207.223 -1207.223 -1207.223] (1.000)
Step: 22099, Reward: [-1746.542 -1746.542 -1746.542] [0.0000], Avg: [-1208.443 -1208.443 -1208.443] (1.000)
Step: 22149, Reward: [-1752.849 -1752.849 -1752.849] [0.0000], Avg: [-1209.672 -1209.672 -1209.672] (1.000)
Step: 22199, Reward: [-2092.01 -2092.01 -2092.01] [0.0000], Avg: [-1211.659 -1211.659 -1211.659] (1.000)
Step: 22249, Reward: [-1818.363 -1818.363 -1818.363] [0.0000], Avg: [-1213.022 -1213.022 -1213.022] (1.000)
Step: 22299, Reward: [-1988.234 -1988.234 -1988.234] [0.0000], Avg: [-1214.76 -1214.76 -1214.76] (1.000)
Step: 22349, Reward: [-1455.649 -1455.649 -1455.649] [0.0000], Avg: [-1215.299 -1215.299 -1215.299] (1.000)
Step: 22399, Reward: [-1653.602 -1653.602 -1653.602] [0.0000], Avg: [-1216.278 -1216.278 -1216.278] (1.000)
Step: 22449, Reward: [-1439.26 -1439.26 -1439.26] [0.0000], Avg: [-1216.774 -1216.774 -1216.774] (1.000)
Step: 22499, Reward: [-1497.379 -1497.379 -1497.379] [0.0000], Avg: [-1217.398 -1217.398 -1217.398] (1.000)
Step: 22549, Reward: [-1546.292 -1546.292 -1546.292] [0.0000], Avg: [-1218.127 -1218.127 -1218.127] (1.000)
Step: 22599, Reward: [-1719.903 -1719.903 -1719.903] [0.0000], Avg: [-1219.237 -1219.237 -1219.237] (1.000)
Step: 22649, Reward: [-1692.798 -1692.798 -1692.798] [0.0000], Avg: [-1220.283 -1220.283 -1220.283] (1.000)
Step: 22699, Reward: [-2063.624 -2063.624 -2063.624] [0.0000], Avg: [-1222.14 -1222.14 -1222.14] (1.000)
Step: 22749, Reward: [-1637.87 -1637.87 -1637.87] [0.0000], Avg: [-1223.054 -1223.054 -1223.054] (1.000)
Step: 22799, Reward: [-1647.283 -1647.283 -1647.283] [0.0000], Avg: [-1223.984 -1223.984 -1223.984] (1.000)
Step: 22849, Reward: [-1936.248 -1936.248 -1936.248] [0.0000], Avg: [-1225.543 -1225.543 -1225.543] (1.000)
Step: 22899, Reward: [-1830.054 -1830.054 -1830.054] [0.0000], Avg: [-1226.863 -1226.863 -1226.863] (1.000)
Step: 22949, Reward: [-1572.139 -1572.139 -1572.139] [0.0000], Avg: [-1227.615 -1227.615 -1227.615] (1.000)
Step: 22999, Reward: [-2026.474 -2026.474 -2026.474] [0.0000], Avg: [-1229.352 -1229.352 -1229.352] (1.000)
Step: 23049, Reward: [-1874.387 -1874.387 -1874.387] [0.0000], Avg: [-1230.751 -1230.751 -1230.751] (1.000)
Step: 23099, Reward: [-890.689 -890.689 -890.689] [0.0000], Avg: [-1230.015 -1230.015 -1230.015] (1.000)
Step: 23149, Reward: [-2115.226 -2115.226 -2115.226] [0.0000], Avg: [-1231.927 -1231.927 -1231.927] (1.000)
Step: 23199, Reward: [-1550.715 -1550.715 -1550.715] [0.0000], Avg: [-1232.614 -1232.614 -1232.614] (1.000)
Step: 23249, Reward: [-945.801 -945.801 -945.801] [0.0000], Avg: [-1231.997 -1231.997 -1231.997] (1.000)
Step: 23299, Reward: [-1709.026 -1709.026 -1709.026] [0.0000], Avg: [-1233.021 -1233.021 -1233.021] (1.000)
Step: 23349, Reward: [-1759.189 -1759.189 -1759.189] [0.0000], Avg: [-1234.147 -1234.147 -1234.147] (1.000)
Step: 23399, Reward: [-2011.855 -2011.855 -2011.855] [0.0000], Avg: [-1235.809 -1235.809 -1235.809] (1.000)
Step: 23449, Reward: [-1897.207 -1897.207 -1897.207] [0.0000], Avg: [-1237.219 -1237.219 -1237.219] (1.000)
Step: 23499, Reward: [-2187.601 -2187.601 -2187.601] [0.0000], Avg: [-1239.241 -1239.241 -1239.241] (1.000)
Step: 23549, Reward: [-2125.42 -2125.42 -2125.42] [0.0000], Avg: [-1241.123 -1241.123 -1241.123] (1.000)
Step: 23599, Reward: [-1020.208 -1020.208 -1020.208] [0.0000], Avg: [-1240.655 -1240.655 -1240.655] (1.000)
Step: 23649, Reward: [-2090.946 -2090.946 -2090.946] [0.0000], Avg: [-1242.452 -1242.452 -1242.452] (1.000)
Step: 23699, Reward: [-2053.071 -2053.071 -2053.071] [0.0000], Avg: [-1244.163 -1244.163 -1244.163] (1.000)
Step: 23749, Reward: [-1965.403 -1965.403 -1965.403] [0.0000], Avg: [-1245.681 -1245.681 -1245.681] (1.000)
Step: 23799, Reward: [-674.864 -674.864 -674.864] [0.0000], Avg: [-1244.482 -1244.482 -1244.482] (1.000)
Step: 23849, Reward: [-1437.397 -1437.397 -1437.397] [0.0000], Avg: [-1244.886 -1244.886 -1244.886] (1.000)
Step: 23899, Reward: [-1932.143 -1932.143 -1932.143] [0.0000], Avg: [-1246.324 -1246.324 -1246.324] (1.000)
Step: 23949, Reward: [-2163.041 -2163.041 -2163.041] [0.0000], Avg: [-1248.238 -1248.238 -1248.238] (1.000)
Step: 23999, Reward: [-1941.148 -1941.148 -1941.148] [0.0000], Avg: [-1249.681 -1249.681 -1249.681] (1.000)
Step: 24049, Reward: [-894.176 -894.176 -894.176] [0.0000], Avg: [-1248.942 -1248.942 -1248.942] (1.000)
Step: 24099, Reward: [-1774.894 -1774.894 -1774.894] [0.0000], Avg: [-1250.033 -1250.033 -1250.033] (1.000)
Step: 24149, Reward: [-604.638 -604.638 -604.638] [0.0000], Avg: [-1248.697 -1248.697 -1248.697] (1.000)
Step: 24199, Reward: [-593.131 -593.131 -593.131] [0.0000], Avg: [-1247.343 -1247.343 -1247.343] (1.000)
Step: 24249, Reward: [-628.648 -628.648 -628.648] [0.0000], Avg: [-1246.067 -1246.067 -1246.067] (1.000)
Step: 24299, Reward: [-513.352 -513.352 -513.352] [0.0000], Avg: [-1244.559 -1244.559 -1244.559] (1.000)
Step: 24349, Reward: [-450.744 -450.744 -450.744] [0.0000], Avg: [-1242.929 -1242.929 -1242.929] (1.000)
Step: 24399, Reward: [-513.385 -513.385 -513.385] [0.0000], Avg: [-1241.434 -1241.434 -1241.434] (1.000)
Step: 24449, Reward: [-561.113 -561.113 -561.113] [0.0000], Avg: [-1240.043 -1240.043 -1240.043] (1.000)
Step: 24499, Reward: [-761.819 -761.819 -761.819] [0.0000], Avg: [-1239.067 -1239.067 -1239.067] (1.000)
Step: 24549, Reward: [-508.974 -508.974 -508.974] [0.0000], Avg: [-1237.58 -1237.58 -1237.58] (1.000)
Step: 24599, Reward: [-521.379 -521.379 -521.379] [0.0000], Avg: [-1236.125 -1236.125 -1236.125] (1.000)
Step: 24649, Reward: [-882.44 -882.44 -882.44] [0.0000], Avg: [-1235.407 -1235.407 -1235.407] (1.000)
Step: 24699, Reward: [-535.281 -535.281 -535.281] [0.0000], Avg: [-1233.99 -1233.99 -1233.99] (1.000)
Step: 24749, Reward: [-401.731 -401.731 -401.731] [0.0000], Avg: [-1232.309 -1232.309 -1232.309] (1.000)
Step: 24799, Reward: [-684.357 -684.357 -684.357] [0.0000], Avg: [-1231.204 -1231.204 -1231.204] (1.000)
Step: 24849, Reward: [-737.924 -737.924 -737.924] [0.0000], Avg: [-1230.211 -1230.211 -1230.211] (1.000)
Step: 24899, Reward: [-420.313 -420.313 -420.313] [0.0000], Avg: [-1228.585 -1228.585 -1228.585] (1.000)
Step: 24949, Reward: [-627.189 -627.189 -627.189] [0.0000], Avg: [-1227.38 -1227.38 -1227.38] (1.000)
Step: 24999, Reward: [-466.151 -466.151 -466.151] [0.0000], Avg: [-1225.857 -1225.857 -1225.857] (1.000)
Step: 25049, Reward: [-356.244 -356.244 -356.244] [0.0000], Avg: [-1224.122 -1224.122 -1224.122] (1.000)
Step: 25099, Reward: [-643.559 -643.559 -643.559] [0.0000], Avg: [-1222.965 -1222.965 -1222.965] (1.000)
Step: 25149, Reward: [-834.308 -834.308 -834.308] [0.0000], Avg: [-1222.192 -1222.192 -1222.192] (1.000)
Step: 25199, Reward: [-571.544 -571.544 -571.544] [0.0000], Avg: [-1220.901 -1220.901 -1220.901] (1.000)
Step: 25249, Reward: [-806.993 -806.993 -806.993] [0.0000], Avg: [-1220.082 -1220.082 -1220.082] (1.000)
Step: 25299, Reward: [-548.87 -548.87 -548.87] [0.0000], Avg: [-1218.755 -1218.755 -1218.755] (1.000)
Step: 25349, Reward: [-639.079 -639.079 -639.079] [0.0000], Avg: [-1217.612 -1217.612 -1217.612] (1.000)
Step: 25399, Reward: [-394.099 -394.099 -394.099] [0.0000], Avg: [-1215.991 -1215.991 -1215.991] (1.000)
Step: 25449, Reward: [-599.941 -599.941 -599.941] [0.0000], Avg: [-1214.781 -1214.781 -1214.781] (1.000)
Step: 25499, Reward: [-678.275 -678.275 -678.275] [0.0000], Avg: [-1213.729 -1213.729 -1213.729] (1.000)
Step: 25549, Reward: [-590.356 -590.356 -590.356] [0.0000], Avg: [-1212.509 -1212.509 -1212.509] (1.000)
Step: 25599, Reward: [-623.379 -623.379 -623.379] [0.0000], Avg: [-1211.358 -1211.358 -1211.358] (1.000)
Step: 25649, Reward: [-594.402 -594.402 -594.402] [0.0000], Avg: [-1210.155 -1210.155 -1210.155] (1.000)
Step: 25699, Reward: [-569.486 -569.486 -569.486] [0.0000], Avg: [-1208.909 -1208.909 -1208.909] (1.000)
Step: 25749, Reward: [-623.464 -623.464 -623.464] [0.0000], Avg: [-1207.772 -1207.772 -1207.772] (1.000)
Step: 25799, Reward: [-616.467 -616.467 -616.467] [0.0000], Avg: [-1206.626 -1206.626 -1206.626] (1.000)
Step: 25849, Reward: [-624.858 -624.858 -624.858] [0.0000], Avg: [-1205.501 -1205.501 -1205.501] (1.000)
Step: 25899, Reward: [-743.704 -743.704 -743.704] [0.0000], Avg: [-1204.609 -1204.609 -1204.609] (1.000)
Step: 25949, Reward: [-631.063 -631.063 -631.063] [0.0000], Avg: [-1203.504 -1203.504 -1203.504] (1.000)
Step: 25999, Reward: [-1329.693 -1329.693 -1329.693] [0.0000], Avg: [-1203.747 -1203.747 -1203.747] (1.000)
Step: 26049, Reward: [-511.23 -511.23 -511.23] [0.0000], Avg: [-1202.418 -1202.418 -1202.418] (1.000)
Step: 26099, Reward: [-489.966 -489.966 -489.966] [0.0000], Avg: [-1201.053 -1201.053 -1201.053] (1.000)
Step: 26149, Reward: [-536.749 -536.749 -536.749] [0.0000], Avg: [-1199.783 -1199.783 -1199.783] (1.000)
Step: 26199, Reward: [-584.828 -584.828 -584.828] [0.0000], Avg: [-1198.609 -1198.609 -1198.609] (1.000)
Step: 26249, Reward: [-401.941 -401.941 -401.941] [0.0000], Avg: [-1197.092 -1197.092 -1197.092] (1.000)
Step: 26299, Reward: [-912.504 -912.504 -912.504] [0.0000], Avg: [-1196.551 -1196.551 -1196.551] (1.000)
Step: 26349, Reward: [-640.894 -640.894 -640.894] [0.0000], Avg: [-1195.496 -1195.496 -1195.496] (1.000)
Step: 26399, Reward: [-578.129 -578.129 -578.129] [0.0000], Avg: [-1194.327 -1194.327 -1194.327] (1.000)
Step: 26449, Reward: [-781.247 -781.247 -781.247] [0.0000], Avg: [-1193.546 -1193.546 -1193.546] (1.000)
Step: 26499, Reward: [-670.186 -670.186 -670.186] [0.0000], Avg: [-1192.559 -1192.559 -1192.559] (1.000)
Step: 26549, Reward: [-698.215 -698.215 -698.215] [0.0000], Avg: [-1191.628 -1191.628 -1191.628] (1.000)
Step: 26599, Reward: [-596.233 -596.233 -596.233] [0.0000], Avg: [-1190.509 -1190.509 -1190.509] (1.000)
Step: 26649, Reward: [-719.57 -719.57 -719.57] [0.0000], Avg: [-1189.625 -1189.625 -1189.625] (1.000)
Step: 26699, Reward: [-955.735 -955.735 -955.735] [0.0000], Avg: [-1189.187 -1189.187 -1189.187] (1.000)
Step: 26749, Reward: [-983.574 -983.574 -983.574] [0.0000], Avg: [-1188.803 -1188.803 -1188.803] (1.000)
Step: 26799, Reward: [-479.704 -479.704 -479.704] [0.0000], Avg: [-1187.48 -1187.48 -1187.48] (1.000)
Step: 26849, Reward: [-871.91 -871.91 -871.91] [0.0000], Avg: [-1186.892 -1186.892 -1186.892] (1.000)
Step: 26899, Reward: [-990.682 -990.682 -990.682] [0.0000], Avg: [-1186.527 -1186.527 -1186.527] (1.000)
Step: 26949, Reward: [-662.748 -662.748 -662.748] [0.0000], Avg: [-1185.556 -1185.556 -1185.556] (1.000)
Step: 26999, Reward: [-784.48 -784.48 -784.48] [0.0000], Avg: [-1184.813 -1184.813 -1184.813] (1.000)
Step: 27049, Reward: [-1390.058 -1390.058 -1390.058] [0.0000], Avg: [-1185.192 -1185.192 -1185.192] (1.000)
Step: 27099, Reward: [-761.204 -761.204 -761.204] [0.0000], Avg: [-1184.41 -1184.41 -1184.41] (1.000)
Step: 27149, Reward: [-618.504 -618.504 -618.504] [0.0000], Avg: [-1183.368 -1183.368 -1183.368] (1.000)
Step: 27199, Reward: [-971.307 -971.307 -971.307] [0.0000], Avg: [-1182.978 -1182.978 -1182.978] (1.000)
Step: 27249, Reward: [-754.909 -754.909 -754.909] [0.0000], Avg: [-1182.193 -1182.193 -1182.193] (1.000)
Step: 27299, Reward: [-833.483 -833.483 -833.483] [0.0000], Avg: [-1181.554 -1181.554 -1181.554] (1.000)
Step: 27349, Reward: [-676.331 -676.331 -676.331] [0.0000], Avg: [-1180.63 -1180.63 -1180.63] (1.000)
Step: 27399, Reward: [-1802.603 -1802.603 -1802.603] [0.0000], Avg: [-1181.765 -1181.765 -1181.765] (1.000)
Step: 27449, Reward: [-1133.372 -1133.372 -1133.372] [0.0000], Avg: [-1181.677 -1181.677 -1181.677] (1.000)
Step: 27499, Reward: [-780.955 -780.955 -780.955] [0.0000], Avg: [-1180.949 -1180.949 -1180.949] (1.000)
Step: 27549, Reward: [-625.492 -625.492 -625.492] [0.0000], Avg: [-1179.94 -1179.94 -1179.94] (1.000)
Step: 27599, Reward: [-508.674 -508.674 -508.674] [0.0000], Avg: [-1178.724 -1178.724 -1178.724] (1.000)
Step: 27649, Reward: [-915.102 -915.102 -915.102] [0.0000], Avg: [-1178.248 -1178.248 -1178.248] (1.000)
Step: 27699, Reward: [-627.925 -627.925 -627.925] [0.0000], Avg: [-1177.254 -1177.254 -1177.254] (1.000)
Step: 27749, Reward: [-1686.991 -1686.991 -1686.991] [0.0000], Avg: [-1178.173 -1178.173 -1178.173] (1.000)
Step: 27799, Reward: [-2363.921 -2363.921 -2363.921] [0.0000], Avg: [-1180.305 -1180.305 -1180.305] (1.000)
Step: 27849, Reward: [-791.484 -791.484 -791.484] [0.0000], Avg: [-1179.607 -1179.607 -1179.607] (1.000)
Step: 27899, Reward: [-1834.886 -1834.886 -1834.886] [0.0000], Avg: [-1180.782 -1180.782 -1180.782] (1.000)
Step: 27949, Reward: [-969.847 -969.847 -969.847] [0.0000], Avg: [-1180.404 -1180.404 -1180.404] (1.000)
Step: 27999, Reward: [-2187.244 -2187.244 -2187.244] [0.0000], Avg: [-1182.202 -1182.202 -1182.202] (1.000)
Step: 28049, Reward: [-2120.413 -2120.413 -2120.413] [0.0000], Avg: [-1183.875 -1183.875 -1183.875] (1.000)
Step: 28099, Reward: [-1604.131 -1604.131 -1604.131] [0.0000], Avg: [-1184.622 -1184.622 -1184.622] (1.000)
Step: 28149, Reward: [-2019.023 -2019.023 -2019.023] [0.0000], Avg: [-1186.105 -1186.105 -1186.105] (1.000)
Step: 28199, Reward: [-1815.267 -1815.267 -1815.267] [0.0000], Avg: [-1187.22 -1187.22 -1187.22] (1.000)
Step: 28249, Reward: [-2192.932 -2192.932 -2192.932] [0.0000], Avg: [-1189. -1189. -1189.] (1.000)
Step: 28299, Reward: [-1821.244 -1821.244 -1821.244] [0.0000], Avg: [-1190.117 -1190.117 -1190.117] (1.000)
Step: 28349, Reward: [-1513.348 -1513.348 -1513.348] [0.0000], Avg: [-1190.687 -1190.687 -1190.687] (1.000)
Step: 28399, Reward: [-1745.396 -1745.396 -1745.396] [0.0000], Avg: [-1191.664 -1191.664 -1191.664] (1.000)
Step: 28449, Reward: [-758.62 -758.62 -758.62] [0.0000], Avg: [-1190.903 -1190.903 -1190.903] (1.000)
Step: 28499, Reward: [-1857.753 -1857.753 -1857.753] [0.0000], Avg: [-1192.073 -1192.073 -1192.073] (1.000)
Step: 28549, Reward: [-1773.234 -1773.234 -1773.234] [0.0000], Avg: [-1193.09 -1193.09 -1193.09] (1.000)
Step: 28599, Reward: [-2023.869 -2023.869 -2023.869] [0.0000], Avg: [-1194.543 -1194.543 -1194.543] (1.000)
Step: 28649, Reward: [-1840.702 -1840.702 -1840.702] [0.0000], Avg: [-1195.671 -1195.671 -1195.671] (1.000)
Step: 28699, Reward: [-1983.92 -1983.92 -1983.92] [0.0000], Avg: [-1197.044 -1197.044 -1197.044] (1.000)
Step: 28749, Reward: [-1962.461 -1962.461 -1962.461] [0.0000], Avg: [-1198.375 -1198.375 -1198.375] (1.000)
Step: 28799, Reward: [-2294.397 -2294.397 -2294.397] [0.0000], Avg: [-1200.278 -1200.278 -1200.278] (1.000)
Step: 28849, Reward: [-2073.134 -2073.134 -2073.134] [0.0000], Avg: [-1201.791 -1201.791 -1201.791] (1.000)
Step: 28899, Reward: [-1774.123 -1774.123 -1774.123] [0.0000], Avg: [-1202.781 -1202.781 -1202.781] (1.000)
Step: 28949, Reward: [-2130.671 -2130.671 -2130.671] [0.0000], Avg: [-1204.383 -1204.383 -1204.383] (1.000)
Step: 28999, Reward: [-1823.287 -1823.287 -1823.287] [0.0000], Avg: [-1205.45 -1205.45 -1205.45] (1.000)
Step: 29049, Reward: [-1744.953 -1744.953 -1744.953] [0.0000], Avg: [-1206.379 -1206.379 -1206.379] (1.000)
Step: 29099, Reward: [-1494.316 -1494.316 -1494.316] [0.0000], Avg: [-1206.874 -1206.874 -1206.874] (1.000)
Step: 29149, Reward: [-1679.831 -1679.831 -1679.831] [0.0000], Avg: [-1207.685 -1207.685 -1207.685] (1.000)
Step: 29199, Reward: [-1714.619 -1714.619 -1714.619] [0.0000], Avg: [-1208.553 -1208.553 -1208.553] (1.000)
Step: 29249, Reward: [-1764.531 -1764.531 -1764.531] [0.0000], Avg: [-1209.503 -1209.503 -1209.503] (1.000)
Step: 29299, Reward: [-1784.771 -1784.771 -1784.771] [0.0000], Avg: [-1210.485 -1210.485 -1210.485] (1.000)
Step: 29349, Reward: [-1687.187 -1687.187 -1687.187] [0.0000], Avg: [-1211.297 -1211.297 -1211.297] (1.000)
Step: 29399, Reward: [-1892.808 -1892.808 -1892.808] [0.0000], Avg: [-1212.456 -1212.456 -1212.456] (1.000)
Step: 29449, Reward: [-1715.927 -1715.927 -1715.927] [0.0000], Avg: [-1213.311 -1213.311 -1213.311] (1.000)
Step: 29499, Reward: [-1414.691 -1414.691 -1414.691] [0.0000], Avg: [-1213.652 -1213.652 -1213.652] (1.000)
Step: 29549, Reward: [-1824.193 -1824.193 -1824.193] [0.0000], Avg: [-1214.685 -1214.685 -1214.685] (1.000)
Step: 29599, Reward: [-1382.745 -1382.745 -1382.745] [0.0000], Avg: [-1214.969 -1214.969 -1214.969] (1.000)
Step: 29649, Reward: [-1333.343 -1333.343 -1333.343] [0.0000], Avg: [-1215.169 -1215.169 -1215.169] (1.000)
Step: 29699, Reward: [-1567.809 -1567.809 -1567.809] [0.0000], Avg: [-1215.763 -1215.763 -1215.763] (1.000)
Step: 29749, Reward: [-1753.214 -1753.214 -1753.214] [0.0000], Avg: [-1216.666 -1216.666 -1216.666] (1.000)
Step: 29799, Reward: [-1932.395 -1932.395 -1932.395] [0.0000], Avg: [-1217.867 -1217.867 -1217.867] (1.000)
Step: 29849, Reward: [-1774.592 -1774.592 -1774.592] [0.0000], Avg: [-1218.799 -1218.799 -1218.799] (1.000)
Step: 29899, Reward: [-2138.421 -2138.421 -2138.421] [0.0000], Avg: [-1220.337 -1220.337 -1220.337] (1.000)
Step: 29949, Reward: [-1653.088 -1653.088 -1653.088] [0.0000], Avg: [-1221.06 -1221.06 -1221.06] (1.000)
Step: 29999, Reward: [-1466.221 -1466.221 -1466.221] [0.0000], Avg: [-1221.468 -1221.468 -1221.468] (1.000)
Step: 30049, Reward: [-1594.894 -1594.894 -1594.894] [0.0000], Avg: [-1222.089 -1222.089 -1222.089] (1.000)
Step: 30099, Reward: [-614.57 -614.57 -614.57] [0.0000], Avg: [-1221.08 -1221.08 -1221.08] (1.000)
Step: 30149, Reward: [-1348.008 -1348.008 -1348.008] [0.0000], Avg: [-1221.291 -1221.291 -1221.291] (1.000)
Step: 30199, Reward: [-1733.733 -1733.733 -1733.733] [0.0000], Avg: [-1222.139 -1222.139 -1222.139] (1.000)
Step: 30249, Reward: [-1700.428 -1700.428 -1700.428] [0.0000], Avg: [-1222.93 -1222.93 -1222.93] (1.000)
Step: 30299, Reward: [-1853.235 -1853.235 -1853.235] [0.0000], Avg: [-1223.97 -1223.97 -1223.97] (1.000)
Step: 30349, Reward: [-1278.02 -1278.02 -1278.02] [0.0000], Avg: [-1224.059 -1224.059 -1224.059] (1.000)
Step: 30399, Reward: [-2056.288 -2056.288 -2056.288] [0.0000], Avg: [-1225.428 -1225.428 -1225.428] (1.000)
Step: 30449, Reward: [-2069.388 -2069.388 -2069.388] [0.0000], Avg: [-1226.814 -1226.814 -1226.814] (1.000)
Step: 30499, Reward: [-1689.222 -1689.222 -1689.222] [0.0000], Avg: [-1227.572 -1227.572 -1227.572] (1.000)
Step: 30549, Reward: [-1791.567 -1791.567 -1791.567] [0.0000], Avg: [-1228.495 -1228.495 -1228.495] (1.000)
Step: 30599, Reward: [-2118.553 -2118.553 -2118.553] [0.0000], Avg: [-1229.949 -1229.949 -1229.949] (1.000)
Step: 30649, Reward: [-2100.473 -2100.473 -2100.473] [0.0000], Avg: [-1231.369 -1231.369 -1231.369] (1.000)
Step: 30699, Reward: [-1543.335 -1543.335 -1543.335] [0.0000], Avg: [-1231.877 -1231.877 -1231.877] (1.000)
Step: 30749, Reward: [-1994.88 -1994.88 -1994.88] [0.0000], Avg: [-1233.118 -1233.118 -1233.118] (1.000)
Step: 30799, Reward: [-1817.087 -1817.087 -1817.087] [0.0000], Avg: [-1234.066 -1234.066 -1234.066] (1.000)
Step: 30849, Reward: [-1768.294 -1768.294 -1768.294] [0.0000], Avg: [-1234.932 -1234.932 -1234.932] (1.000)
Step: 30899, Reward: [-2013.943 -2013.943 -2013.943] [0.0000], Avg: [-1236.192 -1236.192 -1236.192] (1.000)
Step: 30949, Reward: [-2229.128 -2229.128 -2229.128] [0.0000], Avg: [-1237.796 -1237.796 -1237.796] (1.000)
Step: 30999, Reward: [-1897.473 -1897.473 -1897.473] [0.0000], Avg: [-1238.86 -1238.86 -1238.86] (1.000)
Step: 31049, Reward: [-1654.65 -1654.65 -1654.65] [0.0000], Avg: [-1239.53 -1239.53 -1239.53] (1.000)
Step: 31099, Reward: [-2238.531 -2238.531 -2238.531] [0.0000], Avg: [-1241.136 -1241.136 -1241.136] (1.000)
Step: 31149, Reward: [-2270.264 -2270.264 -2270.264] [0.0000], Avg: [-1242.788 -1242.788 -1242.788] (1.000)
Step: 31199, Reward: [-1745.458 -1745.458 -1745.458] [0.0000], Avg: [-1243.593 -1243.593 -1243.593] (1.000)
Step: 31249, Reward: [-2234.829 -2234.829 -2234.829] [0.0000], Avg: [-1245.179 -1245.179 -1245.179] (1.000)
Step: 31299, Reward: [-1683.493 -1683.493 -1683.493] [0.0000], Avg: [-1245.88 -1245.88 -1245.88] (1.000)
Step: 31349, Reward: [-1701.521 -1701.521 -1701.521] [0.0000], Avg: [-1246.606 -1246.606 -1246.606] (1.000)
Step: 31399, Reward: [-847.599 -847.599 -847.599] [0.0000], Avg: [-1245.971 -1245.971 -1245.971] (1.000)
Step: 31449, Reward: [-2048.159 -2048.159 -2048.159] [0.0000], Avg: [-1247.246 -1247.246 -1247.246] (1.000)
Step: 31499, Reward: [-1027.788 -1027.788 -1027.788] [0.0000], Avg: [-1246.898 -1246.898 -1246.898] (1.000)
Step: 31549, Reward: [-772.25 -772.25 -772.25] [0.0000], Avg: [-1246.146 -1246.146 -1246.146] (1.000)
Step: 31599, Reward: [-1794.587 -1794.587 -1794.587] [0.0000], Avg: [-1247.013 -1247.013 -1247.013] (1.000)
Step: 31649, Reward: [-778.001 -778.001 -778.001] [0.0000], Avg: [-1246.273 -1246.273 -1246.273] (1.000)
Step: 31699, Reward: [-1007.899 -1007.899 -1007.899] [0.0000], Avg: [-1245.897 -1245.897 -1245.897] (1.000)
Step: 31749, Reward: [-890.563 -890.563 -890.563] [0.0000], Avg: [-1245.337 -1245.337 -1245.337] (1.000)
Step: 31799, Reward: [-1064.992 -1064.992 -1064.992] [0.0000], Avg: [-1245.053 -1245.053 -1245.053] (1.000)
Step: 31849, Reward: [-769.013 -769.013 -769.013] [0.0000], Avg: [-1244.306 -1244.306 -1244.306] (1.000)
Step: 31899, Reward: [-768.042 -768.042 -768.042] [0.0000], Avg: [-1243.56 -1243.56 -1243.56] (1.000)
Step: 31949, Reward: [-818.521 -818.521 -818.521] [0.0000], Avg: [-1242.894 -1242.894 -1242.894] (1.000)
Step: 31999, Reward: [-850.627 -850.627 -850.627] [0.0000], Avg: [-1242.282 -1242.282 -1242.282] (1.000)
Step: 32049, Reward: [-1514.57 -1514.57 -1514.57] [0.0000], Avg: [-1242.706 -1242.706 -1242.706] (1.000)
Step: 32099, Reward: [-1221.85 -1221.85 -1221.85] [0.0000], Avg: [-1242.674 -1242.674 -1242.674] (1.000)
Step: 32149, Reward: [-1284.88 -1284.88 -1284.88] [0.0000], Avg: [-1242.739 -1242.739 -1242.739] (1.000)
Step: 32199, Reward: [-1110.928 -1110.928 -1110.928] [0.0000], Avg: [-1242.535 -1242.535 -1242.535] (1.000)
Step: 32249, Reward: [-1140.104 -1140.104 -1140.104] [0.0000], Avg: [-1242.376 -1242.376 -1242.376] (1.000)
Step: 32299, Reward: [-1955.882 -1955.882 -1955.882] [0.0000], Avg: [-1243.48 -1243.48 -1243.48] (1.000)
Step: 32349, Reward: [-1880.041 -1880.041 -1880.041] [0.0000], Avg: [-1244.464 -1244.464 -1244.464] (1.000)
Step: 32399, Reward: [-1821.424 -1821.424 -1821.424] [0.0000], Avg: [-1245.355 -1245.355 -1245.355] (1.000)
Step: 32449, Reward: [-1939.719 -1939.719 -1939.719] [0.0000], Avg: [-1246.425 -1246.425 -1246.425] (1.000)
Step: 32499, Reward: [-1731.863 -1731.863 -1731.863] [0.0000], Avg: [-1247.171 -1247.171 -1247.171] (1.000)
Step: 32549, Reward: [-1915.715 -1915.715 -1915.715] [0.0000], Avg: [-1248.198 -1248.198 -1248.198] (1.000)
Step: 32599, Reward: [-1677.759 -1677.759 -1677.759] [0.0000], Avg: [-1248.857 -1248.857 -1248.857] (1.000)
Step: 32649, Reward: [-1935.652 -1935.652 -1935.652] [0.0000], Avg: [-1249.909 -1249.909 -1249.909] (1.000)
Step: 32699, Reward: [-1353.717 -1353.717 -1353.717] [0.0000], Avg: [-1250.068 -1250.068 -1250.068] (1.000)
Step: 32749, Reward: [-1940.111 -1940.111 -1940.111] [0.0000], Avg: [-1251.121 -1251.121 -1251.121] (1.000)
Step: 32799, Reward: [-1699.524 -1699.524 -1699.524] [0.0000], Avg: [-1251.805 -1251.805 -1251.805] (1.000)
Step: 32849, Reward: [-1912.648 -1912.648 -1912.648] [0.0000], Avg: [-1252.811 -1252.811 -1252.811] (1.000)
Step: 32899, Reward: [-1926.572 -1926.572 -1926.572] [0.0000], Avg: [-1253.835 -1253.835 -1253.835] (1.000)
Step: 32949, Reward: [-2296.722 -2296.722 -2296.722] [0.0000], Avg: [-1255.417 -1255.417 -1255.417] (1.000)
Step: 32999, Reward: [-1891.156 -1891.156 -1891.156] [0.0000], Avg: [-1256.38 -1256.38 -1256.38] (1.000)
Step: 33049, Reward: [-2069.054 -2069.054 -2069.054] [0.0000], Avg: [-1257.61 -1257.61 -1257.61] (1.000)
Step: 33099, Reward: [-2106.359 -2106.359 -2106.359] [0.0000], Avg: [-1258.892 -1258.892 -1258.892] (1.000)
Step: 33149, Reward: [-2437.249 -2437.249 -2437.249] [0.0000], Avg: [-1260.669 -1260.669 -1260.669] (1.000)
Step: 33199, Reward: [-1238.48 -1238.48 -1238.48] [0.0000], Avg: [-1260.636 -1260.636 -1260.636] (1.000)
Step: 33249, Reward: [-1570.545 -1570.545 -1570.545] [0.0000], Avg: [-1261.102 -1261.102 -1261.102] (1.000)
Step: 33299, Reward: [-1905.183 -1905.183 -1905.183] [0.0000], Avg: [-1262.069 -1262.069 -1262.069] (1.000)
Step: 33349, Reward: [-1936.255 -1936.255 -1936.255] [0.0000], Avg: [-1263.08 -1263.08 -1263.08] (1.000)
Step: 33399, Reward: [-2139.491 -2139.491 -2139.491] [0.0000], Avg: [-1264.392 -1264.392 -1264.392] (1.000)
Step: 33449, Reward: [-2109.878 -2109.878 -2109.878] [0.0000], Avg: [-1265.655 -1265.655 -1265.655] (1.000)
Step: 33499, Reward: [-1636.672 -1636.672 -1636.672] [0.0000], Avg: [-1266.209 -1266.209 -1266.209] (1.000)
Step: 33549, Reward: [-1249.354 -1249.354 -1249.354] [0.0000], Avg: [-1266.184 -1266.184 -1266.184] (1.000)
Step: 33599, Reward: [-1424.339 -1424.339 -1424.339] [0.0000], Avg: [-1266.419 -1266.419 -1266.419] (1.000)
Step: 33649, Reward: [-1838.819 -1838.819 -1838.819] [0.0000], Avg: [-1267.27 -1267.27 -1267.27] (1.000)
Step: 33699, Reward: [-1337.626 -1337.626 -1337.626] [0.0000], Avg: [-1267.374 -1267.374 -1267.374] (1.000)
Step: 33749, Reward: [-2154.532 -2154.532 -2154.532] [0.0000], Avg: [-1268.689 -1268.689 -1268.689] (1.000)
Step: 33799, Reward: [-1858.817 -1858.817 -1858.817] [0.0000], Avg: [-1269.562 -1269.562 -1269.562] (1.000)
Step: 33849, Reward: [-1925.754 -1925.754 -1925.754] [0.0000], Avg: [-1270.531 -1270.531 -1270.531] (1.000)
Step: 33899, Reward: [-1702.259 -1702.259 -1702.259] [0.0000], Avg: [-1271.168 -1271.168 -1271.168] (1.000)
Step: 33949, Reward: [-1827.714 -1827.714 -1827.714] [0.0000], Avg: [-1271.987 -1271.987 -1271.987] (1.000)
Step: 33999, Reward: [-909.637 -909.637 -909.637] [0.0000], Avg: [-1271.454 -1271.454 -1271.454] (1.000)
Step: 34049, Reward: [-1819.469 -1819.469 -1819.469] [0.0000], Avg: [-1272.259 -1272.259 -1272.259] (1.000)
Step: 34099, Reward: [-2080.114 -2080.114 -2080.114] [0.0000], Avg: [-1273.444 -1273.444 -1273.444] (1.000)
Step: 34149, Reward: [-1788.921 -1788.921 -1788.921] [0.0000], Avg: [-1274.198 -1274.198 -1274.198] (1.000)
Step: 34199, Reward: [-1970.726 -1970.726 -1970.726] [0.0000], Avg: [-1275.217 -1275.217 -1275.217] (1.000)
Step: 34249, Reward: [-1911.285 -1911.285 -1911.285] [0.0000], Avg: [-1276.145 -1276.145 -1276.145] (1.000)
Step: 34299, Reward: [-1851.468 -1851.468 -1851.468] [0.0000], Avg: [-1276.984 -1276.984 -1276.984] (1.000)
Step: 34349, Reward: [-1581.189 -1581.189 -1581.189] [0.0000], Avg: [-1277.427 -1277.427 -1277.427] (1.000)
Step: 34399, Reward: [-1818.009 -1818.009 -1818.009] [0.0000], Avg: [-1278.212 -1278.212 -1278.212] (1.000)
Step: 34449, Reward: [-1891.041 -1891.041 -1891.041] [0.0000], Avg: [-1279.102 -1279.102 -1279.102] (1.000)
Step: 34499, Reward: [-1905.507 -1905.507 -1905.507] [0.0000], Avg: [-1280.01 -1280.01 -1280.01] (1.000)
Step: 34549, Reward: [-2081.066 -2081.066 -2081.066] [0.0000], Avg: [-1281.169 -1281.169 -1281.169] (1.000)
Step: 34599, Reward: [-1774.099 -1774.099 -1774.099] [0.0000], Avg: [-1281.881 -1281.881 -1281.881] (1.000)
Step: 34649, Reward: [-1967.781 -1967.781 -1967.781] [0.0000], Avg: [-1282.871 -1282.871 -1282.871] (1.000)
Step: 34699, Reward: [-1736.68 -1736.68 -1736.68] [0.0000], Avg: [-1283.525 -1283.525 -1283.525] (1.000)
Step: 34749, Reward: [-2026.8 -2026.8 -2026.8] [0.0000], Avg: [-1284.594 -1284.594 -1284.594] (1.000)
Step: 34799, Reward: [-1915.594 -1915.594 -1915.594] [0.0000], Avg: [-1285.501 -1285.501 -1285.501] (1.000)
Step: 34849, Reward: [-1901.46 -1901.46 -1901.46] [0.0000], Avg: [-1286.385 -1286.385 -1286.385] (1.000)
Step: 34899, Reward: [-1662.263 -1662.263 -1662.263] [0.0000], Avg: [-1286.923 -1286.923 -1286.923] (1.000)
Step: 34949, Reward: [-1875.857 -1875.857 -1875.857] [0.0000], Avg: [-1287.766 -1287.766 -1287.766] (1.000)
Step: 34999, Reward: [-1675.726 -1675.726 -1675.726] [0.0000], Avg: [-1288.32 -1288.32 -1288.32] (1.000)
Step: 35049, Reward: [-1883.436 -1883.436 -1883.436] [0.0000], Avg: [-1289.169 -1289.169 -1289.169] (1.000)
Step: 35099, Reward: [-2297.182 -2297.182 -2297.182] [0.0000], Avg: [-1290.605 -1290.605 -1290.605] (1.000)
Step: 35149, Reward: [-1948.784 -1948.784 -1948.784] [0.0000], Avg: [-1291.541 -1291.541 -1291.541] (1.000)
Step: 35199, Reward: [-1713.298 -1713.298 -1713.298] [0.0000], Avg: [-1292.14 -1292.14 -1292.14] (1.000)
Step: 35249, Reward: [-1674.015 -1674.015 -1674.015] [0.0000], Avg: [-1292.682 -1292.682 -1292.682] (1.000)
Step: 35299, Reward: [-1975.758 -1975.758 -1975.758] [0.0000], Avg: [-1293.65 -1293.65 -1293.65] (1.000)
Step: 35349, Reward: [-1683.244 -1683.244 -1683.244] [0.0000], Avg: [-1294.201 -1294.201 -1294.201] (1.000)
Step: 35399, Reward: [-2168.009 -2168.009 -2168.009] [0.0000], Avg: [-1295.435 -1295.435 -1295.435] (1.000)
Step: 35449, Reward: [-2034.699 -2034.699 -2034.699] [0.0000], Avg: [-1296.477 -1296.477 -1296.477] (1.000)
Step: 35499, Reward: [-1981.251 -1981.251 -1981.251] [0.0000], Avg: [-1297.442 -1297.442 -1297.442] (1.000)
Step: 35549, Reward: [-1734.73 -1734.73 -1734.73] [0.0000], Avg: [-1298.057 -1298.057 -1298.057] (1.000)
Step: 35599, Reward: [-1978.496 -1978.496 -1978.496] [0.0000], Avg: [-1299.013 -1299.013 -1299.013] (1.000)
Step: 35649, Reward: [-2119.738 -2119.738 -2119.738] [0.0000], Avg: [-1300.164 -1300.164 -1300.164] (1.000)
Step: 35699, Reward: [-1830.205 -1830.205 -1830.205] [0.0000], Avg: [-1300.906 -1300.906 -1300.906] (1.000)
Step: 35749, Reward: [-1763.102 -1763.102 -1763.102] [0.0000], Avg: [-1301.552 -1301.552 -1301.552] (1.000)
Step: 35799, Reward: [-2223.13 -2223.13 -2223.13] [0.0000], Avg: [-1302.84 -1302.84 -1302.84] (1.000)
Step: 35849, Reward: [-1604.244 -1604.244 -1604.244] [0.0000], Avg: [-1303.26 -1303.26 -1303.26] (1.000)
Step: 35899, Reward: [-1956.261 -1956.261 -1956.261] [0.0000], Avg: [-1304.169 -1304.169 -1304.169] (1.000)
Step: 35949, Reward: [-953.711 -953.711 -953.711] [0.0000], Avg: [-1303.682 -1303.682 -1303.682] (1.000)
Step: 35999, Reward: [-1090.182 -1090.182 -1090.182] [0.0000], Avg: [-1303.385 -1303.385 -1303.385] (1.000)
Step: 36049, Reward: [-2221.766 -2221.766 -2221.766] [0.0000], Avg: [-1304.659 -1304.659 -1304.659] (1.000)
Step: 36099, Reward: [-1829.685 -1829.685 -1829.685] [0.0000], Avg: [-1305.386 -1305.386 -1305.386] (1.000)
Step: 36149, Reward: [-1166.529 -1166.529 -1166.529] [0.0000], Avg: [-1305.194 -1305.194 -1305.194] (1.000)
Step: 36199, Reward: [-1467.662 -1467.662 -1467.662] [0.0000], Avg: [-1305.419 -1305.419 -1305.419] (1.000)
Step: 36249, Reward: [-1415.833 -1415.833 -1415.833] [0.0000], Avg: [-1305.571 -1305.571 -1305.571] (1.000)
Step: 36299, Reward: [-1492.974 -1492.974 -1492.974] [0.0000], Avg: [-1305.829 -1305.829 -1305.829] (1.000)
Step: 36349, Reward: [-1443.264 -1443.264 -1443.264] [0.0000], Avg: [-1306.018 -1306.018 -1306.018] (1.000)
Step: 36399, Reward: [-1121.356 -1121.356 -1121.356] [0.0000], Avg: [-1305.765 -1305.765 -1305.765] (1.000)
Step: 36449, Reward: [-1245.98 -1245.98 -1245.98] [0.0000], Avg: [-1305.683 -1305.683 -1305.683] (1.000)
Step: 36499, Reward: [-1237.159 -1237.159 -1237.159] [0.0000], Avg: [-1305.589 -1305.589 -1305.589] (1.000)
Step: 36549, Reward: [-1880.898 -1880.898 -1880.898] [0.0000], Avg: [-1306.376 -1306.376 -1306.376] (1.000)
Step: 36599, Reward: [-1789.221 -1789.221 -1789.221] [0.0000], Avg: [-1307.035 -1307.035 -1307.035] (1.000)
Step: 36649, Reward: [-2272.135 -2272.135 -2272.135] [0.0000], Avg: [-1308.352 -1308.352 -1308.352] (1.000)
Step: 36699, Reward: [-1602.085 -1602.085 -1602.085] [0.0000], Avg: [-1308.752 -1308.752 -1308.752] (1.000)
Step: 36749, Reward: [-2116.869 -2116.869 -2116.869] [0.0000], Avg: [-1309.852 -1309.852 -1309.852] (1.000)
Step: 36799, Reward: [-2066.911 -2066.911 -2066.911] [0.0000], Avg: [-1310.88 -1310.88 -1310.88] (1.000)
Step: 36849, Reward: [-1787.571 -1787.571 -1787.571] [0.0000], Avg: [-1311.527 -1311.527 -1311.527] (1.000)
Step: 36899, Reward: [-1645.013 -1645.013 -1645.013] [0.0000], Avg: [-1311.979 -1311.979 -1311.979] (1.000)
Step: 36949, Reward: [-1921.169 -1921.169 -1921.169] [0.0000], Avg: [-1312.803 -1312.803 -1312.803] (1.000)
Step: 36999, Reward: [-1219.675 -1219.675 -1219.675] [0.0000], Avg: [-1312.677 -1312.677 -1312.677] (1.000)
Step: 37049, Reward: [-1662.335 -1662.335 -1662.335] [0.0000], Avg: [-1313.149 -1313.149 -1313.149] (1.000)
Step: 37099, Reward: [-919.339 -919.339 -919.339] [0.0000], Avg: [-1312.619 -1312.619 -1312.619] (1.000)
Step: 37149, Reward: [-1916.089 -1916.089 -1916.089] [0.0000], Avg: [-1313.431 -1313.431 -1313.431] (1.000)
Step: 37199, Reward: [-1823.029 -1823.029 -1823.029] [0.0000], Avg: [-1314.116 -1314.116 -1314.116] (1.000)
Step: 37249, Reward: [-1768.497 -1768.497 -1768.497] [0.0000], Avg: [-1314.726 -1314.726 -1314.726] (1.000)
Step: 37299, Reward: [-1739.05 -1739.05 -1739.05] [0.0000], Avg: [-1315.294 -1315.294 -1315.294] (1.000)
Step: 37349, Reward: [-1878.932 -1878.932 -1878.932] [0.0000], Avg: [-1316.049 -1316.049 -1316.049] (1.000)
Step: 37399, Reward: [-1398.012 -1398.012 -1398.012] [0.0000], Avg: [-1316.159 -1316.159 -1316.159] (1.000)
Step: 37449, Reward: [-2290.441 -2290.441 -2290.441] [0.0000], Avg: [-1317.459 -1317.459 -1317.459] (1.000)
Step: 37499, Reward: [-1548.276 -1548.276 -1548.276] [0.0000], Avg: [-1317.767 -1317.767 -1317.767] (1.000)
Step: 37549, Reward: [-1708.25 -1708.25 -1708.25] [0.0000], Avg: [-1318.287 -1318.287 -1318.287] (1.000)
Step: 37599, Reward: [-2170.427 -2170.427 -2170.427] [0.0000], Avg: [-1319.42 -1319.42 -1319.42] (1.000)
Step: 37649, Reward: [-1957.01 -1957.01 -1957.01] [0.0000], Avg: [-1320.267 -1320.267 -1320.267] (1.000)
Step: 37699, Reward: [-1688.36 -1688.36 -1688.36] [0.0000], Avg: [-1320.755 -1320.755 -1320.755] (1.000)
Step: 37749, Reward: [-1799.884 -1799.884 -1799.884] [0.0000], Avg: [-1321.39 -1321.39 -1321.39] (1.000)
Step: 37799, Reward: [-2143.497 -2143.497 -2143.497] [0.0000], Avg: [-1322.477 -1322.477 -1322.477] (1.000)
Step: 37849, Reward: [-2168.223 -2168.223 -2168.223] [0.0000], Avg: [-1323.594 -1323.594 -1323.594] (1.000)
Step: 37899, Reward: [-1824.855 -1824.855 -1824.855] [0.0000], Avg: [-1324.256 -1324.256 -1324.256] (1.000)
Step: 37949, Reward: [-1955.616 -1955.616 -1955.616] [0.0000], Avg: [-1325.088 -1325.088 -1325.088] (1.000)
Step: 37999, Reward: [-1304.204 -1304.204 -1304.204] [0.0000], Avg: [-1325.06 -1325.06 -1325.06] (1.000)
Step: 38049, Reward: [-2025.847 -2025.847 -2025.847] [0.0000], Avg: [-1325.981 -1325.981 -1325.981] (1.000)
Step: 38099, Reward: [-1564.022 -1564.022 -1564.022] [0.0000], Avg: [-1326.293 -1326.293 -1326.293] (1.000)
Step: 38149, Reward: [-1610.929 -1610.929 -1610.929] [0.0000], Avg: [-1326.666 -1326.666 -1326.666] (1.000)
Step: 38199, Reward: [-2200.742 -2200.742 -2200.742] [0.0000], Avg: [-1327.81 -1327.81 -1327.81] (1.000)
Step: 38249, Reward: [-1778.475 -1778.475 -1778.475] [0.0000], Avg: [-1328.4 -1328.4 -1328.4] (1.000)
Step: 38299, Reward: [-1838.53 -1838.53 -1838.53] [0.0000], Avg: [-1329.066 -1329.066 -1329.066] (1.000)
Step: 38349, Reward: [-2028.415 -2028.415 -2028.415] [0.0000], Avg: [-1329.977 -1329.977 -1329.977] (1.000)
Step: 38399, Reward: [-2113.447 -2113.447 -2113.447] [0.0000], Avg: [-1330.997 -1330.997 -1330.997] (1.000)
Step: 38449, Reward: [-1606.161 -1606.161 -1606.161] [0.0000], Avg: [-1331.355 -1331.355 -1331.355] (1.000)
Step: 38499, Reward: [-2189.781 -2189.781 -2189.781] [0.0000], Avg: [-1332.47 -1332.47 -1332.47] (1.000)
Step: 38549, Reward: [-1858.031 -1858.031 -1858.031] [0.0000], Avg: [-1333.152 -1333.152 -1333.152] (1.000)
Step: 38599, Reward: [-2043.707 -2043.707 -2043.707] [0.0000], Avg: [-1334.072 -1334.072 -1334.072] (1.000)
Step: 38649, Reward: [-1703.329 -1703.329 -1703.329] [0.0000], Avg: [-1334.55 -1334.55 -1334.55] (1.000)
Step: 38699, Reward: [-2085.086 -2085.086 -2085.086] [0.0000], Avg: [-1335.52 -1335.52 -1335.52] (1.000)
Step: 38749, Reward: [-1483.534 -1483.534 -1483.534] [0.0000], Avg: [-1335.711 -1335.711 -1335.711] (1.000)
Step: 38799, Reward: [-1794.124 -1794.124 -1794.124] [0.0000], Avg: [-1336.301 -1336.301 -1336.301] (1.000)
Step: 38849, Reward: [-1973.448 -1973.448 -1973.448] [0.0000], Avg: [-1337.121 -1337.121 -1337.121] (1.000)
Step: 38899, Reward: [-1816.086 -1816.086 -1816.086] [0.0000], Avg: [-1337.737 -1337.737 -1337.737] (1.000)
Step: 38949, Reward: [-1680.6 -1680.6 -1680.6] [0.0000], Avg: [-1338.177 -1338.177 -1338.177] (1.000)
Step: 38999, Reward: [-2111.169 -2111.169 -2111.169] [0.0000], Avg: [-1339.168 -1339.168 -1339.168] (1.000)
Step: 39049, Reward: [-2140.212 -2140.212 -2140.212] [0.0000], Avg: [-1340.194 -1340.194 -1340.194] (1.000)
Step: 39099, Reward: [-1699.618 -1699.618 -1699.618] [0.0000], Avg: [-1340.653 -1340.653 -1340.653] (1.000)
Step: 39149, Reward: [-2072.334 -2072.334 -2072.334] [0.0000], Avg: [-1341.588 -1341.588 -1341.588] (1.000)
Step: 39199, Reward: [-2365.686 -2365.686 -2365.686] [0.0000], Avg: [-1342.894 -1342.894 -1342.894] (1.000)
Step: 39249, Reward: [-2180.103 -2180.103 -2180.103] [0.0000], Avg: [-1343.961 -1343.961 -1343.961] (1.000)
Step: 39299, Reward: [-2072.64 -2072.64 -2072.64] [0.0000], Avg: [-1344.888 -1344.888 -1344.888] (1.000)
Step: 39349, Reward: [-1889.269 -1889.269 -1889.269] [0.0000], Avg: [-1345.579 -1345.579 -1345.579] (1.000)
Step: 39399, Reward: [-2265.266 -2265.266 -2265.266] [0.0000], Avg: [-1346.746 -1346.746 -1346.746] (1.000)
Step: 39449, Reward: [-1864.516 -1864.516 -1864.516] [0.0000], Avg: [-1347.403 -1347.403 -1347.403] (1.000)
Step: 39499, Reward: [-1812.033 -1812.033 -1812.033] [0.0000], Avg: [-1347.991 -1347.991 -1347.991] (1.000)
Step: 39549, Reward: [-1431.145 -1431.145 -1431.145] [0.0000], Avg: [-1348.096 -1348.096 -1348.096] (1.000)
Step: 39599, Reward: [-2131.998 -2131.998 -2131.998] [0.0000], Avg: [-1349.086 -1349.086 -1349.086] (1.000)
Step: 39649, Reward: [-1565.357 -1565.357 -1565.357] [0.0000], Avg: [-1349.358 -1349.358 -1349.358] (1.000)
Step: 39699, Reward: [-1731.259 -1731.259 -1731.259] [0.0000], Avg: [-1349.839 -1349.839 -1349.839] (1.000)
Step: 39749, Reward: [-1194.465 -1194.465 -1194.465] [0.0000], Avg: [-1349.644 -1349.644 -1349.644] (1.000)
Step: 39799, Reward: [-1087.921 -1087.921 -1087.921] [0.0000], Avg: [-1349.315 -1349.315 -1349.315] (1.000)
Step: 39849, Reward: [-1685.451 -1685.451 -1685.451] [0.0000], Avg: [-1349.737 -1349.737 -1349.737] (1.000)
Step: 39899, Reward: [-843.829 -843.829 -843.829] [0.0000], Avg: [-1349.103 -1349.103 -1349.103] (1.000)
Step: 39949, Reward: [-609.887 -609.887 -609.887] [0.0000], Avg: [-1348.178 -1348.178 -1348.178] (1.000)
Step: 39999, Reward: [-1142.165 -1142.165 -1142.165] [0.0000], Avg: [-1347.92 -1347.92 -1347.92] (1.000)
Step: 40049, Reward: [-1042.391 -1042.391 -1042.391] [0.0000], Avg: [-1347.539 -1347.539 -1347.539] (1.000)
Step: 40099, Reward: [-430.705 -430.705 -430.705] [0.0000], Avg: [-1346.396 -1346.396 -1346.396] (1.000)
Step: 40149, Reward: [-756.882 -756.882 -756.882] [0.0000], Avg: [-1345.662 -1345.662 -1345.662] (1.000)
Step: 40199, Reward: [-533.049 -533.049 -533.049] [0.0000], Avg: [-1344.651 -1344.651 -1344.651] (1.000)
Step: 40249, Reward: [-491.913 -491.913 -491.913] [0.0000], Avg: [-1343.592 -1343.592 -1343.592] (1.000)
Step: 40299, Reward: [-559.461 -559.461 -559.461] [0.0000], Avg: [-1342.619 -1342.619 -1342.619] (1.000)
Step: 40349, Reward: [-477.055 -477.055 -477.055] [0.0000], Avg: [-1341.546 -1341.546 -1341.546] (1.000)
Step: 40399, Reward: [-683.787 -683.787 -683.787] [0.0000], Avg: [-1340.732 -1340.732 -1340.732] (1.000)
Step: 40449, Reward: [-602.008 -602.008 -602.008] [0.0000], Avg: [-1339.819 -1339.819 -1339.819] (1.000)
Step: 40499, Reward: [-520.619 -520.619 -520.619] [0.0000], Avg: [-1338.808 -1338.808 -1338.808] (1.000)
Step: 40549, Reward: [-641.351 -641.351 -641.351] [0.0000], Avg: [-1337.948 -1337.948 -1337.948] (1.000)
Step: 40599, Reward: [-514.617 -514.617 -514.617] [0.0000], Avg: [-1336.934 -1336.934 -1336.934] (1.000)
Step: 40649, Reward: [-571.623 -571.623 -571.623] [0.0000], Avg: [-1335.992 -1335.992 -1335.992] (1.000)
Step: 40699, Reward: [-637.057 -637.057 -637.057] [0.0000], Avg: [-1335.134 -1335.134 -1335.134] (1.000)
Step: 40749, Reward: [-433.511 -433.511 -433.511] [0.0000], Avg: [-1334.027 -1334.027 -1334.027] (1.000)
Step: 40799, Reward: [-590.517 -590.517 -590.517] [0.0000], Avg: [-1333.116 -1333.116 -1333.116] (1.000)
Step: 40849, Reward: [-461.361 -461.361 -461.361] [0.0000], Avg: [-1332.049 -1332.049 -1332.049] (1.000)
Step: 40899, Reward: [-2327.012 -2327.012 -2327.012] [0.0000], Avg: [-1333.265 -1333.265 -1333.265] (1.000)
Step: 40949, Reward: [-520.729 -520.729 -520.729] [0.0000], Avg: [-1332.273 -1332.273 -1332.273] (1.000)
Step: 40999, Reward: [-845.996 -845.996 -845.996] [0.0000], Avg: [-1331.68 -1331.68 -1331.68] (1.000)
Step: 41049, Reward: [-1837.219 -1837.219 -1837.219] [0.0000], Avg: [-1332.296 -1332.296 -1332.296] (1.000)
Step: 41099, Reward: [-475.435 -475.435 -475.435] [0.0000], Avg: [-1331.254 -1331.254 -1331.254] (1.000)
Step: 41149, Reward: [-615.549 -615.549 -615.549] [0.0000], Avg: [-1330.384 -1330.384 -1330.384] (1.000)
Step: 41199, Reward: [-878.221 -878.221 -878.221] [0.0000], Avg: [-1329.835 -1329.835 -1329.835] (1.000)
Step: 41249, Reward: [-486.56 -486.56 -486.56] [0.0000], Avg: [-1328.813 -1328.813 -1328.813] (1.000)
Step: 41299, Reward: [-669.685 -669.685 -669.685] [0.0000], Avg: [-1328.015 -1328.015 -1328.015] (1.000)
Step: 41349, Reward: [-805.97 -805.97 -805.97] [0.0000], Avg: [-1327.384 -1327.384 -1327.384] (1.000)
Step: 41399, Reward: [-706.057 -706.057 -706.057] [0.0000], Avg: [-1326.634 -1326.634 -1326.634] (1.000)
Step: 41449, Reward: [-1038.53 -1038.53 -1038.53] [0.0000], Avg: [-1326.286 -1326.286 -1326.286] (1.000)
Step: 41499, Reward: [-744.234 -744.234 -744.234] [0.0000], Avg: [-1325.585 -1325.585 -1325.585] (1.000)
Step: 41549, Reward: [-919.151 -919.151 -919.151] [0.0000], Avg: [-1325.096 -1325.096 -1325.096] (1.000)
Step: 41599, Reward: [-1183.335 -1183.335 -1183.335] [0.0000], Avg: [-1324.925 -1324.925 -1324.925] (1.000)
Step: 41649, Reward: [-1436.361 -1436.361 -1436.361] [0.0000], Avg: [-1325.059 -1325.059 -1325.059] (1.000)
Step: 41699, Reward: [-1407.075 -1407.075 -1407.075] [0.0000], Avg: [-1325.157 -1325.157 -1325.157] (1.000)
Step: 41749, Reward: [-1849.102 -1849.102 -1849.102] [0.0000], Avg: [-1325.785 -1325.785 -1325.785] (1.000)
Step: 41799, Reward: [-1400.231 -1400.231 -1400.231] [0.0000], Avg: [-1325.874 -1325.874 -1325.874] (1.000)
Step: 41849, Reward: [-1938.108 -1938.108 -1938.108] [0.0000], Avg: [-1326.605 -1326.605 -1326.605] (1.000)
Step: 41899, Reward: [-1808.575 -1808.575 -1808.575] [0.0000], Avg: [-1327.181 -1327.181 -1327.181] (1.000)
Step: 41949, Reward: [-1877.819 -1877.819 -1877.819] [0.0000], Avg: [-1327.837 -1327.837 -1327.837] (1.000)
Step: 41999, Reward: [-1804.472 -1804.472 -1804.472] [0.0000], Avg: [-1328.404 -1328.404 -1328.404] (1.000)
Step: 42049, Reward: [-1910.939 -1910.939 -1910.939] [0.0000], Avg: [-1329.097 -1329.097 -1329.097] (1.000)
Step: 42099, Reward: [-1847.355 -1847.355 -1847.355] [0.0000], Avg: [-1329.712 -1329.712 -1329.712] (1.000)
Step: 42149, Reward: [-2187.138 -2187.138 -2187.138] [0.0000], Avg: [-1330.73 -1330.73 -1330.73] (1.000)
Step: 42199, Reward: [-2124.534 -2124.534 -2124.534] [0.0000], Avg: [-1331.67 -1331.67 -1331.67] (1.000)
Step: 42249, Reward: [-1741.689 -1741.689 -1741.689] [0.0000], Avg: [-1332.155 -1332.155 -1332.155] (1.000)
Step: 42299, Reward: [-1871.729 -1871.729 -1871.729] [0.0000], Avg: [-1332.793 -1332.793 -1332.793] (1.000)
Step: 42349, Reward: [-1938.241 -1938.241 -1938.241] [0.0000], Avg: [-1333.508 -1333.508 -1333.508] (1.000)
Step: 42399, Reward: [-1931.588 -1931.588 -1931.588] [0.0000], Avg: [-1334.213 -1334.213 -1334.213] (1.000)
Step: 42449, Reward: [-2060.718 -2060.718 -2060.718] [0.0000], Avg: [-1335.069 -1335.069 -1335.069] (1.000)
Step: 42499, Reward: [-1968.596 -1968.596 -1968.596] [0.0000], Avg: [-1335.814 -1335.814 -1335.814] (1.000)
Step: 42549, Reward: [-1659.994 -1659.994 -1659.994] [0.0000], Avg: [-1336.195 -1336.195 -1336.195] (1.000)
Step: 42599, Reward: [-1905.216 -1905.216 -1905.216] [0.0000], Avg: [-1336.863 -1336.863 -1336.863] (1.000)
Step: 42649, Reward: [-2139.756 -2139.756 -2139.756] [0.0000], Avg: [-1337.804 -1337.804 -1337.804] (1.000)
Step: 42699, Reward: [-1792.891 -1792.891 -1792.891] [0.0000], Avg: [-1338.337 -1338.337 -1338.337] (1.000)
Step: 42749, Reward: [-1407.159 -1407.159 -1407.159] [0.0000], Avg: [-1338.418 -1338.418 -1338.418] (1.000)
Step: 42799, Reward: [-1801.068 -1801.068 -1801.068] [0.0000], Avg: [-1338.958 -1338.958 -1338.958] (1.000)
Step: 42849, Reward: [-1913.765 -1913.765 -1913.765] [0.0000], Avg: [-1339.629 -1339.629 -1339.629] (1.000)
Step: 42899, Reward: [-1408.997 -1408.997 -1408.997] [0.0000], Avg: [-1339.71 -1339.71 -1339.71] (1.000)
Step: 42949, Reward: [-1869.877 -1869.877 -1869.877] [0.0000], Avg: [-1340.327 -1340.327 -1340.327] (1.000)
Step: 42999, Reward: [-2085.978 -2085.978 -2085.978] [0.0000], Avg: [-1341.194 -1341.194 -1341.194] (1.000)
Step: 43049, Reward: [-2048.152 -2048.152 -2048.152] [0.0000], Avg: [-1342.015 -1342.015 -1342.015] (1.000)
Step: 43099, Reward: [-1793.503 -1793.503 -1793.503] [0.0000], Avg: [-1342.539 -1342.539 -1342.539] (1.000)
Step: 43149, Reward: [-1814.363 -1814.363 -1814.363] [0.0000], Avg: [-1343.086 -1343.086 -1343.086] (1.000)
Step: 43199, Reward: [-1824.97 -1824.97 -1824.97] [0.0000], Avg: [-1343.643 -1343.643 -1343.643] (1.000)
Step: 43249, Reward: [-1495.33 -1495.33 -1495.33] [0.0000], Avg: [-1343.819 -1343.819 -1343.819] (1.000)
Step: 43299, Reward: [-1874.084 -1874.084 -1874.084] [0.0000], Avg: [-1344.431 -1344.431 -1344.431] (1.000)
Step: 43349, Reward: [-1192.34 -1192.34 -1192.34] [0.0000], Avg: [-1344.256 -1344.256 -1344.256] (1.000)
Step: 43399, Reward: [-1476.658 -1476.658 -1476.658] [0.0000], Avg: [-1344.408 -1344.408 -1344.408] (1.000)
Step: 43449, Reward: [-1312.966 -1312.966 -1312.966] [0.0000], Avg: [-1344.372 -1344.372 -1344.372] (1.000)
Step: 43499, Reward: [-1657.608 -1657.608 -1657.608] [0.0000], Avg: [-1344.732 -1344.732 -1344.732] (1.000)
Step: 43549, Reward: [-1295.889 -1295.889 -1295.889] [0.0000], Avg: [-1344.676 -1344.676 -1344.676] (1.000)
Step: 43599, Reward: [-1575.208 -1575.208 -1575.208] [0.0000], Avg: [-1344.94 -1344.94 -1344.94] (1.000)
Step: 43649, Reward: [-1358.897 -1358.897 -1358.897] [0.0000], Avg: [-1344.956 -1344.956 -1344.956] (1.000)
Step: 43699, Reward: [-1645.246 -1645.246 -1645.246] [0.0000], Avg: [-1345.3 -1345.3 -1345.3] (1.000)
Step: 43749, Reward: [-666.628 -666.628 -666.628] [0.0000], Avg: [-1344.524 -1344.524 -1344.524] (1.000)
Step: 43799, Reward: [-1712.756 -1712.756 -1712.756] [0.0000], Avg: [-1344.945 -1344.945 -1344.945] (1.000)
Step: 43849, Reward: [-1409.605 -1409.605 -1409.605] [0.0000], Avg: [-1345.018 -1345.018 -1345.018] (1.000)
Step: 43899, Reward: [-1436.311 -1436.311 -1436.311] [0.0000], Avg: [-1345.122 -1345.122 -1345.122] (1.000)
Step: 43949, Reward: [-1447.795 -1447.795 -1447.795] [0.0000], Avg: [-1345.239 -1345.239 -1345.239] (1.000)
Step: 43999, Reward: [-1150.751 -1150.751 -1150.751] [0.0000], Avg: [-1345.018 -1345.018 -1345.018] (1.000)
Step: 44049, Reward: [-1166.214 -1166.214 -1166.214] [0.0000], Avg: [-1344.815 -1344.815 -1344.815] (1.000)
Step: 44099, Reward: [-1150.022 -1150.022 -1150.022] [0.0000], Avg: [-1344.594 -1344.594 -1344.594] (1.000)
Step: 44149, Reward: [-1194.837 -1194.837 -1194.837] [0.0000], Avg: [-1344.425 -1344.425 -1344.425] (1.000)
Step: 44199, Reward: [-1053.969 -1053.969 -1053.969] [0.0000], Avg: [-1344.096 -1344.096 -1344.096] (1.000)
Step: 44249, Reward: [-879.889 -879.889 -879.889] [0.0000], Avg: [-1343.572 -1343.572 -1343.572] (1.000)
Step: 44299, Reward: [-973.209 -973.209 -973.209] [0.0000], Avg: [-1343.154 -1343.154 -1343.154] (1.000)
Step: 44349, Reward: [-897.785 -897.785 -897.785] [0.0000], Avg: [-1342.651 -1342.651 -1342.651] (1.000)
Step: 44399, Reward: [-796.857 -796.857 -796.857] [0.0000], Avg: [-1342.037 -1342.037 -1342.037] (1.000)
Step: 44449, Reward: [-601.248 -601.248 -601.248] [0.0000], Avg: [-1341.203 -1341.203 -1341.203] (1.000)
Step: 44499, Reward: [-826.62 -826.62 -826.62] [0.0000], Avg: [-1340.625 -1340.625 -1340.625] (1.000)
Step: 44549, Reward: [-711.951 -711.951 -711.951] [0.0000], Avg: [-1339.92 -1339.92 -1339.92] (1.000)
Step: 44599, Reward: [-660.588 -660.588 -660.588] [0.0000], Avg: [-1339.158 -1339.158 -1339.158] (1.000)
Step: 44649, Reward: [-676.18 -676.18 -676.18] [0.0000], Avg: [-1338.416 -1338.416 -1338.416] (1.000)
Step: 44699, Reward: [-586.94 -586.94 -586.94] [0.0000], Avg: [-1337.575 -1337.575 -1337.575] (1.000)
Step: 44749, Reward: [-773.226 -773.226 -773.226] [0.0000], Avg: [-1336.945 -1336.945 -1336.945] (1.000)
Step: 44799, Reward: [-666.792 -666.792 -666.792] [0.0000], Avg: [-1336.197 -1336.197 -1336.197] (1.000)
Step: 44849, Reward: [-769.307 -769.307 -769.307] [0.0000], Avg: [-1335.565 -1335.565 -1335.565] (1.000)
Step: 44899, Reward: [-539.104 -539.104 -539.104] [0.0000], Avg: [-1334.678 -1334.678 -1334.678] (1.000)
Step: 44949, Reward: [-504.253 -504.253 -504.253] [0.0000], Avg: [-1333.754 -1333.754 -1333.754] (1.000)
Step: 44999, Reward: [-535.623 -535.623 -535.623] [0.0000], Avg: [-1332.867 -1332.867 -1332.867] (1.000)
Step: 45049, Reward: [-494.719 -494.719 -494.719] [0.0000], Avg: [-1331.937 -1331.937 -1331.937] (1.000)
Step: 45099, Reward: [-807.354 -807.354 -807.354] [0.0000], Avg: [-1331.355 -1331.355 -1331.355] (1.000)
Step: 45149, Reward: [-761.225 -761.225 -761.225] [0.0000], Avg: [-1330.724 -1330.724 -1330.724] (1.000)
Step: 45199, Reward: [-603.826 -603.826 -603.826] [0.0000], Avg: [-1329.92 -1329.92 -1329.92] (1.000)
Step: 45249, Reward: [-665.506 -665.506 -665.506] [0.0000], Avg: [-1329.186 -1329.186 -1329.186] (1.000)
Step: 45299, Reward: [-604.724 -604.724 -604.724] [0.0000], Avg: [-1328.386 -1328.386 -1328.386] (1.000)
Step: 45349, Reward: [-1097.831 -1097.831 -1097.831] [0.0000], Avg: [-1328.132 -1328.132 -1328.132] (1.000)
Step: 45399, Reward: [-714.453 -714.453 -714.453] [0.0000], Avg: [-1327.456 -1327.456 -1327.456] (1.000)
Step: 45449, Reward: [-581.995 -581.995 -581.995] [0.0000], Avg: [-1326.636 -1326.636 -1326.636] (1.000)
Step: 45499, Reward: [-258.688 -258.688 -258.688] [0.0000], Avg: [-1325.462 -1325.462 -1325.462] (1.000)
Step: 45549, Reward: [-543.928 -543.928 -543.928] [0.0000], Avg: [-1324.605 -1324.605 -1324.605] (1.000)
Step: 45599, Reward: [-709.699 -709.699 -709.699] [0.0000], Avg: [-1323.93 -1323.93 -1323.93] (1.000)
Step: 45649, Reward: [-807.507 -807.507 -807.507] [0.0000], Avg: [-1323.365 -1323.365 -1323.365] (1.000)
Step: 45699, Reward: [-597.837 -597.837 -597.837] [0.0000], Avg: [-1322.571 -1322.571 -1322.571] (1.000)
Step: 45749, Reward: [-449.597 -449.597 -449.597] [0.0000], Avg: [-1321.617 -1321.617 -1321.617] (1.000)
Step: 45799, Reward: [-405.297 -405.297 -405.297] [0.0000], Avg: [-1320.616 -1320.616 -1320.616] (1.000)
Step: 45849, Reward: [-432.104 -432.104 -432.104] [0.0000], Avg: [-1319.648 -1319.648 -1319.648] (1.000)
Step: 45899, Reward: [-1885.953 -1885.953 -1885.953] [0.0000], Avg: [-1320.264 -1320.264 -1320.264] (1.000)
Step: 45949, Reward: [-618.594 -618.594 -618.594] [0.0000], Avg: [-1319.501 -1319.501 -1319.501] (1.000)
Step: 45999, Reward: [-1723.992 -1723.992 -1723.992] [0.0000], Avg: [-1319.941 -1319.941 -1319.941] (1.000)
Step: 46049, Reward: [-674.879 -674.879 -674.879] [0.0000], Avg: [-1319.24 -1319.24 -1319.24] (1.000)
Step: 46099, Reward: [-749.454 -749.454 -749.454] [0.0000], Avg: [-1318.622 -1318.622 -1318.622] (1.000)
Step: 46149, Reward: [-410.851 -410.851 -410.851] [0.0000], Avg: [-1317.639 -1317.639 -1317.639] (1.000)
Step: 46199, Reward: [-735.414 -735.414 -735.414] [0.0000], Avg: [-1317.009 -1317.009 -1317.009] (1.000)
Step: 46249, Reward: [-520.038 -520.038 -520.038] [0.0000], Avg: [-1316.147 -1316.147 -1316.147] (1.000)
Step: 46299, Reward: [-894.9 -894.9 -894.9] [0.0000], Avg: [-1315.692 -1315.692 -1315.692] (1.000)
Step: 46349, Reward: [-614.722 -614.722 -614.722] [0.0000], Avg: [-1314.936 -1314.936 -1314.936] (1.000)
Step: 46399, Reward: [-780.749 -780.749 -780.749] [0.0000], Avg: [-1314.36 -1314.36 -1314.36] (1.000)
Step: 46449, Reward: [-684.582 -684.582 -684.582] [0.0000], Avg: [-1313.682 -1313.682 -1313.682] (1.000)
Step: 46499, Reward: [-2058.72 -2058.72 -2058.72] [0.0000], Avg: [-1314.483 -1314.483 -1314.483] (1.000)
Step: 46549, Reward: [-462.429 -462.429 -462.429] [0.0000], Avg: [-1313.568 -1313.568 -1313.568] (1.000)
Step: 46599, Reward: [-657.412 -657.412 -657.412] [0.0000], Avg: [-1312.864 -1312.864 -1312.864] (1.000)
Step: 46649, Reward: [-621.119 -621.119 -621.119] [0.0000], Avg: [-1312.123 -1312.123 -1312.123] (1.000)
Step: 46699, Reward: [-1531.196 -1531.196 -1531.196] [0.0000], Avg: [-1312.357 -1312.357 -1312.357] (1.000)
Step: 46749, Reward: [-1575.626 -1575.626 -1575.626] [0.0000], Avg: [-1312.639 -1312.639 -1312.639] (1.000)
Step: 46799, Reward: [-780.025 -780.025 -780.025] [0.0000], Avg: [-1312.07 -1312.07 -1312.07] (1.000)
Step: 46849, Reward: [-870.205 -870.205 -870.205] [0.0000], Avg: [-1311.598 -1311.598 -1311.598] (1.000)
Step: 46899, Reward: [-1969.3 -1969.3 -1969.3] [0.0000], Avg: [-1312.299 -1312.299 -1312.299] (1.000)
Step: 46949, Reward: [-1624.562 -1624.562 -1624.562] [0.0000], Avg: [-1312.632 -1312.632 -1312.632] (1.000)
Step: 46999, Reward: [-657.793 -657.793 -657.793] [0.0000], Avg: [-1311.935 -1311.935 -1311.935] (1.000)
Step: 47049, Reward: [-1812.902 -1812.902 -1812.902] [0.0000], Avg: [-1312.468 -1312.468 -1312.468] (1.000)
Step: 47099, Reward: [-691.083 -691.083 -691.083] [0.0000], Avg: [-1311.808 -1311.808 -1311.808] (1.000)
Step: 47149, Reward: [-1464.02 -1464.02 -1464.02] [0.0000], Avg: [-1311.97 -1311.97 -1311.97] (1.000)
Step: 47199, Reward: [-1029.403 -1029.403 -1029.403] [0.0000], Avg: [-1311.67 -1311.67 -1311.67] (1.000)
Step: 47249, Reward: [-968.858 -968.858 -968.858] [0.0000], Avg: [-1311.307 -1311.307 -1311.307] (1.000)
Step: 47299, Reward: [-672.517 -672.517 -672.517] [0.0000], Avg: [-1310.632 -1310.632 -1310.632] (1.000)
Step: 47349, Reward: [-2054.855 -2054.855 -2054.855] [0.0000], Avg: [-1311.418 -1311.418 -1311.418] (1.000)
Step: 47399, Reward: [-1362.135 -1362.135 -1362.135] [0.0000], Avg: [-1311.472 -1311.472 -1311.472] (1.000)
Step: 47449, Reward: [-1657.875 -1657.875 -1657.875] [0.0000], Avg: [-1311.837 -1311.837 -1311.837] (1.000)
Step: 47499, Reward: [-887.14 -887.14 -887.14] [0.0000], Avg: [-1311.39 -1311.39 -1311.39] (1.000)
Step: 47549, Reward: [-757.667 -757.667 -757.667] [0.0000], Avg: [-1310.807 -1310.807 -1310.807] (1.000)
Step: 47599, Reward: [-2215.08 -2215.08 -2215.08] [0.0000], Avg: [-1311.757 -1311.757 -1311.757] (1.000)
Step: 47649, Reward: [-1849.928 -1849.928 -1849.928] [0.0000], Avg: [-1312.322 -1312.322 -1312.322] (1.000)
Step: 47699, Reward: [-1708.935 -1708.935 -1708.935] [0.0000], Avg: [-1312.738 -1312.738 -1312.738] (1.000)
Step: 47749, Reward: [-1398.518 -1398.518 -1398.518] [0.0000], Avg: [-1312.827 -1312.827 -1312.827] (1.000)
Step: 47799, Reward: [-1472.851 -1472.851 -1472.851] [0.0000], Avg: [-1312.995 -1312.995 -1312.995] (1.000)
Step: 47849, Reward: [-1461.274 -1461.274 -1461.274] [0.0000], Avg: [-1313.15 -1313.15 -1313.15] (1.000)
Step: 47899, Reward: [-818.511 -818.511 -818.511] [0.0000], Avg: [-1312.633 -1312.633 -1312.633] (1.000)
Step: 47949, Reward: [-1622.19 -1622.19 -1622.19] [0.0000], Avg: [-1312.956 -1312.956 -1312.956] (1.000)
Step: 47999, Reward: [-1578.246 -1578.246 -1578.246] [0.0000], Avg: [-1313.233 -1313.233 -1313.233] (1.000)
Step: 48049, Reward: [-1376.975 -1376.975 -1376.975] [0.0000], Avg: [-1313.299 -1313.299 -1313.299] (1.000)
Step: 48099, Reward: [-1268.282 -1268.282 -1268.282] [0.0000], Avg: [-1313.252 -1313.252 -1313.252] (1.000)
Step: 48149, Reward: [-1104.195 -1104.195 -1104.195] [0.0000], Avg: [-1313.035 -1313.035 -1313.035] (1.000)
Step: 48199, Reward: [-1034.012 -1034.012 -1034.012] [0.0000], Avg: [-1312.746 -1312.746 -1312.746] (1.000)
Step: 48249, Reward: [-1448.717 -1448.717 -1448.717] [0.0000], Avg: [-1312.886 -1312.886 -1312.886] (1.000)
Step: 48299, Reward: [-1004.436 -1004.436 -1004.436] [0.0000], Avg: [-1312.567 -1312.567 -1312.567] (1.000)
Step: 48349, Reward: [-1169.479 -1169.479 -1169.479] [0.0000], Avg: [-1312.419 -1312.419 -1312.419] (1.000)
Step: 48399, Reward: [-1181.475 -1181.475 -1181.475] [0.0000], Avg: [-1312.284 -1312.284 -1312.284] (1.000)
Step: 48449, Reward: [-1655.961 -1655.961 -1655.961] [0.0000], Avg: [-1312.639 -1312.639 -1312.639] (1.000)
Step: 48499, Reward: [-1830.619 -1830.619 -1830.619] [0.0000], Avg: [-1313.173 -1313.173 -1313.173] (1.000)
Step: 48549, Reward: [-2008.6 -2008.6 -2008.6] [0.0000], Avg: [-1313.889 -1313.889 -1313.889] (1.000)
Step: 48599, Reward: [-1212.265 -1212.265 -1212.265] [0.0000], Avg: [-1313.784 -1313.784 -1313.784] (1.000)
Step: 48649, Reward: [-1491.293 -1491.293 -1491.293] [0.0000], Avg: [-1313.967 -1313.967 -1313.967] (1.000)
Step: 48699, Reward: [-2209.473 -2209.473 -2209.473] [0.0000], Avg: [-1314.886 -1314.886 -1314.886] (1.000)
Step: 48749, Reward: [-1816.394 -1816.394 -1816.394] [0.0000], Avg: [-1315.4 -1315.4 -1315.4] (1.000)
Step: 48799, Reward: [-2066.631 -2066.631 -2066.631] [0.0000], Avg: [-1316.17 -1316.17 -1316.17] (1.000)
Step: 48849, Reward: [-1583.81 -1583.81 -1583.81] [0.0000], Avg: [-1316.444 -1316.444 -1316.444] (1.000)
Step: 48899, Reward: [-1620.655 -1620.655 -1620.655] [0.0000], Avg: [-1316.755 -1316.755 -1316.755] (1.000)
Step: 48949, Reward: [-2107.129 -2107.129 -2107.129] [0.0000], Avg: [-1317.562 -1317.562 -1317.562] (1.000)
Step: 48999, Reward: [-1746.452 -1746.452 -1746.452] [0.0000], Avg: [-1318. -1318. -1318.] (1.000)
Step: 49049, Reward: [-1466.846 -1466.846 -1466.846] [0.0000], Avg: [-1318.152 -1318.152 -1318.152] (1.000)
Step: 49099, Reward: [-2058.592 -2058.592 -2058.592] [0.0000], Avg: [-1318.906 -1318.906 -1318.906] (1.000)
Step: 49149, Reward: [-2059.036 -2059.036 -2059.036] [0.0000], Avg: [-1319.659 -1319.659 -1319.659] (1.000)
Step: 49199, Reward: [-1362.4 -1362.4 -1362.4] [0.0000], Avg: [-1319.702 -1319.702 -1319.702] (1.000)
Step: 49249, Reward: [-2031.277 -2031.277 -2031.277] [0.0000], Avg: [-1320.425 -1320.425 -1320.425] (1.000)
Step: 49299, Reward: [-1850.307 -1850.307 -1850.307] [0.0000], Avg: [-1320.962 -1320.962 -1320.962] (1.000)
Step: 49349, Reward: [-2061.773 -2061.773 -2061.773] [0.0000], Avg: [-1321.713 -1321.713 -1321.713] (1.000)
Step: 49399, Reward: [-1732.211 -1732.211 -1732.211] [0.0000], Avg: [-1322.128 -1322.128 -1322.128] (1.000)
Step: 49449, Reward: [-1157.291 -1157.291 -1157.291] [0.0000], Avg: [-1321.961 -1321.961 -1321.961] (1.000)
Step: 49499, Reward: [-2086.941 -2086.941 -2086.941] [0.0000], Avg: [-1322.734 -1322.734 -1322.734] (1.000)
Step: 49549, Reward: [-1720.587 -1720.587 -1720.587] [0.0000], Avg: [-1323.136 -1323.136 -1323.136] (1.000)
Step: 49599, Reward: [-1796.791 -1796.791 -1796.791] [0.0000], Avg: [-1323.613 -1323.613 -1323.613] (1.000)
Step: 49649, Reward: [-1597.045 -1597.045 -1597.045] [0.0000], Avg: [-1323.888 -1323.888 -1323.888] (1.000)
Step: 49699, Reward: [-2054.995 -2054.995 -2054.995] [0.0000], Avg: [-1324.624 -1324.624 -1324.624] (1.000)
Step: 49749, Reward: [-1541.765 -1541.765 -1541.765] [0.0000], Avg: [-1324.842 -1324.842 -1324.842] (1.000)
Step: 49799, Reward: [-1811.738 -1811.738 -1811.738] [0.0000], Avg: [-1325.331 -1325.331 -1325.331] (1.000)
Step: 49849, Reward: [-1905.722 -1905.722 -1905.722] [0.0000], Avg: [-1325.913 -1325.913 -1325.913] (1.000)
Step: 49899, Reward: [-2033.668 -2033.668 -2033.668] [0.0000], Avg: [-1326.622 -1326.622 -1326.622] (1.000)
Step: 49949, Reward: [-1329.594 -1329.594 -1329.594] [0.0000], Avg: [-1326.625 -1326.625 -1326.625] (1.000)
Step: 49999, Reward: [-1316.48 -1316.48 -1316.48] [0.0000], Avg: [-1326.615 -1326.615 -1326.615] (1.000)
Step: 50049, Reward: [-1840.208 -1840.208 -1840.208] [0.0000], Avg: [-1327.128 -1327.128 -1327.128] (1.000)
Step: 50099, Reward: [-1352.352 -1352.352 -1352.352] [0.0000], Avg: [-1327.153 -1327.153 -1327.153] (1.000)
Step: 50149, Reward: [-940.034 -940.034 -940.034] [0.0000], Avg: [-1326.767 -1326.767 -1326.767] (1.000)
Step: 50199, Reward: [-999.48 -999.48 -999.48] [0.0000], Avg: [-1326.441 -1326.441 -1326.441] (1.000)
Step: 50249, Reward: [-777.279 -777.279 -777.279] [0.0000], Avg: [-1325.895 -1325.895 -1325.895] (1.000)
Step: 50299, Reward: [-1451.65 -1451.65 -1451.65] [0.0000], Avg: [-1326.02 -1326.02 -1326.02] (1.000)
Step: 50349, Reward: [-716.598 -716.598 -716.598] [0.0000], Avg: [-1325.415 -1325.415 -1325.415] (1.000)
Step: 50399, Reward: [-620.815 -620.815 -620.815] [0.0000], Avg: [-1324.716 -1324.716 -1324.716] (1.000)
Step: 50449, Reward: [-575.583 -575.583 -575.583] [0.0000], Avg: [-1323.973 -1323.973 -1323.973] (1.000)
Step: 50499, Reward: [-617.434 -617.434 -617.434] [0.0000], Avg: [-1323.274 -1323.274 -1323.274] (1.000)
Step: 50549, Reward: [-731.051 -731.051 -731.051] [0.0000], Avg: [-1322.688 -1322.688 -1322.688] (1.000)
Step: 50599, Reward: [-591.458 -591.458 -591.458] [0.0000], Avg: [-1321.966 -1321.966 -1321.966] (1.000)
Step: 50649, Reward: [-622.893 -622.893 -622.893] [0.0000], Avg: [-1321.275 -1321.275 -1321.275] (1.000)
Step: 50699, Reward: [-797.583 -797.583 -797.583] [0.0000], Avg: [-1320.759 -1320.759 -1320.759] (1.000)
Step: 50749, Reward: [-966.884 -966.884 -966.884] [0.0000], Avg: [-1320.41 -1320.41 -1320.41] (1.000)
Step: 50799, Reward: [-668.564 -668.564 -668.564] [0.0000], Avg: [-1319.769 -1319.769 -1319.769] (1.000)
Step: 50849, Reward: [-683.034 -683.034 -683.034] [0.0000], Avg: [-1319.143 -1319.143 -1319.143] (1.000)
Step: 50899, Reward: [-978.394 -978.394 -978.394] [0.0000], Avg: [-1318.808 -1318.808 -1318.808] (1.000)
Step: 50949, Reward: [-700.512 -700.512 -700.512] [0.0000], Avg: [-1318.201 -1318.201 -1318.201] (1.000)
Step: 50999, Reward: [-1175.352 -1175.352 -1175.352] [0.0000], Avg: [-1318.061 -1318.061 -1318.061] (1.000)
Step: 51049, Reward: [-700.736 -700.736 -700.736] [0.0000], Avg: [-1317.456 -1317.456 -1317.456] (1.000)
Step: 51099, Reward: [-1122.443 -1122.443 -1122.443] [0.0000], Avg: [-1317.266 -1317.266 -1317.266] (1.000)
Step: 51149, Reward: [-1000.99 -1000.99 -1000.99] [0.0000], Avg: [-1316.957 -1316.957 -1316.957] (1.000)
Step: 51199, Reward: [-1505.213 -1505.213 -1505.213] [0.0000], Avg: [-1317.14 -1317.14 -1317.14] (1.000)
Step: 51249, Reward: [-1665.169 -1665.169 -1665.169] [0.0000], Avg: [-1317.48 -1317.48 -1317.48] (1.000)
Step: 51299, Reward: [-1030.392 -1030.392 -1030.392] [0.0000], Avg: [-1317.2 -1317.2 -1317.2] (1.000)
Step: 51349, Reward: [-1209.238 -1209.238 -1209.238] [0.0000], Avg: [-1317.095 -1317.095 -1317.095] (1.000)
Step: 51399, Reward: [-1464.624 -1464.624 -1464.624] [0.0000], Avg: [-1317.238 -1317.238 -1317.238] (1.000)
Step: 51449, Reward: [-2172.057 -2172.057 -2172.057] [0.0000], Avg: [-1318.069 -1318.069 -1318.069] (1.000)
Step: 51499, Reward: [-1107.434 -1107.434 -1107.434] [0.0000], Avg: [-1317.865 -1317.865 -1317.865] (1.000)
Step: 51549, Reward: [-2169.398 -2169.398 -2169.398] [0.0000], Avg: [-1318.691 -1318.691 -1318.691] (1.000)
Step: 51599, Reward: [-1980.752 -1980.752 -1980.752] [0.0000], Avg: [-1319.332 -1319.332 -1319.332] (1.000)
Step: 51649, Reward: [-2012.353 -2012.353 -2012.353] [0.0000], Avg: [-1320.003 -1320.003 -1320.003] (1.000)
Step: 51699, Reward: [-1788.474 -1788.474 -1788.474] [0.0000], Avg: [-1320.456 -1320.456 -1320.456] (1.000)
Step: 51749, Reward: [-2142.31 -2142.31 -2142.31] [0.0000], Avg: [-1321.25 -1321.25 -1321.25] (1.000)
Step: 51799, Reward: [-1806.255 -1806.255 -1806.255] [0.0000], Avg: [-1321.718 -1321.718 -1321.718] (1.000)
Step: 51849, Reward: [-1065.399 -1065.399 -1065.399] [0.0000], Avg: [-1321.471 -1321.471 -1321.471] (1.000)
Step: 51899, Reward: [-1687.466 -1687.466 -1687.466] [0.0000], Avg: [-1321.824 -1321.824 -1321.824] (1.000)
Step: 51949, Reward: [-2038.053 -2038.053 -2038.053] [0.0000], Avg: [-1322.513 -1322.513 -1322.513] (1.000)
Step: 51999, Reward: [-998.338 -998.338 -998.338] [0.0000], Avg: [-1322.201 -1322.201 -1322.201] (1.000)
Step: 52049, Reward: [-2043.539 -2043.539 -2043.539] [0.0000], Avg: [-1322.894 -1322.894 -1322.894] (1.000)
Step: 52099, Reward: [-863.941 -863.941 -863.941] [0.0000], Avg: [-1322.454 -1322.454 -1322.454] (1.000)
Step: 52149, Reward: [-1739.235 -1739.235 -1739.235] [0.0000], Avg: [-1322.853 -1322.853 -1322.853] (1.000)
Step: 52199, Reward: [-2327.822 -2327.822 -2327.822] [0.0000], Avg: [-1323.816 -1323.816 -1323.816] (1.000)
Step: 52249, Reward: [-1651.447 -1651.447 -1651.447] [0.0000], Avg: [-1324.13 -1324.13 -1324.13] (1.000)
Step: 52299, Reward: [-1592.246 -1592.246 -1592.246] [0.0000], Avg: [-1324.386 -1324.386 -1324.386] (1.000)
Step: 52349, Reward: [-1575.482 -1575.482 -1575.482] [0.0000], Avg: [-1324.626 -1324.626 -1324.626] (1.000)
Step: 52399, Reward: [-887.926 -887.926 -887.926] [0.0000], Avg: [-1324.209 -1324.209 -1324.209] (1.000)
Step: 52449, Reward: [-1318.736 -1318.736 -1318.736] [0.0000], Avg: [-1324.204 -1324.204 -1324.204] (1.000)
Step: 52499, Reward: [-1362.795 -1362.795 -1362.795] [0.0000], Avg: [-1324.241 -1324.241 -1324.241] (1.000)
Step: 52549, Reward: [-1463.935 -1463.935 -1463.935] [0.0000], Avg: [-1324.373 -1324.373 -1324.373] (1.000)
Step: 52599, Reward: [-1553.72 -1553.72 -1553.72] [0.0000], Avg: [-1324.591 -1324.591 -1324.591] (1.000)
Step: 52649, Reward: [-1663.444 -1663.444 -1663.444] [0.0000], Avg: [-1324.913 -1324.913 -1324.913] (1.000)
Step: 52699, Reward: [-1672.319 -1672.319 -1672.319] [0.0000], Avg: [-1325.243 -1325.243 -1325.243] (1.000)
Step: 52749, Reward: [-1456.134 -1456.134 -1456.134] [0.0000], Avg: [-1325.367 -1325.367 -1325.367] (1.000)
Step: 52799, Reward: [-1918.535 -1918.535 -1918.535] [0.0000], Avg: [-1325.929 -1325.929 -1325.929] (1.000)
Step: 52849, Reward: [-1511.025 -1511.025 -1511.025] [0.0000], Avg: [-1326.104 -1326.104 -1326.104] (1.000)
Step: 52899, Reward: [-2004.491 -2004.491 -2004.491] [0.0000], Avg: [-1326.745 -1326.745 -1326.745] (1.000)
Step: 52949, Reward: [-1747.519 -1747.519 -1747.519] [0.0000], Avg: [-1327.142 -1327.142 -1327.142] (1.000)
Step: 52999, Reward: [-1409.157 -1409.157 -1409.157] [0.0000], Avg: [-1327.22 -1327.22 -1327.22] (1.000)
Step: 53049, Reward: [-1684.293 -1684.293 -1684.293] [0.0000], Avg: [-1327.556 -1327.556 -1327.556] (1.000)
Step: 53099, Reward: [-1930.139 -1930.139 -1930.139] [0.0000], Avg: [-1328.124 -1328.124 -1328.124] (1.000)
Step: 53149, Reward: [-1530.41 -1530.41 -1530.41] [0.0000], Avg: [-1328.314 -1328.314 -1328.314] (1.000)
Step: 53199, Reward: [-1484.9 -1484.9 -1484.9] [0.0000], Avg: [-1328.461 -1328.461 -1328.461] (1.000)
Step: 53249, Reward: [-1590.826 -1590.826 -1590.826] [0.0000], Avg: [-1328.707 -1328.707 -1328.707] (1.000)
Step: 53299, Reward: [-1518.003 -1518.003 -1518.003] [0.0000], Avg: [-1328.885 -1328.885 -1328.885] (1.000)
Step: 53349, Reward: [-1765.275 -1765.275 -1765.275] [0.0000], Avg: [-1329.294 -1329.294 -1329.294] (1.000)
Step: 53399, Reward: [-1479.842 -1479.842 -1479.842] [0.0000], Avg: [-1329.435 -1329.435 -1329.435] (1.000)
Step: 53449, Reward: [-1713.428 -1713.428 -1713.428] [0.0000], Avg: [-1329.794 -1329.794 -1329.794] (1.000)
Step: 53499, Reward: [-1468.037 -1468.037 -1468.037] [0.0000], Avg: [-1329.923 -1329.923 -1329.923] (1.000)
Step: 53549, Reward: [-1316.949 -1316.949 -1316.949] [0.0000], Avg: [-1329.911 -1329.911 -1329.911] (1.000)
Step: 53599, Reward: [-1478.02 -1478.02 -1478.02] [0.0000], Avg: [-1330.049 -1330.049 -1330.049] (1.000)
Step: 53649, Reward: [-1127.017 -1127.017 -1127.017] [0.0000], Avg: [-1329.86 -1329.86 -1329.86] (1.000)
Step: 53699, Reward: [-1663.479 -1663.479 -1663.479] [0.0000], Avg: [-1330.171 -1330.171 -1330.171] (1.000)
Step: 53749, Reward: [-1056.927 -1056.927 -1056.927] [0.0000], Avg: [-1329.917 -1329.917 -1329.917] (1.000)
Step: 53799, Reward: [-1536.72 -1536.72 -1536.72] [0.0000], Avg: [-1330.109 -1330.109 -1330.109] (1.000)
Step: 53849, Reward: [-1715.833 -1715.833 -1715.833] [0.0000], Avg: [-1330.467 -1330.467 -1330.467] (1.000)
Step: 53899, Reward: [-1528.675 -1528.675 -1528.675] [0.0000], Avg: [-1330.651 -1330.651 -1330.651] (1.000)
Step: 53949, Reward: [-1921.674 -1921.674 -1921.674] [0.0000], Avg: [-1331.199 -1331.199 -1331.199] (1.000)
Step: 53999, Reward: [-1385.414 -1385.414 -1385.414] [0.0000], Avg: [-1331.249 -1331.249 -1331.249] (1.000)
Step: 54049, Reward: [-1580.549 -1580.549 -1580.549] [0.0000], Avg: [-1331.479 -1331.479 -1331.479] (1.000)
Step: 54099, Reward: [-1866.13 -1866.13 -1866.13] [0.0000], Avg: [-1331.974 -1331.974 -1331.974] (1.000)
Step: 54149, Reward: [-1675.591 -1675.591 -1675.591] [0.0000], Avg: [-1332.291 -1332.291 -1332.291] (1.000)
Step: 54199, Reward: [-1766.077 -1766.077 -1766.077] [0.0000], Avg: [-1332.691 -1332.691 -1332.691] (1.000)
Step: 54249, Reward: [-1656.7 -1656.7 -1656.7] [0.0000], Avg: [-1332.99 -1332.99 -1332.99] (1.000)
Step: 54299, Reward: [-2064.725 -2064.725 -2064.725] [0.0000], Avg: [-1333.663 -1333.663 -1333.663] (1.000)
Step: 54349, Reward: [-2002.384 -2002.384 -2002.384] [0.0000], Avg: [-1334.279 -1334.279 -1334.279] (1.000)
Step: 54399, Reward: [-2128.138 -2128.138 -2128.138] [0.0000], Avg: [-1335.008 -1335.008 -1335.008] (1.000)
Step: 54449, Reward: [-1872.748 -1872.748 -1872.748] [0.0000], Avg: [-1335.502 -1335.502 -1335.502] (1.000)
Step: 54499, Reward: [-2293.728 -2293.728 -2293.728] [0.0000], Avg: [-1336.381 -1336.381 -1336.381] (1.000)
Step: 54549, Reward: [-2127.729 -2127.729 -2127.729] [0.0000], Avg: [-1337.107 -1337.107 -1337.107] (1.000)
Step: 54599, Reward: [-1796.321 -1796.321 -1796.321] [0.0000], Avg: [-1337.527 -1337.527 -1337.527] (1.000)
Step: 54649, Reward: [-1315.103 -1315.103 -1315.103] [0.0000], Avg: [-1337.507 -1337.507 -1337.507] (1.000)
Step: 54699, Reward: [-2092.433 -2092.433 -2092.433] [0.0000], Avg: [-1338.197 -1338.197 -1338.197] (1.000)
Step: 54749, Reward: [-1892.918 -1892.918 -1892.918] [0.0000], Avg: [-1338.703 -1338.703 -1338.703] (1.000)
Step: 54799, Reward: [-2176.415 -2176.415 -2176.415] [0.0000], Avg: [-1339.468 -1339.468 -1339.468] (1.000)
Step: 54849, Reward: [-1946.493 -1946.493 -1946.493] [0.0000], Avg: [-1340.021 -1340.021 -1340.021] (1.000)
Step: 54899, Reward: [-1989.021 -1989.021 -1989.021] [0.0000], Avg: [-1340.612 -1340.612 -1340.612] (1.000)
Step: 54949, Reward: [-2012.885 -2012.885 -2012.885] [0.0000], Avg: [-1341.224 -1341.224 -1341.224] (1.000)
Step: 54999, Reward: [-2001.474 -2001.474 -2001.474] [0.0000], Avg: [-1341.824 -1341.824 -1341.824] (1.000)
Step: 55049, Reward: [-1708.393 -1708.393 -1708.393] [0.0000], Avg: [-1342.157 -1342.157 -1342.157] (1.000)
Step: 55099, Reward: [-1991.324 -1991.324 -1991.324] [0.0000], Avg: [-1342.746 -1342.746 -1342.746] (1.000)
Step: 55149, Reward: [-1946.584 -1946.584 -1946.584] [0.0000], Avg: [-1343.293 -1343.293 -1343.293] (1.000)
Step: 55199, Reward: [-1735.955 -1735.955 -1735.955] [0.0000], Avg: [-1343.649 -1343.649 -1343.649] (1.000)
Step: 55249, Reward: [-1872.854 -1872.854 -1872.854] [0.0000], Avg: [-1344.128 -1344.128 -1344.128] (1.000)
Step: 55299, Reward: [-1958.273 -1958.273 -1958.273] [0.0000], Avg: [-1344.683 -1344.683 -1344.683] (1.000)
Step: 55349, Reward: [-1856.171 -1856.171 -1856.171] [0.0000], Avg: [-1345.145 -1345.145 -1345.145] (1.000)
Step: 55399, Reward: [-1949.045 -1949.045 -1949.045] [0.0000], Avg: [-1345.69 -1345.69 -1345.69] (1.000)
Step: 55449, Reward: [-1957.866 -1957.866 -1957.866] [0.0000], Avg: [-1346.242 -1346.242 -1346.242] (1.000)
Step: 55499, Reward: [-1918.79 -1918.79 -1918.79] [0.0000], Avg: [-1346.758 -1346.758 -1346.758] (1.000)
Step: 55549, Reward: [-1193.814 -1193.814 -1193.814] [0.0000], Avg: [-1346.621 -1346.621 -1346.621] (1.000)
Step: 55599, Reward: [-1493.609 -1493.609 -1493.609] [0.0000], Avg: [-1346.753 -1346.753 -1346.753] (1.000)
Step: 55649, Reward: [-1187.077 -1187.077 -1187.077] [0.0000], Avg: [-1346.609 -1346.609 -1346.609] (1.000)
Step: 55699, Reward: [-757.784 -757.784 -757.784] [0.0000], Avg: [-1346.081 -1346.081 -1346.081] (1.000)
Step: 55749, Reward: [-644.752 -644.752 -644.752] [0.0000], Avg: [-1345.452 -1345.452 -1345.452] (1.000)
Step: 55799, Reward: [-1737.762 -1737.762 -1737.762] [0.0000], Avg: [-1345.803 -1345.803 -1345.803] (1.000)
Step: 55849, Reward: [-1830.881 -1830.881 -1830.881] [0.0000], Avg: [-1346.237 -1346.237 -1346.237] (1.000)
Step: 55899, Reward: [-754.397 -754.397 -754.397] [0.0000], Avg: [-1345.708 -1345.708 -1345.708] (1.000)
Step: 55949, Reward: [-639.885 -639.885 -639.885] [0.0000], Avg: [-1345.077 -1345.077 -1345.077] (1.000)
Step: 55999, Reward: [-1687.24 -1687.24 -1687.24] [0.0000], Avg: [-1345.383 -1345.383 -1345.383] (1.000)
Step: 56049, Reward: [-1412.296 -1412.296 -1412.296] [0.0000], Avg: [-1345.443 -1345.443 -1345.443] (1.000)
Step: 56099, Reward: [-733.128 -733.128 -733.128] [0.0000], Avg: [-1344.897 -1344.897 -1344.897] (1.000)
Step: 56149, Reward: [-1633.372 -1633.372 -1633.372] [0.0000], Avg: [-1345.154 -1345.154 -1345.154] (1.000)
Step: 56199, Reward: [-1172.884 -1172.884 -1172.884] [0.0000], Avg: [-1345. -1345. -1345.] (1.000)
Step: 56249, Reward: [-2189.743 -2189.743 -2189.743] [0.0000], Avg: [-1345.751 -1345.751 -1345.751] (1.000)
Step: 56299, Reward: [-1734.82 -1734.82 -1734.82] [0.0000], Avg: [-1346.097 -1346.097 -1346.097] (1.000)
Step: 56349, Reward: [-2050.54 -2050.54 -2050.54] [0.0000], Avg: [-1346.722 -1346.722 -1346.722] (1.000)
Step: 56399, Reward: [-1010.85 -1010.85 -1010.85] [0.0000], Avg: [-1346.424 -1346.424 -1346.424] (1.000)
Step: 56449, Reward: [-1899.642 -1899.642 -1899.642] [0.0000], Avg: [-1346.914 -1346.914 -1346.914] (1.000)
Step: 56499, Reward: [-2015.052 -2015.052 -2015.052] [0.0000], Avg: [-1347.505 -1347.505 -1347.505] (1.000)
Step: 56549, Reward: [-1864.183 -1864.183 -1864.183] [0.0000], Avg: [-1347.962 -1347.962 -1347.962] (1.000)
Step: 56599, Reward: [-1079.186 -1079.186 -1079.186] [0.0000], Avg: [-1347.725 -1347.725 -1347.725] (1.000)
Step: 56649, Reward: [-1746.49 -1746.49 -1746.49] [0.0000], Avg: [-1348.077 -1348.077 -1348.077] (1.000)
Step: 56699, Reward: [-2001.501 -2001.501 -2001.501] [0.0000], Avg: [-1348.653 -1348.653 -1348.653] (1.000)
Step: 56749, Reward: [-955.066 -955.066 -955.066] [0.0000], Avg: [-1348.306 -1348.306 -1348.306] (1.000)
Step: 56799, Reward: [-1750.054 -1750.054 -1750.054] [0.0000], Avg: [-1348.66 -1348.66 -1348.66] (1.000)
Step: 56849, Reward: [-1936.069 -1936.069 -1936.069] [0.0000], Avg: [-1349.176 -1349.176 -1349.176] (1.000)
Step: 56899, Reward: [-775.383 -775.383 -775.383] [0.0000], Avg: [-1348.672 -1348.672 -1348.672] (1.000)
Step: 56949, Reward: [-1589.939 -1589.939 -1589.939] [0.0000], Avg: [-1348.884 -1348.884 -1348.884] (1.000)
Step: 56999, Reward: [-1456.243 -1456.243 -1456.243] [0.0000], Avg: [-1348.978 -1348.978 -1348.978] (1.000)
Step: 57049, Reward: [-1746.994 -1746.994 -1746.994] [0.0000], Avg: [-1349.327 -1349.327 -1349.327] (1.000)
Step: 57099, Reward: [-1025.688 -1025.688 -1025.688] [0.0000], Avg: [-1349.044 -1349.044 -1349.044] (1.000)
Step: 57149, Reward: [-539.421 -539.421 -539.421] [0.0000], Avg: [-1348.335 -1348.335 -1348.335] (1.000)
Step: 57199, Reward: [-1431.752 -1431.752 -1431.752] [0.0000], Avg: [-1348.408 -1348.408 -1348.408] (1.000)
Step: 57249, Reward: [-738.456 -738.456 -738.456] [0.0000], Avg: [-1347.876 -1347.876 -1347.876] (1.000)
Step: 57299, Reward: [-457.527 -457.527 -457.527] [0.0000], Avg: [-1347.099 -1347.099 -1347.099] (1.000)
Step: 57349, Reward: [-706.423 -706.423 -706.423] [0.0000], Avg: [-1346.54 -1346.54 -1346.54] (1.000)
Step: 57399, Reward: [-697.701 -697.701 -697.701] [0.0000], Avg: [-1345.975 -1345.975 -1345.975] (1.000)
Step: 57449, Reward: [-586.119 -586.119 -586.119] [0.0000], Avg: [-1345.314 -1345.314 -1345.314] (1.000)
Step: 57499, Reward: [-868.635 -868.635 -868.635] [0.0000], Avg: [-1344.899 -1344.899 -1344.899] (1.000)
Step: 57549, Reward: [-434.954 -434.954 -434.954] [0.0000], Avg: [-1344.108 -1344.108 -1344.108] (1.000)
Step: 57599, Reward: [-444.05 -444.05 -444.05] [0.0000], Avg: [-1343.327 -1343.327 -1343.327] (1.000)
Step: 57649, Reward: [-488.879 -488.879 -488.879] [0.0000], Avg: [-1342.586 -1342.586 -1342.586] (1.000)
Step: 57699, Reward: [-569.044 -569.044 -569.044] [0.0000], Avg: [-1341.916 -1341.916 -1341.916] (1.000)
Step: 57749, Reward: [-403.745 -403.745 -403.745] [0.0000], Avg: [-1341.104 -1341.104 -1341.104] (1.000)
Step: 57799, Reward: [-656.368 -656.368 -656.368] [0.0000], Avg: [-1340.511 -1340.511 -1340.511] (1.000)
Step: 57849, Reward: [-2172.428 -2172.428 -2172.428] [0.0000], Avg: [-1341.23 -1341.23 -1341.23] (1.000)
Step: 57899, Reward: [-2016.991 -2016.991 -2016.991] [0.0000], Avg: [-1341.814 -1341.814 -1341.814] (1.000)
Step: 57949, Reward: [-1939.095 -1939.095 -1939.095] [0.0000], Avg: [-1342.329 -1342.329 -1342.329] (1.000)
Step: 57999, Reward: [-741.426 -741.426 -741.426] [0.0000], Avg: [-1341.811 -1341.811 -1341.811] (1.000)
Step: 58049, Reward: [-1044.67 -1044.67 -1044.67] [0.0000], Avg: [-1341.555 -1341.555 -1341.555] (1.000)
Step: 58099, Reward: [-437.439 -437.439 -437.439] [0.0000], Avg: [-1340.777 -1340.777 -1340.777] (1.000)
Step: 58149, Reward: [-1863.27 -1863.27 -1863.27] [0.0000], Avg: [-1341.226 -1341.226 -1341.226] (1.000)
Step: 58199, Reward: [-1273.666 -1273.666 -1273.666] [0.0000], Avg: [-1341.168 -1341.168 -1341.168] (1.000)
Step: 58249, Reward: [-1332.781 -1332.781 -1332.781] [0.0000], Avg: [-1341.161 -1341.161 -1341.161] (1.000)
Step: 58299, Reward: [-1474.237 -1474.237 -1474.237] [0.0000], Avg: [-1341.275 -1341.275 -1341.275] (1.000)
Step: 58349, Reward: [-2260.92 -2260.92 -2260.92] [0.0000], Avg: [-1342.063 -1342.063 -1342.063] (1.000)
Step: 58399, Reward: [-1136.608 -1136.608 -1136.608] [0.0000], Avg: [-1341.887 -1341.887 -1341.887] (1.000)
Step: 58449, Reward: [-2162.066 -2162.066 -2162.066] [0.0000], Avg: [-1342.589 -1342.589 -1342.589] (1.000)
Step: 58499, Reward: [-2282.682 -2282.682 -2282.682] [0.0000], Avg: [-1343.393 -1343.393 -1343.393] (1.000)
Step: 58549, Reward: [-859.109 -859.109 -859.109] [0.0000], Avg: [-1342.979 -1342.979 -1342.979] (1.000)
Step: 58599, Reward: [-1063.128 -1063.128 -1063.128] [0.0000], Avg: [-1342.74 -1342.74 -1342.74] (1.000)
Step: 58649, Reward: [-1460.766 -1460.766 -1460.766] [0.0000], Avg: [-1342.841 -1342.841 -1342.841] (1.000)
Step: 58699, Reward: [-634.872 -634.872 -634.872] [0.0000], Avg: [-1342.238 -1342.238 -1342.238] (1.000)
Step: 58749, Reward: [-1081.231 -1081.231 -1081.231] [0.0000], Avg: [-1342.016 -1342.016 -1342.016] (1.000)
Step: 58799, Reward: [-1133.013 -1133.013 -1133.013] [0.0000], Avg: [-1341.838 -1341.838 -1341.838] (1.000)
Step: 58849, Reward: [-1023.219 -1023.219 -1023.219] [0.0000], Avg: [-1341.567 -1341.567 -1341.567] (1.000)
Step: 58899, Reward: [-1199.105 -1199.105 -1199.105] [0.0000], Avg: [-1341.446 -1341.446 -1341.446] (1.000)
Step: 58949, Reward: [-948.371 -948.371 -948.371] [0.0000], Avg: [-1341.113 -1341.113 -1341.113] (1.000)
Step: 58999, Reward: [-848.301 -848.301 -848.301] [0.0000], Avg: [-1340.695 -1340.695 -1340.695] (1.000)
Step: 59049, Reward: [-930.521 -930.521 -930.521] [0.0000], Avg: [-1340.348 -1340.348 -1340.348] (1.000)
Step: 59099, Reward: [-914.739 -914.739 -914.739] [0.0000], Avg: [-1339.988 -1339.988 -1339.988] (1.000)
Step: 59149, Reward: [-914.039 -914.039 -914.039] [0.0000], Avg: [-1339.628 -1339.628 -1339.628] (1.000)
Step: 59199, Reward: [-553.153 -553.153 -553.153] [0.0000], Avg: [-1338.964 -1338.964 -1338.964] (1.000)
Step: 59249, Reward: [-719.183 -719.183 -719.183] [0.0000], Avg: [-1338.44 -1338.44 -1338.44] (1.000)
Step: 59299, Reward: [-682.562 -682.562 -682.562] [0.0000], Avg: [-1337.887 -1337.887 -1337.887] (1.000)
Step: 59349, Reward: [-634.288 -634.288 -634.288] [0.0000], Avg: [-1337.295 -1337.295 -1337.295] (1.000)
Step: 59399, Reward: [-692.402 -692.402 -692.402] [0.0000], Avg: [-1336.752 -1336.752 -1336.752] (1.000)
Step: 59449, Reward: [-834.673 -834.673 -834.673] [0.0000], Avg: [-1336.33 -1336.33 -1336.33] (1.000)
Step: 59499, Reward: [-616.995 -616.995 -616.995] [0.0000], Avg: [-1335.725 -1335.725 -1335.725] (1.000)
Step: 59549, Reward: [-1309.457 -1309.457 -1309.457] [0.0000], Avg: [-1335.703 -1335.703 -1335.703] (1.000)
Step: 59599, Reward: [-1074.731 -1074.731 -1074.731] [0.0000], Avg: [-1335.484 -1335.484 -1335.484] (1.000)
Step: 59649, Reward: [-1133.832 -1133.832 -1133.832] [0.0000], Avg: [-1335.315 -1335.315 -1335.315] (1.000)
Step: 59699, Reward: [-1452.1 -1452.1 -1452.1] [0.0000], Avg: [-1335.413 -1335.413 -1335.413] (1.000)
Step: 59749, Reward: [-1637.141 -1637.141 -1637.141] [0.0000], Avg: [-1335.665 -1335.665 -1335.665] (1.000)
Step: 59799, Reward: [-1394.784 -1394.784 -1394.784] [0.0000], Avg: [-1335.715 -1335.715 -1335.715] (1.000)
Step: 59849, Reward: [-1813.503 -1813.503 -1813.503] [0.0000], Avg: [-1336.114 -1336.114 -1336.114] (1.000)
Step: 59899, Reward: [-1922.962 -1922.962 -1922.962] [0.0000], Avg: [-1336.604 -1336.604 -1336.604] (1.000)
Step: 59949, Reward: [-1606.169 -1606.169 -1606.169] [0.0000], Avg: [-1336.829 -1336.829 -1336.829] (1.000)
Step: 59999, Reward: [-1365.32 -1365.32 -1365.32] [0.0000], Avg: [-1336.852 -1336.852 -1336.852] (1.000)
Step: 60049, Reward: [-1388.217 -1388.217 -1388.217] [0.0000], Avg: [-1336.895 -1336.895 -1336.895] (1.000)
Step: 60099, Reward: [-1202.146 -1202.146 -1202.146] [0.0000], Avg: [-1336.783 -1336.783 -1336.783] (1.000)
Step: 60149, Reward: [-834.5 -834.5 -834.5] [0.0000], Avg: [-1336.366 -1336.366 -1336.366] (1.000)
Step: 60199, Reward: [-1376.904 -1376.904 -1376.904] [0.0000], Avg: [-1336.399 -1336.399 -1336.399] (1.000)
Step: 60249, Reward: [-1010.427 -1010.427 -1010.427] [0.0000], Avg: [-1336.129 -1336.129 -1336.129] (1.000)
Step: 60299, Reward: [-793.058 -793.058 -793.058] [0.0000], Avg: [-1335.678 -1335.678 -1335.678] (1.000)
Step: 60349, Reward: [-488.291 -488.291 -488.291] [0.0000], Avg: [-1334.976 -1334.976 -1334.976] (1.000)
Step: 60399, Reward: [-897.739 -897.739 -897.739] [0.0000], Avg: [-1334.614 -1334.614 -1334.614] (1.000)
Step: 60449, Reward: [-837.66 -837.66 -837.66] [0.0000], Avg: [-1334.203 -1334.203 -1334.203] (1.000)
Step: 60499, Reward: [-928.886 -928.886 -928.886] [0.0000], Avg: [-1333.868 -1333.868 -1333.868] (1.000)
Step: 60549, Reward: [-835.22 -835.22 -835.22] [0.0000], Avg: [-1333.457 -1333.457 -1333.457] (1.000)
Step: 60599, Reward: [-899.612 -899.612 -899.612] [0.0000], Avg: [-1333.099 -1333.099 -1333.099] (1.000)
Step: 60649, Reward: [-1348.308 -1348.308 -1348.308] [0.0000], Avg: [-1333.111 -1333.111 -1333.111] (1.000)
Step: 60699, Reward: [-967.751 -967.751 -967.751] [0.0000], Avg: [-1332.81 -1332.81 -1332.81] (1.000)
Step: 60749, Reward: [-1361.478 -1361.478 -1361.478] [0.0000], Avg: [-1332.834 -1332.834 -1332.834] (1.000)
Step: 60799, Reward: [-1189.911 -1189.911 -1189.911] [0.0000], Avg: [-1332.716 -1332.716 -1332.716] (1.000)
Step: 60849, Reward: [-1126.499 -1126.499 -1126.499] [0.0000], Avg: [-1332.547 -1332.547 -1332.547] (1.000)
Step: 60899, Reward: [-798.754 -798.754 -798.754] [0.0000], Avg: [-1332.109 -1332.109 -1332.109] (1.000)
Step: 60949, Reward: [-2239.279 -2239.279 -2239.279] [0.0000], Avg: [-1332.853 -1332.853 -1332.853] (1.000)
Step: 60999, Reward: [-1365.152 -1365.152 -1365.152] [0.0000], Avg: [-1332.879 -1332.879 -1332.879] (1.000)
Step: 61049, Reward: [-1701.86 -1701.86 -1701.86] [0.0000], Avg: [-1333.181 -1333.181 -1333.181] (1.000)
Step: 61099, Reward: [-2066.095 -2066.095 -2066.095] [0.0000], Avg: [-1333.781 -1333.781 -1333.781] (1.000)
Step: 61149, Reward: [-1813.699 -1813.699 -1813.699] [0.0000], Avg: [-1334.174 -1334.174 -1334.174] (1.000)
Step: 61199, Reward: [-1804.528 -1804.528 -1804.528] [0.0000], Avg: [-1334.558 -1334.558 -1334.558] (1.000)
Step: 61249, Reward: [-1722.864 -1722.864 -1722.864] [0.0000], Avg: [-1334.875 -1334.875 -1334.875] (1.000)
Step: 61299, Reward: [-1895.809 -1895.809 -1895.809] [0.0000], Avg: [-1335.332 -1335.332 -1335.332] (1.000)
Step: 61349, Reward: [-2062.487 -2062.487 -2062.487] [0.0000], Avg: [-1335.925 -1335.925 -1335.925] (1.000)
Step: 61399, Reward: [-1775.331 -1775.331 -1775.331] [0.0000], Avg: [-1336.283 -1336.283 -1336.283] (1.000)
Step: 61449, Reward: [-2023.048 -2023.048 -2023.048] [0.0000], Avg: [-1336.842 -1336.842 -1336.842] (1.000)
Step: 61499, Reward: [-1820.171 -1820.171 -1820.171] [0.0000], Avg: [-1337.235 -1337.235 -1337.235] (1.000)
Step: 61549, Reward: [-1777.545 -1777.545 -1777.545] [0.0000], Avg: [-1337.592 -1337.592 -1337.592] (1.000)
Step: 61599, Reward: [-2272.398 -2272.398 -2272.398] [0.0000], Avg: [-1338.351 -1338.351 -1338.351] (1.000)
Step: 61649, Reward: [-1892.382 -1892.382 -1892.382] [0.0000], Avg: [-1338.8 -1338.8 -1338.8] (1.000)
Step: 61699, Reward: [-2026.788 -2026.788 -2026.788] [0.0000], Avg: [-1339.358 -1339.358 -1339.358] (1.000)
Step: 61749, Reward: [-2038.962 -2038.962 -2038.962] [0.0000], Avg: [-1339.924 -1339.924 -1339.924] (1.000)
Step: 61799, Reward: [-1909.755 -1909.755 -1909.755] [0.0000], Avg: [-1340.385 -1340.385 -1340.385] (1.000)
Step: 61849, Reward: [-1993.981 -1993.981 -1993.981] [0.0000], Avg: [-1340.914 -1340.914 -1340.914] (1.000)
Step: 61899, Reward: [-1769.714 -1769.714 -1769.714] [0.0000], Avg: [-1341.26 -1341.26 -1341.26] (1.000)
Step: 61949, Reward: [-2056.341 -2056.341 -2056.341] [0.0000], Avg: [-1341.837 -1341.837 -1341.837] (1.000)
Step: 61999, Reward: [-1553.595 -1553.595 -1553.595] [0.0000], Avg: [-1342.008 -1342.008 -1342.008] (1.000)
Step: 62049, Reward: [-1679.648 -1679.648 -1679.648] [0.0000], Avg: [-1342.28 -1342.28 -1342.28] (1.000)
Step: 62099, Reward: [-2087.382 -2087.382 -2087.382] [0.0000], Avg: [-1342.88 -1342.88 -1342.88] (1.000)
Step: 62149, Reward: [-1586.929 -1586.929 -1586.929] [0.0000], Avg: [-1343.076 -1343.076 -1343.076] (1.000)
Step: 62199, Reward: [-1638.225 -1638.225 -1638.225] [0.0000], Avg: [-1343.314 -1343.314 -1343.314] (1.000)
Step: 62249, Reward: [-1575.656 -1575.656 -1575.656] [0.0000], Avg: [-1343.5 -1343.5 -1343.5] (1.000)
Step: 62299, Reward: [-1764.04 -1764.04 -1764.04] [0.0000], Avg: [-1343.838 -1343.838 -1343.838] (1.000)
Step: 62349, Reward: [-1615.024 -1615.024 -1615.024] [0.0000], Avg: [-1344.055 -1344.055 -1344.055] (1.000)
Step: 62399, Reward: [-1881.102 -1881.102 -1881.102] [0.0000], Avg: [-1344.486 -1344.486 -1344.486] (1.000)
Step: 62449, Reward: [-1573.615 -1573.615 -1573.615] [0.0000], Avg: [-1344.669 -1344.669 -1344.669] (1.000)
Step: 62499, Reward: [-1669.016 -1669.016 -1669.016] [0.0000], Avg: [-1344.929 -1344.929 -1344.929] (1.000)
Step: 62549, Reward: [-1508.591 -1508.591 -1508.591] [0.0000], Avg: [-1345.059 -1345.059 -1345.059] (1.000)
Step: 62599, Reward: [-1839.211 -1839.211 -1839.211] [0.0000], Avg: [-1345.454 -1345.454 -1345.454] (1.000)
Step: 62649, Reward: [-1586.329 -1586.329 -1586.329] [0.0000], Avg: [-1345.646 -1345.646 -1345.646] (1.000)
Step: 62699, Reward: [-1915.045 -1915.045 -1915.045] [0.0000], Avg: [-1346.1 -1346.1 -1346.1] (1.000)
Step: 62749, Reward: [-2241.942 -2241.942 -2241.942] [0.0000], Avg: [-1346.814 -1346.814 -1346.814] (1.000)
Step: 62799, Reward: [-1683.69 -1683.69 -1683.69] [0.0000], Avg: [-1347.082 -1347.082 -1347.082] (1.000)
Step: 62849, Reward: [-1385.148 -1385.148 -1385.148] [0.0000], Avg: [-1347.113 -1347.113 -1347.113] (1.000)
Step: 62899, Reward: [-1934.446 -1934.446 -1934.446] [0.0000], Avg: [-1347.58 -1347.58 -1347.58] (1.000)
Step: 62949, Reward: [-2002.865 -2002.865 -2002.865] [0.0000], Avg: [-1348.1 -1348.1 -1348.1] (1.000)
Step: 62999, Reward: [-2220.451 -2220.451 -2220.451] [0.0000], Avg: [-1348.792 -1348.792 -1348.792] (1.000)
Step: 63049, Reward: [-1828.792 -1828.792 -1828.792] [0.0000], Avg: [-1349.173 -1349.173 -1349.173] (1.000)
Step: 63099, Reward: [-2044.371 -2044.371 -2044.371] [0.0000], Avg: [-1349.724 -1349.724 -1349.724] (1.000)
Step: 63149, Reward: [-2062.912 -2062.912 -2062.912] [0.0000], Avg: [-1350.289 -1350.289 -1350.289] (1.000)
Step: 63199, Reward: [-1833.309 -1833.309 -1833.309] [0.0000], Avg: [-1350.671 -1350.671 -1350.671] (1.000)
Step: 63249, Reward: [-1865.615 -1865.615 -1865.615] [0.0000], Avg: [-1351.078 -1351.078 -1351.078] (1.000)
Step: 63299, Reward: [-1924.601 -1924.601 -1924.601] [0.0000], Avg: [-1351.531 -1351.531 -1351.531] (1.000)
Step: 63349, Reward: [-1826.363 -1826.363 -1826.363] [0.0000], Avg: [-1351.906 -1351.906 -1351.906] (1.000)
Step: 63399, Reward: [-1804.617 -1804.617 -1804.617] [0.0000], Avg: [-1352.263 -1352.263 -1352.263] (1.000)
Step: 63449, Reward: [-1869.13 -1869.13 -1869.13] [0.0000], Avg: [-1352.67 -1352.67 -1352.67] (1.000)
Step: 63499, Reward: [-1970.744 -1970.744 -1970.744] [0.0000], Avg: [-1353.157 -1353.157 -1353.157] (1.000)
Step: 63549, Reward: [-2141.473 -2141.473 -2141.473] [0.0000], Avg: [-1353.777 -1353.777 -1353.777] (1.000)
Step: 63599, Reward: [-2175.122 -2175.122 -2175.122] [0.0000], Avg: [-1354.423 -1354.423 -1354.423] (1.000)
Step: 63649, Reward: [-1986.972 -1986.972 -1986.972] [0.0000], Avg: [-1354.919 -1354.919 -1354.919] (1.000)
Step: 63699, Reward: [-1723.616 -1723.616 -1723.616] [0.0000], Avg: [-1355.209 -1355.209 -1355.209] (1.000)
Step: 63749, Reward: [-1610.832 -1610.832 -1610.832] [0.0000], Avg: [-1355.409 -1355.409 -1355.409] (1.000)
Step: 63799, Reward: [-1454.637 -1454.637 -1454.637] [0.0000], Avg: [-1355.487 -1355.487 -1355.487] (1.000)
Step: 63849, Reward: [-2139.498 -2139.498 -2139.498] [0.0000], Avg: [-1356.101 -1356.101 -1356.101] (1.000)
Step: 63899, Reward: [-1685.342 -1685.342 -1685.342] [0.0000], Avg: [-1356.359 -1356.359 -1356.359] (1.000)
Step: 63949, Reward: [-1046.196 -1046.196 -1046.196] [0.0000], Avg: [-1356.116 -1356.116 -1356.116] (1.000)
Step: 63999, Reward: [-1172.224 -1172.224 -1172.224] [0.0000], Avg: [-1355.972 -1355.972 -1355.972] (1.000)
Step: 64049, Reward: [-1016.683 -1016.683 -1016.683] [0.0000], Avg: [-1355.708 -1355.708 -1355.708] (1.000)
Step: 64099, Reward: [-1174.017 -1174.017 -1174.017] [0.0000], Avg: [-1355.566 -1355.566 -1355.566] (1.000)
Step: 64149, Reward: [-1083.558 -1083.558 -1083.558] [0.0000], Avg: [-1355.354 -1355.354 -1355.354] (1.000)
Step: 64199, Reward: [-1319.38 -1319.38 -1319.38] [0.0000], Avg: [-1355.326 -1355.326 -1355.326] (1.000)
Step: 64249, Reward: [-1015.86 -1015.86 -1015.86] [0.0000], Avg: [-1355.062 -1355.062 -1355.062] (1.000)
Step: 64299, Reward: [-867.314 -867.314 -867.314] [0.0000], Avg: [-1354.682 -1354.682 -1354.682] (1.000)
Step: 64349, Reward: [-820.591 -820.591 -820.591] [0.0000], Avg: [-1354.267 -1354.267 -1354.267] (1.000)
Step: 64399, Reward: [-1344.929 -1344.929 -1344.929] [0.0000], Avg: [-1354.26 -1354.26 -1354.26] (1.000)
Step: 64449, Reward: [-727.001 -727.001 -727.001] [0.0000], Avg: [-1353.774 -1353.774 -1353.774] (1.000)
Step: 64499, Reward: [-639.195 -639.195 -639.195] [0.0000], Avg: [-1353.22 -1353.22 -1353.22] (1.000)
Step: 64549, Reward: [-767.123 -767.123 -767.123] [0.0000], Avg: [-1352.766 -1352.766 -1352.766] (1.000)
Step: 64599, Reward: [-429.256 -429.256 -429.256] [0.0000], Avg: [-1352.051 -1352.051 -1352.051] (1.000)
Step: 64649, Reward: [-522.836 -522.836 -522.836] [0.0000], Avg: [-1351.41 -1351.41 -1351.41] (1.000)
Step: 64699, Reward: [-617.157 -617.157 -617.157] [0.0000], Avg: [-1350.842 -1350.842 -1350.842] (1.000)
Step: 64749, Reward: [-592.118 -592.118 -592.118] [0.0000], Avg: [-1350.256 -1350.256 -1350.256] (1.000)
Step: 64799, Reward: [-603.421 -603.421 -603.421] [0.0000], Avg: [-1349.68 -1349.68 -1349.68] (1.000)
Step: 64849, Reward: [-657.852 -657.852 -657.852] [0.0000], Avg: [-1349.147 -1349.147 -1349.147] (1.000)
Step: 64899, Reward: [-441.965 -441.965 -441.965] [0.0000], Avg: [-1348.448 -1348.448 -1348.448] (1.000)
Step: 64949, Reward: [-747.968 -747.968 -747.968] [0.0000], Avg: [-1347.985 -1347.985 -1347.985] (1.000)
Step: 64999, Reward: [-394.458 -394.458 -394.458] [0.0000], Avg: [-1347.252 -1347.252 -1347.252] (1.000)
Step: 65049, Reward: [-431.237 -431.237 -431.237] [0.0000], Avg: [-1346.548 -1346.548 -1346.548] (1.000)
Step: 65099, Reward: [-639.795 -639.795 -639.795] [0.0000], Avg: [-1346.005 -1346.005 -1346.005] (1.000)
Step: 65149, Reward: [-769.659 -769.659 -769.659] [0.0000], Avg: [-1345.563 -1345.563 -1345.563] (1.000)
Step: 65199, Reward: [-764.31 -764.31 -764.31] [0.0000], Avg: [-1345.117 -1345.117 -1345.117] (1.000)
Step: 65249, Reward: [-567.478 -567.478 -567.478] [0.0000], Avg: [-1344.521 -1344.521 -1344.521] (1.000)
Step: 65299, Reward: [-372.122 -372.122 -372.122] [0.0000], Avg: [-1343.776 -1343.776 -1343.776] (1.000)
Step: 65349, Reward: [-663.209 -663.209 -663.209] [0.0000], Avg: [-1343.256 -1343.256 -1343.256] (1.000)
Step: 65399, Reward: [-550.229 -550.229 -550.229] [0.0000], Avg: [-1342.649 -1342.649 -1342.649] (1.000)
Step: 65449, Reward: [-701.196 -701.196 -701.196] [0.0000], Avg: [-1342.159 -1342.159 -1342.159] (1.000)
Step: 65499, Reward: [-722.625 -722.625 -722.625] [0.0000], Avg: [-1341.687 -1341.687 -1341.687] (1.000)
Step: 65549, Reward: [-430.55 -430.55 -430.55] [0.0000], Avg: [-1340.992 -1340.992 -1340.992] (1.000)
Step: 65599, Reward: [-686.864 -686.864 -686.864] [0.0000], Avg: [-1340.493 -1340.493 -1340.493] (1.000)
Step: 65649, Reward: [-517.476 -517.476 -517.476] [0.0000], Avg: [-1339.866 -1339.866 -1339.866] (1.000)
Step: 65699, Reward: [-410.231 -410.231 -410.231] [0.0000], Avg: [-1339.159 -1339.159 -1339.159] (1.000)
Step: 65749, Reward: [-464.149 -464.149 -464.149] [0.0000], Avg: [-1338.493 -1338.493 -1338.493] (1.000)
Step: 65799, Reward: [-451.745 -451.745 -451.745] [0.0000], Avg: [-1337.819 -1337.819 -1337.819] (1.000)
Step: 65849, Reward: [-579.341 -579.341 -579.341] [0.0000], Avg: [-1337.243 -1337.243 -1337.243] (1.000)
Step: 65899, Reward: [-536.071 -536.071 -536.071] [0.0000], Avg: [-1336.636 -1336.636 -1336.636] (1.000)
Step: 65949, Reward: [-495.385 -495.385 -495.385] [0.0000], Avg: [-1335.998 -1335.998 -1335.998] (1.000)
Step: 65999, Reward: [-758.88 -758.88 -758.88] [0.0000], Avg: [-1335.561 -1335.561 -1335.561] (1.000)
Step: 66049, Reward: [-549.279 -549.279 -549.279] [0.0000], Avg: [-1334.965 -1334.965 -1334.965] (1.000)
Step: 66099, Reward: [-566.067 -566.067 -566.067] [0.0000], Avg: [-1334.384 -1334.384 -1334.384] (1.000)
Step: 66149, Reward: [-490.049 -490.049 -490.049] [0.0000], Avg: [-1333.746 -1333.746 -1333.746] (1.000)
Step: 66199, Reward: [-554.172 -554.172 -554.172] [0.0000], Avg: [-1333.157 -1333.157 -1333.157] (1.000)
Step: 66249, Reward: [-684.439 -684.439 -684.439] [0.0000], Avg: [-1332.667 -1332.667 -1332.667] (1.000)
Step: 66299, Reward: [-480.928 -480.928 -480.928] [0.0000], Avg: [-1332.025 -1332.025 -1332.025] (1.000)
Step: 66349, Reward: [-664.468 -664.468 -664.468] [0.0000], Avg: [-1331.522 -1331.522 -1331.522] (1.000)
Step: 66399, Reward: [-630.784 -630.784 -630.784] [0.0000], Avg: [-1330.994 -1330.994 -1330.994] (1.000)
Step: 66449, Reward: [-675.834 -675.834 -675.834] [0.0000], Avg: [-1330.501 -1330.501 -1330.501] (1.000)
Step: 66499, Reward: [-635.077 -635.077 -635.077] [0.0000], Avg: [-1329.978 -1329.978 -1329.978] (1.000)
Step: 66549, Reward: [-659.919 -659.919 -659.919] [0.0000], Avg: [-1329.475 -1329.475 -1329.475] (1.000)
Step: 66599, Reward: [-881.325 -881.325 -881.325] [0.0000], Avg: [-1329.138 -1329.138 -1329.138] (1.000)
Step: 66649, Reward: [-617.412 -617.412 -617.412] [0.0000], Avg: [-1328.604 -1328.604 -1328.604] (1.000)
Step: 66699, Reward: [-758.47 -758.47 -758.47] [0.0000], Avg: [-1328.177 -1328.177 -1328.177] (1.000)
Step: 66749, Reward: [-660.604 -660.604 -660.604] [0.0000], Avg: [-1327.677 -1327.677 -1327.677] (1.000)
Step: 66799, Reward: [-671.552 -671.552 -671.552] [0.0000], Avg: [-1327.186 -1327.186 -1327.186] (1.000)
Step: 66849, Reward: [-478.053 -478.053 -478.053] [0.0000], Avg: [-1326.551 -1326.551 -1326.551] (1.000)
Step: 66899, Reward: [-784.646 -784.646 -784.646] [0.0000], Avg: [-1326.146 -1326.146 -1326.146] (1.000)
Step: 66949, Reward: [-494.666 -494.666 -494.666] [0.0000], Avg: [-1325.525 -1325.525 -1325.525] (1.000)
Step: 66999, Reward: [-554.967 -554.967 -554.967] [0.0000], Avg: [-1324.95 -1324.95 -1324.95] (1.000)
Step: 67049, Reward: [-481.428 -481.428 -481.428] [0.0000], Avg: [-1324.321 -1324.321 -1324.321] (1.000)
Step: 67099, Reward: [-436.085 -436.085 -436.085] [0.0000], Avg: [-1323.659 -1323.659 -1323.659] (1.000)
Step: 67149, Reward: [-556.19 -556.19 -556.19] [0.0000], Avg: [-1323.087 -1323.087 -1323.087] (1.000)
Step: 67199, Reward: [-591.363 -591.363 -591.363] [0.0000], Avg: [-1322.543 -1322.543 -1322.543] (1.000)
Step: 67249, Reward: [-244.298 -244.298 -244.298] [0.0000], Avg: [-1321.741 -1321.741 -1321.741] (1.000)
Step: 67299, Reward: [-563.753 -563.753 -563.753] [0.0000], Avg: [-1321.178 -1321.178 -1321.178] (1.000)
Step: 67349, Reward: [-770.424 -770.424 -770.424] [0.0000], Avg: [-1320.769 -1320.769 -1320.769] (1.000)
Step: 67399, Reward: [-780.628 -780.628 -780.628] [0.0000], Avg: [-1320.369 -1320.369 -1320.369] (1.000)
Step: 67449, Reward: [-742.751 -742.751 -742.751] [0.0000], Avg: [-1319.94 -1319.94 -1319.94] (1.000)
Step: 67499, Reward: [-1189.907 -1189.907 -1189.907] [0.0000], Avg: [-1319.844 -1319.844 -1319.844] (1.000)
Step: 67549, Reward: [-912.417 -912.417 -912.417] [0.0000], Avg: [-1319.543 -1319.543 -1319.543] (1.000)
Step: 67599, Reward: [-1018.336 -1018.336 -1018.336] [0.0000], Avg: [-1319.32 -1319.32 -1319.32] (1.000)
Step: 67649, Reward: [-1386.705 -1386.705 -1386.705] [0.0000], Avg: [-1319.37 -1319.37 -1319.37] (1.000)
Step: 67699, Reward: [-992.094 -992.094 -992.094] [0.0000], Avg: [-1319.128 -1319.128 -1319.128] (1.000)
Step: 67749, Reward: [-1937.267 -1937.267 -1937.267] [0.0000], Avg: [-1319.584 -1319.584 -1319.584] (1.000)
Step: 67799, Reward: [-1202.806 -1202.806 -1202.806] [0.0000], Avg: [-1319.498 -1319.498 -1319.498] (1.000)
Step: 67849, Reward: [-1850.175 -1850.175 -1850.175] [0.0000], Avg: [-1319.889 -1319.889 -1319.889] (1.000)
Step: 67899, Reward: [-1967.235 -1967.235 -1967.235] [0.0000], Avg: [-1320.366 -1320.366 -1320.366] (1.000)
Step: 67949, Reward: [-2192.3 -2192.3 -2192.3] [0.0000], Avg: [-1321.007 -1321.007 -1321.007] (1.000)
Step: 67999, Reward: [-2127.486 -2127.486 -2127.486] [0.0000], Avg: [-1321.6 -1321.6 -1321.6] (1.000)
Step: 68049, Reward: [-1871.15 -1871.15 -1871.15] [0.0000], Avg: [-1322.004 -1322.004 -1322.004] (1.000)
Step: 68099, Reward: [-1876.649 -1876.649 -1876.649] [0.0000], Avg: [-1322.411 -1322.411 -1322.411] (1.000)
Step: 68149, Reward: [-2029.868 -2029.868 -2029.868] [0.0000], Avg: [-1322.93 -1322.93 -1322.93] (1.000)
Step: 68199, Reward: [-1960.02 -1960.02 -1960.02] [0.0000], Avg: [-1323.397 -1323.397 -1323.397] (1.000)
Step: 68249, Reward: [-1598.017 -1598.017 -1598.017] [0.0000], Avg: [-1323.599 -1323.599 -1323.599] (1.000)
Step: 68299, Reward: [-2150.261 -2150.261 -2150.261] [0.0000], Avg: [-1324.204 -1324.204 -1324.204] (1.000)
Step: 68349, Reward: [-1794.438 -1794.438 -1794.438] [0.0000], Avg: [-1324.548 -1324.548 -1324.548] (1.000)
Step: 68399, Reward: [-1759.18 -1759.18 -1759.18] [0.0000], Avg: [-1324.865 -1324.865 -1324.865] (1.000)
Step: 68449, Reward: [-1795.605 -1795.605 -1795.605] [0.0000], Avg: [-1325.209 -1325.209 -1325.209] (1.000)
Step: 68499, Reward: [-1569.826 -1569.826 -1569.826] [0.0000], Avg: [-1325.388 -1325.388 -1325.388] (1.000)
Step: 68549, Reward: [-1967.737 -1967.737 -1967.737] [0.0000], Avg: [-1325.856 -1325.856 -1325.856] (1.000)
Step: 68599, Reward: [-1543.129 -1543.129 -1543.129] [0.0000], Avg: [-1326.015 -1326.015 -1326.015] (1.000)
Step: 68649, Reward: [-1568.314 -1568.314 -1568.314] [0.0000], Avg: [-1326.191 -1326.191 -1326.191] (1.000)
Step: 68699, Reward: [-1133.395 -1133.395 -1133.395] [0.0000], Avg: [-1326.051 -1326.051 -1326.051] (1.000)
Step: 68749, Reward: [-1282.833 -1282.833 -1282.833] [0.0000], Avg: [-1326.019 -1326.019 -1326.019] (1.000)
Step: 68799, Reward: [-1197.53 -1197.53 -1197.53] [0.0000], Avg: [-1325.926 -1325.926 -1325.926] (1.000)
Step: 68849, Reward: [-1332.643 -1332.643 -1332.643] [0.0000], Avg: [-1325.931 -1325.931 -1325.931] (1.000)
Step: 68899, Reward: [-1244.731 -1244.731 -1244.731] [0.0000], Avg: [-1325.872 -1325.872 -1325.872] (1.000)
Step: 68949, Reward: [-1015.688 -1015.688 -1015.688] [0.0000], Avg: [-1325.647 -1325.647 -1325.647] (1.000)
Step: 68999, Reward: [-1004.634 -1004.634 -1004.634] [0.0000], Avg: [-1325.415 -1325.415 -1325.415] (1.000)
Step: 69049, Reward: [-892.507 -892.507 -892.507] [0.0000], Avg: [-1325.101 -1325.101 -1325.101] (1.000)
Step: 69099, Reward: [-1210.85 -1210.85 -1210.85] [0.0000], Avg: [-1325.018 -1325.018 -1325.018] (1.000)
Step: 69149, Reward: [-739.617 -739.617 -739.617] [0.0000], Avg: [-1324.595 -1324.595 -1324.595] (1.000)
Step: 69199, Reward: [-674.458 -674.458 -674.458] [0.0000], Avg: [-1324.125 -1324.125 -1324.125] (1.000)
Step: 69249, Reward: [-462.347 -462.347 -462.347] [0.0000], Avg: [-1323.503 -1323.503 -1323.503] (1.000)
Step: 69299, Reward: [-488.101 -488.101 -488.101] [0.0000], Avg: [-1322.9 -1322.9 -1322.9] (1.000)
Step: 69349, Reward: [-627.263 -627.263 -627.263] [0.0000], Avg: [-1322.399 -1322.399 -1322.399] (1.000)
Step: 69399, Reward: [-642.963 -642.963 -642.963] [0.0000], Avg: [-1321.909 -1321.909 -1321.909] (1.000)
Step: 69449, Reward: [-497.042 -497.042 -497.042] [0.0000], Avg: [-1321.315 -1321.315 -1321.315] (1.000)
Step: 69499, Reward: [-660.651 -660.651 -660.651] [0.0000], Avg: [-1320.84 -1320.84 -1320.84] (1.000)
Step: 69549, Reward: [-609.044 -609.044 -609.044] [0.0000], Avg: [-1320.328 -1320.328 -1320.328] (1.000)
Step: 69599, Reward: [-555.486 -555.486 -555.486] [0.0000], Avg: [-1319.779 -1319.779 -1319.779] (1.000)
Step: 69649, Reward: [-401.636 -401.636 -401.636] [0.0000], Avg: [-1319.12 -1319.12 -1319.12] (1.000)
Step: 69699, Reward: [-640.406 -640.406 -640.406] [0.0000], Avg: [-1318.633 -1318.633 -1318.633] (1.000)
Step: 69749, Reward: [-755.422 -755.422 -755.422] [0.0000], Avg: [-1318.229 -1318.229 -1318.229] (1.000)
Step: 69799, Reward: [-545.839 -545.839 -545.839] [0.0000], Avg: [-1317.676 -1317.676 -1317.676] (1.000)
Step: 69849, Reward: [-329.293 -329.293 -329.293] [0.0000], Avg: [-1316.968 -1316.968 -1316.968] (1.000)
Step: 69899, Reward: [-489.066 -489.066 -489.066] [0.0000], Avg: [-1316.376 -1316.376 -1316.376] (1.000)
Step: 69949, Reward: [-541.284 -541.284 -541.284] [0.0000], Avg: [-1315.822 -1315.822 -1315.822] (1.000)
Step: 69999, Reward: [-545.057 -545.057 -545.057] [0.0000], Avg: [-1315.272 -1315.272 -1315.272] (1.000)
Step: 70049, Reward: [-581.495 -581.495 -581.495] [0.0000], Avg: [-1314.748 -1314.748 -1314.748] (1.000)
Step: 70099, Reward: [-438.222 -438.222 -438.222] [0.0000], Avg: [-1314.123 -1314.123 -1314.123] (1.000)
Step: 70149, Reward: [-534.081 -534.081 -534.081] [0.0000], Avg: [-1313.567 -1313.567 -1313.567] (1.000)
Step: 70199, Reward: [-804.255 -804.255 -804.255] [0.0000], Avg: [-1313.204 -1313.204 -1313.204] (1.000)
Step: 70249, Reward: [-612.215 -612.215 -612.215] [0.0000], Avg: [-1312.705 -1312.705 -1312.705] (1.000)
Step: 70299, Reward: [-577.642 -577.642 -577.642] [0.0000], Avg: [-1312.182 -1312.182 -1312.182] (1.000)
Step: 70349, Reward: [-729.263 -729.263 -729.263] [0.0000], Avg: [-1311.768 -1311.768 -1311.768] (1.000)
Step: 70399, Reward: [-667.031 -667.031 -667.031] [0.0000], Avg: [-1311.31 -1311.31 -1311.31] (1.000)
Step: 70449, Reward: [-646.976 -646.976 -646.976] [0.0000], Avg: [-1310.839 -1310.839 -1310.839] (1.000)
Step: 70499, Reward: [-464.722 -464.722 -464.722] [0.0000], Avg: [-1310.238 -1310.238 -1310.238] (1.000)
Step: 70549, Reward: [-601.001 -601.001 -601.001] [0.0000], Avg: [-1309.736 -1309.736 -1309.736] (1.000)
Step: 70599, Reward: [-599.487 -599.487 -599.487] [0.0000], Avg: [-1309.233 -1309.233 -1309.233] (1.000)
Step: 70649, Reward: [-600.872 -600.872 -600.872] [0.0000], Avg: [-1308.731 -1308.731 -1308.731] (1.000)
Step: 70699, Reward: [-675.377 -675.377 -675.377] [0.0000], Avg: [-1308.284 -1308.284 -1308.284] (1.000)
Step: 70749, Reward: [-470.189 -470.189 -470.189] [0.0000], Avg: [-1307.691 -1307.691 -1307.691] (1.000)
Step: 70799, Reward: [-606.395 -606.395 -606.395] [0.0000], Avg: [-1307.196 -1307.196 -1307.196] (1.000)
Step: 70849, Reward: [-473.014 -473.014 -473.014] [0.0000], Avg: [-1306.607 -1306.607 -1306.607] (1.000)
Step: 70899, Reward: [-499.369 -499.369 -499.369] [0.0000], Avg: [-1306.038 -1306.038 -1306.038] (1.000)
Step: 70949, Reward: [-523.442 -523.442 -523.442] [0.0000], Avg: [-1305.487 -1305.487 -1305.487] (1.000)
Step: 70999, Reward: [-459.027 -459.027 -459.027] [0.0000], Avg: [-1304.89 -1304.89 -1304.89] (1.000)
Step: 71049, Reward: [-535.612 -535.612 -535.612] [0.0000], Avg: [-1304.349 -1304.349 -1304.349] (1.000)
Step: 71099, Reward: [-442.124 -442.124 -442.124] [0.0000], Avg: [-1303.743 -1303.743 -1303.743] (1.000)
Step: 71149, Reward: [-630.066 -630.066 -630.066] [0.0000], Avg: [-1303.269 -1303.269 -1303.269] (1.000)
Step: 71199, Reward: [-440.903 -440.903 -440.903] [0.0000], Avg: [-1302.664 -1302.664 -1302.664] (1.000)
Step: 71249, Reward: [-544.004 -544.004 -544.004] [0.0000], Avg: [-1302.131 -1302.131 -1302.131] (1.000)
Step: 71299, Reward: [-770.624 -770.624 -770.624] [0.0000], Avg: [-1301.759 -1301.759 -1301.759] (1.000)
Step: 71349, Reward: [-818.764 -818.764 -818.764] [0.0000], Avg: [-1301.42 -1301.42 -1301.42] (1.000)
Step: 71399, Reward: [-823.291 -823.291 -823.291] [0.0000], Avg: [-1301.085 -1301.085 -1301.085] (1.000)
Step: 71449, Reward: [-733.18 -733.18 -733.18] [0.0000], Avg: [-1300.688 -1300.688 -1300.688] (1.000)
Step: 71499, Reward: [-978.627 -978.627 -978.627] [0.0000], Avg: [-1300.463 -1300.463 -1300.463] (1.000)
Step: 71549, Reward: [-589.911 -589.911 -589.911] [0.0000], Avg: [-1299.966 -1299.966 -1299.966] (1.000)
Step: 71599, Reward: [-614.552 -614.552 -614.552] [0.0000], Avg: [-1299.487 -1299.487 -1299.487] (1.000)
Step: 71649, Reward: [-1148.571 -1148.571 -1148.571] [0.0000], Avg: [-1299.382 -1299.382 -1299.382] (1.000)
Step: 71699, Reward: [-1340.089 -1340.089 -1340.089] [0.0000], Avg: [-1299.411 -1299.411 -1299.411] (1.000)
Step: 71749, Reward: [-444.16 -444.16 -444.16] [0.0000], Avg: [-1298.815 -1298.815 -1298.815] (1.000)
Step: 71799, Reward: [-797.133 -797.133 -797.133] [0.0000], Avg: [-1298.465 -1298.465 -1298.465] (1.000)
Step: 71849, Reward: [-1064.657 -1064.657 -1064.657] [0.0000], Avg: [-1298.302 -1298.302 -1298.302] (1.000)
Step: 71899, Reward: [-1330.21 -1330.21 -1330.21] [0.0000], Avg: [-1298.325 -1298.325 -1298.325] (1.000)
Step: 71949, Reward: [-1739.758 -1739.758 -1739.758] [0.0000], Avg: [-1298.631 -1298.631 -1298.631] (1.000)
Step: 71999, Reward: [-1293.762 -1293.762 -1293.762] [0.0000], Avg: [-1298.628 -1298.628 -1298.628] (1.000)
Step: 72049, Reward: [-849.027 -849.027 -849.027] [0.0000], Avg: [-1298.316 -1298.316 -1298.316] (1.000)
Step: 72099, Reward: [-1463.118 -1463.118 -1463.118] [0.0000], Avg: [-1298.43 -1298.43 -1298.43] (1.000)
Step: 72149, Reward: [-2017.32 -2017.32 -2017.32] [0.0000], Avg: [-1298.929 -1298.929 -1298.929] (1.000)
Step: 72199, Reward: [-1252.672 -1252.672 -1252.672] [0.0000], Avg: [-1298.897 -1298.897 -1298.897] (1.000)
Step: 72249, Reward: [-2249.185 -2249.185 -2249.185] [0.0000], Avg: [-1299.554 -1299.554 -1299.554] (1.000)
Step: 72299, Reward: [-2144.472 -2144.472 -2144.472] [0.0000], Avg: [-1300.138 -1300.138 -1300.138] (1.000)
Step: 72349, Reward: [-2210.866 -2210.866 -2210.866] [0.0000], Avg: [-1300.768 -1300.768 -1300.768] (1.000)
Step: 72399, Reward: [-2025.558 -2025.558 -2025.558] [0.0000], Avg: [-1301.268 -1301.268 -1301.268] (1.000)
Step: 72449, Reward: [-2347.844 -2347.844 -2347.844] [0.0000], Avg: [-1301.991 -1301.991 -1301.991] (1.000)
Step: 72499, Reward: [-2004.856 -2004.856 -2004.856] [0.0000], Avg: [-1302.475 -1302.475 -1302.475] (1.000)
Step: 72549, Reward: [-1859.694 -1859.694 -1859.694] [0.0000], Avg: [-1302.859 -1302.859 -1302.859] (1.000)
Step: 72599, Reward: [-1812.28 -1812.28 -1812.28] [0.0000], Avg: [-1303.21 -1303.21 -1303.21] (1.000)
Step: 72649, Reward: [-1990.03 -1990.03 -1990.03] [0.0000], Avg: [-1303.683 -1303.683 -1303.683] (1.000)
Step: 72699, Reward: [-1869.978 -1869.978 -1869.978] [0.0000], Avg: [-1304.072 -1304.072 -1304.072] (1.000)
Step: 72749, Reward: [-1819.889 -1819.889 -1819.889] [0.0000], Avg: [-1304.427 -1304.427 -1304.427] (1.000)
Step: 72799, Reward: [-1876.278 -1876.278 -1876.278] [0.0000], Avg: [-1304.82 -1304.82 -1304.82] (1.000)
Step: 72849, Reward: [-1942.384 -1942.384 -1942.384] [0.0000], Avg: [-1305.257 -1305.257 -1305.257] (1.000)
Step: 72899, Reward: [-2025.613 -2025.613 -2025.613] [0.0000], Avg: [-1305.751 -1305.751 -1305.751] (1.000)
Step: 72949, Reward: [-1940.953 -1940.953 -1940.953] [0.0000], Avg: [-1306.187 -1306.187 -1306.187] (1.000)
Step: 72999, Reward: [-2213.696 -2213.696 -2213.696] [0.0000], Avg: [-1306.808 -1306.808 -1306.808] (1.000)
Step: 73049, Reward: [-1952.191 -1952.191 -1952.191] [0.0000], Avg: [-1307.25 -1307.25 -1307.25] (1.000)
Step: 73099, Reward: [-1983.458 -1983.458 -1983.458] [0.0000], Avg: [-1307.713 -1307.713 -1307.713] (1.000)
Step: 73149, Reward: [-1958.31 -1958.31 -1958.31] [0.0000], Avg: [-1308.157 -1308.157 -1308.157] (1.000)
Step: 73199, Reward: [-1959.754 -1959.754 -1959.754] [0.0000], Avg: [-1308.602 -1308.602 -1308.602] (1.000)
Step: 73249, Reward: [-2203.922 -2203.922 -2203.922] [0.0000], Avg: [-1309.213 -1309.213 -1309.213] (1.000)
Step: 73299, Reward: [-1947.554 -1947.554 -1947.554] [0.0000], Avg: [-1309.649 -1309.649 -1309.649] (1.000)
Step: 73349, Reward: [-1729.935 -1729.935 -1729.935] [0.0000], Avg: [-1309.935 -1309.935 -1309.935] (1.000)
Step: 73399, Reward: [-1870.057 -1870.057 -1870.057] [0.0000], Avg: [-1310.317 -1310.317 -1310.317] (1.000)
Step: 73449, Reward: [-1994.77 -1994.77 -1994.77] [0.0000], Avg: [-1310.783 -1310.783 -1310.783] (1.000)
Step: 73499, Reward: [-1796.498 -1796.498 -1796.498] [0.0000], Avg: [-1311.113 -1311.113 -1311.113] (1.000)
Step: 73549, Reward: [-1953.628 -1953.628 -1953.628] [0.0000], Avg: [-1311.55 -1311.55 -1311.55] (1.000)
Step: 73599, Reward: [-1771.278 -1771.278 -1771.278] [0.0000], Avg: [-1311.862 -1311.862 -1311.862] (1.000)
Step: 73649, Reward: [-1911.483 -1911.483 -1911.483] [0.0000], Avg: [-1312.269 -1312.269 -1312.269] (1.000)
Step: 73699, Reward: [-2411.238 -2411.238 -2411.238] [0.0000], Avg: [-1313.015 -1313.015 -1313.015] (1.000)
Step: 73749, Reward: [-1673.736 -1673.736 -1673.736] [0.0000], Avg: [-1313.26 -1313.26 -1313.26] (1.000)
Step: 73799, Reward: [-1900.742 -1900.742 -1900.742] [0.0000], Avg: [-1313.658 -1313.658 -1313.658] (1.000)
Step: 73849, Reward: [-1929.753 -1929.753 -1929.753] [0.0000], Avg: [-1314.075 -1314.075 -1314.075] (1.000)
Step: 73899, Reward: [-1570.711 -1570.711 -1570.711] [0.0000], Avg: [-1314.248 -1314.248 -1314.248] (1.000)
Step: 73949, Reward: [-2035.441 -2035.441 -2035.441] [0.0000], Avg: [-1314.736 -1314.736 -1314.736] (1.000)
Step: 73999, Reward: [-1364.551 -1364.551 -1364.551] [0.0000], Avg: [-1314.77 -1314.77 -1314.77] (1.000)
Step: 74049, Reward: [-2003.942 -2003.942 -2003.942] [0.0000], Avg: [-1315.235 -1315.235 -1315.235] (1.000)
Step: 74099, Reward: [-1439.149 -1439.149 -1439.149] [0.0000], Avg: [-1315.319 -1315.319 -1315.319] (1.000)
Step: 74149, Reward: [-1902.695 -1902.695 -1902.695] [0.0000], Avg: [-1315.715 -1315.715 -1315.715] (1.000)
Step: 74199, Reward: [-2032.496 -2032.496 -2032.496] [0.0000], Avg: [-1316.198 -1316.198 -1316.198] (1.000)
Step: 74249, Reward: [-1421.259 -1421.259 -1421.259] [0.0000], Avg: [-1316.268 -1316.268 -1316.268] (1.000)
Step: 74299, Reward: [-2019.61 -2019.61 -2019.61] [0.0000], Avg: [-1316.742 -1316.742 -1316.742] (1.000)
Step: 74349, Reward: [-2077.133 -2077.133 -2077.133] [0.0000], Avg: [-1317.253 -1317.253 -1317.253] (1.000)
Step: 74399, Reward: [-1855.661 -1855.661 -1855.661] [0.0000], Avg: [-1317.615 -1317.615 -1317.615] (1.000)
Step: 74449, Reward: [-2042.935 -2042.935 -2042.935] [0.0000], Avg: [-1318.102 -1318.102 -1318.102] (1.000)
Step: 74499, Reward: [-2070.414 -2070.414 -2070.414] [0.0000], Avg: [-1318.607 -1318.607 -1318.607] (1.000)
Step: 74549, Reward: [-1761.486 -1761.486 -1761.486] [0.0000], Avg: [-1318.904 -1318.904 -1318.904] (1.000)
Step: 74599, Reward: [-1977.324 -1977.324 -1977.324] [0.0000], Avg: [-1319.345 -1319.345 -1319.345] (1.000)
Step: 74649, Reward: [-1889.329 -1889.329 -1889.329] [0.0000], Avg: [-1319.727 -1319.727 -1319.727] (1.000)
Step: 74699, Reward: [-2204.613 -2204.613 -2204.613] [0.0000], Avg: [-1320.319 -1320.319 -1320.319] (1.000)
Step: 74749, Reward: [-1919.714 -1919.714 -1919.714] [0.0000], Avg: [-1320.72 -1320.72 -1320.72] (1.000)
Step: 74799, Reward: [-1953.576 -1953.576 -1953.576] [0.0000], Avg: [-1321.143 -1321.143 -1321.143] (1.000)
Step: 74849, Reward: [-1855.409 -1855.409 -1855.409] [0.0000], Avg: [-1321.5 -1321.5 -1321.5] (1.000)
Step: 74899, Reward: [-1718.291 -1718.291 -1718.291] [0.0000], Avg: [-1321.765 -1321.765 -1321.765] (1.000)
Step: 74949, Reward: [-1286.452 -1286.452 -1286.452] [0.0000], Avg: [-1321.742 -1321.742 -1321.742] (1.000)
Step: 74999, Reward: [-1470.644 -1470.644 -1470.644] [0.0000], Avg: [-1321.841 -1321.841 -1321.841] (1.000)
Step: 75049, Reward: [-980.163 -980.163 -980.163] [0.0000], Avg: [-1321.613 -1321.613 -1321.613] (1.000)
Step: 75099, Reward: [-1096.743 -1096.743 -1096.743] [0.0000], Avg: [-1321.464 -1321.464 -1321.464] (1.000)
Step: 75149, Reward: [-884.541 -884.541 -884.541] [0.0000], Avg: [-1321.173 -1321.173 -1321.173] (1.000)
Step: 75199, Reward: [-895.134 -895.134 -895.134] [0.0000], Avg: [-1320.89 -1320.89 -1320.89] (1.000)
Step: 75249, Reward: [-831.769 -831.769 -831.769] [0.0000], Avg: [-1320.565 -1320.565 -1320.565] (1.000)
Step: 75299, Reward: [-488.448 -488.448 -488.448] [0.0000], Avg: [-1320.012 -1320.012 -1320.012] (1.000)
Step: 75349, Reward: [-606.872 -606.872 -606.872] [0.0000], Avg: [-1319.539 -1319.539 -1319.539] (1.000)
Step: 75399, Reward: [-429.703 -429.703 -429.703] [0.0000], Avg: [-1318.949 -1318.949 -1318.949] (1.000)
Step: 75449, Reward: [-620.459 -620.459 -620.459] [0.0000], Avg: [-1318.486 -1318.486 -1318.486] (1.000)
Step: 75499, Reward: [-521.989 -521.989 -521.989] [0.0000], Avg: [-1317.958 -1317.958 -1317.958] (1.000)
Step: 75549, Reward: [-555.574 -555.574 -555.574] [0.0000], Avg: [-1317.454 -1317.454 -1317.454] (1.000)
Step: 75599, Reward: [-826.414 -826.414 -826.414] [0.0000], Avg: [-1317.129 -1317.129 -1317.129] (1.000)
Step: 75649, Reward: [-740.202 -740.202 -740.202] [0.0000], Avg: [-1316.748 -1316.748 -1316.748] (1.000)
Step: 75699, Reward: [-704.741 -704.741 -704.741] [0.0000], Avg: [-1316.343 -1316.343 -1316.343] (1.000)
Step: 75749, Reward: [-538.121 -538.121 -538.121] [0.0000], Avg: [-1315.83 -1315.83 -1315.83] (1.000)
Step: 75799, Reward: [-554.091 -554.091 -554.091] [0.0000], Avg: [-1315.327 -1315.327 -1315.327] (1.000)
Step: 75849, Reward: [-521.972 -521.972 -521.972] [0.0000], Avg: [-1314.804 -1314.804 -1314.804] (1.000)
Step: 75899, Reward: [-621.723 -621.723 -621.723] [0.0000], Avg: [-1314.348 -1314.348 -1314.348] (1.000)
Step: 75949, Reward: [-840.383 -840.383 -840.383] [0.0000], Avg: [-1314.036 -1314.036 -1314.036] (1.000)
Step: 75999, Reward: [-764.298 -764.298 -764.298] [0.0000], Avg: [-1313.674 -1313.674 -1313.674] (1.000)
Step: 76049, Reward: [-729.332 -729.332 -729.332] [0.0000], Avg: [-1313.29 -1313.29 -1313.29] (1.000)
Step: 76099, Reward: [-524.538 -524.538 -524.538] [0.0000], Avg: [-1312.772 -1312.772 -1312.772] (1.000)
Step: 76149, Reward: [-567.722 -567.722 -567.722] [0.0000], Avg: [-1312.282 -1312.282 -1312.282] (1.000)
Step: 76199, Reward: [-572.486 -572.486 -572.486] [0.0000], Avg: [-1311.797 -1311.797 -1311.797] (1.000)
Step: 76249, Reward: [-651.979 -651.979 -651.979] [0.0000], Avg: [-1311.364 -1311.364 -1311.364] (1.000)
Step: 76299, Reward: [-462.441 -462.441 -462.441] [0.0000], Avg: [-1310.808 -1310.808 -1310.808] (1.000)
Step: 76349, Reward: [-507.298 -507.298 -507.298] [0.0000], Avg: [-1310.282 -1310.282 -1310.282] (1.000)
Step: 76399, Reward: [-418.205 -418.205 -418.205] [0.0000], Avg: [-1309.698 -1309.698 -1309.698] (1.000)
Step: 76449, Reward: [-548.636 -548.636 -548.636] [0.0000], Avg: [-1309.2 -1309.2 -1309.2] (1.000)
Step: 76499, Reward: [-401.036 -401.036 -401.036] [0.0000], Avg: [-1308.607 -1308.607 -1308.607] (1.000)
Step: 76549, Reward: [-498.529 -498.529 -498.529] [0.0000], Avg: [-1308.078 -1308.078 -1308.078] (1.000)
Step: 76599, Reward: [-580.84 -580.84 -580.84] [0.0000], Avg: [-1307.603 -1307.603 -1307.603] (1.000)
Step: 76649, Reward: [-711.167 -711.167 -711.167] [0.0000], Avg: [-1307.214 -1307.214 -1307.214] (1.000)
Step: 76699, Reward: [-575.974 -575.974 -575.974] [0.0000], Avg: [-1306.737 -1306.737 -1306.737] (1.000)
Step: 76749, Reward: [-455.298 -455.298 -455.298] [0.0000], Avg: [-1306.182 -1306.182 -1306.182] (1.000)
Step: 76799, Reward: [-673.849 -673.849 -673.849] [0.0000], Avg: [-1305.771 -1305.771 -1305.771] (1.000)
Step: 76849, Reward: [-540.875 -540.875 -540.875] [0.0000], Avg: [-1305.273 -1305.273 -1305.273] (1.000)
Step: 76899, Reward: [-638.172 -638.172 -638.172] [0.0000], Avg: [-1304.839 -1304.839 -1304.839] (1.000)
Step: 76949, Reward: [-850.062 -850.062 -850.062] [0.0000], Avg: [-1304.544 -1304.544 -1304.544] (1.000)
Step: 76999, Reward: [-389.406 -389.406 -389.406] [0.0000], Avg: [-1303.95 -1303.95 -1303.95] (1.000)
Step: 77049, Reward: [-673.363 -673.363 -673.363] [0.0000], Avg: [-1303.54 -1303.54 -1303.54] (1.000)
Step: 77099, Reward: [-1189.943 -1189.943 -1189.943] [0.0000], Avg: [-1303.467 -1303.467 -1303.467] (1.000)
Step: 77149, Reward: [-1242.781 -1242.781 -1242.781] [0.0000], Avg: [-1303.427 -1303.427 -1303.427] (1.000)
Step: 77199, Reward: [-1407.922 -1407.922 -1407.922] [0.0000], Avg: [-1303.495 -1303.495 -1303.495] (1.000)
Step: 77249, Reward: [-655.035 -655.035 -655.035] [0.0000], Avg: [-1303.075 -1303.075 -1303.075] (1.000)
Step: 77299, Reward: [-1225.72 -1225.72 -1225.72] [0.0000], Avg: [-1303.025 -1303.025 -1303.025] (1.000)
Step: 77349, Reward: [-437.105 -437.105 -437.105] [0.0000], Avg: [-1302.466 -1302.466 -1302.466] (1.000)
Step: 77399, Reward: [-1381.573 -1381.573 -1381.573] [0.0000], Avg: [-1302.517 -1302.517 -1302.517] (1.000)
Step: 77449, Reward: [-558.313 -558.313 -558.313] [0.0000], Avg: [-1302.036 -1302.036 -1302.036] (1.000)
Step: 77499, Reward: [-2145.116 -2145.116 -2145.116] [0.0000], Avg: [-1302.58 -1302.58 -1302.58] (1.000)
Step: 77549, Reward: [-630.277 -630.277 -630.277] [0.0000], Avg: [-1302.147 -1302.147 -1302.147] (1.000)
Step: 77599, Reward: [-1438.392 -1438.392 -1438.392] [0.0000], Avg: [-1302.235 -1302.235 -1302.235] (1.000)
Step: 77649, Reward: [-581.39 -581.39 -581.39] [0.0000], Avg: [-1301.77 -1301.77 -1301.77] (1.000)
Step: 77699, Reward: [-610.041 -610.041 -610.041] [0.0000], Avg: [-1301.325 -1301.325 -1301.325] (1.000)
Step: 77749, Reward: [-639.258 -639.258 -639.258] [0.0000], Avg: [-1300.899 -1300.899 -1300.899] (1.000)
Step: 77799, Reward: [-602.059 -602.059 -602.059] [0.0000], Avg: [-1300.45 -1300.45 -1300.45] (1.000)
Step: 77849, Reward: [-2346.103 -2346.103 -2346.103] [0.0000], Avg: [-1301.122 -1301.122 -1301.122] (1.000)
Step: 77899, Reward: [-732.518 -732.518 -732.518] [0.0000], Avg: [-1300.757 -1300.757 -1300.757] (1.000)
Step: 77949, Reward: [-531.746 -531.746 -531.746] [0.0000], Avg: [-1300.264 -1300.264 -1300.264] (1.000)
Step: 77999, Reward: [-1690.64 -1690.64 -1690.64] [0.0000], Avg: [-1300.514 -1300.514 -1300.514] (1.000)
Step: 78049, Reward: [-1869.851 -1869.851 -1869.851] [0.0000], Avg: [-1300.879 -1300.879 -1300.879] (1.000)
Step: 78099, Reward: [-2031.187 -2031.187 -2031.187] [0.0000], Avg: [-1301.346 -1301.346 -1301.346] (1.000)
Step: 78149, Reward: [-1900.997 -1900.997 -1900.997] [0.0000], Avg: [-1301.73 -1301.73 -1301.73] (1.000)
Step: 78199, Reward: [-2012.88 -2012.88 -2012.88] [0.0000], Avg: [-1302.185 -1302.185 -1302.185] (1.000)
Step: 78249, Reward: [-1588.621 -1588.621 -1588.621] [0.0000], Avg: [-1302.368 -1302.368 -1302.368] (1.000)
Step: 78299, Reward: [-1735.968 -1735.968 -1735.968] [0.0000], Avg: [-1302.644 -1302.644 -1302.644] (1.000)
Step: 78349, Reward: [-2025.473 -2025.473 -2025.473] [0.0000], Avg: [-1303.106 -1303.106 -1303.106] (1.000)
Step: 78399, Reward: [-1765.888 -1765.888 -1765.888] [0.0000], Avg: [-1303.401 -1303.401 -1303.401] (1.000)
Step: 78449, Reward: [-2013.808 -2013.808 -2013.808] [0.0000], Avg: [-1303.854 -1303.854 -1303.854] (1.000)
Step: 78499, Reward: [-1563.813 -1563.813 -1563.813] [0.0000], Avg: [-1304.019 -1304.019 -1304.019] (1.000)
Step: 78549, Reward: [-1863.723 -1863.723 -1863.723] [0.0000], Avg: [-1304.376 -1304.376 -1304.376] (1.000)
Step: 78599, Reward: [-1917.719 -1917.719 -1917.719] [0.0000], Avg: [-1304.766 -1304.766 -1304.766] (1.000)
Step: 78649, Reward: [-2018.978 -2018.978 -2018.978] [0.0000], Avg: [-1305.22 -1305.22 -1305.22] (1.000)
Step: 78699, Reward: [-2192.926 -2192.926 -2192.926] [0.0000], Avg: [-1305.784 -1305.784 -1305.784] (1.000)
Step: 78749, Reward: [-1417.696 -1417.696 -1417.696] [0.0000], Avg: [-1305.855 -1305.855 -1305.855] (1.000)
Step: 78799, Reward: [-1457.78 -1457.78 -1457.78] [0.0000], Avg: [-1305.951 -1305.951 -1305.951] (1.000)
Step: 78849, Reward: [-1561.658 -1561.658 -1561.658] [0.0000], Avg: [-1306.113 -1306.113 -1306.113] (1.000)
Step: 78899, Reward: [-1364.958 -1364.958 -1364.958] [0.0000], Avg: [-1306.151 -1306.151 -1306.151] (1.000)
Step: 78949, Reward: [-1585.11 -1585.11 -1585.11] [0.0000], Avg: [-1306.327 -1306.327 -1306.327] (1.000)
Step: 78999, Reward: [-1708.391 -1708.391 -1708.391] [0.0000], Avg: [-1306.582 -1306.582 -1306.582] (1.000)
Step: 79049, Reward: [-1765.102 -1765.102 -1765.102] [0.0000], Avg: [-1306.872 -1306.872 -1306.872] (1.000)
Step: 79099, Reward: [-1553.757 -1553.757 -1553.757] [0.0000], Avg: [-1307.028 -1307.028 -1307.028] (1.000)
Step: 79149, Reward: [-1351.49 -1351.49 -1351.49] [0.0000], Avg: [-1307.056 -1307.056 -1307.056] (1.000)
Step: 79199, Reward: [-1861.88 -1861.88 -1861.88] [0.0000], Avg: [-1307.406 -1307.406 -1307.406] (1.000)
Step: 79249, Reward: [-1902.678 -1902.678 -1902.678] [0.0000], Avg: [-1307.782 -1307.782 -1307.782] (1.000)
Step: 79299, Reward: [-1836.985 -1836.985 -1836.985] [0.0000], Avg: [-1308.115 -1308.115 -1308.115] (1.000)
Step: 79349, Reward: [-1514.015 -1514.015 -1514.015] [0.0000], Avg: [-1308.245 -1308.245 -1308.245] (1.000)
Step: 79399, Reward: [-1029.631 -1029.631 -1029.631] [0.0000], Avg: [-1308.07 -1308.07 -1308.07] (1.000)
Step: 79449, Reward: [-1893.594 -1893.594 -1893.594] [0.0000], Avg: [-1308.438 -1308.438 -1308.438] (1.000)
Step: 79499, Reward: [-1168.195 -1168.195 -1168.195] [0.0000], Avg: [-1308.35 -1308.35 -1308.35] (1.000)
Step: 79549, Reward: [-1256.422 -1256.422 -1256.422] [0.0000], Avg: [-1308.317 -1308.317 -1308.317] (1.000)
Step: 79599, Reward: [-945.82 -945.82 -945.82] [0.0000], Avg: [-1308.09 -1308.09 -1308.09] (1.000)
Step: 79649, Reward: [-1380.383 -1380.383 -1380.383] [0.0000], Avg: [-1308.135 -1308.135 -1308.135] (1.000)
Step: 79699, Reward: [-1368.914 -1368.914 -1368.914] [0.0000], Avg: [-1308.173 -1308.173 -1308.173] (1.000)
Step: 79749, Reward: [-1095.972 -1095.972 -1095.972] [0.0000], Avg: [-1308.04 -1308.04 -1308.04] (1.000)
Step: 79799, Reward: [-1142.947 -1142.947 -1142.947] [0.0000], Avg: [-1307.937 -1307.937 -1307.937] (1.000)
Step: 79849, Reward: [-1627.703 -1627.703 -1627.703] [0.0000], Avg: [-1308.137 -1308.137 -1308.137] (1.000)
Step: 79899, Reward: [-1990.65 -1990.65 -1990.65] [0.0000], Avg: [-1308.564 -1308.564 -1308.564] (1.000)
Step: 79949, Reward: [-1315.396 -1315.396 -1315.396] [0.0000], Avg: [-1308.568 -1308.568 -1308.568] (1.000)
Step: 79999, Reward: [-1922.506 -1922.506 -1922.506] [0.0000], Avg: [-1308.952 -1308.952 -1308.952] (1.000)
Step: 80049, Reward: [-1854.049 -1854.049 -1854.049] [0.0000], Avg: [-1309.292 -1309.292 -1309.292] (1.000)
Step: 80099, Reward: [-1845.439 -1845.439 -1845.439] [0.0000], Avg: [-1309.627 -1309.627 -1309.627] (1.000)
Step: 80149, Reward: [-1703.002 -1703.002 -1703.002] [0.0000], Avg: [-1309.873 -1309.873 -1309.873] (1.000)
Step: 80199, Reward: [-1650.655 -1650.655 -1650.655] [0.0000], Avg: [-1310.085 -1310.085 -1310.085] (1.000)
Step: 80249, Reward: [-1765.896 -1765.896 -1765.896] [0.0000], Avg: [-1310.369 -1310.369 -1310.369] (1.000)
Step: 80299, Reward: [-1397.086 -1397.086 -1397.086] [0.0000], Avg: [-1310.423 -1310.423 -1310.423] (1.000)
Step: 80349, Reward: [-2025.494 -2025.494 -2025.494] [0.0000], Avg: [-1310.868 -1310.868 -1310.868] (1.000)
Step: 80399, Reward: [-1594.757 -1594.757 -1594.757] [0.0000], Avg: [-1311.045 -1311.045 -1311.045] (1.000)
Step: 80449, Reward: [-615.391 -615.391 -615.391] [0.0000], Avg: [-1310.612 -1310.612 -1310.612] (1.000)
Step: 80499, Reward: [-965.214 -965.214 -965.214] [0.0000], Avg: [-1310.398 -1310.398 -1310.398] (1.000)
Step: 80549, Reward: [-1859.912 -1859.912 -1859.912] [0.0000], Avg: [-1310.739 -1310.739 -1310.739] (1.000)
Step: 80599, Reward: [-905.313 -905.313 -905.313] [0.0000], Avg: [-1310.487 -1310.487 -1310.487] (1.000)
Step: 80649, Reward: [-827.604 -827.604 -827.604] [0.0000], Avg: [-1310.188 -1310.188 -1310.188] (1.000)
Step: 80699, Reward: [-1038.882 -1038.882 -1038.882] [0.0000], Avg: [-1310.02 -1310.02 -1310.02] (1.000)
Step: 80749, Reward: [-1763.934 -1763.934 -1763.934] [0.0000], Avg: [-1310.301 -1310.301 -1310.301] (1.000)
Step: 80799, Reward: [-2071.131 -2071.131 -2071.131] [0.0000], Avg: [-1310.772 -1310.772 -1310.772] (1.000)
Step: 80849, Reward: [-881.292 -881.292 -881.292] [0.0000], Avg: [-1310.506 -1310.506 -1310.506] (1.000)
Step: 80899, Reward: [-1470.991 -1470.991 -1470.991] [0.0000], Avg: [-1310.605 -1310.605 -1310.605] (1.000)
Step: 80949, Reward: [-1131.573 -1131.573 -1131.573] [0.0000], Avg: [-1310.495 -1310.495 -1310.495] (1.000)
Step: 80999, Reward: [-1554.485 -1554.485 -1554.485] [0.0000], Avg: [-1310.645 -1310.645 -1310.645] (1.000)
Step: 81049, Reward: [-1710.119 -1710.119 -1710.119] [0.0000], Avg: [-1310.892 -1310.892 -1310.892] (1.000)
Step: 81099, Reward: [-1655.247 -1655.247 -1655.247] [0.0000], Avg: [-1311.104 -1311.104 -1311.104] (1.000)
Step: 81149, Reward: [-1814.193 -1814.193 -1814.193] [0.0000], Avg: [-1311.414 -1311.414 -1311.414] (1.000)
Step: 81199, Reward: [-1679.228 -1679.228 -1679.228] [0.0000], Avg: [-1311.64 -1311.64 -1311.64] (1.000)
Step: 81249, Reward: [-1422.035 -1422.035 -1422.035] [0.0000], Avg: [-1311.708 -1311.708 -1311.708] (1.000)
Step: 81299, Reward: [-1540.149 -1540.149 -1540.149] [0.0000], Avg: [-1311.849 -1311.849 -1311.849] (1.000)
Step: 81349, Reward: [-1731.425 -1731.425 -1731.425] [0.0000], Avg: [-1312.107 -1312.107 -1312.107] (1.000)
Step: 81399, Reward: [-1949.814 -1949.814 -1949.814] [0.0000], Avg: [-1312.498 -1312.498 -1312.498] (1.000)
Step: 81449, Reward: [-1625.31 -1625.31 -1625.31] [0.0000], Avg: [-1312.691 -1312.691 -1312.691] (1.000)
Step: 81499, Reward: [-1742.973 -1742.973 -1742.973] [0.0000], Avg: [-1312.954 -1312.954 -1312.954] (1.000)
Step: 81549, Reward: [-2044.446 -2044.446 -2044.446] [0.0000], Avg: [-1313.403 -1313.403 -1313.403] (1.000)
Step: 81599, Reward: [-1894.025 -1894.025 -1894.025] [0.0000], Avg: [-1313.759 -1313.759 -1313.759] (1.000)
Step: 81649, Reward: [-2025.726 -2025.726 -2025.726] [0.0000], Avg: [-1314.195 -1314.195 -1314.195] (1.000)
Step: 81699, Reward: [-2034.222 -2034.222 -2034.222] [0.0000], Avg: [-1314.635 -1314.635 -1314.635] (1.000)
Step: 81749, Reward: [-1650.174 -1650.174 -1650.174] [0.0000], Avg: [-1314.841 -1314.841 -1314.841] (1.000)
Step: 81799, Reward: [-1958.393 -1958.393 -1958.393] [0.0000], Avg: [-1315.234 -1315.234 -1315.234] (1.000)
Step: 81849, Reward: [-2130.585 -2130.585 -2130.585] [0.0000], Avg: [-1315.732 -1315.732 -1315.732] (1.000)
Step: 81899, Reward: [-1257.449 -1257.449 -1257.449] [0.0000], Avg: [-1315.696 -1315.696 -1315.696] (1.000)
Step: 81949, Reward: [-1924.61 -1924.61 -1924.61] [0.0000], Avg: [-1316.068 -1316.068 -1316.068] (1.000)
Step: 81999, Reward: [-1715.534 -1715.534 -1715.534] [0.0000], Avg: [-1316.312 -1316.312 -1316.312] (1.000)
Step: 82049, Reward: [-1997.434 -1997.434 -1997.434] [0.0000], Avg: [-1316.727 -1316.727 -1316.727] (1.000)
Step: 82099, Reward: [-1703.81 -1703.81 -1703.81] [0.0000], Avg: [-1316.962 -1316.962 -1316.962] (1.000)
Step: 82149, Reward: [-1874.587 -1874.587 -1874.587] [0.0000], Avg: [-1317.302 -1317.302 -1317.302] (1.000)
Step: 82199, Reward: [-2155.899 -2155.899 -2155.899] [0.0000], Avg: [-1317.812 -1317.812 -1317.812] (1.000)
Step: 82249, Reward: [-2120.641 -2120.641 -2120.641] [0.0000], Avg: [-1318.3 -1318.3 -1318.3] (1.000)
Step: 82299, Reward: [-1638.858 -1638.858 -1638.858] [0.0000], Avg: [-1318.495 -1318.495 -1318.495] (1.000)
Step: 82349, Reward: [-1952.976 -1952.976 -1952.976] [0.0000], Avg: [-1318.88 -1318.88 -1318.88] (1.000)
Step: 82399, Reward: [-1430.146 -1430.146 -1430.146] [0.0000], Avg: [-1318.947 -1318.947 -1318.947] (1.000)
Step: 82449, Reward: [-1733.259 -1733.259 -1733.259] [0.0000], Avg: [-1319.199 -1319.199 -1319.199] (1.000)
Step: 82499, Reward: [-1993.853 -1993.853 -1993.853] [0.0000], Avg: [-1319.608 -1319.608 -1319.608] (1.000)
Step: 82549, Reward: [-2092.383 -2092.383 -2092.383] [0.0000], Avg: [-1320.076 -1320.076 -1320.076] (1.000)
Step: 82599, Reward: [-2082.03 -2082.03 -2082.03] [0.0000], Avg: [-1320.537 -1320.537 -1320.537] (1.000)
Step: 82649, Reward: [-1850.118 -1850.118 -1850.118] [0.0000], Avg: [-1320.857 -1320.857 -1320.857] (1.000)
Step: 82699, Reward: [-1858.853 -1858.853 -1858.853] [0.0000], Avg: [-1321.182 -1321.182 -1321.182] (1.000)
Step: 82749, Reward: [-1808.536 -1808.536 -1808.536] [0.0000], Avg: [-1321.477 -1321.477 -1321.477] (1.000)
Step: 82799, Reward: [-2012.91 -2012.91 -2012.91] [0.0000], Avg: [-1321.894 -1321.894 -1321.894] (1.000)
Step: 82849, Reward: [-1728.245 -1728.245 -1728.245] [0.0000], Avg: [-1322.14 -1322.14 -1322.14] (1.000)
Step: 82899, Reward: [-2033.766 -2033.766 -2033.766] [0.0000], Avg: [-1322.569 -1322.569 -1322.569] (1.000)
Step: 82949, Reward: [-1843.514 -1843.514 -1843.514] [0.0000], Avg: [-1322.883 -1322.883 -1322.883] (1.000)
Step: 82999, Reward: [-1877.802 -1877.802 -1877.802] [0.0000], Avg: [-1323.217 -1323.217 -1323.217] (1.000)
Step: 83049, Reward: [-1392.373 -1392.373 -1392.373] [0.0000], Avg: [-1323.259 -1323.259 -1323.259] (1.000)
Step: 83099, Reward: [-2025.698 -2025.698 -2025.698] [0.0000], Avg: [-1323.682 -1323.682 -1323.682] (1.000)
Step: 83149, Reward: [-1841.092 -1841.092 -1841.092] [0.0000], Avg: [-1323.993 -1323.993 -1323.993] (1.000)
Step: 83199, Reward: [-1703.647 -1703.647 -1703.647] [0.0000], Avg: [-1324.221 -1324.221 -1324.221] (1.000)
Step: 83249, Reward: [-1884.68 -1884.68 -1884.68] [0.0000], Avg: [-1324.557 -1324.557 -1324.557] (1.000)
Step: 83299, Reward: [-2042.429 -2042.429 -2042.429] [0.0000], Avg: [-1324.988 -1324.988 -1324.988] (1.000)
Step: 83349, Reward: [-1705.135 -1705.135 -1705.135] [0.0000], Avg: [-1325.216 -1325.216 -1325.216] (1.000)
Step: 83399, Reward: [-1851.076 -1851.076 -1851.076] [0.0000], Avg: [-1325.532 -1325.532 -1325.532] (1.000)
Step: 83449, Reward: [-1520.782 -1520.782 -1520.782] [0.0000], Avg: [-1325.649 -1325.649 -1325.649] (1.000)
Step: 83499, Reward: [-1882.057 -1882.057 -1882.057] [0.0000], Avg: [-1325.982 -1325.982 -1325.982] (1.000)
Step: 83549, Reward: [-2084.515 -2084.515 -2084.515] [0.0000], Avg: [-1326.436 -1326.436 -1326.436] (1.000)
Step: 83599, Reward: [-1905.94 -1905.94 -1905.94] [0.0000], Avg: [-1326.782 -1326.782 -1326.782] (1.000)
Step: 83649, Reward: [-1849.34 -1849.34 -1849.34] [0.0000], Avg: [-1327.095 -1327.095 -1327.095] (1.000)
Step: 83699, Reward: [-1842.802 -1842.802 -1842.802] [0.0000], Avg: [-1327.403 -1327.403 -1327.403] (1.000)
Step: 83749, Reward: [-1922.953 -1922.953 -1922.953] [0.0000], Avg: [-1327.758 -1327.758 -1327.758] (1.000)
Step: 83799, Reward: [-1890.896 -1890.896 -1890.896] [0.0000], Avg: [-1328.094 -1328.094 -1328.094] (1.000)
Step: 83849, Reward: [-1962.622 -1962.622 -1962.622] [0.0000], Avg: [-1328.473 -1328.473 -1328.473] (1.000)
Step: 83899, Reward: [-1928.092 -1928.092 -1928.092] [0.0000], Avg: [-1328.83 -1328.83 -1328.83] (1.000)
Step: 83949, Reward: [-2021.11 -2021.11 -2021.11] [0.0000], Avg: [-1329.242 -1329.242 -1329.242] (1.000)
Step: 83999, Reward: [-1822.924 -1822.924 -1822.924] [0.0000], Avg: [-1329.536 -1329.536 -1329.536] (1.000)
Step: 84049, Reward: [-2160.162 -2160.162 -2160.162] [0.0000], Avg: [-1330.03 -1330.03 -1330.03] (1.000)
Step: 84099, Reward: [-1626.049 -1626.049 -1626.049] [0.0000], Avg: [-1330.206 -1330.206 -1330.206] (1.000)
Step: 84149, Reward: [-1506.867 -1506.867 -1506.867] [0.0000], Avg: [-1330.311 -1330.311 -1330.311] (1.000)
Step: 84199, Reward: [-1776.846 -1776.846 -1776.846] [0.0000], Avg: [-1330.576 -1330.576 -1330.576] (1.000)
Step: 84249, Reward: [-1991.841 -1991.841 -1991.841] [0.0000], Avg: [-1330.969 -1330.969 -1330.969] (1.000)
Step: 84299, Reward: [-1849.095 -1849.095 -1849.095] [0.0000], Avg: [-1331.276 -1331.276 -1331.276] (1.000)
Step: 84349, Reward: [-1405.906 -1405.906 -1405.906] [0.0000], Avg: [-1331.32 -1331.32 -1331.32] (1.000)
Step: 84399, Reward: [-902.754 -902.754 -902.754] [0.0000], Avg: [-1331.067 -1331.067 -1331.067] (1.000)
Step: 84449, Reward: [-623.273 -623.273 -623.273] [0.0000], Avg: [-1330.647 -1330.647 -1330.647] (1.000)
Step: 84499, Reward: [-1203.794 -1203.794 -1203.794] [0.0000], Avg: [-1330.572 -1330.572 -1330.572] (1.000)
Step: 84549, Reward: [-809.277 -809.277 -809.277] [0.0000], Avg: [-1330.264 -1330.264 -1330.264] (1.000)
Step: 84599, Reward: [-719.662 -719.662 -719.662] [0.0000], Avg: [-1329.903 -1329.903 -1329.903] (1.000)
Step: 84649, Reward: [-669.089 -669.089 -669.089] [0.0000], Avg: [-1329.513 -1329.513 -1329.513] (1.000)
Step: 84699, Reward: [-804.716 -804.716 -804.716] [0.0000], Avg: [-1329.203 -1329.203 -1329.203] (1.000)
Step: 84749, Reward: [-616.238 -616.238 -616.238] [0.0000], Avg: [-1328.783 -1328.783 -1328.783] (1.000)
Step: 84799, Reward: [-898.915 -898.915 -898.915] [0.0000], Avg: [-1328.529 -1328.529 -1328.529] (1.000)
Step: 84849, Reward: [-975.647 -975.647 -975.647] [0.0000], Avg: [-1328.321 -1328.321 -1328.321] (1.000)
Step: 84899, Reward: [-1054.942 -1054.942 -1054.942] [0.0000], Avg: [-1328.16 -1328.16 -1328.16] (1.000)
Step: 84949, Reward: [-1171.019 -1171.019 -1171.019] [0.0000], Avg: [-1328.068 -1328.068 -1328.068] (1.000)
Step: 84999, Reward: [-1190.114 -1190.114 -1190.114] [0.0000], Avg: [-1327.986 -1327.986 -1327.986] (1.000)
Step: 85049, Reward: [-1405.941 -1405.941 -1405.941] [0.0000], Avg: [-1328.032 -1328.032 -1328.032] (1.000)
Step: 85099, Reward: [-1465.182 -1465.182 -1465.182] [0.0000], Avg: [-1328.113 -1328.113 -1328.113] (1.000)
Step: 85149, Reward: [-1485.166 -1485.166 -1485.166] [0.0000], Avg: [-1328.205 -1328.205 -1328.205] (1.000)
Step: 85199, Reward: [-1602.651 -1602.651 -1602.651] [0.0000], Avg: [-1328.366 -1328.366 -1328.366] (1.000)
Step: 85249, Reward: [-1494.611 -1494.611 -1494.611] [0.0000], Avg: [-1328.464 -1328.464 -1328.464] (1.000)
Step: 85299, Reward: [-1989.826 -1989.826 -1989.826] [0.0000], Avg: [-1328.851 -1328.851 -1328.851] (1.000)
Step: 85349, Reward: [-1513.87 -1513.87 -1513.87] [0.0000], Avg: [-1328.96 -1328.96 -1328.96] (1.000)
Step: 85399, Reward: [-1858.926 -1858.926 -1858.926] [0.0000], Avg: [-1329.27 -1329.27 -1329.27] (1.000)
Step: 85449, Reward: [-1702.102 -1702.102 -1702.102] [0.0000], Avg: [-1329.488 -1329.488 -1329.488] (1.000)
Step: 85499, Reward: [-1576.46 -1576.46 -1576.46] [0.0000], Avg: [-1329.633 -1329.633 -1329.633] (1.000)
Step: 85549, Reward: [-1677.939 -1677.939 -1677.939] [0.0000], Avg: [-1329.836 -1329.836 -1329.836] (1.000)
Step: 85599, Reward: [-2155.183 -2155.183 -2155.183] [0.0000], Avg: [-1330.318 -1330.318 -1330.318] (1.000)
Step: 85649, Reward: [-1719.805 -1719.805 -1719.805] [0.0000], Avg: [-1330.546 -1330.546 -1330.546] (1.000)
Step: 85699, Reward: [-1796.196 -1796.196 -1796.196] [0.0000], Avg: [-1330.817 -1330.817 -1330.817] (1.000)
Step: 85749, Reward: [-1131.235 -1131.235 -1131.235] [0.0000], Avg: [-1330.701 -1330.701 -1330.701] (1.000)
Step: 85799, Reward: [-1038.904 -1038.904 -1038.904] [0.0000], Avg: [-1330.531 -1330.531 -1330.531] (1.000)
Step: 85849, Reward: [-1894.414 -1894.414 -1894.414] [0.0000], Avg: [-1330.859 -1330.859 -1330.859] (1.000)
Step: 85899, Reward: [-1430.938 -1430.938 -1430.938] [0.0000], Avg: [-1330.918 -1330.918 -1330.918] (1.000)
Step: 85949, Reward: [-1180.44 -1180.44 -1180.44] [0.0000], Avg: [-1330.83 -1330.83 -1330.83] (1.000)
Step: 85999, Reward: [-1438.026 -1438.026 -1438.026] [0.0000], Avg: [-1330.892 -1330.892 -1330.892] (1.000)
Step: 86049, Reward: [-922.764 -922.764 -922.764] [0.0000], Avg: [-1330.655 -1330.655 -1330.655] (1.000)
Step: 86099, Reward: [-953.724 -953.724 -953.724] [0.0000], Avg: [-1330.436 -1330.436 -1330.436] (1.000)
Step: 86149, Reward: [-1026.027 -1026.027 -1026.027] [0.0000], Avg: [-1330.26 -1330.26 -1330.26] (1.000)
Step: 86199, Reward: [-1373.764 -1373.764 -1373.764] [0.0000], Avg: [-1330.285 -1330.285 -1330.285] (1.000)
Step: 86249, Reward: [-973.151 -973.151 -973.151] [0.0000], Avg: [-1330.078 -1330.078 -1330.078] (1.000)
Step: 86299, Reward: [-680.699 -680.699 -680.699] [0.0000], Avg: [-1329.702 -1329.702 -1329.702] (1.000)
Step: 86349, Reward: [-1162.046 -1162.046 -1162.046] [0.0000], Avg: [-1329.604 -1329.604 -1329.604] (1.000)
Step: 86399, Reward: [-1744.71 -1744.71 -1744.71] [0.0000], Avg: [-1329.845 -1329.845 -1329.845] (1.000)
Step: 86449, Reward: [-715.12 -715.12 -715.12] [0.0000], Avg: [-1329.489 -1329.489 -1329.489] (1.000)
Step: 86499, Reward: [-998.595 -998.595 -998.595] [0.0000], Avg: [-1329.298 -1329.298 -1329.298] (1.000)
Step: 86549, Reward: [-1399.14 -1399.14 -1399.14] [0.0000], Avg: [-1329.338 -1329.338 -1329.338] (1.000)
Step: 86599, Reward: [-1301.564 -1301.564 -1301.564] [0.0000], Avg: [-1329.322 -1329.322 -1329.322] (1.000)
Step: 86649, Reward: [-1870.75 -1870.75 -1870.75] [0.0000], Avg: [-1329.635 -1329.635 -1329.635] (1.000)
Step: 86699, Reward: [-1225.071 -1225.071 -1225.071] [0.0000], Avg: [-1329.574 -1329.574 -1329.574] (1.000)
Step: 86749, Reward: [-1758.272 -1758.272 -1758.272] [0.0000], Avg: [-1329.821 -1329.821 -1329.821] (1.000)
Step: 86799, Reward: [-1806.481 -1806.481 -1806.481] [0.0000], Avg: [-1330.096 -1330.096 -1330.096] (1.000)
Step: 86849, Reward: [-1991.361 -1991.361 -1991.361] [0.0000], Avg: [-1330.477 -1330.477 -1330.477] (1.000)
Step: 86899, Reward: [-1800.807 -1800.807 -1800.807] [0.0000], Avg: [-1330.747 -1330.747 -1330.747] (1.000)
Step: 86949, Reward: [-1615.746 -1615.746 -1615.746] [0.0000], Avg: [-1330.911 -1330.911 -1330.911] (1.000)
Step: 86999, Reward: [-1589.836 -1589.836 -1589.836] [0.0000], Avg: [-1331.06 -1331.06 -1331.06] (1.000)
Step: 87049, Reward: [-1494.538 -1494.538 -1494.538] [0.0000], Avg: [-1331.154 -1331.154 -1331.154] (1.000)
Step: 87099, Reward: [-1838.235 -1838.235 -1838.235] [0.0000], Avg: [-1331.445 -1331.445 -1331.445] (1.000)
Step: 87149, Reward: [-1285.243 -1285.243 -1285.243] [0.0000], Avg: [-1331.418 -1331.418 -1331.418] (1.000)
Step: 87199, Reward: [-1420.188 -1420.188 -1420.188] [0.0000], Avg: [-1331.469 -1331.469 -1331.469] (1.000)
Step: 87249, Reward: [-1101.67 -1101.67 -1101.67] [0.0000], Avg: [-1331.338 -1331.338 -1331.338] (1.000)
Step: 87299, Reward: [-1606.67 -1606.67 -1606.67] [0.0000], Avg: [-1331.495 -1331.495 -1331.495] (1.000)
Step: 87349, Reward: [-699.811 -699.811 -699.811] [0.0000], Avg: [-1331.134 -1331.134 -1331.134] (1.000)
Step: 87399, Reward: [-845.59 -845.59 -845.59] [0.0000], Avg: [-1330.856 -1330.856 -1330.856] (1.000)
Step: 87449, Reward: [-851.348 -851.348 -851.348] [0.0000], Avg: [-1330.582 -1330.582 -1330.582] (1.000)
Step: 87499, Reward: [-1375.392 -1375.392 -1375.392] [0.0000], Avg: [-1330.607 -1330.607 -1330.607] (1.000)
Step: 87549, Reward: [-1051.855 -1051.855 -1051.855] [0.0000], Avg: [-1330.448 -1330.448 -1330.448] (1.000)
Step: 87599, Reward: [-826.853 -826.853 -826.853] [0.0000], Avg: [-1330.161 -1330.161 -1330.161] (1.000)
Step: 87649, Reward: [-1049.372 -1049.372 -1049.372] [0.0000], Avg: [-1330.001 -1330.001 -1330.001] (1.000)
Step: 87699, Reward: [-1907.43 -1907.43 -1907.43] [0.0000], Avg: [-1330.33 -1330.33 -1330.33] (1.000)
Step: 87749, Reward: [-778.265 -778.265 -778.265] [0.0000], Avg: [-1330.015 -1330.015 -1330.015] (1.000)
Step: 87799, Reward: [-1442.248 -1442.248 -1442.248] [0.0000], Avg: [-1330.079 -1330.079 -1330.079] (1.000)
Step: 87849, Reward: [-1524.491 -1524.491 -1524.491] [0.0000], Avg: [-1330.19 -1330.19 -1330.19] (1.000)
Step: 87899, Reward: [-880.367 -880.367 -880.367] [0.0000], Avg: [-1329.934 -1329.934 -1329.934] (1.000)
Step: 87949, Reward: [-1031.47 -1031.47 -1031.47] [0.0000], Avg: [-1329.764 -1329.764 -1329.764] (1.000)
Step: 87999, Reward: [-1380.069 -1380.069 -1380.069] [0.0000], Avg: [-1329.793 -1329.793 -1329.793] (1.000)
Step: 88049, Reward: [-1057.635 -1057.635 -1057.635] [0.0000], Avg: [-1329.638 -1329.638 -1329.638] (1.000)
Step: 88099, Reward: [-985.102 -985.102 -985.102] [0.0000], Avg: [-1329.443 -1329.443 -1329.443] (1.000)
Step: 88149, Reward: [-1617.222 -1617.222 -1617.222] [0.0000], Avg: [-1329.606 -1329.606 -1329.606] (1.000)
Step: 88199, Reward: [-1476.741 -1476.741 -1476.741] [0.0000], Avg: [-1329.689 -1329.689 -1329.689] (1.000)
Step: 88249, Reward: [-1433.218 -1433.218 -1433.218] [0.0000], Avg: [-1329.748 -1329.748 -1329.748] (1.000)
Step: 88299, Reward: [-1098.073 -1098.073 -1098.073] [0.0000], Avg: [-1329.617 -1329.617 -1329.617] (1.000)
Step: 88349, Reward: [-1060.469 -1060.469 -1060.469] [0.0000], Avg: [-1329.465 -1329.465 -1329.465] (1.000)
Step: 88399, Reward: [-1060.502 -1060.502 -1060.502] [0.0000], Avg: [-1329.312 -1329.312 -1329.312] (1.000)
Step: 88449, Reward: [-2024.462 -2024.462 -2024.462] [0.0000], Avg: [-1329.705 -1329.705 -1329.705] (1.000)
Step: 88499, Reward: [-730.753 -730.753 -730.753] [0.0000], Avg: [-1329.367 -1329.367 -1329.367] (1.000)
Step: 88549, Reward: [-1117.987 -1117.987 -1117.987] [0.0000], Avg: [-1329.248 -1329.248 -1329.248] (1.000)
Step: 88599, Reward: [-883.227 -883.227 -883.227] [0.0000], Avg: [-1328.996 -1328.996 -1328.996] (1.000)
Step: 88649, Reward: [-1096.271 -1096.271 -1096.271] [0.0000], Avg: [-1328.865 -1328.865 -1328.865] (1.000)
Step: 88699, Reward: [-1564.501 -1564.501 -1564.501] [0.0000], Avg: [-1328.998 -1328.998 -1328.998] (1.000)
Step: 88749, Reward: [-966.82 -966.82 -966.82] [0.0000], Avg: [-1328.794 -1328.794 -1328.794] (1.000)
Step: 88799, Reward: [-973.242 -973.242 -973.242] [0.0000], Avg: [-1328.593 -1328.593 -1328.593] (1.000)
Step: 88849, Reward: [-535.181 -535.181 -535.181] [0.0000], Avg: [-1328.147 -1328.147 -1328.147] (1.000)
Step: 88899, Reward: [-796.433 -796.433 -796.433] [0.0000], Avg: [-1327.848 -1327.848 -1327.848] (1.000)
Step: 88949, Reward: [-854.921 -854.921 -854.921] [0.0000], Avg: [-1327.582 -1327.582 -1327.582] (1.000)
Step: 88999, Reward: [-753.359 -753.359 -753.359] [0.0000], Avg: [-1327.259 -1327.259 -1327.259] (1.000)
Step: 89049, Reward: [-726.373 -726.373 -726.373] [0.0000], Avg: [-1326.922 -1326.922 -1326.922] (1.000)
Step: 89099, Reward: [-630.881 -630.881 -630.881] [0.0000], Avg: [-1326.531 -1326.531 -1326.531] (1.000)
Step: 89149, Reward: [-698.285 -698.285 -698.285] [0.0000], Avg: [-1326.179 -1326.179 -1326.179] (1.000)
Step: 89199, Reward: [-475.405 -475.405 -475.405] [0.0000], Avg: [-1325.702 -1325.702 -1325.702] (1.000)
Step: 89249, Reward: [-699.11 -699.11 -699.11] [0.0000], Avg: [-1325.351 -1325.351 -1325.351] (1.000)
Step: 89299, Reward: [-557.095 -557.095 -557.095] [0.0000], Avg: [-1324.921 -1324.921 -1324.921] (1.000)
Step: 89349, Reward: [-1142.811 -1142.811 -1142.811] [0.0000], Avg: [-1324.819 -1324.819 -1324.819] (1.000)
Step: 89399, Reward: [-544.86 -544.86 -544.86] [0.0000], Avg: [-1324.383 -1324.383 -1324.383] (1.000)
Step: 89449, Reward: [-689.718 -689.718 -689.718] [0.0000], Avg: [-1324.028 -1324.028 -1324.028] (1.000)
Step: 89499, Reward: [-421.45 -421.45 -421.45] [0.0000], Avg: [-1323.524 -1323.524 -1323.524] (1.000)
Step: 89549, Reward: [-473.574 -473.574 -473.574] [0.0000], Avg: [-1323.049 -1323.049 -1323.049] (1.000)
Step: 89599, Reward: [-703.587 -703.587 -703.587] [0.0000], Avg: [-1322.704 -1322.704 -1322.704] (1.000)
Step: 89649, Reward: [-528.193 -528.193 -528.193] [0.0000], Avg: [-1322.26 -1322.26 -1322.26] (1.000)
Step: 89699, Reward: [-550.856 -550.856 -550.856] [0.0000], Avg: [-1321.83 -1321.83 -1321.83] (1.000)
Step: 89749, Reward: [-543.3 -543.3 -543.3] [0.0000], Avg: [-1321.397 -1321.397 -1321.397] (1.000)
Step: 89799, Reward: [-548.707 -548.707 -548.707] [0.0000], Avg: [-1320.967 -1320.967 -1320.967] (1.000)
Step: 89849, Reward: [-569.074 -569.074 -569.074] [0.0000], Avg: [-1320.548 -1320.548 -1320.548] (1.000)
Step: 89899, Reward: [-695.341 -695.341 -695.341] [0.0000], Avg: [-1320.2 -1320.2 -1320.2] (1.000)
Step: 89949, Reward: [-492.235 -492.235 -492.235] [0.0000], Avg: [-1319.74 -1319.74 -1319.74] (1.000)
Step: 89999, Reward: [-632.467 -632.467 -632.467] [0.0000], Avg: [-1319.358 -1319.358 -1319.358] (1.000)
Step: 90049, Reward: [-548.327 -548.327 -548.327] [0.0000], Avg: [-1318.93 -1318.93 -1318.93] (1.000)
Step: 90099, Reward: [-547.335 -547.335 -547.335] [0.0000], Avg: [-1318.502 -1318.502 -1318.502] (1.000)
Step: 90149, Reward: [-361.289 -361.289 -361.289] [0.0000], Avg: [-1317.971 -1317.971 -1317.971] (1.000)
Step: 90199, Reward: [-647.178 -647.178 -647.178] [0.0000], Avg: [-1317.599 -1317.599 -1317.599] (1.000)
Step: 90249, Reward: [-563.219 -563.219 -563.219] [0.0000], Avg: [-1317.181 -1317.181 -1317.181] (1.000)
Step: 90299, Reward: [-474.119 -474.119 -474.119] [0.0000], Avg: [-1316.715 -1316.715 -1316.715] (1.000)
Step: 90349, Reward: [-782.577 -782.577 -782.577] [0.0000], Avg: [-1316.419 -1316.419 -1316.419] (1.000)
Step: 90399, Reward: [-852.492 -852.492 -852.492] [0.0000], Avg: [-1316.162 -1316.162 -1316.162] (1.000)
Step: 90449, Reward: [-508.249 -508.249 -508.249] [0.0000], Avg: [-1315.716 -1315.716 -1315.716] (1.000)
Step: 90499, Reward: [-517.023 -517.023 -517.023] [0.0000], Avg: [-1315.274 -1315.274 -1315.274] (1.000)
Step: 90549, Reward: [-634.4 -634.4 -634.4] [0.0000], Avg: [-1314.898 -1314.898 -1314.898] (1.000)
Step: 90599, Reward: [-970.497 -970.497 -970.497] [0.0000], Avg: [-1314.708 -1314.708 -1314.708] (1.000)
Step: 90649, Reward: [-684.371 -684.371 -684.371] [0.0000], Avg: [-1314.361 -1314.361 -1314.361] (1.000)
Step: 90699, Reward: [-438.826 -438.826 -438.826] [0.0000], Avg: [-1313.878 -1313.878 -1313.878] (1.000)
Step: 90749, Reward: [-796.009 -796.009 -796.009] [0.0000], Avg: [-1313.593 -1313.593 -1313.593] (1.000)
Step: 90799, Reward: [-358.25 -358.25 -358.25] [0.0000], Avg: [-1313.067 -1313.067 -1313.067] (1.000)
Step: 90849, Reward: [-759.156 -759.156 -759.156] [0.0000], Avg: [-1312.762 -1312.762 -1312.762] (1.000)
Step: 90899, Reward: [-692.048 -692.048 -692.048] [0.0000], Avg: [-1312.42 -1312.42 -1312.42] (1.000)
Step: 90949, Reward: [-529.676 -529.676 -529.676] [0.0000], Avg: [-1311.99 -1311.99 -1311.99] (1.000)
Step: 90999, Reward: [-626.946 -626.946 -626.946] [0.0000], Avg: [-1311.614 -1311.614 -1311.614] (1.000)
Step: 91049, Reward: [-540.104 -540.104 -540.104] [0.0000], Avg: [-1311.19 -1311.19 -1311.19] (1.000)
Step: 91099, Reward: [-473.639 -473.639 -473.639] [0.0000], Avg: [-1310.73 -1310.73 -1310.73] (1.000)
Step: 91149, Reward: [-814.045 -814.045 -814.045] [0.0000], Avg: [-1310.458 -1310.458 -1310.458] (1.000)
Step: 91199, Reward: [-857.269 -857.269 -857.269] [0.0000], Avg: [-1310.209 -1310.209 -1310.209] (1.000)
Step: 91249, Reward: [-630.839 -630.839 -630.839] [0.0000], Avg: [-1309.837 -1309.837 -1309.837] (1.000)
Step: 91299, Reward: [-975.797 -975.797 -975.797] [0.0000], Avg: [-1309.654 -1309.654 -1309.654] (1.000)
Step: 91349, Reward: [-1804.619 -1804.619 -1804.619] [0.0000], Avg: [-1309.925 -1309.925 -1309.925] (1.000)
Step: 91399, Reward: [-1024.818 -1024.818 -1024.818] [0.0000], Avg: [-1309.769 -1309.769 -1309.769] (1.000)
Step: 91449, Reward: [-1942.818 -1942.818 -1942.818] [0.0000], Avg: [-1310.115 -1310.115 -1310.115] (1.000)
Step: 91499, Reward: [-1686.534 -1686.534 -1686.534] [0.0000], Avg: [-1310.321 -1310.321 -1310.321] (1.000)
Step: 91549, Reward: [-874.931 -874.931 -874.931] [0.0000], Avg: [-1310.083 -1310.083 -1310.083] (1.000)
Step: 91599, Reward: [-941.69 -941.69 -941.69] [0.0000], Avg: [-1309.882 -1309.882 -1309.882] (1.000)
Step: 91649, Reward: [-1694.391 -1694.391 -1694.391] [0.0000], Avg: [-1310.092 -1310.092 -1310.092] (1.000)
Step: 91699, Reward: [-1666.94 -1666.94 -1666.94] [0.0000], Avg: [-1310.286 -1310.286 -1310.286] (1.000)
Step: 91749, Reward: [-1634.895 -1634.895 -1634.895] [0.0000], Avg: [-1310.463 -1310.463 -1310.463] (1.000)
Step: 91799, Reward: [-1108.715 -1108.715 -1108.715] [0.0000], Avg: [-1310.353 -1310.353 -1310.353] (1.000)
Step: 91849, Reward: [-1748.244 -1748.244 -1748.244] [0.0000], Avg: [-1310.592 -1310.592 -1310.592] (1.000)
Step: 91899, Reward: [-2248.691 -2248.691 -2248.691] [0.0000], Avg: [-1311.102 -1311.102 -1311.102] (1.000)
Step: 91949, Reward: [-1931.554 -1931.554 -1931.554] [0.0000], Avg: [-1311.44 -1311.44 -1311.44] (1.000)
Step: 91999, Reward: [-985.989 -985.989 -985.989] [0.0000], Avg: [-1311.263 -1311.263 -1311.263] (1.000)
Step: 92049, Reward: [-1046.472 -1046.472 -1046.472] [0.0000], Avg: [-1311.119 -1311.119 -1311.119] (1.000)
Step: 92099, Reward: [-1508.01 -1508.01 -1508.01] [0.0000], Avg: [-1311.226 -1311.226 -1311.226] (1.000)
Step: 92149, Reward: [-1296.796 -1296.796 -1296.796] [0.0000], Avg: [-1311.218 -1311.218 -1311.218] (1.000)
Step: 92199, Reward: [-1293.239 -1293.239 -1293.239] [0.0000], Avg: [-1311.208 -1311.208 -1311.208] (1.000)
Step: 92249, Reward: [-2074.872 -2074.872 -2074.872] [0.0000], Avg: [-1311.622 -1311.622 -1311.622] (1.000)
Step: 92299, Reward: [-1386.295 -1386.295 -1386.295] [0.0000], Avg: [-1311.663 -1311.663 -1311.663] (1.000)
Step: 92349, Reward: [-1267.007 -1267.007 -1267.007] [0.0000], Avg: [-1311.638 -1311.638 -1311.638] (1.000)
Step: 92399, Reward: [-1559.39 -1559.39 -1559.39] [0.0000], Avg: [-1311.772 -1311.772 -1311.772] (1.000)
Step: 92449, Reward: [-1084.509 -1084.509 -1084.509] [0.0000], Avg: [-1311.65 -1311.65 -1311.65] (1.000)
Step: 92499, Reward: [-1603.352 -1603.352 -1603.352] [0.0000], Avg: [-1311.807 -1311.807 -1311.807] (1.000)
Step: 92549, Reward: [-1891.567 -1891.567 -1891.567] [0.0000], Avg: [-1312.12 -1312.12 -1312.12] (1.000)
Step: 92599, Reward: [-1276.63 -1276.63 -1276.63] [0.0000], Avg: [-1312.101 -1312.101 -1312.101] (1.000)
Step: 92649, Reward: [-960.998 -960.998 -960.998] [0.0000], Avg: [-1311.912 -1311.912 -1311.912] (1.000)
Step: 92699, Reward: [-1818.751 -1818.751 -1818.751] [0.0000], Avg: [-1312.185 -1312.185 -1312.185] (1.000)
Step: 92749, Reward: [-1652.155 -1652.155 -1652.155] [0.0000], Avg: [-1312.368 -1312.368 -1312.368] (1.000)
Step: 92799, Reward: [-1778.981 -1778.981 -1778.981] [0.0000], Avg: [-1312.62 -1312.62 -1312.62] (1.000)
Step: 92849, Reward: [-954.561 -954.561 -954.561] [0.0000], Avg: [-1312.427 -1312.427 -1312.427] (1.000)
Step: 92899, Reward: [-1233.857 -1233.857 -1233.857] [0.0000], Avg: [-1312.385 -1312.385 -1312.385] (1.000)
Step: 92949, Reward: [-1992.401 -1992.401 -1992.401] [0.0000], Avg: [-1312.751 -1312.751 -1312.751] (1.000)
Step: 92999, Reward: [-1703.519 -1703.519 -1703.519] [0.0000], Avg: [-1312.961 -1312.961 -1312.961] (1.000)
Step: 93049, Reward: [-1940.467 -1940.467 -1940.467] [0.0000], Avg: [-1313.298 -1313.298 -1313.298] (1.000)
Step: 93099, Reward: [-909.104 -909.104 -909.104] [0.0000], Avg: [-1313.081 -1313.081 -1313.081] (1.000)
Step: 93149, Reward: [-1693.584 -1693.584 -1693.584] [0.0000], Avg: [-1313.285 -1313.285 -1313.285] (1.000)
Step: 93199, Reward: [-1858.635 -1858.635 -1858.635] [0.0000], Avg: [-1313.578 -1313.578 -1313.578] (1.000)
Step: 93249, Reward: [-1557.076 -1557.076 -1557.076] [0.0000], Avg: [-1313.708 -1313.708 -1313.708] (1.000)
Step: 93299, Reward: [-1995.176 -1995.176 -1995.176] [0.0000], Avg: [-1314.073 -1314.073 -1314.073] (1.000)
Step: 93349, Reward: [-1780.835 -1780.835 -1780.835] [0.0000], Avg: [-1314.323 -1314.323 -1314.323] (1.000)
Step: 93399, Reward: [-1809.938 -1809.938 -1809.938] [0.0000], Avg: [-1314.589 -1314.589 -1314.589] (1.000)
Step: 93449, Reward: [-1661.377 -1661.377 -1661.377] [0.0000], Avg: [-1314.774 -1314.774 -1314.774] (1.000)
Step: 93499, Reward: [-1302.776 -1302.776 -1302.776] [0.0000], Avg: [-1314.768 -1314.768 -1314.768] (1.000)
Step: 93549, Reward: [-1627.597 -1627.597 -1627.597] [0.0000], Avg: [-1314.935 -1314.935 -1314.935] (1.000)
Step: 93599, Reward: [-1024.849 -1024.849 -1024.849] [0.0000], Avg: [-1314.78 -1314.78 -1314.78] (1.000)
Step: 93649, Reward: [-1028.433 -1028.433 -1028.433] [0.0000], Avg: [-1314.627 -1314.627 -1314.627] (1.000)
Step: 93699, Reward: [-1022.833 -1022.833 -1022.833] [0.0000], Avg: [-1314.471 -1314.471 -1314.471] (1.000)
Step: 93749, Reward: [-799.83 -799.83 -799.83] [0.0000], Avg: [-1314.197 -1314.197 -1314.197] (1.000)
Step: 93799, Reward: [-981.697 -981.697 -981.697] [0.0000], Avg: [-1314.02 -1314.02 -1314.02] (1.000)
Step: 93849, Reward: [-923.141 -923.141 -923.141] [0.0000], Avg: [-1313.812 -1313.812 -1313.812] (1.000)
Step: 93899, Reward: [-796.511 -796.511 -796.511] [0.0000], Avg: [-1313.536 -1313.536 -1313.536] (1.000)
Step: 93949, Reward: [-819.042 -819.042 -819.042] [0.0000], Avg: [-1313.273 -1313.273 -1313.273] (1.000)
Step: 93999, Reward: [-636.301 -636.301 -636.301] [0.0000], Avg: [-1312.913 -1312.913 -1312.913] (1.000)
Step: 94049, Reward: [-812.781 -812.781 -812.781] [0.0000], Avg: [-1312.647 -1312.647 -1312.647] (1.000)
Step: 94099, Reward: [-545.131 -545.131 -545.131] [0.0000], Avg: [-1312.239 -1312.239 -1312.239] (1.000)
Step: 94149, Reward: [-744.156 -744.156 -744.156] [0.0000], Avg: [-1311.937 -1311.937 -1311.937] (1.000)
Step: 94199, Reward: [-510.473 -510.473 -510.473] [0.0000], Avg: [-1311.512 -1311.512 -1311.512] (1.000)
Step: 94249, Reward: [-584.139 -584.139 -584.139] [0.0000], Avg: [-1311.126 -1311.126 -1311.126] (1.000)
Step: 94299, Reward: [-1064.212 -1064.212 -1064.212] [0.0000], Avg: [-1310.995 -1310.995 -1310.995] (1.000)
Step: 94349, Reward: [-835.76 -835.76 -835.76] [0.0000], Avg: [-1310.743 -1310.743 -1310.743] (1.000)
Step: 94399, Reward: [-935.294 -935.294 -935.294] [0.0000], Avg: [-1310.544 -1310.544 -1310.544] (1.000)
Step: 94449, Reward: [-333.724 -333.724 -333.724] [0.0000], Avg: [-1310.027 -1310.027 -1310.027] (1.000)
Step: 94499, Reward: [-1369.47 -1369.47 -1369.47] [0.0000], Avg: [-1310.059 -1310.059 -1310.059] (1.000)
Step: 94549, Reward: [-857.615 -857.615 -857.615] [0.0000], Avg: [-1309.82 -1309.82 -1309.82] (1.000)
Step: 94599, Reward: [-511.469 -511.469 -511.469] [0.0000], Avg: [-1309.398 -1309.398 -1309.398] (1.000)
Step: 94649, Reward: [-1345.012 -1345.012 -1345.012] [0.0000], Avg: [-1309.416 -1309.416 -1309.416] (1.000)
Step: 94699, Reward: [-561.995 -561.995 -561.995] [0.0000], Avg: [-1309.022 -1309.022 -1309.022] (1.000)
Step: 94749, Reward: [-630.554 -630.554 -630.554] [0.0000], Avg: [-1308.664 -1308.664 -1308.664] (1.000)
Step: 94799, Reward: [-437.805 -437.805 -437.805] [0.0000], Avg: [-1308.204 -1308.204 -1308.204] (1.000)
Step: 94849, Reward: [-488.848 -488.848 -488.848] [0.0000], Avg: [-1307.773 -1307.773 -1307.773] (1.000)
Step: 94899, Reward: [-538.219 -538.219 -538.219] [0.0000], Avg: [-1307.367 -1307.367 -1307.367] (1.000)
Step: 94949, Reward: [-645.461 -645.461 -645.461] [0.0000], Avg: [-1307.019 -1307.019 -1307.019] (1.000)
Step: 94999, Reward: [-1327.913 -1327.913 -1327.913] [0.0000], Avg: [-1307.03 -1307.03 -1307.03] (1.000)
Step: 95049, Reward: [-440.177 -440.177 -440.177] [0.0000], Avg: [-1306.574 -1306.574 -1306.574] (1.000)
Step: 95099, Reward: [-541.37 -541.37 -541.37] [0.0000], Avg: [-1306.171 -1306.171 -1306.171] (1.000)
Step: 95149, Reward: [-1066.857 -1066.857 -1066.857] [0.0000], Avg: [-1306.045 -1306.045 -1306.045] (1.000)
Step: 95199, Reward: [-695.578 -695.578 -695.578] [0.0000], Avg: [-1305.725 -1305.725 -1305.725] (1.000)
Step: 95249, Reward: [-931.294 -931.294 -931.294] [0.0000], Avg: [-1305.528 -1305.528 -1305.528] (1.000)
Step: 95299, Reward: [-1072.884 -1072.884 -1072.884] [0.0000], Avg: [-1305.406 -1305.406 -1305.406] (1.000)
Step: 95349, Reward: [-999.58 -999.58 -999.58] [0.0000], Avg: [-1305.246 -1305.246 -1305.246] (1.000)
Step: 95399, Reward: [-1228.44 -1228.44 -1228.44] [0.0000], Avg: [-1305.206 -1305.206 -1305.206] (1.000)
Step: 95449, Reward: [-1347.738 -1347.738 -1347.738] [0.0000], Avg: [-1305.228 -1305.228 -1305.228] (1.000)
Step: 95499, Reward: [-1077.318 -1077.318 -1077.318] [0.0000], Avg: [-1305.109 -1305.109 -1305.109] (1.000)
Step: 95549, Reward: [-1178.729 -1178.729 -1178.729] [0.0000], Avg: [-1305.042 -1305.042 -1305.042] (1.000)
Step: 95599, Reward: [-947.4 -947.4 -947.4] [0.0000], Avg: [-1304.855 -1304.855 -1304.855] (1.000)
Step: 95649, Reward: [-1120.505 -1120.505 -1120.505] [0.0000], Avg: [-1304.759 -1304.759 -1304.759] (1.000)
Step: 95699, Reward: [-1140.585 -1140.585 -1140.585] [0.0000], Avg: [-1304.673 -1304.673 -1304.673] (1.000)
Step: 95749, Reward: [-1145.941 -1145.941 -1145.941] [0.0000], Avg: [-1304.59 -1304.59 -1304.59] (1.000)
Step: 95799, Reward: [-1280.797 -1280.797 -1280.797] [0.0000], Avg: [-1304.578 -1304.578 -1304.578] (1.000)
Step: 95849, Reward: [-909.418 -909.418 -909.418] [0.0000], Avg: [-1304.372 -1304.372 -1304.372] (1.000)
Step: 95899, Reward: [-1073.448 -1073.448 -1073.448] [0.0000], Avg: [-1304.251 -1304.251 -1304.251] (1.000)
Step: 95949, Reward: [-1083.952 -1083.952 -1083.952] [0.0000], Avg: [-1304.137 -1304.137 -1304.137] (1.000)
Step: 95999, Reward: [-788.068 -788.068 -788.068] [0.0000], Avg: [-1303.868 -1303.868 -1303.868] (1.000)
Step: 96049, Reward: [-1042.688 -1042.688 -1042.688] [0.0000], Avg: [-1303.732 -1303.732 -1303.732] (1.000)
Step: 96099, Reward: [-1071.128 -1071.128 -1071.128] [0.0000], Avg: [-1303.611 -1303.611 -1303.611] (1.000)
Step: 96149, Reward: [-784.97 -784.97 -784.97] [0.0000], Avg: [-1303.341 -1303.341 -1303.341] (1.000)
Step: 96199, Reward: [-1013.25 -1013.25 -1013.25] [0.0000], Avg: [-1303.19 -1303.19 -1303.19] (1.000)
Step: 96249, Reward: [-1028.763 -1028.763 -1028.763] [0.0000], Avg: [-1303.048 -1303.048 -1303.048] (1.000)
Step: 96299, Reward: [-760.559 -760.559 -760.559] [0.0000], Avg: [-1302.766 -1302.766 -1302.766] (1.000)
Step: 96349, Reward: [-662.072 -662.072 -662.072] [0.0000], Avg: [-1302.434 -1302.434 -1302.434] (1.000)
Step: 96399, Reward: [-1167.94 -1167.94 -1167.94] [0.0000], Avg: [-1302.364 -1302.364 -1302.364] (1.000)
Step: 96449, Reward: [-488.655 -488.655 -488.655] [0.0000], Avg: [-1301.942 -1301.942 -1301.942] (1.000)
Step: 96499, Reward: [-667.969 -667.969 -667.969] [0.0000], Avg: [-1301.614 -1301.614 -1301.614] (1.000)
Step: 96549, Reward: [-699.98 -699.98 -699.98] [0.0000], Avg: [-1301.302 -1301.302 -1301.302] (1.000)
Step: 96599, Reward: [-1029.706 -1029.706 -1029.706] [0.0000], Avg: [-1301.161 -1301.161 -1301.161] (1.000)
Step: 96649, Reward: [-661.217 -661.217 -661.217] [0.0000], Avg: [-1300.83 -1300.83 -1300.83] (1.000)
Step: 96699, Reward: [-1175.372 -1175.372 -1175.372] [0.0000], Avg: [-1300.765 -1300.765 -1300.765] (1.000)
Step: 96749, Reward: [-703.251 -703.251 -703.251] [0.0000], Avg: [-1300.457 -1300.457 -1300.457] (1.000)
Step: 96799, Reward: [-1088.555 -1088.555 -1088.555] [0.0000], Avg: [-1300.347 -1300.347 -1300.347] (1.000)
Step: 96849, Reward: [-737.296 -737.296 -737.296] [0.0000], Avg: [-1300.057 -1300.057 -1300.057] (1.000)
Step: 96899, Reward: [-784.9 -784.9 -784.9] [0.0000], Avg: [-1299.791 -1299.791 -1299.791] (1.000)
Step: 96949, Reward: [-650.505 -650.505 -650.505] [0.0000], Avg: [-1299.456 -1299.456 -1299.456] (1.000)
Step: 96999, Reward: [-703.673 -703.673 -703.673] [0.0000], Avg: [-1299.149 -1299.149 -1299.149] (1.000)
Step: 97049, Reward: [-877.802 -877.802 -877.802] [0.0000], Avg: [-1298.932 -1298.932 -1298.932] (1.000)
Step: 97099, Reward: [-718.431 -718.431 -718.431] [0.0000], Avg: [-1298.633 -1298.633 -1298.633] (1.000)
Step: 97149, Reward: [-1191.18 -1191.18 -1191.18] [0.0000], Avg: [-1298.577 -1298.577 -1298.577] (1.000)
Step: 97199, Reward: [-856.627 -856.627 -856.627] [0.0000], Avg: [-1298.35 -1298.35 -1298.35] (1.000)
Step: 97249, Reward: [-958.745 -958.745 -958.745] [0.0000], Avg: [-1298.176 -1298.176 -1298.176] (1.000)
Step: 97299, Reward: [-907.723 -907.723 -907.723] [0.0000], Avg: [-1297.975 -1297.975 -1297.975] (1.000)
Step: 97349, Reward: [-1040.005 -1040.005 -1040.005] [0.0000], Avg: [-1297.842 -1297.842 -1297.842] (1.000)
Step: 97399, Reward: [-1186.559 -1186.559 -1186.559] [0.0000], Avg: [-1297.785 -1297.785 -1297.785] (1.000)
Step: 97449, Reward: [-1158.602 -1158.602 -1158.602] [0.0000], Avg: [-1297.714 -1297.714 -1297.714] (1.000)
Step: 97499, Reward: [-1066.951 -1066.951 -1066.951] [0.0000], Avg: [-1297.596 -1297.596 -1297.596] (1.000)
Step: 97549, Reward: [-1098.226 -1098.226 -1098.226] [0.0000], Avg: [-1297.493 -1297.493 -1297.493] (1.000)
Step: 97599, Reward: [-1090.112 -1090.112 -1090.112] [0.0000], Avg: [-1297.387 -1297.387 -1297.387] (1.000)
Step: 97649, Reward: [-1235.521 -1235.521 -1235.521] [0.0000], Avg: [-1297.355 -1297.355 -1297.355] (1.000)
Step: 97699, Reward: [-1196.043 -1196.043 -1196.043] [0.0000], Avg: [-1297.304 -1297.304 -1297.304] (1.000)
Step: 97749, Reward: [-1280.849 -1280.849 -1280.849] [0.0000], Avg: [-1297.295 -1297.295 -1297.295] (1.000)
Step: 97799, Reward: [-1157.312 -1157.312 -1157.312] [0.0000], Avg: [-1297.224 -1297.224 -1297.224] (1.000)
Step: 97849, Reward: [-1763.911 -1763.911 -1763.911] [0.0000], Avg: [-1297.462 -1297.462 -1297.462] (1.000)
Step: 97899, Reward: [-1459.388 -1459.388 -1459.388] [0.0000], Avg: [-1297.545 -1297.545 -1297.545] (1.000)
Step: 97949, Reward: [-1951.811 -1951.811 -1951.811] [0.0000], Avg: [-1297.879 -1297.879 -1297.879] (1.000)
Step: 97999, Reward: [-1901.059 -1901.059 -1901.059] [0.0000], Avg: [-1298.186 -1298.186 -1298.186] (1.000)
Step: 98049, Reward: [-1920.875 -1920.875 -1920.875] [0.0000], Avg: [-1298.504 -1298.504 -1298.504] (1.000)
Step: 98099, Reward: [-2041.269 -2041.269 -2041.269] [0.0000], Avg: [-1298.883 -1298.883 -1298.883] (1.000)
Step: 98149, Reward: [-1870.652 -1870.652 -1870.652] [0.0000], Avg: [-1299.174 -1299.174 -1299.174] (1.000)
Step: 98199, Reward: [-2030.444 -2030.444 -2030.444] [0.0000], Avg: [-1299.546 -1299.546 -1299.546] (1.000)
Step: 98249, Reward: [-1785.63 -1785.63 -1785.63] [0.0000], Avg: [-1299.794 -1299.794 -1299.794] (1.000)
Step: 98299, Reward: [-2016.12 -2016.12 -2016.12] [0.0000], Avg: [-1300.158 -1300.158 -1300.158] (1.000)
Step: 98349, Reward: [-2015.028 -2015.028 -2015.028] [0.0000], Avg: [-1300.521 -1300.521 -1300.521] (1.000)
Step: 98399, Reward: [-1717.039 -1717.039 -1717.039] [0.0000], Avg: [-1300.733 -1300.733 -1300.733] (1.000)
Step: 98449, Reward: [-1727.503 -1727.503 -1727.503] [0.0000], Avg: [-1300.95 -1300.95 -1300.95] (1.000)
Step: 98499, Reward: [-1748.379 -1748.379 -1748.379] [0.0000], Avg: [-1301.177 -1301.177 -1301.177] (1.000)
Step: 98549, Reward: [-2418.418 -2418.418 -2418.418] [0.0000], Avg: [-1301.744 -1301.744 -1301.744] (1.000)
Step: 98599, Reward: [-2172.713 -2172.713 -2172.713] [0.0000], Avg: [-1302.185 -1302.185 -1302.185] (1.000)
Step: 98649, Reward: [-2188.501 -2188.501 -2188.501] [0.0000], Avg: [-1302.635 -1302.635 -1302.635] (1.000)
Step: 98699, Reward: [-1882.893 -1882.893 -1882.893] [0.0000], Avg: [-1302.929 -1302.929 -1302.929] (1.000)
Step: 98749, Reward: [-1822.337 -1822.337 -1822.337] [0.0000], Avg: [-1303.192 -1303.192 -1303.192] (1.000)
Step: 98799, Reward: [-2016.578 -2016.578 -2016.578] [0.0000], Avg: [-1303.553 -1303.553 -1303.553] (1.000)
Step: 98849, Reward: [-2053.854 -2053.854 -2053.854] [0.0000], Avg: [-1303.932 -1303.932 -1303.932] (1.000)
Step: 98899, Reward: [-1729.253 -1729.253 -1729.253] [0.0000], Avg: [-1304.147 -1304.147 -1304.147] (1.000)
Step: 98949, Reward: [-2176.311 -2176.311 -2176.311] [0.0000], Avg: [-1304.588 -1304.588 -1304.588] (1.000)
Step: 98999, Reward: [-1668.913 -1668.913 -1668.913] [0.0000], Avg: [-1304.772 -1304.772 -1304.772] (1.000)
Step: 99049, Reward: [-1518.403 -1518.403 -1518.403] [0.0000], Avg: [-1304.88 -1304.88 -1304.88] (1.000)
Step: 99099, Reward: [-1789.589 -1789.589 -1789.589] [0.0000], Avg: [-1305.124 -1305.124 -1305.124] (1.000)
Step: 99149, Reward: [-1526.632 -1526.632 -1526.632] [0.0000], Avg: [-1305.236 -1305.236 -1305.236] (1.000)
Step: 99199, Reward: [-1228.682 -1228.682 -1228.682] [0.0000], Avg: [-1305.197 -1305.197 -1305.197] (1.000)
Step: 99249, Reward: [-788.156 -788.156 -788.156] [0.0000], Avg: [-1304.937 -1304.937 -1304.937] (1.000)
Step: 99299, Reward: [-854.859 -854.859 -854.859] [0.0000], Avg: [-1304.71 -1304.71 -1304.71] (1.000)
Step: 99349, Reward: [-930.295 -930.295 -930.295] [0.0000], Avg: [-1304.522 -1304.522 -1304.522] (1.000)
Step: 99399, Reward: [-754.785 -754.785 -754.785] [0.0000], Avg: [-1304.245 -1304.245 -1304.245] (1.000)
Step: 99449, Reward: [-604.579 -604.579 -604.579] [0.0000], Avg: [-1303.893 -1303.893 -1303.893] (1.000)
Step: 99499, Reward: [-1227.034 -1227.034 -1227.034] [0.0000], Avg: [-1303.855 -1303.855 -1303.855] (1.000)
Step: 99549, Reward: [-407.817 -407.817 -407.817] [0.0000], Avg: [-1303.405 -1303.405 -1303.405] (1.000)
Step: 99599, Reward: [-484.436 -484.436 -484.436] [0.0000], Avg: [-1302.994 -1302.994 -1302.994] (1.000)
Step: 99649, Reward: [-570.069 -570.069 -570.069] [0.0000], Avg: [-1302.626 -1302.626 -1302.626] (1.000)
Step: 99699, Reward: [-512.309 -512.309 -512.309] [0.0000], Avg: [-1302.23 -1302.23 -1302.23] (1.000)
Step: 99749, Reward: [-687.672 -687.672 -687.672] [0.0000], Avg: [-1301.922 -1301.922 -1301.922] (1.000)
Step: 99799, Reward: [-883.896 -883.896 -883.896] [0.0000], Avg: [-1301.712 -1301.712 -1301.712] (1.000)
Step: 99849, Reward: [-933.099 -933.099 -933.099] [0.0000], Avg: [-1301.528 -1301.528 -1301.528] (1.000)
Step: 99899, Reward: [-854.825 -854.825 -854.825] [0.0000], Avg: [-1301.304 -1301.304 -1301.304] (1.000)
Step: 99949, Reward: [-766.524 -766.524 -766.524] [0.0000], Avg: [-1301.036 -1301.036 -1301.036] (1.000)
Step: 99999, Reward: [-686.074 -686.074 -686.074] [0.0000], Avg: [-1300.729 -1300.729 -1300.729] (1.000)
