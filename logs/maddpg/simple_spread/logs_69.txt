Model: <class 'multiagent.maddpg.MADDPGAgent'>, Dir: simple_spread
num_envs: 1, state_size: [(1, 18), (1, 18), (1, 18)], action_size: [[1, 5], [1, 5], [1, 5]], action_space: [<gym.spaces.multi_discrete.MultiDiscrete object at 0x7f18f3a21550>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f18f3a215f8>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f18f3a21668>],

import torch
import random
import numpy as np
from models.rand import MultiagentReplayBuffer
from models.ddpg import DDPGActor, DDPGCritic, DDPGNetwork
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACAgent, LEARN_RATE, NUM_STEPS, EPS_MIN, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, MAX_BUFFER_SIZE, gsoftmax, one_hot

REPLAY_BATCH_SIZE = 1024
ENTROPY_WEIGHT = 0.001			# The weight for the entropy term of the Actor loss
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64
LEARN_RATE = 0.01
TARGET_UPDATE_RATE = 0.01

class MADDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, sample=True):
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		action_mu = self.action_mu(state)
		action = action_mu.view(*out_dims, -1)
		return action
	
class MADDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1]+action_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1]+action_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, action):
		state = torch.cat([state, action], -1)
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		q_value = self.q_value(state)
		q_value = q_value.view(*out_dims, -1)
		return q_value

class MADDPGNetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=True, load=None):
		super().__init__(tau=tau, gpu=gpu)
		self.state_size = state_size
		self.action_size = action_size
		self.critic = MADDPGCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.models = [DDPGNetwork(s_size, a_size, MADDPGActor, lambda s,a: self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		
	def get_action_probs(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [model.get_action(s, use_target, grad, numpy, sample) for s,model in zip(state, self.models)]
			return action

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_value = [model.get_q_value(state, action, use_target, grad, numpy) for model in self.models]
			return q_value

	def optimize(self, states, actions, states_joint, actions_joint, q_targets, e_weight=ENTROPY_WEIGHT):
		for (i,model),state,q_target in zip(enumerate(self.models), states, q_targets):
			q_values = model.get_q_value(states_joint, actions_joint, grad=True, numpy=False)
			critic_error = q_values[:q_target.size(0)] - q_target.detach()
			critic_loss = critic_error.pow(2)
			model.step(model.critic_optimizer, critic_loss.mean(), param_norm=model.critic_local.parameters())
			model.soft_copy(model.critic_local, model.critic_target)

			actor_action = model.get_action(state, grad=True, numpy=False)
			critic_action = [actor_action if j==i else other.get_action(states[j], numpy=False) for j,other in enumerate(self.models)]
			action_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(critic_action, self.action_size)], dim=-1)
			q_actions = model.critic_local(states_joint, action_joint)
			actor_loss = -q_actions.mean() + e_weight*actor_action.pow(2).mean()
			model.step(model.actor_optimizer, actor_loss.mean(), param_norm=model.actor_local.parameters())
			model.soft_copy(model.actor_local, model.actor_target)

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class MADDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, MADDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.agent = MADDPG(state_size, action_size)
		self.replay_buffer = MultiagentReplayBuffer(MAX_BUFFER_SIZE, len(state_size), [obsp[-1] for obsp in state_size], [acsp[-1] for acsp in action_size])

	def get_action(self, state, eps=None, sample=True, numpy=True):
		state = [torch.autograd.Variable(torch.Tensor(np.vstack(s)), requires_grad=False) for s in state]
		agent_actions = self.agent.get_action_probs(state, numpy=True)
		# torch_agent_actions = self.agent.step(state)
		# agent_actions = [ac.data.numpy() for ac in agent_actions]
		return agent_actions
		"""
			# eps = self.eps if eps is None else eps
			# action_random = super().get_action(state)
			# action_greedy = self.network.get_action_probs(self.to_tensor(state), sample=sample, numpy=numpy)
			# action = [(1-eps)*a_greedy + eps*a_random for a_greedy,a_random in zip(action_greedy, action_random)]
			# return action
		"""

	def train(self, state, action, next_state, reward, done):
		self.t = 0 if not hasattr(self, "t") else self.t + 1
		self.replay_buffer.push(state, action, next_state, reward, done)
		if (len(self.replay_buffer) >= REPLAY_BATCH_SIZE and (self.t % 100)==0):
			states, actions, next_states, rewards, dones = self.replay_buffer.sample(REPLAY_BATCH_SIZE, to_gpu=False)
			self.agent.update(states, actions, next_states, rewards, dones)
		"""
			# self.buffer.append((state, action, reward, done))
			# if np.any(done[0]) or len(self.buffer) >= self.update_freq:
			# 	states, actions, rewards, dones = map(lambda x: self.to_tensor(x), zip(*self.buffer))
			# 	self.buffer.clear()
			# 	next_state = self.to_tensor(next_state)
			# 	states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, next_state)]
			# 	actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.network.get_action_probs(next_state, use_target=True))]
			# 	states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			# 	actions_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions, self.action_size)], dim=-1)
			# 	q_values = self.network.get_q_value(states_joint, actions_joint, use_target=True)
			# 	q_targets = [self.compute_gae(q_value[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_value[:-1])[0] for q_value,reward,done in zip(q_values, rewards, dones)]
				
			# 	to_stack = lambda items: list(zip(*[x.view(-1, *x.shape[2:]).cpu().numpy() for x in items]))
			# 	states, actions, states_joint, actions_joint = map(lambda items: [x[:-1] for x in items], [states, actions, [states_joint], [actions_joint]])
			# 	states, actions, states_joint, actions_joint, q_targets = map(to_stack, [states, actions, states_joint, actions_joint, q_targets])
			# 	self.replay_buffer.extend(list(zip(states, actions, states_joint, actions_joint, q_targets)), shuffle=False)	
			# if len(self.replay_buffer) > REPLAY_BATCH_SIZE:
			# 	states, actions, states_joint, actions_joint, q_targets = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
			# 	self.network.optimize(states, actions, states_joint[0], actions_joint[0], q_targets)
			# if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)
		"""

class MADDPG():
	def __init__(self, state_size, action_size, gamma=0.95, tau=0.01, lr=0.01, gpu=False, load=None):
		self.tau = tau
		self.gamma = gamma
		self.state_size = state_size
		self.action_size = action_size
		# num_in_critic = np.sum([np.prod(s) for s in state_size]) + np.sum([np.prod(a) for a in action_size])
		# self.agents2 = [DDPGAgent(s_size[-1], a_size[-1], num_in_critic) for s_size, a_size in zip(state_size, action_size)]
		self.critic = lambda s,a: MADDPGCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.agents = [DDPGNetwork(s_size, a_size, MADDPGActor, self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]

	# def step(self, states):
	# 	return [gsoftmax(a.policy(obs), hard=True) for a, obs in zip(self.agents, states)]

	def get_action_probs(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [gsoftmax(model.get_action(s, use_target, grad, numpy=False), hard=True) for s,model in zip(state, self.agents)]
			return [a.cpu().numpy() if numpy else a for a in action]

	def update(self, states, actions, next_states, rewards, dones):
		for agent_i, curr_agent in enumerate(self.agents):
			# all_trgt_acs = [one_hot(agent.policy(nobs)) for agent, nobs in zip(self.agents2, next_states)]
			next_actions = [one_hot(agent.get_action(nobs, numpy=False)) for agent, nobs in zip(self.agents, next_states)]
			# trgt_vf_in = torch.cat((*next_states, *next_actions), dim=1)
			next_states_joint = torch.cat([*next_states], dim=-1)
			next_actions_joint = torch.cat([*next_actions], dim=-1)
			# target_value = (rewards[agent_i].view(-1, 1) + self.gamma * curr_agent.target_critic(trgt_vf_in) * (1 - dones[agent_i].view(-1, 1)))
			target_value = (rewards[agent_i].view(-1, 1) + self.gamma * curr_agent.get_q_value(next_states_joint, next_actions_joint, use_target=True, numpy=False) * (1 - dones[agent_i].view(-1, 1)))

			# critic_inputs = torch.cat((*states, *actions), dim=1)
			states_joint = torch.cat([*states], dim=-1)
			actions_joint = torch.cat([*actions], dim=-1)
			# actual_value = curr_agent.critic(critic_inputs)
			actual_value = curr_agent.get_q_value(states_joint, actions_joint, grad=True, numpy=False)
			vf_loss = (actual_value - target_value.detach()).pow(2).mean()
			curr_agent.step(curr_agent.critic_optimizer, vf_loss, param_norm=curr_agent.critic_local.parameters())
			# curr_agent.step(curr_agent.critic_optimizer, vf_loss, param_norm=curr_agent.critic.parameters())
			curr_agent.soft_copy(curr_agent.critic_local, curr_agent.critic_target)
			# curr_agent.soft_copy(curr_agent.critic, curr_agent.target_critic)

			curr_pol_out = curr_agent.get_action(states[agent_i], grad=True, numpy=False)
			# curr_pol_out = curr_agent.policy(states[agent_i])
			curr_pol_vf_in = gsoftmax(curr_pol_out, hard=True)
			action = [curr_pol_vf_in if i==agent_i else one_hot(agent.get_action(ob, numpy=False)) for (i,agent), ob in zip(enumerate(self.agents), states)]
			# action = [curr_pol_vf_in if i==agent_i else one_hot(agent.policy(ob)) for (i,agent), ob in zip(enumerate(self.agents), states)]
			# critic_inputs = torch.cat((*states, *action), dim=1)
			action_joint = torch.cat([*action], dim=-1)
			pol_loss = -curr_agent.critic_local(states_joint, action_joint).mean() + 0.001*(curr_pol_out**2).mean() 
			# pol_loss = -curr_agent.critic(critic_inputs).mean() + 0.001*(curr_pol_out**2).mean() 
			curr_agent.step(curr_agent.actor_optimizer, pol_loss, param_norm=curr_agent.actor_local.parameters())
			# curr_agent.step(curr_agent.policy_optimizer, pol_loss, param_norm=curr_agent.policy.parameters())
			curr_agent.soft_copy(curr_agent.actor_local, curr_agent.actor_target)
			# curr_agent.soft_copy(curr_agent.policy, curr_agent.target_policy)

class DDPGAgent(PTNetwork):
	def __init__(self, num_in_pol, num_out_pol, num_in_critic, hidden_dim=64, lr=0.01, tau=0.01):
		super().__init__(tau, gpu=False)
		self.policy = MLPNetwork(num_in_pol, num_out_pol, hidden_dim=hidden_dim)
		self.target_policy = MLPNetwork(num_in_pol, num_out_pol, hidden_dim=hidden_dim)
		self.policy_optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr)
		self.critic = MLPNetwork(num_in_critic, 1, hidden_dim=hidden_dim)
		self.target_critic = MLPNetwork(num_in_critic, 1, hidden_dim=hidden_dim)
		self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr)
		self.tau = tau

class MLPNetwork(torch.nn.Module):
	def __init__(self, input_dim, out_dim, hidden_dim=64):
		super().__init__()
		self.fc1 = torch.nn.Linear(input_dim, hidden_dim)
		self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)
		self.fc3 = torch.nn.Linear(hidden_dim, out_dim)

	def forward(self, X):
		h1 = self.fc1(X).relu()
		h2 = self.fc2(h1).relu()
		action = self.fc3(h2)
		return action

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.900             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)
# np.random.seed(1)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return gym.make(env_name)
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":0} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env)

def run(model, steps=10000, ports=16, env_name=env_name, eval_at=1000, checkpoint=False, save_best=False, log=True, render=True):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports, render=False, env_name=env_name)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, num_envs=num_envs, gpu=False, agent2=RandomAgent) 
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if np.any(dones[0]):
			rollouts = [rollout(envs.env, agent.reset(1), render=render) for _ in range(1)]
			test_reward = np.mean(rollouts, axis=0) - np.std(rollouts, axis=0)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if save_best and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts, axis=0)} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")
			agent.reset(num_envs)

def trial(model):
	envs = EnsembleEnv(make_env, 0, log=True, render=True)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, load=f"{env_name}")
	print(f"Reward: {rollout(envs.env, agent, eps=0.02, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[1], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="maddpg", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--test", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.test:
		trial(model)
	elif args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		run(model, args.steps, args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)

Step: 49, Reward: [-365.74 -365.74 -365.74] [0.0000], Avg: [-365.74 -365.74 -365.74] (1.000)
Step: 99, Reward: [-589.038 -589.038 -589.038] [0.0000], Avg: [-477.389 -477.389 -477.389] (1.000)
Step: 149, Reward: [-508.836 -508.836 -508.836] [0.0000], Avg: [-487.871 -487.871 -487.871] (1.000)
Step: 199, Reward: [-657.51 -657.51 -657.51] [0.0000], Avg: [-530.281 -530.281 -530.281] (1.000)
Step: 249, Reward: [-300.821 -300.821 -300.821] [0.0000], Avg: [-484.389 -484.389 -484.389] (1.000)
Step: 299, Reward: [-631.217 -631.217 -631.217] [0.0000], Avg: [-508.86 -508.86 -508.86] (1.000)
Step: 349, Reward: [-391.473 -391.473 -391.473] [0.0000], Avg: [-492.09 -492.09 -492.09] (1.000)
Step: 399, Reward: [-630.395 -630.395 -630.395] [0.0000], Avg: [-509.379 -509.379 -509.379] (1.000)
Step: 449, Reward: [-527.928 -527.928 -527.928] [0.0000], Avg: [-511.44 -511.44 -511.44] (1.000)
Step: 499, Reward: [-530.072 -530.072 -530.072] [0.0000], Avg: [-513.303 -513.303 -513.303] (1.000)
Step: 549, Reward: [-521.878 -521.878 -521.878] [0.0000], Avg: [-514.082 -514.082 -514.082] (1.000)
Step: 599, Reward: [-387.571 -387.571 -387.571] [0.0000], Avg: [-503.54 -503.54 -503.54] (1.000)
Step: 649, Reward: [-472.451 -472.451 -472.451] [0.0000], Avg: [-501.148 -501.148 -501.148] (1.000)
Step: 699, Reward: [-489.485 -489.485 -489.485] [0.0000], Avg: [-500.315 -500.315 -500.315] (1.000)
Step: 749, Reward: [-484.775 -484.775 -484.775] [0.0000], Avg: [-499.279 -499.279 -499.279] (1.000)
Step: 799, Reward: [-936.402 -936.402 -936.402] [0.0000], Avg: [-526.599 -526.599 -526.599] (1.000)
Step: 849, Reward: [-456.892 -456.892 -456.892] [0.0000], Avg: [-522.499 -522.499 -522.499] (1.000)
Step: 899, Reward: [-464.582 -464.582 -464.582] [0.0000], Avg: [-519.281 -519.281 -519.281] (1.000)
Step: 949, Reward: [-616.415 -616.415 -616.415] [0.0000], Avg: [-524.394 -524.394 -524.394] (1.000)
Step: 999, Reward: [-660.363 -660.363 -660.363] [0.0000], Avg: [-531.192 -531.192 -531.192] (1.000)
Step: 1049, Reward: [-649.758 -649.758 -649.758] [0.0000], Avg: [-536.838 -536.838 -536.838] (1.000)
Step: 1099, Reward: [-744.026 -744.026 -744.026] [0.0000], Avg: [-546.256 -546.256 -546.256] (1.000)
Step: 1149, Reward: [-533.357 -533.357 -533.357] [0.0000], Avg: [-545.695 -545.695 -545.695] (1.000)
Step: 1199, Reward: [-1048.83 -1048.83 -1048.83] [0.0000], Avg: [-566.659 -566.659 -566.659] (1.000)
Step: 1249, Reward: [-954.506 -954.506 -954.506] [0.0000], Avg: [-582.173 -582.173 -582.173] (1.000)
Step: 1299, Reward: [-625.542 -625.542 -625.542] [0.0000], Avg: [-583.841 -583.841 -583.841] (1.000)
Step: 1349, Reward: [-949.703 -949.703 -949.703] [0.0000], Avg: [-597.391 -597.391 -597.391] (1.000)
Step: 1399, Reward: [-818.799 -818.799 -818.799] [0.0000], Avg: [-605.299 -605.299 -605.299] (1.000)
Step: 1449, Reward: [-726.854 -726.854 -726.854] [0.0000], Avg: [-609.49 -609.49 -609.49] (1.000)
Step: 1499, Reward: [-1504.358 -1504.358 -1504.358] [0.0000], Avg: [-639.319 -639.319 -639.319] (1.000)
Step: 1549, Reward: [-1717.918 -1717.918 -1717.918] [0.0000], Avg: [-674.113 -674.113 -674.113] (1.000)
Step: 1599, Reward: [-849.836 -849.836 -849.836] [0.0000], Avg: [-679.604 -679.604 -679.604] (1.000)
Step: 1649, Reward: [-1190.887 -1190.887 -1190.887] [0.0000], Avg: [-695.097 -695.097 -695.097] (1.000)
Step: 1699, Reward: [-1116.828 -1116.828 -1116.828] [0.0000], Avg: [-707.501 -707.501 -707.501] (1.000)
Step: 1749, Reward: [-1138.405 -1138.405 -1138.405] [0.0000], Avg: [-719.813 -719.813 -719.813] (1.000)
Step: 1799, Reward: [-824.242 -824.242 -824.242] [0.0000], Avg: [-722.714 -722.714 -722.714] (1.000)
Step: 1849, Reward: [-913.35 -913.35 -913.35] [0.0000], Avg: [-727.866 -727.866 -727.866] (1.000)
Step: 1899, Reward: [-1220.701 -1220.701 -1220.701] [0.0000], Avg: [-740.835 -740.835 -740.835] (1.000)
Step: 1949, Reward: [-937.684 -937.684 -937.684] [0.0000], Avg: [-745.883 -745.883 -745.883] (1.000)
Step: 1999, Reward: [-637.157 -637.157 -637.157] [0.0000], Avg: [-743.165 -743.165 -743.165] (1.000)
Step: 2049, Reward: [-555.312 -555.312 -555.312] [0.0000], Avg: [-738.583 -738.583 -738.583] (1.000)
Step: 2099, Reward: [-712.799 -712.799 -712.799] [0.0000], Avg: [-737.969 -737.969 -737.969] (1.000)
Step: 2149, Reward: [-574.396 -574.396 -574.396] [0.0000], Avg: [-734.165 -734.165 -734.165] (1.000)
Step: 2199, Reward: [-1422.444 -1422.444 -1422.444] [0.0000], Avg: [-749.808 -749.808 -749.808] (1.000)
Step: 2249, Reward: [-1302.648 -1302.648 -1302.648] [0.0000], Avg: [-762.093 -762.093 -762.093] (1.000)
Step: 2299, Reward: [-359.962 -359.962 -359.962] [0.0000], Avg: [-753.351 -753.351 -753.351] (1.000)
Step: 2349, Reward: [-643.91 -643.91 -643.91] [0.0000], Avg: [-751.022 -751.022 -751.022] (1.000)
Step: 2399, Reward: [-503.413 -503.413 -503.413] [0.0000], Avg: [-745.864 -745.864 -745.864] (1.000)
Step: 2449, Reward: [-437.364 -437.364 -437.364] [0.0000], Avg: [-739.568 -739.568 -739.568] (1.000)
Step: 2499, Reward: [-440.949 -440.949 -440.949] [0.0000], Avg: [-733.596 -733.596 -733.596] (1.000)
Step: 2549, Reward: [-573.86 -573.86 -573.86] [0.0000], Avg: [-730.464 -730.464 -730.464] (1.000)
Step: 2599, Reward: [-619.426 -619.426 -619.426] [0.0000], Avg: [-728.328 -728.328 -728.328] (1.000)
Step: 2649, Reward: [-697.939 -697.939 -697.939] [0.0000], Avg: [-727.755 -727.755 -727.755] (1.000)
Step: 2699, Reward: [-443.645 -443.645 -443.645] [0.0000], Avg: [-722.494 -722.494 -722.494] (1.000)
Step: 2749, Reward: [-517.086 -517.086 -517.086] [0.0000], Avg: [-718.759 -718.759 -718.759] (1.000)
Step: 2799, Reward: [-710.749 -710.749 -710.749] [0.0000], Avg: [-718.616 -718.616 -718.616] (1.000)
Step: 2849, Reward: [-494.476 -494.476 -494.476] [0.0000], Avg: [-714.684 -714.684 -714.684] (1.000)
Step: 2899, Reward: [-537.549 -537.549 -537.549] [0.0000], Avg: [-711.629 -711.629 -711.629] (1.000)
Step: 2949, Reward: [-640.954 -640.954 -640.954] [0.0000], Avg: [-710.432 -710.432 -710.432] (1.000)
Step: 2999, Reward: [-580.732 -580.732 -580.732] [0.0000], Avg: [-708.27 -708.27 -708.27] (1.000)
Step: 3049, Reward: [-445.625 -445.625 -445.625] [0.0000], Avg: [-703.964 -703.964 -703.964] (1.000)
Step: 3099, Reward: [-612.805 -612.805 -612.805] [0.0000], Avg: [-702.494 -702.494 -702.494] (1.000)
Step: 3149, Reward: [-644.758 -644.758 -644.758] [0.0000], Avg: [-701.578 -701.578 -701.578] (1.000)
Step: 3199, Reward: [-478.914 -478.914 -478.914] [0.0000], Avg: [-698.098 -698.098 -698.098] (1.000)
Step: 3249, Reward: [-534.865 -534.865 -534.865] [0.0000], Avg: [-695.587 -695.587 -695.587] (1.000)
Step: 3299, Reward: [-751.025 -751.025 -751.025] [0.0000], Avg: [-696.427 -696.427 -696.427] (1.000)
Step: 3349, Reward: [-516.354 -516.354 -516.354] [0.0000], Avg: [-693.739 -693.739 -693.739] (1.000)
Step: 3399, Reward: [-543.647 -543.647 -543.647] [0.0000], Avg: [-691.532 -691.532 -691.532] (1.000)
Step: 3449, Reward: [-849.655 -849.655 -849.655] [0.0000], Avg: [-693.824 -693.824 -693.824] (1.000)
Step: 3499, Reward: [-509.008 -509.008 -509.008] [0.0000], Avg: [-691.184 -691.184 -691.184] (1.000)
Step: 3549, Reward: [-754.048 -754.048 -754.048] [0.0000], Avg: [-692.069 -692.069 -692.069] (1.000)
Step: 3599, Reward: [-546.034 -546.034 -546.034] [0.0000], Avg: [-690.041 -690.041 -690.041] (1.000)
Step: 3649, Reward: [-584.809 -584.809 -584.809] [0.0000], Avg: [-688.599 -688.599 -688.599] (1.000)
Step: 3699, Reward: [-719.331 -719.331 -719.331] [0.0000], Avg: [-689.015 -689.015 -689.015] (1.000)
Step: 3749, Reward: [-574.009 -574.009 -574.009] [0.0000], Avg: [-687.481 -687.481 -687.481] (1.000)
Step: 3799, Reward: [-846.736 -846.736 -846.736] [0.0000], Avg: [-689.577 -689.577 -689.577] (1.000)
Step: 3849, Reward: [-508.198 -508.198 -508.198] [0.0000], Avg: [-687.221 -687.221 -687.221] (1.000)
Step: 3899, Reward: [-809.018 -809.018 -809.018] [0.0000], Avg: [-688.783 -688.783 -688.783] (1.000)
Step: 3949, Reward: [-750.686 -750.686 -750.686] [0.0000], Avg: [-689.566 -689.566 -689.566] (1.000)
Step: 3999, Reward: [-499.768 -499.768 -499.768] [0.0000], Avg: [-687.194 -687.194 -687.194] (1.000)
Step: 4049, Reward: [-645.173 -645.173 -645.173] [0.0000], Avg: [-686.675 -686.675 -686.675] (1.000)
Step: 4099, Reward: [-478.509 -478.509 -478.509] [0.0000], Avg: [-684.136 -684.136 -684.136] (1.000)
Step: 4149, Reward: [-668.272 -668.272 -668.272] [0.0000], Avg: [-683.945 -683.945 -683.945] (1.000)
Step: 4199, Reward: [-395.574 -395.574 -395.574] [0.0000], Avg: [-680.512 -680.512 -680.512] (1.000)
Step: 4249, Reward: [-455.27 -455.27 -455.27] [0.0000], Avg: [-677.862 -677.862 -677.862] (1.000)
Step: 4299, Reward: [-648.573 -648.573 -648.573] [0.0000], Avg: [-677.522 -677.522 -677.522] (1.000)
Step: 4349, Reward: [-578.729 -578.729 -578.729] [0.0000], Avg: [-676.386 -676.386 -676.386] (1.000)
Step: 4399, Reward: [-801.096 -801.096 -801.096] [0.0000], Avg: [-677.803 -677.803 -677.803] (1.000)
Step: 4449, Reward: [-1052.781 -1052.781 -1052.781] [0.0000], Avg: [-682.017 -682.017 -682.017] (1.000)
Step: 4499, Reward: [-331.785 -331.785 -331.785] [0.0000], Avg: [-678.125 -678.125 -678.125] (1.000)
Step: 4549, Reward: [-704.913 -704.913 -704.913] [0.0000], Avg: [-678.419 -678.419 -678.419] (1.000)
Step: 4599, Reward: [-564.096 -564.096 -564.096] [0.0000], Avg: [-677.177 -677.177 -677.177] (1.000)
Step: 4649, Reward: [-441.876 -441.876 -441.876] [0.0000], Avg: [-674.647 -674.647 -674.647] (1.000)
Step: 4699, Reward: [-958.795 -958.795 -958.795] [0.0000], Avg: [-677.67 -677.67 -677.67] (1.000)
Step: 4749, Reward: [-1076.058 -1076.058 -1076.058] [0.0000], Avg: [-681.863 -681.863 -681.863] (1.000)
Step: 4799, Reward: [-801.304 -801.304 -801.304] [0.0000], Avg: [-683.107 -683.107 -683.107] (1.000)
Step: 4849, Reward: [-975.479 -975.479 -975.479] [0.0000], Avg: [-686.121 -686.121 -686.121] (1.000)
Step: 4899, Reward: [-503.857 -503.857 -503.857] [0.0000], Avg: [-684.262 -684.262 -684.262] (1.000)
Step: 4949, Reward: [-754.953 -754.953 -754.953] [0.0000], Avg: [-684.976 -684.976 -684.976] (1.000)
Step: 4999, Reward: [-404.792 -404.792 -404.792] [0.0000], Avg: [-682.174 -682.174 -682.174] (1.000)
Step: 5049, Reward: [-458.987 -458.987 -458.987] [0.0000], Avg: [-679.964 -679.964 -679.964] (1.000)
Step: 5099, Reward: [-683.846 -683.846 -683.846] [0.0000], Avg: [-680.002 -680.002 -680.002] (1.000)
Step: 5149, Reward: [-365.589 -365.589 -365.589] [0.0000], Avg: [-676.95 -676.95 -676.95] (1.000)
Step: 5199, Reward: [-773.86 -773.86 -773.86] [0.0000], Avg: [-677.881 -677.881 -677.881] (1.000)
Step: 5249, Reward: [-750.996 -750.996 -750.996] [0.0000], Avg: [-678.578 -678.578 -678.578] (1.000)
Step: 5299, Reward: [-508.744 -508.744 -508.744] [0.0000], Avg: [-676.975 -676.975 -676.975] (1.000)
Step: 5349, Reward: [-379.885 -379.885 -379.885] [0.0000], Avg: [-674.199 -674.199 -674.199] (1.000)
Step: 5399, Reward: [-476.043 -476.043 -476.043] [0.0000], Avg: [-672.364 -672.364 -672.364] (1.000)
Step: 5449, Reward: [-475.22 -475.22 -475.22] [0.0000], Avg: [-670.555 -670.555 -670.555] (1.000)
Step: 5499, Reward: [-304.172 -304.172 -304.172] [0.0000], Avg: [-667.225 -667.225 -667.225] (1.000)
Step: 5549, Reward: [-430.69 -430.69 -430.69] [0.0000], Avg: [-665.094 -665.094 -665.094] (1.000)
Step: 5599, Reward: [-512.57 -512.57 -512.57] [0.0000], Avg: [-663.732 -663.732 -663.732] (1.000)
Step: 5649, Reward: [-489.959 -489.959 -489.959] [0.0000], Avg: [-662.194 -662.194 -662.194] (1.000)
Step: 5699, Reward: [-514.09 -514.09 -514.09] [0.0000], Avg: [-660.895 -660.895 -660.895] (1.000)
Step: 5749, Reward: [-461.697 -461.697 -461.697] [0.0000], Avg: [-659.163 -659.163 -659.163] (1.000)
Step: 5799, Reward: [-617.588 -617.588 -617.588] [0.0000], Avg: [-658.804 -658.804 -658.804] (1.000)
Step: 5849, Reward: [-453.171 -453.171 -453.171] [0.0000], Avg: [-657.047 -657.047 -657.047] (1.000)
Step: 5899, Reward: [-638.242 -638.242 -638.242] [0.0000], Avg: [-656.888 -656.888 -656.888] (1.000)
Step: 5949, Reward: [-476.337 -476.337 -476.337] [0.0000], Avg: [-655.37 -655.37 -655.37] (1.000)
Step: 5999, Reward: [-962.322 -962.322 -962.322] [0.0000], Avg: [-657.928 -657.928 -657.928] (1.000)
Step: 6049, Reward: [-510.227 -510.227 -510.227] [0.0000], Avg: [-656.708 -656.708 -656.708] (1.000)
Step: 6099, Reward: [-595.088 -595.088 -595.088] [0.0000], Avg: [-656.202 -656.202 -656.202] (1.000)
Step: 6149, Reward: [-523.257 -523.257 -523.257] [0.0000], Avg: [-655.122 -655.122 -655.122] (1.000)
Step: 6199, Reward: [-646.728 -646.728 -646.728] [0.0000], Avg: [-655.054 -655.054 -655.054] (1.000)
Step: 6249, Reward: [-743.247 -743.247 -743.247] [0.0000], Avg: [-655.759 -655.759 -655.759] (1.000)
Step: 6299, Reward: [-632.494 -632.494 -632.494] [0.0000], Avg: [-655.575 -655.575 -655.575] (1.000)
Step: 6349, Reward: [-1122.086 -1122.086 -1122.086] [0.0000], Avg: [-659.248 -659.248 -659.248] (1.000)
Step: 6399, Reward: [-555.088 -555.088 -555.088] [0.0000], Avg: [-658.434 -658.434 -658.434] (1.000)
Step: 6449, Reward: [-704.534 -704.534 -704.534] [0.0000], Avg: [-658.792 -658.792 -658.792] (1.000)
Step: 6499, Reward: [-1225.947 -1225.947 -1225.947] [0.0000], Avg: [-663.154 -663.154 -663.154] (1.000)
Step: 6549, Reward: [-808.928 -808.928 -808.928] [0.0000], Avg: [-664.267 -664.267 -664.267] (1.000)
Step: 6599, Reward: [-696.874 -696.874 -696.874] [0.0000], Avg: [-664.514 -664.514 -664.514] (1.000)
Step: 6649, Reward: [-952.758 -952.758 -952.758] [0.0000], Avg: [-666.682 -666.682 -666.682] (1.000)
Step: 6699, Reward: [-895.581 -895.581 -895.581] [0.0000], Avg: [-668.39 -668.39 -668.39] (1.000)
Step: 6749, Reward: [-1053.997 -1053.997 -1053.997] [0.0000], Avg: [-671.246 -671.246 -671.246] (1.000)
Step: 6799, Reward: [-781.738 -781.738 -781.738] [0.0000], Avg: [-672.059 -672.059 -672.059] (1.000)
Step: 6849, Reward: [-1061.796 -1061.796 -1061.796] [0.0000], Avg: [-674.903 -674.903 -674.903] (1.000)
Step: 6899, Reward: [-1247.187 -1247.187 -1247.187] [0.0000], Avg: [-679.05 -679.05 -679.05] (1.000)
Step: 6949, Reward: [-745.369 -745.369 -745.369] [0.0000], Avg: [-679.527 -679.527 -679.527] (1.000)
Step: 6999, Reward: [-575.212 -575.212 -575.212] [0.0000], Avg: [-678.782 -678.782 -678.782] (1.000)
Step: 7049, Reward: [-1763.649 -1763.649 -1763.649] [0.0000], Avg: [-686.476 -686.476 -686.476] (1.000)
Step: 7099, Reward: [-667.439 -667.439 -667.439] [0.0000], Avg: [-686.342 -686.342 -686.342] (1.000)
Step: 7149, Reward: [-1329.118 -1329.118 -1329.118] [0.0000], Avg: [-690.837 -690.837 -690.837] (1.000)
Step: 7199, Reward: [-1323.168 -1323.168 -1323.168] [0.0000], Avg: [-695.228 -695.228 -695.228] (1.000)
Step: 7249, Reward: [-1059.813 -1059.813 -1059.813] [0.0000], Avg: [-697.743 -697.743 -697.743] (1.000)
Step: 7299, Reward: [-773.334 -773.334 -773.334] [0.0000], Avg: [-698.261 -698.261 -698.261] (1.000)
Step: 7349, Reward: [-788.665 -788.665 -788.665] [0.0000], Avg: [-698.876 -698.876 -698.876] (1.000)
Step: 7399, Reward: [-973.637 -973.637 -973.637] [0.0000], Avg: [-700.732 -700.732 -700.732] (1.000)
Step: 7449, Reward: [-989.06 -989.06 -989.06] [0.0000], Avg: [-702.667 -702.667 -702.667] (1.000)
Step: 7499, Reward: [-772.893 -772.893 -772.893] [0.0000], Avg: [-703.135 -703.135 -703.135] (1.000)
Step: 7549, Reward: [-707.78 -707.78 -707.78] [0.0000], Avg: [-703.166 -703.166 -703.166] (1.000)
Step: 7599, Reward: [-828.061 -828.061 -828.061] [0.0000], Avg: [-703.988 -703.988 -703.988] (1.000)
Step: 7649, Reward: [-871.784 -871.784 -871.784] [0.0000], Avg: [-705.084 -705.084 -705.084] (1.000)
Step: 7699, Reward: [-1540.014 -1540.014 -1540.014] [0.0000], Avg: [-710.506 -710.506 -710.506] (1.000)
Step: 7749, Reward: [-1269.137 -1269.137 -1269.137] [0.0000], Avg: [-714.11 -714.11 -714.11] (1.000)
Step: 7799, Reward: [-644.251 -644.251 -644.251] [0.0000], Avg: [-713.662 -713.662 -713.662] (1.000)
Step: 7849, Reward: [-624.068 -624.068 -624.068] [0.0000], Avg: [-713.092 -713.092 -713.092] (1.000)
Step: 7899, Reward: [-522.993 -522.993 -522.993] [0.0000], Avg: [-711.889 -711.889 -711.889] (1.000)
Step: 7949, Reward: [-959.14 -959.14 -959.14] [0.0000], Avg: [-713.444 -713.444 -713.444] (1.000)
Step: 7999, Reward: [-627.915 -627.915 -627.915] [0.0000], Avg: [-712.909 -712.909 -712.909] (1.000)
Step: 8049, Reward: [-499.777 -499.777 -499.777] [0.0000], Avg: [-711.585 -711.585 -711.585] (1.000)
Step: 8099, Reward: [-616.8 -616.8 -616.8] [0.0000], Avg: [-711. -711. -711.] (1.000)
Step: 8149, Reward: [-599.144 -599.144 -599.144] [0.0000], Avg: [-710.314 -710.314 -710.314] (1.000)
Step: 8199, Reward: [-860.884 -860.884 -860.884] [0.0000], Avg: [-711.232 -711.232 -711.232] (1.000)
Step: 8249, Reward: [-523.807 -523.807 -523.807] [0.0000], Avg: [-710.096 -710.096 -710.096] (1.000)
Step: 8299, Reward: [-699.988 -699.988 -699.988] [0.0000], Avg: [-710.035 -710.035 -710.035] (1.000)
Step: 8349, Reward: [-934.233 -934.233 -934.233] [0.0000], Avg: [-711.378 -711.378 -711.378] (1.000)
Step: 8399, Reward: [-837.133 -837.133 -837.133] [0.0000], Avg: [-712.126 -712.126 -712.126] (1.000)
Step: 8449, Reward: [-944.358 -944.358 -944.358] [0.0000], Avg: [-713.5 -713.5 -713.5] (1.000)
Step: 8499, Reward: [-582.333 -582.333 -582.333] [0.0000], Avg: [-712.729 -712.729 -712.729] (1.000)
Step: 8549, Reward: [-559.715 -559.715 -559.715] [0.0000], Avg: [-711.834 -711.834 -711.834] (1.000)
Step: 8599, Reward: [-1231.416 -1231.416 -1231.416] [0.0000], Avg: [-714.855 -714.855 -714.855] (1.000)
Step: 8649, Reward: [-1013.131 -1013.131 -1013.131] [0.0000], Avg: [-716.579 -716.579 -716.579] (1.000)
Step: 8699, Reward: [-559.103 -559.103 -559.103] [0.0000], Avg: [-715.674 -715.674 -715.674] (1.000)
Step: 8749, Reward: [-926.293 -926.293 -926.293] [0.0000], Avg: [-716.877 -716.877 -716.877] (1.000)
Step: 8799, Reward: [-1460.986 -1460.986 -1460.986] [0.0000], Avg: [-721.105 -721.105 -721.105] (1.000)
Step: 8849, Reward: [-949.816 -949.816 -949.816] [0.0000], Avg: [-722.397 -722.397 -722.397] (1.000)
Step: 8899, Reward: [-653.181 -653.181 -653.181] [0.0000], Avg: [-722.009 -722.009 -722.009] (1.000)
Step: 8949, Reward: [-1014.343 -1014.343 -1014.343] [0.0000], Avg: [-723.642 -723.642 -723.642] (1.000)
Step: 8999, Reward: [-518.556 -518.556 -518.556] [0.0000], Avg: [-722.502 -722.502 -722.502] (1.000)
Step: 9049, Reward: [-520.069 -520.069 -520.069] [0.0000], Avg: [-721.384 -721.384 -721.384] (1.000)
Step: 9099, Reward: [-571.808 -571.808 -571.808] [0.0000], Avg: [-720.562 -720.562 -720.562] (1.000)
Step: 9149, Reward: [-743.005 -743.005 -743.005] [0.0000], Avg: [-720.685 -720.685 -720.685] (1.000)
Step: 9199, Reward: [-1241.367 -1241.367 -1241.367] [0.0000], Avg: [-723.515 -723.515 -723.515] (1.000)
Step: 9249, Reward: [-685.344 -685.344 -685.344] [0.0000], Avg: [-723.308 -723.308 -723.308] (1.000)
Step: 9299, Reward: [-437.17 -437.17 -437.17] [0.0000], Avg: [-721.77 -721.77 -721.77] (1.000)
Step: 9349, Reward: [-989.786 -989.786 -989.786] [0.0000], Avg: [-723.203 -723.203 -723.203] (1.000)
Step: 9399, Reward: [-527.337 -527.337 -527.337] [0.0000], Avg: [-722.161 -722.161 -722.161] (1.000)
Step: 9449, Reward: [-690.428 -690.428 -690.428] [0.0000], Avg: [-721.993 -721.993 -721.993] (1.000)
Step: 9499, Reward: [-959.705 -959.705 -959.705] [0.0000], Avg: [-723.244 -723.244 -723.244] (1.000)
Step: 9549, Reward: [-966.804 -966.804 -966.804] [0.0000], Avg: [-724.52 -724.52 -724.52] (1.000)
Step: 9599, Reward: [-802.746 -802.746 -802.746] [0.0000], Avg: [-724.927 -724.927 -724.927] (1.000)
Step: 9649, Reward: [-527.562 -527.562 -527.562] [0.0000], Avg: [-723.904 -723.904 -723.904] (1.000)
Step: 9699, Reward: [-592.208 -592.208 -592.208] [0.0000], Avg: [-723.226 -723.226 -723.226] (1.000)
Step: 9749, Reward: [-795.488 -795.488 -795.488] [0.0000], Avg: [-723.596 -723.596 -723.596] (1.000)
Step: 9799, Reward: [-786.435 -786.435 -786.435] [0.0000], Avg: [-723.917 -723.917 -723.917] (1.000)
Step: 9849, Reward: [-650.928 -650.928 -650.928] [0.0000], Avg: [-723.546 -723.546 -723.546] (1.000)
Step: 9899, Reward: [-655.926 -655.926 -655.926] [0.0000], Avg: [-723.205 -723.205 -723.205] (1.000)
Step: 9949, Reward: [-626.067 -626.067 -626.067] [0.0000], Avg: [-722.717 -722.717 -722.717] (1.000)
Step: 9999, Reward: [-938.735 -938.735 -938.735] [0.0000], Avg: [-723.797 -723.797 -723.797] (1.000)
Step: 10049, Reward: [-948.788 -948.788 -948.788] [0.0000], Avg: [-724.916 -724.916 -724.916] (1.000)
Step: 10099, Reward: [-658.976 -658.976 -658.976] [0.0000], Avg: [-724.59 -724.59 -724.59] (1.000)
Step: 10149, Reward: [-731.046 -731.046 -731.046] [0.0000], Avg: [-724.621 -724.621 -724.621] (1.000)
Step: 10199, Reward: [-1358.34 -1358.34 -1358.34] [0.0000], Avg: [-727.728 -727.728 -727.728] (1.000)
Step: 10249, Reward: [-1057.725 -1057.725 -1057.725] [0.0000], Avg: [-729.338 -729.338 -729.338] (1.000)
Step: 10299, Reward: [-488.346 -488.346 -488.346] [0.0000], Avg: [-728.168 -728.168 -728.168] (1.000)
Step: 10349, Reward: [-1328.57 -1328.57 -1328.57] [0.0000], Avg: [-731.068 -731.068 -731.068] (1.000)
Step: 10399, Reward: [-634.842 -634.842 -634.842] [0.0000], Avg: [-730.606 -730.606 -730.606] (1.000)
Step: 10449, Reward: [-487.293 -487.293 -487.293] [0.0000], Avg: [-729.442 -729.442 -729.442] (1.000)
Step: 10499, Reward: [-422.635 -422.635 -422.635] [0.0000], Avg: [-727.981 -727.981 -727.981] (1.000)
Step: 10549, Reward: [-456.608 -456.608 -456.608] [0.0000], Avg: [-726.694 -726.694 -726.694] (1.000)
Step: 10599, Reward: [-1126.57 -1126.57 -1126.57] [0.0000], Avg: [-728.581 -728.581 -728.581] (1.000)
Step: 10649, Reward: [-604.204 -604.204 -604.204] [0.0000], Avg: [-727.997 -727.997 -727.997] (1.000)
Step: 10699, Reward: [-735.768 -735.768 -735.768] [0.0000], Avg: [-728.033 -728.033 -728.033] (1.000)
Step: 10749, Reward: [-679.666 -679.666 -679.666] [0.0000], Avg: [-727.808 -727.808 -727.808] (1.000)
Step: 10799, Reward: [-518.412 -518.412 -518.412] [0.0000], Avg: [-726.839 -726.839 -726.839] (1.000)
Step: 10849, Reward: [-359.073 -359.073 -359.073] [0.0000], Avg: [-725.144 -725.144 -725.144] (1.000)
Step: 10899, Reward: [-706.132 -706.132 -706.132] [0.0000], Avg: [-725.057 -725.057 -725.057] (1.000)
Step: 10949, Reward: [-560.646 -560.646 -560.646] [0.0000], Avg: [-724.306 -724.306 -724.306] (1.000)
Step: 10999, Reward: [-385.573 -385.573 -385.573] [0.0000], Avg: [-722.766 -722.766 -722.766] (1.000)
Step: 11049, Reward: [-409.258 -409.258 -409.258] [0.0000], Avg: [-721.348 -721.348 -721.348] (1.000)
Step: 11099, Reward: [-576.602 -576.602 -576.602] [0.0000], Avg: [-720.696 -720.696 -720.696] (1.000)
Step: 11149, Reward: [-450.702 -450.702 -450.702] [0.0000], Avg: [-719.485 -719.485 -719.485] (1.000)
Step: 11199, Reward: [-531.131 -531.131 -531.131] [0.0000], Avg: [-718.644 -718.644 -718.644] (1.000)
Step: 11249, Reward: [-508.415 -508.415 -508.415] [0.0000], Avg: [-717.71 -717.71 -717.71] (1.000)
Step: 11299, Reward: [-490.121 -490.121 -490.121] [0.0000], Avg: [-716.703 -716.703 -716.703] (1.000)
Step: 11349, Reward: [-868.96 -868.96 -868.96] [0.0000], Avg: [-717.373 -717.373 -717.373] (1.000)
Step: 11399, Reward: [-513.532 -513.532 -513.532] [0.0000], Avg: [-716.479 -716.479 -716.479] (1.000)
Step: 11449, Reward: [-873.29 -873.29 -873.29] [0.0000], Avg: [-717.164 -717.164 -717.164] (1.000)
Step: 11499, Reward: [-467.824 -467.824 -467.824] [0.0000], Avg: [-716.08 -716.08 -716.08] (1.000)
Step: 11549, Reward: [-456.701 -456.701 -456.701] [0.0000], Avg: [-714.957 -714.957 -714.957] (1.000)
Step: 11599, Reward: [-370.809 -370.809 -370.809] [0.0000], Avg: [-713.474 -713.474 -713.474] (1.000)
Step: 11649, Reward: [-409.547 -409.547 -409.547] [0.0000], Avg: [-712.169 -712.169 -712.169] (1.000)
Step: 11699, Reward: [-357.874 -357.874 -357.874] [0.0000], Avg: [-710.655 -710.655 -710.655] (1.000)
Step: 11749, Reward: [-906.137 -906.137 -906.137] [0.0000], Avg: [-711.487 -711.487 -711.487] (1.000)
Step: 11799, Reward: [-540.901 -540.901 -540.901] [0.0000], Avg: [-710.764 -710.764 -710.764] (1.000)
Step: 11849, Reward: [-980.081 -980.081 -980.081] [0.0000], Avg: [-711.901 -711.901 -711.901] (1.000)
Step: 11899, Reward: [-686.309 -686.309 -686.309] [0.0000], Avg: [-711.793 -711.793 -711.793] (1.000)
Step: 11949, Reward: [-512.179 -512.179 -512.179] [0.0000], Avg: [-710.958 -710.958 -710.958] (1.000)
Step: 11999, Reward: [-743.302 -743.302 -743.302] [0.0000], Avg: [-711.093 -711.093 -711.093] (1.000)
Step: 12049, Reward: [-463.03 -463.03 -463.03] [0.0000], Avg: [-710.063 -710.063 -710.063] (1.000)
Step: 12099, Reward: [-344.34 -344.34 -344.34] [0.0000], Avg: [-708.552 -708.552 -708.552] (1.000)
Step: 12149, Reward: [-697.674 -697.674 -697.674] [0.0000], Avg: [-708.507 -708.507 -708.507] (1.000)
Step: 12199, Reward: [-1134.776 -1134.776 -1134.776] [0.0000], Avg: [-710.254 -710.254 -710.254] (1.000)
Step: 12249, Reward: [-713.236 -713.236 -713.236] [0.0000], Avg: [-710.267 -710.267 -710.267] (1.000)
Step: 12299, Reward: [-907.513 -907.513 -907.513] [0.0000], Avg: [-711.068 -711.068 -711.068] (1.000)
Step: 12349, Reward: [-800.787 -800.787 -800.787] [0.0000], Avg: [-711.432 -711.432 -711.432] (1.000)
Step: 12399, Reward: [-885.302 -885.302 -885.302] [0.0000], Avg: [-712.133 -712.133 -712.133] (1.000)
Step: 12449, Reward: [-530.953 -530.953 -530.953] [0.0000], Avg: [-711.405 -711.405 -711.405] (1.000)
Step: 12499, Reward: [-499.646 -499.646 -499.646] [0.0000], Avg: [-710.558 -710.558 -710.558] (1.000)
Step: 12549, Reward: [-700.108 -700.108 -700.108] [0.0000], Avg: [-710.516 -710.516 -710.516] (1.000)
Step: 12599, Reward: [-1048.841 -1048.841 -1048.841] [0.0000], Avg: [-711.859 -711.859 -711.859] (1.000)
Step: 12649, Reward: [-713.212 -713.212 -713.212] [0.0000], Avg: [-711.864 -711.864 -711.864] (1.000)
Step: 12699, Reward: [-412.626 -412.626 -412.626] [0.0000], Avg: [-710.686 -710.686 -710.686] (1.000)
Step: 12749, Reward: [-526.935 -526.935 -526.935] [0.0000], Avg: [-709.966 -709.966 -709.966] (1.000)
Step: 12799, Reward: [-614.313 -614.313 -614.313] [0.0000], Avg: [-709.592 -709.592 -709.592] (1.000)
Step: 12849, Reward: [-518.347 -518.347 -518.347] [0.0000], Avg: [-708.848 -708.848 -708.848] (1.000)
Step: 12899, Reward: [-594.53 -594.53 -594.53] [0.0000], Avg: [-708.405 -708.405 -708.405] (1.000)
Step: 12949, Reward: [-767.624 -767.624 -767.624] [0.0000], Avg: [-708.633 -708.633 -708.633] (1.000)
Step: 12999, Reward: [-645.926 -645.926 -645.926] [0.0000], Avg: [-708.392 -708.392 -708.392] (1.000)
Step: 13049, Reward: [-440.546 -440.546 -440.546] [0.0000], Avg: [-707.366 -707.366 -707.366] (1.000)
Step: 13099, Reward: [-1143.893 -1143.893 -1143.893] [0.0000], Avg: [-709.032 -709.032 -709.032] (1.000)
Step: 13149, Reward: [-390.331 -390.331 -390.331] [0.0000], Avg: [-707.82 -707.82 -707.82] (1.000)
Step: 13199, Reward: [-501.76 -501.76 -501.76] [0.0000], Avg: [-707.04 -707.04 -707.04] (1.000)
Step: 13249, Reward: [-477.879 -477.879 -477.879] [0.0000], Avg: [-706.175 -706.175 -706.175] (1.000)
Step: 13299, Reward: [-639.66 -639.66 -639.66] [0.0000], Avg: [-705.925 -705.925 -705.925] (1.000)
Step: 13349, Reward: [-1590.515 -1590.515 -1590.515] [0.0000], Avg: [-709.238 -709.238 -709.238] (1.000)
Step: 13399, Reward: [-470.072 -470.072 -470.072] [0.0000], Avg: [-708.346 -708.346 -708.346] (1.000)
Step: 13449, Reward: [-600.891 -600.891 -600.891] [0.0000], Avg: [-707.946 -707.946 -707.946] (1.000)
Step: 13499, Reward: [-552.769 -552.769 -552.769] [0.0000], Avg: [-707.371 -707.371 -707.371] (1.000)
Step: 13549, Reward: [-627.886 -627.886 -627.886] [0.0000], Avg: [-707.078 -707.078 -707.078] (1.000)
Step: 13599, Reward: [-713.253 -713.253 -713.253] [0.0000], Avg: [-707.101 -707.101 -707.101] (1.000)
Step: 13649, Reward: [-763.655 -763.655 -763.655] [0.0000], Avg: [-707.308 -707.308 -707.308] (1.000)
Step: 13699, Reward: [-533.767 -533.767 -533.767] [0.0000], Avg: [-706.675 -706.675 -706.675] (1.000)
Step: 13749, Reward: [-602.02 -602.02 -602.02] [0.0000], Avg: [-706.294 -706.294 -706.294] (1.000)
Step: 13799, Reward: [-1674.675 -1674.675 -1674.675] [0.0000], Avg: [-709.803 -709.803 -709.803] (1.000)
Step: 13849, Reward: [-500.362 -500.362 -500.362] [0.0000], Avg: [-709.047 -709.047 -709.047] (1.000)
Step: 13899, Reward: [-243.967 -243.967 -243.967] [0.0000], Avg: [-707.374 -707.374 -707.374] (1.000)
Step: 13949, Reward: [-551.571 -551.571 -551.571] [0.0000], Avg: [-706.815 -706.815 -706.815] (1.000)
Step: 13999, Reward: [-374.531 -374.531 -374.531] [0.0000], Avg: [-705.628 -705.628 -705.628] (1.000)
Step: 14049, Reward: [-703.299 -703.299 -703.299] [0.0000], Avg: [-705.62 -705.62 -705.62] (1.000)
Step: 14099, Reward: [-496.47 -496.47 -496.47] [0.0000], Avg: [-704.878 -704.878 -704.878] (1.000)
Step: 14149, Reward: [-484.927 -484.927 -484.927] [0.0000], Avg: [-704.101 -704.101 -704.101] (1.000)
Step: 14199, Reward: [-532.213 -532.213 -532.213] [0.0000], Avg: [-703.496 -703.496 -703.496] (1.000)
Step: 14249, Reward: [-1095.709 -1095.709 -1095.709] [0.0000], Avg: [-704.872 -704.872 -704.872] (1.000)
Step: 14299, Reward: [-594.691 -594.691 -594.691] [0.0000], Avg: [-704.487 -704.487 -704.487] (1.000)
Step: 14349, Reward: [-415.46 -415.46 -415.46] [0.0000], Avg: [-703.48 -703.48 -703.48] (1.000)
Step: 14399, Reward: [-455.601 -455.601 -455.601] [0.0000], Avg: [-702.619 -702.619 -702.619] (1.000)
Step: 14449, Reward: [-527.422 -527.422 -527.422] [0.0000], Avg: [-702.013 -702.013 -702.013] (1.000)
Step: 14499, Reward: [-629.167 -629.167 -629.167] [0.0000], Avg: [-701.762 -701.762 -701.762] (1.000)
Step: 14549, Reward: [-502.724 -502.724 -502.724] [0.0000], Avg: [-701.078 -701.078 -701.078] (1.000)
Step: 14599, Reward: [-486.789 -486.789 -486.789] [0.0000], Avg: [-700.344 -700.344 -700.344] (1.000)
Step: 14649, Reward: [-1386.735 -1386.735 -1386.735] [0.0000], Avg: [-702.687 -702.687 -702.687] (1.000)
Step: 14699, Reward: [-337.819 -337.819 -337.819] [0.0000], Avg: [-701.446 -701.446 -701.446] (1.000)
Step: 14749, Reward: [-515.111 -515.111 -515.111] [0.0000], Avg: [-700.814 -700.814 -700.814] (1.000)
Step: 14799, Reward: [-443.318 -443.318 -443.318] [0.0000], Avg: [-699.944 -699.944 -699.944] (1.000)
Step: 14849, Reward: [-847.321 -847.321 -847.321] [0.0000], Avg: [-700.44 -700.44 -700.44] (1.000)
Step: 14899, Reward: [-742.715 -742.715 -742.715] [0.0000], Avg: [-700.582 -700.582 -700.582] (1.000)
Step: 14949, Reward: [-471.998 -471.998 -471.998] [0.0000], Avg: [-699.818 -699.818 -699.818] (1.000)
Step: 14999, Reward: [-500.286 -500.286 -500.286] [0.0000], Avg: [-699.152 -699.152 -699.152] (1.000)
Step: 15049, Reward: [-498.584 -498.584 -498.584] [0.0000], Avg: [-698.486 -698.486 -698.486] (1.000)
Step: 15099, Reward: [-408.129 -408.129 -408.129] [0.0000], Avg: [-697.525 -697.525 -697.525] (1.000)
Step: 15149, Reward: [-550.739 -550.739 -550.739] [0.0000], Avg: [-697.04 -697.04 -697.04] (1.000)
Step: 15199, Reward: [-455.481 -455.481 -455.481] [0.0000], Avg: [-696.246 -696.246 -696.246] (1.000)
Step: 15249, Reward: [-626.427 -626.427 -626.427] [0.0000], Avg: [-696.017 -696.017 -696.017] (1.000)
Step: 15299, Reward: [-535.392 -535.392 -535.392] [0.0000], Avg: [-695.492 -695.492 -695.492] (1.000)
Step: 15349, Reward: [-600.612 -600.612 -600.612] [0.0000], Avg: [-695.183 -695.183 -695.183] (1.000)
Step: 15399, Reward: [-780.117 -780.117 -780.117] [0.0000], Avg: [-695.458 -695.458 -695.458] (1.000)
Step: 15449, Reward: [-669.173 -669.173 -669.173] [0.0000], Avg: [-695.373 -695.373 -695.373] (1.000)
Step: 15499, Reward: [-460.613 -460.613 -460.613] [0.0000], Avg: [-694.616 -694.616 -694.616] (1.000)
Step: 15549, Reward: [-532.334 -532.334 -532.334] [0.0000], Avg: [-694.094 -694.094 -694.094] (1.000)
Step: 15599, Reward: [-774.312 -774.312 -774.312] [0.0000], Avg: [-694.351 -694.351 -694.351] (1.000)
Step: 15649, Reward: [-502.136 -502.136 -502.136] [0.0000], Avg: [-693.737 -693.737 -693.737] (1.000)
Step: 15699, Reward: [-557.835 -557.835 -557.835] [0.0000], Avg: [-693.305 -693.305 -693.305] (1.000)
Step: 15749, Reward: [-413.027 -413.027 -413.027] [0.0000], Avg: [-692.415 -692.415 -692.415] (1.000)
Step: 15799, Reward: [-554.1 -554.1 -554.1] [0.0000], Avg: [-691.977 -691.977 -691.977] (1.000)
Step: 15849, Reward: [-394.219 -394.219 -394.219] [0.0000], Avg: [-691.038 -691.038 -691.038] (1.000)
Step: 15899, Reward: [-507.972 -507.972 -507.972] [0.0000], Avg: [-690.462 -690.462 -690.462] (1.000)
Step: 15949, Reward: [-504.802 -504.802 -504.802] [0.0000], Avg: [-689.88 -689.88 -689.88] (1.000)
Step: 15999, Reward: [-493.939 -493.939 -493.939] [0.0000], Avg: [-689.268 -689.268 -689.268] (1.000)
Step: 16049, Reward: [-641.695 -641.695 -641.695] [0.0000], Avg: [-689.12 -689.12 -689.12] (1.000)
Step: 16099, Reward: [-487.997 -487.997 -487.997] [0.0000], Avg: [-688.495 -688.495 -688.495] (1.000)
Step: 16149, Reward: [-643.311 -643.311 -643.311] [0.0000], Avg: [-688.355 -688.355 -688.355] (1.000)
Step: 16199, Reward: [-505.51 -505.51 -505.51] [0.0000], Avg: [-687.791 -687.791 -687.791] (1.000)
Step: 16249, Reward: [-662.987 -662.987 -662.987] [0.0000], Avg: [-687.714 -687.714 -687.714] (1.000)
Step: 16299, Reward: [-664.738 -664.738 -664.738] [0.0000], Avg: [-687.644 -687.644 -687.644] (1.000)
Step: 16349, Reward: [-372.237 -372.237 -372.237] [0.0000], Avg: [-686.679 -686.679 -686.679] (1.000)
Step: 16399, Reward: [-516.598 -516.598 -516.598] [0.0000], Avg: [-686.161 -686.161 -686.161] (1.000)
Step: 16449, Reward: [-504.982 -504.982 -504.982] [0.0000], Avg: [-685.61 -685.61 -685.61] (1.000)
Step: 16499, Reward: [-502.911 -502.911 -502.911] [0.0000], Avg: [-685.056 -685.056 -685.056] (1.000)
Step: 16549, Reward: [-590.615 -590.615 -590.615] [0.0000], Avg: [-684.771 -684.771 -684.771] (1.000)
Step: 16599, Reward: [-480.833 -480.833 -480.833] [0.0000], Avg: [-684.157 -684.157 -684.157] (1.000)
Step: 16649, Reward: [-429.806 -429.806 -429.806] [0.0000], Avg: [-683.393 -683.393 -683.393] (1.000)
Step: 16699, Reward: [-724.258 -724.258 -724.258] [0.0000], Avg: [-683.515 -683.515 -683.515] (1.000)
Step: 16749, Reward: [-453.01 -453.01 -453.01] [0.0000], Avg: [-682.827 -682.827 -682.827] (1.000)
Step: 16799, Reward: [-542.084 -542.084 -542.084] [0.0000], Avg: [-682.408 -682.408 -682.408] (1.000)
Step: 16849, Reward: [-518.037 -518.037 -518.037] [0.0000], Avg: [-681.921 -681.921 -681.921] (1.000)
Step: 16899, Reward: [-563.137 -563.137 -563.137] [0.0000], Avg: [-681.569 -681.569 -681.569] (1.000)
Step: 16949, Reward: [-754.469 -754.469 -754.469] [0.0000], Avg: [-681.784 -681.784 -681.784] (1.000)
Step: 16999, Reward: [-561.423 -561.423 -561.423] [0.0000], Avg: [-681.43 -681.43 -681.43] (1.000)
Step: 17049, Reward: [-445.661 -445.661 -445.661] [0.0000], Avg: [-680.739 -680.739 -680.739] (1.000)
Step: 17099, Reward: [-429.657 -429.657 -429.657] [0.0000], Avg: [-680.005 -680.005 -680.005] (1.000)
Step: 17149, Reward: [-463.5 -463.5 -463.5] [0.0000], Avg: [-679.374 -679.374 -679.374] (1.000)
Step: 17199, Reward: [-433.15 -433.15 -433.15] [0.0000], Avg: [-678.658 -678.658 -678.658] (1.000)
Step: 17249, Reward: [-477.648 -477.648 -477.648] [0.0000], Avg: [-678.075 -678.075 -678.075] (1.000)
Step: 17299, Reward: [-361.953 -361.953 -361.953] [0.0000], Avg: [-677.162 -677.162 -677.162] (1.000)
Step: 17349, Reward: [-851.362 -851.362 -851.362] [0.0000], Avg: [-677.664 -677.664 -677.664] (1.000)
Step: 17399, Reward: [-426.78 -426.78 -426.78] [0.0000], Avg: [-676.943 -676.943 -676.943] (1.000)
Step: 17449, Reward: [-494.187 -494.187 -494.187] [0.0000], Avg: [-676.419 -676.419 -676.419] (1.000)
Step: 17499, Reward: [-515.141 -515.141 -515.141] [0.0000], Avg: [-675.958 -675.958 -675.958] (1.000)
Step: 17549, Reward: [-955.282 -955.282 -955.282] [0.0000], Avg: [-676.754 -676.754 -676.754] (1.000)
Step: 17599, Reward: [-578.491 -578.491 -578.491] [0.0000], Avg: [-676.475 -676.475 -676.475] (1.000)
Step: 17649, Reward: [-442.553 -442.553 -442.553] [0.0000], Avg: [-675.812 -675.812 -675.812] (1.000)
Step: 17699, Reward: [-516.599 -516.599 -516.599] [0.0000], Avg: [-675.362 -675.362 -675.362] (1.000)
Step: 17749, Reward: [-501.712 -501.712 -501.712] [0.0000], Avg: [-674.873 -674.873 -674.873] (1.000)
Step: 17799, Reward: [-813.955 -813.955 -813.955] [0.0000], Avg: [-675.264 -675.264 -675.264] (1.000)
Step: 17849, Reward: [-494.899 -494.899 -494.899] [0.0000], Avg: [-674.759 -674.759 -674.759] (1.000)
Step: 17899, Reward: [-489.442 -489.442 -489.442] [0.0000], Avg: [-674.241 -674.241 -674.241] (1.000)
Step: 17949, Reward: [-543.647 -543.647 -543.647] [0.0000], Avg: [-673.877 -673.877 -673.877] (1.000)
Step: 17999, Reward: [-422.26 -422.26 -422.26] [0.0000], Avg: [-673.178 -673.178 -673.178] (1.000)
Step: 18049, Reward: [-363.815 -363.815 -363.815] [0.0000], Avg: [-672.321 -672.321 -672.321] (1.000)
Step: 18099, Reward: [-485.657 -485.657 -485.657] [0.0000], Avg: [-671.806 -671.806 -671.806] (1.000)
Step: 18149, Reward: [-439.2 -439.2 -439.2] [0.0000], Avg: [-671.165 -671.165 -671.165] (1.000)
Step: 18199, Reward: [-572.056 -572.056 -572.056] [0.0000], Avg: [-670.893 -670.893 -670.893] (1.000)
Step: 18249, Reward: [-593.04 -593.04 -593.04] [0.0000], Avg: [-670.679 -670.679 -670.679] (1.000)
Step: 18299, Reward: [-534.225 -534.225 -534.225] [0.0000], Avg: [-670.307 -670.307 -670.307] (1.000)
Step: 18349, Reward: [-492.771 -492.771 -492.771] [0.0000], Avg: [-669.823 -669.823 -669.823] (1.000)
Step: 18399, Reward: [-424.964 -424.964 -424.964] [0.0000], Avg: [-669.157 -669.157 -669.157] (1.000)
Step: 18449, Reward: [-540.422 -540.422 -540.422] [0.0000], Avg: [-668.809 -668.809 -668.809] (1.000)
Step: 18499, Reward: [-661.616 -661.616 -661.616] [0.0000], Avg: [-668.789 -668.789 -668.789] (1.000)
Step: 18549, Reward: [-538.594 -538.594 -538.594] [0.0000], Avg: [-668.438 -668.438 -668.438] (1.000)
Step: 18599, Reward: [-509.118 -509.118 -509.118] [0.0000], Avg: [-668.01 -668.01 -668.01] (1.000)
Step: 18649, Reward: [-508.523 -508.523 -508.523] [0.0000], Avg: [-667.582 -667.582 -667.582] (1.000)
Step: 18699, Reward: [-493.513 -493.513 -493.513] [0.0000], Avg: [-667.117 -667.117 -667.117] (1.000)
Step: 18749, Reward: [-491.028 -491.028 -491.028] [0.0000], Avg: [-666.647 -666.647 -666.647] (1.000)
Step: 18799, Reward: [-513.833 -513.833 -513.833] [0.0000], Avg: [-666.241 -666.241 -666.241] (1.000)
Step: 18849, Reward: [-561.553 -561.553 -561.553] [0.0000], Avg: [-665.963 -665.963 -665.963] (1.000)
Step: 18899, Reward: [-489.145 -489.145 -489.145] [0.0000], Avg: [-665.495 -665.495 -665.495] (1.000)
Step: 18949, Reward: [-512.971 -512.971 -512.971] [0.0000], Avg: [-665.093 -665.093 -665.093] (1.000)
Step: 18999, Reward: [-430.09 -430.09 -430.09] [0.0000], Avg: [-664.475 -664.475 -664.475] (1.000)
Step: 19049, Reward: [-454.839 -454.839 -454.839] [0.0000], Avg: [-663.924 -663.924 -663.924] (1.000)
Step: 19099, Reward: [-511.274 -511.274 -511.274] [0.0000], Avg: [-663.525 -663.525 -663.525] (1.000)
Step: 19149, Reward: [-409.965 -409.965 -409.965] [0.0000], Avg: [-662.863 -662.863 -662.863] (1.000)
Step: 19199, Reward: [-499.945 -499.945 -499.945] [0.0000], Avg: [-662.438 -662.438 -662.438] (1.000)
Step: 19249, Reward: [-327.764 -327.764 -327.764] [0.0000], Avg: [-661.569 -661.569 -661.569] (1.000)
Step: 19299, Reward: [-568.674 -568.674 -568.674] [0.0000], Avg: [-661.328 -661.328 -661.328] (1.000)
Step: 19349, Reward: [-431.398 -431.398 -431.398] [0.0000], Avg: [-660.734 -660.734 -660.734] (1.000)
Step: 19399, Reward: [-686.778 -686.778 -686.778] [0.0000], Avg: [-660.801 -660.801 -660.801] (1.000)
Step: 19449, Reward: [-416.399 -416.399 -416.399] [0.0000], Avg: [-660.173 -660.173 -660.173] (1.000)
Step: 19499, Reward: [-456.445 -456.445 -456.445] [0.0000], Avg: [-659.651 -659.651 -659.651] (1.000)
Step: 19549, Reward: [-497.541 -497.541 -497.541] [0.0000], Avg: [-659.236 -659.236 -659.236] (1.000)
Step: 19599, Reward: [-457.531 -457.531 -457.531] [0.0000], Avg: [-658.722 -658.722 -658.722] (1.000)
Step: 19649, Reward: [-394.164 -394.164 -394.164] [0.0000], Avg: [-658.048 -658.048 -658.048] (1.000)
Step: 19699, Reward: [-373.566 -373.566 -373.566] [0.0000], Avg: [-657.326 -657.326 -657.326] (1.000)
Step: 19749, Reward: [-578.728 -578.728 -578.728] [0.0000], Avg: [-657.127 -657.127 -657.127] (1.000)
Step: 19799, Reward: [-504.96 -504.96 -504.96] [0.0000], Avg: [-656.743 -656.743 -656.743] (1.000)
Step: 19849, Reward: [-411.256 -411.256 -411.256] [0.0000], Avg: [-656.125 -656.125 -656.125] (1.000)
Step: 19899, Reward: [-461.434 -461.434 -461.434] [0.0000], Avg: [-655.636 -655.636 -655.636] (1.000)
Step: 19949, Reward: [-436.802 -436.802 -436.802] [0.0000], Avg: [-655.087 -655.087 -655.087] (1.000)
Step: 19999, Reward: [-459.456 -459.456 -459.456] [0.0000], Avg: [-654.598 -654.598 -654.598] (1.000)
Step: 20049, Reward: [-363.555 -363.555 -363.555] [0.0000], Avg: [-653.872 -653.872 -653.872] (1.000)
Step: 20099, Reward: [-460.824 -460.824 -460.824] [0.0000], Avg: [-653.392 -653.392 -653.392] (1.000)
Step: 20149, Reward: [-568.416 -568.416 -568.416] [0.0000], Avg: [-653.181 -653.181 -653.181] (1.000)
Step: 20199, Reward: [-445.191 -445.191 -445.191] [0.0000], Avg: [-652.666 -652.666 -652.666] (1.000)
Step: 20249, Reward: [-531.287 -531.287 -531.287] [0.0000], Avg: [-652.367 -652.367 -652.367] (1.000)
Step: 20299, Reward: [-562.022 -562.022 -562.022] [0.0000], Avg: [-652.144 -652.144 -652.144] (1.000)
Step: 20349, Reward: [-361.04 -361.04 -361.04] [0.0000], Avg: [-651.429 -651.429 -651.429] (1.000)
Step: 20399, Reward: [-390.168 -390.168 -390.168] [0.0000], Avg: [-650.789 -650.789 -650.789] (1.000)
Step: 20449, Reward: [-349.556 -349.556 -349.556] [0.0000], Avg: [-650.052 -650.052 -650.052] (1.000)
Step: 20499, Reward: [-522.98 -522.98 -522.98] [0.0000], Avg: [-649.742 -649.742 -649.742] (1.000)
Step: 20549, Reward: [-379.646 -379.646 -379.646] [0.0000], Avg: [-649.085 -649.085 -649.085] (1.000)
Step: 20599, Reward: [-525.484 -525.484 -525.484] [0.0000], Avg: [-648.785 -648.785 -648.785] (1.000)
Step: 20649, Reward: [-467.223 -467.223 -467.223] [0.0000], Avg: [-648.345 -648.345 -648.345] (1.000)
Step: 20699, Reward: [-428.954 -428.954 -428.954] [0.0000], Avg: [-647.815 -647.815 -647.815] (1.000)
Step: 20749, Reward: [-597.294 -597.294 -597.294] [0.0000], Avg: [-647.694 -647.694 -647.694] (1.000)
Step: 20799, Reward: [-532.063 -532.063 -532.063] [0.0000], Avg: [-647.416 -647.416 -647.416] (1.000)
Step: 20849, Reward: [-510.949 -510.949 -510.949] [0.0000], Avg: [-647.088 -647.088 -647.088] (1.000)
Step: 20899, Reward: [-428.907 -428.907 -428.907] [0.0000], Avg: [-646.567 -646.567 -646.567] (1.000)
Step: 20949, Reward: [-584.603 -584.603 -584.603] [0.0000], Avg: [-646.419 -646.419 -646.419] (1.000)
Step: 20999, Reward: [-420.333 -420.333 -420.333] [0.0000], Avg: [-645.88 -645.88 -645.88] (1.000)
Step: 21049, Reward: [-574.007 -574.007 -574.007] [0.0000], Avg: [-645.71 -645.71 -645.71] (1.000)
Step: 21099, Reward: [-451.075 -451.075 -451.075] [0.0000], Avg: [-645.248 -645.248 -645.248] (1.000)
Step: 21149, Reward: [-395.194 -395.194 -395.194] [0.0000], Avg: [-644.657 -644.657 -644.657] (1.000)
Step: 21199, Reward: [-430.74 -430.74 -430.74] [0.0000], Avg: [-644.153 -644.153 -644.153] (1.000)
Step: 21249, Reward: [-707.782 -707.782 -707.782] [0.0000], Avg: [-644.302 -644.302 -644.302] (1.000)
Step: 21299, Reward: [-434.915 -434.915 -434.915] [0.0000], Avg: [-643.811 -643.811 -643.811] (1.000)
Step: 21349, Reward: [-522.225 -522.225 -522.225] [0.0000], Avg: [-643.526 -643.526 -643.526] (1.000)
Step: 21399, Reward: [-544.396 -544.396 -544.396] [0.0000], Avg: [-643.295 -643.295 -643.295] (1.000)
Step: 21449, Reward: [-364.786 -364.786 -364.786] [0.0000], Avg: [-642.645 -642.645 -642.645] (1.000)
Step: 21499, Reward: [-379.015 -379.015 -379.015] [0.0000], Avg: [-642.032 -642.032 -642.032] (1.000)
Step: 21549, Reward: [-372.524 -372.524 -372.524] [0.0000], Avg: [-641.407 -641.407 -641.407] (1.000)
Step: 21599, Reward: [-412.647 -412.647 -412.647] [0.0000], Avg: [-640.877 -640.877 -640.877] (1.000)
Step: 21649, Reward: [-501.848 -501.848 -501.848] [0.0000], Avg: [-640.556 -640.556 -640.556] (1.000)
Step: 21699, Reward: [-467.526 -467.526 -467.526] [0.0000], Avg: [-640.158 -640.158 -640.158] (1.000)
Step: 21749, Reward: [-457.018 -457.018 -457.018] [0.0000], Avg: [-639.737 -639.737 -639.737] (1.000)
Step: 21799, Reward: [-750.424 -750.424 -750.424] [0.0000], Avg: [-639.991 -639.991 -639.991] (1.000)
Step: 21849, Reward: [-362.826 -362.826 -362.826] [0.0000], Avg: [-639.356 -639.356 -639.356] (1.000)
Step: 21899, Reward: [-441.423 -441.423 -441.423] [0.0000], Avg: [-638.904 -638.904 -638.904] (1.000)
Step: 21949, Reward: [-550.842 -550.842 -550.842] [0.0000], Avg: [-638.704 -638.704 -638.704] (1.000)
Step: 21999, Reward: [-422.27 -422.27 -422.27] [0.0000], Avg: [-638.212 -638.212 -638.212] (1.000)
Step: 22049, Reward: [-291.135 -291.135 -291.135] [0.0000], Avg: [-637.425 -637.425 -637.425] (1.000)
Step: 22099, Reward: [-449.746 -449.746 -449.746] [0.0000], Avg: [-637. -637. -637.] (1.000)
Step: 22149, Reward: [-507.387 -507.387 -507.387] [0.0000], Avg: [-636.708 -636.708 -636.708] (1.000)
Step: 22199, Reward: [-369.466 -369.466 -369.466] [0.0000], Avg: [-636.106 -636.106 -636.106] (1.000)
Step: 22249, Reward: [-520.064 -520.064 -520.064] [0.0000], Avg: [-635.845 -635.845 -635.845] (1.000)
Step: 22299, Reward: [-412.303 -412.303 -412.303] [0.0000], Avg: [-635.344 -635.344 -635.344] (1.000)
Step: 22349, Reward: [-416.999 -416.999 -416.999] [0.0000], Avg: [-634.855 -634.855 -634.855] (1.000)
Step: 22399, Reward: [-497.342 -497.342 -497.342] [0.0000], Avg: [-634.548 -634.548 -634.548] (1.000)
Step: 22449, Reward: [-318.814 -318.814 -318.814] [0.0000], Avg: [-633.845 -633.845 -633.845] (1.000)
Step: 22499, Reward: [-401.826 -401.826 -401.826] [0.0000], Avg: [-633.33 -633.33 -633.33] (1.000)
Step: 22549, Reward: [-450.905 -450.905 -450.905] [0.0000], Avg: [-632.925 -632.925 -632.925] (1.000)
Step: 22599, Reward: [-318.885 -318.885 -318.885] [0.0000], Avg: [-632.23 -632.23 -632.23] (1.000)
Step: 22649, Reward: [-661.11 -661.11 -661.11] [0.0000], Avg: [-632.294 -632.294 -632.294] (1.000)
Step: 22699, Reward: [-441.02 -441.02 -441.02] [0.0000], Avg: [-631.873 -631.873 -631.873] (1.000)
Step: 22749, Reward: [-389.692 -389.692 -389.692] [0.0000], Avg: [-631.34 -631.34 -631.34] (1.000)
Step: 22799, Reward: [-443.075 -443.075 -443.075] [0.0000], Avg: [-630.928 -630.928 -630.928] (1.000)
Step: 22849, Reward: [-430.504 -430.504 -430.504] [0.0000], Avg: [-630.489 -630.489 -630.489] (1.000)
Step: 22899, Reward: [-462.94 -462.94 -462.94] [0.0000], Avg: [-630.123 -630.123 -630.123] (1.000)
Step: 22949, Reward: [-379.645 -379.645 -379.645] [0.0000], Avg: [-629.578 -629.578 -629.578] (1.000)
Step: 22999, Reward: [-451.582 -451.582 -451.582] [0.0000], Avg: [-629.191 -629.191 -629.191] (1.000)
Step: 23049, Reward: [-412.974 -412.974 -412.974] [0.0000], Avg: [-628.722 -628.722 -628.722] (1.000)
Step: 23099, Reward: [-627.77 -627.77 -627.77] [0.0000], Avg: [-628.72 -628.72 -628.72] (1.000)
Step: 23149, Reward: [-499.09 -499.09 -499.09] [0.0000], Avg: [-628.44 -628.44 -628.44] (1.000)
Step: 23199, Reward: [-468.974 -468.974 -468.974] [0.0000], Avg: [-628.096 -628.096 -628.096] (1.000)
Step: 23249, Reward: [-384.148 -384.148 -384.148] [0.0000], Avg: [-627.571 -627.571 -627.571] (1.000)
Step: 23299, Reward: [-407.438 -407.438 -407.438] [0.0000], Avg: [-627.099 -627.099 -627.099] (1.000)
Step: 23349, Reward: [-490.721 -490.721 -490.721] [0.0000], Avg: [-626.807 -626.807 -626.807] (1.000)
Step: 23399, Reward: [-452.609 -452.609 -452.609] [0.0000], Avg: [-626.435 -626.435 -626.435] (1.000)
Step: 23449, Reward: [-435.809 -435.809 -435.809] [0.0000], Avg: [-626.028 -626.028 -626.028] (1.000)
Step: 23499, Reward: [-358.635 -358.635 -358.635] [0.0000], Avg: [-625.459 -625.459 -625.459] (1.000)
Step: 23549, Reward: [-380.113 -380.113 -380.113] [0.0000], Avg: [-624.938 -624.938 -624.938] (1.000)
Step: 23599, Reward: [-409.213 -409.213 -409.213] [0.0000], Avg: [-624.481 -624.481 -624.481] (1.000)
Step: 23649, Reward: [-488.54 -488.54 -488.54] [0.0000], Avg: [-624.194 -624.194 -624.194] (1.000)
Step: 23699, Reward: [-506.205 -506.205 -506.205] [0.0000], Avg: [-623.945 -623.945 -623.945] (1.000)
Step: 23749, Reward: [-491.117 -491.117 -491.117] [0.0000], Avg: [-623.665 -623.665 -623.665] (1.000)
Step: 23799, Reward: [-463.811 -463.811 -463.811] [0.0000], Avg: [-623.329 -623.329 -623.329] (1.000)
Step: 23849, Reward: [-414.451 -414.451 -414.451] [0.0000], Avg: [-622.892 -622.892 -622.892] (1.000)
Step: 23899, Reward: [-482.642 -482.642 -482.642] [0.0000], Avg: [-622.598 -622.598 -622.598] (1.000)
Step: 23949, Reward: [-498.595 -498.595 -498.595] [0.0000], Avg: [-622.339 -622.339 -622.339] (1.000)
Step: 23999, Reward: [-374.304 -374.304 -374.304] [0.0000], Avg: [-621.823 -621.823 -621.823] (1.000)
Step: 24049, Reward: [-379.256 -379.256 -379.256] [0.0000], Avg: [-621.318 -621.318 -621.318] (1.000)
Step: 24099, Reward: [-406.127 -406.127 -406.127] [0.0000], Avg: [-620.872 -620.872 -620.872] (1.000)
Step: 24149, Reward: [-631.901 -631.901 -631.901] [0.0000], Avg: [-620.895 -620.895 -620.895] (1.000)
Step: 24199, Reward: [-396.958 -396.958 -396.958] [0.0000], Avg: [-620.432 -620.432 -620.432] (1.000)
Step: 24249, Reward: [-348.608 -348.608 -348.608] [0.0000], Avg: [-619.872 -619.872 -619.872] (1.000)
Step: 24299, Reward: [-310.296 -310.296 -310.296] [0.0000], Avg: [-619.235 -619.235 -619.235] (1.000)
Step: 24349, Reward: [-384.849 -384.849 -384.849] [0.0000], Avg: [-618.753 -618.753 -618.753] (1.000)
Step: 24399, Reward: [-461.099 -461.099 -461.099] [0.0000], Avg: [-618.43 -618.43 -618.43] (1.000)
Step: 24449, Reward: [-363.478 -363.478 -363.478] [0.0000], Avg: [-617.909 -617.909 -617.909] (1.000)
Step: 24499, Reward: [-520.75 -520.75 -520.75] [0.0000], Avg: [-617.711 -617.711 -617.711] (1.000)
Step: 24549, Reward: [-393.668 -393.668 -393.668] [0.0000], Avg: [-617.254 -617.254 -617.254] (1.000)
Step: 24599, Reward: [-600.077 -600.077 -600.077] [0.0000], Avg: [-617.219 -617.219 -617.219] (1.000)
Step: 24649, Reward: [-636.772 -636.772 -636.772] [0.0000], Avg: [-617.259 -617.259 -617.259] (1.000)
Step: 24699, Reward: [-510.673 -510.673 -510.673] [0.0000], Avg: [-617.043 -617.043 -617.043] (1.000)
Step: 24749, Reward: [-486.773 -486.773 -486.773] [0.0000], Avg: [-616.78 -616.78 -616.78] (1.000)
Step: 24799, Reward: [-326.9 -326.9 -326.9] [0.0000], Avg: [-616.196 -616.196 -616.196] (1.000)
Step: 24849, Reward: [-455.7 -455.7 -455.7] [0.0000], Avg: [-615.873 -615.873 -615.873] (1.000)
Step: 24899, Reward: [-404.502 -404.502 -404.502] [0.0000], Avg: [-615.448 -615.448 -615.448] (1.000)
Step: 24949, Reward: [-452.196 -452.196 -452.196] [0.0000], Avg: [-615.121 -615.121 -615.121] (1.000)
Step: 24999, Reward: [-464.118 -464.118 -464.118] [0.0000], Avg: [-614.819 -614.819 -614.819] (1.000)
Step: 25049, Reward: [-407.015 -407.015 -407.015] [0.0000], Avg: [-614.404 -614.404 -614.404] (1.000)
Step: 25099, Reward: [-352.466 -352.466 -352.466] [0.0000], Avg: [-613.882 -613.882 -613.882] (1.000)
Step: 25149, Reward: [-453.919 -453.919 -453.919] [0.0000], Avg: [-613.564 -613.564 -613.564] (1.000)
Step: 25199, Reward: [-376.462 -376.462 -376.462] [0.0000], Avg: [-613.094 -613.094 -613.094] (1.000)
Step: 25249, Reward: [-475.851 -475.851 -475.851] [0.0000], Avg: [-612.822 -612.822 -612.822] (1.000)
Step: 25299, Reward: [-470.385 -470.385 -470.385] [0.0000], Avg: [-612.541 -612.541 -612.541] (1.000)
Step: 25349, Reward: [-398.297 -398.297 -398.297] [0.0000], Avg: [-612.118 -612.118 -612.118] (1.000)
Step: 25399, Reward: [-336.537 -336.537 -336.537] [0.0000], Avg: [-611.576 -611.576 -611.576] (1.000)
Step: 25449, Reward: [-461.689 -461.689 -461.689] [0.0000], Avg: [-611.281 -611.281 -611.281] (1.000)
Step: 25499, Reward: [-368.071 -368.071 -368.071] [0.0000], Avg: [-610.804 -610.804 -610.804] (1.000)
Step: 25549, Reward: [-324.538 -324.538 -324.538] [0.0000], Avg: [-610.244 -610.244 -610.244] (1.000)
Step: 25599, Reward: [-423.86 -423.86 -423.86] [0.0000], Avg: [-609.88 -609.88 -609.88] (1.000)
Step: 25649, Reward: [-442.678 -442.678 -442.678] [0.0000], Avg: [-609.554 -609.554 -609.554] (1.000)
Step: 25699, Reward: [-444.768 -444.768 -444.768] [0.0000], Avg: [-609.234 -609.234 -609.234] (1.000)
Step: 25749, Reward: [-364.101 -364.101 -364.101] [0.0000], Avg: [-608.758 -608.758 -608.758] (1.000)
Step: 25799, Reward: [-439.821 -439.821 -439.821] [0.0000], Avg: [-608.43 -608.43 -608.43] (1.000)
Step: 25849, Reward: [-415.143 -415.143 -415.143] [0.0000], Avg: [-608.056 -608.056 -608.056] (1.000)
Step: 25899, Reward: [-627.113 -627.113 -627.113] [0.0000], Avg: [-608.093 -608.093 -608.093] (1.000)
Step: 25949, Reward: [-451.783 -451.783 -451.783] [0.0000], Avg: [-607.792 -607.792 -607.792] (1.000)
Step: 25999, Reward: [-467.349 -467.349 -467.349] [0.0000], Avg: [-607.522 -607.522 -607.522] (1.000)
Step: 26049, Reward: [-377.802 -377.802 -377.802] [0.0000], Avg: [-607.081 -607.081 -607.081] (1.000)
Step: 26099, Reward: [-385.977 -385.977 -385.977] [0.0000], Avg: [-606.657 -606.657 -606.657] (1.000)
Step: 26149, Reward: [-473.779 -473.779 -473.779] [0.0000], Avg: [-606.403 -606.403 -606.403] (1.000)
Step: 26199, Reward: [-327.502 -327.502 -327.502] [0.0000], Avg: [-605.871 -605.871 -605.871] (1.000)
Step: 26249, Reward: [-416.716 -416.716 -416.716] [0.0000], Avg: [-605.511 -605.511 -605.511] (1.000)
Step: 26299, Reward: [-581.546 -581.546 -581.546] [0.0000], Avg: [-605.465 -605.465 -605.465] (1.000)
Step: 26349, Reward: [-402.964 -402.964 -402.964] [0.0000], Avg: [-605.081 -605.081 -605.081] (1.000)
Step: 26399, Reward: [-555.395 -555.395 -555.395] [0.0000], Avg: [-604.987 -604.987 -604.987] (1.000)
Step: 26449, Reward: [-467.285 -467.285 -467.285] [0.0000], Avg: [-604.727 -604.727 -604.727] (1.000)
Step: 26499, Reward: [-393.927 -393.927 -393.927] [0.0000], Avg: [-604.329 -604.329 -604.329] (1.000)
Step: 26549, Reward: [-438.331 -438.331 -438.331] [0.0000], Avg: [-604.016 -604.016 -604.016] (1.000)
Step: 26599, Reward: [-339.703 -339.703 -339.703] [0.0000], Avg: [-603.519 -603.519 -603.519] (1.000)
Step: 26649, Reward: [-426.5 -426.5 -426.5] [0.0000], Avg: [-603.187 -603.187 -603.187] (1.000)
Step: 26699, Reward: [-473.51 -473.51 -473.51] [0.0000], Avg: [-602.944 -602.944 -602.944] (1.000)
Step: 26749, Reward: [-535.139 -535.139 -535.139] [0.0000], Avg: [-602.818 -602.818 -602.818] (1.000)
Step: 26799, Reward: [-453.356 -453.356 -453.356] [0.0000], Avg: [-602.539 -602.539 -602.539] (1.000)
Step: 26849, Reward: [-445.494 -445.494 -445.494] [0.0000], Avg: [-602.246 -602.246 -602.246] (1.000)
Step: 26899, Reward: [-373.784 -373.784 -373.784] [0.0000], Avg: [-601.822 -601.822 -601.822] (1.000)
Step: 26949, Reward: [-648.833 -648.833 -648.833] [0.0000], Avg: [-601.909 -601.909 -601.909] (1.000)
Step: 26999, Reward: [-441.559 -441.559 -441.559] [0.0000], Avg: [-601.612 -601.612 -601.612] (1.000)
Step: 27049, Reward: [-266.66 -266.66 -266.66] [0.0000], Avg: [-600.993 -600.993 -600.993] (1.000)
Step: 27099, Reward: [-328.194 -328.194 -328.194] [0.0000], Avg: [-600.49 -600.49 -600.49] (1.000)
Step: 27149, Reward: [-505.605 -505.605 -505.605] [0.0000], Avg: [-600.315 -600.315 -600.315] (1.000)
Step: 27199, Reward: [-426.86 -426.86 -426.86] [0.0000], Avg: [-599.996 -599.996 -599.996] (1.000)
Step: 27249, Reward: [-394.469 -394.469 -394.469] [0.0000], Avg: [-599.619 -599.619 -599.619] (1.000)
Step: 27299, Reward: [-446.459 -446.459 -446.459] [0.0000], Avg: [-599.338 -599.338 -599.338] (1.000)
Step: 27349, Reward: [-496.416 -496.416 -496.416] [0.0000], Avg: [-599.15 -599.15 -599.15] (1.000)
Step: 27399, Reward: [-481.156 -481.156 -481.156] [0.0000], Avg: [-598.935 -598.935 -598.935] (1.000)
Step: 27449, Reward: [-297.416 -297.416 -297.416] [0.0000], Avg: [-598.386 -598.386 -598.386] (1.000)
Step: 27499, Reward: [-413.038 -413.038 -413.038] [0.0000], Avg: [-598.049 -598.049 -598.049] (1.000)
Step: 27549, Reward: [-350.307 -350.307 -350.307] [0.0000], Avg: [-597.599 -597.599 -597.599] (1.000)
Step: 27599, Reward: [-323.309 -323.309 -323.309] [0.0000], Avg: [-597.102 -597.102 -597.102] (1.000)
Step: 27649, Reward: [-388.988 -388.988 -388.988] [0.0000], Avg: [-596.726 -596.726 -596.726] (1.000)
Step: 27699, Reward: [-434.022 -434.022 -434.022] [0.0000], Avg: [-596.432 -596.432 -596.432] (1.000)
Step: 27749, Reward: [-413.738 -413.738 -413.738] [0.0000], Avg: [-596.103 -596.103 -596.103] (1.000)
Step: 27799, Reward: [-398.58 -398.58 -398.58] [0.0000], Avg: [-595.748 -595.748 -595.748] (1.000)
Step: 27849, Reward: [-526.398 -526.398 -526.398] [0.0000], Avg: [-595.623 -595.623 -595.623] (1.000)
Step: 27899, Reward: [-389.151 -389.151 -389.151] [0.0000], Avg: [-595.253 -595.253 -595.253] (1.000)
Step: 27949, Reward: [-369.85 -369.85 -369.85] [0.0000], Avg: [-594.85 -594.85 -594.85] (1.000)
Step: 27999, Reward: [-443.347 -443.347 -443.347] [0.0000], Avg: [-594.579 -594.579 -594.579] (1.000)
Step: 28049, Reward: [-520.822 -520.822 -520.822] [0.0000], Avg: [-594.448 -594.448 -594.448] (1.000)
Step: 28099, Reward: [-453.068 -453.068 -453.068] [0.0000], Avg: [-594.196 -594.196 -594.196] (1.000)
Step: 28149, Reward: [-321.161 -321.161 -321.161] [0.0000], Avg: [-593.711 -593.711 -593.711] (1.000)
Step: 28199, Reward: [-435.593 -435.593 -435.593] [0.0000], Avg: [-593.431 -593.431 -593.431] (1.000)
Step: 28249, Reward: [-473.434 -473.434 -473.434] [0.0000], Avg: [-593.219 -593.219 -593.219] (1.000)
Step: 28299, Reward: [-455.942 -455.942 -455.942] [0.0000], Avg: [-592.976 -592.976 -592.976] (1.000)
Step: 28349, Reward: [-416.882 -416.882 -416.882] [0.0000], Avg: [-592.666 -592.666 -592.666] (1.000)
Step: 28399, Reward: [-370.928 -370.928 -370.928] [0.0000], Avg: [-592.275 -592.275 -592.275] (1.000)
Step: 28449, Reward: [-370.86 -370.86 -370.86] [0.0000], Avg: [-591.886 -591.886 -591.886] (1.000)
Step: 28499, Reward: [-394.845 -394.845 -394.845] [0.0000], Avg: [-591.54 -591.54 -591.54] (1.000)
Step: 28549, Reward: [-408.078 -408.078 -408.078] [0.0000], Avg: [-591.219 -591.219 -591.219] (1.000)
Step: 28599, Reward: [-425.477 -425.477 -425.477] [0.0000], Avg: [-590.929 -590.929 -590.929] (1.000)
Step: 28649, Reward: [-620.181 -620.181 -620.181] [0.0000], Avg: [-590.98 -590.98 -590.98] (1.000)
Step: 28699, Reward: [-545.67 -545.67 -545.67] [0.0000], Avg: [-590.901 -590.901 -590.901] (1.000)
Step: 28749, Reward: [-466.322 -466.322 -466.322] [0.0000], Avg: [-590.685 -590.685 -590.685] (1.000)
Step: 28799, Reward: [-445.758 -445.758 -445.758] [0.0000], Avg: [-590.433 -590.433 -590.433] (1.000)
Step: 28849, Reward: [-408.123 -408.123 -408.123] [0.0000], Avg: [-590.117 -590.117 -590.117] (1.000)
Step: 28899, Reward: [-421.958 -421.958 -421.958] [0.0000], Avg: [-589.826 -589.826 -589.826] (1.000)
Step: 28949, Reward: [-676.379 -676.379 -676.379] [0.0000], Avg: [-589.976 -589.976 -589.976] (1.000)
Step: 28999, Reward: [-437.908 -437.908 -437.908] [0.0000], Avg: [-589.714 -589.714 -589.714] (1.000)
Step: 29049, Reward: [-440.621 -440.621 -440.621] [0.0000], Avg: [-589.457 -589.457 -589.457] (1.000)
Step: 29099, Reward: [-504.245 -504.245 -504.245] [0.0000], Avg: [-589.31 -589.31 -589.31] (1.000)
Step: 29149, Reward: [-473.891 -473.891 -473.891] [0.0000], Avg: [-589.113 -589.113 -589.113] (1.000)
Step: 29199, Reward: [-337.661 -337.661 -337.661] [0.0000], Avg: [-588.682 -588.682 -588.682] (1.000)
Step: 29249, Reward: [-400.631 -400.631 -400.631] [0.0000], Avg: [-588.36 -588.36 -588.36] (1.000)
Step: 29299, Reward: [-548.45 -548.45 -548.45] [0.0000], Avg: [-588.292 -588.292 -588.292] (1.000)
Step: 29349, Reward: [-389.987 -389.987 -389.987] [0.0000], Avg: [-587.955 -587.955 -587.955] (1.000)
Step: 29399, Reward: [-548.847 -548.847 -548.847] [0.0000], Avg: [-587.888 -587.888 -587.888] (1.000)
Step: 29449, Reward: [-507.828 -507.828 -507.828] [0.0000], Avg: [-587.752 -587.752 -587.752] (1.000)
Step: 29499, Reward: [-476.507 -476.507 -476.507] [0.0000], Avg: [-587.564 -587.564 -587.564] (1.000)
Step: 29549, Reward: [-381.516 -381.516 -381.516] [0.0000], Avg: [-587.215 -587.215 -587.215] (1.000)
Step: 29599, Reward: [-537.713 -537.713 -537.713] [0.0000], Avg: [-587.131 -587.131 -587.131] (1.000)
Step: 29649, Reward: [-465.852 -465.852 -465.852] [0.0000], Avg: [-586.927 -586.927 -586.927] (1.000)
Step: 29699, Reward: [-425.429 -425.429 -425.429] [0.0000], Avg: [-586.655 -586.655 -586.655] (1.000)
Step: 29749, Reward: [-439.133 -439.133 -439.133] [0.0000], Avg: [-586.407 -586.407 -586.407] (1.000)
Step: 29799, Reward: [-321.384 -321.384 -321.384] [0.0000], Avg: [-585.962 -585.962 -585.962] (1.000)
Step: 29849, Reward: [-539.459 -539.459 -539.459] [0.0000], Avg: [-585.884 -585.884 -585.884] (1.000)
Step: 29899, Reward: [-465.559 -465.559 -465.559] [0.0000], Avg: [-585.683 -585.683 -585.683] (1.000)
Step: 29949, Reward: [-385.421 -385.421 -385.421] [0.0000], Avg: [-585.349 -585.349 -585.349] (1.000)
Step: 29999, Reward: [-390.405 -390.405 -390.405] [0.0000], Avg: [-585.024 -585.024 -585.024] (1.000)
Step: 30049, Reward: [-388.083 -388.083 -388.083] [0.0000], Avg: [-584.696 -584.696 -584.696] (1.000)
Step: 30099, Reward: [-320.079 -320.079 -320.079] [0.0000], Avg: [-584.257 -584.257 -584.257] (1.000)
Step: 30149, Reward: [-451.629 -451.629 -451.629] [0.0000], Avg: [-584.037 -584.037 -584.037] (1.000)
Step: 30199, Reward: [-462.353 -462.353 -462.353] [0.0000], Avg: [-583.835 -583.835 -583.835] (1.000)
Step: 30249, Reward: [-426.999 -426.999 -426.999] [0.0000], Avg: [-583.576 -583.576 -583.576] (1.000)
Step: 30299, Reward: [-664.183 -664.183 -664.183] [0.0000], Avg: [-583.709 -583.709 -583.709] (1.000)
Step: 30349, Reward: [-273.801 -273.801 -273.801] [0.0000], Avg: [-583.199 -583.199 -583.199] (1.000)
Step: 30399, Reward: [-558.248 -558.248 -558.248] [0.0000], Avg: [-583.157 -583.157 -583.157] (1.000)
Step: 30449, Reward: [-605.804 -605.804 -605.804] [0.0000], Avg: [-583.195 -583.195 -583.195] (1.000)
Step: 30499, Reward: [-427.074 -427.074 -427.074] [0.0000], Avg: [-582.939 -582.939 -582.939] (1.000)
Step: 30549, Reward: [-426.428 -426.428 -426.428] [0.0000], Avg: [-582.683 -582.683 -582.683] (1.000)
Step: 30599, Reward: [-477.913 -477.913 -477.913] [0.0000], Avg: [-582.511 -582.511 -582.511] (1.000)
Step: 30649, Reward: [-747.287 -747.287 -747.287] [0.0000], Avg: [-582.78 -582.78 -582.78] (1.000)
Step: 30699, Reward: [-494.934 -494.934 -494.934] [0.0000], Avg: [-582.637 -582.637 -582.637] (1.000)
Step: 30749, Reward: [-365.389 -365.389 -365.389] [0.0000], Avg: [-582.284 -582.284 -582.284] (1.000)
Step: 30799, Reward: [-362.871 -362.871 -362.871] [0.0000], Avg: [-581.928 -581.928 -581.928] (1.000)
Step: 30849, Reward: [-614.52 -614.52 -614.52] [0.0000], Avg: [-581.98 -581.98 -581.98] (1.000)
Step: 30899, Reward: [-398.844 -398.844 -398.844] [0.0000], Avg: [-581.684 -581.684 -581.684] (1.000)
Step: 30949, Reward: [-427.128 -427.128 -427.128] [0.0000], Avg: [-581.434 -581.434 -581.434] (1.000)
Step: 30999, Reward: [-504.099 -504.099 -504.099] [0.0000], Avg: [-581.31 -581.31 -581.31] (1.000)
Step: 31049, Reward: [-461.684 -461.684 -461.684] [0.0000], Avg: [-581.117 -581.117 -581.117] (1.000)
Step: 31099, Reward: [-408.518 -408.518 -408.518] [0.0000], Avg: [-580.84 -580.84 -580.84] (1.000)
Step: 31149, Reward: [-465.21 -465.21 -465.21] [0.0000], Avg: [-580.654 -580.654 -580.654] (1.000)
Step: 31199, Reward: [-509.918 -509.918 -509.918] [0.0000], Avg: [-580.541 -580.541 -580.541] (1.000)
Step: 31249, Reward: [-398.947 -398.947 -398.947] [0.0000], Avg: [-580.25 -580.25 -580.25] (1.000)
Step: 31299, Reward: [-470.219 -470.219 -470.219] [0.0000], Avg: [-580.074 -580.074 -580.074] (1.000)
Step: 31349, Reward: [-361.08 -361.08 -361.08] [0.0000], Avg: [-579.725 -579.725 -579.725] (1.000)
Step: 31399, Reward: [-576.284 -576.284 -576.284] [0.0000], Avg: [-579.72 -579.72 -579.72] (1.000)
Step: 31449, Reward: [-456.117 -456.117 -456.117] [0.0000], Avg: [-579.523 -579.523 -579.523] (1.000)
Step: 31499, Reward: [-447.809 -447.809 -447.809] [0.0000], Avg: [-579.314 -579.314 -579.314] (1.000)
Step: 31549, Reward: [-397.925 -397.925 -397.925] [0.0000], Avg: [-579.027 -579.027 -579.027] (1.000)
Step: 31599, Reward: [-379.444 -379.444 -379.444] [0.0000], Avg: [-578.711 -578.711 -578.711] (1.000)
Step: 31649, Reward: [-473.325 -473.325 -473.325] [0.0000], Avg: [-578.544 -578.544 -578.544] (1.000)
Step: 31699, Reward: [-355.429 -355.429 -355.429] [0.0000], Avg: [-578.192 -578.192 -578.192] (1.000)
Step: 31749, Reward: [-481.949 -481.949 -481.949] [0.0000], Avg: [-578.041 -578.041 -578.041] (1.000)
Step: 31799, Reward: [-534.612 -534.612 -534.612] [0.0000], Avg: [-577.972 -577.972 -577.972] (1.000)
Step: 31849, Reward: [-503.459 -503.459 -503.459] [0.0000], Avg: [-577.856 -577.856 -577.856] (1.000)
Step: 31899, Reward: [-420.225 -420.225 -420.225] [0.0000], Avg: [-577.608 -577.608 -577.608] (1.000)
Step: 31949, Reward: [-369.409 -369.409 -369.409] [0.0000], Avg: [-577.283 -577.283 -577.283] (1.000)
Step: 31999, Reward: [-449.951 -449.951 -449.951] [0.0000], Avg: [-577.084 -577.084 -577.084] (1.000)
Step: 32049, Reward: [-412.865 -412.865 -412.865] [0.0000], Avg: [-576.827 -576.827 -576.827] (1.000)
Step: 32099, Reward: [-446.044 -446.044 -446.044] [0.0000], Avg: [-576.624 -576.624 -576.624] (1.000)
Step: 32149, Reward: [-341.586 -341.586 -341.586] [0.0000], Avg: [-576.258 -576.258 -576.258] (1.000)
Step: 32199, Reward: [-501.901 -501.901 -501.901] [0.0000], Avg: [-576.143 -576.143 -576.143] (1.000)
Step: 32249, Reward: [-410.627 -410.627 -410.627] [0.0000], Avg: [-575.886 -575.886 -575.886] (1.000)
Step: 32299, Reward: [-468.338 -468.338 -468.338] [0.0000], Avg: [-575.72 -575.72 -575.72] (1.000)
Step: 32349, Reward: [-349.74 -349.74 -349.74] [0.0000], Avg: [-575.37 -575.37 -575.37] (1.000)
Step: 32399, Reward: [-472.63 -472.63 -472.63] [0.0000], Avg: [-575.212 -575.212 -575.212] (1.000)
Step: 32449, Reward: [-538.4 -538.4 -538.4] [0.0000], Avg: [-575.155 -575.155 -575.155] (1.000)
Step: 32499, Reward: [-526.14 -526.14 -526.14] [0.0000], Avg: [-575.08 -575.08 -575.08] (1.000)
Step: 32549, Reward: [-303.633 -303.633 -303.633] [0.0000], Avg: [-574.663 -574.663 -574.663] (1.000)
Step: 32599, Reward: [-502.424 -502.424 -502.424] [0.0000], Avg: [-574.552 -574.552 -574.552] (1.000)
Step: 32649, Reward: [-486.771 -486.771 -486.771] [0.0000], Avg: [-574.418 -574.418 -574.418] (1.000)
Step: 32699, Reward: [-486.505 -486.505 -486.505] [0.0000], Avg: [-574.283 -574.283 -574.283] (1.000)
Step: 32749, Reward: [-484.569 -484.569 -484.569] [0.0000], Avg: [-574.146 -574.146 -574.146] (1.000)
Step: 32799, Reward: [-493.037 -493.037 -493.037] [0.0000], Avg: [-574.023 -574.023 -574.023] (1.000)
Step: 32849, Reward: [-400.305 -400.305 -400.305] [0.0000], Avg: [-573.758 -573.758 -573.758] (1.000)
Step: 32899, Reward: [-461.404 -461.404 -461.404] [0.0000], Avg: [-573.587 -573.587 -573.587] (1.000)
Step: 32949, Reward: [-626.189 -626.189 -626.189] [0.0000], Avg: [-573.667 -573.667 -573.667] (1.000)
Step: 32999, Reward: [-337.375 -337.375 -337.375] [0.0000], Avg: [-573.309 -573.309 -573.309] (1.000)
Step: 33049, Reward: [-470.536 -470.536 -470.536] [0.0000], Avg: [-573.154 -573.154 -573.154] (1.000)
Step: 33099, Reward: [-397.067 -397.067 -397.067] [0.0000], Avg: [-572.888 -572.888 -572.888] (1.000)
Step: 33149, Reward: [-451.093 -451.093 -451.093] [0.0000], Avg: [-572.704 -572.704 -572.704] (1.000)
Step: 33199, Reward: [-425.963 -425.963 -425.963] [0.0000], Avg: [-572.483 -572.483 -572.483] (1.000)
Step: 33249, Reward: [-420.307 -420.307 -420.307] [0.0000], Avg: [-572.254 -572.254 -572.254] (1.000)
Step: 33299, Reward: [-420.596 -420.596 -420.596] [0.0000], Avg: [-572.026 -572.026 -572.026] (1.000)
Step: 33349, Reward: [-466.811 -466.811 -466.811] [0.0000], Avg: [-571.869 -571.869 -571.869] (1.000)
Step: 33399, Reward: [-516.282 -516.282 -516.282] [0.0000], Avg: [-571.785 -571.785 -571.785] (1.000)
Step: 33449, Reward: [-407.601 -407.601 -407.601] [0.0000], Avg: [-571.54 -571.54 -571.54] (1.000)
Step: 33499, Reward: [-522.037 -522.037 -522.037] [0.0000], Avg: [-571.466 -571.466 -571.466] (1.000)
Step: 33549, Reward: [-362.435 -362.435 -362.435] [0.0000], Avg: [-571.155 -571.155 -571.155] (1.000)
Step: 33599, Reward: [-377.553 -377.553 -377.553] [0.0000], Avg: [-570.867 -570.867 -570.867] (1.000)
Step: 33649, Reward: [-293.266 -293.266 -293.266] [0.0000], Avg: [-570.454 -570.454 -570.454] (1.000)
Step: 33699, Reward: [-374.278 -374.278 -374.278] [0.0000], Avg: [-570.163 -570.163 -570.163] (1.000)
Step: 33749, Reward: [-442.109 -442.109 -442.109] [0.0000], Avg: [-569.973 -569.973 -569.973] (1.000)
Step: 33799, Reward: [-607.244 -607.244 -607.244] [0.0000], Avg: [-570.028 -570.028 -570.028] (1.000)
Step: 33849, Reward: [-532.124 -532.124 -532.124] [0.0000], Avg: [-569.972 -569.972 -569.972] (1.000)
Step: 33899, Reward: [-535.612 -535.612 -535.612] [0.0000], Avg: [-569.922 -569.922 -569.922] (1.000)
Step: 33949, Reward: [-581.214 -581.214 -581.214] [0.0000], Avg: [-569.938 -569.938 -569.938] (1.000)
Step: 33999, Reward: [-459.273 -459.273 -459.273] [0.0000], Avg: [-569.776 -569.776 -569.776] (1.000)
Step: 34049, Reward: [-548.464 -548.464 -548.464] [0.0000], Avg: [-569.744 -569.744 -569.744] (1.000)
Step: 34099, Reward: [-376.829 -376.829 -376.829] [0.0000], Avg: [-569.461 -569.461 -569.461] (1.000)
Step: 34149, Reward: [-387.877 -387.877 -387.877] [0.0000], Avg: [-569.196 -569.196 -569.196] (1.000)
Step: 34199, Reward: [-417.926 -417.926 -417.926] [0.0000], Avg: [-568.974 -568.974 -568.974] (1.000)
Step: 34249, Reward: [-554.483 -554.483 -554.483] [0.0000], Avg: [-568.953 -568.953 -568.953] (1.000)
Step: 34299, Reward: [-537.777 -537.777 -537.777] [0.0000], Avg: [-568.908 -568.908 -568.908] (1.000)
Step: 34349, Reward: [-564.916 -564.916 -564.916] [0.0000], Avg: [-568.902 -568.902 -568.902] (1.000)
Step: 34399, Reward: [-368.856 -368.856 -368.856] [0.0000], Avg: [-568.611 -568.611 -568.611] (1.000)
Step: 34449, Reward: [-409.047 -409.047 -409.047] [0.0000], Avg: [-568.38 -568.38 -568.38] (1.000)
Step: 34499, Reward: [-519.602 -519.602 -519.602] [0.0000], Avg: [-568.309 -568.309 -568.309] (1.000)
Step: 34549, Reward: [-537.594 -537.594 -537.594] [0.0000], Avg: [-568.265 -568.265 -568.265] (1.000)
Step: 34599, Reward: [-396.914 -396.914 -396.914] [0.0000], Avg: [-568.017 -568.017 -568.017] (1.000)
Step: 34649, Reward: [-921.855 -921.855 -921.855] [0.0000], Avg: [-568.528 -568.528 -568.528] (1.000)
Step: 34699, Reward: [-519.755 -519.755 -519.755] [0.0000], Avg: [-568.457 -568.457 -568.457] (1.000)
Step: 34749, Reward: [-404.341 -404.341 -404.341] [0.0000], Avg: [-568.221 -568.221 -568.221] (1.000)
Step: 34799, Reward: [-454.567 -454.567 -454.567] [0.0000], Avg: [-568.058 -568.058 -568.058] (1.000)
Step: 34849, Reward: [-363.875 -363.875 -363.875] [0.0000], Avg: [-567.765 -567.765 -567.765] (1.000)
Step: 34899, Reward: [-372.298 -372.298 -372.298] [0.0000], Avg: [-567.485 -567.485 -567.485] (1.000)
Step: 34949, Reward: [-431.488 -431.488 -431.488] [0.0000], Avg: [-567.29 -567.29 -567.29] (1.000)
Step: 34999, Reward: [-438.677 -438.677 -438.677] [0.0000], Avg: [-567.107 -567.107 -567.107] (1.000)
Step: 35049, Reward: [-468.323 -468.323 -468.323] [0.0000], Avg: [-566.966 -566.966 -566.966] (1.000)
Step: 35099, Reward: [-445.472 -445.472 -445.472] [0.0000], Avg: [-566.793 -566.793 -566.793] (1.000)
Step: 35149, Reward: [-343.855 -343.855 -343.855] [0.0000], Avg: [-566.475 -566.475 -566.475] (1.000)
Step: 35199, Reward: [-351.056 -351.056 -351.056] [0.0000], Avg: [-566.169 -566.169 -566.169] (1.000)
Step: 35249, Reward: [-409.669 -409.669 -409.669] [0.0000], Avg: [-565.947 -565.947 -565.947] (1.000)
Step: 35299, Reward: [-708.582 -708.582 -708.582] [0.0000], Avg: [-566.149 -566.149 -566.149] (1.000)
Step: 35349, Reward: [-483.674 -483.674 -483.674] [0.0000], Avg: [-566.033 -566.033 -566.033] (1.000)
Step: 35399, Reward: [-336.203 -336.203 -336.203] [0.0000], Avg: [-565.708 -565.708 -565.708] (1.000)
Step: 35449, Reward: [-549.005 -549.005 -549.005] [0.0000], Avg: [-565.685 -565.685 -565.685] (1.000)
Step: 35499, Reward: [-944.677 -944.677 -944.677] [0.0000], Avg: [-566.218 -566.218 -566.218] (1.000)
Step: 35549, Reward: [-465.421 -465.421 -465.421] [0.0000], Avg: [-566.077 -566.077 -566.077] (1.000)
Step: 35599, Reward: [-456.663 -456.663 -456.663] [0.0000], Avg: [-565.923 -565.923 -565.923] (1.000)
Step: 35649, Reward: [-489.696 -489.696 -489.696] [0.0000], Avg: [-565.816 -565.816 -565.816] (1.000)
Step: 35699, Reward: [-527.087 -527.087 -527.087] [0.0000], Avg: [-565.762 -565.762 -565.762] (1.000)
Step: 35749, Reward: [-519.438 -519.438 -519.438] [0.0000], Avg: [-565.697 -565.697 -565.697] (1.000)
Step: 35799, Reward: [-448.323 -448.323 -448.323] [0.0000], Avg: [-565.533 -565.533 -565.533] (1.000)
Step: 35849, Reward: [-470.036 -470.036 -470.036] [0.0000], Avg: [-565.4 -565.4 -565.4] (1.000)
Step: 35899, Reward: [-754.063 -754.063 -754.063] [0.0000], Avg: [-565.663 -565.663 -565.663] (1.000)
Step: 35949, Reward: [-478.324 -478.324 -478.324] [0.0000], Avg: [-565.541 -565.541 -565.541] (1.000)
Step: 35999, Reward: [-520.536 -520.536 -520.536] [0.0000], Avg: [-565.479 -565.479 -565.479] (1.000)
Step: 36049, Reward: [-374.952 -374.952 -374.952] [0.0000], Avg: [-565.214 -565.214 -565.214] (1.000)
Step: 36099, Reward: [-651.487 -651.487 -651.487] [0.0000], Avg: [-565.334 -565.334 -565.334] (1.000)
Step: 36149, Reward: [-563.212 -563.212 -563.212] [0.0000], Avg: [-565.331 -565.331 -565.331] (1.000)
Step: 36199, Reward: [-515.449 -515.449 -515.449] [0.0000], Avg: [-565.262 -565.262 -565.262] (1.000)
Step: 36249, Reward: [-462.142 -462.142 -462.142] [0.0000], Avg: [-565.12 -565.12 -565.12] (1.000)
Step: 36299, Reward: [-304.622 -304.622 -304.622] [0.0000], Avg: [-564.761 -564.761 -564.761] (1.000)
Step: 36349, Reward: [-406.564 -406.564 -406.564] [0.0000], Avg: [-564.543 -564.543 -564.543] (1.000)
Step: 36399, Reward: [-354.339 -354.339 -354.339] [0.0000], Avg: [-564.255 -564.255 -564.255] (1.000)
Step: 36449, Reward: [-457.673 -457.673 -457.673] [0.0000], Avg: [-564.109 -564.109 -564.109] (1.000)
Step: 36499, Reward: [-345.365 -345.365 -345.365] [0.0000], Avg: [-563.809 -563.809 -563.809] (1.000)
Step: 36549, Reward: [-458.251 -458.251 -458.251] [0.0000], Avg: [-563.664 -563.664 -563.664] (1.000)
Step: 36599, Reward: [-437.357 -437.357 -437.357] [0.0000], Avg: [-563.492 -563.492 -563.492] (1.000)
Step: 36649, Reward: [-378.659 -378.659 -378.659] [0.0000], Avg: [-563.24 -563.24 -563.24] (1.000)
Step: 36699, Reward: [-368.505 -368.505 -368.505] [0.0000], Avg: [-562.974 -562.974 -562.974] (1.000)
Step: 36749, Reward: [-331.191 -331.191 -331.191] [0.0000], Avg: [-562.659 -562.659 -562.659] (1.000)
Step: 36799, Reward: [-459.938 -459.938 -459.938] [0.0000], Avg: [-562.52 -562.52 -562.52] (1.000)
Step: 36849, Reward: [-438.039 -438.039 -438.039] [0.0000], Avg: [-562.351 -562.351 -562.351] (1.000)
Step: 36899, Reward: [-370.788 -370.788 -370.788] [0.0000], Avg: [-562.091 -562.091 -562.091] (1.000)
Step: 36949, Reward: [-453.962 -453.962 -453.962] [0.0000], Avg: [-561.945 -561.945 -561.945] (1.000)
Step: 36999, Reward: [-442.309 -442.309 -442.309] [0.0000], Avg: [-561.783 -561.783 -561.783] (1.000)
Step: 37049, Reward: [-378.664 -378.664 -378.664] [0.0000], Avg: [-561.536 -561.536 -561.536] (1.000)
Step: 37099, Reward: [-415.384 -415.384 -415.384] [0.0000], Avg: [-561.339 -561.339 -561.339] (1.000)
Step: 37149, Reward: [-455.437 -455.437 -455.437] [0.0000], Avg: [-561.196 -561.196 -561.196] (1.000)
Step: 37199, Reward: [-337.212 -337.212 -337.212] [0.0000], Avg: [-560.895 -560.895 -560.895] (1.000)
Step: 37249, Reward: [-391.664 -391.664 -391.664] [0.0000], Avg: [-560.668 -560.668 -560.668] (1.000)
Step: 37299, Reward: [-434.504 -434.504 -434.504] [0.0000], Avg: [-560.499 -560.499 -560.499] (1.000)
Step: 37349, Reward: [-1002.84 -1002.84 -1002.84] [0.0000], Avg: [-561.091 -561.091 -561.091] (1.000)
Step: 37399, Reward: [-553.613 -553.613 -553.613] [0.0000], Avg: [-561.081 -561.081 -561.081] (1.000)
Step: 37449, Reward: [-524.873 -524.873 -524.873] [0.0000], Avg: [-561.033 -561.033 -561.033] (1.000)
Step: 37499, Reward: [-307.692 -307.692 -307.692] [0.0000], Avg: [-560.695 -560.695 -560.695] (1.000)
Step: 37549, Reward: [-625.346 -625.346 -625.346] [0.0000], Avg: [-560.781 -560.781 -560.781] (1.000)
Step: 37599, Reward: [-615.442 -615.442 -615.442] [0.0000], Avg: [-560.854 -560.854 -560.854] (1.000)
Step: 37649, Reward: [-345.137 -345.137 -345.137] [0.0000], Avg: [-560.567 -560.567 -560.567] (1.000)
Step: 37699, Reward: [-361.476 -361.476 -361.476] [0.0000], Avg: [-560.303 -560.303 -560.303] (1.000)
Step: 37749, Reward: [-542.914 -542.914 -542.914] [0.0000], Avg: [-560.28 -560.28 -560.28] (1.000)
Step: 37799, Reward: [-550.325 -550.325 -550.325] [0.0000], Avg: [-560.267 -560.267 -560.267] (1.000)
Step: 37849, Reward: [-414.248 -414.248 -414.248] [0.0000], Avg: [-560.074 -560.074 -560.074] (1.000)
Step: 37899, Reward: [-421.767 -421.767 -421.767] [0.0000], Avg: [-559.892 -559.892 -559.892] (1.000)
Step: 37949, Reward: [-414.944 -414.944 -414.944] [0.0000], Avg: [-559.701 -559.701 -559.701] (1.000)
Step: 37999, Reward: [-396.027 -396.027 -396.027] [0.0000], Avg: [-559.486 -559.486 -559.486] (1.000)
Step: 38049, Reward: [-594.687 -594.687 -594.687] [0.0000], Avg: [-559.532 -559.532 -559.532] (1.000)
Step: 38099, Reward: [-550.362 -550.362 -550.362] [0.0000], Avg: [-559.52 -559.52 -559.52] (1.000)
Step: 38149, Reward: [-822.857 -822.857 -822.857] [0.0000], Avg: [-559.865 -559.865 -559.865] (1.000)
Step: 38199, Reward: [-408.385 -408.385 -408.385] [0.0000], Avg: [-559.667 -559.667 -559.667] (1.000)
Step: 38249, Reward: [-595.697 -595.697 -595.697] [0.0000], Avg: [-559.714 -559.714 -559.714] (1.000)
Step: 38299, Reward: [-356.818 -356.818 -356.818] [0.0000], Avg: [-559.449 -559.449 -559.449] (1.000)
Step: 38349, Reward: [-478.056 -478.056 -478.056] [0.0000], Avg: [-559.343 -559.343 -559.343] (1.000)
Step: 38399, Reward: [-501.65 -501.65 -501.65] [0.0000], Avg: [-559.268 -559.268 -559.268] (1.000)
Step: 38449, Reward: [-475.566 -475.566 -475.566] [0.0000], Avg: [-559.159 -559.159 -559.159] (1.000)
Step: 38499, Reward: [-762.472 -762.472 -762.472] [0.0000], Avg: [-559.423 -559.423 -559.423] (1.000)
Step: 38549, Reward: [-390.869 -390.869 -390.869] [0.0000], Avg: [-559.204 -559.204 -559.204] (1.000)
Step: 38599, Reward: [-450.137 -450.137 -450.137] [0.0000], Avg: [-559.063 -559.063 -559.063] (1.000)
Step: 38649, Reward: [-638.101 -638.101 -638.101] [0.0000], Avg: [-559.165 -559.165 -559.165] (1.000)
Step: 38699, Reward: [-472.631 -472.631 -472.631] [0.0000], Avg: [-559.053 -559.053 -559.053] (1.000)
Step: 38749, Reward: [-502.429 -502.429 -502.429] [0.0000], Avg: [-558.98 -558.98 -558.98] (1.000)
Step: 38799, Reward: [-349.948 -349.948 -349.948] [0.0000], Avg: [-558.711 -558.711 -558.711] (1.000)
Step: 38849, Reward: [-419.176 -419.176 -419.176] [0.0000], Avg: [-558.531 -558.531 -558.531] (1.000)
Step: 38899, Reward: [-417.826 -417.826 -417.826] [0.0000], Avg: [-558.35 -558.35 -558.35] (1.000)
Step: 38949, Reward: [-551.016 -551.016 -551.016] [0.0000], Avg: [-558.341 -558.341 -558.341] (1.000)
Step: 38999, Reward: [-331.886 -331.886 -331.886] [0.0000], Avg: [-558.051 -558.051 -558.051] (1.000)
Step: 39049, Reward: [-509.069 -509.069 -509.069] [0.0000], Avg: [-557.988 -557.988 -557.988] (1.000)
Step: 39099, Reward: [-342.774 -342.774 -342.774] [0.0000], Avg: [-557.713 -557.713 -557.713] (1.000)
Step: 39149, Reward: [-433.727 -433.727 -433.727] [0.0000], Avg: [-557.554 -557.554 -557.554] (1.000)
Step: 39199, Reward: [-377.48 -377.48 -377.48] [0.0000], Avg: [-557.325 -557.325 -557.325] (1.000)
Step: 39249, Reward: [-549.066 -549.066 -549.066] [0.0000], Avg: [-557.314 -557.314 -557.314] (1.000)
Step: 39299, Reward: [-376.478 -376.478 -376.478] [0.0000], Avg: [-557.084 -557.084 -557.084] (1.000)
Step: 39349, Reward: [-387.691 -387.691 -387.691] [0.0000], Avg: [-556.869 -556.869 -556.869] (1.000)
Step: 39399, Reward: [-495.399 -495.399 -495.399] [0.0000], Avg: [-556.791 -556.791 -556.791] (1.000)
Step: 39449, Reward: [-393.968 -393.968 -393.968] [0.0000], Avg: [-556.585 -556.585 -556.585] (1.000)
Step: 39499, Reward: [-479.361 -479.361 -479.361] [0.0000], Avg: [-556.487 -556.487 -556.487] (1.000)
Step: 39549, Reward: [-545.388 -545.388 -545.388] [0.0000], Avg: [-556.473 -556.473 -556.473] (1.000)
Step: 39599, Reward: [-403.495 -403.495 -403.495] [0.0000], Avg: [-556.28 -556.28 -556.28] (1.000)
Step: 39649, Reward: [-382.741 -382.741 -382.741] [0.0000], Avg: [-556.061 -556.061 -556.061] (1.000)
Step: 39699, Reward: [-358.241 -358.241 -358.241] [0.0000], Avg: [-555.812 -555.812 -555.812] (1.000)
Step: 39749, Reward: [-390.344 -390.344 -390.344] [0.0000], Avg: [-555.603 -555.603 -555.603] (1.000)
Step: 39799, Reward: [-386.856 -386.856 -386.856] [0.0000], Avg: [-555.392 -555.392 -555.392] (1.000)
Step: 39849, Reward: [-434.004 -434.004 -434.004] [0.0000], Avg: [-555.239 -555.239 -555.239] (1.000)
Step: 39899, Reward: [-454.579 -454.579 -454.579] [0.0000], Avg: [-555.113 -555.113 -555.113] (1.000)
Step: 39949, Reward: [-395.174 -395.174 -395.174] [0.0000], Avg: [-554.913 -554.913 -554.913] (1.000)
Step: 39999, Reward: [-667.394 -667.394 -667.394] [0.0000], Avg: [-555.053 -555.053 -555.053] (1.000)
Step: 40049, Reward: [-531.667 -531.667 -531.667] [0.0000], Avg: [-555.024 -555.024 -555.024] (1.000)
Step: 40099, Reward: [-412.256 -412.256 -412.256] [0.0000], Avg: [-554.846 -554.846 -554.846] (1.000)
Step: 40149, Reward: [-360.798 -360.798 -360.798] [0.0000], Avg: [-554.605 -554.605 -554.605] (1.000)
Step: 40199, Reward: [-471.981 -471.981 -471.981] [0.0000], Avg: [-554.502 -554.502 -554.502] (1.000)
Step: 40249, Reward: [-432.504 -432.504 -432.504] [0.0000], Avg: [-554.35 -554.35 -554.35] (1.000)
Step: 40299, Reward: [-340.134 -340.134 -340.134] [0.0000], Avg: [-554.085 -554.085 -554.085] (1.000)
Step: 40349, Reward: [-447.69 -447.69 -447.69] [0.0000], Avg: [-553.953 -553.953 -553.953] (1.000)
Step: 40399, Reward: [-495.242 -495.242 -495.242] [0.0000], Avg: [-553.88 -553.88 -553.88] (1.000)
Step: 40449, Reward: [-540.587 -540.587 -540.587] [0.0000], Avg: [-553.864 -553.864 -553.864] (1.000)
Step: 40499, Reward: [-523.542 -523.542 -523.542] [0.0000], Avg: [-553.826 -553.826 -553.826] (1.000)
Step: 40549, Reward: [-381.887 -381.887 -381.887] [0.0000], Avg: [-553.614 -553.614 -553.614] (1.000)
Step: 40599, Reward: [-330.882 -330.882 -330.882] [0.0000], Avg: [-553.34 -553.34 -553.34] (1.000)
Step: 40649, Reward: [-352.6 -352.6 -352.6] [0.0000], Avg: [-553.093 -553.093 -553.093] (1.000)
Step: 40699, Reward: [-627.495 -627.495 -627.495] [0.0000], Avg: [-553.184 -553.184 -553.184] (1.000)
Step: 40749, Reward: [-332.373 -332.373 -332.373] [0.0000], Avg: [-552.913 -552.913 -552.913] (1.000)
Step: 40799, Reward: [-433.995 -433.995 -433.995] [0.0000], Avg: [-552.768 -552.768 -552.768] (1.000)
Step: 40849, Reward: [-364.115 -364.115 -364.115] [0.0000], Avg: [-552.537 -552.537 -552.537] (1.000)
Step: 40899, Reward: [-474.275 -474.275 -474.275] [0.0000], Avg: [-552.441 -552.441 -552.441] (1.000)
Step: 40949, Reward: [-445.465 -445.465 -445.465] [0.0000], Avg: [-552.31 -552.31 -552.31] (1.000)
Step: 40999, Reward: [-460.835 -460.835 -460.835] [0.0000], Avg: [-552.199 -552.199 -552.199] (1.000)
Step: 41049, Reward: [-842.005 -842.005 -842.005] [0.0000], Avg: [-552.552 -552.552 -552.552] (1.000)
Step: 41099, Reward: [-375.434 -375.434 -375.434] [0.0000], Avg: [-552.336 -552.336 -552.336] (1.000)
Step: 41149, Reward: [-457.667 -457.667 -457.667] [0.0000], Avg: [-552.221 -552.221 -552.221] (1.000)
Step: 41199, Reward: [-442.271 -442.271 -442.271] [0.0000], Avg: [-552.088 -552.088 -552.088] (1.000)
Step: 41249, Reward: [-366.472 -366.472 -366.472] [0.0000], Avg: [-551.863 -551.863 -551.863] (1.000)
Step: 41299, Reward: [-365.49 -365.49 -365.49] [0.0000], Avg: [-551.637 -551.637 -551.637] (1.000)
Step: 41349, Reward: [-635.07 -635.07 -635.07] [0.0000], Avg: [-551.738 -551.738 -551.738] (1.000)
Step: 41399, Reward: [-377.759 -377.759 -377.759] [0.0000], Avg: [-551.528 -551.528 -551.528] (1.000)
Step: 41449, Reward: [-319.853 -319.853 -319.853] [0.0000], Avg: [-551.249 -551.249 -551.249] (1.000)
Step: 41499, Reward: [-389.23 -389.23 -389.23] [0.0000], Avg: [-551.053 -551.053 -551.053] (1.000)
Step: 41549, Reward: [-452.959 -452.959 -452.959] [0.0000], Avg: [-550.935 -550.935 -550.935] (1.000)
Step: 41599, Reward: [-552.901 -552.901 -552.901] [0.0000], Avg: [-550.938 -550.938 -550.938] (1.000)
Step: 41649, Reward: [-422.898 -422.898 -422.898] [0.0000], Avg: [-550.784 -550.784 -550.784] (1.000)
Step: 41699, Reward: [-506.445 -506.445 -506.445] [0.0000], Avg: [-550.731 -550.731 -550.731] (1.000)
Step: 41749, Reward: [-409.592 -409.592 -409.592] [0.0000], Avg: [-550.562 -550.562 -550.562] (1.000)
Step: 41799, Reward: [-420.572 -420.572 -420.572] [0.0000], Avg: [-550.406 -550.406 -550.406] (1.000)
Step: 41849, Reward: [-360.092 -360.092 -360.092] [0.0000], Avg: [-550.179 -550.179 -550.179] (1.000)
Step: 41899, Reward: [-357.483 -357.483 -357.483] [0.0000], Avg: [-549.949 -549.949 -549.949] (1.000)
Step: 41949, Reward: [-488.533 -488.533 -488.533] [0.0000], Avg: [-549.876 -549.876 -549.876] (1.000)
Step: 41999, Reward: [-431.624 -431.624 -431.624] [0.0000], Avg: [-549.735 -549.735 -549.735] (1.000)
Step: 42049, Reward: [-442.831 -442.831 -442.831] [0.0000], Avg: [-549.608 -549.608 -549.608] (1.000)
Step: 42099, Reward: [-356.465 -356.465 -356.465] [0.0000], Avg: [-549.379 -549.379 -549.379] (1.000)
Step: 42149, Reward: [-545.94 -545.94 -545.94] [0.0000], Avg: [-549.374 -549.374 -549.374] (1.000)
Step: 42199, Reward: [-364.381 -364.381 -364.381] [0.0000], Avg: [-549.155 -549.155 -549.155] (1.000)
Step: 42249, Reward: [-501.122 -501.122 -501.122] [0.0000], Avg: [-549.098 -549.098 -549.098] (1.000)
Step: 42299, Reward: [-452.749 -452.749 -452.749] [0.0000], Avg: [-548.985 -548.985 -548.985] (1.000)
Step: 42349, Reward: [-450.83 -450.83 -450.83] [0.0000], Avg: [-548.869 -548.869 -548.869] (1.000)
Step: 42399, Reward: [-363.601 -363.601 -363.601] [0.0000], Avg: [-548.65 -548.65 -548.65] (1.000)
Step: 42449, Reward: [-303.965 -303.965 -303.965] [0.0000], Avg: [-548.362 -548.362 -548.362] (1.000)
Step: 42499, Reward: [-424.925 -424.925 -424.925] [0.0000], Avg: [-548.217 -548.217 -548.217] (1.000)
Step: 42549, Reward: [-371.107 -371.107 -371.107] [0.0000], Avg: [-548.009 -548.009 -548.009] (1.000)
Step: 42599, Reward: [-582.108 -582.108 -582.108] [0.0000], Avg: [-548.049 -548.049 -548.049] (1.000)
Step: 42649, Reward: [-508.592 -508.592 -508.592] [0.0000], Avg: [-548.002 -548.002 -548.002] (1.000)
Step: 42699, Reward: [-499.82 -499.82 -499.82] [0.0000], Avg: [-547.946 -547.946 -547.946] (1.000)
Step: 42749, Reward: [-434.754 -434.754 -434.754] [0.0000], Avg: [-547.814 -547.814 -547.814] (1.000)
Step: 42799, Reward: [-522.655 -522.655 -522.655] [0.0000], Avg: [-547.784 -547.784 -547.784] (1.000)
Step: 42849, Reward: [-524.021 -524.021 -524.021] [0.0000], Avg: [-547.757 -547.757 -547.757] (1.000)
Step: 42899, Reward: [-400.234 -400.234 -400.234] [0.0000], Avg: [-547.585 -547.585 -547.585] (1.000)
Step: 42949, Reward: [-1263.901 -1263.901 -1263.901] [0.0000], Avg: [-548.418 -548.418 -548.418] (1.000)
Step: 42999, Reward: [-378.317 -378.317 -378.317] [0.0000], Avg: [-548.221 -548.221 -548.221] (1.000)
Step: 43049, Reward: [-389.513 -389.513 -389.513] [0.0000], Avg: [-548.036 -548.036 -548.036] (1.000)
Step: 43099, Reward: [-496.504 -496.504 -496.504] [0.0000], Avg: [-547.977 -547.977 -547.977] (1.000)
Step: 43149, Reward: [-481.612 -481.612 -481.612] [0.0000], Avg: [-547.9 -547.9 -547.9] (1.000)
Step: 43199, Reward: [-372.277 -372.277 -372.277] [0.0000], Avg: [-547.696 -547.696 -547.696] (1.000)
Step: 43249, Reward: [-413.739 -413.739 -413.739] [0.0000], Avg: [-547.542 -547.542 -547.542] (1.000)
Step: 43299, Reward: [-937.424 -937.424 -937.424] [0.0000], Avg: [-547.992 -547.992 -547.992] (1.000)
Step: 43349, Reward: [-415.269 -415.269 -415.269] [0.0000], Avg: [-547.839 -547.839 -547.839] (1.000)
Step: 43399, Reward: [-422.204 -422.204 -422.204] [0.0000], Avg: [-547.694 -547.694 -547.694] (1.000)
Step: 43449, Reward: [-689.917 -689.917 -689.917] [0.0000], Avg: [-547.858 -547.858 -547.858] (1.000)
Step: 43499, Reward: [-474.262 -474.262 -474.262] [0.0000], Avg: [-547.773 -547.773 -547.773] (1.000)
Step: 43549, Reward: [-519.529 -519.529 -519.529] [0.0000], Avg: [-547.741 -547.741 -547.741] (1.000)
Step: 43599, Reward: [-379.793 -379.793 -379.793] [0.0000], Avg: [-547.548 -547.548 -547.548] (1.000)
Step: 43649, Reward: [-407.694 -407.694 -407.694] [0.0000], Avg: [-547.388 -547.388 -547.388] (1.000)
Step: 43699, Reward: [-395.564 -395.564 -395.564] [0.0000], Avg: [-547.214 -547.214 -547.214] (1.000)
Step: 43749, Reward: [-505.689 -505.689 -505.689] [0.0000], Avg: [-547.167 -547.167 -547.167] (1.000)
Step: 43799, Reward: [-398.106 -398.106 -398.106] [0.0000], Avg: [-546.996 -546.996 -546.996] (1.000)
Step: 43849, Reward: [-454.627 -454.627 -454.627] [0.0000], Avg: [-546.891 -546.891 -546.891] (1.000)
Step: 43899, Reward: [-461.644 -461.644 -461.644] [0.0000], Avg: [-546.794 -546.794 -546.794] (1.000)
Step: 43949, Reward: [-506.383 -506.383 -506.383] [0.0000], Avg: [-546.748 -546.748 -546.748] (1.000)
Step: 43999, Reward: [-668.823 -668.823 -668.823] [0.0000], Avg: [-546.887 -546.887 -546.887] (1.000)
Step: 44049, Reward: [-436.176 -436.176 -436.176] [0.0000], Avg: [-546.761 -546.761 -546.761] (1.000)
Step: 44099, Reward: [-389.32 -389.32 -389.32] [0.0000], Avg: [-546.583 -546.583 -546.583] (1.000)
Step: 44149, Reward: [-377.599 -377.599 -377.599] [0.0000], Avg: [-546.391 -546.391 -546.391] (1.000)
Step: 44199, Reward: [-351.811 -351.811 -351.811] [0.0000], Avg: [-546.171 -546.171 -546.171] (1.000)
Step: 44249, Reward: [-382.421 -382.421 -382.421] [0.0000], Avg: [-545.986 -545.986 -545.986] (1.000)
Step: 44299, Reward: [-420.886 -420.886 -420.886] [0.0000], Avg: [-545.845 -545.845 -545.845] (1.000)
Step: 44349, Reward: [-422.344 -422.344 -422.344] [0.0000], Avg: [-545.706 -545.706 -545.706] (1.000)
Step: 44399, Reward: [-369.44 -369.44 -369.44] [0.0000], Avg: [-545.507 -545.507 -545.507] (1.000)
Step: 44449, Reward: [-474.255 -474.255 -474.255] [0.0000], Avg: [-545.427 -545.427 -545.427] (1.000)
Step: 44499, Reward: [-560.386 -560.386 -560.386] [0.0000], Avg: [-545.444 -545.444 -545.444] (1.000)
Step: 44549, Reward: [-348.941 -348.941 -348.941] [0.0000], Avg: [-545.223 -545.223 -545.223] (1.000)
Step: 44599, Reward: [-349.686 -349.686 -349.686] [0.0000], Avg: [-545.004 -545.004 -545.004] (1.000)
Step: 44649, Reward: [-377.254 -377.254 -377.254] [0.0000], Avg: [-544.816 -544.816 -544.816] (1.000)
Step: 44699, Reward: [-488.847 -488.847 -488.847] [0.0000], Avg: [-544.754 -544.754 -544.754] (1.000)
Step: 44749, Reward: [-281.972 -281.972 -281.972] [0.0000], Avg: [-544.46 -544.46 -544.46] (1.000)
Step: 44799, Reward: [-383.579 -383.579 -383.579] [0.0000], Avg: [-544.28 -544.28 -544.28] (1.000)
Step: 44849, Reward: [-383.989 -383.989 -383.989] [0.0000], Avg: [-544.102 -544.102 -544.102] (1.000)
Step: 44899, Reward: [-510.794 -510.794 -510.794] [0.0000], Avg: [-544.065 -544.065 -544.065] (1.000)
Step: 44949, Reward: [-505.182 -505.182 -505.182] [0.0000], Avg: [-544.021 -544.021 -544.021] (1.000)
Step: 44999, Reward: [-534.632 -534.632 -534.632] [0.0000], Avg: [-544.011 -544.011 -544.011] (1.000)
Step: 45049, Reward: [-553.987 -553.987 -553.987] [0.0000], Avg: [-544.022 -544.022 -544.022] (1.000)
Step: 45099, Reward: [-414.802 -414.802 -414.802] [0.0000], Avg: [-543.879 -543.879 -543.879] (1.000)
Step: 45149, Reward: [-412.811 -412.811 -412.811] [0.0000], Avg: [-543.734 -543.734 -543.734] (1.000)
Step: 45199, Reward: [-481.65 -481.65 -481.65] [0.0000], Avg: [-543.665 -543.665 -543.665] (1.000)
Step: 45249, Reward: [-493.044 -493.044 -493.044] [0.0000], Avg: [-543.609 -543.609 -543.609] (1.000)
Step: 45299, Reward: [-361.756 -361.756 -361.756] [0.0000], Avg: [-543.408 -543.408 -543.408] (1.000)
Step: 45349, Reward: [-509.257 -509.257 -509.257] [0.0000], Avg: [-543.371 -543.371 -543.371] (1.000)
Step: 45399, Reward: [-362.081 -362.081 -362.081] [0.0000], Avg: [-543.171 -543.171 -543.171] (1.000)
Step: 45449, Reward: [-361.588 -361.588 -361.588] [0.0000], Avg: [-542.971 -542.971 -542.971] (1.000)
Step: 45499, Reward: [-503.273 -503.273 -503.273] [0.0000], Avg: [-542.928 -542.928 -542.928] (1.000)
Step: 45549, Reward: [-650.78 -650.78 -650.78] [0.0000], Avg: [-543.046 -543.046 -543.046] (1.000)
Step: 45599, Reward: [-391.797 -391.797 -391.797] [0.0000], Avg: [-542.88 -542.88 -542.88] (1.000)
Step: 45649, Reward: [-494.741 -494.741 -494.741] [0.0000], Avg: [-542.827 -542.827 -542.827] (1.000)
Step: 45699, Reward: [-419.76 -419.76 -419.76] [0.0000], Avg: [-542.693 -542.693 -542.693] (1.000)
Step: 45749, Reward: [-369.882 -369.882 -369.882] [0.0000], Avg: [-542.504 -542.504 -542.504] (1.000)
Step: 45799, Reward: [-332.802 -332.802 -332.802] [0.0000], Avg: [-542.275 -542.275 -542.275] (1.000)
Step: 45849, Reward: [-618.116 -618.116 -618.116] [0.0000], Avg: [-542.358 -542.358 -542.358] (1.000)
Step: 45899, Reward: [-366.575 -366.575 -366.575] [0.0000], Avg: [-542.166 -542.166 -542.166] (1.000)
Step: 45949, Reward: [-332.688 -332.688 -332.688] [0.0000], Avg: [-541.938 -541.938 -541.938] (1.000)
Step: 45999, Reward: [-549.568 -549.568 -549.568] [0.0000], Avg: [-541.947 -541.947 -541.947] (1.000)
Step: 46049, Reward: [-427.99 -427.99 -427.99] [0.0000], Avg: [-541.823 -541.823 -541.823] (1.000)
Step: 46099, Reward: [-529.239 -529.239 -529.239] [0.0000], Avg: [-541.809 -541.809 -541.809] (1.000)
Step: 46149, Reward: [-456.309 -456.309 -456.309] [0.0000], Avg: [-541.717 -541.717 -541.717] (1.000)
Step: 46199, Reward: [-447.782 -447.782 -447.782] [0.0000], Avg: [-541.615 -541.615 -541.615] (1.000)
Step: 46249, Reward: [-344.819 -344.819 -344.819] [0.0000], Avg: [-541.402 -541.402 -541.402] (1.000)
Step: 46299, Reward: [-366.784 -366.784 -366.784] [0.0000], Avg: [-541.214 -541.214 -541.214] (1.000)
Step: 46349, Reward: [-353.312 -353.312 -353.312] [0.0000], Avg: [-541.011 -541.011 -541.011] (1.000)
Step: 46399, Reward: [-417.437 -417.437 -417.437] [0.0000], Avg: [-540.878 -540.878 -540.878] (1.000)
Step: 46449, Reward: [-416.502 -416.502 -416.502] [0.0000], Avg: [-540.744 -540.744 -540.744] (1.000)
Step: 46499, Reward: [-476.507 -476.507 -476.507] [0.0000], Avg: [-540.675 -540.675 -540.675] (1.000)
Step: 46549, Reward: [-438.595 -438.595 -438.595] [0.0000], Avg: [-540.565 -540.565 -540.565] (1.000)
Step: 46599, Reward: [-322.862 -322.862 -322.862] [0.0000], Avg: [-540.332 -540.332 -540.332] (1.000)
Step: 46649, Reward: [-410.778 -410.778 -410.778] [0.0000], Avg: [-540.193 -540.193 -540.193] (1.000)
Step: 46699, Reward: [-330.317 -330.317 -330.317] [0.0000], Avg: [-539.968 -539.968 -539.968] (1.000)
Step: 46749, Reward: [-421.014 -421.014 -421.014] [0.0000], Avg: [-539.841 -539.841 -539.841] (1.000)
Step: 46799, Reward: [-689.315 -689.315 -689.315] [0.0000], Avg: [-540. -540. -540.] (1.000)
Step: 46849, Reward: [-409.979 -409.979 -409.979] [0.0000], Avg: [-539.862 -539.862 -539.862] (1.000)
Step: 46899, Reward: [-393.331 -393.331 -393.331] [0.0000], Avg: [-539.705 -539.705 -539.705] (1.000)
Step: 46949, Reward: [-498.557 -498.557 -498.557] [0.0000], Avg: [-539.662 -539.662 -539.662] (1.000)
Step: 46999, Reward: [-337.699 -337.699 -337.699] [0.0000], Avg: [-539.447 -539.447 -539.447] (1.000)
Step: 47049, Reward: [-466.413 -466.413 -466.413] [0.0000], Avg: [-539.369 -539.369 -539.369] (1.000)
Step: 47099, Reward: [-313.012 -313.012 -313.012] [0.0000], Avg: [-539.129 -539.129 -539.129] (1.000)
Step: 47149, Reward: [-456.447 -456.447 -456.447] [0.0000], Avg: [-539.041 -539.041 -539.041] (1.000)
Step: 47199, Reward: [-439.946 -439.946 -439.946] [0.0000], Avg: [-538.936 -538.936 -538.936] (1.000)
Step: 47249, Reward: [-419.044 -419.044 -419.044] [0.0000], Avg: [-538.809 -538.809 -538.809] (1.000)
Step: 47299, Reward: [-375.943 -375.943 -375.943] [0.0000], Avg: [-538.637 -538.637 -538.637] (1.000)
Step: 47349, Reward: [-391.594 -391.594 -391.594] [0.0000], Avg: [-538.482 -538.482 -538.482] (1.000)
Step: 47399, Reward: [-437.529 -437.529 -437.529] [0.0000], Avg: [-538.375 -538.375 -538.375] (1.000)
Step: 47449, Reward: [-467.444 -467.444 -467.444] [0.0000], Avg: [-538.301 -538.301 -538.301] (1.000)
Step: 47499, Reward: [-493.526 -493.526 -493.526] [0.0000], Avg: [-538.254 -538.254 -538.254] (1.000)
Step: 47549, Reward: [-338.397 -338.397 -338.397] [0.0000], Avg: [-538.043 -538.043 -538.043] (1.000)
Step: 47599, Reward: [-414.541 -414.541 -414.541] [0.0000], Avg: [-537.914 -537.914 -537.914] (1.000)
Step: 47649, Reward: [-492.147 -492.147 -492.147] [0.0000], Avg: [-537.866 -537.866 -537.866] (1.000)
Step: 47699, Reward: [-489.764 -489.764 -489.764] [0.0000], Avg: [-537.815 -537.815 -537.815] (1.000)
Step: 47749, Reward: [-376.599 -376.599 -376.599] [0.0000], Avg: [-537.646 -537.646 -537.646] (1.000)
Step: 47799, Reward: [-403.44 -403.44 -403.44] [0.0000], Avg: [-537.506 -537.506 -537.506] (1.000)
Step: 47849, Reward: [-420.425 -420.425 -420.425] [0.0000], Avg: [-537.384 -537.384 -537.384] (1.000)
Step: 47899, Reward: [-528.145 -528.145 -528.145] [0.0000], Avg: [-537.374 -537.374 -537.374] (1.000)
Step: 47949, Reward: [-367.479 -367.479 -367.479] [0.0000], Avg: [-537.197 -537.197 -537.197] (1.000)
Step: 47999, Reward: [-385.822 -385.822 -385.822] [0.0000], Avg: [-537.039 -537.039 -537.039] (1.000)
Step: 48049, Reward: [-414.101 -414.101 -414.101] [0.0000], Avg: [-536.911 -536.911 -536.911] (1.000)
Step: 48099, Reward: [-408.95 -408.95 -408.95] [0.0000], Avg: [-536.778 -536.778 -536.778] (1.000)
Step: 48149, Reward: [-502.974 -502.974 -502.974] [0.0000], Avg: [-536.743 -536.743 -536.743] (1.000)
Step: 48199, Reward: [-445.887 -445.887 -445.887] [0.0000], Avg: [-536.649 -536.649 -536.649] (1.000)
Step: 48249, Reward: [-424.069 -424.069 -424.069] [0.0000], Avg: [-536.532 -536.532 -536.532] (1.000)
Step: 48299, Reward: [-468.146 -468.146 -468.146] [0.0000], Avg: [-536.461 -536.461 -536.461] (1.000)
Step: 48349, Reward: [-486.487 -486.487 -486.487] [0.0000], Avg: [-536.41 -536.41 -536.41] (1.000)
Step: 48399, Reward: [-302.714 -302.714 -302.714] [0.0000], Avg: [-536.168 -536.168 -536.168] (1.000)
Step: 48449, Reward: [-385.235 -385.235 -385.235] [0.0000], Avg: [-536.013 -536.013 -536.013] (1.000)
Step: 48499, Reward: [-479.26 -479.26 -479.26] [0.0000], Avg: [-535.954 -535.954 -535.954] (1.000)
Step: 48549, Reward: [-484.674 -484.674 -484.674] [0.0000], Avg: [-535.901 -535.901 -535.901] (1.000)
Step: 48599, Reward: [-365.072 -365.072 -365.072] [0.0000], Avg: [-535.725 -535.725 -535.725] (1.000)
Step: 48649, Reward: [-440.655 -440.655 -440.655] [0.0000], Avg: [-535.628 -535.628 -535.628] (1.000)
Step: 48699, Reward: [-446.512 -446.512 -446.512] [0.0000], Avg: [-535.536 -535.536 -535.536] (1.000)
Step: 48749, Reward: [-356.936 -356.936 -356.936] [0.0000], Avg: [-535.353 -535.353 -535.353] (1.000)
Step: 48799, Reward: [-449.992 -449.992 -449.992] [0.0000], Avg: [-535.266 -535.266 -535.266] (1.000)
Step: 48849, Reward: [-478.682 -478.682 -478.682] [0.0000], Avg: [-535.208 -535.208 -535.208] (1.000)
Step: 48899, Reward: [-391.592 -391.592 -391.592] [0.0000], Avg: [-535.061 -535.061 -535.061] (1.000)
Step: 48949, Reward: [-477.113 -477.113 -477.113] [0.0000], Avg: [-535.002 -535.002 -535.002] (1.000)
Step: 48999, Reward: [-548.236 -548.236 -548.236] [0.0000], Avg: [-535.015 -535.015 -535.015] (1.000)
Step: 49049, Reward: [-389.437 -389.437 -389.437] [0.0000], Avg: [-534.867 -534.867 -534.867] (1.000)
Step: 49099, Reward: [-345.32 -345.32 -345.32] [0.0000], Avg: [-534.674 -534.674 -534.674] (1.000)
Step: 49149, Reward: [-393.513 -393.513 -393.513] [0.0000], Avg: [-534.53 -534.53 -534.53] (1.000)
Step: 49199, Reward: [-524.276 -524.276 -524.276] [0.0000], Avg: [-534.52 -534.52 -534.52] (1.000)
Step: 49249, Reward: [-358.484 -358.484 -358.484] [0.0000], Avg: [-534.341 -534.341 -534.341] (1.000)
Step: 49299, Reward: [-383.047 -383.047 -383.047] [0.0000], Avg: [-534.188 -534.188 -534.188] (1.000)
Step: 49349, Reward: [-385.457 -385.457 -385.457] [0.0000], Avg: [-534.037 -534.037 -534.037] (1.000)
Step: 49399, Reward: [-293.181 -293.181 -293.181] [0.0000], Avg: [-533.793 -533.793 -533.793] (1.000)
Step: 49449, Reward: [-1026.234 -1026.234 -1026.234] [0.0000], Avg: [-534.291 -534.291 -534.291] (1.000)
Step: 49499, Reward: [-511.306 -511.306 -511.306] [0.0000], Avg: [-534.268 -534.268 -534.268] (1.000)
Step: 49549, Reward: [-493.477 -493.477 -493.477] [0.0000], Avg: [-534.227 -534.227 -534.227] (1.000)
Step: 49599, Reward: [-442.83 -442.83 -442.83] [0.0000], Avg: [-534.135 -534.135 -534.135] (1.000)
Step: 49649, Reward: [-381.321 -381.321 -381.321] [0.0000], Avg: [-533.981 -533.981 -533.981] (1.000)
Step: 49699, Reward: [-387.611 -387.611 -387.611] [0.0000], Avg: [-533.833 -533.833 -533.833] (1.000)
Step: 49749, Reward: [-438.821 -438.821 -438.821] [0.0000], Avg: [-533.738 -533.738 -533.738] (1.000)
Step: 49799, Reward: [-414.015 -414.015 -414.015] [0.0000], Avg: [-533.618 -533.618 -533.618] (1.000)
Step: 49849, Reward: [-396.795 -396.795 -396.795] [0.0000], Avg: [-533.48 -533.48 -533.48] (1.000)
Step: 49899, Reward: [-380.499 -380.499 -380.499] [0.0000], Avg: [-533.327 -533.327 -533.327] (1.000)
Step: 49949, Reward: [-459.322 -459.322 -459.322] [0.0000], Avg: [-533.253 -533.253 -533.253] (1.000)
Step: 49999, Reward: [-403.055 -403.055 -403.055] [0.0000], Avg: [-533.123 -533.123 -533.123] (1.000)
Step: 50049, Reward: [-397.355 -397.355 -397.355] [0.0000], Avg: [-532.987 -532.987 -532.987] (1.000)
Step: 50099, Reward: [-433.729 -433.729 -433.729] [0.0000], Avg: [-532.888 -532.888 -532.888] (1.000)
Step: 50149, Reward: [-301.393 -301.393 -301.393] [0.0000], Avg: [-532.657 -532.657 -532.657] (1.000)
Step: 50199, Reward: [-431.543 -431.543 -431.543] [0.0000], Avg: [-532.557 -532.557 -532.557] (1.000)
Step: 50249, Reward: [-375.155 -375.155 -375.155] [0.0000], Avg: [-532.4 -532.4 -532.4] (1.000)
Step: 50299, Reward: [-265.692 -265.692 -265.692] [0.0000], Avg: [-532.135 -532.135 -532.135] (1.000)
Step: 50349, Reward: [-383.519 -383.519 -383.519] [0.0000], Avg: [-531.987 -531.987 -531.987] (1.000)
Step: 50399, Reward: [-356.437 -356.437 -356.437] [0.0000], Avg: [-531.813 -531.813 -531.813] (1.000)
Step: 50449, Reward: [-401.046 -401.046 -401.046] [0.0000], Avg: [-531.684 -531.684 -531.684] (1.000)
Step: 50499, Reward: [-493.829 -493.829 -493.829] [0.0000], Avg: [-531.646 -531.646 -531.646] (1.000)
Step: 50549, Reward: [-305.672 -305.672 -305.672] [0.0000], Avg: [-531.423 -531.423 -531.423] (1.000)
Step: 50599, Reward: [-389.894 -389.894 -389.894] [0.0000], Avg: [-531.283 -531.283 -531.283] (1.000)
Step: 50649, Reward: [-351.564 -351.564 -351.564] [0.0000], Avg: [-531.105 -531.105 -531.105] (1.000)
Step: 50699, Reward: [-413.577 -413.577 -413.577] [0.0000], Avg: [-530.989 -530.989 -530.989] (1.000)
Step: 50749, Reward: [-285.354 -285.354 -285.354] [0.0000], Avg: [-530.747 -530.747 -530.747] (1.000)
Step: 50799, Reward: [-380.069 -380.069 -380.069] [0.0000], Avg: [-530.599 -530.599 -530.599] (1.000)
Step: 50849, Reward: [-407.609 -407.609 -407.609] [0.0000], Avg: [-530.478 -530.478 -530.478] (1.000)
Step: 50899, Reward: [-347.385 -347.385 -347.385] [0.0000], Avg: [-530.298 -530.298 -530.298] (1.000)
Step: 50949, Reward: [-405.675 -405.675 -405.675] [0.0000], Avg: [-530.176 -530.176 -530.176] (1.000)
Step: 50999, Reward: [-387.532 -387.532 -387.532] [0.0000], Avg: [-530.036 -530.036 -530.036] (1.000)
Step: 51049, Reward: [-354.398 -354.398 -354.398] [0.0000], Avg: [-529.864 -529.864 -529.864] (1.000)
Step: 51099, Reward: [-473.752 -473.752 -473.752] [0.0000], Avg: [-529.809 -529.809 -529.809] (1.000)
Step: 51149, Reward: [-492.906 -492.906 -492.906] [0.0000], Avg: [-529.773 -529.773 -529.773] (1.000)
Step: 51199, Reward: [-366.323 -366.323 -366.323] [0.0000], Avg: [-529.614 -529.614 -529.614] (1.000)
Step: 51249, Reward: [-279.515 -279.515 -279.515] [0.0000], Avg: [-529.37 -529.37 -529.37] (1.000)
Step: 51299, Reward: [-482.693 -482.693 -482.693] [0.0000], Avg: [-529.324 -529.324 -529.324] (1.000)
Step: 51349, Reward: [-316.428 -316.428 -316.428] [0.0000], Avg: [-529.117 -529.117 -529.117] (1.000)
Step: 51399, Reward: [-331.037 -331.037 -331.037] [0.0000], Avg: [-528.924 -528.924 -528.924] (1.000)
Step: 51449, Reward: [-338.083 -338.083 -338.083] [0.0000], Avg: [-528.739 -528.739 -528.739] (1.000)
Step: 51499, Reward: [-495.564 -495.564 -495.564] [0.0000], Avg: [-528.706 -528.706 -528.706] (1.000)
Step: 51549, Reward: [-368.771 -368.771 -368.771] [0.0000], Avg: [-528.551 -528.551 -528.551] (1.000)
Step: 51599, Reward: [-389.57 -389.57 -389.57] [0.0000], Avg: [-528.417 -528.417 -528.417] (1.000)
Step: 51649, Reward: [-431.395 -431.395 -431.395] [0.0000], Avg: [-528.323 -528.323 -528.323] (1.000)
Step: 51699, Reward: [-495.187 -495.187 -495.187] [0.0000], Avg: [-528.291 -528.291 -528.291] (1.000)
Step: 51749, Reward: [-561.783 -561.783 -561.783] [0.0000], Avg: [-528.323 -528.323 -528.323] (1.000)
Step: 51799, Reward: [-477.734 -477.734 -477.734] [0.0000], Avg: [-528.274 -528.274 -528.274] (1.000)
Step: 51849, Reward: [-433.694 -433.694 -433.694] [0.0000], Avg: [-528.183 -528.183 -528.183] (1.000)
Step: 51899, Reward: [-502.89 -502.89 -502.89] [0.0000], Avg: [-528.159 -528.159 -528.159] (1.000)
Step: 51949, Reward: [-396.566 -396.566 -396.566] [0.0000], Avg: [-528.032 -528.032 -528.032] (1.000)
Step: 51999, Reward: [-472.206 -472.206 -472.206] [0.0000], Avg: [-527.978 -527.978 -527.978] (1.000)
Step: 52049, Reward: [-470.556 -470.556 -470.556] [0.0000], Avg: [-527.923 -527.923 -527.923] (1.000)
Step: 52099, Reward: [-381.272 -381.272 -381.272] [0.0000], Avg: [-527.782 -527.782 -527.782] (1.000)
Step: 52149, Reward: [-397.815 -397.815 -397.815] [0.0000], Avg: [-527.658 -527.658 -527.658] (1.000)
Step: 52199, Reward: [-325.863 -325.863 -325.863] [0.0000], Avg: [-527.464 -527.464 -527.464] (1.000)
Step: 52249, Reward: [-377.018 -377.018 -377.018] [0.0000], Avg: [-527.321 -527.321 -527.321] (1.000)
Step: 52299, Reward: [-369.21 -369.21 -369.21] [0.0000], Avg: [-527.169 -527.169 -527.169] (1.000)
Step: 52349, Reward: [-422.783 -422.783 -422.783] [0.0000], Avg: [-527.07 -527.07 -527.07] (1.000)
Step: 52399, Reward: [-514.05 -514.05 -514.05] [0.0000], Avg: [-527.057 -527.057 -527.057] (1.000)
Step: 52449, Reward: [-498.069 -498.069 -498.069] [0.0000], Avg: [-527.03 -527.03 -527.03] (1.000)
Step: 52499, Reward: [-369.64 -369.64 -369.64] [0.0000], Avg: [-526.88 -526.88 -526.88] (1.000)
Step: 52549, Reward: [-425.632 -425.632 -425.632] [0.0000], Avg: [-526.783 -526.783 -526.783] (1.000)
Step: 52599, Reward: [-426.014 -426.014 -426.014] [0.0000], Avg: [-526.688 -526.688 -526.688] (1.000)
Step: 52649, Reward: [-395.459 -395.459 -395.459] [0.0000], Avg: [-526.563 -526.563 -526.563] (1.000)
Step: 52699, Reward: [-424.266 -424.266 -424.266] [0.0000], Avg: [-526.466 -526.466 -526.466] (1.000)
Step: 52749, Reward: [-429.57 -429.57 -429.57] [0.0000], Avg: [-526.374 -526.374 -526.374] (1.000)
Step: 52799, Reward: [-397.869 -397.869 -397.869] [0.0000], Avg: [-526.252 -526.252 -526.252] (1.000)
Step: 52849, Reward: [-418.313 -418.313 -418.313] [0.0000], Avg: [-526.15 -526.15 -526.15] (1.000)
Step: 52899, Reward: [-375.167 -375.167 -375.167] [0.0000], Avg: [-526.008 -526.008 -526.008] (1.000)
Step: 52949, Reward: [-419.689 -419.689 -419.689] [0.0000], Avg: [-525.907 -525.907 -525.907] (1.000)
Step: 52999, Reward: [-476.406 -476.406 -476.406] [0.0000], Avg: [-525.86 -525.86 -525.86] (1.000)
Step: 53049, Reward: [-350.085 -350.085 -350.085] [0.0000], Avg: [-525.695 -525.695 -525.695] (1.000)
Step: 53099, Reward: [-427.44 -427.44 -427.44] [0.0000], Avg: [-525.602 -525.602 -525.602] (1.000)
Step: 53149, Reward: [-424.995 -424.995 -424.995] [0.0000], Avg: [-525.508 -525.508 -525.508] (1.000)
Step: 53199, Reward: [-380.119 -380.119 -380.119] [0.0000], Avg: [-525.371 -525.371 -525.371] (1.000)
Step: 53249, Reward: [-393.129 -393.129 -393.129] [0.0000], Avg: [-525.247 -525.247 -525.247] (1.000)
Step: 53299, Reward: [-483.894 -483.894 -483.894] [0.0000], Avg: [-525.208 -525.208 -525.208] (1.000)
Step: 53349, Reward: [-331.18 -331.18 -331.18] [0.0000], Avg: [-525.026 -525.026 -525.026] (1.000)
Step: 53399, Reward: [-299.983 -299.983 -299.983] [0.0000], Avg: [-524.815 -524.815 -524.815] (1.000)
Step: 53449, Reward: [-444.533 -444.533 -444.533] [0.0000], Avg: [-524.74 -524.74 -524.74] (1.000)
Step: 53499, Reward: [-370.796 -370.796 -370.796] [0.0000], Avg: [-524.596 -524.596 -524.596] (1.000)
Step: 53549, Reward: [-336.06 -336.06 -336.06] [0.0000], Avg: [-524.42 -524.42 -524.42] (1.000)
Step: 53599, Reward: [-396.517 -396.517 -396.517] [0.0000], Avg: [-524.301 -524.301 -524.301] (1.000)
Step: 53649, Reward: [-429.723 -429.723 -429.723] [0.0000], Avg: [-524.213 -524.213 -524.213] (1.000)
Step: 53699, Reward: [-381.534 -381.534 -381.534] [0.0000], Avg: [-524.08 -524.08 -524.08] (1.000)
Step: 53749, Reward: [-385.413 -385.413 -385.413] [0.0000], Avg: [-523.951 -523.951 -523.951] (1.000)
Step: 53799, Reward: [-396.251 -396.251 -396.251] [0.0000], Avg: [-523.832 -523.832 -523.832] (1.000)
Step: 53849, Reward: [-502.73 -502.73 -502.73] [0.0000], Avg: [-523.813 -523.813 -523.813] (1.000)
Step: 53899, Reward: [-390.543 -390.543 -390.543] [0.0000], Avg: [-523.689 -523.689 -523.689] (1.000)
Step: 53949, Reward: [-471.553 -471.553 -471.553] [0.0000], Avg: [-523.641 -523.641 -523.641] (1.000)
Step: 53999, Reward: [-406.197 -406.197 -406.197] [0.0000], Avg: [-523.532 -523.532 -523.532] (1.000)
Step: 54049, Reward: [-358.714 -358.714 -358.714] [0.0000], Avg: [-523.38 -523.38 -523.38] (1.000)
Step: 54099, Reward: [-430.96 -430.96 -430.96] [0.0000], Avg: [-523.294 -523.294 -523.294] (1.000)
Step: 54149, Reward: [-350.377 -350.377 -350.377] [0.0000], Avg: [-523.135 -523.135 -523.135] (1.000)
Step: 54199, Reward: [-408.415 -408.415 -408.415] [0.0000], Avg: [-523.029 -523.029 -523.029] (1.000)
Step: 54249, Reward: [-522.382 -522.382 -522.382] [0.0000], Avg: [-523.028 -523.028 -523.028] (1.000)
Step: 54299, Reward: [-301.156 -301.156 -301.156] [0.0000], Avg: [-522.824 -522.824 -522.824] (1.000)
Step: 54349, Reward: [-403.029 -403.029 -403.029] [0.0000], Avg: [-522.714 -522.714 -522.714] (1.000)
Step: 54399, Reward: [-372.313 -372.313 -372.313] [0.0000], Avg: [-522.575 -522.575 -522.575] (1.000)
Step: 54449, Reward: [-529.069 -529.069 -529.069] [0.0000], Avg: [-522.581 -522.581 -522.581] (1.000)
Step: 54499, Reward: [-540.23 -540.23 -540.23] [0.0000], Avg: [-522.598 -522.598 -522.598] (1.000)
Step: 54549, Reward: [-423.582 -423.582 -423.582] [0.0000], Avg: [-522.507 -522.507 -522.507] (1.000)
Step: 54599, Reward: [-439.811 -439.811 -439.811] [0.0000], Avg: [-522.431 -522.431 -522.431] (1.000)
Step: 54649, Reward: [-363.499 -363.499 -363.499] [0.0000], Avg: [-522.286 -522.286 -522.286] (1.000)
Step: 54699, Reward: [-379.286 -379.286 -379.286] [0.0000], Avg: [-522.155 -522.155 -522.155] (1.000)
Step: 54749, Reward: [-383.721 -383.721 -383.721] [0.0000], Avg: [-522.029 -522.029 -522.029] (1.000)
Step: 54799, Reward: [-552.123 -552.123 -552.123] [0.0000], Avg: [-522.056 -522.056 -522.056] (1.000)
Step: 54849, Reward: [-486.741 -486.741 -486.741] [0.0000], Avg: [-522.024 -522.024 -522.024] (1.000)
Step: 54899, Reward: [-411.886 -411.886 -411.886] [0.0000], Avg: [-521.924 -521.924 -521.924] (1.000)
Step: 54949, Reward: [-512.395 -512.395 -512.395] [0.0000], Avg: [-521.915 -521.915 -521.915] (1.000)
Step: 54999, Reward: [-633.605 -633.605 -633.605] [0.0000], Avg: [-522.016 -522.016 -522.016] (1.000)
Step: 55049, Reward: [-334.409 -334.409 -334.409] [0.0000], Avg: [-521.846 -521.846 -521.846] (1.000)
Step: 55099, Reward: [-350.903 -350.903 -350.903] [0.0000], Avg: [-521.691 -521.691 -521.691] (1.000)
Step: 55149, Reward: [-411.151 -411.151 -411.151] [0.0000], Avg: [-521.591 -521.591 -521.591] (1.000)
Step: 55199, Reward: [-440.071 -440.071 -440.071] [0.0000], Avg: [-521.517 -521.517 -521.517] (1.000)
Step: 55249, Reward: [-428.937 -428.937 -428.937] [0.0000], Avg: [-521.433 -521.433 -521.433] (1.000)
Step: 55299, Reward: [-364.655 -364.655 -364.655] [0.0000], Avg: [-521.291 -521.291 -521.291] (1.000)
Step: 55349, Reward: [-764.456 -764.456 -764.456] [0.0000], Avg: [-521.511 -521.511 -521.511] (1.000)
Step: 55399, Reward: [-480.179 -480.179 -480.179] [0.0000], Avg: [-521.474 -521.474 -521.474] (1.000)
Step: 55449, Reward: [-574.332 -574.332 -574.332] [0.0000], Avg: [-521.521 -521.521 -521.521] (1.000)
Step: 55499, Reward: [-449.087 -449.087 -449.087] [0.0000], Avg: [-521.456 -521.456 -521.456] (1.000)
Step: 55549, Reward: [-325.418 -325.418 -325.418] [0.0000], Avg: [-521.28 -521.28 -521.28] (1.000)
Step: 55599, Reward: [-484.639 -484.639 -484.639] [0.0000], Avg: [-521.247 -521.247 -521.247] (1.000)
Step: 55649, Reward: [-375.937 -375.937 -375.937] [0.0000], Avg: [-521.116 -521.116 -521.116] (1.000)
Step: 55699, Reward: [-443.411 -443.411 -443.411] [0.0000], Avg: [-521.046 -521.046 -521.046] (1.000)
Step: 55749, Reward: [-553.287 -553.287 -553.287] [0.0000], Avg: [-521.075 -521.075 -521.075] (1.000)
Step: 55799, Reward: [-391.931 -391.931 -391.931] [0.0000], Avg: [-520.96 -520.96 -520.96] (1.000)
Step: 55849, Reward: [-389.684 -389.684 -389.684] [0.0000], Avg: [-520.842 -520.842 -520.842] (1.000)
Step: 55899, Reward: [-290.625 -290.625 -290.625] [0.0000], Avg: [-520.636 -520.636 -520.636] (1.000)
Step: 55949, Reward: [-319.503 -319.503 -319.503] [0.0000], Avg: [-520.456 -520.456 -520.456] (1.000)
Step: 55999, Reward: [-378.88 -378.88 -378.88] [0.0000], Avg: [-520.33 -520.33 -520.33] (1.000)
Step: 56049, Reward: [-412.091 -412.091 -412.091] [0.0000], Avg: [-520.233 -520.233 -520.233] (1.000)
Step: 56099, Reward: [-382.143 -382.143 -382.143] [0.0000], Avg: [-520.11 -520.11 -520.11] (1.000)
Step: 56149, Reward: [-339.881 -339.881 -339.881] [0.0000], Avg: [-519.95 -519.95 -519.95] (1.000)
Step: 56199, Reward: [-548.695 -548.695 -548.695] [0.0000], Avg: [-519.975 -519.975 -519.975] (1.000)
Step: 56249, Reward: [-400.461 -400.461 -400.461] [0.0000], Avg: [-519.869 -519.869 -519.869] (1.000)
Step: 56299, Reward: [-358.997 -358.997 -358.997] [0.0000], Avg: [-519.726 -519.726 -519.726] (1.000)
Step: 56349, Reward: [-529.816 -529.816 -529.816] [0.0000], Avg: [-519.735 -519.735 -519.735] (1.000)
Step: 56399, Reward: [-471.852 -471.852 -471.852] [0.0000], Avg: [-519.693 -519.693 -519.693] (1.000)
Step: 56449, Reward: [-814.961 -814.961 -814.961] [0.0000], Avg: [-519.954 -519.954 -519.954] (1.000)
Step: 56499, Reward: [-564.13 -564.13 -564.13] [0.0000], Avg: [-519.993 -519.993 -519.993] (1.000)
Step: 56549, Reward: [-376.749 -376.749 -376.749] [0.0000], Avg: [-519.867 -519.867 -519.867] (1.000)
Step: 56599, Reward: [-437.225 -437.225 -437.225] [0.0000], Avg: [-519.794 -519.794 -519.794] (1.000)
Step: 56649, Reward: [-306.541 -306.541 -306.541] [0.0000], Avg: [-519.606 -519.606 -519.606] (1.000)
Step: 56699, Reward: [-443.63 -443.63 -443.63] [0.0000], Avg: [-519.539 -519.539 -519.539] (1.000)
Step: 56749, Reward: [-306.609 -306.609 -306.609] [0.0000], Avg: [-519.351 -519.351 -519.351] (1.000)
Step: 56799, Reward: [-372.386 -372.386 -372.386] [0.0000], Avg: [-519.222 -519.222 -519.222] (1.000)
Step: 56849, Reward: [-393.34 -393.34 -393.34] [0.0000], Avg: [-519.111 -519.111 -519.111] (1.000)
Step: 56899, Reward: [-395.668 -395.668 -395.668] [0.0000], Avg: [-519.002 -519.002 -519.002] (1.000)
Step: 56949, Reward: [-469.261 -469.261 -469.261] [0.0000], Avg: [-518.959 -518.959 -518.959] (1.000)
Step: 56999, Reward: [-382.157 -382.157 -382.157] [0.0000], Avg: [-518.839 -518.839 -518.839] (1.000)
Step: 57049, Reward: [-453.013 -453.013 -453.013] [0.0000], Avg: [-518.781 -518.781 -518.781] (1.000)
Step: 57099, Reward: [-438.186 -438.186 -438.186] [0.0000], Avg: [-518.71 -518.71 -518.71] (1.000)
Step: 57149, Reward: [-291.631 -291.631 -291.631] [0.0000], Avg: [-518.512 -518.512 -518.512] (1.000)
Step: 57199, Reward: [-402.292 -402.292 -402.292] [0.0000], Avg: [-518.41 -518.41 -518.41] (1.000)
Step: 57249, Reward: [-413.139 -413.139 -413.139] [0.0000], Avg: [-518.318 -518.318 -518.318] (1.000)
Step: 57299, Reward: [-360.966 -360.966 -360.966] [0.0000], Avg: [-518.181 -518.181 -518.181] (1.000)
Step: 57349, Reward: [-485.104 -485.104 -485.104] [0.0000], Avg: [-518.152 -518.152 -518.152] (1.000)
Step: 57399, Reward: [-400.131 -400.131 -400.131] [0.0000], Avg: [-518.049 -518.049 -518.049] (1.000)
Step: 57449, Reward: [-280.347 -280.347 -280.347] [0.0000], Avg: [-517.842 -517.842 -517.842] (1.000)
Step: 57499, Reward: [-356.287 -356.287 -356.287] [0.0000], Avg: [-517.702 -517.702 -517.702] (1.000)
Step: 57549, Reward: [-317.196 -317.196 -317.196] [0.0000], Avg: [-517.528 -517.528 -517.528] (1.000)
Step: 57599, Reward: [-395.332 -395.332 -395.332] [0.0000], Avg: [-517.422 -517.422 -517.422] (1.000)
Step: 57649, Reward: [-369.663 -369.663 -369.663] [0.0000], Avg: [-517.294 -517.294 -517.294] (1.000)
Step: 57699, Reward: [-275.654 -275.654 -275.654] [0.0000], Avg: [-517.084 -517.084 -517.084] (1.000)
Step: 57749, Reward: [-493.811 -493.811 -493.811] [0.0000], Avg: [-517.064 -517.064 -517.064] (1.000)
Step: 57799, Reward: [-475.466 -475.466 -475.466] [0.0000], Avg: [-517.028 -517.028 -517.028] (1.000)
Step: 57849, Reward: [-486.045 -486.045 -486.045] [0.0000], Avg: [-517.001 -517.001 -517.001] (1.000)
Step: 57899, Reward: [-537.49 -537.49 -537.49] [0.0000], Avg: [-517.019 -517.019 -517.019] (1.000)
Step: 57949, Reward: [-423.239 -423.239 -423.239] [0.0000], Avg: [-516.938 -516.938 -516.938] (1.000)
Step: 57999, Reward: [-489.614 -489.614 -489.614] [0.0000], Avg: [-516.914 -516.914 -516.914] (1.000)
Step: 58049, Reward: [-435.576 -435.576 -435.576] [0.0000], Avg: [-516.844 -516.844 -516.844] (1.000)
Step: 58099, Reward: [-393.004 -393.004 -393.004] [0.0000], Avg: [-516.738 -516.738 -516.738] (1.000)
Step: 58149, Reward: [-521.22 -521.22 -521.22] [0.0000], Avg: [-516.742 -516.742 -516.742] (1.000)
Step: 58199, Reward: [-347.632 -347.632 -347.632] [0.0000], Avg: [-516.596 -516.596 -516.596] (1.000)
Step: 58249, Reward: [-281.595 -281.595 -281.595] [0.0000], Avg: [-516.395 -516.395 -516.395] (1.000)
Step: 58299, Reward: [-461.028 -461.028 -461.028] [0.0000], Avg: [-516.347 -516.347 -516.347] (1.000)
Step: 58349, Reward: [-572.845 -572.845 -572.845] [0.0000], Avg: [-516.396 -516.396 -516.396] (1.000)
Step: 58399, Reward: [-281.813 -281.813 -281.813] [0.0000], Avg: [-516.195 -516.195 -516.195] (1.000)
Step: 58449, Reward: [-340.909 -340.909 -340.909] [0.0000], Avg: [-516.045 -516.045 -516.045] (1.000)
Step: 58499, Reward: [-313.177 -313.177 -313.177] [0.0000], Avg: [-515.871 -515.871 -515.871] (1.000)
Step: 58549, Reward: [-400.144 -400.144 -400.144] [0.0000], Avg: [-515.773 -515.773 -515.773] (1.000)
Step: 58599, Reward: [-462.663 -462.663 -462.663] [0.0000], Avg: [-515.727 -515.727 -515.727] (1.000)
Step: 58649, Reward: [-507.105 -507.105 -507.105] [0.0000], Avg: [-515.72 -515.72 -515.72] (1.000)
Step: 58699, Reward: [-350.939 -350.939 -350.939] [0.0000], Avg: [-515.58 -515.58 -515.58] (1.000)
Step: 58749, Reward: [-339.858 -339.858 -339.858] [0.0000], Avg: [-515.43 -515.43 -515.43] (1.000)
Step: 58799, Reward: [-560.707 -560.707 -560.707] [0.0000], Avg: [-515.469 -515.469 -515.469] (1.000)
Step: 58849, Reward: [-339.658 -339.658 -339.658] [0.0000], Avg: [-515.319 -515.319 -515.319] (1.000)
Step: 58899, Reward: [-373.43 -373.43 -373.43] [0.0000], Avg: [-515.199 -515.199 -515.199] (1.000)
Step: 58949, Reward: [-323.475 -323.475 -323.475] [0.0000], Avg: [-515.036 -515.036 -515.036] (1.000)
Step: 58999, Reward: [-327.372 -327.372 -327.372] [0.0000], Avg: [-514.877 -514.877 -514.877] (1.000)
Step: 59049, Reward: [-354.287 -354.287 -354.287] [0.0000], Avg: [-514.741 -514.741 -514.741] (1.000)
Step: 59099, Reward: [-397.306 -397.306 -397.306] [0.0000], Avg: [-514.642 -514.642 -514.642] (1.000)
Step: 59149, Reward: [-413.588 -413.588 -413.588] [0.0000], Avg: [-514.556 -514.556 -514.556] (1.000)
Step: 59199, Reward: [-401.33 -401.33 -401.33] [0.0000], Avg: [-514.461 -514.461 -514.461] (1.000)
Step: 59249, Reward: [-451.289 -451.289 -451.289] [0.0000], Avg: [-514.407 -514.407 -514.407] (1.000)
Step: 59299, Reward: [-537.189 -537.189 -537.189] [0.0000], Avg: [-514.427 -514.427 -514.427] (1.000)
Step: 59349, Reward: [-561.448 -561.448 -561.448] [0.0000], Avg: [-514.466 -514.466 -514.466] (1.000)
Step: 59399, Reward: [-365.038 -365.038 -365.038] [0.0000], Avg: [-514.34 -514.34 -514.34] (1.000)
Step: 59449, Reward: [-424.52 -424.52 -424.52] [0.0000], Avg: [-514.265 -514.265 -514.265] (1.000)
Step: 59499, Reward: [-387.528 -387.528 -387.528] [0.0000], Avg: [-514.158 -514.158 -514.158] (1.000)
Step: 59549, Reward: [-500.166 -500.166 -500.166] [0.0000], Avg: [-514.147 -514.147 -514.147] (1.000)
Step: 59599, Reward: [-396.297 -396.297 -396.297] [0.0000], Avg: [-514.048 -514.048 -514.048] (1.000)
Step: 59649, Reward: [-444.071 -444.071 -444.071] [0.0000], Avg: [-513.989 -513.989 -513.989] (1.000)
Step: 59699, Reward: [-450.697 -450.697 -450.697] [0.0000], Avg: [-513.936 -513.936 -513.936] (1.000)
Step: 59749, Reward: [-416.224 -416.224 -416.224] [0.0000], Avg: [-513.854 -513.854 -513.854] (1.000)
Step: 59799, Reward: [-394.051 -394.051 -394.051] [0.0000], Avg: [-513.754 -513.754 -513.754] (1.000)
Step: 59849, Reward: [-404.505 -404.505 -404.505] [0.0000], Avg: [-513.663 -513.663 -513.663] (1.000)
Step: 59899, Reward: [-405.198 -405.198 -405.198] [0.0000], Avg: [-513.572 -513.572 -513.572] (1.000)
Step: 59949, Reward: [-457.459 -457.459 -457.459] [0.0000], Avg: [-513.526 -513.526 -513.526] (1.000)
Step: 59999, Reward: [-603.449 -603.449 -603.449] [0.0000], Avg: [-513.6 -513.6 -513.6] (1.000)
Step: 60049, Reward: [-394.555 -394.555 -394.555] [0.0000], Avg: [-513.501 -513.501 -513.501] (1.000)
Step: 60099, Reward: [-442.889 -442.889 -442.889] [0.0000], Avg: [-513.443 -513.443 -513.443] (1.000)
Step: 60149, Reward: [-408.312 -408.312 -408.312] [0.0000], Avg: [-513.355 -513.355 -513.355] (1.000)
Step: 60199, Reward: [-407.983 -407.983 -407.983] [0.0000], Avg: [-513.268 -513.268 -513.268] (1.000)
Step: 60249, Reward: [-434.016 -434.016 -434.016] [0.0000], Avg: [-513.202 -513.202 -513.202] (1.000)
Step: 60299, Reward: [-321.54 -321.54 -321.54] [0.0000], Avg: [-513.043 -513.043 -513.043] (1.000)
Step: 60349, Reward: [-344.103 -344.103 -344.103] [0.0000], Avg: [-512.903 -512.903 -512.903] (1.000)
Step: 60399, Reward: [-594.563 -594.563 -594.563] [0.0000], Avg: [-512.971 -512.971 -512.971] (1.000)
Step: 60449, Reward: [-428.31 -428.31 -428.31] [0.0000], Avg: [-512.901 -512.901 -512.901] (1.000)
Step: 60499, Reward: [-326.143 -326.143 -326.143] [0.0000], Avg: [-512.746 -512.746 -512.746] (1.000)
Step: 60549, Reward: [-484.192 -484.192 -484.192] [0.0000], Avg: [-512.723 -512.723 -512.723] (1.000)
Step: 60599, Reward: [-454.86 -454.86 -454.86] [0.0000], Avg: [-512.675 -512.675 -512.675] (1.000)
Step: 60649, Reward: [-493.855 -493.855 -493.855] [0.0000], Avg: [-512.659 -512.659 -512.659] (1.000)
Step: 60699, Reward: [-475.26 -475.26 -475.26] [0.0000], Avg: [-512.629 -512.629 -512.629] (1.000)
Step: 60749, Reward: [-360.474 -360.474 -360.474] [0.0000], Avg: [-512.503 -512.503 -512.503] (1.000)
Step: 60799, Reward: [-383.985 -383.985 -383.985] [0.0000], Avg: [-512.398 -512.398 -512.398] (1.000)
Step: 60849, Reward: [-340.789 -340.789 -340.789] [0.0000], Avg: [-512.257 -512.257 -512.257] (1.000)
Step: 60899, Reward: [-382.59 -382.59 -382.59] [0.0000], Avg: [-512.15 -512.15 -512.15] (1.000)
Step: 60949, Reward: [-401.317 -401.317 -401.317] [0.0000], Avg: [-512.059 -512.059 -512.059] (1.000)
Step: 60999, Reward: [-392.982 -392.982 -392.982] [0.0000], Avg: [-511.962 -511.962 -511.962] (1.000)
Step: 61049, Reward: [-372.049 -372.049 -372.049] [0.0000], Avg: [-511.847 -511.847 -511.847] (1.000)
Step: 61099, Reward: [-353.088 -353.088 -353.088] [0.0000], Avg: [-511.717 -511.717 -511.717] (1.000)
Step: 61149, Reward: [-357.71 -357.71 -357.71] [0.0000], Avg: [-511.591 -511.591 -511.591] (1.000)
Step: 61199, Reward: [-501.472 -501.472 -501.472] [0.0000], Avg: [-511.583 -511.583 -511.583] (1.000)
Step: 61249, Reward: [-320.105 -320.105 -320.105] [0.0000], Avg: [-511.427 -511.427 -511.427] (1.000)
Step: 61299, Reward: [-380.953 -380.953 -380.953] [0.0000], Avg: [-511.32 -511.32 -511.32] (1.000)
Step: 61349, Reward: [-324.222 -324.222 -324.222] [0.0000], Avg: [-511.168 -511.168 -511.168] (1.000)
Step: 61399, Reward: [-387.445 -387.445 -387.445] [0.0000], Avg: [-511.067 -511.067 -511.067] (1.000)
Step: 61449, Reward: [-330.233 -330.233 -330.233] [0.0000], Avg: [-510.92 -510.92 -510.92] (1.000)
Step: 61499, Reward: [-329.03 -329.03 -329.03] [0.0000], Avg: [-510.772 -510.772 -510.772] (1.000)
Step: 61549, Reward: [-461.208 -461.208 -461.208] [0.0000], Avg: [-510.732 -510.732 -510.732] (1.000)
Step: 61599, Reward: [-360.95 -360.95 -360.95] [0.0000], Avg: [-510.61 -510.61 -510.61] (1.000)
Step: 61649, Reward: [-372.348 -372.348 -372.348] [0.0000], Avg: [-510.498 -510.498 -510.498] (1.000)
Step: 61699, Reward: [-384.745 -384.745 -384.745] [0.0000], Avg: [-510.396 -510.396 -510.396] (1.000)
Step: 61749, Reward: [-442.052 -442.052 -442.052] [0.0000], Avg: [-510.341 -510.341 -510.341] (1.000)
Step: 61799, Reward: [-467.466 -467.466 -467.466] [0.0000], Avg: [-510.306 -510.306 -510.306] (1.000)
Step: 61849, Reward: [-371.852 -371.852 -371.852] [0.0000], Avg: [-510.194 -510.194 -510.194] (1.000)
Step: 61899, Reward: [-385.107 -385.107 -385.107] [0.0000], Avg: [-510.093 -510.093 -510.093] (1.000)
Step: 61949, Reward: [-403.198 -403.198 -403.198] [0.0000], Avg: [-510.007 -510.007 -510.007] (1.000)
Step: 61999, Reward: [-499.345 -499.345 -499.345] [0.0000], Avg: [-509.998 -509.998 -509.998] (1.000)
Step: 62049, Reward: [-380.929 -380.929 -380.929] [0.0000], Avg: [-509.894 -509.894 -509.894] (1.000)
Step: 62099, Reward: [-329.141 -329.141 -329.141] [0.0000], Avg: [-509.749 -509.749 -509.749] (1.000)
Step: 62149, Reward: [-380.841 -380.841 -380.841] [0.0000], Avg: [-509.645 -509.645 -509.645] (1.000)
Step: 62199, Reward: [-379.436 -379.436 -379.436] [0.0000], Avg: [-509.54 -509.54 -509.54] (1.000)
Step: 62249, Reward: [-328.421 -328.421 -328.421] [0.0000], Avg: [-509.395 -509.395 -509.395] (1.000)
Step: 62299, Reward: [-438.98 -438.98 -438.98] [0.0000], Avg: [-509.338 -509.338 -509.338] (1.000)
Step: 62349, Reward: [-318.544 -318.544 -318.544] [0.0000], Avg: [-509.185 -509.185 -509.185] (1.000)
Step: 62399, Reward: [-412.359 -412.359 -412.359] [0.0000], Avg: [-509.108 -509.108 -509.108] (1.000)
Step: 62449, Reward: [-339.802 -339.802 -339.802] [0.0000], Avg: [-508.972 -508.972 -508.972] (1.000)
Step: 62499, Reward: [-362.841 -362.841 -362.841] [0.0000], Avg: [-508.855 -508.855 -508.855] (1.000)
Step: 62549, Reward: [-290.645 -290.645 -290.645] [0.0000], Avg: [-508.681 -508.681 -508.681] (1.000)
Step: 62599, Reward: [-503. -503. -503.] [0.0000], Avg: [-508.676 -508.676 -508.676] (1.000)
Step: 62649, Reward: [-517.45 -517.45 -517.45] [0.0000], Avg: [-508.683 -508.683 -508.683] (1.000)
Step: 62699, Reward: [-360.909 -360.909 -360.909] [0.0000], Avg: [-508.565 -508.565 -508.565] (1.000)
Step: 62749, Reward: [-422.131 -422.131 -422.131] [0.0000], Avg: [-508.497 -508.497 -508.497] (1.000)
Step: 62799, Reward: [-356.294 -356.294 -356.294] [0.0000], Avg: [-508.375 -508.375 -508.375] (1.000)
Step: 62849, Reward: [-365.342 -365.342 -365.342] [0.0000], Avg: [-508.262 -508.262 -508.262] (1.000)
Step: 62899, Reward: [-387.363 -387.363 -387.363] [0.0000], Avg: [-508.166 -508.166 -508.166] (1.000)
Step: 62949, Reward: [-576.768 -576.768 -576.768] [0.0000], Avg: [-508.22 -508.22 -508.22] (1.000)
Step: 62999, Reward: [-325.148 -325.148 -325.148] [0.0000], Avg: [-508.075 -508.075 -508.075] (1.000)
Step: 63049, Reward: [-515.885 -515.885 -515.885] [0.0000], Avg: [-508.081 -508.081 -508.081] (1.000)
Step: 63099, Reward: [-472.672 -472.672 -472.672] [0.0000], Avg: [-508.053 -508.053 -508.053] (1.000)
Step: 63149, Reward: [-370.684 -370.684 -370.684] [0.0000], Avg: [-507.944 -507.944 -507.944] (1.000)
Step: 63199, Reward: [-357.992 -357.992 -357.992] [0.0000], Avg: [-507.825 -507.825 -507.825] (1.000)
Step: 63249, Reward: [-300.167 -300.167 -300.167] [0.0000], Avg: [-507.661 -507.661 -507.661] (1.000)
Step: 63299, Reward: [-412.889 -412.889 -412.889] [0.0000], Avg: [-507.586 -507.586 -507.586] (1.000)
Step: 63349, Reward: [-324.656 -324.656 -324.656] [0.0000], Avg: [-507.442 -507.442 -507.442] (1.000)
Step: 63399, Reward: [-450.737 -450.737 -450.737] [0.0000], Avg: [-507.397 -507.397 -507.397] (1.000)
Step: 63449, Reward: [-526.285 -526.285 -526.285] [0.0000], Avg: [-507.412 -507.412 -507.412] (1.000)
Step: 63499, Reward: [-379.157 -379.157 -379.157] [0.0000], Avg: [-507.311 -507.311 -507.311] (1.000)
Step: 63549, Reward: [-502.232 -502.232 -502.232] [0.0000], Avg: [-507.307 -507.307 -507.307] (1.000)
Step: 63599, Reward: [-412.581 -412.581 -412.581] [0.0000], Avg: [-507.233 -507.233 -507.233] (1.000)
Step: 63649, Reward: [-431.945 -431.945 -431.945] [0.0000], Avg: [-507.174 -507.174 -507.174] (1.000)
Step: 63699, Reward: [-457.262 -457.262 -457.262] [0.0000], Avg: [-507.134 -507.134 -507.134] (1.000)
Step: 63749, Reward: [-347.061 -347.061 -347.061] [0.0000], Avg: [-507.009 -507.009 -507.009] (1.000)
Step: 63799, Reward: [-467.358 -467.358 -467.358] [0.0000], Avg: [-506.978 -506.978 -506.978] (1.000)
Step: 63849, Reward: [-303.842 -303.842 -303.842] [0.0000], Avg: [-506.819 -506.819 -506.819] (1.000)
Step: 63899, Reward: [-521.656 -521.656 -521.656] [0.0000], Avg: [-506.83 -506.83 -506.83] (1.000)
Step: 63949, Reward: [-357.166 -357.166 -357.166] [0.0000], Avg: [-506.713 -506.713 -506.713] (1.000)
Step: 63999, Reward: [-576.157 -576.157 -576.157] [0.0000], Avg: [-506.768 -506.768 -506.768] (1.000)
Step: 64049, Reward: [-429.657 -429.657 -429.657] [0.0000], Avg: [-506.707 -506.707 -506.707] (1.000)
Step: 64099, Reward: [-364.434 -364.434 -364.434] [0.0000], Avg: [-506.596 -506.596 -506.596] (1.000)
Step: 64149, Reward: [-470.797 -470.797 -470.797] [0.0000], Avg: [-506.569 -506.569 -506.569] (1.000)
Step: 64199, Reward: [-334.373 -334.373 -334.373] [0.0000], Avg: [-506.434 -506.434 -506.434] (1.000)
Step: 64249, Reward: [-430.335 -430.335 -430.335] [0.0000], Avg: [-506.375 -506.375 -506.375] (1.000)
Step: 64299, Reward: [-616.75 -616.75 -616.75] [0.0000], Avg: [-506.461 -506.461 -506.461] (1.000)
Step: 64349, Reward: [-299.784 -299.784 -299.784] [0.0000], Avg: [-506.3 -506.3 -506.3] (1.000)
Step: 64399, Reward: [-365.852 -365.852 -365.852] [0.0000], Avg: [-506.191 -506.191 -506.191] (1.000)
Step: 64449, Reward: [-482.114 -482.114 -482.114] [0.0000], Avg: [-506.173 -506.173 -506.173] (1.000)
Step: 64499, Reward: [-397.235 -397.235 -397.235] [0.0000], Avg: [-506.088 -506.088 -506.088] (1.000)
Step: 64549, Reward: [-506.425 -506.425 -506.425] [0.0000], Avg: [-506.089 -506.089 -506.089] (1.000)
Step: 64599, Reward: [-377.445 -377.445 -377.445] [0.0000], Avg: [-505.989 -505.989 -505.989] (1.000)
Step: 64649, Reward: [-410.224 -410.224 -410.224] [0.0000], Avg: [-505.915 -505.915 -505.915] (1.000)
Step: 64699, Reward: [-516.101 -516.101 -516.101] [0.0000], Avg: [-505.923 -505.923 -505.923] (1.000)
Step: 64749, Reward: [-380.793 -380.793 -380.793] [0.0000], Avg: [-505.826 -505.826 -505.826] (1.000)
Step: 64799, Reward: [-443.843 -443.843 -443.843] [0.0000], Avg: [-505.778 -505.778 -505.778] (1.000)
Step: 64849, Reward: [-363.974 -363.974 -363.974] [0.0000], Avg: [-505.669 -505.669 -505.669] (1.000)
Step: 64899, Reward: [-356.148 -356.148 -356.148] [0.0000], Avg: [-505.554 -505.554 -505.554] (1.000)
Step: 64949, Reward: [-379.437 -379.437 -379.437] [0.0000], Avg: [-505.457 -505.457 -505.457] (1.000)
Step: 64999, Reward: [-522.125 -522.125 -522.125] [0.0000], Avg: [-505.47 -505.47 -505.47] (1.000)
Step: 65049, Reward: [-407.25 -407.25 -407.25] [0.0000], Avg: [-505.394 -505.394 -505.394] (1.000)
Step: 65099, Reward: [-455.303 -455.303 -455.303] [0.0000], Avg: [-505.356 -505.356 -505.356] (1.000)
Step: 65149, Reward: [-419.07 -419.07 -419.07] [0.0000], Avg: [-505.289 -505.289 -505.289] (1.000)
Step: 65199, Reward: [-366.916 -366.916 -366.916] [0.0000], Avg: [-505.183 -505.183 -505.183] (1.000)
Step: 65249, Reward: [-442.831 -442.831 -442.831] [0.0000], Avg: [-505.135 -505.135 -505.135] (1.000)
Step: 65299, Reward: [-420.432 -420.432 -420.432] [0.0000], Avg: [-505.071 -505.071 -505.071] (1.000)
Step: 65349, Reward: [-439.839 -439.839 -439.839] [0.0000], Avg: [-505.021 -505.021 -505.021] (1.000)
Step: 65399, Reward: [-413.228 -413.228 -413.228] [0.0000], Avg: [-504.951 -504.951 -504.951] (1.000)
Step: 65449, Reward: [-452.425 -452.425 -452.425] [0.0000], Avg: [-504.91 -504.91 -504.91] (1.000)
Step: 65499, Reward: [-313.967 -313.967 -313.967] [0.0000], Avg: [-504.765 -504.765 -504.765] (1.000)
Step: 65549, Reward: [-397.369 -397.369 -397.369] [0.0000], Avg: [-504.683 -504.683 -504.683] (1.000)
Step: 65599, Reward: [-381.345 -381.345 -381.345] [0.0000], Avg: [-504.589 -504.589 -504.589] (1.000)
Step: 65649, Reward: [-505.348 -505.348 -505.348] [0.0000], Avg: [-504.589 -504.589 -504.589] (1.000)
Step: 65699, Reward: [-324.878 -324.878 -324.878] [0.0000], Avg: [-504.453 -504.453 -504.453] (1.000)
Step: 65749, Reward: [-359.449 -359.449 -359.449] [0.0000], Avg: [-504.342 -504.342 -504.342] (1.000)
Step: 65799, Reward: [-388.105 -388.105 -388.105] [0.0000], Avg: [-504.254 -504.254 -504.254] (1.000)
Step: 65849, Reward: [-538.997 -538.997 -538.997] [0.0000], Avg: [-504.28 -504.28 -504.28] (1.000)
Step: 65899, Reward: [-440.977 -440.977 -440.977] [0.0000], Avg: [-504.232 -504.232 -504.232] (1.000)
Step: 65949, Reward: [-420.176 -420.176 -420.176] [0.0000], Avg: [-504.169 -504.169 -504.169] (1.000)
Step: 65999, Reward: [-591.62 -591.62 -591.62] [0.0000], Avg: [-504.235 -504.235 -504.235] (1.000)
Step: 66049, Reward: [-497.284 -497.284 -497.284] [0.0000], Avg: [-504.23 -504.23 -504.23] (1.000)
Step: 66099, Reward: [-326.492 -326.492 -326.492] [0.0000], Avg: [-504.095 -504.095 -504.095] (1.000)
Step: 66149, Reward: [-428.9 -428.9 -428.9] [0.0000], Avg: [-504.038 -504.038 -504.038] (1.000)
Step: 66199, Reward: [-472.692 -472.692 -472.692] [0.0000], Avg: [-504.015 -504.015 -504.015] (1.000)
Step: 66249, Reward: [-331.399 -331.399 -331.399] [0.0000], Avg: [-503.884 -503.884 -503.884] (1.000)
Step: 66299, Reward: [-330.045 -330.045 -330.045] [0.0000], Avg: [-503.753 -503.753 -503.753] (1.000)
Step: 66349, Reward: [-418.407 -418.407 -418.407] [0.0000], Avg: [-503.689 -503.689 -503.689] (1.000)
Step: 66399, Reward: [-407.336 -407.336 -407.336] [0.0000], Avg: [-503.616 -503.616 -503.616] (1.000)
Step: 66449, Reward: [-355.729 -355.729 -355.729] [0.0000], Avg: [-503.505 -503.505 -503.505] (1.000)
Step: 66499, Reward: [-370.065 -370.065 -370.065] [0.0000], Avg: [-503.405 -503.405 -503.405] (1.000)
Step: 66549, Reward: [-364.67 -364.67 -364.67] [0.0000], Avg: [-503.3 -503.3 -503.3] (1.000)
Step: 66599, Reward: [-493.161 -493.161 -493.161] [0.0000], Avg: [-503.293 -503.293 -503.293] (1.000)
Step: 66649, Reward: [-344.136 -344.136 -344.136] [0.0000], Avg: [-503.173 -503.173 -503.173] (1.000)
Step: 66699, Reward: [-327.188 -327.188 -327.188] [0.0000], Avg: [-503.042 -503.042 -503.042] (1.000)
Step: 66749, Reward: [-480.377 -480.377 -480.377] [0.0000], Avg: [-503.025 -503.025 -503.025] (1.000)
Step: 66799, Reward: [-401.909 -401.909 -401.909] [0.0000], Avg: [-502.949 -502.949 -502.949] (1.000)
Step: 66849, Reward: [-443.304 -443.304 -443.304] [0.0000], Avg: [-502.904 -502.904 -502.904] (1.000)
Step: 66899, Reward: [-420.448 -420.448 -420.448] [0.0000], Avg: [-502.843 -502.843 -502.843] (1.000)
Step: 66949, Reward: [-318.423 -318.423 -318.423] [0.0000], Avg: [-502.705 -502.705 -502.705] (1.000)
Step: 66999, Reward: [-551.216 -551.216 -551.216] [0.0000], Avg: [-502.741 -502.741 -502.741] (1.000)
Step: 67049, Reward: [-416.028 -416.028 -416.028] [0.0000], Avg: [-502.676 -502.676 -502.676] (1.000)
Step: 67099, Reward: [-496.667 -496.667 -496.667] [0.0000], Avg: [-502.672 -502.672 -502.672] (1.000)
Step: 67149, Reward: [-336.07 -336.07 -336.07] [0.0000], Avg: [-502.548 -502.548 -502.548] (1.000)
Step: 67199, Reward: [-383.799 -383.799 -383.799] [0.0000], Avg: [-502.46 -502.46 -502.46] (1.000)
Step: 67249, Reward: [-368.293 -368.293 -368.293] [0.0000], Avg: [-502.36 -502.36 -502.36] (1.000)
Step: 67299, Reward: [-407.975 -407.975 -407.975] [0.0000], Avg: [-502.29 -502.29 -502.29] (1.000)
Step: 67349, Reward: [-303.312 -303.312 -303.312] [0.0000], Avg: [-502.142 -502.142 -502.142] (1.000)
Step: 67399, Reward: [-461.583 -461.583 -461.583] [0.0000], Avg: [-502.112 -502.112 -502.112] (1.000)
Step: 67449, Reward: [-453.087 -453.087 -453.087] [0.0000], Avg: [-502.076 -502.076 -502.076] (1.000)
Step: 67499, Reward: [-404.47 -404.47 -404.47] [0.0000], Avg: [-502.003 -502.003 -502.003] (1.000)
Step: 67549, Reward: [-490.778 -490.778 -490.778] [0.0000], Avg: [-501.995 -501.995 -501.995] (1.000)
Step: 67599, Reward: [-429.816 -429.816 -429.816] [0.0000], Avg: [-501.942 -501.942 -501.942] (1.000)
Step: 67649, Reward: [-414.019 -414.019 -414.019] [0.0000], Avg: [-501.877 -501.877 -501.877] (1.000)
Step: 67699, Reward: [-399.965 -399.965 -399.965] [0.0000], Avg: [-501.801 -501.801 -501.801] (1.000)
Step: 67749, Reward: [-276.531 -276.531 -276.531] [0.0000], Avg: [-501.635 -501.635 -501.635] (1.000)
Step: 67799, Reward: [-439.26 -439.26 -439.26] [0.0000], Avg: [-501.589 -501.589 -501.589] (1.000)
Step: 67849, Reward: [-402.538 -402.538 -402.538] [0.0000], Avg: [-501.516 -501.516 -501.516] (1.000)
Step: 67899, Reward: [-448.278 -448.278 -448.278] [0.0000], Avg: [-501.477 -501.477 -501.477] (1.000)
Step: 67949, Reward: [-396.199 -396.199 -396.199] [0.0000], Avg: [-501.399 -501.399 -501.399] (1.000)
Step: 67999, Reward: [-393.265 -393.265 -393.265] [0.0000], Avg: [-501.32 -501.32 -501.32] (1.000)
Step: 68049, Reward: [-339.646 -339.646 -339.646] [0.0000], Avg: [-501.201 -501.201 -501.201] (1.000)
Step: 68099, Reward: [-370.063 -370.063 -370.063] [0.0000], Avg: [-501.105 -501.105 -501.105] (1.000)
Step: 68149, Reward: [-291.47 -291.47 -291.47] [0.0000], Avg: [-500.951 -500.951 -500.951] (1.000)
Step: 68199, Reward: [-359.658 -359.658 -359.658] [0.0000], Avg: [-500.847 -500.847 -500.847] (1.000)
Step: 68249, Reward: [-417.424 -417.424 -417.424] [0.0000], Avg: [-500.786 -500.786 -500.786] (1.000)
Step: 68299, Reward: [-322.494 -322.494 -322.494] [0.0000], Avg: [-500.656 -500.656 -500.656] (1.000)
Step: 68349, Reward: [-305.651 -305.651 -305.651] [0.0000], Avg: [-500.513 -500.513 -500.513] (1.000)
Step: 68399, Reward: [-535.227 -535.227 -535.227] [0.0000], Avg: [-500.539 -500.539 -500.539] (1.000)
Step: 68449, Reward: [-352.439 -352.439 -352.439] [0.0000], Avg: [-500.43 -500.43 -500.43] (1.000)
Step: 68499, Reward: [-351.219 -351.219 -351.219] [0.0000], Avg: [-500.321 -500.321 -500.321] (1.000)
Step: 68549, Reward: [-474.801 -474.801 -474.801] [0.0000], Avg: [-500.303 -500.303 -500.303] (1.000)
Step: 68599, Reward: [-444.037 -444.037 -444.037] [0.0000], Avg: [-500.262 -500.262 -500.262] (1.000)
Step: 68649, Reward: [-450.413 -450.413 -450.413] [0.0000], Avg: [-500.225 -500.225 -500.225] (1.000)
Step: 68699, Reward: [-415.398 -415.398 -415.398] [0.0000], Avg: [-500.164 -500.164 -500.164] (1.000)
Step: 68749, Reward: [-484.94 -484.94 -484.94] [0.0000], Avg: [-500.153 -500.153 -500.153] (1.000)
Step: 68799, Reward: [-370.575 -370.575 -370.575] [0.0000], Avg: [-500.059 -500.059 -500.059] (1.000)
Step: 68849, Reward: [-469.579 -469.579 -469.579] [0.0000], Avg: [-500.036 -500.036 -500.036] (1.000)
Step: 68899, Reward: [-346.154 -346.154 -346.154] [0.0000], Avg: [-499.925 -499.925 -499.925] (1.000)
Step: 68949, Reward: [-323.568 -323.568 -323.568] [0.0000], Avg: [-499.797 -499.797 -499.797] (1.000)
Step: 68999, Reward: [-438.337 -438.337 -438.337] [0.0000], Avg: [-499.752 -499.752 -499.752] (1.000)
Step: 69049, Reward: [-376.025 -376.025 -376.025] [0.0000], Avg: [-499.663 -499.663 -499.663] (1.000)
Step: 69099, Reward: [-380.663 -380.663 -380.663] [0.0000], Avg: [-499.577 -499.577 -499.577] (1.000)
Step: 69149, Reward: [-489.86 -489.86 -489.86] [0.0000], Avg: [-499.57 -499.57 -499.57] (1.000)
Step: 69199, Reward: [-325.644 -325.644 -325.644] [0.0000], Avg: [-499.444 -499.444 -499.444] (1.000)
Step: 69249, Reward: [-439.151 -439.151 -439.151] [0.0000], Avg: [-499.4 -499.4 -499.4] (1.000)
Step: 69299, Reward: [-475.138 -475.138 -475.138] [0.0000], Avg: [-499.383 -499.383 -499.383] (1.000)
Step: 69349, Reward: [-487.176 -487.176 -487.176] [0.0000], Avg: [-499.374 -499.374 -499.374] (1.000)
Step: 69399, Reward: [-300.457 -300.457 -300.457] [0.0000], Avg: [-499.231 -499.231 -499.231] (1.000)
Step: 69449, Reward: [-398.012 -398.012 -398.012] [0.0000], Avg: [-499.158 -499.158 -499.158] (1.000)
Step: 69499, Reward: [-299.345 -299.345 -299.345] [0.0000], Avg: [-499.014 -499.014 -499.014] (1.000)
Step: 69549, Reward: [-360.069 -360.069 -360.069] [0.0000], Avg: [-498.914 -498.914 -498.914] (1.000)
Step: 69599, Reward: [-393.71 -393.71 -393.71] [0.0000], Avg: [-498.839 -498.839 -498.839] (1.000)
Step: 69649, Reward: [-440.334 -440.334 -440.334] [0.0000], Avg: [-498.797 -498.797 -498.797] (1.000)
Step: 69699, Reward: [-452.97 -452.97 -452.97] [0.0000], Avg: [-498.764 -498.764 -498.764] (1.000)
Step: 69749, Reward: [-469.079 -469.079 -469.079] [0.0000], Avg: [-498.742 -498.742 -498.742] (1.000)
Step: 69799, Reward: [-383.46 -383.46 -383.46] [0.0000], Avg: [-498.66 -498.66 -498.66] (1.000)
Step: 69849, Reward: [-460.981 -460.981 -460.981] [0.0000], Avg: [-498.633 -498.633 -498.633] (1.000)
Step: 69899, Reward: [-430.259 -430.259 -430.259] [0.0000], Avg: [-498.584 -498.584 -498.584] (1.000)
Step: 69949, Reward: [-410.055 -410.055 -410.055] [0.0000], Avg: [-498.521 -498.521 -498.521] (1.000)
Step: 69999, Reward: [-467.913 -467.913 -467.913] [0.0000], Avg: [-498.499 -498.499 -498.499] (1.000)
Step: 70049, Reward: [-403.455 -403.455 -403.455] [0.0000], Avg: [-498.431 -498.431 -498.431] (1.000)
Step: 70099, Reward: [-337.143 -337.143 -337.143] [0.0000], Avg: [-498.316 -498.316 -498.316] (1.000)
Step: 70149, Reward: [-349.926 -349.926 -349.926] [0.0000], Avg: [-498.21 -498.21 -498.21] (1.000)
Step: 70199, Reward: [-364.752 -364.752 -364.752] [0.0000], Avg: [-498.115 -498.115 -498.115] (1.000)
Step: 70249, Reward: [-361.305 -361.305 -361.305] [0.0000], Avg: [-498.018 -498.018 -498.018] (1.000)
Step: 70299, Reward: [-394.913 -394.913 -394.913] [0.0000], Avg: [-497.944 -497.944 -497.944] (1.000)
Step: 70349, Reward: [-389.783 -389.783 -389.783] [0.0000], Avg: [-497.868 -497.868 -497.868] (1.000)
Step: 70399, Reward: [-356.41 -356.41 -356.41] [0.0000], Avg: [-497.767 -497.767 -497.767] (1.000)
Step: 70449, Reward: [-423.917 -423.917 -423.917] [0.0000], Avg: [-497.715 -497.715 -497.715] (1.000)
Step: 70499, Reward: [-408.815 -408.815 -408.815] [0.0000], Avg: [-497.652 -497.652 -497.652] (1.000)
Step: 70549, Reward: [-436.902 -436.902 -436.902] [0.0000], Avg: [-497.609 -497.609 -497.609] (1.000)
Step: 70599, Reward: [-402.17 -402.17 -402.17] [0.0000], Avg: [-497.541 -497.541 -497.541] (1.000)
Step: 70649, Reward: [-505.896 -505.896 -505.896] [0.0000], Avg: [-497.547 -497.547 -497.547] (1.000)
Step: 70699, Reward: [-291.783 -291.783 -291.783] [0.0000], Avg: [-497.401 -497.401 -497.401] (1.000)
Step: 70749, Reward: [-346.357 -346.357 -346.357] [0.0000], Avg: [-497.295 -497.295 -497.295] (1.000)
Step: 70799, Reward: [-301.676 -301.676 -301.676] [0.0000], Avg: [-497.157 -497.157 -497.157] (1.000)
Step: 70849, Reward: [-459.826 -459.826 -459.826] [0.0000], Avg: [-497.13 -497.13 -497.13] (1.000)
Step: 70899, Reward: [-376.724 -376.724 -376.724] [0.0000], Avg: [-497.045 -497.045 -497.045] (1.000)
Step: 70949, Reward: [-427.059 -427.059 -427.059] [0.0000], Avg: [-496.996 -496.996 -496.996] (1.000)
Step: 70999, Reward: [-524.008 -524.008 -524.008] [0.0000], Avg: [-497.015 -497.015 -497.015] (1.000)
Step: 71049, Reward: [-365.283 -365.283 -365.283] [0.0000], Avg: [-496.922 -496.922 -496.922] (1.000)
Step: 71099, Reward: [-490.34 -490.34 -490.34] [0.0000], Avg: [-496.918 -496.918 -496.918] (1.000)
Step: 71149, Reward: [-408.213 -408.213 -408.213] [0.0000], Avg: [-496.855 -496.855 -496.855] (1.000)
Step: 71199, Reward: [-411.979 -411.979 -411.979] [0.0000], Avg: [-496.796 -496.796 -496.796] (1.000)
Step: 71249, Reward: [-356.55 -356.55 -356.55] [0.0000], Avg: [-496.697 -496.697 -496.697] (1.000)
Step: 71299, Reward: [-329.849 -329.849 -329.849] [0.0000], Avg: [-496.58 -496.58 -496.58] (1.000)
Step: 71349, Reward: [-377.542 -377.542 -377.542] [0.0000], Avg: [-496.497 -496.497 -496.497] (1.000)
Step: 71399, Reward: [-430.576 -430.576 -430.576] [0.0000], Avg: [-496.451 -496.451 -496.451] (1.000)
Step: 71449, Reward: [-398.886 -398.886 -398.886] [0.0000], Avg: [-496.382 -496.382 -496.382] (1.000)
Step: 71499, Reward: [-323.615 -323.615 -323.615] [0.0000], Avg: [-496.262 -496.262 -496.262] (1.000)
Step: 71549, Reward: [-426.771 -426.771 -426.771] [0.0000], Avg: [-496.213 -496.213 -496.213] (1.000)
Step: 71599, Reward: [-374.357 -374.357 -374.357] [0.0000], Avg: [-496.128 -496.128 -496.128] (1.000)
Step: 71649, Reward: [-354.163 -354.163 -354.163] [0.0000], Avg: [-496.029 -496.029 -496.029] (1.000)
Step: 71699, Reward: [-419.441 -419.441 -419.441] [0.0000], Avg: [-495.975 -495.975 -495.975] (1.000)
Step: 71749, Reward: [-322.391 -322.391 -322.391] [0.0000], Avg: [-495.855 -495.855 -495.855] (1.000)
Step: 71799, Reward: [-371.247 -371.247 -371.247] [0.0000], Avg: [-495.768 -495.768 -495.768] (1.000)
Step: 71849, Reward: [-397.557 -397.557 -397.557] [0.0000], Avg: [-495.699 -495.699 -495.699] (1.000)
Step: 71899, Reward: [-357.73 -357.73 -357.73] [0.0000], Avg: [-495.603 -495.603 -495.603] (1.000)
Step: 71949, Reward: [-412.102 -412.102 -412.102] [0.0000], Avg: [-495.545 -495.545 -495.545] (1.000)
Step: 71999, Reward: [-365.857 -365.857 -365.857] [0.0000], Avg: [-495.455 -495.455 -495.455] (1.000)
Step: 72049, Reward: [-349.622 -349.622 -349.622] [0.0000], Avg: [-495.354 -495.354 -495.354] (1.000)
Step: 72099, Reward: [-405.583 -405.583 -405.583] [0.0000], Avg: [-495.292 -495.292 -495.292] (1.000)
Step: 72149, Reward: [-428.603 -428.603 -428.603] [0.0000], Avg: [-495.246 -495.246 -495.246] (1.000)
Step: 72199, Reward: [-370.611 -370.611 -370.611] [0.0000], Avg: [-495.159 -495.159 -495.159] (1.000)
Step: 72249, Reward: [-375.657 -375.657 -375.657] [0.0000], Avg: [-495.077 -495.077 -495.077] (1.000)
Step: 72299, Reward: [-401.128 -401.128 -401.128] [0.0000], Avg: [-495.012 -495.012 -495.012] (1.000)
Step: 72349, Reward: [-357.119 -357.119 -357.119] [0.0000], Avg: [-494.916 -494.916 -494.916] (1.000)
Step: 72399, Reward: [-443.487 -443.487 -443.487] [0.0000], Avg: [-494.881 -494.881 -494.881] (1.000)
Step: 72449, Reward: [-367.72 -367.72 -367.72] [0.0000], Avg: [-494.793 -494.793 -494.793] (1.000)
Step: 72499, Reward: [-360.043 -360.043 -360.043] [0.0000], Avg: [-494.7 -494.7 -494.7] (1.000)
Step: 72549, Reward: [-356.495 -356.495 -356.495] [0.0000], Avg: [-494.605 -494.605 -494.605] (1.000)
Step: 72599, Reward: [-324.139 -324.139 -324.139] [0.0000], Avg: [-494.488 -494.488 -494.488] (1.000)
Step: 72649, Reward: [-436.556 -436.556 -436.556] [0.0000], Avg: [-494.448 -494.448 -494.448] (1.000)
Step: 72699, Reward: [-375.387 -375.387 -375.387] [0.0000], Avg: [-494.366 -494.366 -494.366] (1.000)
Step: 72749, Reward: [-366.462 -366.462 -366.462] [0.0000], Avg: [-494.278 -494.278 -494.278] (1.000)
Step: 72799, Reward: [-389.317 -389.317 -389.317] [0.0000], Avg: [-494.206 -494.206 -494.206] (1.000)
Step: 72849, Reward: [-372.425 -372.425 -372.425] [0.0000], Avg: [-494.122 -494.122 -494.122] (1.000)
Step: 72899, Reward: [-384.242 -384.242 -384.242] [0.0000], Avg: [-494.047 -494.047 -494.047] (1.000)
Step: 72949, Reward: [-488.088 -488.088 -488.088] [0.0000], Avg: [-494.043 -494.043 -494.043] (1.000)
Step: 72999, Reward: [-469.471 -469.471 -469.471] [0.0000], Avg: [-494.026 -494.026 -494.026] (1.000)
Step: 73049, Reward: [-412.06 -412.06 -412.06] [0.0000], Avg: [-493.97 -493.97 -493.97] (1.000)
Step: 73099, Reward: [-380.994 -380.994 -380.994] [0.0000], Avg: [-493.893 -493.893 -493.893] (1.000)
Step: 73149, Reward: [-382.291 -382.291 -382.291] [0.0000], Avg: [-493.816 -493.816 -493.816] (1.000)
Step: 73199, Reward: [-388.776 -388.776 -388.776] [0.0000], Avg: [-493.745 -493.745 -493.745] (1.000)
Step: 73249, Reward: [-386.717 -386.717 -386.717] [0.0000], Avg: [-493.671 -493.671 -493.671] (1.000)
Step: 73299, Reward: [-360.385 -360.385 -360.385] [0.0000], Avg: [-493.581 -493.581 -493.581] (1.000)
Step: 73349, Reward: [-411.997 -411.997 -411.997] [0.0000], Avg: [-493.525 -493.525 -493.525] (1.000)
Step: 73399, Reward: [-604.321 -604.321 -604.321] [0.0000], Avg: [-493.6 -493.6 -493.6] (1.000)
Step: 73449, Reward: [-420.209 -420.209 -420.209] [0.0000], Avg: [-493.55 -493.55 -493.55] (1.000)
Step: 73499, Reward: [-579.832 -579.832 -579.832] [0.0000], Avg: [-493.609 -493.609 -493.609] (1.000)
Step: 73549, Reward: [-436.322 -436.322 -436.322] [0.0000], Avg: [-493.57 -493.57 -493.57] (1.000)
Step: 73599, Reward: [-430.852 -430.852 -430.852] [0.0000], Avg: [-493.528 -493.528 -493.528] (1.000)
Step: 73649, Reward: [-366.579 -366.579 -366.579] [0.0000], Avg: [-493.441 -493.441 -493.441] (1.000)
Step: 73699, Reward: [-318.703 -318.703 -318.703] [0.0000], Avg: [-493.323 -493.323 -493.323] (1.000)
Step: 73749, Reward: [-321.091 -321.091 -321.091] [0.0000], Avg: [-493.206 -493.206 -493.206] (1.000)
Step: 73799, Reward: [-439.043 -439.043 -439.043] [0.0000], Avg: [-493.169 -493.169 -493.169] (1.000)
Step: 73849, Reward: [-454.641 -454.641 -454.641] [0.0000], Avg: [-493.143 -493.143 -493.143] (1.000)
Step: 73899, Reward: [-353.551 -353.551 -353.551] [0.0000], Avg: [-493.049 -493.049 -493.049] (1.000)
Step: 73949, Reward: [-336.509 -336.509 -336.509] [0.0000], Avg: [-492.943 -492.943 -492.943] (1.000)
Step: 73999, Reward: [-369.071 -369.071 -369.071] [0.0000], Avg: [-492.859 -492.859 -492.859] (1.000)
Step: 74049, Reward: [-406.491 -406.491 -406.491] [0.0000], Avg: [-492.801 -492.801 -492.801] (1.000)
Step: 74099, Reward: [-385.912 -385.912 -385.912] [0.0000], Avg: [-492.729 -492.729 -492.729] (1.000)
Step: 74149, Reward: [-579.321 -579.321 -579.321] [0.0000], Avg: [-492.787 -492.787 -492.787] (1.000)
Step: 74199, Reward: [-409.054 -409.054 -409.054] [0.0000], Avg: [-492.731 -492.731 -492.731] (1.000)
Step: 74249, Reward: [-395.581 -395.581 -395.581] [0.0000], Avg: [-492.665 -492.665 -492.665] (1.000)
Step: 74299, Reward: [-376.732 -376.732 -376.732] [0.0000], Avg: [-492.587 -492.587 -492.587] (1.000)
Step: 74349, Reward: [-417.253 -417.253 -417.253] [0.0000], Avg: [-492.537 -492.537 -492.537] (1.000)
Step: 74399, Reward: [-414.736 -414.736 -414.736] [0.0000], Avg: [-492.484 -492.484 -492.484] (1.000)
Step: 74449, Reward: [-314.857 -314.857 -314.857] [0.0000], Avg: [-492.365 -492.365 -492.365] (1.000)
Step: 74499, Reward: [-379.216 -379.216 -379.216] [0.0000], Avg: [-492.289 -492.289 -492.289] (1.000)
Step: 74549, Reward: [-486.765 -486.765 -486.765] [0.0000], Avg: [-492.286 -492.286 -492.286] (1.000)
Step: 74599, Reward: [-359.972 -359.972 -359.972] [0.0000], Avg: [-492.197 -492.197 -492.197] (1.000)
Step: 74649, Reward: [-394.178 -394.178 -394.178] [0.0000], Avg: [-492.131 -492.131 -492.131] (1.000)
Step: 74699, Reward: [-336.884 -336.884 -336.884] [0.0000], Avg: [-492.027 -492.027 -492.027] (1.000)
Step: 74749, Reward: [-339.492 -339.492 -339.492] [0.0000], Avg: [-491.925 -491.925 -491.925] (1.000)
Step: 74799, Reward: [-410.635 -410.635 -410.635] [0.0000], Avg: [-491.871 -491.871 -491.871] (1.000)
Step: 74849, Reward: [-424.442 -424.442 -424.442] [0.0000], Avg: [-491.826 -491.826 -491.826] (1.000)
Step: 74899, Reward: [-407.663 -407.663 -407.663] [0.0000], Avg: [-491.77 -491.77 -491.77] (1.000)
Step: 74949, Reward: [-352.371 -352.371 -352.371] [0.0000], Avg: [-491.677 -491.677 -491.677] (1.000)
Step: 74999, Reward: [-470.515 -470.515 -470.515] [0.0000], Avg: [-491.663 -491.663 -491.663] (1.000)
Step: 75049, Reward: [-316.192 -316.192 -316.192] [0.0000], Avg: [-491.546 -491.546 -491.546] (1.000)
Step: 75099, Reward: [-402.351 -402.351 -402.351] [0.0000], Avg: [-491.486 -491.486 -491.486] (1.000)
Step: 75149, Reward: [-425.587 -425.587 -425.587] [0.0000], Avg: [-491.442 -491.442 -491.442] (1.000)
Step: 75199, Reward: [-298.814 -298.814 -298.814] [0.0000], Avg: [-491.314 -491.314 -491.314] (1.000)
Step: 75249, Reward: [-473.22 -473.22 -473.22] [0.0000], Avg: [-491.302 -491.302 -491.302] (1.000)
Step: 75299, Reward: [-451.204 -451.204 -451.204] [0.0000], Avg: [-491.276 -491.276 -491.276] (1.000)
Step: 75349, Reward: [-434.615 -434.615 -434.615] [0.0000], Avg: [-491.238 -491.238 -491.238] (1.000)
Step: 75399, Reward: [-453.237 -453.237 -453.237] [0.0000], Avg: [-491.213 -491.213 -491.213] (1.000)
Step: 75449, Reward: [-350.999 -350.999 -350.999] [0.0000], Avg: [-491.12 -491.12 -491.12] (1.000)
Step: 75499, Reward: [-433.803 -433.803 -433.803] [0.0000], Avg: [-491.082 -491.082 -491.082] (1.000)
Step: 75549, Reward: [-422.174 -422.174 -422.174] [0.0000], Avg: [-491.036 -491.036 -491.036] (1.000)
Step: 75599, Reward: [-375.969 -375.969 -375.969] [0.0000], Avg: [-490.96 -490.96 -490.96] (1.000)
Step: 75649, Reward: [-414.648 -414.648 -414.648] [0.0000], Avg: [-490.91 -490.91 -490.91] (1.000)
Step: 75699, Reward: [-340.116 -340.116 -340.116] [0.0000], Avg: [-490.81 -490.81 -490.81] (1.000)
Step: 75749, Reward: [-382.763 -382.763 -382.763] [0.0000], Avg: [-490.739 -490.739 -490.739] (1.000)
Step: 75799, Reward: [-466.325 -466.325 -466.325] [0.0000], Avg: [-490.723 -490.723 -490.723] (1.000)
Step: 75849, Reward: [-324.971 -324.971 -324.971] [0.0000], Avg: [-490.614 -490.614 -490.614] (1.000)
Step: 75899, Reward: [-327.195 -327.195 -327.195] [0.0000], Avg: [-490.506 -490.506 -490.506] (1.000)
Step: 75949, Reward: [-428.243 -428.243 -428.243] [0.0000], Avg: [-490.465 -490.465 -490.465] (1.000)
Step: 75999, Reward: [-395.655 -395.655 -395.655] [0.0000], Avg: [-490.403 -490.403 -490.403] (1.000)
Step: 76049, Reward: [-485.748 -485.748 -485.748] [0.0000], Avg: [-490.4 -490.4 -490.4] (1.000)
Step: 76099, Reward: [-432.283 -432.283 -432.283] [0.0000], Avg: [-490.361 -490.361 -490.361] (1.000)
Step: 76149, Reward: [-626.313 -626.313 -626.313] [0.0000], Avg: [-490.451 -490.451 -490.451] (1.000)
Step: 76199, Reward: [-423.722 -423.722 -423.722] [0.0000], Avg: [-490.407 -490.407 -490.407] (1.000)
Step: 76249, Reward: [-421.687 -421.687 -421.687] [0.0000], Avg: [-490.362 -490.362 -490.362] (1.000)
Step: 76299, Reward: [-401.42 -401.42 -401.42] [0.0000], Avg: [-490.303 -490.303 -490.303] (1.000)
Step: 76349, Reward: [-357.023 -357.023 -357.023] [0.0000], Avg: [-490.216 -490.216 -490.216] (1.000)
Step: 76399, Reward: [-278.295 -278.295 -278.295] [0.0000], Avg: [-490.078 -490.078 -490.078] (1.000)
Step: 76449, Reward: [-356.258 -356.258 -356.258] [0.0000], Avg: [-489.99 -489.99 -489.99] (1.000)
Step: 76499, Reward: [-365.146 -365.146 -365.146] [0.0000], Avg: [-489.908 -489.908 -489.908] (1.000)
Step: 76549, Reward: [-433.687 -433.687 -433.687] [0.0000], Avg: [-489.872 -489.872 -489.872] (1.000)
Step: 76599, Reward: [-357.333 -357.333 -357.333] [0.0000], Avg: [-489.785 -489.785 -489.785] (1.000)
Step: 76649, Reward: [-366.33 -366.33 -366.33] [0.0000], Avg: [-489.705 -489.705 -489.705] (1.000)
Step: 76699, Reward: [-297.811 -297.811 -297.811] [0.0000], Avg: [-489.58 -489.58 -489.58] (1.000)
Step: 76749, Reward: [-337.618 -337.618 -337.618] [0.0000], Avg: [-489.481 -489.481 -489.481] (1.000)
Step: 76799, Reward: [-363.573 -363.573 -363.573] [0.0000], Avg: [-489.399 -489.399 -489.399] (1.000)
Step: 76849, Reward: [-429.027 -429.027 -429.027] [0.0000], Avg: [-489.359 -489.359 -489.359] (1.000)
Step: 76899, Reward: [-483.793 -483.793 -483.793] [0.0000], Avg: [-489.356 -489.356 -489.356] (1.000)
Step: 76949, Reward: [-428.623 -428.623 -428.623] [0.0000], Avg: [-489.316 -489.316 -489.316] (1.000)
Step: 76999, Reward: [-422.831 -422.831 -422.831] [0.0000], Avg: [-489.273 -489.273 -489.273] (1.000)
Step: 77049, Reward: [-464.566 -464.566 -464.566] [0.0000], Avg: [-489.257 -489.257 -489.257] (1.000)
Step: 77099, Reward: [-402.762 -402.762 -402.762] [0.0000], Avg: [-489.201 -489.201 -489.201] (1.000)
Step: 77149, Reward: [-432.827 -432.827 -432.827] [0.0000], Avg: [-489.164 -489.164 -489.164] (1.000)
Step: 77199, Reward: [-486.466 -486.466 -486.466] [0.0000], Avg: [-489.163 -489.163 -489.163] (1.000)
Step: 77249, Reward: [-374.422 -374.422 -374.422] [0.0000], Avg: [-489.088 -489.088 -489.088] (1.000)
Step: 77299, Reward: [-406.25 -406.25 -406.25] [0.0000], Avg: [-489.035 -489.035 -489.035] (1.000)
Step: 77349, Reward: [-477.853 -477.853 -477.853] [0.0000], Avg: [-489.028 -489.028 -489.028] (1.000)
Step: 77399, Reward: [-313.137 -313.137 -313.137] [0.0000], Avg: [-488.914 -488.914 -488.914] (1.000)
Step: 77449, Reward: [-433.439 -433.439 -433.439] [0.0000], Avg: [-488.878 -488.878 -488.878] (1.000)
Step: 77499, Reward: [-378.344 -378.344 -378.344] [0.0000], Avg: [-488.807 -488.807 -488.807] (1.000)
Step: 77549, Reward: [-320.82 -320.82 -320.82] [0.0000], Avg: [-488.698 -488.698 -488.698] (1.000)
Step: 77599, Reward: [-355.682 -355.682 -355.682] [0.0000], Avg: [-488.613 -488.613 -488.613] (1.000)
Step: 77649, Reward: [-407.558 -407.558 -407.558] [0.0000], Avg: [-488.561 -488.561 -488.561] (1.000)
Step: 77699, Reward: [-358.898 -358.898 -358.898] [0.0000], Avg: [-488.477 -488.477 -488.477] (1.000)
Step: 77749, Reward: [-390.593 -390.593 -390.593] [0.0000], Avg: [-488.414 -488.414 -488.414] (1.000)
Step: 77799, Reward: [-437.424 -437.424 -437.424] [0.0000], Avg: [-488.381 -488.381 -488.381] (1.000)
Step: 77849, Reward: [-338.287 -338.287 -338.287] [0.0000], Avg: [-488.285 -488.285 -488.285] (1.000)
Step: 77899, Reward: [-411.125 -411.125 -411.125] [0.0000], Avg: [-488.236 -488.236 -488.236] (1.000)
Step: 77949, Reward: [-331.229 -331.229 -331.229] [0.0000], Avg: [-488.135 -488.135 -488.135] (1.000)
Step: 77999, Reward: [-352.129 -352.129 -352.129] [0.0000], Avg: [-488.048 -488.048 -488.048] (1.000)
Step: 78049, Reward: [-458.024 -458.024 -458.024] [0.0000], Avg: [-488.028 -488.028 -488.028] (1.000)
Step: 78099, Reward: [-547.273 -547.273 -547.273] [0.0000], Avg: [-488.066 -488.066 -488.066] (1.000)
Step: 78149, Reward: [-276.532 -276.532 -276.532] [0.0000], Avg: [-487.931 -487.931 -487.931] (1.000)
Step: 78199, Reward: [-393.919 -393.919 -393.919] [0.0000], Avg: [-487.871 -487.871 -487.871] (1.000)
Step: 78249, Reward: [-452.894 -452.894 -452.894] [0.0000], Avg: [-487.849 -487.849 -487.849] (1.000)
Step: 78299, Reward: [-407.598 -407.598 -407.598] [0.0000], Avg: [-487.797 -487.797 -487.797] (1.000)
Step: 78349, Reward: [-327.309 -327.309 -327.309] [0.0000], Avg: [-487.695 -487.695 -487.695] (1.000)
Step: 78399, Reward: [-367.698 -367.698 -367.698] [0.0000], Avg: [-487.618 -487.618 -487.618] (1.000)
Step: 78449, Reward: [-484.377 -484.377 -484.377] [0.0000], Avg: [-487.616 -487.616 -487.616] (1.000)
Step: 78499, Reward: [-352.563 -352.563 -352.563] [0.0000], Avg: [-487.53 -487.53 -487.53] (1.000)
Step: 78549, Reward: [-411.543 -411.543 -411.543] [0.0000], Avg: [-487.482 -487.482 -487.482] (1.000)
Step: 78599, Reward: [-362.148 -362.148 -362.148] [0.0000], Avg: [-487.402 -487.402 -487.402] (1.000)
Step: 78649, Reward: [-374.17 -374.17 -374.17] [0.0000], Avg: [-487.33 -487.33 -487.33] (1.000)
Step: 78699, Reward: [-422.568 -422.568 -422.568] [0.0000], Avg: [-487.289 -487.289 -487.289] (1.000)
Step: 78749, Reward: [-311.268 -311.268 -311.268] [0.0000], Avg: [-487.177 -487.177 -487.177] (1.000)
Step: 78799, Reward: [-316.045 -316.045 -316.045] [0.0000], Avg: [-487.069 -487.069 -487.069] (1.000)
Step: 78849, Reward: [-505.808 -505.808 -505.808] [0.0000], Avg: [-487.081 -487.081 -487.081] (1.000)
Step: 78899, Reward: [-379.03 -379.03 -379.03] [0.0000], Avg: [-487.012 -487.012 -487.012] (1.000)
Step: 78949, Reward: [-320.011 -320.011 -320.011] [0.0000], Avg: [-486.906 -486.906 -486.906] (1.000)
Step: 78999, Reward: [-394.711 -394.711 -394.711] [0.0000], Avg: [-486.848 -486.848 -486.848] (1.000)
Step: 79049, Reward: [-473.852 -473.852 -473.852] [0.0000], Avg: [-486.84 -486.84 -486.84] (1.000)
Step: 79099, Reward: [-368.027 -368.027 -368.027] [0.0000], Avg: [-486.765 -486.765 -486.765] (1.000)
Step: 79149, Reward: [-486.175 -486.175 -486.175] [0.0000], Avg: [-486.764 -486.764 -486.764] (1.000)
Step: 79199, Reward: [-338.418 -338.418 -338.418] [0.0000], Avg: [-486.671 -486.671 -486.671] (1.000)
Step: 79249, Reward: [-403.148 -403.148 -403.148] [0.0000], Avg: [-486.618 -486.618 -486.618] (1.000)
Step: 79299, Reward: [-298.673 -298.673 -298.673] [0.0000], Avg: [-486.499 -486.499 -486.499] (1.000)
Step: 79349, Reward: [-497.158 -497.158 -497.158] [0.0000], Avg: [-486.506 -486.506 -486.506] (1.000)
Step: 79399, Reward: [-431.317 -431.317 -431.317] [0.0000], Avg: [-486.471 -486.471 -486.471] (1.000)
Step: 79449, Reward: [-450.155 -450.155 -450.155] [0.0000], Avg: [-486.449 -486.449 -486.449] (1.000)
Step: 79499, Reward: [-501.56 -501.56 -501.56] [0.0000], Avg: [-486.458 -486.458 -486.458] (1.000)
Step: 79549, Reward: [-410.586 -410.586 -410.586] [0.0000], Avg: [-486.41 -486.41 -486.41] (1.000)
Step: 79599, Reward: [-395.915 -395.915 -395.915] [0.0000], Avg: [-486.353 -486.353 -486.353] (1.000)
Step: 79649, Reward: [-425.751 -425.751 -425.751] [0.0000], Avg: [-486.315 -486.315 -486.315] (1.000)
Step: 79699, Reward: [-479.883 -479.883 -479.883] [0.0000], Avg: [-486.311 -486.311 -486.311] (1.000)
Step: 79749, Reward: [-348.866 -348.866 -348.866] [0.0000], Avg: [-486.225 -486.225 -486.225] (1.000)
Step: 79799, Reward: [-342.323 -342.323 -342.323] [0.0000], Avg: [-486.135 -486.135 -486.135] (1.000)
Step: 79849, Reward: [-419.897 -419.897 -419.897] [0.0000], Avg: [-486.094 -486.094 -486.094] (1.000)
Step: 79899, Reward: [-350.791 -350.791 -350.791] [0.0000], Avg: [-486.009 -486.009 -486.009] (1.000)
Step: 79949, Reward: [-386.764 -386.764 -386.764] [0.0000], Avg: [-485.947 -485.947 -485.947] (1.000)
Step: 79999, Reward: [-329.754 -329.754 -329.754] [0.0000], Avg: [-485.849 -485.849 -485.849] (1.000)
Step: 80049, Reward: [-420.299 -420.299 -420.299] [0.0000], Avg: [-485.808 -485.808 -485.808] (1.000)
Step: 80099, Reward: [-452.667 -452.667 -452.667] [0.0000], Avg: [-485.788 -485.788 -485.788] (1.000)
Step: 80149, Reward: [-491.199 -491.199 -491.199] [0.0000], Avg: [-485.791 -485.791 -485.791] (1.000)
Step: 80199, Reward: [-294.697 -294.697 -294.697] [0.0000], Avg: [-485.672 -485.672 -485.672] (1.000)
Step: 80249, Reward: [-339.48 -339.48 -339.48] [0.0000], Avg: [-485.581 -485.581 -485.581] (1.000)
Step: 80299, Reward: [-492.723 -492.723 -492.723] [0.0000], Avg: [-485.585 -485.585 -485.585] (1.000)
Step: 80349, Reward: [-328.122 -328.122 -328.122] [0.0000], Avg: [-485.487 -485.487 -485.487] (1.000)
Step: 80399, Reward: [-419.578 -419.578 -419.578] [0.0000], Avg: [-485.446 -485.446 -485.446] (1.000)
Step: 80449, Reward: [-430.987 -430.987 -430.987] [0.0000], Avg: [-485.412 -485.412 -485.412] (1.000)
Step: 80499, Reward: [-522.118 -522.118 -522.118] [0.0000], Avg: [-485.435 -485.435 -485.435] (1.000)
Step: 80549, Reward: [-482.984 -482.984 -482.984] [0.0000], Avg: [-485.434 -485.434 -485.434] (1.000)
Step: 80599, Reward: [-319.884 -319.884 -319.884] [0.0000], Avg: [-485.331 -485.331 -485.331] (1.000)
Step: 80649, Reward: [-387.572 -387.572 -387.572] [0.0000], Avg: [-485.27 -485.27 -485.27] (1.000)
Step: 80699, Reward: [-458.733 -458.733 -458.733] [0.0000], Avg: [-485.254 -485.254 -485.254] (1.000)
Step: 80749, Reward: [-373.143 -373.143 -373.143] [0.0000], Avg: [-485.185 -485.185 -485.185] (1.000)
Step: 80799, Reward: [-382.496 -382.496 -382.496] [0.0000], Avg: [-485.121 -485.121 -485.121] (1.000)
Step: 80849, Reward: [-393.91 -393.91 -393.91] [0.0000], Avg: [-485.065 -485.065 -485.065] (1.000)
Step: 80899, Reward: [-301.298 -301.298 -301.298] [0.0000], Avg: [-484.951 -484.951 -484.951] (1.000)
Step: 80949, Reward: [-361.804 -361.804 -361.804] [0.0000], Avg: [-484.875 -484.875 -484.875] (1.000)
Step: 80999, Reward: [-385.846 -385.846 -385.846] [0.0000], Avg: [-484.814 -484.814 -484.814] (1.000)
Step: 81049, Reward: [-362.963 -362.963 -362.963] [0.0000], Avg: [-484.739 -484.739 -484.739] (1.000)
Step: 81099, Reward: [-324.682 -324.682 -324.682] [0.0000], Avg: [-484.64 -484.64 -484.64] (1.000)
Step: 81149, Reward: [-344.751 -344.751 -344.751] [0.0000], Avg: [-484.554 -484.554 -484.554] (1.000)
Step: 81199, Reward: [-327.057 -327.057 -327.057] [0.0000], Avg: [-484.457 -484.457 -484.457] (1.000)
Step: 81249, Reward: [-380.165 -380.165 -380.165] [0.0000], Avg: [-484.393 -484.393 -484.393] (1.000)
Step: 81299, Reward: [-401.372 -401.372 -401.372] [0.0000], Avg: [-484.342 -484.342 -484.342] (1.000)
Step: 81349, Reward: [-454.274 -454.274 -454.274] [0.0000], Avg: [-484.323 -484.323 -484.323] (1.000)
Step: 81399, Reward: [-354.075 -354.075 -354.075] [0.0000], Avg: [-484.243 -484.243 -484.243] (1.000)
Step: 81449, Reward: [-389.752 -389.752 -389.752] [0.0000], Avg: [-484.185 -484.185 -484.185] (1.000)
Step: 81499, Reward: [-334.777 -334.777 -334.777] [0.0000], Avg: [-484.093 -484.093 -484.093] (1.000)
Step: 81549, Reward: [-472.171 -472.171 -472.171] [0.0000], Avg: [-484.086 -484.086 -484.086] (1.000)
Step: 81599, Reward: [-324.845 -324.845 -324.845] [0.0000], Avg: [-483.988 -483.988 -483.988] (1.000)
Step: 81649, Reward: [-614.224 -614.224 -614.224] [0.0000], Avg: [-484.068 -484.068 -484.068] (1.000)
Step: 81699, Reward: [-559.748 -559.748 -559.748] [0.0000], Avg: [-484.115 -484.115 -484.115] (1.000)
Step: 81749, Reward: [-435.332 -435.332 -435.332] [0.0000], Avg: [-484.085 -484.085 -484.085] (1.000)
Step: 81799, Reward: [-409.495 -409.495 -409.495] [0.0000], Avg: [-484.039 -484.039 -484.039] (1.000)
Step: 81849, Reward: [-347.987 -347.987 -347.987] [0.0000], Avg: [-483.956 -483.956 -483.956] (1.000)
Step: 81899, Reward: [-473.299 -473.299 -473.299] [0.0000], Avg: [-483.95 -483.95 -483.95] (1.000)
Step: 81949, Reward: [-401.006 -401.006 -401.006] [0.0000], Avg: [-483.899 -483.899 -483.899] (1.000)
Step: 81999, Reward: [-414.964 -414.964 -414.964] [0.0000], Avg: [-483.857 -483.857 -483.857] (1.000)
Step: 82049, Reward: [-331.226 -331.226 -331.226] [0.0000], Avg: [-483.764 -483.764 -483.764] (1.000)
Step: 82099, Reward: [-406.743 -406.743 -406.743] [0.0000], Avg: [-483.717 -483.717 -483.717] (1.000)
Step: 82149, Reward: [-401.544 -401.544 -401.544] [0.0000], Avg: [-483.667 -483.667 -483.667] (1.000)
Step: 82199, Reward: [-507.319 -507.319 -507.319] [0.0000], Avg: [-483.681 -483.681 -483.681] (1.000)
Step: 82249, Reward: [-394.679 -394.679 -394.679] [0.0000], Avg: [-483.627 -483.627 -483.627] (1.000)
Step: 82299, Reward: [-340.54 -340.54 -340.54] [0.0000], Avg: [-483.54 -483.54 -483.54] (1.000)
Step: 82349, Reward: [-429.4 -429.4 -429.4] [0.0000], Avg: [-483.507 -483.507 -483.507] (1.000)
Step: 82399, Reward: [-322.064 -322.064 -322.064] [0.0000], Avg: [-483.409 -483.409 -483.409] (1.000)
Step: 82449, Reward: [-407.569 -407.569 -407.569] [0.0000], Avg: [-483.363 -483.363 -483.363] (1.000)
Step: 82499, Reward: [-311.466 -311.466 -311.466] [0.0000], Avg: [-483.259 -483.259 -483.259] (1.000)
Step: 82549, Reward: [-369.71 -369.71 -369.71] [0.0000], Avg: [-483.191 -483.191 -483.191] (1.000)
Step: 82599, Reward: [-379.479 -379.479 -379.479] [0.0000], Avg: [-483.128 -483.128 -483.128] (1.000)
Step: 82649, Reward: [-337.806 -337.806 -337.806] [0.0000], Avg: [-483.04 -483.04 -483.04] (1.000)
Step: 82699, Reward: [-351.497 -351.497 -351.497] [0.0000], Avg: [-482.96 -482.96 -482.96] (1.000)
Step: 82749, Reward: [-477.486 -477.486 -477.486] [0.0000], Avg: [-482.957 -482.957 -482.957] (1.000)
Step: 82799, Reward: [-431.918 -431.918 -431.918] [0.0000], Avg: [-482.926 -482.926 -482.926] (1.000)
Step: 82849, Reward: [-311.831 -311.831 -311.831] [0.0000], Avg: [-482.823 -482.823 -482.823] (1.000)
Step: 82899, Reward: [-417.833 -417.833 -417.833] [0.0000], Avg: [-482.784 -482.784 -482.784] (1.000)
Step: 82949, Reward: [-396.544 -396.544 -396.544] [0.0000], Avg: [-482.732 -482.732 -482.732] (1.000)
Step: 82999, Reward: [-441.302 -441.302 -441.302] [0.0000], Avg: [-482.707 -482.707 -482.707] (1.000)
Step: 83049, Reward: [-552.634 -552.634 -552.634] [0.0000], Avg: [-482.749 -482.749 -482.749] (1.000)
Step: 83099, Reward: [-408.272 -408.272 -408.272] [0.0000], Avg: [-482.704 -482.704 -482.704] (1.000)
Step: 83149, Reward: [-325.793 -325.793 -325.793] [0.0000], Avg: [-482.61 -482.61 -482.61] (1.000)
Step: 83199, Reward: [-487.392 -487.392 -487.392] [0.0000], Avg: [-482.613 -482.613 -482.613] (1.000)
Step: 83249, Reward: [-437.404 -437.404 -437.404] [0.0000], Avg: [-482.585 -482.585 -482.585] (1.000)
Step: 83299, Reward: [-442.585 -442.585 -442.585] [0.0000], Avg: [-482.561 -482.561 -482.561] (1.000)
Step: 83349, Reward: [-404.774 -404.774 -404.774] [0.0000], Avg: [-482.515 -482.515 -482.515] (1.000)
Step: 83399, Reward: [-375.361 -375.361 -375.361] [0.0000], Avg: [-482.451 -482.451 -482.451] (1.000)
Step: 83449, Reward: [-414.098 -414.098 -414.098] [0.0000], Avg: [-482.41 -482.41 -482.41] (1.000)
Step: 83499, Reward: [-394.469 -394.469 -394.469] [0.0000], Avg: [-482.357 -482.357 -482.357] (1.000)
Step: 83549, Reward: [-399.74 -399.74 -399.74] [0.0000], Avg: [-482.307 -482.307 -482.307] (1.000)
Step: 83599, Reward: [-424.296 -424.296 -424.296] [0.0000], Avg: [-482.273 -482.273 -482.273] (1.000)
Step: 83649, Reward: [-405.9 -405.9 -405.9] [0.0000], Avg: [-482.227 -482.227 -482.227] (1.000)
Step: 83699, Reward: [-315.28 -315.28 -315.28] [0.0000], Avg: [-482.127 -482.127 -482.127] (1.000)
Step: 83749, Reward: [-460.922 -460.922 -460.922] [0.0000], Avg: [-482.115 -482.115 -482.115] (1.000)
Step: 83799, Reward: [-378.431 -378.431 -378.431] [0.0000], Avg: [-482.053 -482.053 -482.053] (1.000)
Step: 83849, Reward: [-444.805 -444.805 -444.805] [0.0000], Avg: [-482.031 -482.031 -482.031] (1.000)
Step: 83899, Reward: [-284.271 -284.271 -284.271] [0.0000], Avg: [-481.913 -481.913 -481.913] (1.000)
Step: 83949, Reward: [-358.052 -358.052 -358.052] [0.0000], Avg: [-481.839 -481.839 -481.839] (1.000)
Step: 83999, Reward: [-334.602 -334.602 -334.602] [0.0000], Avg: [-481.751 -481.751 -481.751] (1.000)
Step: 84049, Reward: [-327.518 -327.518 -327.518] [0.0000], Avg: [-481.66 -481.66 -481.66] (1.000)
Step: 84099, Reward: [-384.108 -384.108 -384.108] [0.0000], Avg: [-481.602 -481.602 -481.602] (1.000)
Step: 84149, Reward: [-320.205 -320.205 -320.205] [0.0000], Avg: [-481.506 -481.506 -481.506] (1.000)
Step: 84199, Reward: [-378.771 -378.771 -378.771] [0.0000], Avg: [-481.445 -481.445 -481.445] (1.000)
Step: 84249, Reward: [-313.39 -313.39 -313.39] [0.0000], Avg: [-481.345 -481.345 -481.345] (1.000)
Step: 84299, Reward: [-422.934 -422.934 -422.934] [0.0000], Avg: [-481.31 -481.31 -481.31] (1.000)
Step: 84349, Reward: [-317.134 -317.134 -317.134] [0.0000], Avg: [-481.213 -481.213 -481.213] (1.000)
Step: 84399, Reward: [-391.663 -391.663 -391.663] [0.0000], Avg: [-481.16 -481.16 -481.16] (1.000)
Step: 84449, Reward: [-370.989 -370.989 -370.989] [0.0000], Avg: [-481.095 -481.095 -481.095] (1.000)
Step: 84499, Reward: [-370.487 -370.487 -370.487] [0.0000], Avg: [-481.029 -481.029 -481.029] (1.000)
Step: 84549, Reward: [-389.829 -389.829 -389.829] [0.0000], Avg: [-480.975 -480.975 -480.975] (1.000)
Step: 84599, Reward: [-371.356 -371.356 -371.356] [0.0000], Avg: [-480.911 -480.911 -480.911] (1.000)
Step: 84649, Reward: [-472.977 -472.977 -472.977] [0.0000], Avg: [-480.906 -480.906 -480.906] (1.000)
Step: 84699, Reward: [-312.478 -312.478 -312.478] [0.0000], Avg: [-480.806 -480.806 -480.806] (1.000)
Step: 84749, Reward: [-499.425 -499.425 -499.425] [0.0000], Avg: [-480.817 -480.817 -480.817] (1.000)
Step: 84799, Reward: [-366.869 -366.869 -366.869] [0.0000], Avg: [-480.75 -480.75 -480.75] (1.000)
Step: 84849, Reward: [-484.23 -484.23 -484.23] [0.0000], Avg: [-480.752 -480.752 -480.752] (1.000)
Step: 84899, Reward: [-570.413 -570.413 -570.413] [0.0000], Avg: [-480.805 -480.805 -480.805] (1.000)
Step: 84949, Reward: [-438.005 -438.005 -438.005] [0.0000], Avg: [-480.78 -480.78 -480.78] (1.000)
Step: 84999, Reward: [-336.003 -336.003 -336.003] [0.0000], Avg: [-480.695 -480.695 -480.695] (1.000)
Step: 85049, Reward: [-394.161 -394.161 -394.161] [0.0000], Avg: [-480.644 -480.644 -480.644] (1.000)
Step: 85099, Reward: [-480.149 -480.149 -480.149] [0.0000], Avg: [-480.644 -480.644 -480.644] (1.000)
Step: 85149, Reward: [-440.086 -440.086 -440.086] [0.0000], Avg: [-480.62 -480.62 -480.62] (1.000)
Step: 85199, Reward: [-389.545 -389.545 -389.545] [0.0000], Avg: [-480.566 -480.566 -480.566] (1.000)
Step: 85249, Reward: [-319.69 -319.69 -319.69] [0.0000], Avg: [-480.472 -480.472 -480.472] (1.000)
Step: 85299, Reward: [-362.371 -362.371 -362.371] [0.0000], Avg: [-480.403 -480.403 -480.403] (1.000)
Step: 85349, Reward: [-434.691 -434.691 -434.691] [0.0000], Avg: [-480.376 -480.376 -480.376] (1.000)
Step: 85399, Reward: [-445.439 -445.439 -445.439] [0.0000], Avg: [-480.356 -480.356 -480.356] (1.000)
Step: 85449, Reward: [-321.485 -321.485 -321.485] [0.0000], Avg: [-480.263 -480.263 -480.263] (1.000)
Step: 85499, Reward: [-454.22 -454.22 -454.22] [0.0000], Avg: [-480.247 -480.247 -480.247] (1.000)
Step: 85549, Reward: [-398.26 -398.26 -398.26] [0.0000], Avg: [-480.199 -480.199 -480.199] (1.000)
Step: 85599, Reward: [-396.761 -396.761 -396.761] [0.0000], Avg: [-480.151 -480.151 -480.151] (1.000)
Step: 85649, Reward: [-325.984 -325.984 -325.984] [0.0000], Avg: [-480.061 -480.061 -480.061] (1.000)
Step: 85699, Reward: [-290.927 -290.927 -290.927] [0.0000], Avg: [-479.95 -479.95 -479.95] (1.000)
Step: 85749, Reward: [-444.29 -444.29 -444.29] [0.0000], Avg: [-479.93 -479.93 -479.93] (1.000)
Step: 85799, Reward: [-330.769 -330.769 -330.769] [0.0000], Avg: [-479.843 -479.843 -479.843] (1.000)
Step: 85849, Reward: [-426.25 -426.25 -426.25] [0.0000], Avg: [-479.811 -479.811 -479.811] (1.000)
Step: 85899, Reward: [-436.305 -436.305 -436.305] [0.0000], Avg: [-479.786 -479.786 -479.786] (1.000)
Step: 85949, Reward: [-317.665 -317.665 -317.665] [0.0000], Avg: [-479.692 -479.692 -479.692] (1.000)
Step: 85999, Reward: [-314.918 -314.918 -314.918] [0.0000], Avg: [-479.596 -479.596 -479.596] (1.000)
Step: 86049, Reward: [-557.799 -557.799 -557.799] [0.0000], Avg: [-479.641 -479.641 -479.641] (1.000)
Step: 86099, Reward: [-457.63 -457.63 -457.63] [0.0000], Avg: [-479.629 -479.629 -479.629] (1.000)
Step: 86149, Reward: [-357.612 -357.612 -357.612] [0.0000], Avg: [-479.558 -479.558 -479.558] (1.000)
Step: 86199, Reward: [-389.412 -389.412 -389.412] [0.0000], Avg: [-479.506 -479.506 -479.506] (1.000)
Step: 86249, Reward: [-361.066 -361.066 -361.066] [0.0000], Avg: [-479.437 -479.437 -479.437] (1.000)
Step: 86299, Reward: [-425.149 -425.149 -425.149] [0.0000], Avg: [-479.405 -479.405 -479.405] (1.000)
Step: 86349, Reward: [-411.31 -411.31 -411.31] [0.0000], Avg: [-479.366 -479.366 -479.366] (1.000)
Step: 86399, Reward: [-415.221 -415.221 -415.221] [0.0000], Avg: [-479.329 -479.329 -479.329] (1.000)
Step: 86449, Reward: [-325.875 -325.875 -325.875] [0.0000], Avg: [-479.24 -479.24 -479.24] (1.000)
Step: 86499, Reward: [-418.465 -418.465 -418.465] [0.0000], Avg: [-479.205 -479.205 -479.205] (1.000)
Step: 86549, Reward: [-386.051 -386.051 -386.051] [0.0000], Avg: [-479.151 -479.151 -479.151] (1.000)
Step: 86599, Reward: [-467.655 -467.655 -467.655] [0.0000], Avg: [-479.145 -479.145 -479.145] (1.000)
Step: 86649, Reward: [-327.447 -327.447 -327.447] [0.0000], Avg: [-479.057 -479.057 -479.057] (1.000)
Step: 86699, Reward: [-432.624 -432.624 -432.624] [0.0000], Avg: [-479.03 -479.03 -479.03] (1.000)
Step: 86749, Reward: [-434.454 -434.454 -434.454] [0.0000], Avg: [-479.005 -479.005 -479.005] (1.000)
Step: 86799, Reward: [-336.057 -336.057 -336.057] [0.0000], Avg: [-478.922 -478.922 -478.922] (1.000)
Step: 86849, Reward: [-451.096 -451.096 -451.096] [0.0000], Avg: [-478.906 -478.906 -478.906] (1.000)
Step: 86899, Reward: [-428.607 -428.607 -428.607] [0.0000], Avg: [-478.877 -478.877 -478.877] (1.000)
Step: 86949, Reward: [-399.767 -399.767 -399.767] [0.0000], Avg: [-478.832 -478.832 -478.832] (1.000)
Step: 86999, Reward: [-406.514 -406.514 -406.514] [0.0000], Avg: [-478.79 -478.79 -478.79] (1.000)
Step: 87049, Reward: [-397.726 -397.726 -397.726] [0.0000], Avg: [-478.744 -478.744 -478.744] (1.000)
Step: 87099, Reward: [-350.139 -350.139 -350.139] [0.0000], Avg: [-478.67 -478.67 -478.67] (1.000)
Step: 87149, Reward: [-353.791 -353.791 -353.791] [0.0000], Avg: [-478.598 -478.598 -478.598] (1.000)
Step: 87199, Reward: [-411.5 -411.5 -411.5] [0.0000], Avg: [-478.56 -478.56 -478.56] (1.000)
Step: 87249, Reward: [-390.895 -390.895 -390.895] [0.0000], Avg: [-478.509 -478.509 -478.509] (1.000)
Step: 87299, Reward: [-377.391 -377.391 -377.391] [0.0000], Avg: [-478.451 -478.451 -478.451] (1.000)
Step: 87349, Reward: [-404.875 -404.875 -404.875] [0.0000], Avg: [-478.409 -478.409 -478.409] (1.000)
Step: 87399, Reward: [-478.676 -478.676 -478.676] [0.0000], Avg: [-478.41 -478.41 -478.41] (1.000)
Step: 87449, Reward: [-318.75 -318.75 -318.75] [0.0000], Avg: [-478.318 -478.318 -478.318] (1.000)
Step: 87499, Reward: [-362.13 -362.13 -362.13] [0.0000], Avg: [-478.252 -478.252 -478.252] (1.000)
Step: 87549, Reward: [-313.514 -313.514 -313.514] [0.0000], Avg: [-478.158 -478.158 -478.158] (1.000)
Step: 87599, Reward: [-445.036 -445.036 -445.036] [0.0000], Avg: [-478.139 -478.139 -478.139] (1.000)
Step: 87649, Reward: [-530.3 -530.3 -530.3] [0.0000], Avg: [-478.169 -478.169 -478.169] (1.000)
Step: 87699, Reward: [-427.692 -427.692 -427.692] [0.0000], Avg: [-478.14 -478.14 -478.14] (1.000)
Step: 87749, Reward: [-487.783 -487.783 -487.783] [0.0000], Avg: [-478.145 -478.145 -478.145] (1.000)
Step: 87799, Reward: [-490.784 -490.784 -490.784] [0.0000], Avg: [-478.153 -478.153 -478.153] (1.000)
Step: 87849, Reward: [-415.56 -415.56 -415.56] [0.0000], Avg: [-478.117 -478.117 -478.117] (1.000)
Step: 87899, Reward: [-291.725 -291.725 -291.725] [0.0000], Avg: [-478.011 -478.011 -478.011] (1.000)
Step: 87949, Reward: [-317.075 -317.075 -317.075] [0.0000], Avg: [-477.919 -477.919 -477.919] (1.000)
Step: 87999, Reward: [-279.633 -279.633 -279.633] [0.0000], Avg: [-477.807 -477.807 -477.807] (1.000)
Step: 88049, Reward: [-444.458 -444.458 -444.458] [0.0000], Avg: [-477.788 -477.788 -477.788] (1.000)
Step: 88099, Reward: [-509.074 -509.074 -509.074] [0.0000], Avg: [-477.806 -477.806 -477.806] (1.000)
Step: 88149, Reward: [-373.122 -373.122 -373.122] [0.0000], Avg: [-477.746 -477.746 -477.746] (1.000)
Step: 88199, Reward: [-419.634 -419.634 -419.634] [0.0000], Avg: [-477.713 -477.713 -477.713] (1.000)
Step: 88249, Reward: [-310.299 -310.299 -310.299] [0.0000], Avg: [-477.618 -477.618 -477.618] (1.000)
Step: 88299, Reward: [-385.988 -385.988 -385.988] [0.0000], Avg: [-477.566 -477.566 -477.566] (1.000)
Step: 88349, Reward: [-348.172 -348.172 -348.172] [0.0000], Avg: [-477.493 -477.493 -477.493] (1.000)
Step: 88399, Reward: [-350.136 -350.136 -350.136] [0.0000], Avg: [-477.421 -477.421 -477.421] (1.000)
Step: 88449, Reward: [-311.482 -311.482 -311.482] [0.0000], Avg: [-477.327 -477.327 -477.327] (1.000)
Step: 88499, Reward: [-369.168 -369.168 -369.168] [0.0000], Avg: [-477.266 -477.266 -477.266] (1.000)
Step: 88549, Reward: [-387.434 -387.434 -387.434] [0.0000], Avg: [-477.216 -477.216 -477.216] (1.000)
Step: 88599, Reward: [-421.049 -421.049 -421.049] [0.0000], Avg: [-477.184 -477.184 -477.184] (1.000)
Step: 88649, Reward: [-463.879 -463.879 -463.879] [0.0000], Avg: [-477.176 -477.176 -477.176] (1.000)
Step: 88699, Reward: [-284.622 -284.622 -284.622] [0.0000], Avg: [-477.068 -477.068 -477.068] (1.000)
Step: 88749, Reward: [-308.779 -308.779 -308.779] [0.0000], Avg: [-476.973 -476.973 -476.973] (1.000)
Step: 88799, Reward: [-465.328 -465.328 -465.328] [0.0000], Avg: [-476.966 -476.966 -476.966] (1.000)
Step: 88849, Reward: [-292.7 -292.7 -292.7] [0.0000], Avg: [-476.863 -476.863 -476.863] (1.000)
Step: 88899, Reward: [-339.043 -339.043 -339.043] [0.0000], Avg: [-476.785 -476.785 -476.785] (1.000)
Step: 88949, Reward: [-378.559 -378.559 -378.559] [0.0000], Avg: [-476.73 -476.73 -476.73] (1.000)
Step: 88999, Reward: [-411.034 -411.034 -411.034] [0.0000], Avg: [-476.693 -476.693 -476.693] (1.000)
Step: 89049, Reward: [-415.721 -415.721 -415.721] [0.0000], Avg: [-476.659 -476.659 -476.659] (1.000)
Step: 89099, Reward: [-467.455 -467.455 -467.455] [0.0000], Avg: [-476.654 -476.654 -476.654] (1.000)
Step: 89149, Reward: [-328.529 -328.529 -328.529] [0.0000], Avg: [-476.571 -476.571 -476.571] (1.000)
Step: 89199, Reward: [-372.036 -372.036 -372.036] [0.0000], Avg: [-476.512 -476.512 -476.512] (1.000)
Step: 89249, Reward: [-429.227 -429.227 -429.227] [0.0000], Avg: [-476.486 -476.486 -476.486] (1.000)
Step: 89299, Reward: [-416.217 -416.217 -416.217] [0.0000], Avg: [-476.452 -476.452 -476.452] (1.000)
Step: 89349, Reward: [-364.52 -364.52 -364.52] [0.0000], Avg: [-476.389 -476.389 -476.389] (1.000)
Step: 89399, Reward: [-365.578 -365.578 -365.578] [0.0000], Avg: [-476.327 -476.327 -476.327] (1.000)
Step: 89449, Reward: [-456.988 -456.988 -456.988] [0.0000], Avg: [-476.316 -476.316 -476.316] (1.000)
Step: 89499, Reward: [-422.011 -422.011 -422.011] [0.0000], Avg: [-476.286 -476.286 -476.286] (1.000)
Step: 89549, Reward: [-432.572 -432.572 -432.572] [0.0000], Avg: [-476.262 -476.262 -476.262] (1.000)
Step: 89599, Reward: [-279.059 -279.059 -279.059] [0.0000], Avg: [-476.152 -476.152 -476.152] (1.000)
Step: 89649, Reward: [-434.38 -434.38 -434.38] [0.0000], Avg: [-476.128 -476.128 -476.128] (1.000)
Step: 89699, Reward: [-459.178 -459.178 -459.178] [0.0000], Avg: [-476.119 -476.119 -476.119] (1.000)
Step: 89749, Reward: [-416.266 -416.266 -416.266] [0.0000], Avg: [-476.086 -476.086 -476.086] (1.000)
Step: 89799, Reward: [-370.147 -370.147 -370.147] [0.0000], Avg: [-476.027 -476.027 -476.027] (1.000)
Step: 89849, Reward: [-356.773 -356.773 -356.773] [0.0000], Avg: [-475.96 -475.96 -475.96] (1.000)
Step: 89899, Reward: [-395.194 -395.194 -395.194] [0.0000], Avg: [-475.915 -475.915 -475.915] (1.000)
Step: 89949, Reward: [-420.928 -420.928 -420.928] [0.0000], Avg: [-475.885 -475.885 -475.885] (1.000)
Step: 89999, Reward: [-441.008 -441.008 -441.008] [0.0000], Avg: [-475.865 -475.865 -475.865] (1.000)
Step: 90049, Reward: [-425.316 -425.316 -425.316] [0.0000], Avg: [-475.837 -475.837 -475.837] (1.000)
Step: 90099, Reward: [-386.211 -386.211 -386.211] [0.0000], Avg: [-475.788 -475.788 -475.788] (1.000)
Step: 90149, Reward: [-306.885 -306.885 -306.885] [0.0000], Avg: [-475.694 -475.694 -475.694] (1.000)
Step: 90199, Reward: [-390.39 -390.39 -390.39] [0.0000], Avg: [-475.647 -475.647 -475.647] (1.000)
Step: 90249, Reward: [-348.94 -348.94 -348.94] [0.0000], Avg: [-475.576 -475.576 -475.576] (1.000)
Step: 90299, Reward: [-412.854 -412.854 -412.854] [0.0000], Avg: [-475.542 -475.542 -475.542] (1.000)
Step: 90349, Reward: [-339.573 -339.573 -339.573] [0.0000], Avg: [-475.466 -475.466 -475.466] (1.000)
Step: 90399, Reward: [-438.213 -438.213 -438.213] [0.0000], Avg: [-475.446 -475.446 -475.446] (1.000)
Step: 90449, Reward: [-440.361 -440.361 -440.361] [0.0000], Avg: [-475.426 -475.426 -475.426] (1.000)
Step: 90499, Reward: [-330.559 -330.559 -330.559] [0.0000], Avg: [-475.346 -475.346 -475.346] (1.000)
Step: 90549, Reward: [-288.609 -288.609 -288.609] [0.0000], Avg: [-475.243 -475.243 -475.243] (1.000)
Step: 90599, Reward: [-368.468 -368.468 -368.468] [0.0000], Avg: [-475.184 -475.184 -475.184] (1.000)
Step: 90649, Reward: [-381.107 -381.107 -381.107] [0.0000], Avg: [-475.132 -475.132 -475.132] (1.000)
Step: 90699, Reward: [-297.85 -297.85 -297.85] [0.0000], Avg: [-475.035 -475.035 -475.035] (1.000)
Step: 90749, Reward: [-412.863 -412.863 -412.863] [0.0000], Avg: [-475. -475. -475.] (1.000)
Step: 90799, Reward: [-442.786 -442.786 -442.786] [0.0000], Avg: [-474.983 -474.983 -474.983] (1.000)
Step: 90849, Reward: [-269.964 -269.964 -269.964] [0.0000], Avg: [-474.87 -474.87 -474.87] (1.000)
Step: 90899, Reward: [-308.471 -308.471 -308.471] [0.0000], Avg: [-474.778 -474.778 -474.778] (1.000)
Step: 90949, Reward: [-491.947 -491.947 -491.947] [0.0000], Avg: [-474.788 -474.788 -474.788] (1.000)
Step: 90999, Reward: [-442.006 -442.006 -442.006] [0.0000], Avg: [-474.77 -474.77 -474.77] (1.000)
Step: 91049, Reward: [-311.693 -311.693 -311.693] [0.0000], Avg: [-474.68 -474.68 -474.68] (1.000)
Step: 91099, Reward: [-292.841 -292.841 -292.841] [0.0000], Avg: [-474.58 -474.58 -474.58] (1.000)
Step: 91149, Reward: [-377.82 -377.82 -377.82] [0.0000], Avg: [-474.527 -474.527 -474.527] (1.000)
Step: 91199, Reward: [-378.768 -378.768 -378.768] [0.0000], Avg: [-474.475 -474.475 -474.475] (1.000)
Step: 91249, Reward: [-373.434 -373.434 -373.434] [0.0000], Avg: [-474.419 -474.419 -474.419] (1.000)
Step: 91299, Reward: [-437.22 -437.22 -437.22] [0.0000], Avg: [-474.399 -474.399 -474.399] (1.000)
Step: 91349, Reward: [-567.149 -567.149 -567.149] [0.0000], Avg: [-474.45 -474.45 -474.45] (1.000)
Step: 91399, Reward: [-284.789 -284.789 -284.789] [0.0000], Avg: [-474.346 -474.346 -474.346] (1.000)
Step: 91449, Reward: [-296.877 -296.877 -296.877] [0.0000], Avg: [-474.249 -474.249 -474.249] (1.000)
Step: 91499, Reward: [-392.724 -392.724 -392.724] [0.0000], Avg: [-474.205 -474.205 -474.205] (1.000)
Step: 91549, Reward: [-310.799 -310.799 -310.799] [0.0000], Avg: [-474.115 -474.115 -474.115] (1.000)
Step: 91599, Reward: [-427.714 -427.714 -427.714] [0.0000], Avg: [-474.09 -474.09 -474.09] (1.000)
Step: 91649, Reward: [-359.048 -359.048 -359.048] [0.0000], Avg: [-474.027 -474.027 -474.027] (1.000)
Step: 91699, Reward: [-389.763 -389.763 -389.763] [0.0000], Avg: [-473.981 -473.981 -473.981] (1.000)
Step: 91749, Reward: [-350.497 -350.497 -350.497] [0.0000], Avg: [-473.914 -473.914 -473.914] (1.000)
Step: 91799, Reward: [-328.711 -328.711 -328.711] [0.0000], Avg: [-473.835 -473.835 -473.835] (1.000)
Step: 91849, Reward: [-402.824 -402.824 -402.824] [0.0000], Avg: [-473.796 -473.796 -473.796] (1.000)
Step: 91899, Reward: [-322.456 -322.456 -322.456] [0.0000], Avg: [-473.714 -473.714 -473.714] (1.000)
Step: 91949, Reward: [-346.955 -346.955 -346.955] [0.0000], Avg: [-473.645 -473.645 -473.645] (1.000)
Step: 91999, Reward: [-324.129 -324.129 -324.129] [0.0000], Avg: [-473.564 -473.564 -473.564] (1.000)
Step: 92049, Reward: [-351.042 -351.042 -351.042] [0.0000], Avg: [-473.497 -473.497 -473.497] (1.000)
Step: 92099, Reward: [-361.355 -361.355 -361.355] [0.0000], Avg: [-473.436 -473.436 -473.436] (1.000)
Step: 92149, Reward: [-452.702 -452.702 -452.702] [0.0000], Avg: [-473.425 -473.425 -473.425] (1.000)
Step: 92199, Reward: [-348.356 -348.356 -348.356] [0.0000], Avg: [-473.357 -473.357 -473.357] (1.000)
Step: 92249, Reward: [-463.196 -463.196 -463.196] [0.0000], Avg: [-473.352 -473.352 -473.352] (1.000)
Step: 92299, Reward: [-463.266 -463.266 -463.266] [0.0000], Avg: [-473.346 -473.346 -473.346] (1.000)
Step: 92349, Reward: [-343.863 -343.863 -343.863] [0.0000], Avg: [-473.276 -473.276 -473.276] (1.000)
Step: 92399, Reward: [-306.617 -306.617 -306.617] [0.0000], Avg: [-473.186 -473.186 -473.186] (1.000)
Step: 92449, Reward: [-401.529 -401.529 -401.529] [0.0000], Avg: [-473.147 -473.147 -473.147] (1.000)
Step: 92499, Reward: [-346.347 -346.347 -346.347] [0.0000], Avg: [-473.079 -473.079 -473.079] (1.000)
Step: 92549, Reward: [-367.467 -367.467 -367.467] [0.0000], Avg: [-473.022 -473.022 -473.022] (1.000)
Step: 92599, Reward: [-296.043 -296.043 -296.043] [0.0000], Avg: [-472.926 -472.926 -472.926] (1.000)
Step: 92649, Reward: [-367.226 -367.226 -367.226] [0.0000], Avg: [-472.869 -472.869 -472.869] (1.000)
Step: 92699, Reward: [-432.263 -432.263 -432.263] [0.0000], Avg: [-472.847 -472.847 -472.847] (1.000)
Step: 92749, Reward: [-462.96 -462.96 -462.96] [0.0000], Avg: [-472.842 -472.842 -472.842] (1.000)
Step: 92799, Reward: [-441.781 -441.781 -441.781] [0.0000], Avg: [-472.825 -472.825 -472.825] (1.000)
Step: 92849, Reward: [-234.749 -234.749 -234.749] [0.0000], Avg: [-472.697 -472.697 -472.697] (1.000)
Step: 92899, Reward: [-453.58 -453.58 -453.58] [0.0000], Avg: [-472.687 -472.687 -472.687] (1.000)
Step: 92949, Reward: [-362.475 -362.475 -362.475] [0.0000], Avg: [-472.627 -472.627 -472.627] (1.000)
Step: 92999, Reward: [-323.332 -323.332 -323.332] [0.0000], Avg: [-472.547 -472.547 -472.547] (1.000)
Step: 93049, Reward: [-316.687 -316.687 -316.687] [0.0000], Avg: [-472.463 -472.463 -472.463] (1.000)
Step: 93099, Reward: [-449.947 -449.947 -449.947] [0.0000], Avg: [-472.451 -472.451 -472.451] (1.000)
Step: 93149, Reward: [-517.151 -517.151 -517.151] [0.0000], Avg: [-472.475 -472.475 -472.475] (1.000)
Step: 93199, Reward: [-454.855 -454.855 -454.855] [0.0000], Avg: [-472.466 -472.466 -472.466] (1.000)
Step: 93249, Reward: [-409.188 -409.188 -409.188] [0.0000], Avg: [-472.432 -472.432 -472.432] (1.000)
Step: 93299, Reward: [-267.338 -267.338 -267.338] [0.0000], Avg: [-472.322 -472.322 -472.322] (1.000)
Step: 93349, Reward: [-382.437 -382.437 -382.437] [0.0000], Avg: [-472.274 -472.274 -472.274] (1.000)
Step: 93399, Reward: [-522.132 -522.132 -522.132] [0.0000], Avg: [-472.3 -472.3 -472.3] (1.000)
Step: 93449, Reward: [-403.385 -403.385 -403.385] [0.0000], Avg: [-472.263 -472.263 -472.263] (1.000)
Step: 93499, Reward: [-395.175 -395.175 -395.175] [0.0000], Avg: [-472.222 -472.222 -472.222] (1.000)
Step: 93549, Reward: [-360.275 -360.275 -360.275] [0.0000], Avg: [-472.162 -472.162 -472.162] (1.000)
Step: 93599, Reward: [-411.129 -411.129 -411.129] [0.0000], Avg: [-472.13 -472.13 -472.13] (1.000)
Step: 93649, Reward: [-470.649 -470.649 -470.649] [0.0000], Avg: [-472.129 -472.129 -472.129] (1.000)
Step: 93699, Reward: [-522.7 -522.7 -522.7] [0.0000], Avg: [-472.156 -472.156 -472.156] (1.000)
Step: 93749, Reward: [-480.49 -480.49 -480.49] [0.0000], Avg: [-472.16 -472.16 -472.16] (1.000)
Step: 93799, Reward: [-358.784 -358.784 -358.784] [0.0000], Avg: [-472.1 -472.1 -472.1] (1.000)
Step: 93849, Reward: [-367.308 -367.308 -367.308] [0.0000], Avg: [-472.044 -472.044 -472.044] (1.000)
Step: 93899, Reward: [-441.98 -441.98 -441.98] [0.0000], Avg: [-472.028 -472.028 -472.028] (1.000)
Step: 93949, Reward: [-343.954 -343.954 -343.954] [0.0000], Avg: [-471.96 -471.96 -471.96] (1.000)
Step: 93999, Reward: [-347.97 -347.97 -347.97] [0.0000], Avg: [-471.894 -471.894 -471.894] (1.000)
Step: 94049, Reward: [-489.317 -489.317 -489.317] [0.0000], Avg: [-471.903 -471.903 -471.903] (1.000)
Step: 94099, Reward: [-364.042 -364.042 -364.042] [0.0000], Avg: [-471.846 -471.846 -471.846] (1.000)
Step: 94149, Reward: [-416.979 -416.979 -416.979] [0.0000], Avg: [-471.817 -471.817 -471.817] (1.000)
Step: 94199, Reward: [-306.203 -306.203 -306.203] [0.0000], Avg: [-471.729 -471.729 -471.729] (1.000)
Step: 94249, Reward: [-349.482 -349.482 -349.482] [0.0000], Avg: [-471.664 -471.664 -471.664] (1.000)
Step: 94299, Reward: [-389.768 -389.768 -389.768] [0.0000], Avg: [-471.621 -471.621 -471.621] (1.000)
Step: 94349, Reward: [-330.081 -330.081 -330.081] [0.0000], Avg: [-471.546 -471.546 -471.546] (1.000)
Step: 94399, Reward: [-388.248 -388.248 -388.248] [0.0000], Avg: [-471.502 -471.502 -471.502] (1.000)
Step: 94449, Reward: [-408.697 -408.697 -408.697] [0.0000], Avg: [-471.468 -471.468 -471.468] (1.000)
Step: 94499, Reward: [-298.578 -298.578 -298.578] [0.0000], Avg: [-471.377 -471.377 -471.377] (1.000)
Step: 94549, Reward: [-436.23 -436.23 -436.23] [0.0000], Avg: [-471.358 -471.358 -471.358] (1.000)
Step: 94599, Reward: [-458.139 -458.139 -458.139] [0.0000], Avg: [-471.351 -471.351 -471.351] (1.000)
Step: 94649, Reward: [-353.835 -353.835 -353.835] [0.0000], Avg: [-471.289 -471.289 -471.289] (1.000)
Step: 94699, Reward: [-399.269 -399.269 -399.269] [0.0000], Avg: [-471.251 -471.251 -471.251] (1.000)
Step: 94749, Reward: [-463.407 -463.407 -463.407] [0.0000], Avg: [-471.247 -471.247 -471.247] (1.000)
Step: 94799, Reward: [-450.764 -450.764 -450.764] [0.0000], Avg: [-471.236 -471.236 -471.236] (1.000)
Step: 94849, Reward: [-405.223 -405.223 -405.223] [0.0000], Avg: [-471.201 -471.201 -471.201] (1.000)
Step: 94899, Reward: [-295.972 -295.972 -295.972] [0.0000], Avg: [-471.109 -471.109 -471.109] (1.000)
Step: 94949, Reward: [-423.213 -423.213 -423.213] [0.0000], Avg: [-471.084 -471.084 -471.084] (1.000)
Step: 94999, Reward: [-371.03 -371.03 -371.03] [0.0000], Avg: [-471.031 -471.031 -471.031] (1.000)
Step: 95049, Reward: [-298.173 -298.173 -298.173] [0.0000], Avg: [-470.94 -470.94 -470.94] (1.000)
Step: 95099, Reward: [-418.746 -418.746 -418.746] [0.0000], Avg: [-470.913 -470.913 -470.913] (1.000)
Step: 95149, Reward: [-430.042 -430.042 -430.042] [0.0000], Avg: [-470.891 -470.891 -470.891] (1.000)
Step: 95199, Reward: [-416.952 -416.952 -416.952] [0.0000], Avg: [-470.863 -470.863 -470.863] (1.000)
Step: 95249, Reward: [-280.479 -280.479 -280.479] [0.0000], Avg: [-470.763 -470.763 -470.763] (1.000)
Step: 95299, Reward: [-382.561 -382.561 -382.561] [0.0000], Avg: [-470.717 -470.717 -470.717] (1.000)
Step: 95349, Reward: [-354.965 -354.965 -354.965] [0.0000], Avg: [-470.656 -470.656 -470.656] (1.000)
Step: 95399, Reward: [-452.111 -452.111 -452.111] [0.0000], Avg: [-470.646 -470.646 -470.646] (1.000)
Step: 95449, Reward: [-400.756 -400.756 -400.756] [0.0000], Avg: [-470.61 -470.61 -470.61] (1.000)
Step: 95499, Reward: [-377.635 -377.635 -377.635] [0.0000], Avg: [-470.561 -470.561 -470.561] (1.000)
Step: 95549, Reward: [-340.543 -340.543 -340.543] [0.0000], Avg: [-470.493 -470.493 -470.493] (1.000)
Step: 95599, Reward: [-368.083 -368.083 -368.083] [0.0000], Avg: [-470.44 -470.44 -470.44] (1.000)
Step: 95649, Reward: [-408.594 -408.594 -408.594] [0.0000], Avg: [-470.407 -470.407 -470.407] (1.000)
Step: 95699, Reward: [-389.963 -389.963 -389.963] [0.0000], Avg: [-470.365 -470.365 -470.365] (1.000)
Step: 95749, Reward: [-384.364 -384.364 -384.364] [0.0000], Avg: [-470.32 -470.32 -470.32] (1.000)
Step: 95799, Reward: [-459.922 -459.922 -459.922] [0.0000], Avg: [-470.315 -470.315 -470.315] (1.000)
Step: 95849, Reward: [-329.741 -329.741 -329.741] [0.0000], Avg: [-470.242 -470.242 -470.242] (1.000)
Step: 95899, Reward: [-293.313 -293.313 -293.313] [0.0000], Avg: [-470.149 -470.149 -470.149] (1.000)
Step: 95949, Reward: [-421.491 -421.491 -421.491] [0.0000], Avg: [-470.124 -470.124 -470.124] (1.000)
Step: 95999, Reward: [-390.945 -390.945 -390.945] [0.0000], Avg: [-470.083 -470.083 -470.083] (1.000)
Step: 96049, Reward: [-416.674 -416.674 -416.674] [0.0000], Avg: [-470.055 -470.055 -470.055] (1.000)
Step: 96099, Reward: [-334.069 -334.069 -334.069] [0.0000], Avg: [-469.984 -469.984 -469.984] (1.000)
Step: 96149, Reward: [-256.566 -256.566 -256.566] [0.0000], Avg: [-469.873 -469.873 -469.873] (1.000)
Step: 96199, Reward: [-328.886 -328.886 -328.886] [0.0000], Avg: [-469.8 -469.8 -469.8] (1.000)
Step: 96249, Reward: [-546.973 -546.973 -546.973] [0.0000], Avg: [-469.84 -469.84 -469.84] (1.000)
Step: 96299, Reward: [-296.813 -296.813 -296.813] [0.0000], Avg: [-469.75 -469.75 -469.75] (1.000)
Step: 96349, Reward: [-479.298 -479.298 -479.298] [0.0000], Avg: [-469.755 -469.755 -469.755] (1.000)
Step: 96399, Reward: [-368.113 -368.113 -368.113] [0.0000], Avg: [-469.702 -469.702 -469.702] (1.000)
Step: 96449, Reward: [-416.129 -416.129 -416.129] [0.0000], Avg: [-469.675 -469.675 -469.675] (1.000)
Step: 96499, Reward: [-368.506 -368.506 -368.506] [0.0000], Avg: [-469.622 -469.622 -469.622] (1.000)
Step: 96549, Reward: [-366.28 -366.28 -366.28] [0.0000], Avg: [-469.569 -469.569 -469.569] (1.000)
Step: 96599, Reward: [-442.506 -442.506 -442.506] [0.0000], Avg: [-469.555 -469.555 -469.555] (1.000)
Step: 96649, Reward: [-393.523 -393.523 -393.523] [0.0000], Avg: [-469.515 -469.515 -469.515] (1.000)
Step: 96699, Reward: [-429.526 -429.526 -429.526] [0.0000], Avg: [-469.495 -469.495 -469.495] (1.000)
Step: 96749, Reward: [-424.633 -424.633 -424.633] [0.0000], Avg: [-469.471 -469.471 -469.471] (1.000)
Step: 96799, Reward: [-326.436 -326.436 -326.436] [0.0000], Avg: [-469.398 -469.398 -469.398] (1.000)
Step: 96849, Reward: [-295.626 -295.626 -295.626] [0.0000], Avg: [-469.308 -469.308 -469.308] (1.000)
Step: 96899, Reward: [-492.182 -492.182 -492.182] [0.0000], Avg: [-469.32 -469.32 -469.32] (1.000)
Step: 96949, Reward: [-367.824 -367.824 -367.824] [0.0000], Avg: [-469.267 -469.267 -469.267] (1.000)
Step: 96999, Reward: [-286.585 -286.585 -286.585] [0.0000], Avg: [-469.173 -469.173 -469.173] (1.000)
Step: 97049, Reward: [-374.634 -374.634 -374.634] [0.0000], Avg: [-469.124 -469.124 -469.124] (1.000)
Step: 97099, Reward: [-315.427 -315.427 -315.427] [0.0000], Avg: [-469.045 -469.045 -469.045] (1.000)
Step: 97149, Reward: [-240.602 -240.602 -240.602] [0.0000], Avg: [-468.928 -468.928 -468.928] (1.000)
Step: 97199, Reward: [-493.935 -493.935 -493.935] [0.0000], Avg: [-468.941 -468.941 -468.941] (1.000)
Step: 97249, Reward: [-309.328 -309.328 -309.328] [0.0000], Avg: [-468.859 -468.859 -468.859] (1.000)
Step: 97299, Reward: [-386.074 -386.074 -386.074] [0.0000], Avg: [-468.816 -468.816 -468.816] (1.000)
Step: 97349, Reward: [-373.54 -373.54 -373.54] [0.0000], Avg: [-468.767 -468.767 -468.767] (1.000)
Step: 97399, Reward: [-410.242 -410.242 -410.242] [0.0000], Avg: [-468.737 -468.737 -468.737] (1.000)
Step: 97449, Reward: [-355.254 -355.254 -355.254] [0.0000], Avg: [-468.679 -468.679 -468.679] (1.000)
Step: 97499, Reward: [-497.483 -497.483 -497.483] [0.0000], Avg: [-468.694 -468.694 -468.694] (1.000)
Step: 97549, Reward: [-345.512 -345.512 -345.512] [0.0000], Avg: [-468.63 -468.63 -468.63] (1.000)
Step: 97599, Reward: [-432.245 -432.245 -432.245] [0.0000], Avg: [-468.612 -468.612 -468.612] (1.000)
Step: 97649, Reward: [-325.863 -325.863 -325.863] [0.0000], Avg: [-468.539 -468.539 -468.539] (1.000)
Step: 97699, Reward: [-340.033 -340.033 -340.033] [0.0000], Avg: [-468.473 -468.473 -468.473] (1.000)
Step: 97749, Reward: [-291.213 -291.213 -291.213] [0.0000], Avg: [-468.382 -468.382 -468.382] (1.000)
Step: 97799, Reward: [-334.33 -334.33 -334.33] [0.0000], Avg: [-468.314 -468.314 -468.314] (1.000)
Step: 97849, Reward: [-479.883 -479.883 -479.883] [0.0000], Avg: [-468.32 -468.32 -468.32] (1.000)
Step: 97899, Reward: [-327.909 -327.909 -327.909] [0.0000], Avg: [-468.248 -468.248 -468.248] (1.000)
Step: 97949, Reward: [-451.72 -451.72 -451.72] [0.0000], Avg: [-468.239 -468.239 -468.239] (1.000)
Step: 97999, Reward: [-395.107 -395.107 -395.107] [0.0000], Avg: [-468.202 -468.202 -468.202] (1.000)
Step: 98049, Reward: [-386.212 -386.212 -386.212] [0.0000], Avg: [-468.16 -468.16 -468.16] (1.000)
Step: 98099, Reward: [-273.944 -273.944 -273.944] [0.0000], Avg: [-468.061 -468.061 -468.061] (1.000)
Step: 98149, Reward: [-427.612 -427.612 -427.612] [0.0000], Avg: [-468.041 -468.041 -468.041] (1.000)
Step: 98199, Reward: [-414.672 -414.672 -414.672] [0.0000], Avg: [-468.014 -468.014 -468.014] (1.000)
Step: 98249, Reward: [-387.655 -387.655 -387.655] [0.0000], Avg: [-467.973 -467.973 -467.973] (1.000)
Step: 98299, Reward: [-472.015 -472.015 -472.015] [0.0000], Avg: [-467.975 -467.975 -467.975] (1.000)
Step: 98349, Reward: [-404.494 -404.494 -404.494] [0.0000], Avg: [-467.942 -467.942 -467.942] (1.000)
Step: 98399, Reward: [-400.564 -400.564 -400.564] [0.0000], Avg: [-467.908 -467.908 -467.908] (1.000)
Step: 98449, Reward: [-396.903 -396.903 -396.903] [0.0000], Avg: [-467.872 -467.872 -467.872] (1.000)
Step: 98499, Reward: [-448.969 -448.969 -448.969] [0.0000], Avg: [-467.863 -467.863 -467.863] (1.000)
Step: 98549, Reward: [-394.703 -394.703 -394.703] [0.0000], Avg: [-467.825 -467.825 -467.825] (1.000)
Step: 98599, Reward: [-376.293 -376.293 -376.293] [0.0000], Avg: [-467.779 -467.779 -467.779] (1.000)
Step: 98649, Reward: [-353.877 -353.877 -353.877] [0.0000], Avg: [-467.721 -467.721 -467.721] (1.000)
Step: 98699, Reward: [-359.312 -359.312 -359.312] [0.0000], Avg: [-467.666 -467.666 -467.666] (1.000)
Step: 98749, Reward: [-414.695 -414.695 -414.695] [0.0000], Avg: [-467.64 -467.64 -467.64] (1.000)
Step: 98799, Reward: [-310.18 -310.18 -310.18] [0.0000], Avg: [-467.56 -467.56 -467.56] (1.000)
Step: 98849, Reward: [-360.616 -360.616 -360.616] [0.0000], Avg: [-467.506 -467.506 -467.506] (1.000)
Step: 98899, Reward: [-378.956 -378.956 -378.956] [0.0000], Avg: [-467.461 -467.461 -467.461] (1.000)
Step: 98949, Reward: [-432.349 -432.349 -432.349] [0.0000], Avg: [-467.443 -467.443 -467.443] (1.000)
Step: 98999, Reward: [-404.357 -404.357 -404.357] [0.0000], Avg: [-467.411 -467.411 -467.411] (1.000)
Step: 99049, Reward: [-412.312 -412.312 -412.312] [0.0000], Avg: [-467.384 -467.384 -467.384] (1.000)
Step: 99099, Reward: [-304.894 -304.894 -304.894] [0.0000], Avg: [-467.302 -467.302 -467.302] (1.000)
Step: 99149, Reward: [-487.102 -487.102 -487.102] [0.0000], Avg: [-467.312 -467.312 -467.312] (1.000)
Step: 99199, Reward: [-457.558 -457.558 -457.558] [0.0000], Avg: [-467.307 -467.307 -467.307] (1.000)
Step: 99249, Reward: [-321.68 -321.68 -321.68] [0.0000], Avg: [-467.233 -467.233 -467.233] (1.000)
Step: 99299, Reward: [-410.302 -410.302 -410.302] [0.0000], Avg: [-467.205 -467.205 -467.205] (1.000)
Step: 99349, Reward: [-351.815 -351.815 -351.815] [0.0000], Avg: [-467.147 -467.147 -467.147] (1.000)
Step: 99399, Reward: [-305.91 -305.91 -305.91] [0.0000], Avg: [-467.065 -467.065 -467.065] (1.000)
Step: 99449, Reward: [-353.34 -353.34 -353.34] [0.0000], Avg: [-467.008 -467.008 -467.008] (1.000)
Step: 99499, Reward: [-396.743 -396.743 -396.743] [0.0000], Avg: [-466.973 -466.973 -466.973] (1.000)
Step: 99549, Reward: [-355.94 -355.94 -355.94] [0.0000], Avg: [-466.917 -466.917 -466.917] (1.000)
Step: 99599, Reward: [-509.449 -509.449 -509.449] [0.0000], Avg: [-466.939 -466.939 -466.939] (1.000)
Step: 99649, Reward: [-483.119 -483.119 -483.119] [0.0000], Avg: [-466.947 -466.947 -466.947] (1.000)
Step: 99699, Reward: [-454.569 -454.569 -454.569] [0.0000], Avg: [-466.94 -466.94 -466.94] (1.000)
Step: 99749, Reward: [-391.261 -391.261 -391.261] [0.0000], Avg: [-466.903 -466.903 -466.903] (1.000)
Step: 99799, Reward: [-338.035 -338.035 -338.035] [0.0000], Avg: [-466.838 -466.838 -466.838] (1.000)
Step: 99849, Reward: [-345.827 -345.827 -345.827] [0.0000], Avg: [-466.777 -466.777 -466.777] (1.000)
Step: 99899, Reward: [-500.712 -500.712 -500.712] [0.0000], Avg: [-466.794 -466.794 -466.794] (1.000)
Step: 99949, Reward: [-502.903 -502.903 -502.903] [0.0000], Avg: [-466.812 -466.812 -466.812] (1.000)
Step: 99999, Reward: [-444.335 -444.335 -444.335] [0.0000], Avg: [-466.801 -466.801 -466.801] (1.000)
