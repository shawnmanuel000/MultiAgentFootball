Model: <class 'multiagent.maddpg.MADDPGAgent'>, Dir: simple_spread
num_envs: 1, state_size: [(1, 18), (1, 18), (1, 18)], action_size: [[1, 5], [1, 5], [1, 5]], action_space: [<gym.spaces.multi_discrete.MultiDiscrete object at 0x7fc5c8a94d68>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7fc5c8a94e10>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7fc5c8a94e80>],

import torch
import random
import numpy as np
from models.rand import MultiagentReplayBuffer
from models.ddpg import DDPGActor, DDPGCritic, DDPGNetwork
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACAgent, LEARN_RATE, NUM_STEPS, EPS_MIN, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, MAX_BUFFER_SIZE, gumbel_softmax, one_hot

REPLAY_BATCH_SIZE = 1024
ENTROPY_WEIGHT = 0.001			# The weight for the entropy term of the Actor loss
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64
LEARN_RATE = 0.01
TARGET_UPDATE_RATE = 0.01

class MADDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, sample=True):
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		action_mu = self.action_mu(state)
		action = gumbel_softmax(action_mu, hard=True)
		action = action.view(*out_dims, -1)
		return action
	
class MADDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1]+action_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1]+action_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, action):
		state = torch.cat([state, action], -1)
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		q_value = self.q_value(state)
		q_value = q_value.view(*out_dims, -1)
		return q_value

class MADDPGNetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=True, load=None):
		super().__init__(tau=tau, gpu=gpu)
		self.state_size = state_size
		self.action_size = action_size
		self.critic = MADDPGCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.models = [DDPGNetwork(s_size, a_size, MADDPGActor, lambda s,a: self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		
	def get_action_probs(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [model.get_action(s, use_target, grad, numpy, sample) for s,model in zip(state, self.models)]
			return action

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_value = [model.get_q_value(state, action, use_target, grad, numpy) for model in self.models]
			return q_value

	def optimize(self, states, actions, states_joint, actions_joint, q_targets, e_weight=ENTROPY_WEIGHT):
		for (i,model),state,q_target in zip(enumerate(self.models), states, q_targets):
			q_values = model.get_q_value(states_joint, actions_joint, grad=True, numpy=False)
			critic_error = q_values[:q_target.size(0)] - q_target.detach()
			critic_loss = critic_error.pow(2)
			model.step(model.critic_optimizer, critic_loss.mean(), param_norm=model.critic_local.parameters())
			model.soft_copy(model.critic_local, model.critic_target)

			actor_action = model.get_action(state, grad=True, numpy=False)
			critic_action = [actor_action if j==i else other.get_action(states[j], numpy=False) for j,other in enumerate(self.models)]
			action_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(critic_action, self.action_size)], dim=-1)
			q_actions = model.critic_local(states_joint, action_joint)
			actor_loss = -q_actions.mean() + e_weight*actor_action.pow(2).mean()
			model.step(model.actor_optimizer, actor_loss.mean(), param_norm=model.actor_local.parameters())
			model.soft_copy(model.actor_local, model.actor_target)

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class MADDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, MADDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		# agent_init_params = []
		# for acsp, obsp in zip(action_size, state_size):
		# 	num_in_pol = obsp[-1]
		# 	num_out_pol = acsp[-1]
		# 	num_in_critic = sum([*[x[-1] for x in state_size], *[x.n for x in action_size]])
		# 	agent_init_params.append({'num_in_pol': num_in_pol, 'num_out_pol': num_out_pol, 'num_in_critic': num_in_critic})
		self.agent = MADDPG(state_size, action_size)
		self.replay_buffer = MultiagentReplayBuffer(MAX_BUFFER_SIZE, self.agent.nagents, [obsp[-1] for obsp in state_size], [acsp[-1] for acsp in action_size])

	def get_action(self, state, eps=None, sample=True, numpy=True):
		state = [torch.autograd.Variable(torch.Tensor(np.vstack(state[i])), requires_grad=False) for i in range(self.agent.nagents)]
		torch_agent_actions = self.agent.step(state, explore=True)
		agent_actions = [ac.data.numpy() for ac in torch_agent_actions]
		return agent_actions
		# eps = self.eps if eps is None else eps
		# action_random = super().get_action(state)
		# action_greedy = self.network.get_action_probs(self.to_tensor(state), sample=sample, numpy=numpy)
		# action = [(1-eps)*a_greedy + eps*a_random for a_greedy,a_random in zip(action_greedy, action_random)]
		# return action

	def train(self, state, action, next_state, reward, done):
		if not hasattr(self, "t"): self.t = 0
		self.replay_buffer.push(state, action, next_state, reward, done)
		if (len(self.replay_buffer) >= 1024 and (self.t % 100)==0):
			self.agent.prep_training(device='cpu')
			for a_i in range(self.agent.nagents):
				sample = self.replay_buffer.sample(1024, to_gpu=False)
				self.agent.update(sample, a_i)
			self.agent.update_all_targets()
			self.agent.prep_rollouts(device='cpu')
		self.t += 1
		# self.buffer.append((state, action, reward, done))
		# if np.any(done[0]) or len(self.buffer) >= self.update_freq:
		# 	states, actions, rewards, dones = map(lambda x: self.to_tensor(x), zip(*self.buffer))
		# 	self.buffer.clear()
		# 	next_state = self.to_tensor(next_state)
		# 	states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, next_state)]
		# 	actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.network.get_action_probs(next_state, use_target=True))]
		# 	states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
		# 	actions_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions, self.action_size)], dim=-1)
		# 	q_values = self.network.get_q_value(states_joint, actions_joint, use_target=True)
		# 	q_targets = [self.compute_gae(q_value[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_value[:-1])[0] for q_value,reward,done in zip(q_values, rewards, dones)]
			
		# 	to_stack = lambda items: list(zip(*[x.view(-1, *x.shape[2:]).cpu().numpy() for x in items]))
		# 	states, actions, states_joint, actions_joint = map(lambda items: [x[:-1] for x in items], [states, actions, [states_joint], [actions_joint]])
		# 	states, actions, states_joint, actions_joint, q_targets = map(to_stack, [states, actions, states_joint, actions_joint, q_targets])
		# 	self.replay_buffer.extend(list(zip(states, actions, states_joint, actions_joint, q_targets)), shuffle=False)	
		# if len(self.replay_buffer) > REPLAY_BATCH_SIZE:
		# 	states, actions, states_joint, actions_joint, q_targets = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
		# 	self.network.optimize(states, actions, states_joint[0], actions_joint[0], q_targets)
		# if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)

MSELoss = torch.nn.MSELoss()


class MADDPG():
	"""
	Wrapper class for DDPG-esque (i.e. also MADDPG) agents in multi-agent task
	"""
	def __init__(self, state_size, action_size, gamma=0.95, tau=0.01, lr=0.01, hidden_dim=64):
		self.agents = []# [DDPGAgent(**params) for params in agent_init_params]
		num_in_critic = sum([x[-1] for x in state_size]) + sum([x[-1] for x in action_size])
		for acsp, obsp in zip(action_size, state_size):
			self.agents.append(DDPGAgent(obsp[-1], acsp[-1], num_in_critic))
			# agent_init_params.append({'num_in_pol': num_in_pol, 'num_out_pol': num_out_pol, 'num_in_critic': num_in_critic})
		self.nagents = len(state_size)
		self.gamma = gamma
		self.tau = tau
		self.lr = lr
		self.niter = 0

	@property
	def policies(self):
		return [a.policy for a in self.agents]

	@property
	def target_policies(self):
		return [a.target_policy for a in self.agents]

	def step(self, observations, explore=False):
		return [a.step(obs, explore=explore) for a, obs in zip(self.agents, observations)]

	def update(self, sample, agent_i, parallel=False, logger=None):
		obs, acs, rews, next_obs, dones = sample
		curr_agent = self.agents[agent_i]

		all_trgt_acs = [one_hot(pi(nobs)) for pi, nobs in zip(self.target_policies, next_obs)]
		trgt_vf_in = torch.cat((*next_obs, *all_trgt_acs), dim=1)
		target_value = (rews[agent_i].view(-1, 1) + self.gamma * curr_agent.target_critic(trgt_vf_in) * (1 - dones[agent_i].view(-1, 1)))

		critic_inputs = torch.cat((*obs, *acs), dim=1)
		actual_value = curr_agent.critic(critic_inputs)

		curr_agent.critic_optimizer.zero_grad()
		vf_loss = (actual_value - target_value.detach()).pow(2).mean()
		vf_loss.backward()
		torch.nn.utils.clip_grad_norm(curr_agent.critic.parameters(), 0.5)
		curr_agent.critic_optimizer.step()

		curr_agent.policy_optimizer.zero_grad()
		curr_pol_out = curr_agent.policy(obs[agent_i])
		curr_pol_vf_in = gumbel_softmax(curr_pol_out, hard=True)
		all_pol_acs = [curr_pol_vf_in if i==agent_i else one_hot(pi(ob)) for i, pi, ob in zip(range(self.nagents), self.policies, obs)]
		critic_inputs = torch.cat((*obs, *all_pol_acs), dim=1)
		pol_loss = -curr_agent.critic(critic_inputs).mean()
		pol_loss += (curr_pol_out**2).mean() * 1e-3
		pol_loss.backward()
		torch.nn.utils.clip_grad_norm(curr_agent.policy.parameters(), 0.5)
		curr_agent.policy_optimizer.step()

	def update_all_targets(self):
		for a in self.agents:
			# PTNetwork.soft_copy(a.critic, a.target_critic)
			# PTNetwork.soft_copy(a.policy, a.target_policy)
			for target_param, param in zip(a.target_critic.parameters(), a.critic.parameters()):
				target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)
			for target_param, param in zip(a.target_policy.parameters(), a.policy.parameters()):
				target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)
		self.niter += 1

	def prep_training(self, device='gpu'):
		for a in self.agents:
			a.policy.train()
			a.critic.train()
			a.target_policy.train()
			a.target_critic.train()

	def prep_rollouts(self, device='cpu'):
		for a in self.agents:
			a.policy.eval()

class DDPGAgent(object):
	def __init__(self, num_in_pol, num_out_pol, num_in_critic, hidden_dim=64, lr=0.01):
		self.policy = MLPNetwork(num_in_pol, num_out_pol, hidden_dim=hidden_dim)
		self.critic = MLPNetwork(num_in_critic, 1, hidden_dim=hidden_dim)
		self.target_policy = MLPNetwork(num_in_pol, num_out_pol, hidden_dim=hidden_dim)
		self.target_critic = MLPNetwork(num_in_critic, 1, hidden_dim=hidden_dim)
		for target_param, param in zip(self.target_policy.parameters(), self.policy.parameters()):
			target_param.data.copy_(param.data)
		for target_param, param in zip(self.target_critic.parameters(), self.critic.parameters()):
			target_param.data.copy_(param.data)
		self.policy_optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr)
		self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr)

	def step(self, obs, explore=False):
		action = self.policy(obs)
		if explore:
			action = gumbel_softmax(action, hard=True)
		else:
			action = one_hot(action)
		return action

class MLPNetwork(torch.nn.Module):
	def __init__(self, input_dim, out_dim, hidden_dim=64, nonlin=torch.relu):
		super(MLPNetwork, self).__init__()

		# if norm_in:  # normalize inputs
		# 	self.in_fn = nn.BatchNorm1d(input_dim)
		# 	self.in_fn.weight.data.fill_(1)
		# 	self.in_fn.bias.data.fill_(0)
		# else:
		# 	self.in_fn = lambda x: x
		self.fc1 = torch.nn.Linear(input_dim, hidden_dim)
		self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)
		self.fc3 = torch.nn.Linear(hidden_dim, out_dim)
		self.nonlin = nonlin
		# if constrain_out and not discrete_action:
		# 	self.fc3.weight.data.uniform_(-3e-3, 3e-3)
		# 	self.out_fn = torch.tanh
		# 	raise EnvironmentError()
		# else:  # logits for discrete action (will softmax later)
		# 	self.out_fn = lambda x: x

	def forward(self, X):
		h1 = self.nonlin(self.fc1(X))
		h2 = self.nonlin(self.fc2(h1))
		out = self.fc3(h2)
		return out
REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.900             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)
# np.random.seed(1)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return gym.make(env_name)
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":0} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env)

def run(model, steps=10000, ports=16, env_name=env_name, eval_at=1000, checkpoint=False, save_best=False, log=True, render=True):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports, render=False, env_name=env_name)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, num_envs=num_envs, gpu=False, agent2=RandomAgent) 
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if np.any(dones[0]):
			rollouts = [rollout(envs.env, agent.reset(1), render=render) for _ in range(1)]
			test_reward = np.mean(rollouts, axis=0) - np.std(rollouts, axis=0)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if save_best and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts, axis=0)} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")
			agent.reset(num_envs)

def trial(model):
	envs = EnsembleEnv(make_env, 0, log=True, render=True)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, load=f"{env_name}")
	print(f"Reward: {rollout(envs.env, agent, eps=0.02, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[1], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="maddpg", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--test", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.test:
		trial(model)
	elif args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		run(model, args.steps, args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)

Step: 49, Reward: [-523.363 -523.363 -523.363] [0.0000], Avg: [-523.363 -523.363 -523.363] (1.000)
Step: 99, Reward: [-424.133 -424.133 -424.133] [0.0000], Avg: [-473.748 -473.748 -473.748] (1.000)
Step: 149, Reward: [-571. -571. -571.] [0.0000], Avg: [-506.166 -506.166 -506.166] (1.000)
Step: 199, Reward: [-428.948 -428.948 -428.948] [0.0000], Avg: [-486.861 -486.861 -486.861] (1.000)
Step: 249, Reward: [-516.041 -516.041 -516.041] [0.0000], Avg: [-492.697 -492.697 -492.697] (1.000)
Step: 299, Reward: [-539.625 -539.625 -539.625] [0.0000], Avg: [-500.518 -500.518 -500.518] (1.000)
Step: 349, Reward: [-412.562 -412.562 -412.562] [0.0000], Avg: [-487.953 -487.953 -487.953] (1.000)
Step: 399, Reward: [-521.126 -521.126 -521.126] [0.0000], Avg: [-492.1 -492.1 -492.1] (1.000)
Step: 449, Reward: [-591.088 -591.088 -591.088] [0.0000], Avg: [-503.098 -503.098 -503.098] (1.000)
Step: 499, Reward: [-622.975 -622.975 -622.975] [0.0000], Avg: [-515.086 -515.086 -515.086] (1.000)
Step: 549, Reward: [-527.163 -527.163 -527.163] [0.0000], Avg: [-516.184 -516.184 -516.184] (1.000)
Step: 599, Reward: [-481.531 -481.531 -481.531] [0.0000], Avg: [-513.296 -513.296 -513.296] (1.000)
Step: 649, Reward: [-332.016 -332.016 -332.016] [0.0000], Avg: [-499.352 -499.352 -499.352] (1.000)
Step: 699, Reward: [-631.42 -631.42 -631.42] [0.0000], Avg: [-508.785 -508.785 -508.785] (1.000)
Step: 749, Reward: [-393.271 -393.271 -393.271] [0.0000], Avg: [-501.084 -501.084 -501.084] (1.000)
Step: 799, Reward: [-351.728 -351.728 -351.728] [0.0000], Avg: [-491.749 -491.749 -491.749] (1.000)
Step: 849, Reward: [-421.088 -421.088 -421.088] [0.0000], Avg: [-487.593 -487.593 -487.593] (1.000)
Step: 899, Reward: [-480.716 -480.716 -480.716] [0.0000], Avg: [-487.211 -487.211 -487.211] (1.000)
Step: 949, Reward: [-451.995 -451.995 -451.995] [0.0000], Avg: [-485.357 -485.357 -485.357] (1.000)
Step: 999, Reward: [-432.639 -432.639 -432.639] [0.0000], Avg: [-482.721 -482.721 -482.721] (1.000)
Step: 1049, Reward: [-446.894 -446.894 -446.894] [0.0000], Avg: [-481.015 -481.015 -481.015] (1.000)
Step: 1099, Reward: [-521.698 -521.698 -521.698] [0.0000], Avg: [-482.865 -482.865 -482.865] (1.000)
Step: 1149, Reward: [-455.491 -455.491 -455.491] [0.0000], Avg: [-481.674 -481.674 -481.674] (1.000)
Step: 1199, Reward: [-505.664 -505.664 -505.664] [0.0000], Avg: [-482.674 -482.674 -482.674] (1.000)
Step: 1249, Reward: [-518.92 -518.92 -518.92] [0.0000], Avg: [-484.124 -484.124 -484.124] (1.000)
Step: 1299, Reward: [-357.908 -357.908 -357.908] [0.0000], Avg: [-479.269 -479.269 -479.269] (1.000)
Step: 1349, Reward: [-498.577 -498.577 -498.577] [0.0000], Avg: [-479.984 -479.984 -479.984] (1.000)
Step: 1399, Reward: [-661.477 -661.477 -661.477] [0.0000], Avg: [-486.466 -486.466 -486.466] (1.000)
Step: 1449, Reward: [-594.326 -594.326 -594.326] [0.0000], Avg: [-490.186 -490.186 -490.186] (1.000)
Step: 1499, Reward: [-600.196 -600.196 -600.196] [0.0000], Avg: [-493.853 -493.853 -493.853] (1.000)
Step: 1549, Reward: [-479.175 -479.175 -479.175] [0.0000], Avg: [-493.379 -493.379 -493.379] (1.000)
Step: 1599, Reward: [-559.692 -559.692 -559.692] [0.0000], Avg: [-495.452 -495.452 -495.452] (1.000)
Step: 1649, Reward: [-722.115 -722.115 -722.115] [0.0000], Avg: [-502.32 -502.32 -502.32] (1.000)
Step: 1699, Reward: [-1025.216 -1025.216 -1025.216] [0.0000], Avg: [-517.699 -517.699 -517.699] (1.000)
Step: 1749, Reward: [-884.633 -884.633 -884.633] [0.0000], Avg: [-528.183 -528.183 -528.183] (1.000)
Step: 1799, Reward: [-782.851 -782.851 -782.851] [0.0000], Avg: [-535.257 -535.257 -535.257] (1.000)
Step: 1849, Reward: [-1094.574 -1094.574 -1094.574] [0.0000], Avg: [-550.374 -550.374 -550.374] (1.000)
Step: 1899, Reward: [-942.984 -942.984 -942.984] [0.0000], Avg: [-560.706 -560.706 -560.706] (1.000)
Step: 1949, Reward: [-911.869 -911.869 -911.869] [0.0000], Avg: [-569.71 -569.71 -569.71] (1.000)
Step: 1999, Reward: [-1367.66 -1367.66 -1367.66] [0.0000], Avg: [-589.659 -589.659 -589.659] (1.000)
Step: 2049, Reward: [-1139.138 -1139.138 -1139.138] [0.0000], Avg: [-603.061 -603.061 -603.061] (1.000)
Step: 2099, Reward: [-581.533 -581.533 -581.533] [0.0000], Avg: [-602.548 -602.548 -602.548] (1.000)
Step: 2149, Reward: [-675.597 -675.597 -675.597] [0.0000], Avg: [-604.247 -604.247 -604.247] (1.000)
Step: 2199, Reward: [-900.701 -900.701 -900.701] [0.0000], Avg: [-610.985 -610.985 -610.985] (1.000)
Step: 2249, Reward: [-818.486 -818.486 -818.486] [0.0000], Avg: [-615.596 -615.596 -615.596] (1.000)
Step: 2299, Reward: [-904.399 -904.399 -904.399] [0.0000], Avg: [-621.874 -621.874 -621.874] (1.000)
Step: 2349, Reward: [-645.449 -645.449 -645.449] [0.0000], Avg: [-622.376 -622.376 -622.376] (1.000)
Step: 2399, Reward: [-482.088 -482.088 -482.088] [0.0000], Avg: [-619.453 -619.453 -619.453] (1.000)
Step: 2449, Reward: [-340.212 -340.212 -340.212] [0.0000], Avg: [-613.754 -613.754 -613.754] (1.000)
Step: 2499, Reward: [-565.339 -565.339 -565.339] [0.0000], Avg: [-612.786 -612.786 -612.786] (1.000)
Step: 2549, Reward: [-573.939 -573.939 -573.939] [0.0000], Avg: [-612.024 -612.024 -612.024] (1.000)
Step: 2599, Reward: [-514.211 -514.211 -514.211] [0.0000], Avg: [-610.143 -610.143 -610.143] (1.000)
Step: 2649, Reward: [-388.48 -388.48 -388.48] [0.0000], Avg: [-605.961 -605.961 -605.961] (1.000)
Step: 2699, Reward: [-811.265 -811.265 -811.265] [0.0000], Avg: [-609.763 -609.763 -609.763] (1.000)
Step: 2749, Reward: [-683.338 -683.338 -683.338] [0.0000], Avg: [-611.1 -611.1 -611.1] (1.000)
Step: 2799, Reward: [-473.354 -473.354 -473.354] [0.0000], Avg: [-608.641 -608.641 -608.641] (1.000)
Step: 2849, Reward: [-393.464 -393.464 -393.464] [0.0000], Avg: [-604.866 -604.866 -604.866] (1.000)
Step: 2899, Reward: [-372.105 -372.105 -372.105] [0.0000], Avg: [-600.853 -600.853 -600.853] (1.000)
Step: 2949, Reward: [-668.035 -668.035 -668.035] [0.0000], Avg: [-601.991 -601.991 -601.991] (1.000)
Step: 2999, Reward: [-663.697 -663.697 -663.697] [0.0000], Avg: [-603.02 -603.02 -603.02] (1.000)
Step: 3049, Reward: [-350.192 -350.192 -350.192] [0.0000], Avg: [-598.875 -598.875 -598.875] (1.000)
Step: 3099, Reward: [-505.193 -505.193 -505.193] [0.0000], Avg: [-597.364 -597.364 -597.364] (1.000)
Step: 3149, Reward: [-452.682 -452.682 -452.682] [0.0000], Avg: [-595.067 -595.067 -595.067] (1.000)
Step: 3199, Reward: [-400.926 -400.926 -400.926] [0.0000], Avg: [-592.034 -592.034 -592.034] (1.000)
Step: 3249, Reward: [-596.799 -596.799 -596.799] [0.0000], Avg: [-592.107 -592.107 -592.107] (1.000)
Step: 3299, Reward: [-846.635 -846.635 -846.635] [0.0000], Avg: [-595.964 -595.964 -595.964] (1.000)
Step: 3349, Reward: [-643.125 -643.125 -643.125] [0.0000], Avg: [-596.668 -596.668 -596.668] (1.000)
Step: 3399, Reward: [-411.9 -411.9 -411.9] [0.0000], Avg: [-593.95 -593.95 -593.95] (1.000)
Step: 3449, Reward: [-404.423 -404.423 -404.423] [0.0000], Avg: [-591.204 -591.204 -591.204] (1.000)
Step: 3499, Reward: [-628.791 -628.791 -628.791] [0.0000], Avg: [-591.741 -591.741 -591.741] (1.000)
Step: 3549, Reward: [-650.239 -650.239 -650.239] [0.0000], Avg: [-592.565 -592.565 -592.565] (1.000)
Step: 3599, Reward: [-850.794 -850.794 -850.794] [0.0000], Avg: [-596.151 -596.151 -596.151] (1.000)
Step: 3649, Reward: [-476.076 -476.076 -476.076] [0.0000], Avg: [-594.506 -594.506 -594.506] (1.000)
Step: 3699, Reward: [-433.848 -433.848 -433.848] [0.0000], Avg: [-592.335 -592.335 -592.335] (1.000)
Step: 3749, Reward: [-522.813 -522.813 -522.813] [0.0000], Avg: [-591.408 -591.408 -591.408] (1.000)
Step: 3799, Reward: [-893.814 -893.814 -893.814] [0.0000], Avg: [-595.387 -595.387 -595.387] (1.000)
Step: 3849, Reward: [-750.074 -750.074 -750.074] [0.0000], Avg: [-597.396 -597.396 -597.396] (1.000)
Step: 3899, Reward: [-597.013 -597.013 -597.013] [0.0000], Avg: [-597.391 -597.391 -597.391] (1.000)
Step: 3949, Reward: [-478.552 -478.552 -478.552] [0.0000], Avg: [-595.887 -595.887 -595.887] (1.000)
Step: 3999, Reward: [-377.146 -377.146 -377.146] [0.0000], Avg: [-593.153 -593.153 -593.153] (1.000)
Step: 4049, Reward: [-497.313 -497.313 -497.313] [0.0000], Avg: [-591.97 -591.97 -591.97] (1.000)
Step: 4099, Reward: [-569.856 -569.856 -569.856] [0.0000], Avg: [-591.7 -591.7 -591.7] (1.000)
Step: 4149, Reward: [-817.348 -817.348 -817.348] [0.0000], Avg: [-594.418 -594.418 -594.418] (1.000)
Step: 4199, Reward: [-863.461 -863.461 -863.461] [0.0000], Avg: [-597.621 -597.621 -597.621] (1.000)
Step: 4249, Reward: [-587.002 -587.002 -587.002] [0.0000], Avg: [-597.496 -597.496 -597.496] (1.000)
Step: 4299, Reward: [-685.675 -685.675 -685.675] [0.0000], Avg: [-598.522 -598.522 -598.522] (1.000)
Step: 4349, Reward: [-1358.592 -1358.592 -1358.592] [0.0000], Avg: [-607.258 -607.258 -607.258] (1.000)
Step: 4399, Reward: [-925.331 -925.331 -925.331] [0.0000], Avg: [-610.873 -610.873 -610.873] (1.000)
Step: 4449, Reward: [-1116.236 -1116.236 -1116.236] [0.0000], Avg: [-616.551 -616.551 -616.551] (1.000)
Step: 4499, Reward: [-626.824 -626.824 -626.824] [0.0000], Avg: [-616.665 -616.665 -616.665] (1.000)
Step: 4549, Reward: [-720.178 -720.178 -720.178] [0.0000], Avg: [-617.803 -617.803 -617.803] (1.000)
Step: 4599, Reward: [-723.406 -723.406 -723.406] [0.0000], Avg: [-618.95 -618.95 -618.95] (1.000)
Step: 4649, Reward: [-449.165 -449.165 -449.165] [0.0000], Avg: [-617.125 -617.125 -617.125] (1.000)
Step: 4699, Reward: [-749.618 -749.618 -749.618] [0.0000], Avg: [-618.534 -618.534 -618.534] (1.000)
Step: 4749, Reward: [-748.282 -748.282 -748.282] [0.0000], Avg: [-619.9 -619.9 -619.9] (1.000)
Step: 4799, Reward: [-676.275 -676.275 -676.275] [0.0000], Avg: [-620.487 -620.487 -620.487] (1.000)
Step: 4849, Reward: [-602.734 -602.734 -602.734] [0.0000], Avg: [-620.304 -620.304 -620.304] (1.000)
Step: 4899, Reward: [-491.18 -491.18 -491.18] [0.0000], Avg: [-618.987 -618.987 -618.987] (1.000)
Step: 4949, Reward: [-535.241 -535.241 -535.241] [0.0000], Avg: [-618.141 -618.141 -618.141] (1.000)
Step: 4999, Reward: [-673.026 -673.026 -673.026] [0.0000], Avg: [-618.69 -618.69 -618.69] (1.000)
Step: 5049, Reward: [-918.795 -918.795 -918.795] [0.0000], Avg: [-621.661 -621.661 -621.661] (1.000)
Step: 5099, Reward: [-753.647 -753.647 -753.647] [0.0000], Avg: [-622.955 -622.955 -622.955] (1.000)
Step: 5149, Reward: [-942.632 -942.632 -942.632] [0.0000], Avg: [-626.059 -626.059 -626.059] (1.000)
Step: 5199, Reward: [-974.194 -974.194 -974.194] [0.0000], Avg: [-629.406 -629.406 -629.406] (1.000)
Step: 5249, Reward: [-2254.669 -2254.669 -2254.669] [0.0000], Avg: [-644.885 -644.885 -644.885] (1.000)
Step: 5299, Reward: [-943.692 -943.692 -943.692] [0.0000], Avg: [-647.704 -647.704 -647.704] (1.000)
Step: 5349, Reward: [-2202.189 -2202.189 -2202.189] [0.0000], Avg: [-662.232 -662.232 -662.232] (1.000)
Step: 5399, Reward: [-853.124 -853.124 -853.124] [0.0000], Avg: [-663.999 -663.999 -663.999] (1.000)
Step: 5449, Reward: [-1784.283 -1784.283 -1784.283] [0.0000], Avg: [-674.277 -674.277 -674.277] (1.000)
Step: 5499, Reward: [-1936.323 -1936.323 -1936.323] [0.0000], Avg: [-685.75 -685.75 -685.75] (1.000)
Step: 5549, Reward: [-2077.664 -2077.664 -2077.664] [0.0000], Avg: [-698.29 -698.29 -698.29] (1.000)
Step: 5599, Reward: [-1576.334 -1576.334 -1576.334] [0.0000], Avg: [-706.13 -706.13 -706.13] (1.000)
Step: 5649, Reward: [-1755.903 -1755.903 -1755.903] [0.0000], Avg: [-715.42 -715.42 -715.42] (1.000)
Step: 5699, Reward: [-2254.448 -2254.448 -2254.448] [0.0000], Avg: [-728.92 -728.92 -728.92] (1.000)
Step: 5749, Reward: [-1993.157 -1993.157 -1993.157] [0.0000], Avg: [-739.913 -739.913 -739.913] (1.000)
Step: 5799, Reward: [-1046.198 -1046.198 -1046.198] [0.0000], Avg: [-742.554 -742.554 -742.554] (1.000)
Step: 5849, Reward: [-1547.182 -1547.182 -1547.182] [0.0000], Avg: [-749.431 -749.431 -749.431] (1.000)
Step: 5899, Reward: [-658.051 -658.051 -658.051] [0.0000], Avg: [-748.656 -748.656 -748.656] (1.000)
Step: 5949, Reward: [-676.675 -676.675 -676.675] [0.0000], Avg: [-748.051 -748.051 -748.051] (1.000)
Step: 5999, Reward: [-1434.004 -1434.004 -1434.004] [0.0000], Avg: [-753.768 -753.768 -753.768] (1.000)
Step: 6049, Reward: [-761.267 -761.267 -761.267] [0.0000], Avg: [-753.83 -753.83 -753.83] (1.000)
Step: 6099, Reward: [-640.029 -640.029 -640.029] [0.0000], Avg: [-752.897 -752.897 -752.897] (1.000)
Step: 6149, Reward: [-604.107 -604.107 -604.107] [0.0000], Avg: [-751.687 -751.687 -751.687] (1.000)
Step: 6199, Reward: [-1203.572 -1203.572 -1203.572] [0.0000], Avg: [-755.331 -755.331 -755.331] (1.000)
Step: 6249, Reward: [-924.195 -924.195 -924.195] [0.0000], Avg: [-756.682 -756.682 -756.682] (1.000)
Step: 6299, Reward: [-962.862 -962.862 -962.862] [0.0000], Avg: [-758.319 -758.319 -758.319] (1.000)
Step: 6349, Reward: [-739.845 -739.845 -739.845] [0.0000], Avg: [-758.173 -758.173 -758.173] (1.000)
Step: 6399, Reward: [-883.8 -883.8 -883.8] [0.0000], Avg: [-759.155 -759.155 -759.155] (1.000)
Step: 6449, Reward: [-677.161 -677.161 -677.161] [0.0000], Avg: [-758.519 -758.519 -758.519] (1.000)
Step: 6499, Reward: [-766.281 -766.281 -766.281] [0.0000], Avg: [-758.579 -758.579 -758.579] (1.000)
Step: 6549, Reward: [-644.55 -644.55 -644.55] [0.0000], Avg: [-757.708 -757.708 -757.708] (1.000)
Step: 6599, Reward: [-580.32 -580.32 -580.32] [0.0000], Avg: [-756.365 -756.365 -756.365] (1.000)
Step: 6649, Reward: [-556.719 -556.719 -556.719] [0.0000], Avg: [-754.863 -754.863 -754.863] (1.000)
Step: 6699, Reward: [-1017.744 -1017.744 -1017.744] [0.0000], Avg: [-756.825 -756.825 -756.825] (1.000)
Step: 6749, Reward: [-1099.237 -1099.237 -1099.237] [0.0000], Avg: [-759.362 -759.362 -759.362] (1.000)
Step: 6799, Reward: [-623.806 -623.806 -623.806] [0.0000], Avg: [-758.365 -758.365 -758.365] (1.000)
Step: 6849, Reward: [-1057.652 -1057.652 -1057.652] [0.0000], Avg: [-760.549 -760.549 -760.549] (1.000)
Step: 6899, Reward: [-691.669 -691.669 -691.669] [0.0000], Avg: [-760.05 -760.05 -760.05] (1.000)
Step: 6949, Reward: [-1064.662 -1064.662 -1064.662] [0.0000], Avg: [-762.242 -762.242 -762.242] (1.000)
Step: 6999, Reward: [-678.261 -678.261 -678.261] [0.0000], Avg: [-761.642 -761.642 -761.642] (1.000)
Step: 7049, Reward: [-1382.632 -1382.632 -1382.632] [0.0000], Avg: [-766.046 -766.046 -766.046] (1.000)
Step: 7099, Reward: [-548.09 -548.09 -548.09] [0.0000], Avg: [-764.511 -764.511 -764.511] (1.000)
Step: 7149, Reward: [-911.081 -911.081 -911.081] [0.0000], Avg: [-765.536 -765.536 -765.536] (1.000)
Step: 7199, Reward: [-712.224 -712.224 -712.224] [0.0000], Avg: [-765.166 -765.166 -765.166] (1.000)
Step: 7249, Reward: [-1506.481 -1506.481 -1506.481] [0.0000], Avg: [-770.278 -770.278 -770.278] (1.000)
Step: 7299, Reward: [-779.853 -779.853 -779.853] [0.0000], Avg: [-770.344 -770.344 -770.344] (1.000)
Step: 7349, Reward: [-1001.646 -1001.646 -1001.646] [0.0000], Avg: [-771.917 -771.917 -771.917] (1.000)
Step: 7399, Reward: [-1328.327 -1328.327 -1328.327] [0.0000], Avg: [-775.677 -775.677 -775.677] (1.000)
Step: 7449, Reward: [-1117.006 -1117.006 -1117.006] [0.0000], Avg: [-777.968 -777.968 -777.968] (1.000)
Step: 7499, Reward: [-1258.065 -1258.065 -1258.065] [0.0000], Avg: [-781.168 -781.168 -781.168] (1.000)
Step: 7549, Reward: [-849.755 -849.755 -849.755] [0.0000], Avg: [-781.623 -781.623 -781.623] (1.000)
Step: 7599, Reward: [-554.54 -554.54 -554.54] [0.0000], Avg: [-780.129 -780.129 -780.129] (1.000)
Step: 7649, Reward: [-711.793 -711.793 -711.793] [0.0000], Avg: [-779.682 -779.682 -779.682] (1.000)
Step: 7699, Reward: [-957.484 -957.484 -957.484] [0.0000], Avg: [-780.837 -780.837 -780.837] (1.000)
Step: 7749, Reward: [-664.487 -664.487 -664.487] [0.0000], Avg: [-780.086 -780.086 -780.086] (1.000)
Step: 7799, Reward: [-786.926 -786.926 -786.926] [0.0000], Avg: [-780.13 -780.13 -780.13] (1.000)
Step: 7849, Reward: [-624.407 -624.407 -624.407] [0.0000], Avg: [-779.138 -779.138 -779.138] (1.000)
Step: 7899, Reward: [-724.158 -724.158 -724.158] [0.0000], Avg: [-778.79 -778.79 -778.79] (1.000)
Step: 7949, Reward: [-514.808 -514.808 -514.808] [0.0000], Avg: [-777.13 -777.13 -777.13] (1.000)
Step: 7999, Reward: [-731.084 -731.084 -731.084] [0.0000], Avg: [-776.842 -776.842 -776.842] (1.000)
Step: 8049, Reward: [-449.67 -449.67 -449.67] [0.0000], Avg: [-774.81 -774.81 -774.81] (1.000)
Step: 8099, Reward: [-627.631 -627.631 -627.631] [0.0000], Avg: [-773.901 -773.901 -773.901] (1.000)
Step: 8149, Reward: [-513.158 -513.158 -513.158] [0.0000], Avg: [-772.302 -772.302 -772.302] (1.000)
Step: 8199, Reward: [-511.226 -511.226 -511.226] [0.0000], Avg: [-770.71 -770.71 -770.71] (1.000)
Step: 8249, Reward: [-409.635 -409.635 -409.635] [0.0000], Avg: [-768.521 -768.521 -768.521] (1.000)
Step: 8299, Reward: [-367.607 -367.607 -367.607] [0.0000], Avg: [-766.106 -766.106 -766.106] (1.000)
Step: 8349, Reward: [-650.992 -650.992 -650.992] [0.0000], Avg: [-765.417 -765.417 -765.417] (1.000)
Step: 8399, Reward: [-473.103 -473.103 -473.103] [0.0000], Avg: [-763.677 -763.677 -763.677] (1.000)
Step: 8449, Reward: [-634.383 -634.383 -634.383] [0.0000], Avg: [-762.912 -762.912 -762.912] (1.000)
Step: 8499, Reward: [-501.844 -501.844 -501.844] [0.0000], Avg: [-761.376 -761.376 -761.376] (1.000)
Step: 8549, Reward: [-463.684 -463.684 -463.684] [0.0000], Avg: [-759.635 -759.635 -759.635] (1.000)
Step: 8599, Reward: [-548.511 -548.511 -548.511] [0.0000], Avg: [-758.408 -758.408 -758.408] (1.000)
Step: 8649, Reward: [-549.31 -549.31 -549.31] [0.0000], Avg: [-757.199 -757.199 -757.199] (1.000)
Step: 8699, Reward: [-483.028 -483.028 -483.028] [0.0000], Avg: [-755.624 -755.624 -755.624] (1.000)
Step: 8749, Reward: [-431.924 -431.924 -431.924] [0.0000], Avg: [-753.774 -753.774 -753.774] (1.000)
Step: 8799, Reward: [-465.655 -465.655 -465.655] [0.0000], Avg: [-752.137 -752.137 -752.137] (1.000)
Step: 8849, Reward: [-348.403 -348.403 -348.403] [0.0000], Avg: [-749.856 -749.856 -749.856] (1.000)
Step: 8899, Reward: [-657.76 -657.76 -657.76] [0.0000], Avg: [-749.338 -749.338 -749.338] (1.000)
Step: 8949, Reward: [-615.054 -615.054 -615.054] [0.0000], Avg: [-748.588 -748.588 -748.588] (1.000)
Step: 8999, Reward: [-505.471 -505.471 -505.471] [0.0000], Avg: [-747.238 -747.238 -747.238] (1.000)
Step: 9049, Reward: [-600.428 -600.428 -600.428] [0.0000], Avg: [-746.426 -746.426 -746.426] (1.000)
Step: 9099, Reward: [-552.956 -552.956 -552.956] [0.0000], Avg: [-745.363 -745.363 -745.363] (1.000)
Step: 9149, Reward: [-498.333 -498.333 -498.333] [0.0000], Avg: [-744.014 -744.014 -744.014] (1.000)
Step: 9199, Reward: [-349.969 -349.969 -349.969] [0.0000], Avg: [-741.872 -741.872 -741.872] (1.000)
Step: 9249, Reward: [-469.583 -469.583 -469.583] [0.0000], Avg: [-740.4 -740.4 -740.4] (1.000)
Step: 9299, Reward: [-405.703 -405.703 -405.703] [0.0000], Avg: [-738.601 -738.601 -738.601] (1.000)
Step: 9349, Reward: [-742.789 -742.789 -742.789] [0.0000], Avg: [-738.623 -738.623 -738.623] (1.000)
Step: 9399, Reward: [-696.885 -696.885 -696.885] [0.0000], Avg: [-738.401 -738.401 -738.401] (1.000)
Step: 9449, Reward: [-568.676 -568.676 -568.676] [0.0000], Avg: [-737.503 -737.503 -737.503] (1.000)
Step: 9499, Reward: [-533.407 -533.407 -533.407] [0.0000], Avg: [-736.429 -736.429 -736.429] (1.000)
Step: 9549, Reward: [-604.517 -604.517 -604.517] [0.0000], Avg: [-735.738 -735.738 -735.738] (1.000)
Step: 9599, Reward: [-406.05 -406.05 -406.05] [0.0000], Avg: [-734.021 -734.021 -734.021] (1.000)
Step: 9649, Reward: [-491.796 -491.796 -491.796] [0.0000], Avg: [-732.766 -732.766 -732.766] (1.000)
Step: 9699, Reward: [-505.1 -505.1 -505.1] [0.0000], Avg: [-731.593 -731.593 -731.593] (1.000)
Step: 9749, Reward: [-712.167 -712.167 -712.167] [0.0000], Avg: [-731.493 -731.493 -731.493] (1.000)
Step: 9799, Reward: [-449.383 -449.383 -449.383] [0.0000], Avg: [-730.054 -730.054 -730.054] (1.000)
Step: 9849, Reward: [-557.297 -557.297 -557.297] [0.0000], Avg: [-729.177 -729.177 -729.177] (1.000)
Step: 9899, Reward: [-508.658 -508.658 -508.658] [0.0000], Avg: [-728.063 -728.063 -728.063] (1.000)
Step: 9949, Reward: [-544.331 -544.331 -544.331] [0.0000], Avg: [-727.14 -727.14 -727.14] (1.000)
Step: 9999, Reward: [-623.533 -623.533 -623.533] [0.0000], Avg: [-726.622 -726.622 -726.622] (1.000)
Step: 10049, Reward: [-564.6 -564.6 -564.6] [0.0000], Avg: [-725.816 -725.816 -725.816] (1.000)
Step: 10099, Reward: [-705.172 -705.172 -705.172] [0.0000], Avg: [-725.713 -725.713 -725.713] (1.000)
Step: 10149, Reward: [-699.052 -699.052 -699.052] [0.0000], Avg: [-725.582 -725.582 -725.582] (1.000)
Step: 10199, Reward: [-681.732 -681.732 -681.732] [0.0000], Avg: [-725.367 -725.367 -725.367] (1.000)
Step: 10249, Reward: [-893.204 -893.204 -893.204] [0.0000], Avg: [-726.186 -726.186 -726.186] (1.000)
Step: 10299, Reward: [-655.057 -655.057 -655.057] [0.0000], Avg: [-725.84 -725.84 -725.84] (1.000)
Step: 10349, Reward: [-563.891 -563.891 -563.891] [0.0000], Avg: [-725.058 -725.058 -725.058] (1.000)
Step: 10399, Reward: [-674.172 -674.172 -674.172] [0.0000], Avg: [-724.813 -724.813 -724.813] (1.000)
Step: 10449, Reward: [-620.249 -620.249 -620.249] [0.0000], Avg: [-724.313 -724.313 -724.313] (1.000)
Step: 10499, Reward: [-657.298 -657.298 -657.298] [0.0000], Avg: [-723.994 -723.994 -723.994] (1.000)
Step: 10549, Reward: [-584.361 -584.361 -584.361] [0.0000], Avg: [-723.332 -723.332 -723.332] (1.000)
Step: 10599, Reward: [-677.619 -677.619 -677.619] [0.0000], Avg: [-723.117 -723.117 -723.117] (1.000)
Step: 10649, Reward: [-570.55 -570.55 -570.55] [0.0000], Avg: [-722.4 -722.4 -722.4] (1.000)
Step: 10699, Reward: [-757.547 -757.547 -757.547] [0.0000], Avg: [-722.565 -722.565 -722.565] (1.000)
Step: 10749, Reward: [-600.527 -600.527 -600.527] [0.0000], Avg: [-721.997 -721.997 -721.997] (1.000)
Step: 10799, Reward: [-464.063 -464.063 -464.063] [0.0000], Avg: [-720.803 -720.803 -720.803] (1.000)
Step: 10849, Reward: [-616.322 -616.322 -616.322] [0.0000], Avg: [-720.321 -720.321 -720.321] (1.000)
Step: 10899, Reward: [-703.109 -703.109 -703.109] [0.0000], Avg: [-720.242 -720.242 -720.242] (1.000)
Step: 10949, Reward: [-615.25 -615.25 -615.25] [0.0000], Avg: [-719.763 -719.763 -719.763] (1.000)
Step: 10999, Reward: [-808.996 -808.996 -808.996] [0.0000], Avg: [-720.169 -720.169 -720.169] (1.000)
Step: 11049, Reward: [-542.552 -542.552 -542.552] [0.0000], Avg: [-719.365 -719.365 -719.365] (1.000)
Step: 11099, Reward: [-467.387 -467.387 -467.387] [0.0000], Avg: [-718.23 -718.23 -718.23] (1.000)
Step: 11149, Reward: [-807.995 -807.995 -807.995] [0.0000], Avg: [-718.632 -718.632 -718.632] (1.000)
Step: 11199, Reward: [-722.005 -722.005 -722.005] [0.0000], Avg: [-718.647 -718.647 -718.647] (1.000)
Step: 11249, Reward: [-595.03 -595.03 -595.03] [0.0000], Avg: [-718.098 -718.098 -718.098] (1.000)
Step: 11299, Reward: [-690.96 -690.96 -690.96] [0.0000], Avg: [-717.978 -717.978 -717.978] (1.000)
Step: 11349, Reward: [-609.047 -609.047 -609.047] [0.0000], Avg: [-717.498 -717.498 -717.498] (1.000)
Step: 11399, Reward: [-769.681 -769.681 -769.681] [0.0000], Avg: [-717.727 -717.727 -717.727] (1.000)
Step: 11449, Reward: [-454.87 -454.87 -454.87] [0.0000], Avg: [-716.579 -716.579 -716.579] (1.000)
Step: 11499, Reward: [-603.249 -603.249 -603.249] [0.0000], Avg: [-716.086 -716.086 -716.086] (1.000)
Step: 11549, Reward: [-731.89 -731.89 -731.89] [0.0000], Avg: [-716.155 -716.155 -716.155] (1.000)
Step: 11599, Reward: [-597.356 -597.356 -597.356] [0.0000], Avg: [-715.643 -715.643 -715.643] (1.000)
Step: 11649, Reward: [-710.621 -710.621 -710.621] [0.0000], Avg: [-715.621 -715.621 -715.621] (1.000)
Step: 11699, Reward: [-886.719 -886.719 -886.719] [0.0000], Avg: [-716.352 -716.352 -716.352] (1.000)
Step: 11749, Reward: [-610.647 -610.647 -610.647] [0.0000], Avg: [-715.903 -715.903 -715.903] (1.000)
Step: 11799, Reward: [-587.565 -587.565 -587.565] [0.0000], Avg: [-715.359 -715.359 -715.359] (1.000)
Step: 11849, Reward: [-629.713 -629.713 -629.713] [0.0000], Avg: [-714.997 -714.997 -714.997] (1.000)
Step: 11899, Reward: [-476.526 -476.526 -476.526] [0.0000], Avg: [-713.995 -713.995 -713.995] (1.000)
Step: 11949, Reward: [-462.866 -462.866 -462.866] [0.0000], Avg: [-712.945 -712.945 -712.945] (1.000)
Step: 11999, Reward: [-725.019 -725.019 -725.019] [0.0000], Avg: [-712.995 -712.995 -712.995] (1.000)
Step: 12049, Reward: [-495.453 -495.453 -495.453] [0.0000], Avg: [-712.092 -712.092 -712.092] (1.000)
Step: 12099, Reward: [-819.021 -819.021 -819.021] [0.0000], Avg: [-712.534 -712.534 -712.534] (1.000)
Step: 12149, Reward: [-639.121 -639.121 -639.121] [0.0000], Avg: [-712.232 -712.232 -712.232] (1.000)
Step: 12199, Reward: [-864.674 -864.674 -864.674] [0.0000], Avg: [-712.857 -712.857 -712.857] (1.000)
Step: 12249, Reward: [-759.616 -759.616 -759.616] [0.0000], Avg: [-713.048 -713.048 -713.048] (1.000)
Step: 12299, Reward: [-664.051 -664.051 -664.051] [0.0000], Avg: [-712.848 -712.848 -712.848] (1.000)
Step: 12349, Reward: [-881.003 -881.003 -881.003] [0.0000], Avg: [-713.529 -713.529 -713.529] (1.000)
Step: 12399, Reward: [-932.157 -932.157 -932.157] [0.0000], Avg: [-714.411 -714.411 -714.411] (1.000)
Step: 12449, Reward: [-874.133 -874.133 -874.133] [0.0000], Avg: [-715.052 -715.052 -715.052] (1.000)
Step: 12499, Reward: [-794.982 -794.982 -794.982] [0.0000], Avg: [-715.372 -715.372 -715.372] (1.000)
Step: 12549, Reward: [-723.182 -723.182 -723.182] [0.0000], Avg: [-715.403 -715.403 -715.403] (1.000)
Step: 12599, Reward: [-539.395 -539.395 -539.395] [0.0000], Avg: [-714.705 -714.705 -714.705] (1.000)
Step: 12649, Reward: [-591.244 -591.244 -591.244] [0.0000], Avg: [-714.217 -714.217 -714.217] (1.000)
Step: 12699, Reward: [-699.464 -699.464 -699.464] [0.0000], Avg: [-714.159 -714.159 -714.159] (1.000)
Step: 12749, Reward: [-943.3 -943.3 -943.3] [0.0000], Avg: [-715.057 -715.057 -715.057] (1.000)
Step: 12799, Reward: [-644.399 -644.399 -644.399] [0.0000], Avg: [-714.781 -714.781 -714.781] (1.000)
Step: 12849, Reward: [-622.729 -622.729 -622.729] [0.0000], Avg: [-714.423 -714.423 -714.423] (1.000)
Step: 12899, Reward: [-812.216 -812.216 -812.216] [0.0000], Avg: [-714.802 -714.802 -714.802] (1.000)
Step: 12949, Reward: [-727.333 -727.333 -727.333] [0.0000], Avg: [-714.85 -714.85 -714.85] (1.000)
Step: 12999, Reward: [-754.991 -754.991 -754.991] [0.0000], Avg: [-715.005 -715.005 -715.005] (1.000)
Step: 13049, Reward: [-700.63 -700.63 -700.63] [0.0000], Avg: [-714.95 -714.95 -714.95] (1.000)
Step: 13099, Reward: [-850.776 -850.776 -850.776] [0.0000], Avg: [-715.468 -715.468 -715.468] (1.000)
Step: 13149, Reward: [-761.005 -761.005 -761.005] [0.0000], Avg: [-715.641 -715.641 -715.641] (1.000)
Step: 13199, Reward: [-789.618 -789.618 -789.618] [0.0000], Avg: [-715.922 -715.922 -715.922] (1.000)
Step: 13249, Reward: [-1013.06 -1013.06 -1013.06] [0.0000], Avg: [-717.043 -717.043 -717.043] (1.000)
Step: 13299, Reward: [-896.455 -896.455 -896.455] [0.0000], Avg: [-717.717 -717.717 -717.717] (1.000)
Step: 13349, Reward: [-762.511 -762.511 -762.511] [0.0000], Avg: [-717.885 -717.885 -717.885] (1.000)
Step: 13399, Reward: [-656.191 -656.191 -656.191] [0.0000], Avg: [-717.655 -717.655 -717.655] (1.000)
Step: 13449, Reward: [-883.419 -883.419 -883.419] [0.0000], Avg: [-718.271 -718.271 -718.271] (1.000)
Step: 13499, Reward: [-759.627 -759.627 -759.627] [0.0000], Avg: [-718.424 -718.424 -718.424] (1.000)
Step: 13549, Reward: [-1016.922 -1016.922 -1016.922] [0.0000], Avg: [-719.526 -719.526 -719.526] (1.000)
Step: 13599, Reward: [-928.046 -928.046 -928.046] [0.0000], Avg: [-720.292 -720.292 -720.292] (1.000)
Step: 13649, Reward: [-895.005 -895.005 -895.005] [0.0000], Avg: [-720.932 -720.932 -720.932] (1.000)
Step: 13699, Reward: [-1110.911 -1110.911 -1110.911] [0.0000], Avg: [-722.356 -722.356 -722.356] (1.000)
Step: 13749, Reward: [-542.14 -542.14 -542.14] [0.0000], Avg: [-721.7 -721.7 -721.7] (1.000)
Step: 13799, Reward: [-741.983 -741.983 -741.983] [0.0000], Avg: [-721.774 -721.774 -721.774] (1.000)
Step: 13849, Reward: [-745.815 -745.815 -745.815] [0.0000], Avg: [-721.861 -721.861 -721.861] (1.000)
Step: 13899, Reward: [-876.194 -876.194 -876.194] [0.0000], Avg: [-722.416 -722.416 -722.416] (1.000)
Step: 13949, Reward: [-883.957 -883.957 -883.957] [0.0000], Avg: [-722.995 -722.995 -722.995] (1.000)
Step: 13999, Reward: [-738.989 -738.989 -738.989] [0.0000], Avg: [-723.052 -723.052 -723.052] (1.000)
Step: 14049, Reward: [-545.11 -545.11 -545.11] [0.0000], Avg: [-722.419 -722.419 -722.419] (1.000)
Step: 14099, Reward: [-407.932 -407.932 -407.932] [0.0000], Avg: [-721.303 -721.303 -721.303] (1.000)
Step: 14149, Reward: [-991.643 -991.643 -991.643] [0.0000], Avg: [-722.259 -722.259 -722.259] (1.000)
Step: 14199, Reward: [-591.095 -591.095 -591.095] [0.0000], Avg: [-721.797 -721.797 -721.797] (1.000)
Step: 14249, Reward: [-865.561 -865.561 -865.561] [0.0000], Avg: [-722.301 -722.301 -722.301] (1.000)
Step: 14299, Reward: [-709.295 -709.295 -709.295] [0.0000], Avg: [-722.256 -722.256 -722.256] (1.000)
Step: 14349, Reward: [-736.784 -736.784 -736.784] [0.0000], Avg: [-722.306 -722.306 -722.306] (1.000)
Step: 14399, Reward: [-572.766 -572.766 -572.766] [0.0000], Avg: [-721.787 -721.787 -721.787] (1.000)
Step: 14449, Reward: [-837.892 -837.892 -837.892] [0.0000], Avg: [-722.189 -722.189 -722.189] (1.000)
Step: 14499, Reward: [-802.091 -802.091 -802.091] [0.0000], Avg: [-722.464 -722.464 -722.464] (1.000)
Step: 14549, Reward: [-554.702 -554.702 -554.702] [0.0000], Avg: [-721.888 -721.888 -721.888] (1.000)
Step: 14599, Reward: [-648.007 -648.007 -648.007] [0.0000], Avg: [-721.635 -721.635 -721.635] (1.000)
Step: 14649, Reward: [-534.247 -534.247 -534.247] [0.0000], Avg: [-720.995 -720.995 -720.995] (1.000)
Step: 14699, Reward: [-642.74 -642.74 -642.74] [0.0000], Avg: [-720.729 -720.729 -720.729] (1.000)
Step: 14749, Reward: [-579.18 -579.18 -579.18] [0.0000], Avg: [-720.249 -720.249 -720.249] (1.000)
Step: 14799, Reward: [-732.096 -732.096 -732.096] [0.0000], Avg: [-720.289 -720.289 -720.289] (1.000)
Step: 14849, Reward: [-542.894 -542.894 -542.894] [0.0000], Avg: [-719.692 -719.692 -719.692] (1.000)
Step: 14899, Reward: [-581.79 -581.79 -581.79] [0.0000], Avg: [-719.229 -719.229 -719.229] (1.000)
Step: 14949, Reward: [-553.79 -553.79 -553.79] [0.0000], Avg: [-718.676 -718.676 -718.676] (1.000)
Step: 14999, Reward: [-678.394 -678.394 -678.394] [0.0000], Avg: [-718.542 -718.542 -718.542] (1.000)
Step: 15049, Reward: [-519.32 -519.32 -519.32] [0.0000], Avg: [-717.88 -717.88 -717.88] (1.000)
Step: 15099, Reward: [-710.447 -710.447 -710.447] [0.0000], Avg: [-717.855 -717.855 -717.855] (1.000)
Step: 15149, Reward: [-497.353 -497.353 -497.353] [0.0000], Avg: [-717.128 -717.128 -717.128] (1.000)
Step: 15199, Reward: [-630.246 -630.246 -630.246] [0.0000], Avg: [-716.842 -716.842 -716.842] (1.000)
Step: 15249, Reward: [-419.667 -419.667 -419.667] [0.0000], Avg: [-715.867 -715.867 -715.867] (1.000)
Step: 15299, Reward: [-726.021 -726.021 -726.021] [0.0000], Avg: [-715.901 -715.901 -715.901] (1.000)
Step: 15349, Reward: [-557.556 -557.556 -557.556] [0.0000], Avg: [-715.385 -715.385 -715.385] (1.000)
Step: 15399, Reward: [-1009.842 -1009.842 -1009.842] [0.0000], Avg: [-716.341 -716.341 -716.341] (1.000)
Step: 15449, Reward: [-914.785 -914.785 -914.785] [0.0000], Avg: [-716.983 -716.983 -716.983] (1.000)
Step: 15499, Reward: [-561.978 -561.978 -561.978] [0.0000], Avg: [-716.483 -716.483 -716.483] (1.000)
Step: 15549, Reward: [-1049.262 -1049.262 -1049.262] [0.0000], Avg: [-717.553 -717.553 -717.553] (1.000)
Step: 15599, Reward: [-911.257 -911.257 -911.257] [0.0000], Avg: [-718.174 -718.174 -718.174] (1.000)
Step: 15649, Reward: [-572.593 -572.593 -572.593] [0.0000], Avg: [-717.709 -717.709 -717.709] (1.000)
Step: 15699, Reward: [-1355.515 -1355.515 -1355.515] [0.0000], Avg: [-719.74 -719.74 -719.74] (1.000)
Step: 15749, Reward: [-1521.932 -1521.932 -1521.932] [0.0000], Avg: [-722.287 -722.287 -722.287] (1.000)
Step: 15799, Reward: [-1163.889 -1163.889 -1163.889] [0.0000], Avg: [-723.684 -723.684 -723.684] (1.000)
Step: 15849, Reward: [-860.49 -860.49 -860.49] [0.0000], Avg: [-724.116 -724.116 -724.116] (1.000)
Step: 15899, Reward: [-560.865 -560.865 -560.865] [0.0000], Avg: [-723.602 -723.602 -723.602] (1.000)
Step: 15949, Reward: [-754.959 -754.959 -754.959] [0.0000], Avg: [-723.701 -723.701 -723.701] (1.000)
Step: 15999, Reward: [-507.642 -507.642 -507.642] [0.0000], Avg: [-723.025 -723.025 -723.025] (1.000)
Step: 16049, Reward: [-547.944 -547.944 -547.944] [0.0000], Avg: [-722.48 -722.48 -722.48] (1.000)
Step: 16099, Reward: [-435.895 -435.895 -435.895] [0.0000], Avg: [-721.59 -721.59 -721.59] (1.000)
Step: 16149, Reward: [-416.979 -416.979 -416.979] [0.0000], Avg: [-720.647 -720.647 -720.647] (1.000)
Step: 16199, Reward: [-374.726 -374.726 -374.726] [0.0000], Avg: [-719.579 -719.579 -719.579] (1.000)
Step: 16249, Reward: [-494.065 -494.065 -494.065] [0.0000], Avg: [-718.885 -718.885 -718.885] (1.000)
Step: 16299, Reward: [-576.178 -576.178 -576.178] [0.0000], Avg: [-718.448 -718.448 -718.448] (1.000)
Step: 16349, Reward: [-520.846 -520.846 -520.846] [0.0000], Avg: [-717.843 -717.843 -717.843] (1.000)
Step: 16399, Reward: [-442.391 -442.391 -442.391] [0.0000], Avg: [-717.004 -717.004 -717.004] (1.000)
Step: 16449, Reward: [-456.646 -456.646 -456.646] [0.0000], Avg: [-716.212 -716.212 -716.212] (1.000)
Step: 16499, Reward: [-357.826 -357.826 -357.826] [0.0000], Avg: [-715.126 -715.126 -715.126] (1.000)
Step: 16549, Reward: [-354.237 -354.237 -354.237] [0.0000], Avg: [-714.036 -714.036 -714.036] (1.000)
Step: 16599, Reward: [-430.625 -430.625 -430.625] [0.0000], Avg: [-713.182 -713.182 -713.182] (1.000)
Step: 16649, Reward: [-473.29 -473.29 -473.29] [0.0000], Avg: [-712.462 -712.462 -712.462] (1.000)
Step: 16699, Reward: [-432.774 -432.774 -432.774] [0.0000], Avg: [-711.624 -711.624 -711.624] (1.000)
Step: 16749, Reward: [-509.471 -509.471 -509.471] [0.0000], Avg: [-711.021 -711.021 -711.021] (1.000)
Step: 16799, Reward: [-571.498 -571.498 -571.498] [0.0000], Avg: [-710.606 -710.606 -710.606] (1.000)
Step: 16849, Reward: [-539.929 -539.929 -539.929] [0.0000], Avg: [-710.099 -710.099 -710.099] (1.000)
Step: 16899, Reward: [-553.767 -553.767 -553.767] [0.0000], Avg: [-709.637 -709.637 -709.637] (1.000)
Step: 16949, Reward: [-344.021 -344.021 -344.021] [0.0000], Avg: [-708.558 -708.558 -708.558] (1.000)
Step: 16999, Reward: [-423.473 -423.473 -423.473] [0.0000], Avg: [-707.72 -707.72 -707.72] (1.000)
Step: 17049, Reward: [-466.862 -466.862 -466.862] [0.0000], Avg: [-707.013 -707.013 -707.013] (1.000)
Step: 17099, Reward: [-447.707 -447.707 -447.707] [0.0000], Avg: [-706.255 -706.255 -706.255] (1.000)
Step: 17149, Reward: [-406.551 -406.551 -406.551] [0.0000], Avg: [-705.381 -705.381 -705.381] (1.000)
Step: 17199, Reward: [-453.288 -453.288 -453.288] [0.0000], Avg: [-704.649 -704.649 -704.649] (1.000)
Step: 17249, Reward: [-430.08 -430.08 -430.08] [0.0000], Avg: [-703.853 -703.853 -703.853] (1.000)
Step: 17299, Reward: [-319.637 -319.637 -319.637] [0.0000], Avg: [-702.742 -702.742 -702.742] (1.000)
Step: 17349, Reward: [-422.237 -422.237 -422.237] [0.0000], Avg: [-701.934 -701.934 -701.934] (1.000)
Step: 17399, Reward: [-681.077 -681.077 -681.077] [0.0000], Avg: [-701.874 -701.874 -701.874] (1.000)
Step: 17449, Reward: [-574.801 -574.801 -574.801] [0.0000], Avg: [-701.51 -701.51 -701.51] (1.000)
Step: 17499, Reward: [-495.719 -495.719 -495.719] [0.0000], Avg: [-700.922 -700.922 -700.922] (1.000)
Step: 17549, Reward: [-512.204 -512.204 -512.204] [0.0000], Avg: [-700.384 -700.384 -700.384] (1.000)
Step: 17599, Reward: [-469.157 -469.157 -469.157] [0.0000], Avg: [-699.727 -699.727 -699.727] (1.000)
Step: 17649, Reward: [-467.109 -467.109 -467.109] [0.0000], Avg: [-699.068 -699.068 -699.068] (1.000)
Step: 17699, Reward: [-447.699 -447.699 -447.699] [0.0000], Avg: [-698.358 -698.358 -698.358] (1.000)
Step: 17749, Reward: [-474.696 -474.696 -474.696] [0.0000], Avg: [-697.728 -697.728 -697.728] (1.000)
Step: 17799, Reward: [-520.927 -520.927 -520.927] [0.0000], Avg: [-697.232 -697.232 -697.232] (1.000)
Step: 17849, Reward: [-509.88 -509.88 -509.88] [0.0000], Avg: [-696.707 -696.707 -696.707] (1.000)
Step: 17899, Reward: [-441.721 -441.721 -441.721] [0.0000], Avg: [-695.995 -695.995 -695.995] (1.000)
Step: 17949, Reward: [-571.512 -571.512 -571.512] [0.0000], Avg: [-695.648 -695.648 -695.648] (1.000)
Step: 17999, Reward: [-418.091 -418.091 -418.091] [0.0000], Avg: [-694.877 -694.877 -694.877] (1.000)
Step: 18049, Reward: [-641.739 -641.739 -641.739] [0.0000], Avg: [-694.73 -694.73 -694.73] (1.000)
Step: 18099, Reward: [-578.822 -578.822 -578.822] [0.0000], Avg: [-694.41 -694.41 -694.41] (1.000)
Step: 18149, Reward: [-502.398 -502.398 -502.398] [0.0000], Avg: [-693.881 -693.881 -693.881] (1.000)
Step: 18199, Reward: [-542.548 -542.548 -542.548] [0.0000], Avg: [-693.465 -693.465 -693.465] (1.000)
Step: 18249, Reward: [-513.508 -513.508 -513.508] [0.0000], Avg: [-692.972 -692.972 -692.972] (1.000)
Step: 18299, Reward: [-528.907 -528.907 -528.907] [0.0000], Avg: [-692.523 -692.523 -692.523] (1.000)
Step: 18349, Reward: [-434.612 -434.612 -434.612] [0.0000], Avg: [-691.821 -691.821 -691.821] (1.000)
Step: 18399, Reward: [-319.793 -319.793 -319.793] [0.0000], Avg: [-690.81 -690.81 -690.81] (1.000)
Step: 18449, Reward: [-697.362 -697.362 -697.362] [0.0000], Avg: [-690.828 -690.828 -690.828] (1.000)
Step: 18499, Reward: [-436.419 -436.419 -436.419] [0.0000], Avg: [-690.14 -690.14 -690.14] (1.000)
Step: 18549, Reward: [-373.47 -373.47 -373.47] [0.0000], Avg: [-689.286 -689.286 -689.286] (1.000)
Step: 18599, Reward: [-375.91 -375.91 -375.91] [0.0000], Avg: [-688.444 -688.444 -688.444] (1.000)
Step: 18649, Reward: [-350.659 -350.659 -350.659] [0.0000], Avg: [-687.538 -687.538 -687.538] (1.000)
Step: 18699, Reward: [-420.503 -420.503 -420.503] [0.0000], Avg: [-686.824 -686.824 -686.824] (1.000)
Step: 18749, Reward: [-436.007 -436.007 -436.007] [0.0000], Avg: [-686.156 -686.156 -686.156] (1.000)
Step: 18799, Reward: [-538.901 -538.901 -538.901] [0.0000], Avg: [-685.764 -685.764 -685.764] (1.000)
Step: 18849, Reward: [-424.701 -424.701 -424.701] [0.0000], Avg: [-685.071 -685.071 -685.071] (1.000)
Step: 18899, Reward: [-547.679 -547.679 -547.679] [0.0000], Avg: [-684.708 -684.708 -684.708] (1.000)
Step: 18949, Reward: [-623.725 -623.725 -623.725] [0.0000], Avg: [-684.547 -684.547 -684.547] (1.000)
Step: 18999, Reward: [-483.467 -483.467 -483.467] [0.0000], Avg: [-684.018 -684.018 -684.018] (1.000)
Step: 19049, Reward: [-445.797 -445.797 -445.797] [0.0000], Avg: [-683.393 -683.393 -683.393] (1.000)
Step: 19099, Reward: [-438.264 -438.264 -438.264] [0.0000], Avg: [-682.751 -682.751 -682.751] (1.000)
Step: 19149, Reward: [-487.371 -487.371 -487.371] [0.0000], Avg: [-682.241 -682.241 -682.241] (1.000)
Step: 19199, Reward: [-424.537 -424.537 -424.537] [0.0000], Avg: [-681.57 -681.57 -681.57] (1.000)
Step: 19249, Reward: [-465.991 -465.991 -465.991] [0.0000], Avg: [-681.01 -681.01 -681.01] (1.000)
Step: 19299, Reward: [-325.709 -325.709 -325.709] [0.0000], Avg: [-680.089 -680.089 -680.089] (1.000)
Step: 19349, Reward: [-604.757 -604.757 -604.757] [0.0000], Avg: [-679.895 -679.895 -679.895] (1.000)
Step: 19399, Reward: [-335.076 -335.076 -335.076] [0.0000], Avg: [-679.006 -679.006 -679.006] (1.000)
Step: 19449, Reward: [-497.059 -497.059 -497.059] [0.0000], Avg: [-678.538 -678.538 -678.538] (1.000)
Step: 19499, Reward: [-621.988 -621.988 -621.988] [0.0000], Avg: [-678.393 -678.393 -678.393] (1.000)
Step: 19549, Reward: [-562.135 -562.135 -562.135] [0.0000], Avg: [-678.096 -678.096 -678.096] (1.000)
Step: 19599, Reward: [-427.283 -427.283 -427.283] [0.0000], Avg: [-677.456 -677.456 -677.456] (1.000)
Step: 19649, Reward: [-682.619 -682.619 -682.619] [0.0000], Avg: [-677.469 -677.469 -677.469] (1.000)
Step: 19699, Reward: [-467.617 -467.617 -467.617] [0.0000], Avg: [-676.937 -676.937 -676.937] (1.000)
Step: 19749, Reward: [-504.329 -504.329 -504.329] [0.0000], Avg: [-676.5 -676.5 -676.5] (1.000)
Step: 19799, Reward: [-518.365 -518.365 -518.365] [0.0000], Avg: [-676.1 -676.1 -676.1] (1.000)
Step: 19849, Reward: [-744.131 -744.131 -744.131] [0.0000], Avg: [-676.272 -676.272 -676.272] (1.000)
Step: 19899, Reward: [-410.807 -410.807 -410.807] [0.0000], Avg: [-675.605 -675.605 -675.605] (1.000)
Step: 19949, Reward: [-520.252 -520.252 -520.252] [0.0000], Avg: [-675.215 -675.215 -675.215] (1.000)
Step: 19999, Reward: [-751.007 -751.007 -751.007] [0.0000], Avg: [-675.405 -675.405 -675.405] (1.000)
Step: 20049, Reward: [-358.003 -358.003 -358.003] [0.0000], Avg: [-674.613 -674.613 -674.613] (1.000)
Step: 20099, Reward: [-596.271 -596.271 -596.271] [0.0000], Avg: [-674.418 -674.418 -674.418] (1.000)
Step: 20149, Reward: [-443.843 -443.843 -443.843] [0.0000], Avg: [-673.846 -673.846 -673.846] (1.000)
Step: 20199, Reward: [-575.83 -575.83 -575.83] [0.0000], Avg: [-673.604 -673.604 -673.604] (1.000)
Step: 20249, Reward: [-417.032 -417.032 -417.032] [0.0000], Avg: [-672.97 -672.97 -672.97] (1.000)
Step: 20299, Reward: [-548.666 -548.666 -548.666] [0.0000], Avg: [-672.664 -672.664 -672.664] (1.000)
Step: 20349, Reward: [-455.4 -455.4 -455.4] [0.0000], Avg: [-672.13 -672.13 -672.13] (1.000)
Step: 20399, Reward: [-436.75 -436.75 -436.75] [0.0000], Avg: [-671.553 -671.553 -671.553] (1.000)
Step: 20449, Reward: [-480.503 -480.503 -480.503] [0.0000], Avg: [-671.086 -671.086 -671.086] (1.000)
Step: 20499, Reward: [-622.078 -622.078 -622.078] [0.0000], Avg: [-670.967 -670.967 -670.967] (1.000)
Step: 20549, Reward: [-522.201 -522.201 -522.201] [0.0000], Avg: [-670.605 -670.605 -670.605] (1.000)
Step: 20599, Reward: [-411.471 -411.471 -411.471] [0.0000], Avg: [-669.976 -669.976 -669.976] (1.000)
Step: 20649, Reward: [-427.324 -427.324 -427.324] [0.0000], Avg: [-669.388 -669.388 -669.388] (1.000)
Step: 20699, Reward: [-569.941 -569.941 -569.941] [0.0000], Avg: [-669.148 -669.148 -669.148] (1.000)
Step: 20749, Reward: [-449.833 -449.833 -449.833] [0.0000], Avg: [-668.619 -668.619 -668.619] (1.000)
Step: 20799, Reward: [-556.445 -556.445 -556.445] [0.0000], Avg: [-668.35 -668.35 -668.35] (1.000)
Step: 20849, Reward: [-550.895 -550.895 -550.895] [0.0000], Avg: [-668.068 -668.068 -668.068] (1.000)
Step: 20899, Reward: [-861.905 -861.905 -861.905] [0.0000], Avg: [-668.532 -668.532 -668.532] (1.000)
Step: 20949, Reward: [-427.668 -427.668 -427.668] [0.0000], Avg: [-667.957 -667.957 -667.957] (1.000)
Step: 20999, Reward: [-482.392 -482.392 -482.392] [0.0000], Avg: [-667.515 -667.515 -667.515] (1.000)
Step: 21049, Reward: [-633.163 -633.163 -633.163] [0.0000], Avg: [-667.434 -667.434 -667.434] (1.000)
Step: 21099, Reward: [-559.276 -559.276 -559.276] [0.0000], Avg: [-667.177 -667.177 -667.177] (1.000)
Step: 21149, Reward: [-628.472 -628.472 -628.472] [0.0000], Avg: [-667.086 -667.086 -667.086] (1.000)
Step: 21199, Reward: [-532.38 -532.38 -532.38] [0.0000], Avg: [-666.768 -666.768 -666.768] (1.000)
Step: 21249, Reward: [-595.672 -595.672 -595.672] [0.0000], Avg: [-666.601 -666.601 -666.601] (1.000)
Step: 21299, Reward: [-551.689 -551.689 -551.689] [0.0000], Avg: [-666.331 -666.331 -666.331] (1.000)
Step: 21349, Reward: [-505.444 -505.444 -505.444] [0.0000], Avg: [-665.954 -665.954 -665.954] (1.000)
Step: 21399, Reward: [-380.876 -380.876 -380.876] [0.0000], Avg: [-665.288 -665.288 -665.288] (1.000)
Step: 21449, Reward: [-590.755 -590.755 -590.755] [0.0000], Avg: [-665.114 -665.114 -665.114] (1.000)
Step: 21499, Reward: [-508.946 -508.946 -508.946] [0.0000], Avg: [-664.751 -664.751 -664.751] (1.000)
Step: 21549, Reward: [-424.502 -424.502 -424.502] [0.0000], Avg: [-664.194 -664.194 -664.194] (1.000)
Step: 21599, Reward: [-395.21 -395.21 -395.21] [0.0000], Avg: [-663.571 -663.571 -663.571] (1.000)
Step: 21649, Reward: [-668.577 -668.577 -668.577] [0.0000], Avg: [-663.583 -663.583 -663.583] (1.000)
Step: 21699, Reward: [-721.617 -721.617 -721.617] [0.0000], Avg: [-663.716 -663.716 -663.716] (1.000)
Step: 21749, Reward: [-458.35 -458.35 -458.35] [0.0000], Avg: [-663.244 -663.244 -663.244] (1.000)
Step: 21799, Reward: [-531.567 -531.567 -531.567] [0.0000], Avg: [-662.942 -662.942 -662.942] (1.000)
Step: 21849, Reward: [-484.89 -484.89 -484.89] [0.0000], Avg: [-662.535 -662.535 -662.535] (1.000)
Step: 21899, Reward: [-559.843 -559.843 -559.843] [0.0000], Avg: [-662.3 -662.3 -662.3] (1.000)
Step: 21949, Reward: [-436.931 -436.931 -436.931] [0.0000], Avg: [-661.787 -661.787 -661.787] (1.000)
Step: 21999, Reward: [-564.21 -564.21 -564.21] [0.0000], Avg: [-661.565 -661.565 -661.565] (1.000)
Step: 22049, Reward: [-388.071 -388.071 -388.071] [0.0000], Avg: [-660.945 -660.945 -660.945] (1.000)
Step: 22099, Reward: [-459.573 -459.573 -459.573] [0.0000], Avg: [-660.49 -660.49 -660.49] (1.000)
Step: 22149, Reward: [-560.79 -560.79 -560.79] [0.0000], Avg: [-660.264 -660.264 -660.264] (1.000)
Step: 22199, Reward: [-333.104 -333.104 -333.104] [0.0000], Avg: [-659.528 -659.528 -659.528] (1.000)
Step: 22249, Reward: [-700.409 -700.409 -700.409] [0.0000], Avg: [-659.619 -659.619 -659.619] (1.000)
Step: 22299, Reward: [-366.173 -366.173 -366.173] [0.0000], Avg: [-658.962 -658.962 -658.962] (1.000)
Step: 22349, Reward: [-455.349 -455.349 -455.349] [0.0000], Avg: [-658.506 -658.506 -658.506] (1.000)
Step: 22399, Reward: [-474.805 -474.805 -474.805] [0.0000], Avg: [-658.096 -658.096 -658.096] (1.000)
Step: 22449, Reward: [-366.268 -366.268 -366.268] [0.0000], Avg: [-657.446 -657.446 -657.446] (1.000)
Step: 22499, Reward: [-361.38 -361.38 -361.38] [0.0000], Avg: [-656.788 -656.788 -656.788] (1.000)
Step: 22549, Reward: [-411.178 -411.178 -411.178] [0.0000], Avg: [-656.244 -656.244 -656.244] (1.000)
Step: 22599, Reward: [-372.87 -372.87 -372.87] [0.0000], Avg: [-655.617 -655.617 -655.617] (1.000)
Step: 22649, Reward: [-456.863 -456.863 -456.863] [0.0000], Avg: [-655.178 -655.178 -655.178] (1.000)
Step: 22699, Reward: [-365.26 -365.26 -365.26] [0.0000], Avg: [-654.539 -654.539 -654.539] (1.000)
Step: 22749, Reward: [-380.709 -380.709 -380.709] [0.0000], Avg: [-653.937 -653.937 -653.937] (1.000)
Step: 22799, Reward: [-383.713 -383.713 -383.713] [0.0000], Avg: [-653.345 -653.345 -653.345] (1.000)
Step: 22849, Reward: [-465.729 -465.729 -465.729] [0.0000], Avg: [-652.934 -652.934 -652.934] (1.000)
Step: 22899, Reward: [-505.239 -505.239 -505.239] [0.0000], Avg: [-652.612 -652.612 -652.612] (1.000)
Step: 22949, Reward: [-450.994 -450.994 -450.994] [0.0000], Avg: [-652.173 -652.173 -652.173] (1.000)
Step: 22999, Reward: [-597.277 -597.277 -597.277] [0.0000], Avg: [-652.053 -652.053 -652.053] (1.000)
Step: 23049, Reward: [-408.92 -408.92 -408.92] [0.0000], Avg: [-651.526 -651.526 -651.526] (1.000)
Step: 23099, Reward: [-508.97 -508.97 -508.97] [0.0000], Avg: [-651.217 -651.217 -651.217] (1.000)
Step: 23149, Reward: [-399.917 -399.917 -399.917] [0.0000], Avg: [-650.674 -650.674 -650.674] (1.000)
Step: 23199, Reward: [-449.064 -449.064 -449.064] [0.0000], Avg: [-650.24 -650.24 -650.24] (1.000)
Step: 23249, Reward: [-496.861 -496.861 -496.861] [0.0000], Avg: [-649.91 -649.91 -649.91] (1.000)
Step: 23299, Reward: [-850.29 -850.29 -850.29] [0.0000], Avg: [-650.34 -650.34 -650.34] (1.000)
Step: 23349, Reward: [-463.505 -463.505 -463.505] [0.0000], Avg: [-649.94 -649.94 -649.94] (1.000)
Step: 23399, Reward: [-499.639 -499.639 -499.639] [0.0000], Avg: [-649.619 -649.619 -649.619] (1.000)
Step: 23449, Reward: [-508.671 -508.671 -508.671] [0.0000], Avg: [-649.318 -649.318 -649.318] (1.000)
Step: 23499, Reward: [-425.235 -425.235 -425.235] [0.0000], Avg: [-648.842 -648.842 -648.842] (1.000)
Step: 23549, Reward: [-900.47 -900.47 -900.47] [0.0000], Avg: [-649.376 -649.376 -649.376] (1.000)
Step: 23599, Reward: [-538.844 -538.844 -538.844] [0.0000], Avg: [-649.142 -649.142 -649.142] (1.000)
Step: 23649, Reward: [-838.295 -838.295 -838.295] [0.0000], Avg: [-649.542 -649.542 -649.542] (1.000)
Step: 23699, Reward: [-654.49 -654.49 -654.49] [0.0000], Avg: [-649.552 -649.552 -649.552] (1.000)
Step: 23749, Reward: [-643.8 -643.8 -643.8] [0.0000], Avg: [-649.54 -649.54 -649.54] (1.000)
Step: 23799, Reward: [-683.253 -683.253 -683.253] [0.0000], Avg: [-649.611 -649.611 -649.611] (1.000)
Step: 23849, Reward: [-616.005 -616.005 -616.005] [0.0000], Avg: [-649.54 -649.54 -649.54] (1.000)
Step: 23899, Reward: [-841.406 -841.406 -841.406] [0.0000], Avg: [-649.942 -649.942 -649.942] (1.000)
Step: 23949, Reward: [-990.872 -990.872 -990.872] [0.0000], Avg: [-650.653 -650.653 -650.653] (1.000)
Step: 23999, Reward: [-791.17 -791.17 -791.17] [0.0000], Avg: [-650.946 -650.946 -650.946] (1.000)
Step: 24049, Reward: [-965.176 -965.176 -965.176] [0.0000], Avg: [-651.599 -651.599 -651.599] (1.000)
Step: 24099, Reward: [-702.022 -702.022 -702.022] [0.0000], Avg: [-651.704 -651.704 -651.704] (1.000)
Step: 24149, Reward: [-523.016 -523.016 -523.016] [0.0000], Avg: [-651.438 -651.438 -651.438] (1.000)
Step: 24199, Reward: [-747.388 -747.388 -747.388] [0.0000], Avg: [-651.636 -651.636 -651.636] (1.000)
Step: 24249, Reward: [-904.124 -904.124 -904.124] [0.0000], Avg: [-652.156 -652.156 -652.156] (1.000)
Step: 24299, Reward: [-753.202 -753.202 -753.202] [0.0000], Avg: [-652.364 -652.364 -652.364] (1.000)
Step: 24349, Reward: [-871.278 -871.278 -871.278] [0.0000], Avg: [-652.814 -652.814 -652.814] (1.000)
Step: 24399, Reward: [-923.716 -923.716 -923.716] [0.0000], Avg: [-653.369 -653.369 -653.369] (1.000)
Step: 24449, Reward: [-928.002 -928.002 -928.002] [0.0000], Avg: [-653.931 -653.931 -653.931] (1.000)
Step: 24499, Reward: [-964.46 -964.46 -964.46] [0.0000], Avg: [-654.564 -654.564 -654.564] (1.000)
Step: 24549, Reward: [-769.35 -769.35 -769.35] [0.0000], Avg: [-654.798 -654.798 -654.798] (1.000)
Step: 24599, Reward: [-806.715 -806.715 -806.715] [0.0000], Avg: [-655.107 -655.107 -655.107] (1.000)
Step: 24649, Reward: [-607.326 -607.326 -607.326] [0.0000], Avg: [-655.01 -655.01 -655.01] (1.000)
Step: 24699, Reward: [-631.209 -631.209 -631.209] [0.0000], Avg: [-654.962 -654.962 -654.962] (1.000)
Step: 24749, Reward: [-687.115 -687.115 -687.115] [0.0000], Avg: [-655.027 -655.027 -655.027] (1.000)
Step: 24799, Reward: [-591.097 -591.097 -591.097] [0.0000], Avg: [-654.898 -654.898 -654.898] (1.000)
Step: 24849, Reward: [-619.822 -619.822 -619.822] [0.0000], Avg: [-654.827 -654.827 -654.827] (1.000)
Step: 24899, Reward: [-609.257 -609.257 -609.257] [0.0000], Avg: [-654.736 -654.736 -654.736] (1.000)
Step: 24949, Reward: [-836.297 -836.297 -836.297] [0.0000], Avg: [-655.1 -655.1 -655.1] (1.000)
Step: 24999, Reward: [-687.592 -687.592 -687.592] [0.0000], Avg: [-655.165 -655.165 -655.165] (1.000)
Step: 25049, Reward: [-463.075 -463.075 -463.075] [0.0000], Avg: [-654.781 -654.781 -654.781] (1.000)
Step: 25099, Reward: [-371.468 -371.468 -371.468] [0.0000], Avg: [-654.217 -654.217 -654.217] (1.000)
Step: 25149, Reward: [-776.441 -776.441 -776.441] [0.0000], Avg: [-654.46 -654.46 -654.46] (1.000)
Step: 25199, Reward: [-505.941 -505.941 -505.941] [0.0000], Avg: [-654.165 -654.165 -654.165] (1.000)
Step: 25249, Reward: [-503. -503. -503.] [0.0000], Avg: [-653.866 -653.866 -653.866] (1.000)
Step: 25299, Reward: [-780.098 -780.098 -780.098] [0.0000], Avg: [-654.115 -654.115 -654.115] (1.000)
Step: 25349, Reward: [-585.78 -585.78 -585.78] [0.0000], Avg: [-653.981 -653.981 -653.981] (1.000)
Step: 25399, Reward: [-311.242 -311.242 -311.242] [0.0000], Avg: [-653.306 -653.306 -653.306] (1.000)
Step: 25449, Reward: [-691.121 -691.121 -691.121] [0.0000], Avg: [-653.38 -653.38 -653.38] (1.000)
Step: 25499, Reward: [-776.953 -776.953 -776.953] [0.0000], Avg: [-653.622 -653.622 -653.622] (1.000)
Step: 25549, Reward: [-566.796 -566.796 -566.796] [0.0000], Avg: [-653.453 -653.453 -653.453] (1.000)
Step: 25599, Reward: [-872.028 -872.028 -872.028] [0.0000], Avg: [-653.879 -653.879 -653.879] (1.000)
Step: 25649, Reward: [-481.869 -481.869 -481.869] [0.0000], Avg: [-653.544 -653.544 -653.544] (1.000)
Step: 25699, Reward: [-701.819 -701.819 -701.819] [0.0000], Avg: [-653.638 -653.638 -653.638] (1.000)
Step: 25749, Reward: [-816.617 -816.617 -816.617] [0.0000], Avg: [-653.955 -653.955 -653.955] (1.000)
Step: 25799, Reward: [-579.005 -579.005 -579.005] [0.0000], Avg: [-653.809 -653.809 -653.809] (1.000)
Step: 25849, Reward: [-850.367 -850.367 -850.367] [0.0000], Avg: [-654.189 -654.189 -654.189] (1.000)
Step: 25899, Reward: [-513.749 -513.749 -513.749] [0.0000], Avg: [-653.918 -653.918 -653.918] (1.000)
Step: 25949, Reward: [-403.725 -403.725 -403.725] [0.0000], Avg: [-653.436 -653.436 -653.436] (1.000)
Step: 25999, Reward: [-539.067 -539.067 -539.067] [0.0000], Avg: [-653.216 -653.216 -653.216] (1.000)
Step: 26049, Reward: [-491.491 -491.491 -491.491] [0.0000], Avg: [-652.906 -652.906 -652.906] (1.000)
Step: 26099, Reward: [-641.053 -641.053 -641.053] [0.0000], Avg: [-652.883 -652.883 -652.883] (1.000)
Step: 26149, Reward: [-690.353 -690.353 -690.353] [0.0000], Avg: [-652.955 -652.955 -652.955] (1.000)
Step: 26199, Reward: [-354.019 -354.019 -354.019] [0.0000], Avg: [-652.384 -652.384 -652.384] (1.000)
Step: 26249, Reward: [-332.437 -332.437 -332.437] [0.0000], Avg: [-651.775 -651.775 -651.775] (1.000)
Step: 26299, Reward: [-377.65 -377.65 -377.65] [0.0000], Avg: [-651.254 -651.254 -651.254] (1.000)
Step: 26349, Reward: [-424.05 -424.05 -424.05] [0.0000], Avg: [-650.823 -650.823 -650.823] (1.000)
Step: 26399, Reward: [-337.077 -337.077 -337.077] [0.0000], Avg: [-650.228 -650.228 -650.228] (1.000)
Step: 26449, Reward: [-449.147 -449.147 -449.147] [0.0000], Avg: [-649.848 -649.848 -649.848] (1.000)
Step: 26499, Reward: [-417.028 -417.028 -417.028] [0.0000], Avg: [-649.409 -649.409 -649.409] (1.000)
Step: 26549, Reward: [-419.896 -419.896 -419.896] [0.0000], Avg: [-648.977 -648.977 -648.977] (1.000)
Step: 26599, Reward: [-436.45 -436.45 -436.45] [0.0000], Avg: [-648.577 -648.577 -648.577] (1.000)
Step: 26649, Reward: [-514.877 -514.877 -514.877] [0.0000], Avg: [-648.326 -648.326 -648.326] (1.000)
Step: 26699, Reward: [-422.818 -422.818 -422.818] [0.0000], Avg: [-647.904 -647.904 -647.904] (1.000)
Step: 26749, Reward: [-502.802 -502.802 -502.802] [0.0000], Avg: [-647.633 -647.633 -647.633] (1.000)
Step: 26799, Reward: [-500.31 -500.31 -500.31] [0.0000], Avg: [-647.358 -647.358 -647.358] (1.000)
Step: 26849, Reward: [-398.682 -398.682 -398.682] [0.0000], Avg: [-646.895 -646.895 -646.895] (1.000)
Step: 26899, Reward: [-409.148 -409.148 -409.148] [0.0000], Avg: [-646.453 -646.453 -646.453] (1.000)
Step: 26949, Reward: [-466.558 -466.558 -466.558] [0.0000], Avg: [-646.119 -646.119 -646.119] (1.000)
Step: 26999, Reward: [-333.387 -333.387 -333.387] [0.0000], Avg: [-645.54 -645.54 -645.54] (1.000)
Step: 27049, Reward: [-367.112 -367.112 -367.112] [0.0000], Avg: [-645.026 -645.026 -645.026] (1.000)
Step: 27099, Reward: [-468.023 -468.023 -468.023] [0.0000], Avg: [-644.699 -644.699 -644.699] (1.000)
Step: 27149, Reward: [-379.737 -379.737 -379.737] [0.0000], Avg: [-644.211 -644.211 -644.211] (1.000)
Step: 27199, Reward: [-428.429 -428.429 -428.429] [0.0000], Avg: [-643.814 -643.814 -643.814] (1.000)
Step: 27249, Reward: [-405.684 -405.684 -405.684] [0.0000], Avg: [-643.377 -643.377 -643.377] (1.000)
Step: 27299, Reward: [-510.422 -510.422 -510.422] [0.0000], Avg: [-643.134 -643.134 -643.134] (1.000)
Step: 27349, Reward: [-368.234 -368.234 -368.234] [0.0000], Avg: [-642.631 -642.631 -642.631] (1.000)
Step: 27399, Reward: [-451.91 -451.91 -451.91] [0.0000], Avg: [-642.283 -642.283 -642.283] (1.000)
Step: 27449, Reward: [-342.51 -342.51 -342.51] [0.0000], Avg: [-641.737 -641.737 -641.737] (1.000)
Step: 27499, Reward: [-442.933 -442.933 -442.933] [0.0000], Avg: [-641.376 -641.376 -641.376] (1.000)
Step: 27549, Reward: [-643.446 -643.446 -643.446] [0.0000], Avg: [-641.38 -641.38 -641.38] (1.000)
Step: 27599, Reward: [-401.957 -401.957 -401.957] [0.0000], Avg: [-640.946 -640.946 -640.946] (1.000)
Step: 27649, Reward: [-499.686 -499.686 -499.686] [0.0000], Avg: [-640.69 -640.69 -640.69] (1.000)
Step: 27699, Reward: [-403.513 -403.513 -403.513] [0.0000], Avg: [-640.262 -640.262 -640.262] (1.000)
Step: 27749, Reward: [-462.061 -462.061 -462.061] [0.0000], Avg: [-639.941 -639.941 -639.941] (1.000)
Step: 27799, Reward: [-340.872 -340.872 -340.872] [0.0000], Avg: [-639.403 -639.403 -639.403] (1.000)
Step: 27849, Reward: [-495.012 -495.012 -495.012] [0.0000], Avg: [-639.144 -639.144 -639.144] (1.000)
Step: 27899, Reward: [-391.256 -391.256 -391.256] [0.0000], Avg: [-638.7 -638.7 -638.7] (1.000)
Step: 27949, Reward: [-379.891 -379.891 -379.891] [0.0000], Avg: [-638.237 -638.237 -638.237] (1.000)
Step: 27999, Reward: [-430.757 -430.757 -430.757] [0.0000], Avg: [-637.866 -637.866 -637.866] (1.000)
Step: 28049, Reward: [-553.182 -553.182 -553.182] [0.0000], Avg: [-637.715 -637.715 -637.715] (1.000)
Step: 28099, Reward: [-419.22 -419.22 -419.22] [0.0000], Avg: [-637.327 -637.327 -637.327] (1.000)
Step: 28149, Reward: [-473.137 -473.137 -473.137] [0.0000], Avg: [-637.035 -637.035 -637.035] (1.000)
Step: 28199, Reward: [-466.787 -466.787 -466.787] [0.0000], Avg: [-636.733 -636.733 -636.733] (1.000)
Step: 28249, Reward: [-382.579 -382.579 -382.579] [0.0000], Avg: [-636.283 -636.283 -636.283] (1.000)
Step: 28299, Reward: [-414.04 -414.04 -414.04] [0.0000], Avg: [-635.891 -635.891 -635.891] (1.000)
Step: 28349, Reward: [-678.144 -678.144 -678.144] [0.0000], Avg: [-635.965 -635.965 -635.965] (1.000)
Step: 28399, Reward: [-442.008 -442.008 -442.008] [0.0000], Avg: [-635.624 -635.624 -635.624] (1.000)
Step: 28449, Reward: [-515.816 -515.816 -515.816] [0.0000], Avg: [-635.413 -635.413 -635.413] (1.000)
Step: 28499, Reward: [-449.698 -449.698 -449.698] [0.0000], Avg: [-635.087 -635.087 -635.087] (1.000)
Step: 28549, Reward: [-442.746 -442.746 -442.746] [0.0000], Avg: [-634.75 -634.75 -634.75] (1.000)
Step: 28599, Reward: [-466.329 -466.329 -466.329] [0.0000], Avg: [-634.456 -634.456 -634.456] (1.000)
Step: 28649, Reward: [-391.156 -391.156 -391.156] [0.0000], Avg: [-634.031 -634.031 -634.031] (1.000)
Step: 28699, Reward: [-467.636 -467.636 -467.636] [0.0000], Avg: [-633.742 -633.742 -633.742] (1.000)
Step: 28749, Reward: [-536.412 -536.412 -536.412] [0.0000], Avg: [-633.572 -633.572 -633.572] (1.000)
Step: 28799, Reward: [-296.161 -296.161 -296.161] [0.0000], Avg: [-632.986 -632.986 -632.986] (1.000)
Step: 28849, Reward: [-369.297 -369.297 -369.297] [0.0000], Avg: [-632.529 -632.529 -632.529] (1.000)
Step: 28899, Reward: [-722.797 -722.797 -722.797] [0.0000], Avg: [-632.686 -632.686 -632.686] (1.000)
Step: 28949, Reward: [-437.82 -437.82 -437.82] [0.0000], Avg: [-632.349 -632.349 -632.349] (1.000)
Step: 28999, Reward: [-595.556 -595.556 -595.556] [0.0000], Avg: [-632.286 -632.286 -632.286] (1.000)
Step: 29049, Reward: [-538.534 -538.534 -538.534] [0.0000], Avg: [-632.124 -632.124 -632.124] (1.000)
Step: 29099, Reward: [-516.608 -516.608 -516.608] [0.0000], Avg: [-631.926 -631.926 -631.926] (1.000)
Step: 29149, Reward: [-331.237 -331.237 -331.237] [0.0000], Avg: [-631.41 -631.41 -631.41] (1.000)
Step: 29199, Reward: [-533.991 -533.991 -533.991] [0.0000], Avg: [-631.243 -631.243 -631.243] (1.000)
Step: 29249, Reward: [-497.038 -497.038 -497.038] [0.0000], Avg: [-631.014 -631.014 -631.014] (1.000)
Step: 29299, Reward: [-402.19 -402.19 -402.19] [0.0000], Avg: [-630.623 -630.623 -630.623] (1.000)
Step: 29349, Reward: [-493.964 -493.964 -493.964] [0.0000], Avg: [-630.391 -630.391 -630.391] (1.000)
Step: 29399, Reward: [-375.588 -375.588 -375.588] [0.0000], Avg: [-629.957 -629.957 -629.957] (1.000)
Step: 29449, Reward: [-440.732 -440.732 -440.732] [0.0000], Avg: [-629.636 -629.636 -629.636] (1.000)
Step: 29499, Reward: [-407.075 -407.075 -407.075] [0.0000], Avg: [-629.259 -629.259 -629.259] (1.000)
Step: 29549, Reward: [-495.787 -495.787 -495.787] [0.0000], Avg: [-629.033 -629.033 -629.033] (1.000)
Step: 29599, Reward: [-457.459 -457.459 -457.459] [0.0000], Avg: [-628.743 -628.743 -628.743] (1.000)
Step: 29649, Reward: [-559.07 -559.07 -559.07] [0.0000], Avg: [-628.626 -628.626 -628.626] (1.000)
Step: 29699, Reward: [-410.694 -410.694 -410.694] [0.0000], Avg: [-628.259 -628.259 -628.259] (1.000)
Step: 29749, Reward: [-545.658 -545.658 -545.658] [0.0000], Avg: [-628.12 -628.12 -628.12] (1.000)
Step: 29799, Reward: [-552.68 -552.68 -552.68] [0.0000], Avg: [-627.993 -627.993 -627.993] (1.000)
Step: 29849, Reward: [-553.886 -553.886 -553.886] [0.0000], Avg: [-627.869 -627.869 -627.869] (1.000)
Step: 29899, Reward: [-397.164 -397.164 -397.164] [0.0000], Avg: [-627.483 -627.483 -627.483] (1.000)
Step: 29949, Reward: [-528.111 -528.111 -528.111] [0.0000], Avg: [-627.317 -627.317 -627.317] (1.000)
Step: 29999, Reward: [-340.11 -340.11 -340.11] [0.0000], Avg: [-626.839 -626.839 -626.839] (1.000)
Step: 30049, Reward: [-460.62 -460.62 -460.62] [0.0000], Avg: [-626.562 -626.562 -626.562] (1.000)
Step: 30099, Reward: [-441.921 -441.921 -441.921] [0.0000], Avg: [-626.255 -626.255 -626.255] (1.000)
Step: 30149, Reward: [-477.389 -477.389 -477.389] [0.0000], Avg: [-626.009 -626.009 -626.009] (1.000)
Step: 30199, Reward: [-299.206 -299.206 -299.206] [0.0000], Avg: [-625.468 -625.468 -625.468] (1.000)
Step: 30249, Reward: [-549.101 -549.101 -549.101] [0.0000], Avg: [-625.341 -625.341 -625.341] (1.000)
Step: 30299, Reward: [-437.352 -437.352 -437.352] [0.0000], Avg: [-625.031 -625.031 -625.031] (1.000)
Step: 30349, Reward: [-400.36 -400.36 -400.36] [0.0000], Avg: [-624.661 -624.661 -624.661] (1.000)
Step: 30399, Reward: [-479.465 -479.465 -479.465] [0.0000], Avg: [-624.422 -624.422 -624.422] (1.000)
Step: 30449, Reward: [-397.489 -397.489 -397.489] [0.0000], Avg: [-624.05 -624.05 -624.05] (1.000)
Step: 30499, Reward: [-505.415 -505.415 -505.415] [0.0000], Avg: [-623.855 -623.855 -623.855] (1.000)
Step: 30549, Reward: [-584.983 -584.983 -584.983] [0.0000], Avg: [-623.791 -623.791 -623.791] (1.000)
Step: 30599, Reward: [-421.904 -421.904 -421.904] [0.0000], Avg: [-623.462 -623.462 -623.462] (1.000)
Step: 30649, Reward: [-462.753 -462.753 -462.753] [0.0000], Avg: [-623.199 -623.199 -623.199] (1.000)
Step: 30699, Reward: [-582.92 -582.92 -582.92] [0.0000], Avg: [-623.134 -623.134 -623.134] (1.000)
Step: 30749, Reward: [-430.076 -430.076 -430.076] [0.0000], Avg: [-622.82 -622.82 -622.82] (1.000)
Step: 30799, Reward: [-510.079 -510.079 -510.079] [0.0000], Avg: [-622.637 -622.637 -622.637] (1.000)
Step: 30849, Reward: [-466.126 -466.126 -466.126] [0.0000], Avg: [-622.383 -622.383 -622.383] (1.000)
Step: 30899, Reward: [-569.385 -569.385 -569.385] [0.0000], Avg: [-622.297 -622.297 -622.297] (1.000)
Step: 30949, Reward: [-546.106 -546.106 -546.106] [0.0000], Avg: [-622.174 -622.174 -622.174] (1.000)
Step: 30999, Reward: [-570.906 -570.906 -570.906] [0.0000], Avg: [-622.092 -622.092 -622.092] (1.000)
Step: 31049, Reward: [-434.725 -434.725 -434.725] [0.0000], Avg: [-621.79 -621.79 -621.79] (1.000)
Step: 31099, Reward: [-628.966 -628.966 -628.966] [0.0000], Avg: [-621.801 -621.801 -621.801] (1.000)
Step: 31149, Reward: [-539.05 -539.05 -539.05] [0.0000], Avg: [-621.669 -621.669 -621.669] (1.000)
Step: 31199, Reward: [-499.764 -499.764 -499.764] [0.0000], Avg: [-621.473 -621.473 -621.473] (1.000)
Step: 31249, Reward: [-584.43 -584.43 -584.43] [0.0000], Avg: [-621.414 -621.414 -621.414] (1.000)
Step: 31299, Reward: [-452.516 -452.516 -452.516] [0.0000], Avg: [-621.144 -621.144 -621.144] (1.000)
Step: 31349, Reward: [-404.633 -404.633 -404.633] [0.0000], Avg: [-620.799 -620.799 -620.799] (1.000)
Step: 31399, Reward: [-448.149 -448.149 -448.149] [0.0000], Avg: [-620.524 -620.524 -620.524] (1.000)
Step: 31449, Reward: [-373.919 -373.919 -373.919] [0.0000], Avg: [-620.132 -620.132 -620.132] (1.000)
Step: 31499, Reward: [-597.338 -597.338 -597.338] [0.0000], Avg: [-620.096 -620.096 -620.096] (1.000)
Step: 31549, Reward: [-468.714 -468.714 -468.714] [0.0000], Avg: [-619.856 -619.856 -619.856] (1.000)
Step: 31599, Reward: [-489.136 -489.136 -489.136] [0.0000], Avg: [-619.649 -619.649 -619.649] (1.000)
Step: 31649, Reward: [-573.384 -573.384 -573.384] [0.0000], Avg: [-619.576 -619.576 -619.576] (1.000)
Step: 31699, Reward: [-562.076 -562.076 -562.076] [0.0000], Avg: [-619.485 -619.485 -619.485] (1.000)
Step: 31749, Reward: [-546.361 -546.361 -546.361] [0.0000], Avg: [-619.37 -619.37 -619.37] (1.000)
Step: 31799, Reward: [-527.129 -527.129 -527.129] [0.0000], Avg: [-619.225 -619.225 -619.225] (1.000)
Step: 31849, Reward: [-581.875 -581.875 -581.875] [0.0000], Avg: [-619.166 -619.166 -619.166] (1.000)
Step: 31899, Reward: [-405.34 -405.34 -405.34] [0.0000], Avg: [-618.831 -618.831 -618.831] (1.000)
Step: 31949, Reward: [-506.976 -506.976 -506.976] [0.0000], Avg: [-618.656 -618.656 -618.656] (1.000)
Step: 31999, Reward: [-415.106 -415.106 -415.106] [0.0000], Avg: [-618.338 -618.338 -618.338] (1.000)
Step: 32049, Reward: [-648.1 -648.1 -648.1] [0.0000], Avg: [-618.385 -618.385 -618.385] (1.000)
Step: 32099, Reward: [-563.617 -563.617 -563.617] [0.0000], Avg: [-618.299 -618.299 -618.299] (1.000)
Step: 32149, Reward: [-540.603 -540.603 -540.603] [0.0000], Avg: [-618.178 -618.178 -618.178] (1.000)
Step: 32199, Reward: [-451.044 -451.044 -451.044] [0.0000], Avg: [-617.919 -617.919 -617.919] (1.000)
Step: 32249, Reward: [-413.36 -413.36 -413.36] [0.0000], Avg: [-617.602 -617.602 -617.602] (1.000)
Step: 32299, Reward: [-502.291 -502.291 -502.291] [0.0000], Avg: [-617.423 -617.423 -617.423] (1.000)
Step: 32349, Reward: [-544.107 -544.107 -544.107] [0.0000], Avg: [-617.31 -617.31 -617.31] (1.000)
Step: 32399, Reward: [-556.263 -556.263 -556.263] [0.0000], Avg: [-617.216 -617.216 -617.216] (1.000)
Step: 32449, Reward: [-589.813 -589.813 -589.813] [0.0000], Avg: [-617.173 -617.173 -617.173] (1.000)
Step: 32499, Reward: [-555.541 -555.541 -555.541] [0.0000], Avg: [-617.079 -617.079 -617.079] (1.000)
Step: 32549, Reward: [-658.107 -658.107 -658.107] [0.0000], Avg: [-617.142 -617.142 -617.142] (1.000)
Step: 32599, Reward: [-415.98 -415.98 -415.98] [0.0000], Avg: [-616.833 -616.833 -616.833] (1.000)
Step: 32649, Reward: [-477.261 -477.261 -477.261] [0.0000], Avg: [-616.619 -616.619 -616.619] (1.000)
Step: 32699, Reward: [-496.347 -496.347 -496.347] [0.0000], Avg: [-616.436 -616.436 -616.436] (1.000)
Step: 32749, Reward: [-386.891 -386.891 -386.891] [0.0000], Avg: [-616.085 -616.085 -616.085] (1.000)
Step: 32799, Reward: [-546.843 -546.843 -546.843] [0.0000], Avg: [-615.98 -615.98 -615.98] (1.000)
Step: 32849, Reward: [-383.291 -383.291 -383.291] [0.0000], Avg: [-615.625 -615.625 -615.625] (1.000)
Step: 32899, Reward: [-356.295 -356.295 -356.295] [0.0000], Avg: [-615.231 -615.231 -615.231] (1.000)
Step: 32949, Reward: [-418.964 -418.964 -418.964] [0.0000], Avg: [-614.933 -614.933 -614.933] (1.000)
Step: 32999, Reward: [-444.703 -444.703 -444.703] [0.0000], Avg: [-614.675 -614.675 -614.675] (1.000)
Step: 33049, Reward: [-437.595 -437.595 -437.595] [0.0000], Avg: [-614.408 -614.408 -614.408] (1.000)
Step: 33099, Reward: [-422.85 -422.85 -422.85] [0.0000], Avg: [-614.118 -614.118 -614.118] (1.000)
Step: 33149, Reward: [-383.734 -383.734 -383.734] [0.0000], Avg: [-613.771 -613.771 -613.771] (1.000)
Step: 33199, Reward: [-446.622 -446.622 -446.622] [0.0000], Avg: [-613.519 -613.519 -613.519] (1.000)
Step: 33249, Reward: [-471.626 -471.626 -471.626] [0.0000], Avg: [-613.306 -613.306 -613.306] (1.000)
Step: 33299, Reward: [-448.854 -448.854 -448.854] [0.0000], Avg: [-613.059 -613.059 -613.059] (1.000)
Step: 33349, Reward: [-517.186 -517.186 -517.186] [0.0000], Avg: [-612.915 -612.915 -612.915] (1.000)
Step: 33399, Reward: [-460.592 -460.592 -460.592] [0.0000], Avg: [-612.687 -612.687 -612.687] (1.000)
Step: 33449, Reward: [-484.816 -484.816 -484.816] [0.0000], Avg: [-612.496 -612.496 -612.496] (1.000)
Step: 33499, Reward: [-442.961 -442.961 -442.961] [0.0000], Avg: [-612.243 -612.243 -612.243] (1.000)
Step: 33549, Reward: [-498.461 -498.461 -498.461] [0.0000], Avg: [-612.073 -612.073 -612.073] (1.000)
Step: 33599, Reward: [-501.29 -501.29 -501.29] [0.0000], Avg: [-611.908 -611.908 -611.908] (1.000)
Step: 33649, Reward: [-462.627 -462.627 -462.627] [0.0000], Avg: [-611.687 -611.687 -611.687] (1.000)
Step: 33699, Reward: [-437.183 -437.183 -437.183] [0.0000], Avg: [-611.428 -611.428 -611.428] (1.000)
Step: 33749, Reward: [-368.331 -368.331 -368.331] [0.0000], Avg: [-611.067 -611.067 -611.067] (1.000)
Step: 33799, Reward: [-520.918 -520.918 -520.918] [0.0000], Avg: [-610.934 -610.934 -610.934] (1.000)
Step: 33849, Reward: [-452.415 -452.415 -452.415] [0.0000], Avg: [-610.7 -610.7 -610.7] (1.000)
Step: 33899, Reward: [-422.087 -422.087 -422.087] [0.0000], Avg: [-610.422 -610.422 -610.422] (1.000)
Step: 33949, Reward: [-470.201 -470.201 -470.201] [0.0000], Avg: [-610.215 -610.215 -610.215] (1.000)
Step: 33999, Reward: [-522.536 -522.536 -522.536] [0.0000], Avg: [-610.086 -610.086 -610.086] (1.000)
Step: 34049, Reward: [-487.728 -487.728 -487.728] [0.0000], Avg: [-609.907 -609.907 -609.907] (1.000)
Step: 34099, Reward: [-509.229 -509.229 -509.229] [0.0000], Avg: [-609.759 -609.759 -609.759] (1.000)
Step: 34149, Reward: [-557.777 -557.777 -557.777] [0.0000], Avg: [-609.683 -609.683 -609.683] (1.000)
Step: 34199, Reward: [-414.941 -414.941 -414.941] [0.0000], Avg: [-609.398 -609.398 -609.398] (1.000)
Step: 34249, Reward: [-471.287 -471.287 -471.287] [0.0000], Avg: [-609.197 -609.197 -609.197] (1.000)
Step: 34299, Reward: [-414.303 -414.303 -414.303] [0.0000], Avg: [-608.912 -608.912 -608.912] (1.000)
Step: 34349, Reward: [-552.15 -552.15 -552.15] [0.0000], Avg: [-608.83 -608.83 -608.83] (1.000)
Step: 34399, Reward: [-431.356 -431.356 -431.356] [0.0000], Avg: [-608.572 -608.572 -608.572] (1.000)
Step: 34449, Reward: [-487.853 -487.853 -487.853] [0.0000], Avg: [-608.397 -608.397 -608.397] (1.000)
Step: 34499, Reward: [-391.643 -391.643 -391.643] [0.0000], Avg: [-608.083 -608.083 -608.083] (1.000)
Step: 34549, Reward: [-484.488 -484.488 -484.488] [0.0000], Avg: [-607.904 -607.904 -607.904] (1.000)
Step: 34599, Reward: [-447.737 -447.737 -447.737] [0.0000], Avg: [-607.672 -607.672 -607.672] (1.000)
Step: 34649, Reward: [-388.708 -388.708 -388.708] [0.0000], Avg: [-607.356 -607.356 -607.356] (1.000)
Step: 34699, Reward: [-404.942 -404.942 -404.942] [0.0000], Avg: [-607.065 -607.065 -607.065] (1.000)
Step: 34749, Reward: [-434.635 -434.635 -434.635] [0.0000], Avg: [-606.817 -606.817 -606.817] (1.000)
Step: 34799, Reward: [-549.717 -549.717 -549.717] [0.0000], Avg: [-606.734 -606.734 -606.734] (1.000)
Step: 34849, Reward: [-734.248 -734.248 -734.248] [0.0000], Avg: [-606.917 -606.917 -606.917] (1.000)
Step: 34899, Reward: [-480.362 -480.362 -480.362] [0.0000], Avg: [-606.736 -606.736 -606.736] (1.000)
Step: 34949, Reward: [-406.109 -406.109 -406.109] [0.0000], Avg: [-606.449 -606.449 -606.449] (1.000)
Step: 34999, Reward: [-607.847 -607.847 -607.847] [0.0000], Avg: [-606.451 -606.451 -606.451] (1.000)
Step: 35049, Reward: [-528.054 -528.054 -528.054] [0.0000], Avg: [-606.339 -606.339 -606.339] (1.000)
Step: 35099, Reward: [-457.287 -457.287 -457.287] [0.0000], Avg: [-606.127 -606.127 -606.127] (1.000)
Step: 35149, Reward: [-573.546 -573.546 -573.546] [0.0000], Avg: [-606.081 -606.081 -606.081] (1.000)
Step: 35199, Reward: [-375.066 -375.066 -375.066] [0.0000], Avg: [-605.752 -605.752 -605.752] (1.000)
Step: 35249, Reward: [-364.7 -364.7 -364.7] [0.0000], Avg: [-605.411 -605.411 -605.411] (1.000)
Step: 35299, Reward: [-410.083 -410.083 -410.083] [0.0000], Avg: [-605.134 -605.134 -605.134] (1.000)
Step: 35349, Reward: [-524.371 -524.371 -524.371] [0.0000], Avg: [-605.02 -605.02 -605.02] (1.000)
Step: 35399, Reward: [-603.664 -603.664 -603.664] [0.0000], Avg: [-605.018 -605.018 -605.018] (1.000)
Step: 35449, Reward: [-366.86 -366.86 -366.86] [0.0000], Avg: [-604.682 -604.682 -604.682] (1.000)
Step: 35499, Reward: [-487.065 -487.065 -487.065] [0.0000], Avg: [-604.516 -604.516 -604.516] (1.000)
Step: 35549, Reward: [-373.771 -373.771 -373.771] [0.0000], Avg: [-604.192 -604.192 -604.192] (1.000)
Step: 35599, Reward: [-379.159 -379.159 -379.159] [0.0000], Avg: [-603.876 -603.876 -603.876] (1.000)
Step: 35649, Reward: [-430.007 -430.007 -430.007] [0.0000], Avg: [-603.632 -603.632 -603.632] (1.000)
Step: 35699, Reward: [-364.361 -364.361 -364.361] [0.0000], Avg: [-603.297 -603.297 -603.297] (1.000)
Step: 35749, Reward: [-356.064 -356.064 -356.064] [0.0000], Avg: [-602.951 -602.951 -602.951] (1.000)
Step: 35799, Reward: [-522.572 -522.572 -522.572] [0.0000], Avg: [-602.839 -602.839 -602.839] (1.000)
Step: 35849, Reward: [-496.339 -496.339 -496.339] [0.0000], Avg: [-602.69 -602.69 -602.69] (1.000)
Step: 35899, Reward: [-350.537 -350.537 -350.537] [0.0000], Avg: [-602.339 -602.339 -602.339] (1.000)
Step: 35949, Reward: [-487.049 -487.049 -487.049] [0.0000], Avg: [-602.178 -602.178 -602.178] (1.000)
Step: 35999, Reward: [-370.933 -370.933 -370.933] [0.0000], Avg: [-601.857 -601.857 -601.857] (1.000)
Step: 36049, Reward: [-623.941 -623.941 -623.941] [0.0000], Avg: [-601.888 -601.888 -601.888] (1.000)
Step: 36099, Reward: [-426.223 -426.223 -426.223] [0.0000], Avg: [-601.645 -601.645 -601.645] (1.000)
Step: 36149, Reward: [-464.439 -464.439 -464.439] [0.0000], Avg: [-601.455 -601.455 -601.455] (1.000)
Step: 36199, Reward: [-645.95 -645.95 -645.95] [0.0000], Avg: [-601.516 -601.516 -601.516] (1.000)
Step: 36249, Reward: [-485.469 -485.469 -485.469] [0.0000], Avg: [-601.356 -601.356 -601.356] (1.000)
Step: 36299, Reward: [-418.051 -418.051 -418.051] [0.0000], Avg: [-601.104 -601.104 -601.104] (1.000)
Step: 36349, Reward: [-430.01 -430.01 -430.01] [0.0000], Avg: [-600.868 -600.868 -600.868] (1.000)
Step: 36399, Reward: [-585.038 -585.038 -585.038] [0.0000], Avg: [-600.847 -600.847 -600.847] (1.000)
Step: 36449, Reward: [-412.932 -412.932 -412.932] [0.0000], Avg: [-600.589 -600.589 -600.589] (1.000)
Step: 36499, Reward: [-616.895 -616.895 -616.895] [0.0000], Avg: [-600.611 -600.611 -600.611] (1.000)
Step: 36549, Reward: [-463.462 -463.462 -463.462] [0.0000], Avg: [-600.424 -600.424 -600.424] (1.000)
Step: 36599, Reward: [-395.127 -395.127 -395.127] [0.0000], Avg: [-600.143 -600.143 -600.143] (1.000)
Step: 36649, Reward: [-418.173 -418.173 -418.173] [0.0000], Avg: [-599.895 -599.895 -599.895] (1.000)
Step: 36699, Reward: [-407.563 -407.563 -407.563] [0.0000], Avg: [-599.633 -599.633 -599.633] (1.000)
Step: 36749, Reward: [-442.362 -442.362 -442.362] [0.0000], Avg: [-599.419 -599.419 -599.419] (1.000)
Step: 36799, Reward: [-367.857 -367.857 -367.857] [0.0000], Avg: [-599.104 -599.104 -599.104] (1.000)
Step: 36849, Reward: [-526.327 -526.327 -526.327] [0.0000], Avg: [-599.006 -599.006 -599.006] (1.000)
Step: 36899, Reward: [-471.831 -471.831 -471.831] [0.0000], Avg: [-598.833 -598.833 -598.833] (1.000)
Step: 36949, Reward: [-334.18 -334.18 -334.18] [0.0000], Avg: [-598.475 -598.475 -598.475] (1.000)
Step: 36999, Reward: [-398.585 -398.585 -398.585] [0.0000], Avg: [-598.205 -598.205 -598.205] (1.000)
Step: 37049, Reward: [-387.075 -387.075 -387.075] [0.0000], Avg: [-597.92 -597.92 -597.92] (1.000)
Step: 37099, Reward: [-533.691 -533.691 -533.691] [0.0000], Avg: [-597.833 -597.833 -597.833] (1.000)
Step: 37149, Reward: [-436.361 -436.361 -436.361] [0.0000], Avg: [-597.616 -597.616 -597.616] (1.000)
Step: 37199, Reward: [-375.604 -375.604 -375.604] [0.0000], Avg: [-597.318 -597.318 -597.318] (1.000)
Step: 37249, Reward: [-468.136 -468.136 -468.136] [0.0000], Avg: [-597.144 -597.144 -597.144] (1.000)
Step: 37299, Reward: [-336.222 -336.222 -336.222] [0.0000], Avg: [-596.795 -596.795 -596.795] (1.000)
Step: 37349, Reward: [-371.362 -371.362 -371.362] [0.0000], Avg: [-596.493 -596.493 -596.493] (1.000)
Step: 37399, Reward: [-427.096 -427.096 -427.096] [0.0000], Avg: [-596.266 -596.266 -596.266] (1.000)
Step: 37449, Reward: [-424.048 -424.048 -424.048] [0.0000], Avg: [-596.036 -596.036 -596.036] (1.000)
Step: 37499, Reward: [-369.263 -369.263 -369.263] [0.0000], Avg: [-595.734 -595.734 -595.734] (1.000)
Step: 37549, Reward: [-401.836 -401.836 -401.836] [0.0000], Avg: [-595.476 -595.476 -595.476] (1.000)
Step: 37599, Reward: [-262.949 -262.949 -262.949] [0.0000], Avg: [-595.034 -595.034 -595.034] (1.000)
Step: 37649, Reward: [-345.637 -345.637 -345.637] [0.0000], Avg: [-594.702 -594.702 -594.702] (1.000)
Step: 37699, Reward: [-516.322 -516.322 -516.322] [0.0000], Avg: [-594.599 -594.599 -594.599] (1.000)
Step: 37749, Reward: [-440.283 -440.283 -440.283] [0.0000], Avg: [-594.394 -594.394 -594.394] (1.000)
Step: 37799, Reward: [-490.571 -490.571 -490.571] [0.0000], Avg: [-594.257 -594.257 -594.257] (1.000)
Step: 37849, Reward: [-341.397 -341.397 -341.397] [0.0000], Avg: [-593.923 -593.923 -593.923] (1.000)
Step: 37899, Reward: [-468.573 -468.573 -468.573] [0.0000], Avg: [-593.757 -593.757 -593.757] (1.000)
Step: 37949, Reward: [-415.884 -415.884 -415.884] [0.0000], Avg: [-593.523 -593.523 -593.523] (1.000)
Step: 37999, Reward: [-376.886 -376.886 -376.886] [0.0000], Avg: [-593.238 -593.238 -593.238] (1.000)
Step: 38049, Reward: [-435.395 -435.395 -435.395] [0.0000], Avg: [-593.031 -593.031 -593.031] (1.000)
Step: 38099, Reward: [-430.878 -430.878 -430.878] [0.0000], Avg: [-592.818 -592.818 -592.818] (1.000)
Step: 38149, Reward: [-373.568 -373.568 -373.568] [0.0000], Avg: [-592.53 -592.53 -592.53] (1.000)
Step: 38199, Reward: [-354.092 -354.092 -354.092] [0.0000], Avg: [-592.218 -592.218 -592.218] (1.000)
Step: 38249, Reward: [-393.921 -393.921 -393.921] [0.0000], Avg: [-591.959 -591.959 -591.959] (1.000)
Step: 38299, Reward: [-339.946 -339.946 -339.946] [0.0000], Avg: [-591.63 -591.63 -591.63] (1.000)
Step: 38349, Reward: [-494.673 -494.673 -494.673] [0.0000], Avg: [-591.504 -591.504 -591.504] (1.000)
Step: 38399, Reward: [-351.747 -351.747 -351.747] [0.0000], Avg: [-591.192 -591.192 -591.192] (1.000)
Step: 38449, Reward: [-395.236 -395.236 -395.236] [0.0000], Avg: [-590.937 -590.937 -590.937] (1.000)
Step: 38499, Reward: [-328.503 -328.503 -328.503] [0.0000], Avg: [-590.596 -590.596 -590.596] (1.000)
Step: 38549, Reward: [-348.382 -348.382 -348.382] [0.0000], Avg: [-590.282 -590.282 -590.282] (1.000)
Step: 38599, Reward: [-461.512 -461.512 -461.512] [0.0000], Avg: [-590.115 -590.115 -590.115] (1.000)
Step: 38649, Reward: [-341.608 -341.608 -341.608] [0.0000], Avg: [-589.793 -589.793 -589.793] (1.000)
Step: 38699, Reward: [-460.745 -460.745 -460.745] [0.0000], Avg: [-589.627 -589.627 -589.627] (1.000)
Step: 38749, Reward: [-415.306 -415.306 -415.306] [0.0000], Avg: [-589.402 -589.402 -589.402] (1.000)
Step: 38799, Reward: [-403.374 -403.374 -403.374] [0.0000], Avg: [-589.162 -589.162 -589.162] (1.000)
Step: 38849, Reward: [-364.339 -364.339 -364.339] [0.0000], Avg: [-588.873 -588.873 -588.873] (1.000)
Step: 38899, Reward: [-403.062 -403.062 -403.062] [0.0000], Avg: [-588.634 -588.634 -588.634] (1.000)
Step: 38949, Reward: [-326.406 -326.406 -326.406] [0.0000], Avg: [-588.297 -588.297 -588.297] (1.000)
Step: 38999, Reward: [-383.016 -383.016 -383.016] [0.0000], Avg: [-588.034 -588.034 -588.034] (1.000)
Step: 39049, Reward: [-327.626 -327.626 -327.626] [0.0000], Avg: [-587.701 -587.701 -587.701] (1.000)
Step: 39099, Reward: [-407.869 -407.869 -407.869] [0.0000], Avg: [-587.471 -587.471 -587.471] (1.000)
Step: 39149, Reward: [-445.39 -445.39 -445.39] [0.0000], Avg: [-587.289 -587.289 -587.289] (1.000)
Step: 39199, Reward: [-329.532 -329.532 -329.532] [0.0000], Avg: [-586.96 -586.96 -586.96] (1.000)
Step: 39249, Reward: [-363.083 -363.083 -363.083] [0.0000], Avg: [-586.675 -586.675 -586.675] (1.000)
Step: 39299, Reward: [-298.658 -298.658 -298.658] [0.0000], Avg: [-586.309 -586.309 -586.309] (1.000)
Step: 39349, Reward: [-294.809 -294.809 -294.809] [0.0000], Avg: [-585.938 -585.938 -585.938] (1.000)
Step: 39399, Reward: [-296.613 -296.613 -296.613] [0.0000], Avg: [-585.571 -585.571 -585.571] (1.000)
Step: 39449, Reward: [-364.713 -364.713 -364.713] [0.0000], Avg: [-585.291 -585.291 -585.291] (1.000)
Step: 39499, Reward: [-275.296 -275.296 -275.296] [0.0000], Avg: [-584.899 -584.899 -584.899] (1.000)
Step: 39549, Reward: [-361.853 -361.853 -361.853] [0.0000], Avg: [-584.617 -584.617 -584.617] (1.000)
Step: 39599, Reward: [-377.266 -377.266 -377.266] [0.0000], Avg: [-584.355 -584.355 -584.355] (1.000)
Step: 39649, Reward: [-497.621 -497.621 -497.621] [0.0000], Avg: [-584.246 -584.246 -584.246] (1.000)
Step: 39699, Reward: [-326.578 -326.578 -326.578] [0.0000], Avg: [-583.921 -583.921 -583.921] (1.000)
Step: 39749, Reward: [-518.159 -518.159 -518.159] [0.0000], Avg: [-583.839 -583.839 -583.839] (1.000)
Step: 39799, Reward: [-486.902 -486.902 -486.902] [0.0000], Avg: [-583.717 -583.717 -583.717] (1.000)
Step: 39849, Reward: [-329.391 -329.391 -329.391] [0.0000], Avg: [-583.398 -583.398 -583.398] (1.000)
Step: 39899, Reward: [-290.254 -290.254 -290.254] [0.0000], Avg: [-583.03 -583.03 -583.03] (1.000)
Step: 39949, Reward: [-376.287 -376.287 -376.287] [0.0000], Avg: [-582.772 -582.772 -582.772] (1.000)
Step: 39999, Reward: [-451.126 -451.126 -451.126] [0.0000], Avg: [-582.607 -582.607 -582.607] (1.000)
Step: 40049, Reward: [-387.568 -387.568 -387.568] [0.0000], Avg: [-582.364 -582.364 -582.364] (1.000)
Step: 40099, Reward: [-331.023 -331.023 -331.023] [0.0000], Avg: [-582.05 -582.05 -582.05] (1.000)
Step: 40149, Reward: [-375.857 -375.857 -375.857] [0.0000], Avg: [-581.793 -581.793 -581.793] (1.000)
Step: 40199, Reward: [-318.986 -318.986 -318.986] [0.0000], Avg: [-581.466 -581.466 -581.466] (1.000)
Step: 40249, Reward: [-431.382 -431.382 -431.382] [0.0000], Avg: [-581.28 -581.28 -581.28] (1.000)
Step: 40299, Reward: [-300.374 -300.374 -300.374] [0.0000], Avg: [-580.931 -580.931 -580.931] (1.000)
Step: 40349, Reward: [-308.29 -308.29 -308.29] [0.0000], Avg: [-580.594 -580.594 -580.594] (1.000)
Step: 40399, Reward: [-414.514 -414.514 -414.514] [0.0000], Avg: [-580.388 -580.388 -580.388] (1.000)
Step: 40449, Reward: [-340.489 -340.489 -340.489] [0.0000], Avg: [-580.092 -580.092 -580.092] (1.000)
Step: 40499, Reward: [-356.785 -356.785 -356.785] [0.0000], Avg: [-579.816 -579.816 -579.816] (1.000)
Step: 40549, Reward: [-403.77 -403.77 -403.77] [0.0000], Avg: [-579.599 -579.599 -579.599] (1.000)
Step: 40599, Reward: [-387.519 -387.519 -387.519] [0.0000], Avg: [-579.362 -579.362 -579.362] (1.000)
Step: 40649, Reward: [-350.004 -350.004 -350.004] [0.0000], Avg: [-579.08 -579.08 -579.08] (1.000)
Step: 40699, Reward: [-411.081 -411.081 -411.081] [0.0000], Avg: [-578.874 -578.874 -578.874] (1.000)
Step: 40749, Reward: [-288.824 -288.824 -288.824] [0.0000], Avg: [-578.518 -578.518 -578.518] (1.000)
Step: 40799, Reward: [-395.172 -395.172 -395.172] [0.0000], Avg: [-578.293 -578.293 -578.293] (1.000)
Step: 40849, Reward: [-405.37 -405.37 -405.37] [0.0000], Avg: [-578.082 -578.082 -578.082] (1.000)
Step: 40899, Reward: [-403.289 -403.289 -403.289] [0.0000], Avg: [-577.868 -577.868 -577.868] (1.000)
Step: 40949, Reward: [-417.555 -417.555 -417.555] [0.0000], Avg: [-577.672 -577.672 -577.672] (1.000)
Step: 40999, Reward: [-328.543 -328.543 -328.543] [0.0000], Avg: [-577.368 -577.368 -577.368] (1.000)
Step: 41049, Reward: [-344.735 -344.735 -344.735] [0.0000], Avg: [-577.085 -577.085 -577.085] (1.000)
Step: 41099, Reward: [-376.978 -376.978 -376.978] [0.0000], Avg: [-576.841 -576.841 -576.841] (1.000)
Step: 41149, Reward: [-347.076 -347.076 -347.076] [0.0000], Avg: [-576.562 -576.562 -576.562] (1.000)
Step: 41199, Reward: [-427.671 -427.671 -427.671] [0.0000], Avg: [-576.382 -576.382 -576.382] (1.000)
Step: 41249, Reward: [-426.914 -426.914 -426.914] [0.0000], Avg: [-576.2 -576.2 -576.2] (1.000)
Step: 41299, Reward: [-369.772 -369.772 -369.772] [0.0000], Avg: [-575.951 -575.951 -575.951] (1.000)
Step: 41349, Reward: [-370.188 -370.188 -370.188] [0.0000], Avg: [-575.702 -575.702 -575.702] (1.000)
Step: 41399, Reward: [-362.379 -362.379 -362.379] [0.0000], Avg: [-575.444 -575.444 -575.444] (1.000)
Step: 41449, Reward: [-401.333 -401.333 -401.333] [0.0000], Avg: [-575.234 -575.234 -575.234] (1.000)
Step: 41499, Reward: [-297.256 -297.256 -297.256] [0.0000], Avg: [-574.899 -574.899 -574.899] (1.000)
Step: 41549, Reward: [-329.072 -329.072 -329.072] [0.0000], Avg: [-574.603 -574.603 -574.603] (1.000)
Step: 41599, Reward: [-310.39 -310.39 -310.39] [0.0000], Avg: [-574.286 -574.286 -574.286] (1.000)
Step: 41649, Reward: [-339.376 -339.376 -339.376] [0.0000], Avg: [-574.004 -574.004 -574.004] (1.000)
Step: 41699, Reward: [-375.584 -375.584 -375.584] [0.0000], Avg: [-573.766 -573.766 -573.766] (1.000)
Step: 41749, Reward: [-342.866 -342.866 -342.866] [0.0000], Avg: [-573.489 -573.489 -573.489] (1.000)
Step: 41799, Reward: [-373.651 -373.651 -373.651] [0.0000], Avg: [-573.25 -573.25 -573.25] (1.000)
Step: 41849, Reward: [-347.887 -347.887 -347.887] [0.0000], Avg: [-572.981 -572.981 -572.981] (1.000)
Step: 41899, Reward: [-496.61 -496.61 -496.61] [0.0000], Avg: [-572.89 -572.89 -572.89] (1.000)
Step: 41949, Reward: [-459.081 -459.081 -459.081] [0.0000], Avg: [-572.754 -572.754 -572.754] (1.000)
Step: 41999, Reward: [-323.487 -323.487 -323.487] [0.0000], Avg: [-572.457 -572.457 -572.457] (1.000)
Step: 42049, Reward: [-368.772 -368.772 -368.772] [0.0000], Avg: [-572.215 -572.215 -572.215] (1.000)
Step: 42099, Reward: [-466.114 -466.114 -466.114] [0.0000], Avg: [-572.089 -572.089 -572.089] (1.000)
Step: 42149, Reward: [-430.459 -430.459 -430.459] [0.0000], Avg: [-571.921 -571.921 -571.921] (1.000)
Step: 42199, Reward: [-382.898 -382.898 -382.898] [0.0000], Avg: [-571.697 -571.697 -571.697] (1.000)
Step: 42249, Reward: [-326. -326. -326.] [0.0000], Avg: [-571.407 -571.407 -571.407] (1.000)
Step: 42299, Reward: [-376.193 -376.193 -376.193] [0.0000], Avg: [-571.176 -571.176 -571.176] (1.000)
Step: 42349, Reward: [-325.133 -325.133 -325.133] [0.0000], Avg: [-570.885 -570.885 -570.885] (1.000)
Step: 42399, Reward: [-551.183 -551.183 -551.183] [0.0000], Avg: [-570.862 -570.862 -570.862] (1.000)
Step: 42449, Reward: [-383.884 -383.884 -383.884] [0.0000], Avg: [-570.642 -570.642 -570.642] (1.000)
Step: 42499, Reward: [-343.016 -343.016 -343.016] [0.0000], Avg: [-570.374 -570.374 -570.374] (1.000)
Step: 42549, Reward: [-360.088 -360.088 -360.088] [0.0000], Avg: [-570.127 -570.127 -570.127] (1.000)
Step: 42599, Reward: [-383.68 -383.68 -383.68] [0.0000], Avg: [-569.908 -569.908 -569.908] (1.000)
Step: 42649, Reward: [-436.133 -436.133 -436.133] [0.0000], Avg: [-569.751 -569.751 -569.751] (1.000)
Step: 42699, Reward: [-389.988 -389.988 -389.988] [0.0000], Avg: [-569.541 -569.541 -569.541] (1.000)
Step: 42749, Reward: [-426.08 -426.08 -426.08] [0.0000], Avg: [-569.373 -569.373 -569.373] (1.000)
Step: 42799, Reward: [-319.25 -319.25 -319.25] [0.0000], Avg: [-569.081 -569.081 -569.081] (1.000)
Step: 42849, Reward: [-390.001 -390.001 -390.001] [0.0000], Avg: [-568.872 -568.872 -568.872] (1.000)
Step: 42899, Reward: [-430.994 -430.994 -430.994] [0.0000], Avg: [-568.711 -568.711 -568.711] (1.000)
Step: 42949, Reward: [-328.596 -328.596 -328.596] [0.0000], Avg: [-568.432 -568.432 -568.432] (1.000)
Step: 42999, Reward: [-396.742 -396.742 -396.742] [0.0000], Avg: [-568.232 -568.232 -568.232] (1.000)
Step: 43049, Reward: [-369.478 -369.478 -369.478] [0.0000], Avg: [-568.001 -568.001 -568.001] (1.000)
Step: 43099, Reward: [-383.175 -383.175 -383.175] [0.0000], Avg: [-567.787 -567.787 -567.787] (1.000)
Step: 43149, Reward: [-319.208 -319.208 -319.208] [0.0000], Avg: [-567.499 -567.499 -567.499] (1.000)
Step: 43199, Reward: [-368.561 -368.561 -368.561] [0.0000], Avg: [-567.268 -567.268 -567.268] (1.000)
Step: 43249, Reward: [-391.335 -391.335 -391.335] [0.0000], Avg: [-567.065 -567.065 -567.065] (1.000)
Step: 43299, Reward: [-446.418 -446.418 -446.418] [0.0000], Avg: [-566.926 -566.926 -566.926] (1.000)
Step: 43349, Reward: [-430.513 -430.513 -430.513] [0.0000], Avg: [-566.768 -566.768 -566.768] (1.000)
Step: 43399, Reward: [-343.843 -343.843 -343.843] [0.0000], Avg: [-566.512 -566.512 -566.512] (1.000)
Step: 43449, Reward: [-329.463 -329.463 -329.463] [0.0000], Avg: [-566.239 -566.239 -566.239] (1.000)
Step: 43499, Reward: [-284.986 -284.986 -284.986] [0.0000], Avg: [-565.915 -565.915 -565.915] (1.000)
Step: 43549, Reward: [-360.112 -360.112 -360.112] [0.0000], Avg: [-565.679 -565.679 -565.679] (1.000)
Step: 43599, Reward: [-465.369 -465.369 -465.369] [0.0000], Avg: [-565.564 -565.564 -565.564] (1.000)
Step: 43649, Reward: [-381.811 -381.811 -381.811] [0.0000], Avg: [-565.354 -565.354 -565.354] (1.000)
Step: 43699, Reward: [-368.044 -368.044 -368.044] [0.0000], Avg: [-565.128 -565.128 -565.128] (1.000)
Step: 43749, Reward: [-355.387 -355.387 -355.387] [0.0000], Avg: [-564.888 -564.888 -564.888] (1.000)
Step: 43799, Reward: [-397.61 -397.61 -397.61] [0.0000], Avg: [-564.697 -564.697 -564.697] (1.000)
Step: 43849, Reward: [-305.25 -305.25 -305.25] [0.0000], Avg: [-564.401 -564.401 -564.401] (1.000)
Step: 43899, Reward: [-408.154 -408.154 -408.154] [0.0000], Avg: [-564.223 -564.223 -564.223] (1.000)
Step: 43949, Reward: [-359.873 -359.873 -359.873] [0.0000], Avg: [-563.991 -563.991 -563.991] (1.000)
Step: 43999, Reward: [-465.293 -465.293 -465.293] [0.0000], Avg: [-563.879 -563.879 -563.879] (1.000)
Step: 44049, Reward: [-321.668 -321.668 -321.668] [0.0000], Avg: [-563.604 -563.604 -563.604] (1.000)
Step: 44099, Reward: [-509.31 -509.31 -509.31] [0.0000], Avg: [-563.542 -563.542 -563.542] (1.000)
Step: 44149, Reward: [-281.811 -281.811 -281.811] [0.0000], Avg: [-563.223 -563.223 -563.223] (1.000)
Step: 44199, Reward: [-503.1 -503.1 -503.1] [0.0000], Avg: [-563.155 -563.155 -563.155] (1.000)
Step: 44249, Reward: [-453.694 -453.694 -453.694] [0.0000], Avg: [-563.032 -563.032 -563.032] (1.000)
Step: 44299, Reward: [-376.36 -376.36 -376.36] [0.0000], Avg: [-562.821 -562.821 -562.821] (1.000)
Step: 44349, Reward: [-422.625 -422.625 -422.625] [0.0000], Avg: [-562.663 -562.663 -562.663] (1.000)
Step: 44399, Reward: [-347.356 -347.356 -347.356] [0.0000], Avg: [-562.42 -562.42 -562.42] (1.000)
Step: 44449, Reward: [-425.897 -425.897 -425.897] [0.0000], Avg: [-562.267 -562.267 -562.267] (1.000)
Step: 44499, Reward: [-308.115 -308.115 -308.115] [0.0000], Avg: [-561.981 -561.981 -561.981] (1.000)
Step: 44549, Reward: [-395.699 -395.699 -395.699] [0.0000], Avg: [-561.795 -561.795 -561.795] (1.000)
Step: 44599, Reward: [-423.269 -423.269 -423.269] [0.0000], Avg: [-561.639 -561.639 -561.639] (1.000)
Step: 44649, Reward: [-312.113 -312.113 -312.113] [0.0000], Avg: [-561.36 -561.36 -561.36] (1.000)
Step: 44699, Reward: [-561.411 -561.411 -561.411] [0.0000], Avg: [-561.36 -561.36 -561.36] (1.000)
Step: 44749, Reward: [-450.671 -450.671 -450.671] [0.0000], Avg: [-561.236 -561.236 -561.236] (1.000)
Step: 44799, Reward: [-310.249 -310.249 -310.249] [0.0000], Avg: [-560.956 -560.956 -560.956] (1.000)
Step: 44849, Reward: [-407.049 -407.049 -407.049] [0.0000], Avg: [-560.785 -560.785 -560.785] (1.000)
Step: 44899, Reward: [-286.893 -286.893 -286.893] [0.0000], Avg: [-560.48 -560.48 -560.48] (1.000)
Step: 44949, Reward: [-298.134 -298.134 -298.134] [0.0000], Avg: [-560.188 -560.188 -560.188] (1.000)
Step: 44999, Reward: [-364.782 -364.782 -364.782] [0.0000], Avg: [-559.971 -559.971 -559.971] (1.000)
Step: 45049, Reward: [-437.167 -437.167 -437.167] [0.0000], Avg: [-559.834 -559.834 -559.834] (1.000)
Step: 45099, Reward: [-303.75 -303.75 -303.75] [0.0000], Avg: [-559.55 -559.55 -559.55] (1.000)
Step: 45149, Reward: [-403.076 -403.076 -403.076] [0.0000], Avg: [-559.377 -559.377 -559.377] (1.000)
Step: 45199, Reward: [-299.512 -299.512 -299.512] [0.0000], Avg: [-559.09 -559.09 -559.09] (1.000)
Step: 45249, Reward: [-338.787 -338.787 -338.787] [0.0000], Avg: [-558.846 -558.846 -558.846] (1.000)
Step: 45299, Reward: [-296.256 -296.256 -296.256] [0.0000], Avg: [-558.556 -558.556 -558.556] (1.000)
Step: 45349, Reward: [-282.07 -282.07 -282.07] [0.0000], Avg: [-558.252 -558.252 -558.252] (1.000)
Step: 45399, Reward: [-399.919 -399.919 -399.919] [0.0000], Avg: [-558.077 -558.077 -558.077] (1.000)
Step: 45449, Reward: [-355.298 -355.298 -355.298] [0.0000], Avg: [-557.854 -557.854 -557.854] (1.000)
Step: 45499, Reward: [-320.606 -320.606 -320.606] [0.0000], Avg: [-557.593 -557.593 -557.593] (1.000)
Step: 45549, Reward: [-297.587 -297.587 -297.587] [0.0000], Avg: [-557.308 -557.308 -557.308] (1.000)
Step: 45599, Reward: [-384.634 -384.634 -384.634] [0.0000], Avg: [-557.119 -557.119 -557.119] (1.000)
Step: 45649, Reward: [-509.994 -509.994 -509.994] [0.0000], Avg: [-557.067 -557.067 -557.067] (1.000)
Step: 45699, Reward: [-283.212 -283.212 -283.212] [0.0000], Avg: [-556.767 -556.767 -556.767] (1.000)
Step: 45749, Reward: [-585.517 -585.517 -585.517] [0.0000], Avg: [-556.799 -556.799 -556.799] (1.000)
Step: 45799, Reward: [-449.196 -449.196 -449.196] [0.0000], Avg: [-556.681 -556.681 -556.681] (1.000)
Step: 45849, Reward: [-373.849 -373.849 -373.849] [0.0000], Avg: [-556.482 -556.482 -556.482] (1.000)
Step: 45899, Reward: [-445.163 -445.163 -445.163] [0.0000], Avg: [-556.361 -556.361 -556.361] (1.000)
Step: 45949, Reward: [-413.626 -413.626 -413.626] [0.0000], Avg: [-556.205 -556.205 -556.205] (1.000)
Step: 45999, Reward: [-495.791 -495.791 -495.791] [0.0000], Avg: [-556.14 -556.14 -556.14] (1.000)
Step: 46049, Reward: [-375.865 -375.865 -375.865] [0.0000], Avg: [-555.944 -555.944 -555.944] (1.000)
Step: 46099, Reward: [-382.755 -382.755 -382.755] [0.0000], Avg: [-555.756 -555.756 -555.756] (1.000)
Step: 46149, Reward: [-527.721 -527.721 -527.721] [0.0000], Avg: [-555.726 -555.726 -555.726] (1.000)
Step: 46199, Reward: [-315.21 -315.21 -315.21] [0.0000], Avg: [-555.466 -555.466 -555.466] (1.000)
Step: 46249, Reward: [-377.269 -377.269 -377.269] [0.0000], Avg: [-555.273 -555.273 -555.273] (1.000)
Step: 46299, Reward: [-432.268 -432.268 -432.268] [0.0000], Avg: [-555.14 -555.14 -555.14] (1.000)
Step: 46349, Reward: [-470.206 -470.206 -470.206] [0.0000], Avg: [-555.048 -555.048 -555.048] (1.000)
Step: 46399, Reward: [-353.241 -353.241 -353.241] [0.0000], Avg: [-554.831 -554.831 -554.831] (1.000)
Step: 46449, Reward: [-355.511 -355.511 -355.511] [0.0000], Avg: [-554.616 -554.616 -554.616] (1.000)
Step: 46499, Reward: [-341.34 -341.34 -341.34] [0.0000], Avg: [-554.387 -554.387 -554.387] (1.000)
Step: 46549, Reward: [-306.392 -306.392 -306.392] [0.0000], Avg: [-554.121 -554.121 -554.121] (1.000)
Step: 46599, Reward: [-300.863 -300.863 -300.863] [0.0000], Avg: [-553.849 -553.849 -553.849] (1.000)
Step: 46649, Reward: [-279.347 -279.347 -279.347] [0.0000], Avg: [-553.555 -553.555 -553.555] (1.000)
Step: 46699, Reward: [-383.227 -383.227 -383.227] [0.0000], Avg: [-553.372 -553.372 -553.372] (1.000)
Step: 46749, Reward: [-330.391 -330.391 -330.391] [0.0000], Avg: [-553.134 -553.134 -553.134] (1.000)
Step: 46799, Reward: [-348.812 -348.812 -348.812] [0.0000], Avg: [-552.916 -552.916 -552.916] (1.000)
Step: 46849, Reward: [-376.409 -376.409 -376.409] [0.0000], Avg: [-552.727 -552.727 -552.727] (1.000)
Step: 46899, Reward: [-372.002 -372.002 -372.002] [0.0000], Avg: [-552.535 -552.535 -552.535] (1.000)
Step: 46949, Reward: [-403.864 -403.864 -403.864] [0.0000], Avg: [-552.376 -552.376 -552.376] (1.000)
Step: 46999, Reward: [-421.952 -421.952 -421.952] [0.0000], Avg: [-552.237 -552.237 -552.237] (1.000)
Step: 47049, Reward: [-379.782 -379.782 -379.782] [0.0000], Avg: [-552.054 -552.054 -552.054] (1.000)
Step: 47099, Reward: [-300.847 -300.847 -300.847] [0.0000], Avg: [-551.788 -551.788 -551.788] (1.000)
Step: 47149, Reward: [-299.691 -299.691 -299.691] [0.0000], Avg: [-551.52 -551.52 -551.52] (1.000)
Step: 47199, Reward: [-311.674 -311.674 -311.674] [0.0000], Avg: [-551.266 -551.266 -551.266] (1.000)
Step: 47249, Reward: [-439.542 -439.542 -439.542] [0.0000], Avg: [-551.148 -551.148 -551.148] (1.000)
Step: 47299, Reward: [-400.508 -400.508 -400.508] [0.0000], Avg: [-550.989 -550.989 -550.989] (1.000)
Step: 47349, Reward: [-415.565 -415.565 -415.565] [0.0000], Avg: [-550.846 -550.846 -550.846] (1.000)
Step: 47399, Reward: [-311. -311. -311.] [0.0000], Avg: [-550.593 -550.593 -550.593] (1.000)
Step: 47449, Reward: [-367.969 -367.969 -367.969] [0.0000], Avg: [-550.4 -550.4 -550.4] (1.000)
Step: 47499, Reward: [-345.736 -345.736 -345.736] [0.0000], Avg: [-550.185 -550.185 -550.185] (1.000)
Step: 47549, Reward: [-436.823 -436.823 -436.823] [0.0000], Avg: [-550.066 -550.066 -550.066] (1.000)
Step: 47599, Reward: [-397.34 -397.34 -397.34] [0.0000], Avg: [-549.905 -549.905 -549.905] (1.000)
Step: 47649, Reward: [-333.769 -333.769 -333.769] [0.0000], Avg: [-549.678 -549.678 -549.678] (1.000)
Step: 47699, Reward: [-263.812 -263.812 -263.812] [0.0000], Avg: [-549.379 -549.379 -549.379] (1.000)
Step: 47749, Reward: [-400.904 -400.904 -400.904] [0.0000], Avg: [-549.223 -549.223 -549.223] (1.000)
Step: 47799, Reward: [-409.218 -409.218 -409.218] [0.0000], Avg: [-549.077 -549.077 -549.077] (1.000)
Step: 47849, Reward: [-384.899 -384.899 -384.899] [0.0000], Avg: [-548.905 -548.905 -548.905] (1.000)
Step: 47899, Reward: [-348.302 -348.302 -348.302] [0.0000], Avg: [-548.696 -548.696 -548.696] (1.000)
Step: 47949, Reward: [-342.597 -342.597 -342.597] [0.0000], Avg: [-548.481 -548.481 -548.481] (1.000)
Step: 47999, Reward: [-406.691 -406.691 -406.691] [0.0000], Avg: [-548.333 -548.333 -548.333] (1.000)
Step: 48049, Reward: [-387.248 -387.248 -387.248] [0.0000], Avg: [-548.166 -548.166 -548.166] (1.000)
Step: 48099, Reward: [-383.012 -383.012 -383.012] [0.0000], Avg: [-547.994 -547.994 -547.994] (1.000)
Step: 48149, Reward: [-354.361 -354.361 -354.361] [0.0000], Avg: [-547.793 -547.793 -547.793] (1.000)
Step: 48199, Reward: [-394.404 -394.404 -394.404] [0.0000], Avg: [-547.634 -547.634 -547.634] (1.000)
Step: 48249, Reward: [-426.29 -426.29 -426.29] [0.0000], Avg: [-547.508 -547.508 -547.508] (1.000)
Step: 48299, Reward: [-444.321 -444.321 -444.321] [0.0000], Avg: [-547.401 -547.401 -547.401] (1.000)
Step: 48349, Reward: [-333.332 -333.332 -333.332] [0.0000], Avg: [-547.18 -547.18 -547.18] (1.000)
Step: 48399, Reward: [-420.308 -420.308 -420.308] [0.0000], Avg: [-547.049 -547.049 -547.049] (1.000)
Step: 48449, Reward: [-359.89 -359.89 -359.89] [0.0000], Avg: [-546.856 -546.856 -546.856] (1.000)
Step: 48499, Reward: [-291.174 -291.174 -291.174] [0.0000], Avg: [-546.592 -546.592 -546.592] (1.000)
Step: 48549, Reward: [-359.487 -359.487 -359.487] [0.0000], Avg: [-546.399 -546.399 -546.399] (1.000)
Step: 48599, Reward: [-417.377 -417.377 -417.377] [0.0000], Avg: [-546.267 -546.267 -546.267] (1.000)
Step: 48649, Reward: [-534.437 -534.437 -534.437] [0.0000], Avg: [-546.254 -546.254 -546.254] (1.000)
Step: 48699, Reward: [-407.143 -407.143 -407.143] [0.0000], Avg: [-546.112 -546.112 -546.112] (1.000)
Step: 48749, Reward: [-370.433 -370.433 -370.433] [0.0000], Avg: [-545.931 -545.931 -545.931] (1.000)
Step: 48799, Reward: [-489.621 -489.621 -489.621] [0.0000], Avg: [-545.874 -545.874 -545.874] (1.000)
Step: 48849, Reward: [-358.553 -358.553 -358.553] [0.0000], Avg: [-545.682 -545.682 -545.682] (1.000)
Step: 48899, Reward: [-445.198 -445.198 -445.198] [0.0000], Avg: [-545.579 -545.579 -545.579] (1.000)
Step: 48949, Reward: [-425.572 -425.572 -425.572] [0.0000], Avg: [-545.457 -545.457 -545.457] (1.000)
Step: 48999, Reward: [-499.815 -499.815 -499.815] [0.0000], Avg: [-545.41 -545.41 -545.41] (1.000)
Step: 49049, Reward: [-328.773 -328.773 -328.773] [0.0000], Avg: [-545.189 -545.189 -545.189] (1.000)
Step: 49099, Reward: [-427.564 -427.564 -427.564] [0.0000], Avg: [-545.069 -545.069 -545.069] (1.000)
Step: 49149, Reward: [-350.946 -350.946 -350.946] [0.0000], Avg: [-544.872 -544.872 -544.872] (1.000)
Step: 49199, Reward: [-410.07 -410.07 -410.07] [0.0000], Avg: [-544.735 -544.735 -544.735] (1.000)
Step: 49249, Reward: [-414.127 -414.127 -414.127] [0.0000], Avg: [-544.602 -544.602 -544.602] (1.000)
Step: 49299, Reward: [-303.234 -303.234 -303.234] [0.0000], Avg: [-544.358 -544.358 -544.358] (1.000)
Step: 49349, Reward: [-421.898 -421.898 -421.898] [0.0000], Avg: [-544.234 -544.234 -544.234] (1.000)
Step: 49399, Reward: [-312.327 -312.327 -312.327] [0.0000], Avg: [-543.999 -543.999 -543.999] (1.000)
Step: 49449, Reward: [-302.028 -302.028 -302.028] [0.0000], Avg: [-543.754 -543.754 -543.754] (1.000)
Step: 49499, Reward: [-330.176 -330.176 -330.176] [0.0000], Avg: [-543.538 -543.538 -543.538] (1.000)
Step: 49549, Reward: [-456.202 -456.202 -456.202] [0.0000], Avg: [-543.45 -543.45 -543.45] (1.000)
Step: 49599, Reward: [-330.905 -330.905 -330.905] [0.0000], Avg: [-543.236 -543.236 -543.236] (1.000)
Step: 49649, Reward: [-321.25 -321.25 -321.25] [0.0000], Avg: [-543.012 -543.012 -543.012] (1.000)
Step: 49699, Reward: [-441.709 -441.709 -441.709] [0.0000], Avg: [-542.911 -542.911 -542.911] (1.000)
Step: 49749, Reward: [-322.866 -322.866 -322.866] [0.0000], Avg: [-542.689 -542.689 -542.689] (1.000)
Step: 49799, Reward: [-351.379 -351.379 -351.379] [0.0000], Avg: [-542.497 -542.497 -542.497] (1.000)
Step: 49849, Reward: [-385.054 -385.054 -385.054] [0.0000], Avg: [-542.339 -542.339 -542.339] (1.000)
Step: 49899, Reward: [-416.374 -416.374 -416.374] [0.0000], Avg: [-542.213 -542.213 -542.213] (1.000)
Step: 49949, Reward: [-348.584 -348.584 -348.584] [0.0000], Avg: [-542.019 -542.019 -542.019] (1.000)
Step: 49999, Reward: [-390.04 -390.04 -390.04] [0.0000], Avg: [-541.867 -541.867 -541.867] (1.000)
Step: 50049, Reward: [-395.379 -395.379 -395.379] [0.0000], Avg: [-541.721 -541.721 -541.721] (1.000)
Step: 50099, Reward: [-384.299 -384.299 -384.299] [0.0000], Avg: [-541.564 -541.564 -541.564] (1.000)
Step: 50149, Reward: [-407.472 -407.472 -407.472] [0.0000], Avg: [-541.43 -541.43 -541.43] (1.000)
Step: 50199, Reward: [-471.193 -471.193 -471.193] [0.0000], Avg: [-541.36 -541.36 -541.36] (1.000)
Step: 50249, Reward: [-468.893 -468.893 -468.893] [0.0000], Avg: [-541.288 -541.288 -541.288] (1.000)
Step: 50299, Reward: [-390.266 -390.266 -390.266] [0.0000], Avg: [-541.138 -541.138 -541.138] (1.000)
Step: 50349, Reward: [-370.38 -370.38 -370.38] [0.0000], Avg: [-540.969 -540.969 -540.969] (1.000)
Step: 50399, Reward: [-380.316 -380.316 -380.316] [0.0000], Avg: [-540.809 -540.809 -540.809] (1.000)
Step: 50449, Reward: [-320.12 -320.12 -320.12] [0.0000], Avg: [-540.59 -540.59 -540.59] (1.000)
Step: 50499, Reward: [-455.94 -455.94 -455.94] [0.0000], Avg: [-540.507 -540.507 -540.507] (1.000)
Step: 50549, Reward: [-421.803 -421.803 -421.803] [0.0000], Avg: [-540.389 -540.389 -540.389] (1.000)
Step: 50599, Reward: [-298.443 -298.443 -298.443] [0.0000], Avg: [-540.15 -540.15 -540.15] (1.000)
Step: 50649, Reward: [-446.091 -446.091 -446.091] [0.0000], Avg: [-540.057 -540.057 -540.057] (1.000)
Step: 50699, Reward: [-478.473 -478.473 -478.473] [0.0000], Avg: [-539.997 -539.997 -539.997] (1.000)
Step: 50749, Reward: [-427.823 -427.823 -427.823] [0.0000], Avg: [-539.886 -539.886 -539.886] (1.000)
Step: 50799, Reward: [-391.922 -391.922 -391.922] [0.0000], Avg: [-539.74 -539.74 -539.74] (1.000)
Step: 50849, Reward: [-370.617 -370.617 -370.617] [0.0000], Avg: [-539.574 -539.574 -539.574] (1.000)
Step: 50899, Reward: [-418.69 -418.69 -418.69] [0.0000], Avg: [-539.455 -539.455 -539.455] (1.000)
Step: 50949, Reward: [-378.619 -378.619 -378.619] [0.0000], Avg: [-539.297 -539.297 -539.297] (1.000)
Step: 50999, Reward: [-324.204 -324.204 -324.204] [0.0000], Avg: [-539.087 -539.087 -539.087] (1.000)
Step: 51049, Reward: [-389.305 -389.305 -389.305] [0.0000], Avg: [-538.94 -538.94 -538.94] (1.000)
Step: 51099, Reward: [-389.644 -389.644 -389.644] [0.0000], Avg: [-538.794 -538.794 -538.794] (1.000)
Step: 51149, Reward: [-429.159 -429.159 -429.159] [0.0000], Avg: [-538.687 -538.687 -538.687] (1.000)
Step: 51199, Reward: [-295.2 -295.2 -295.2] [0.0000], Avg: [-538.449 -538.449 -538.449] (1.000)
Step: 51249, Reward: [-383.121 -383.121 -383.121] [0.0000], Avg: [-538.297 -538.297 -538.297] (1.000)
Step: 51299, Reward: [-331.67 -331.67 -331.67] [0.0000], Avg: [-538.096 -538.096 -538.096] (1.000)
Step: 51349, Reward: [-309.244 -309.244 -309.244] [0.0000], Avg: [-537.873 -537.873 -537.873] (1.000)
Step: 51399, Reward: [-296.32 -296.32 -296.32] [0.0000], Avg: [-537.638 -537.638 -537.638] (1.000)
Step: 51449, Reward: [-338.673 -338.673 -338.673] [0.0000], Avg: [-537.445 -537.445 -537.445] (1.000)
Step: 51499, Reward: [-320.769 -320.769 -320.769] [0.0000], Avg: [-537.234 -537.234 -537.234] (1.000)
Step: 51549, Reward: [-444.992 -444.992 -444.992] [0.0000], Avg: [-537.145 -537.145 -537.145] (1.000)
Step: 51599, Reward: [-318.975 -318.975 -318.975] [0.0000], Avg: [-536.934 -536.934 -536.934] (1.000)
Step: 51649, Reward: [-458.43 -458.43 -458.43] [0.0000], Avg: [-536.858 -536.858 -536.858] (1.000)
Step: 51699, Reward: [-382.825 -382.825 -382.825] [0.0000], Avg: [-536.709 -536.709 -536.709] (1.000)
Step: 51749, Reward: [-298.523 -298.523 -298.523] [0.0000], Avg: [-536.478 -536.478 -536.478] (1.000)
Step: 51799, Reward: [-362.121 -362.121 -362.121] [0.0000], Avg: [-536.31 -536.31 -536.31] (1.000)
Step: 51849, Reward: [-338.587 -338.587 -338.587] [0.0000], Avg: [-536.119 -536.119 -536.119] (1.000)
Step: 51899, Reward: [-405.898 -405.898 -405.898] [0.0000], Avg: [-535.994 -535.994 -535.994] (1.000)
Step: 51949, Reward: [-409.392 -409.392 -409.392] [0.0000], Avg: [-535.872 -535.872 -535.872] (1.000)
Step: 51999, Reward: [-345.086 -345.086 -345.086] [0.0000], Avg: [-535.689 -535.689 -535.689] (1.000)
Step: 52049, Reward: [-365.19 -365.19 -365.19] [0.0000], Avg: [-535.525 -535.525 -535.525] (1.000)
Step: 52099, Reward: [-338.687 -338.687 -338.687] [0.0000], Avg: [-535.336 -535.336 -535.336] (1.000)
Step: 52149, Reward: [-333.465 -333.465 -333.465] [0.0000], Avg: [-535.142 -535.142 -535.142] (1.000)
Step: 52199, Reward: [-338.596 -338.596 -338.596] [0.0000], Avg: [-534.954 -534.954 -534.954] (1.000)
Step: 52249, Reward: [-345.329 -345.329 -345.329] [0.0000], Avg: [-534.773 -534.773 -534.773] (1.000)
Step: 52299, Reward: [-318.98 -318.98 -318.98] [0.0000], Avg: [-534.566 -534.566 -534.566] (1.000)
Step: 52349, Reward: [-380.822 -380.822 -380.822] [0.0000], Avg: [-534.42 -534.42 -534.42] (1.000)
Step: 52399, Reward: [-334.464 -334.464 -334.464] [0.0000], Avg: [-534.229 -534.229 -534.229] (1.000)
Step: 52449, Reward: [-383.796 -383.796 -383.796] [0.0000], Avg: [-534.085 -534.085 -534.085] (1.000)
Step: 52499, Reward: [-369.278 -369.278 -369.278] [0.0000], Avg: [-533.928 -533.928 -533.928] (1.000)
Step: 52549, Reward: [-477.769 -477.769 -477.769] [0.0000], Avg: [-533.875 -533.875 -533.875] (1.000)
Step: 52599, Reward: [-494.087 -494.087 -494.087] [0.0000], Avg: [-533.837 -533.837 -533.837] (1.000)
Step: 52649, Reward: [-319.534 -319.534 -319.534] [0.0000], Avg: [-533.634 -533.634 -533.634] (1.000)
Step: 52699, Reward: [-334.51 -334.51 -334.51] [0.0000], Avg: [-533.445 -533.445 -533.445] (1.000)
Step: 52749, Reward: [-455.18 -455.18 -455.18] [0.0000], Avg: [-533.371 -533.371 -533.371] (1.000)
Step: 52799, Reward: [-418.09 -418.09 -418.09] [0.0000], Avg: [-533.261 -533.261 -533.261] (1.000)
Step: 52849, Reward: [-332.155 -332.155 -332.155] [0.0000], Avg: [-533.071 -533.071 -533.071] (1.000)
Step: 52899, Reward: [-305.271 -305.271 -305.271] [0.0000], Avg: [-532.856 -532.856 -532.856] (1.000)
Step: 52949, Reward: [-317.422 -317.422 -317.422] [0.0000], Avg: [-532.652 -532.652 -532.652] (1.000)
Step: 52999, Reward: [-368.562 -368.562 -368.562] [0.0000], Avg: [-532.498 -532.498 -532.498] (1.000)
Step: 53049, Reward: [-358.573 -358.573 -358.573] [0.0000], Avg: [-532.334 -532.334 -532.334] (1.000)
Step: 53099, Reward: [-298.137 -298.137 -298.137] [0.0000], Avg: [-532.113 -532.113 -532.113] (1.000)
Step: 53149, Reward: [-424.185 -424.185 -424.185] [0.0000], Avg: [-532.012 -532.012 -532.012] (1.000)
Step: 53199, Reward: [-356.878 -356.878 -356.878] [0.0000], Avg: [-531.847 -531.847 -531.847] (1.000)
Step: 53249, Reward: [-350.69 -350.69 -350.69] [0.0000], Avg: [-531.677 -531.677 -531.677] (1.000)
Step: 53299, Reward: [-349.804 -349.804 -349.804] [0.0000], Avg: [-531.506 -531.506 -531.506] (1.000)
Step: 53349, Reward: [-421.515 -421.515 -421.515] [0.0000], Avg: [-531.403 -531.403 -531.403] (1.000)
Step: 53399, Reward: [-496.44 -496.44 -496.44] [0.0000], Avg: [-531.37 -531.37 -531.37] (1.000)
Step: 53449, Reward: [-362.592 -362.592 -362.592] [0.0000], Avg: [-531.213 -531.213 -531.213] (1.000)
Step: 53499, Reward: [-426.066 -426.066 -426.066] [0.0000], Avg: [-531.114 -531.114 -531.114] (1.000)
Step: 53549, Reward: [-334.908 -334.908 -334.908] [0.0000], Avg: [-530.931 -530.931 -530.931] (1.000)
Step: 53599, Reward: [-397.271 -397.271 -397.271] [0.0000], Avg: [-530.806 -530.806 -530.806] (1.000)
Step: 53649, Reward: [-364.322 -364.322 -364.322] [0.0000], Avg: [-530.651 -530.651 -530.651] (1.000)
Step: 53699, Reward: [-497.206 -497.206 -497.206] [0.0000], Avg: [-530.62 -530.62 -530.62] (1.000)
Step: 53749, Reward: [-409.29 -409.29 -409.29] [0.0000], Avg: [-530.507 -530.507 -530.507] (1.000)
Step: 53799, Reward: [-338.021 -338.021 -338.021] [0.0000], Avg: [-530.328 -530.328 -530.328] (1.000)
Step: 53849, Reward: [-425.412 -425.412 -425.412] [0.0000], Avg: [-530.231 -530.231 -530.231] (1.000)
Step: 53899, Reward: [-410.981 -410.981 -410.981] [0.0000], Avg: [-530.12 -530.12 -530.12] (1.000)
Step: 53949, Reward: [-329.587 -329.587 -329.587] [0.0000], Avg: [-529.935 -529.935 -529.935] (1.000)
Step: 53999, Reward: [-492.552 -492.552 -492.552] [0.0000], Avg: [-529.9 -529.9 -529.9] (1.000)
Step: 54049, Reward: [-415.592 -415.592 -415.592] [0.0000], Avg: [-529.794 -529.794 -529.794] (1.000)
Step: 54099, Reward: [-410.19 -410.19 -410.19] [0.0000], Avg: [-529.684 -529.684 -529.684] (1.000)
Step: 54149, Reward: [-442.707 -442.707 -442.707] [0.0000], Avg: [-529.603 -529.603 -529.603] (1.000)
Step: 54199, Reward: [-381.085 -381.085 -381.085] [0.0000], Avg: [-529.466 -529.466 -529.466] (1.000)
Step: 54249, Reward: [-378.18 -378.18 -378.18] [0.0000], Avg: [-529.327 -529.327 -529.327] (1.000)
Step: 54299, Reward: [-317.617 -317.617 -317.617] [0.0000], Avg: [-529.132 -529.132 -529.132] (1.000)
Step: 54349, Reward: [-355.215 -355.215 -355.215] [0.0000], Avg: [-528.972 -528.972 -528.972] (1.000)
Step: 54399, Reward: [-368.843 -368.843 -368.843] [0.0000], Avg: [-528.825 -528.825 -528.825] (1.000)
Step: 54449, Reward: [-442.479 -442.479 -442.479] [0.0000], Avg: [-528.745 -528.745 -528.745] (1.000)
Step: 54499, Reward: [-344.143 -344.143 -344.143] [0.0000], Avg: [-528.576 -528.576 -528.576] (1.000)
Step: 54549, Reward: [-381.287 -381.287 -381.287] [0.0000], Avg: [-528.441 -528.441 -528.441] (1.000)
Step: 54599, Reward: [-371.972 -371.972 -371.972] [0.0000], Avg: [-528.298 -528.298 -528.298] (1.000)
Step: 54649, Reward: [-351.836 -351.836 -351.836] [0.0000], Avg: [-528.136 -528.136 -528.136] (1.000)
Step: 54699, Reward: [-290.208 -290.208 -290.208] [0.0000], Avg: [-527.919 -527.919 -527.919] (1.000)
Step: 54749, Reward: [-393.959 -393.959 -393.959] [0.0000], Avg: [-527.797 -527.797 -527.797] (1.000)
Step: 54799, Reward: [-338.933 -338.933 -338.933] [0.0000], Avg: [-527.624 -527.624 -527.624] (1.000)
Step: 54849, Reward: [-381.35 -381.35 -381.35] [0.0000], Avg: [-527.491 -527.491 -527.491] (1.000)
Step: 54899, Reward: [-468.481 -468.481 -468.481] [0.0000], Avg: [-527.437 -527.437 -527.437] (1.000)
Step: 54949, Reward: [-420.657 -420.657 -420.657] [0.0000], Avg: [-527.34 -527.34 -527.34] (1.000)
Step: 54999, Reward: [-342.422 -342.422 -342.422] [0.0000], Avg: [-527.172 -527.172 -527.172] (1.000)
Step: 55049, Reward: [-433.342 -433.342 -433.342] [0.0000], Avg: [-527.087 -527.087 -527.087] (1.000)
Step: 55099, Reward: [-390.995 -390.995 -390.995] [0.0000], Avg: [-526.963 -526.963 -526.963] (1.000)
Step: 55149, Reward: [-331.871 -331.871 -331.871] [0.0000], Avg: [-526.786 -526.786 -526.786] (1.000)
Step: 55199, Reward: [-598.945 -598.945 -598.945] [0.0000], Avg: [-526.852 -526.852 -526.852] (1.000)
Step: 55249, Reward: [-374.069 -374.069 -374.069] [0.0000], Avg: [-526.713 -526.713 -526.713] (1.000)
Step: 55299, Reward: [-318.493 -318.493 -318.493] [0.0000], Avg: [-526.525 -526.525 -526.525] (1.000)
Step: 55349, Reward: [-407.952 -407.952 -407.952] [0.0000], Avg: [-526.418 -526.418 -526.418] (1.000)
Step: 55399, Reward: [-382.101 -382.101 -382.101] [0.0000], Avg: [-526.288 -526.288 -526.288] (1.000)
Step: 55449, Reward: [-304.407 -304.407 -304.407] [0.0000], Avg: [-526.088 -526.088 -526.088] (1.000)
Step: 55499, Reward: [-411.46 -411.46 -411.46] [0.0000], Avg: [-525.984 -525.984 -525.984] (1.000)
Step: 55549, Reward: [-327.725 -327.725 -327.725] [0.0000], Avg: [-525.806 -525.806 -525.806] (1.000)
Step: 55599, Reward: [-421.393 -421.393 -421.393] [0.0000], Avg: [-525.712 -525.712 -525.712] (1.000)
Step: 55649, Reward: [-438.54 -438.54 -438.54] [0.0000], Avg: [-525.634 -525.634 -525.634] (1.000)
Step: 55699, Reward: [-401.887 -401.887 -401.887] [0.0000], Avg: [-525.523 -525.523 -525.523] (1.000)
Step: 55749, Reward: [-458.956 -458.956 -458.956] [0.0000], Avg: [-525.463 -525.463 -525.463] (1.000)
Step: 55799, Reward: [-400.513 -400.513 -400.513] [0.0000], Avg: [-525.351 -525.351 -525.351] (1.000)
Step: 55849, Reward: [-341.518 -341.518 -341.518] [0.0000], Avg: [-525.186 -525.186 -525.186] (1.000)
Step: 55899, Reward: [-333.059 -333.059 -333.059] [0.0000], Avg: [-525.015 -525.015 -525.015] (1.000)
Step: 55949, Reward: [-479.262 -479.262 -479.262] [0.0000], Avg: [-524.974 -524.974 -524.974] (1.000)
Step: 55999, Reward: [-396.946 -396.946 -396.946] [0.0000], Avg: [-524.859 -524.859 -524.859] (1.000)
Step: 56049, Reward: [-349.496 -349.496 -349.496] [0.0000], Avg: [-524.703 -524.703 -524.703] (1.000)
Step: 56099, Reward: [-315.704 -315.704 -315.704] [0.0000], Avg: [-524.517 -524.517 -524.517] (1.000)
Step: 56149, Reward: [-561.949 -561.949 -561.949] [0.0000], Avg: [-524.55 -524.55 -524.55] (1.000)
Step: 56199, Reward: [-362.348 -362.348 -362.348] [0.0000], Avg: [-524.406 -524.406 -524.406] (1.000)
Step: 56249, Reward: [-348.033 -348.033 -348.033] [0.0000], Avg: [-524.249 -524.249 -524.249] (1.000)
Step: 56299, Reward: [-486.666 -486.666 -486.666] [0.0000], Avg: [-524.216 -524.216 -524.216] (1.000)
Step: 56349, Reward: [-344.326 -344.326 -344.326] [0.0000], Avg: [-524.056 -524.056 -524.056] (1.000)
Step: 56399, Reward: [-369.297 -369.297 -369.297] [0.0000], Avg: [-523.919 -523.919 -523.919] (1.000)
Step: 56449, Reward: [-252.167 -252.167 -252.167] [0.0000], Avg: [-523.678 -523.678 -523.678] (1.000)
Step: 56499, Reward: [-270.933 -270.933 -270.933] [0.0000], Avg: [-523.454 -523.454 -523.454] (1.000)
Step: 56549, Reward: [-337.706 -337.706 -337.706] [0.0000], Avg: [-523.29 -523.29 -523.29] (1.000)
Step: 56599, Reward: [-282.484 -282.484 -282.484] [0.0000], Avg: [-523.077 -523.077 -523.077] (1.000)
Step: 56649, Reward: [-343.822 -343.822 -343.822] [0.0000], Avg: [-522.919 -522.919 -522.919] (1.000)
Step: 56699, Reward: [-280.954 -280.954 -280.954] [0.0000], Avg: [-522.706 -522.706 -522.706] (1.000)
Step: 56749, Reward: [-324.214 -324.214 -324.214] [0.0000], Avg: [-522.531 -522.531 -522.531] (1.000)
Step: 56799, Reward: [-434.626 -434.626 -434.626] [0.0000], Avg: [-522.454 -522.454 -522.454] (1.000)
Step: 56849, Reward: [-285.755 -285.755 -285.755] [0.0000], Avg: [-522.245 -522.245 -522.245] (1.000)
Step: 56899, Reward: [-266.545 -266.545 -266.545] [0.0000], Avg: [-522.021 -522.021 -522.021] (1.000)
Step: 56949, Reward: [-319.397 -319.397 -319.397] [0.0000], Avg: [-521.843 -521.843 -521.843] (1.000)
Step: 56999, Reward: [-277.384 -277.384 -277.384] [0.0000], Avg: [-521.628 -521.628 -521.628] (1.000)
Step: 57049, Reward: [-339.985 -339.985 -339.985] [0.0000], Avg: [-521.469 -521.469 -521.469] (1.000)
Step: 57099, Reward: [-271.784 -271.784 -271.784] [0.0000], Avg: [-521.25 -521.25 -521.25] (1.000)
Step: 57149, Reward: [-313.188 -313.188 -313.188] [0.0000], Avg: [-521.068 -521.068 -521.068] (1.000)
Step: 57199, Reward: [-453.612 -453.612 -453.612] [0.0000], Avg: [-521.009 -521.009 -521.009] (1.000)
Step: 57249, Reward: [-306.591 -306.591 -306.591] [0.0000], Avg: [-520.822 -520.822 -520.822] (1.000)
Step: 57299, Reward: [-357.829 -357.829 -357.829] [0.0000], Avg: [-520.68 -520.68 -520.68] (1.000)
Step: 57349, Reward: [-345.686 -345.686 -345.686] [0.0000], Avg: [-520.527 -520.527 -520.527] (1.000)
Step: 57399, Reward: [-336.913 -336.913 -336.913] [0.0000], Avg: [-520.367 -520.367 -520.367] (1.000)
Step: 57449, Reward: [-300.174 -300.174 -300.174] [0.0000], Avg: [-520.176 -520.176 -520.176] (1.000)
Step: 57499, Reward: [-385.751 -385.751 -385.751] [0.0000], Avg: [-520.059 -520.059 -520.059] (1.000)
Step: 57549, Reward: [-340.653 -340.653 -340.653] [0.0000], Avg: [-519.903 -519.903 -519.903] (1.000)
Step: 57599, Reward: [-437.722 -437.722 -437.722] [0.0000], Avg: [-519.832 -519.832 -519.832] (1.000)
Step: 57649, Reward: [-312.362 -312.362 -312.362] [0.0000], Avg: [-519.652 -519.652 -519.652] (1.000)
Step: 57699, Reward: [-456.669 -456.669 -456.669] [0.0000], Avg: [-519.597 -519.597 -519.597] (1.000)
Step: 57749, Reward: [-479.052 -479.052 -479.052] [0.0000], Avg: [-519.562 -519.562 -519.562] (1.000)
Step: 57799, Reward: [-400.084 -400.084 -400.084] [0.0000], Avg: [-519.459 -519.459 -519.459] (1.000)
Step: 57849, Reward: [-404.767 -404.767 -404.767] [0.0000], Avg: [-519.36 -519.36 -519.36] (1.000)
Step: 57899, Reward: [-404.564 -404.564 -404.564] [0.0000], Avg: [-519.261 -519.261 -519.261] (1.000)
Step: 57949, Reward: [-387.893 -387.893 -387.893] [0.0000], Avg: [-519.147 -519.147 -519.147] (1.000)
Step: 57999, Reward: [-403.857 -403.857 -403.857] [0.0000], Avg: [-519.048 -519.048 -519.048] (1.000)
Step: 58049, Reward: [-353.243 -353.243 -353.243] [0.0000], Avg: [-518.905 -518.905 -518.905] (1.000)
Step: 58099, Reward: [-375.032 -375.032 -375.032] [0.0000], Avg: [-518.781 -518.781 -518.781] (1.000)
Step: 58149, Reward: [-430.39 -430.39 -430.39] [0.0000], Avg: [-518.705 -518.705 -518.705] (1.000)
Step: 58199, Reward: [-394.239 -394.239 -394.239] [0.0000], Avg: [-518.598 -518.598 -518.598] (1.000)
Step: 58249, Reward: [-405.55 -405.55 -405.55] [0.0000], Avg: [-518.501 -518.501 -518.501] (1.000)
Step: 58299, Reward: [-258.947 -258.947 -258.947] [0.0000], Avg: [-518.279 -518.279 -518.279] (1.000)
Step: 58349, Reward: [-382.619 -382.619 -382.619] [0.0000], Avg: [-518.162 -518.162 -518.162] (1.000)
Step: 58399, Reward: [-387.22 -387.22 -387.22] [0.0000], Avg: [-518.05 -518.05 -518.05] (1.000)
Step: 58449, Reward: [-392.39 -392.39 -392.39] [0.0000], Avg: [-517.943 -517.943 -517.943] (1.000)
Step: 58499, Reward: [-319.622 -319.622 -319.622] [0.0000], Avg: [-517.773 -517.773 -517.773] (1.000)
Step: 58549, Reward: [-282.78 -282.78 -282.78] [0.0000], Avg: [-517.573 -517.573 -517.573] (1.000)
Step: 58599, Reward: [-340.281 -340.281 -340.281] [0.0000], Avg: [-517.421 -517.421 -517.421] (1.000)
Step: 58649, Reward: [-340.612 -340.612 -340.612] [0.0000], Avg: [-517.271 -517.271 -517.271] (1.000)
Step: 58699, Reward: [-421.057 -421.057 -421.057] [0.0000], Avg: [-517.189 -517.189 -517.189] (1.000)
Step: 58749, Reward: [-405.091 -405.091 -405.091] [0.0000], Avg: [-517.093 -517.093 -517.093] (1.000)
Step: 58799, Reward: [-291.19 -291.19 -291.19] [0.0000], Avg: [-516.901 -516.901 -516.901] (1.000)
Step: 58849, Reward: [-417.051 -417.051 -417.051] [0.0000], Avg: [-516.816 -516.816 -516.816] (1.000)
Step: 58899, Reward: [-377.059 -377.059 -377.059] [0.0000], Avg: [-516.698 -516.698 -516.698] (1.000)
Step: 58949, Reward: [-357.385 -357.385 -357.385] [0.0000], Avg: [-516.562 -516.562 -516.562] (1.000)
Step: 58999, Reward: [-425.342 -425.342 -425.342] [0.0000], Avg: [-516.485 -516.485 -516.485] (1.000)
Step: 59049, Reward: [-364.299 -364.299 -364.299] [0.0000], Avg: [-516.356 -516.356 -516.356] (1.000)
Step: 59099, Reward: [-418.448 -418.448 -418.448] [0.0000], Avg: [-516.273 -516.273 -516.273] (1.000)
Step: 59149, Reward: [-359.361 -359.361 -359.361] [0.0000], Avg: [-516.141 -516.141 -516.141] (1.000)
Step: 59199, Reward: [-377.108 -377.108 -377.108] [0.0000], Avg: [-516.023 -516.023 -516.023] (1.000)
Step: 59249, Reward: [-328.446 -328.446 -328.446] [0.0000], Avg: [-515.865 -515.865 -515.865] (1.000)
Step: 59299, Reward: [-405.119 -405.119 -405.119] [0.0000], Avg: [-515.772 -515.772 -515.772] (1.000)
Step: 59349, Reward: [-476.166 -476.166 -476.166] [0.0000], Avg: [-515.738 -515.738 -515.738] (1.000)
Step: 59399, Reward: [-275.673 -275.673 -275.673] [0.0000], Avg: [-515.536 -515.536 -515.536] (1.000)
Step: 59449, Reward: [-297.298 -297.298 -297.298] [0.0000], Avg: [-515.353 -515.353 -515.353] (1.000)
Step: 59499, Reward: [-343.539 -343.539 -343.539] [0.0000], Avg: [-515.208 -515.208 -515.208] (1.000)
Step: 59549, Reward: [-384.437 -384.437 -384.437] [0.0000], Avg: [-515.099 -515.099 -515.099] (1.000)
Step: 59599, Reward: [-371.947 -371.947 -371.947] [0.0000], Avg: [-514.978 -514.978 -514.978] (1.000)
Step: 59649, Reward: [-385.519 -385.519 -385.519] [0.0000], Avg: [-514.87 -514.87 -514.87] (1.000)
Step: 59699, Reward: [-307.81 -307.81 -307.81] [0.0000], Avg: [-514.697 -514.697 -514.697] (1.000)
Step: 59749, Reward: [-359.894 -359.894 -359.894] [0.0000], Avg: [-514.567 -514.567 -514.567] (1.000)
Step: 59799, Reward: [-302.688 -302.688 -302.688] [0.0000], Avg: [-514.39 -514.39 -514.39] (1.000)
Step: 59849, Reward: [-404.281 -404.281 -404.281] [0.0000], Avg: [-514.298 -514.298 -514.298] (1.000)
Step: 59899, Reward: [-373.735 -373.735 -373.735] [0.0000], Avg: [-514.181 -514.181 -514.181] (1.000)
Step: 59949, Reward: [-448.785 -448.785 -448.785] [0.0000], Avg: [-514.126 -514.126 -514.126] (1.000)
Step: 59999, Reward: [-426.397 -426.397 -426.397] [0.0000], Avg: [-514.053 -514.053 -514.053] (1.000)
Step: 60049, Reward: [-445.941 -445.941 -445.941] [0.0000], Avg: [-513.996 -513.996 -513.996] (1.000)
Step: 60099, Reward: [-309.018 -309.018 -309.018] [0.0000], Avg: [-513.826 -513.826 -513.826] (1.000)
Step: 60149, Reward: [-392.653 -392.653 -392.653] [0.0000], Avg: [-513.725 -513.725 -513.725] (1.000)
Step: 60199, Reward: [-340.827 -340.827 -340.827] [0.0000], Avg: [-513.581 -513.581 -513.581] (1.000)
Step: 60249, Reward: [-364.797 -364.797 -364.797] [0.0000], Avg: [-513.458 -513.458 -513.458] (1.000)
Step: 60299, Reward: [-282.807 -282.807 -282.807] [0.0000], Avg: [-513.267 -513.267 -513.267] (1.000)
Step: 60349, Reward: [-380.057 -380.057 -380.057] [0.0000], Avg: [-513.156 -513.156 -513.156] (1.000)
Step: 60399, Reward: [-298.473 -298.473 -298.473] [0.0000], Avg: [-512.979 -512.979 -512.979] (1.000)
Step: 60449, Reward: [-457.695 -457.695 -457.695] [0.0000], Avg: [-512.933 -512.933 -512.933] (1.000)
Step: 60499, Reward: [-351.753 -351.753 -351.753] [0.0000], Avg: [-512.8 -512.8 -512.8] (1.000)
Step: 60549, Reward: [-316.743 -316.743 -316.743] [0.0000], Avg: [-512.638 -512.638 -512.638] (1.000)
Step: 60599, Reward: [-343.904 -343.904 -343.904] [0.0000], Avg: [-512.498 -512.498 -512.498] (1.000)
Step: 60649, Reward: [-248.026 -248.026 -248.026] [0.0000], Avg: [-512.28 -512.28 -512.28] (1.000)
Step: 60699, Reward: [-385.433 -385.433 -385.433] [0.0000], Avg: [-512.176 -512.176 -512.176] (1.000)
Step: 60749, Reward: [-455.243 -455.243 -455.243] [0.0000], Avg: [-512.129 -512.129 -512.129] (1.000)
Step: 60799, Reward: [-327.988 -327.988 -327.988] [0.0000], Avg: [-511.978 -511.978 -511.978] (1.000)
Step: 60849, Reward: [-396.332 -396.332 -396.332] [0.0000], Avg: [-511.883 -511.883 -511.883] (1.000)
Step: 60899, Reward: [-372.535 -372.535 -372.535] [0.0000], Avg: [-511.768 -511.768 -511.768] (1.000)
Step: 60949, Reward: [-391.777 -391.777 -391.777] [0.0000], Avg: [-511.67 -511.67 -511.67] (1.000)
Step: 60999, Reward: [-377.625 -377.625 -377.625] [0.0000], Avg: [-511.56 -511.56 -511.56] (1.000)
Step: 61049, Reward: [-293.179 -293.179 -293.179] [0.0000], Avg: [-511.381 -511.381 -511.381] (1.000)
Step: 61099, Reward: [-266.226 -266.226 -266.226] [0.0000], Avg: [-511.18 -511.18 -511.18] (1.000)
Step: 61149, Reward: [-367.956 -367.956 -367.956] [0.0000], Avg: [-511.063 -511.063 -511.063] (1.000)
Step: 61199, Reward: [-394.138 -394.138 -394.138] [0.0000], Avg: [-510.968 -510.968 -510.968] (1.000)
Step: 61249, Reward: [-423.077 -423.077 -423.077] [0.0000], Avg: [-510.896 -510.896 -510.896] (1.000)
Step: 61299, Reward: [-315.789 -315.789 -315.789] [0.0000], Avg: [-510.737 -510.737 -510.737] (1.000)
Step: 61349, Reward: [-283.043 -283.043 -283.043] [0.0000], Avg: [-510.551 -510.551 -510.551] (1.000)
Step: 61399, Reward: [-384.782 -384.782 -384.782] [0.0000], Avg: [-510.449 -510.449 -510.449] (1.000)
Step: 61449, Reward: [-356.346 -356.346 -356.346] [0.0000], Avg: [-510.324 -510.324 -510.324] (1.000)
Step: 61499, Reward: [-345.096 -345.096 -345.096] [0.0000], Avg: [-510.189 -510.189 -510.189] (1.000)
Step: 61549, Reward: [-381.794 -381.794 -381.794] [0.0000], Avg: [-510.085 -510.085 -510.085] (1.000)
Step: 61599, Reward: [-268.74 -268.74 -268.74] [0.0000], Avg: [-509.889 -509.889 -509.889] (1.000)
Step: 61649, Reward: [-455.509 -455.509 -455.509] [0.0000], Avg: [-509.845 -509.845 -509.845] (1.000)
Step: 61699, Reward: [-344.249 -344.249 -344.249] [0.0000], Avg: [-509.711 -509.711 -509.711] (1.000)
Step: 61749, Reward: [-310.156 -310.156 -310.156] [0.0000], Avg: [-509.549 -509.549 -509.549] (1.000)
Step: 61799, Reward: [-431.433 -431.433 -431.433] [0.0000], Avg: [-509.486 -509.486 -509.486] (1.000)
Step: 61849, Reward: [-354.513 -354.513 -354.513] [0.0000], Avg: [-509.361 -509.361 -509.361] (1.000)
Step: 61899, Reward: [-350.019 -350.019 -350.019] [0.0000], Avg: [-509.232 -509.232 -509.232] (1.000)
Step: 61949, Reward: [-387.668 -387.668 -387.668] [0.0000], Avg: [-509.134 -509.134 -509.134] (1.000)
Step: 61999, Reward: [-298.249 -298.249 -298.249] [0.0000], Avg: [-508.964 -508.964 -508.964] (1.000)
Step: 62049, Reward: [-331.427 -331.427 -331.427] [0.0000], Avg: [-508.821 -508.821 -508.821] (1.000)
Step: 62099, Reward: [-477.982 -477.982 -477.982] [0.0000], Avg: [-508.796 -508.796 -508.796] (1.000)
Step: 62149, Reward: [-421.24 -421.24 -421.24] [0.0000], Avg: [-508.725 -508.725 -508.725] (1.000)
Step: 62199, Reward: [-370.1 -370.1 -370.1] [0.0000], Avg: [-508.614 -508.614 -508.614] (1.000)
Step: 62249, Reward: [-319.397 -319.397 -319.397] [0.0000], Avg: [-508.462 -508.462 -508.462] (1.000)
Step: 62299, Reward: [-278.781 -278.781 -278.781] [0.0000], Avg: [-508.278 -508.278 -508.278] (1.000)
Step: 62349, Reward: [-397.512 -397.512 -397.512] [0.0000], Avg: [-508.189 -508.189 -508.189] (1.000)
Step: 62399, Reward: [-382.327 -382.327 -382.327] [0.0000], Avg: [-508.088 -508.088 -508.088] (1.000)
Step: 62449, Reward: [-312.901 -312.901 -312.901] [0.0000], Avg: [-507.932 -507.932 -507.932] (1.000)
Step: 62499, Reward: [-434.692 -434.692 -434.692] [0.0000], Avg: [-507.873 -507.873 -507.873] (1.000)
Step: 62549, Reward: [-361.794 -361.794 -361.794] [0.0000], Avg: [-507.756 -507.756 -507.756] (1.000)
Step: 62599, Reward: [-314.195 -314.195 -314.195] [0.0000], Avg: [-507.602 -507.602 -507.602] (1.000)
Step: 62649, Reward: [-336.141 -336.141 -336.141] [0.0000], Avg: [-507.465 -507.465 -507.465] (1.000)
Step: 62699, Reward: [-465.26 -465.26 -465.26] [0.0000], Avg: [-507.431 -507.431 -507.431] (1.000)
Step: 62749, Reward: [-427.777 -427.777 -427.777] [0.0000], Avg: [-507.368 -507.368 -507.368] (1.000)
Step: 62799, Reward: [-382.892 -382.892 -382.892] [0.0000], Avg: [-507.269 -507.269 -507.269] (1.000)
Step: 62849, Reward: [-335.479 -335.479 -335.479] [0.0000], Avg: [-507.132 -507.132 -507.132] (1.000)
Step: 62899, Reward: [-316.313 -316.313 -316.313] [0.0000], Avg: [-506.98 -506.98 -506.98] (1.000)
Step: 62949, Reward: [-415.441 -415.441 -415.441] [0.0000], Avg: [-506.908 -506.908 -506.908] (1.000)
Step: 62999, Reward: [-390.662 -390.662 -390.662] [0.0000], Avg: [-506.815 -506.815 -506.815] (1.000)
Step: 63049, Reward: [-429.571 -429.571 -429.571] [0.0000], Avg: [-506.754 -506.754 -506.754] (1.000)
Step: 63099, Reward: [-366.193 -366.193 -366.193] [0.0000], Avg: [-506.643 -506.643 -506.643] (1.000)
Step: 63149, Reward: [-414.62 -414.62 -414.62] [0.0000], Avg: [-506.57 -506.57 -506.57] (1.000)
Step: 63199, Reward: [-397.63 -397.63 -397.63] [0.0000], Avg: [-506.484 -506.484 -506.484] (1.000)
Step: 63249, Reward: [-310.37 -310.37 -310.37] [0.0000], Avg: [-506.329 -506.329 -506.329] (1.000)
Step: 63299, Reward: [-374.704 -374.704 -374.704] [0.0000], Avg: [-506.225 -506.225 -506.225] (1.000)
Step: 63349, Reward: [-345.561 -345.561 -345.561] [0.0000], Avg: [-506.098 -506.098 -506.098] (1.000)
Step: 63399, Reward: [-290.163 -290.163 -290.163] [0.0000], Avg: [-505.928 -505.928 -505.928] (1.000)
Step: 63449, Reward: [-446.359 -446.359 -446.359] [0.0000], Avg: [-505.881 -505.881 -505.881] (1.000)
Step: 63499, Reward: [-493.074 -493.074 -493.074] [0.0000], Avg: [-505.871 -505.871 -505.871] (1.000)
Step: 63549, Reward: [-303.623 -303.623 -303.623] [0.0000], Avg: [-505.711 -505.711 -505.711] (1.000)
Step: 63599, Reward: [-371.731 -371.731 -371.731] [0.0000], Avg: [-505.606 -505.606 -505.606] (1.000)
Step: 63649, Reward: [-396.449 -396.449 -396.449] [0.0000], Avg: [-505.52 -505.52 -505.52] (1.000)
Step: 63699, Reward: [-374.171 -374.171 -374.171] [0.0000], Avg: [-505.417 -505.417 -505.417] (1.000)
Step: 63749, Reward: [-496.767 -496.767 -496.767] [0.0000], Avg: [-505.41 -505.41 -505.41] (1.000)
Step: 63799, Reward: [-360.691 -360.691 -360.691] [0.0000], Avg: [-505.297 -505.297 -505.297] (1.000)
Step: 63849, Reward: [-394.215 -394.215 -394.215] [0.0000], Avg: [-505.21 -505.21 -505.21] (1.000)
Step: 63899, Reward: [-299.276 -299.276 -299.276] [0.0000], Avg: [-505.049 -505.049 -505.049] (1.000)
Step: 63949, Reward: [-382.488 -382.488 -382.488] [0.0000], Avg: [-504.953 -504.953 -504.953] (1.000)
Step: 63999, Reward: [-356.871 -356.871 -356.871] [0.0000], Avg: [-504.837 -504.837 -504.837] (1.000)
Step: 64049, Reward: [-458.537 -458.537 -458.537] [0.0000], Avg: [-504.801 -504.801 -504.801] (1.000)
Step: 64099, Reward: [-367.841 -367.841 -367.841] [0.0000], Avg: [-504.694 -504.694 -504.694] (1.000)
Step: 64149, Reward: [-367.057 -367.057 -367.057] [0.0000], Avg: [-504.587 -504.587 -504.587] (1.000)
Step: 64199, Reward: [-320.825 -320.825 -320.825] [0.0000], Avg: [-504.444 -504.444 -504.444] (1.000)
Step: 64249, Reward: [-400.267 -400.267 -400.267] [0.0000], Avg: [-504.363 -504.363 -504.363] (1.000)
Step: 64299, Reward: [-337.465 -337.465 -337.465] [0.0000], Avg: [-504.233 -504.233 -504.233] (1.000)
Step: 64349, Reward: [-373.073 -373.073 -373.073] [0.0000], Avg: [-504.131 -504.131 -504.131] (1.000)
Step: 64399, Reward: [-260.278 -260.278 -260.278] [0.0000], Avg: [-503.942 -503.942 -503.942] (1.000)
Step: 64449, Reward: [-488.391 -488.391 -488.391] [0.0000], Avg: [-503.93 -503.93 -503.93] (1.000)
Step: 64499, Reward: [-269.809 -269.809 -269.809] [0.0000], Avg: [-503.748 -503.748 -503.748] (1.000)
Step: 64549, Reward: [-402.289 -402.289 -402.289] [0.0000], Avg: [-503.67 -503.67 -503.67] (1.000)
Step: 64599, Reward: [-282.387 -282.387 -282.387] [0.0000], Avg: [-503.499 -503.499 -503.499] (1.000)
Step: 64649, Reward: [-404.569 -404.569 -404.569] [0.0000], Avg: [-503.422 -503.422 -503.422] (1.000)
Step: 64699, Reward: [-355.842 -355.842 -355.842] [0.0000], Avg: [-503.308 -503.308 -503.308] (1.000)
Step: 64749, Reward: [-417.798 -417.798 -417.798] [0.0000], Avg: [-503.242 -503.242 -503.242] (1.000)
Step: 64799, Reward: [-350.55 -350.55 -350.55] [0.0000], Avg: [-503.124 -503.124 -503.124] (1.000)
Step: 64849, Reward: [-356.201 -356.201 -356.201] [0.0000], Avg: [-503.011 -503.011 -503.011] (1.000)
Step: 64899, Reward: [-448.364 -448.364 -448.364] [0.0000], Avg: [-502.969 -502.969 -502.969] (1.000)
Step: 64949, Reward: [-304.053 -304.053 -304.053] [0.0000], Avg: [-502.816 -502.816 -502.816] (1.000)
Step: 64999, Reward: [-342.739 -342.739 -342.739] [0.0000], Avg: [-502.692 -502.692 -502.692] (1.000)
Step: 65049, Reward: [-344.941 -344.941 -344.941] [0.0000], Avg: [-502.571 -502.571 -502.571] (1.000)
Step: 65099, Reward: [-269.922 -269.922 -269.922] [0.0000], Avg: [-502.393 -502.393 -502.393] (1.000)
Step: 65149, Reward: [-355.689 -355.689 -355.689] [0.0000], Avg: [-502.28 -502.28 -502.28] (1.000)
Step: 65199, Reward: [-357.364 -357.364 -357.364] [0.0000], Avg: [-502.169 -502.169 -502.169] (1.000)
Step: 65249, Reward: [-380.468 -380.468 -380.468] [0.0000], Avg: [-502.076 -502.076 -502.076] (1.000)
Step: 65299, Reward: [-362.799 -362.799 -362.799] [0.0000], Avg: [-501.969 -501.969 -501.969] (1.000)
Step: 65349, Reward: [-444.944 -444.944 -444.944] [0.0000], Avg: [-501.925 -501.925 -501.925] (1.000)
Step: 65399, Reward: [-317.151 -317.151 -317.151] [0.0000], Avg: [-501.784 -501.784 -501.784] (1.000)
Step: 65449, Reward: [-308.751 -308.751 -308.751] [0.0000], Avg: [-501.637 -501.637 -501.637] (1.000)
Step: 65499, Reward: [-395.506 -395.506 -395.506] [0.0000], Avg: [-501.556 -501.556 -501.556] (1.000)
Step: 65549, Reward: [-374.66 -374.66 -374.66] [0.0000], Avg: [-501.459 -501.459 -501.459] (1.000)
Step: 65599, Reward: [-319.065 -319.065 -319.065] [0.0000], Avg: [-501.32 -501.32 -501.32] (1.000)
Step: 65649, Reward: [-342.703 -342.703 -342.703] [0.0000], Avg: [-501.199 -501.199 -501.199] (1.000)
Step: 65699, Reward: [-318.132 -318.132 -318.132] [0.0000], Avg: [-501.06 -501.06 -501.06] (1.000)
Step: 65749, Reward: [-369.143 -369.143 -369.143] [0.0000], Avg: [-500.959 -500.959 -500.959] (1.000)
Step: 65799, Reward: [-296.461 -296.461 -296.461] [0.0000], Avg: [-500.804 -500.804 -500.804] (1.000)
Step: 65849, Reward: [-320.156 -320.156 -320.156] [0.0000], Avg: [-500.667 -500.667 -500.667] (1.000)
Step: 65899, Reward: [-328.917 -328.917 -328.917] [0.0000], Avg: [-500.536 -500.536 -500.536] (1.000)
Step: 65949, Reward: [-437.1 -437.1 -437.1] [0.0000], Avg: [-500.488 -500.488 -500.488] (1.000)
Step: 65999, Reward: [-297.771 -297.771 -297.771] [0.0000], Avg: [-500.335 -500.335 -500.335] (1.000)
Step: 66049, Reward: [-410.487 -410.487 -410.487] [0.0000], Avg: [-500.267 -500.267 -500.267] (1.000)
Step: 66099, Reward: [-377.661 -377.661 -377.661] [0.0000], Avg: [-500.174 -500.174 -500.174] (1.000)
Step: 66149, Reward: [-302.782 -302.782 -302.782] [0.0000], Avg: [-500.025 -500.025 -500.025] (1.000)
Step: 66199, Reward: [-362.172 -362.172 -362.172] [0.0000], Avg: [-499.921 -499.921 -499.921] (1.000)
Step: 66249, Reward: [-383.622 -383.622 -383.622] [0.0000], Avg: [-499.833 -499.833 -499.833] (1.000)
Step: 66299, Reward: [-479.742 -479.742 -479.742] [0.0000], Avg: [-499.818 -499.818 -499.818] (1.000)
Step: 66349, Reward: [-305.7 -305.7 -305.7] [0.0000], Avg: [-499.671 -499.671 -499.671] (1.000)
Step: 66399, Reward: [-385.762 -385.762 -385.762] [0.0000], Avg: [-499.586 -499.586 -499.586] (1.000)
Step: 66449, Reward: [-355.389 -355.389 -355.389] [0.0000], Avg: [-499.477 -499.477 -499.477] (1.000)
Step: 66499, Reward: [-342.267 -342.267 -342.267] [0.0000], Avg: [-499.359 -499.359 -499.359] (1.000)
Step: 66549, Reward: [-450.68 -450.68 -450.68] [0.0000], Avg: [-499.322 -499.322 -499.322] (1.000)
Step: 66599, Reward: [-287.583 -287.583 -287.583] [0.0000], Avg: [-499.163 -499.163 -499.163] (1.000)
Step: 66649, Reward: [-387.807 -387.807 -387.807] [0.0000], Avg: [-499.08 -499.08 -499.08] (1.000)
Step: 66699, Reward: [-315.352 -315.352 -315.352] [0.0000], Avg: [-498.942 -498.942 -498.942] (1.000)
Step: 66749, Reward: [-399.287 -399.287 -399.287] [0.0000], Avg: [-498.868 -498.868 -498.868] (1.000)
Step: 66799, Reward: [-373.565 -373.565 -373.565] [0.0000], Avg: [-498.774 -498.774 -498.774] (1.000)
Step: 66849, Reward: [-287.471 -287.471 -287.471] [0.0000], Avg: [-498.616 -498.616 -498.616] (1.000)
Step: 66899, Reward: [-278.365 -278.365 -278.365] [0.0000], Avg: [-498.451 -498.451 -498.451] (1.000)
Step: 66949, Reward: [-323.655 -323.655 -323.655] [0.0000], Avg: [-498.321 -498.321 -498.321] (1.000)
Step: 66999, Reward: [-461.828 -461.828 -461.828] [0.0000], Avg: [-498.293 -498.293 -498.293] (1.000)
Step: 67049, Reward: [-312.866 -312.866 -312.866] [0.0000], Avg: [-498.155 -498.155 -498.155] (1.000)
Step: 67099, Reward: [-370.334 -370.334 -370.334] [0.0000], Avg: [-498.06 -498.06 -498.06] (1.000)
Step: 67149, Reward: [-355.122 -355.122 -355.122] [0.0000], Avg: [-497.953 -497.953 -497.953] (1.000)
Step: 67199, Reward: [-360.25 -360.25 -360.25] [0.0000], Avg: [-497.851 -497.851 -497.851] (1.000)
Step: 67249, Reward: [-390.693 -390.693 -390.693] [0.0000], Avg: [-497.771 -497.771 -497.771] (1.000)
Step: 67299, Reward: [-402.807 -402.807 -402.807] [0.0000], Avg: [-497.701 -497.701 -497.701] (1.000)
Step: 67349, Reward: [-359.985 -359.985 -359.985] [0.0000], Avg: [-497.598 -497.598 -497.598] (1.000)
Step: 67399, Reward: [-350.3 -350.3 -350.3] [0.0000], Avg: [-497.489 -497.489 -497.489] (1.000)
Step: 67449, Reward: [-351. -351. -351.] [0.0000], Avg: [-497.381 -497.381 -497.381] (1.000)
Step: 67499, Reward: [-300.818 -300.818 -300.818] [0.0000], Avg: [-497.235 -497.235 -497.235] (1.000)
Step: 67549, Reward: [-302.892 -302.892 -302.892] [0.0000], Avg: [-497.091 -497.091 -497.091] (1.000)
Step: 67599, Reward: [-343.849 -343.849 -343.849] [0.0000], Avg: [-496.978 -496.978 -496.978] (1.000)
Step: 67649, Reward: [-444.571 -444.571 -444.571] [0.0000], Avg: [-496.939 -496.939 -496.939] (1.000)
Step: 67699, Reward: [-388.145 -388.145 -388.145] [0.0000], Avg: [-496.859 -496.859 -496.859] (1.000)
Step: 67749, Reward: [-278.964 -278.964 -278.964] [0.0000], Avg: [-496.698 -496.698 -496.698] (1.000)
Step: 67799, Reward: [-353.472 -353.472 -353.472] [0.0000], Avg: [-496.592 -496.592 -496.592] (1.000)
Step: 67849, Reward: [-401.131 -401.131 -401.131] [0.0000], Avg: [-496.522 -496.522 -496.522] (1.000)
Step: 67899, Reward: [-545.243 -545.243 -545.243] [0.0000], Avg: [-496.558 -496.558 -496.558] (1.000)
Step: 67949, Reward: [-288.033 -288.033 -288.033] [0.0000], Avg: [-496.404 -496.404 -496.404] (1.000)
Step: 67999, Reward: [-429.005 -429.005 -429.005] [0.0000], Avg: [-496.355 -496.355 -496.355] (1.000)
Step: 68049, Reward: [-322.772 -322.772 -322.772] [0.0000], Avg: [-496.227 -496.227 -496.227] (1.000)
Step: 68099, Reward: [-408.15 -408.15 -408.15] [0.0000], Avg: [-496.163 -496.163 -496.163] (1.000)
Step: 68149, Reward: [-250.703 -250.703 -250.703] [0.0000], Avg: [-495.983 -495.983 -495.983] (1.000)
Step: 68199, Reward: [-331.888 -331.888 -331.888] [0.0000], Avg: [-495.862 -495.862 -495.862] (1.000)
Step: 68249, Reward: [-423.109 -423.109 -423.109] [0.0000], Avg: [-495.809 -495.809 -495.809] (1.000)
Step: 68299, Reward: [-294.013 -294.013 -294.013] [0.0000], Avg: [-495.661 -495.661 -495.661] (1.000)
Step: 68349, Reward: [-304.078 -304.078 -304.078] [0.0000], Avg: [-495.521 -495.521 -495.521] (1.000)
Step: 68399, Reward: [-283.538 -283.538 -283.538] [0.0000], Avg: [-495.366 -495.366 -495.366] (1.000)
Step: 68449, Reward: [-419.628 -419.628 -419.628] [0.0000], Avg: [-495.311 -495.311 -495.311] (1.000)
Step: 68499, Reward: [-418.858 -418.858 -418.858] [0.0000], Avg: [-495.255 -495.255 -495.255] (1.000)
Step: 68549, Reward: [-324.536 -324.536 -324.536] [0.0000], Avg: [-495.13 -495.13 -495.13] (1.000)
Step: 68599, Reward: [-471.38 -471.38 -471.38] [0.0000], Avg: [-495.113 -495.113 -495.113] (1.000)
Step: 68649, Reward: [-384.519 -384.519 -384.519] [0.0000], Avg: [-495.033 -495.033 -495.033] (1.000)
Step: 68699, Reward: [-489.994 -489.994 -489.994] [0.0000], Avg: [-495.029 -495.029 -495.029] (1.000)
Step: 68749, Reward: [-263.883 -263.883 -263.883] [0.0000], Avg: [-494.861 -494.861 -494.861] (1.000)
Step: 68799, Reward: [-462.238 -462.238 -462.238] [0.0000], Avg: [-494.837 -494.837 -494.837] (1.000)
Step: 68849, Reward: [-357.485 -357.485 -357.485] [0.0000], Avg: [-494.737 -494.737 -494.737] (1.000)
Step: 68899, Reward: [-290.334 -290.334 -290.334] [0.0000], Avg: [-494.589 -494.589 -494.589] (1.000)
Step: 68949, Reward: [-419.601 -419.601 -419.601] [0.0000], Avg: [-494.535 -494.535 -494.535] (1.000)
Step: 68999, Reward: [-387.37 -387.37 -387.37] [0.0000], Avg: [-494.457 -494.457 -494.457] (1.000)
Step: 69049, Reward: [-352.675 -352.675 -352.675] [0.0000], Avg: [-494.354 -494.354 -494.354] (1.000)
Step: 69099, Reward: [-399.701 -399.701 -399.701] [0.0000], Avg: [-494.286 -494.286 -494.286] (1.000)
Step: 69149, Reward: [-325.408 -325.408 -325.408] [0.0000], Avg: [-494.164 -494.164 -494.164] (1.000)
Step: 69199, Reward: [-334.88 -334.88 -334.88] [0.0000], Avg: [-494.049 -494.049 -494.049] (1.000)
Step: 69249, Reward: [-305.351 -305.351 -305.351] [0.0000], Avg: [-493.912 -493.912 -493.912] (1.000)
Step: 69299, Reward: [-354.089 -354.089 -354.089] [0.0000], Avg: [-493.811 -493.811 -493.811] (1.000)
Step: 69349, Reward: [-344.947 -344.947 -344.947] [0.0000], Avg: [-493.704 -493.704 -493.704] (1.000)
Step: 69399, Reward: [-447.681 -447.681 -447.681] [0.0000], Avg: [-493.671 -493.671 -493.671] (1.000)
Step: 69449, Reward: [-341.251 -341.251 -341.251] [0.0000], Avg: [-493.561 -493.561 -493.561] (1.000)
Step: 69499, Reward: [-423.907 -423.907 -423.907] [0.0000], Avg: [-493.511 -493.511 -493.511] (1.000)
Step: 69549, Reward: [-360.027 -360.027 -360.027] [0.0000], Avg: [-493.415 -493.415 -493.415] (1.000)
Step: 69599, Reward: [-317.822 -317.822 -317.822] [0.0000], Avg: [-493.289 -493.289 -493.289] (1.000)
Step: 69649, Reward: [-280.969 -280.969 -280.969] [0.0000], Avg: [-493.137 -493.137 -493.137] (1.000)
Step: 69699, Reward: [-286.663 -286.663 -286.663] [0.0000], Avg: [-492.989 -492.989 -492.989] (1.000)
Step: 69749, Reward: [-313.274 -313.274 -313.274] [0.0000], Avg: [-492.86 -492.86 -492.86] (1.000)
Step: 69799, Reward: [-344.378 -344.378 -344.378] [0.0000], Avg: [-492.753 -492.753 -492.753] (1.000)
Step: 69849, Reward: [-449.24 -449.24 -449.24] [0.0000], Avg: [-492.722 -492.722 -492.722] (1.000)
Step: 69899, Reward: [-376.708 -376.708 -376.708] [0.0000], Avg: [-492.639 -492.639 -492.639] (1.000)
Step: 69949, Reward: [-393.793 -393.793 -393.793] [0.0000], Avg: [-492.569 -492.569 -492.569] (1.000)
Step: 69999, Reward: [-377.638 -377.638 -377.638] [0.0000], Avg: [-492.486 -492.486 -492.486] (1.000)
Step: 70049, Reward: [-294.289 -294.289 -294.289] [0.0000], Avg: [-492.345 -492.345 -492.345] (1.000)
Step: 70099, Reward: [-362.283 -362.283 -362.283] [0.0000], Avg: [-492.252 -492.252 -492.252] (1.000)
Step: 70149, Reward: [-319.953 -319.953 -319.953] [0.0000], Avg: [-492.129 -492.129 -492.129] (1.000)
Step: 70199, Reward: [-305.601 -305.601 -305.601] [0.0000], Avg: [-491.997 -491.997 -491.997] (1.000)
Step: 70249, Reward: [-452.603 -452.603 -452.603] [0.0000], Avg: [-491.968 -491.968 -491.968] (1.000)
Step: 70299, Reward: [-317.372 -317.372 -317.372] [0.0000], Avg: [-491.844 -491.844 -491.844] (1.000)
Step: 70349, Reward: [-290.426 -290.426 -290.426] [0.0000], Avg: [-491.701 -491.701 -491.701] (1.000)
Step: 70399, Reward: [-327.803 -327.803 -327.803] [0.0000], Avg: [-491.585 -491.585 -491.585] (1.000)
Step: 70449, Reward: [-327.992 -327.992 -327.992] [0.0000], Avg: [-491.469 -491.469 -491.469] (1.000)
Step: 70499, Reward: [-402.453 -402.453 -402.453] [0.0000], Avg: [-491.406 -491.406 -491.406] (1.000)
Step: 70549, Reward: [-366.77 -366.77 -366.77] [0.0000], Avg: [-491.317 -491.317 -491.317] (1.000)
Step: 70599, Reward: [-378.592 -378.592 -378.592] [0.0000], Avg: [-491.237 -491.237 -491.237] (1.000)
Step: 70649, Reward: [-436.823 -436.823 -436.823] [0.0000], Avg: [-491.199 -491.199 -491.199] (1.000)
Step: 70699, Reward: [-364.444 -364.444 -364.444] [0.0000], Avg: [-491.109 -491.109 -491.109] (1.000)
Step: 70749, Reward: [-349.684 -349.684 -349.684] [0.0000], Avg: [-491.009 -491.009 -491.009] (1.000)
Step: 70799, Reward: [-409.322 -409.322 -409.322] [0.0000], Avg: [-490.952 -490.952 -490.952] (1.000)
Step: 70849, Reward: [-262.884 -262.884 -262.884] [0.0000], Avg: [-490.791 -490.791 -490.791] (1.000)
Step: 70899, Reward: [-308.636 -308.636 -308.636] [0.0000], Avg: [-490.662 -490.662 -490.662] (1.000)
Step: 70949, Reward: [-262.805 -262.805 -262.805] [0.0000], Avg: [-490.502 -490.502 -490.502] (1.000)
Step: 70999, Reward: [-464.465 -464.465 -464.465] [0.0000], Avg: [-490.483 -490.483 -490.483] (1.000)
Step: 71049, Reward: [-305.245 -305.245 -305.245] [0.0000], Avg: [-490.353 -490.353 -490.353] (1.000)
Step: 71099, Reward: [-251.249 -251.249 -251.249] [0.0000], Avg: [-490.185 -490.185 -490.185] (1.000)
Step: 71149, Reward: [-447.205 -447.205 -447.205] [0.0000], Avg: [-490.155 -490.155 -490.155] (1.000)
Step: 71199, Reward: [-306.348 -306.348 -306.348] [0.0000], Avg: [-490.025 -490.025 -490.025] (1.000)
Step: 71249, Reward: [-336.302 -336.302 -336.302] [0.0000], Avg: [-489.918 -489.918 -489.918] (1.000)
Step: 71299, Reward: [-311.101 -311.101 -311.101] [0.0000], Avg: [-489.792 -489.792 -489.792] (1.000)
Step: 71349, Reward: [-384.62 -384.62 -384.62] [0.0000], Avg: [-489.718 -489.718 -489.718] (1.000)
Step: 71399, Reward: [-418.727 -418.727 -418.727] [0.0000], Avg: [-489.669 -489.669 -489.669] (1.000)
Step: 71449, Reward: [-340.831 -340.831 -340.831] [0.0000], Avg: [-489.565 -489.565 -489.565] (1.000)
Step: 71499, Reward: [-334.991 -334.991 -334.991] [0.0000], Avg: [-489.457 -489.457 -489.457] (1.000)
Step: 71549, Reward: [-339.312 -339.312 -339.312] [0.0000], Avg: [-489.352 -489.352 -489.352] (1.000)
Step: 71599, Reward: [-305.451 -305.451 -305.451] [0.0000], Avg: [-489.223 -489.223 -489.223] (1.000)
Step: 71649, Reward: [-309.167 -309.167 -309.167] [0.0000], Avg: [-489.098 -489.098 -489.098] (1.000)
Step: 71699, Reward: [-313.268 -313.268 -313.268] [0.0000], Avg: [-488.975 -488.975 -488.975] (1.000)
Step: 71749, Reward: [-360.424 -360.424 -360.424] [0.0000], Avg: [-488.885 -488.885 -488.885] (1.000)
Step: 71799, Reward: [-372.274 -372.274 -372.274] [0.0000], Avg: [-488.804 -488.804 -488.804] (1.000)
Step: 71849, Reward: [-392.932 -392.932 -392.932] [0.0000], Avg: [-488.737 -488.737 -488.737] (1.000)
Step: 71899, Reward: [-379.433 -379.433 -379.433] [0.0000], Avg: [-488.661 -488.661 -488.661] (1.000)
Step: 71949, Reward: [-411.136 -411.136 -411.136] [0.0000], Avg: [-488.608 -488.608 -488.608] (1.000)
Step: 71999, Reward: [-333.495 -333.495 -333.495] [0.0000], Avg: [-488.5 -488.5 -488.5] (1.000)
Step: 72049, Reward: [-391.672 -391.672 -391.672] [0.0000], Avg: [-488.433 -488.433 -488.433] (1.000)
Step: 72099, Reward: [-440.32 -440.32 -440.32] [0.0000], Avg: [-488.399 -488.399 -488.399] (1.000)
Step: 72149, Reward: [-413.577 -413.577 -413.577] [0.0000], Avg: [-488.347 -488.347 -488.347] (1.000)
Step: 72199, Reward: [-458.783 -458.783 -458.783] [0.0000], Avg: [-488.327 -488.327 -488.327] (1.000)
Step: 72249, Reward: [-431.505 -431.505 -431.505] [0.0000], Avg: [-488.288 -488.288 -488.288] (1.000)
Step: 72299, Reward: [-304.548 -304.548 -304.548] [0.0000], Avg: [-488.161 -488.161 -488.161] (1.000)
Step: 72349, Reward: [-327.476 -327.476 -327.476] [0.0000], Avg: [-488.049 -488.049 -488.049] (1.000)
Step: 72399, Reward: [-385.378 -385.378 -385.378] [0.0000], Avg: [-487.979 -487.979 -487.979] (1.000)
Step: 72449, Reward: [-378.361 -378.361 -378.361] [0.0000], Avg: [-487.903 -487.903 -487.903] (1.000)
Step: 72499, Reward: [-281.724 -281.724 -281.724] [0.0000], Avg: [-487.761 -487.761 -487.761] (1.000)
Step: 72549, Reward: [-276.079 -276.079 -276.079] [0.0000], Avg: [-487.615 -487.615 -487.615] (1.000)
Step: 72599, Reward: [-292.103 -292.103 -292.103] [0.0000], Avg: [-487.48 -487.48 -487.48] (1.000)
Step: 72649, Reward: [-262.993 -262.993 -262.993] [0.0000], Avg: [-487.326 -487.326 -487.326] (1.000)
Step: 72699, Reward: [-354.73 -354.73 -354.73] [0.0000], Avg: [-487.235 -487.235 -487.235] (1.000)
Step: 72749, Reward: [-376.989 -376.989 -376.989] [0.0000], Avg: [-487.159 -487.159 -487.159] (1.000)
Step: 72799, Reward: [-403.764 -403.764 -403.764] [0.0000], Avg: [-487.101 -487.101 -487.101] (1.000)
Step: 72849, Reward: [-315.207 -315.207 -315.207] [0.0000], Avg: [-486.983 -486.983 -486.983] (1.000)
Step: 72899, Reward: [-343.385 -343.385 -343.385] [0.0000], Avg: [-486.885 -486.885 -486.885] (1.000)
Step: 72949, Reward: [-445.153 -445.153 -445.153] [0.0000], Avg: [-486.856 -486.856 -486.856] (1.000)
Step: 72999, Reward: [-384.33 -384.33 -384.33] [0.0000], Avg: [-486.786 -486.786 -486.786] (1.000)
Step: 73049, Reward: [-421.969 -421.969 -421.969] [0.0000], Avg: [-486.742 -486.742 -486.742] (1.000)
Step: 73099, Reward: [-478.189 -478.189 -478.189] [0.0000], Avg: [-486.736 -486.736 -486.736] (1.000)
Step: 73149, Reward: [-460.514 -460.514 -460.514] [0.0000], Avg: [-486.718 -486.718 -486.718] (1.000)
Step: 73199, Reward: [-430.809 -430.809 -430.809] [0.0000], Avg: [-486.68 -486.68 -486.68] (1.000)
Step: 73249, Reward: [-444.618 -444.618 -444.618] [0.0000], Avg: [-486.651 -486.651 -486.651] (1.000)
Step: 73299, Reward: [-394.934 -394.934 -394.934] [0.0000], Avg: [-486.589 -486.589 -486.589] (1.000)
Step: 73349, Reward: [-314.713 -314.713 -314.713] [0.0000], Avg: [-486.471 -486.471 -486.471] (1.000)
Step: 73399, Reward: [-354.56 -354.56 -354.56] [0.0000], Avg: [-486.382 -486.382 -486.382] (1.000)
Step: 73449, Reward: [-446.586 -446.586 -446.586] [0.0000], Avg: [-486.354 -486.354 -486.354] (1.000)
Step: 73499, Reward: [-315.437 -315.437 -315.437] [0.0000], Avg: [-486.238 -486.238 -486.238] (1.000)
Step: 73549, Reward: [-424.232 -424.232 -424.232] [0.0000], Avg: [-486.196 -486.196 -486.196] (1.000)
Step: 73599, Reward: [-277.73 -277.73 -277.73] [0.0000], Avg: [-486.054 -486.054 -486.054] (1.000)
Step: 73649, Reward: [-413.134 -413.134 -413.134] [0.0000], Avg: [-486.005 -486.005 -486.005] (1.000)
Step: 73699, Reward: [-374.75 -374.75 -374.75] [0.0000], Avg: [-485.929 -485.929 -485.929] (1.000)
Step: 73749, Reward: [-297.343 -297.343 -297.343] [0.0000], Avg: [-485.802 -485.802 -485.802] (1.000)
Step: 73799, Reward: [-260.965 -260.965 -260.965] [0.0000], Avg: [-485.649 -485.649 -485.649] (1.000)
Step: 73849, Reward: [-353.737 -353.737 -353.737] [0.0000], Avg: [-485.56 -485.56 -485.56] (1.000)
Step: 73899, Reward: [-308.125 -308.125 -308.125] [0.0000], Avg: [-485.44 -485.44 -485.44] (1.000)
Step: 73949, Reward: [-319.614 -319.614 -319.614] [0.0000], Avg: [-485.328 -485.328 -485.328] (1.000)
Step: 73999, Reward: [-429.745 -429.745 -429.745] [0.0000], Avg: [-485.29 -485.29 -485.29] (1.000)
Step: 74049, Reward: [-300.112 -300.112 -300.112] [0.0000], Avg: [-485.165 -485.165 -485.165] (1.000)
Step: 74099, Reward: [-414.097 -414.097 -414.097] [0.0000], Avg: [-485.117 -485.117 -485.117] (1.000)
Step: 74149, Reward: [-311.96 -311.96 -311.96] [0.0000], Avg: [-485. -485. -485.] (1.000)
Step: 74199, Reward: [-405.028 -405.028 -405.028] [0.0000], Avg: [-484.947 -484.947 -484.947] (1.000)
Step: 74249, Reward: [-419.584 -419.584 -419.584] [0.0000], Avg: [-484.903 -484.903 -484.903] (1.000)
Step: 74299, Reward: [-264.795 -264.795 -264.795] [0.0000], Avg: [-484.754 -484.754 -484.754] (1.000)
Step: 74349, Reward: [-452.527 -452.527 -452.527] [0.0000], Avg: [-484.733 -484.733 -484.733] (1.000)
Step: 74399, Reward: [-305.706 -305.706 -305.706] [0.0000], Avg: [-484.612 -484.612 -484.612] (1.000)
Step: 74449, Reward: [-288.874 -288.874 -288.874] [0.0000], Avg: [-484.481 -484.481 -484.481] (1.000)
Step: 74499, Reward: [-310.661 -310.661 -310.661] [0.0000], Avg: [-484.364 -484.364 -484.364] (1.000)
Step: 74549, Reward: [-321.781 -321.781 -321.781] [0.0000], Avg: [-484.255 -484.255 -484.255] (1.000)
Step: 74599, Reward: [-314.865 -314.865 -314.865] [0.0000], Avg: [-484.142 -484.142 -484.142] (1.000)
Step: 74649, Reward: [-305.016 -305.016 -305.016] [0.0000], Avg: [-484.022 -484.022 -484.022] (1.000)
Step: 74699, Reward: [-318.899 -318.899 -318.899] [0.0000], Avg: [-483.911 -483.911 -483.911] (1.000)
Step: 74749, Reward: [-391.954 -391.954 -391.954] [0.0000], Avg: [-483.85 -483.85 -483.85] (1.000)
Step: 74799, Reward: [-298.713 -298.713 -298.713] [0.0000], Avg: [-483.726 -483.726 -483.726] (1.000)
Step: 74849, Reward: [-272.66 -272.66 -272.66] [0.0000], Avg: [-483.585 -483.585 -483.585] (1.000)
Step: 74899, Reward: [-369.163 -369.163 -369.163] [0.0000], Avg: [-483.509 -483.509 -483.509] (1.000)
Step: 74949, Reward: [-298.507 -298.507 -298.507] [0.0000], Avg: [-483.385 -483.385 -483.385] (1.000)
Step: 74999, Reward: [-350.518 -350.518 -350.518] [0.0000], Avg: [-483.297 -483.297 -483.297] (1.000)
Step: 75049, Reward: [-275.775 -275.775 -275.775] [0.0000], Avg: [-483.158 -483.158 -483.158] (1.000)
Step: 75099, Reward: [-267.411 -267.411 -267.411] [0.0000], Avg: [-483.015 -483.015 -483.015] (1.000)
Step: 75149, Reward: [-435.57 -435.57 -435.57] [0.0000], Avg: [-482.983 -482.983 -482.983] (1.000)
Step: 75199, Reward: [-364.487 -364.487 -364.487] [0.0000], Avg: [-482.904 -482.904 -482.904] (1.000)
Step: 75249, Reward: [-416.572 -416.572 -416.572] [0.0000], Avg: [-482.86 -482.86 -482.86] (1.000)
Step: 75299, Reward: [-262.876 -262.876 -262.876] [0.0000], Avg: [-482.714 -482.714 -482.714] (1.000)
Step: 75349, Reward: [-345.13 -345.13 -345.13] [0.0000], Avg: [-482.623 -482.623 -482.623] (1.000)
Step: 75399, Reward: [-326.203 -326.203 -326.203] [0.0000], Avg: [-482.519 -482.519 -482.519] (1.000)
Step: 75449, Reward: [-398.434 -398.434 -398.434] [0.0000], Avg: [-482.463 -482.463 -482.463] (1.000)
Step: 75499, Reward: [-449.676 -449.676 -449.676] [0.0000], Avg: [-482.442 -482.442 -482.442] (1.000)
Step: 75549, Reward: [-408.053 -408.053 -408.053] [0.0000], Avg: [-482.393 -482.393 -482.393] (1.000)
Step: 75599, Reward: [-340.879 -340.879 -340.879] [0.0000], Avg: [-482.299 -482.299 -482.299] (1.000)
Step: 75649, Reward: [-394.858 -394.858 -394.858] [0.0000], Avg: [-482.241 -482.241 -482.241] (1.000)
Step: 75699, Reward: [-371.017 -371.017 -371.017] [0.0000], Avg: [-482.168 -482.168 -482.168] (1.000)
Step: 75749, Reward: [-273.88 -273.88 -273.88] [0.0000], Avg: [-482.03 -482.03 -482.03] (1.000)
Step: 75799, Reward: [-469.01 -469.01 -469.01] [0.0000], Avg: [-482.022 -482.022 -482.022] (1.000)
Step: 75849, Reward: [-328.907 -328.907 -328.907] [0.0000], Avg: [-481.921 -481.921 -481.921] (1.000)
Step: 75899, Reward: [-306.237 -306.237 -306.237] [0.0000], Avg: [-481.805 -481.805 -481.805] (1.000)
Step: 75949, Reward: [-365.907 -365.907 -365.907] [0.0000], Avg: [-481.729 -481.729 -481.729] (1.000)
Step: 75999, Reward: [-305.186 -305.186 -305.186] [0.0000], Avg: [-481.612 -481.612 -481.612] (1.000)
Step: 76049, Reward: [-478.441 -478.441 -478.441] [0.0000], Avg: [-481.61 -481.61 -481.61] (1.000)
Step: 76099, Reward: [-312.99 -312.99 -312.99] [0.0000], Avg: [-481.5 -481.5 -481.5] (1.000)
Step: 76149, Reward: [-460.728 -460.728 -460.728] [0.0000], Avg: [-481.486 -481.486 -481.486] (1.000)
Step: 76199, Reward: [-393.313 -393.313 -393.313] [0.0000], Avg: [-481.428 -481.428 -481.428] (1.000)
Step: 76249, Reward: [-412.328 -412.328 -412.328] [0.0000], Avg: [-481.383 -481.383 -481.383] (1.000)
Step: 76299, Reward: [-466.212 -466.212 -466.212] [0.0000], Avg: [-481.373 -481.373 -481.373] (1.000)
Step: 76349, Reward: [-323.785 -323.785 -323.785] [0.0000], Avg: [-481.27 -481.27 -481.27] (1.000)
Step: 76399, Reward: [-409.272 -409.272 -409.272] [0.0000], Avg: [-481.223 -481.223 -481.223] (1.000)
Step: 76449, Reward: [-331.129 -331.129 -331.129] [0.0000], Avg: [-481.124 -481.124 -481.124] (1.000)
Step: 76499, Reward: [-270.496 -270.496 -270.496] [0.0000], Avg: [-480.987 -480.987 -480.987] (1.000)
Step: 76549, Reward: [-413.523 -413.523 -413.523] [0.0000], Avg: [-480.943 -480.943 -480.943] (1.000)
Step: 76599, Reward: [-320.691 -320.691 -320.691] [0.0000], Avg: [-480.838 -480.838 -480.838] (1.000)
Step: 76649, Reward: [-362.16 -362.16 -362.16] [0.0000], Avg: [-480.761 -480.761 -480.761] (1.000)
Step: 76699, Reward: [-412.264 -412.264 -412.264] [0.0000], Avg: [-480.716 -480.716 -480.716] (1.000)
Step: 76749, Reward: [-422.496 -422.496 -422.496] [0.0000], Avg: [-480.678 -480.678 -480.678] (1.000)
Step: 76799, Reward: [-358.654 -358.654 -358.654] [0.0000], Avg: [-480.599 -480.599 -480.599] (1.000)
Step: 76849, Reward: [-328.008 -328.008 -328.008] [0.0000], Avg: [-480.499 -480.499 -480.499] (1.000)
Step: 76899, Reward: [-434.577 -434.577 -434.577] [0.0000], Avg: [-480.469 -480.469 -480.469] (1.000)
Step: 76949, Reward: [-331.231 -331.231 -331.231] [0.0000], Avg: [-480.373 -480.373 -480.373] (1.000)
Step: 76999, Reward: [-400.576 -400.576 -400.576] [0.0000], Avg: [-480.321 -480.321 -480.321] (1.000)
Step: 77049, Reward: [-298.641 -298.641 -298.641] [0.0000], Avg: [-480.203 -480.203 -480.203] (1.000)
Step: 77099, Reward: [-482.15 -482.15 -482.15] [0.0000], Avg: [-480.204 -480.204 -480.204] (1.000)
Step: 77149, Reward: [-352.681 -352.681 -352.681] [0.0000], Avg: [-480.121 -480.121 -480.121] (1.000)
Step: 77199, Reward: [-397.065 -397.065 -397.065] [0.0000], Avg: [-480.068 -480.068 -480.068] (1.000)
Step: 77249, Reward: [-304.649 -304.649 -304.649] [0.0000], Avg: [-479.954 -479.954 -479.954] (1.000)
Step: 77299, Reward: [-345.79 -345.79 -345.79] [0.0000], Avg: [-479.867 -479.867 -479.867] (1.000)
Step: 77349, Reward: [-378.138 -378.138 -378.138] [0.0000], Avg: [-479.802 -479.802 -479.802] (1.000)
Step: 77399, Reward: [-328.51 -328.51 -328.51] [0.0000], Avg: [-479.704 -479.704 -479.704] (1.000)
Step: 77449, Reward: [-334.391 -334.391 -334.391] [0.0000], Avg: [-479.61 -479.61 -479.61] (1.000)
Step: 77499, Reward: [-373.823 -373.823 -373.823] [0.0000], Avg: [-479.542 -479.542 -479.542] (1.000)
Step: 77549, Reward: [-449.781 -449.781 -449.781] [0.0000], Avg: [-479.523 -479.523 -479.523] (1.000)
Step: 77599, Reward: [-358.489 -358.489 -358.489] [0.0000], Avg: [-479.445 -479.445 -479.445] (1.000)
Step: 77649, Reward: [-286.655 -286.655 -286.655] [0.0000], Avg: [-479.32 -479.32 -479.32] (1.000)
Step: 77699, Reward: [-393.688 -393.688 -393.688] [0.0000], Avg: [-479.265 -479.265 -479.265] (1.000)
Step: 77749, Reward: [-397.959 -397.959 -397.959] [0.0000], Avg: [-479.213 -479.213 -479.213] (1.000)
Step: 77799, Reward: [-359.039 -359.039 -359.039] [0.0000], Avg: [-479.136 -479.136 -479.136] (1.000)
Step: 77849, Reward: [-437.308 -437.308 -437.308] [0.0000], Avg: [-479.109 -479.109 -479.109] (1.000)
Step: 77899, Reward: [-372.847 -372.847 -372.847] [0.0000], Avg: [-479.041 -479.041 -479.041] (1.000)
Step: 77949, Reward: [-341.579 -341.579 -341.579] [0.0000], Avg: [-478.953 -478.953 -478.953] (1.000)
Step: 77999, Reward: [-395.268 -395.268 -395.268] [0.0000], Avg: [-478.899 -478.899 -478.899] (1.000)
Step: 78049, Reward: [-332.454 -332.454 -332.454] [0.0000], Avg: [-478.805 -478.805 -478.805] (1.000)
Step: 78099, Reward: [-316.565 -316.565 -316.565] [0.0000], Avg: [-478.701 -478.701 -478.701] (1.000)
Step: 78149, Reward: [-251.92 -251.92 -251.92] [0.0000], Avg: [-478.556 -478.556 -478.556] (1.000)
Step: 78199, Reward: [-294.384 -294.384 -294.384] [0.0000], Avg: [-478.438 -478.438 -478.438] (1.000)
Step: 78249, Reward: [-342.092 -342.092 -342.092] [0.0000], Avg: [-478.351 -478.351 -478.351] (1.000)
Step: 78299, Reward: [-309.401 -309.401 -309.401] [0.0000], Avg: [-478.243 -478.243 -478.243] (1.000)
Step: 78349, Reward: [-402.955 -402.955 -402.955] [0.0000], Avg: [-478.195 -478.195 -478.195] (1.000)
Step: 78399, Reward: [-390.212 -390.212 -390.212] [0.0000], Avg: [-478.139 -478.139 -478.139] (1.000)
Step: 78449, Reward: [-379.615 -379.615 -379.615] [0.0000], Avg: [-478.076 -478.076 -478.076] (1.000)
Step: 78499, Reward: [-384.862 -384.862 -384.862] [0.0000], Avg: [-478.017 -478.017 -478.017] (1.000)
Step: 78549, Reward: [-320.126 -320.126 -320.126] [0.0000], Avg: [-477.917 -477.917 -477.917] (1.000)
Step: 78599, Reward: [-306.724 -306.724 -306.724] [0.0000], Avg: [-477.808 -477.808 -477.808] (1.000)
Step: 78649, Reward: [-338.722 -338.722 -338.722] [0.0000], Avg: [-477.719 -477.719 -477.719] (1.000)
Step: 78699, Reward: [-327.678 -327.678 -327.678] [0.0000], Avg: [-477.624 -477.624 -477.624] (1.000)
Step: 78749, Reward: [-484.044 -484.044 -484.044] [0.0000], Avg: [-477.628 -477.628 -477.628] (1.000)
Step: 78799, Reward: [-368.753 -368.753 -368.753] [0.0000], Avg: [-477.559 -477.559 -477.559] (1.000)
Step: 78849, Reward: [-378.368 -378.368 -378.368] [0.0000], Avg: [-477.496 -477.496 -477.496] (1.000)
Step: 78899, Reward: [-294.736 -294.736 -294.736] [0.0000], Avg: [-477.38 -477.38 -477.38] (1.000)
Step: 78949, Reward: [-352.495 -352.495 -352.495] [0.0000], Avg: [-477.301 -477.301 -477.301] (1.000)
Step: 78999, Reward: [-471.261 -471.261 -471.261] [0.0000], Avg: [-477.297 -477.297 -477.297] (1.000)
Step: 79049, Reward: [-329.165 -329.165 -329.165] [0.0000], Avg: [-477.204 -477.204 -477.204] (1.000)
Step: 79099, Reward: [-332.89 -332.89 -332.89] [0.0000], Avg: [-477.112 -477.112 -477.112] (1.000)
Step: 79149, Reward: [-315.351 -315.351 -315.351] [0.0000], Avg: [-477.01 -477.01 -477.01] (1.000)
Step: 79199, Reward: [-438.658 -438.658 -438.658] [0.0000], Avg: [-476.986 -476.986 -476.986] (1.000)
Step: 79249, Reward: [-358.135 -358.135 -358.135] [0.0000], Avg: [-476.911 -476.911 -476.911] (1.000)
Step: 79299, Reward: [-407.233 -407.233 -407.233] [0.0000], Avg: [-476.867 -476.867 -476.867] (1.000)
Step: 79349, Reward: [-381.985 -381.985 -381.985] [0.0000], Avg: [-476.807 -476.807 -476.807] (1.000)
Step: 79399, Reward: [-359.713 -359.713 -359.713] [0.0000], Avg: [-476.734 -476.734 -476.734] (1.000)
Step: 79449, Reward: [-369.531 -369.531 -369.531] [0.0000], Avg: [-476.666 -476.666 -476.666] (1.000)
Step: 79499, Reward: [-351.369 -351.369 -351.369] [0.0000], Avg: [-476.587 -476.587 -476.587] (1.000)
Step: 79549, Reward: [-387.865 -387.865 -387.865] [0.0000], Avg: [-476.531 -476.531 -476.531] (1.000)
Step: 79599, Reward: [-301.34 -301.34 -301.34] [0.0000], Avg: [-476.421 -476.421 -476.421] (1.000)
Step: 79649, Reward: [-407.493 -407.493 -407.493] [0.0000], Avg: [-476.378 -476.378 -476.378] (1.000)
Step: 79699, Reward: [-323.934 -323.934 -323.934] [0.0000], Avg: [-476.283 -476.283 -476.283] (1.000)
Step: 79749, Reward: [-355.355 -355.355 -355.355] [0.0000], Avg: [-476.207 -476.207 -476.207] (1.000)
Step: 79799, Reward: [-270.177 -270.177 -270.177] [0.0000], Avg: [-476.078 -476.078 -476.078] (1.000)
Step: 79849, Reward: [-411.073 -411.073 -411.073] [0.0000], Avg: [-476.037 -476.037 -476.037] (1.000)
Step: 79899, Reward: [-422.751 -422.751 -422.751] [0.0000], Avg: [-476.004 -476.004 -476.004] (1.000)
Step: 79949, Reward: [-411.063 -411.063 -411.063] [0.0000], Avg: [-475.963 -475.963 -475.963] (1.000)
Step: 79999, Reward: [-335.633 -335.633 -335.633] [0.0000], Avg: [-475.875 -475.875 -475.875] (1.000)
Step: 80049, Reward: [-462.017 -462.017 -462.017] [0.0000], Avg: [-475.867 -475.867 -475.867] (1.000)
Step: 80099, Reward: [-372.209 -372.209 -372.209] [0.0000], Avg: [-475.802 -475.802 -475.802] (1.000)
Step: 80149, Reward: [-272.606 -272.606 -272.606] [0.0000], Avg: [-475.675 -475.675 -475.675] (1.000)
Step: 80199, Reward: [-380.638 -380.638 -380.638] [0.0000], Avg: [-475.616 -475.616 -475.616] (1.000)
Step: 80249, Reward: [-434.291 -434.291 -434.291] [0.0000], Avg: [-475.59 -475.59 -475.59] (1.000)
Step: 80299, Reward: [-332.678 -332.678 -332.678] [0.0000], Avg: [-475.501 -475.501 -475.501] (1.000)
Step: 80349, Reward: [-361.86 -361.86 -361.86] [0.0000], Avg: [-475.43 -475.43 -475.43] (1.000)
Step: 80399, Reward: [-310.922 -310.922 -310.922] [0.0000], Avg: [-475.328 -475.328 -475.328] (1.000)
Step: 80449, Reward: [-340.183 -340.183 -340.183] [0.0000], Avg: [-475.244 -475.244 -475.244] (1.000)
Step: 80499, Reward: [-367.167 -367.167 -367.167] [0.0000], Avg: [-475.177 -475.177 -475.177] (1.000)
Step: 80549, Reward: [-428.247 -428.247 -428.247] [0.0000], Avg: [-475.148 -475.148 -475.148] (1.000)
Step: 80599, Reward: [-450.666 -450.666 -450.666] [0.0000], Avg: [-475.133 -475.133 -475.133] (1.000)
Step: 80649, Reward: [-311.125 -311.125 -311.125] [0.0000], Avg: [-475.031 -475.031 -475.031] (1.000)
Step: 80699, Reward: [-435.773 -435.773 -435.773] [0.0000], Avg: [-475.007 -475.007 -475.007] (1.000)
Step: 80749, Reward: [-332.626 -332.626 -332.626] [0.0000], Avg: [-474.919 -474.919 -474.919] (1.000)
Step: 80799, Reward: [-391.632 -391.632 -391.632] [0.0000], Avg: [-474.867 -474.867 -474.867] (1.000)
Step: 80849, Reward: [-322.625 -322.625 -322.625] [0.0000], Avg: [-474.773 -474.773 -474.773] (1.000)
Step: 80899, Reward: [-318.727 -318.727 -318.727] [0.0000], Avg: [-474.676 -474.676 -474.676] (1.000)
Step: 80949, Reward: [-514.605 -514.605 -514.605] [0.0000], Avg: [-474.701 -474.701 -474.701] (1.000)
Step: 80999, Reward: [-410.559 -410.559 -410.559] [0.0000], Avg: [-474.661 -474.661 -474.661] (1.000)
Step: 81049, Reward: [-319.097 -319.097 -319.097] [0.0000], Avg: [-474.565 -474.565 -474.565] (1.000)
Step: 81099, Reward: [-293.328 -293.328 -293.328] [0.0000], Avg: [-474.454 -474.454 -474.454] (1.000)
Step: 81149, Reward: [-383.194 -383.194 -383.194] [0.0000], Avg: [-474.398 -474.398 -474.398] (1.000)
Step: 81199, Reward: [-256.782 -256.782 -256.782] [0.0000], Avg: [-474.264 -474.264 -474.264] (1.000)
Step: 81249, Reward: [-551.42 -551.42 -551.42] [0.0000], Avg: [-474.311 -474.311 -474.311] (1.000)
Step: 81299, Reward: [-413.902 -413.902 -413.902] [0.0000], Avg: [-474.274 -474.274 -474.274] (1.000)
Step: 81349, Reward: [-363.802 -363.802 -363.802] [0.0000], Avg: [-474.206 -474.206 -474.206] (1.000)
Step: 81399, Reward: [-431.602 -431.602 -431.602] [0.0000], Avg: [-474.18 -474.18 -474.18] (1.000)
Step: 81449, Reward: [-296.321 -296.321 -296.321] [0.0000], Avg: [-474.071 -474.071 -474.071] (1.000)
Step: 81499, Reward: [-361.448 -361.448 -361.448] [0.0000], Avg: [-474.001 -474.001 -474.001] (1.000)
Step: 81549, Reward: [-386.866 -386.866 -386.866] [0.0000], Avg: [-473.948 -473.948 -473.948] (1.000)
Step: 81599, Reward: [-457.259 -457.259 -457.259] [0.0000], Avg: [-473.938 -473.938 -473.938] (1.000)
Step: 81649, Reward: [-369.054 -369.054 -369.054] [0.0000], Avg: [-473.874 -473.874 -473.874] (1.000)
Step: 81699, Reward: [-333.251 -333.251 -333.251] [0.0000], Avg: [-473.788 -473.788 -473.788] (1.000)
Step: 81749, Reward: [-431.008 -431.008 -431.008] [0.0000], Avg: [-473.761 -473.761 -473.761] (1.000)
Step: 81799, Reward: [-329.087 -329.087 -329.087] [0.0000], Avg: [-473.673 -473.673 -473.673] (1.000)
Step: 81849, Reward: [-391.616 -391.616 -391.616] [0.0000], Avg: [-473.623 -473.623 -473.623] (1.000)
Step: 81899, Reward: [-303.813 -303.813 -303.813] [0.0000], Avg: [-473.519 -473.519 -473.519] (1.000)
Step: 81949, Reward: [-333.7 -333.7 -333.7] [0.0000], Avg: [-473.434 -473.434 -473.434] (1.000)
Step: 81999, Reward: [-303.269 -303.269 -303.269] [0.0000], Avg: [-473.33 -473.33 -473.33] (1.000)
Step: 82049, Reward: [-343.96 -343.96 -343.96] [0.0000], Avg: [-473.251 -473.251 -473.251] (1.000)
Step: 82099, Reward: [-365.87 -365.87 -365.87] [0.0000], Avg: [-473.186 -473.186 -473.186] (1.000)
Step: 82149, Reward: [-428.069 -428.069 -428.069] [0.0000], Avg: [-473.158 -473.158 -473.158] (1.000)
Step: 82199, Reward: [-416.293 -416.293 -416.293] [0.0000], Avg: [-473.124 -473.124 -473.124] (1.000)
Step: 82249, Reward: [-376.7 -376.7 -376.7] [0.0000], Avg: [-473.065 -473.065 -473.065] (1.000)
Step: 82299, Reward: [-402.724 -402.724 -402.724] [0.0000], Avg: [-473.022 -473.022 -473.022] (1.000)
Step: 82349, Reward: [-293.163 -293.163 -293.163] [0.0000], Avg: [-472.913 -472.913 -472.913] (1.000)
Step: 82399, Reward: [-360.68 -360.68 -360.68] [0.0000], Avg: [-472.845 -472.845 -472.845] (1.000)
Step: 82449, Reward: [-310.923 -310.923 -310.923] [0.0000], Avg: [-472.747 -472.747 -472.747] (1.000)
Step: 82499, Reward: [-370.584 -370.584 -370.584] [0.0000], Avg: [-472.685 -472.685 -472.685] (1.000)
Step: 82549, Reward: [-391.327 -391.327 -391.327] [0.0000], Avg: [-472.636 -472.636 -472.636] (1.000)
Step: 82599, Reward: [-273.374 -273.374 -273.374] [0.0000], Avg: [-472.515 -472.515 -472.515] (1.000)
Step: 82649, Reward: [-397.812 -397.812 -397.812] [0.0000], Avg: [-472.47 -472.47 -472.47] (1.000)
Step: 82699, Reward: [-372.667 -372.667 -372.667] [0.0000], Avg: [-472.41 -472.41 -472.41] (1.000)
Step: 82749, Reward: [-444.148 -444.148 -444.148] [0.0000], Avg: [-472.393 -472.393 -472.393] (1.000)
Step: 82799, Reward: [-382.89 -382.89 -382.89] [0.0000], Avg: [-472.338 -472.338 -472.338] (1.000)
Step: 82849, Reward: [-334.849 -334.849 -334.849] [0.0000], Avg: [-472.256 -472.256 -472.256] (1.000)
Step: 82899, Reward: [-298.558 -298.558 -298.558] [0.0000], Avg: [-472.151 -472.151 -472.151] (1.000)
Step: 82949, Reward: [-376.266 -376.266 -376.266] [0.0000], Avg: [-472.093 -472.093 -472.093] (1.000)
Step: 82999, Reward: [-313.205 -313.205 -313.205] [0.0000], Avg: [-471.997 -471.997 -471.997] (1.000)
Step: 83049, Reward: [-313.016 -313.016 -313.016] [0.0000], Avg: [-471.902 -471.902 -471.902] (1.000)
Step: 83099, Reward: [-395.337 -395.337 -395.337] [0.0000], Avg: [-471.855 -471.855 -471.855] (1.000)
Step: 83149, Reward: [-393.207 -393.207 -393.207] [0.0000], Avg: [-471.808 -471.808 -471.808] (1.000)
Step: 83199, Reward: [-452.493 -452.493 -452.493] [0.0000], Avg: [-471.797 -471.797 -471.797] (1.000)
Step: 83249, Reward: [-339.76 -339.76 -339.76] [0.0000], Avg: [-471.717 -471.717 -471.717] (1.000)
Step: 83299, Reward: [-453.559 -453.559 -453.559] [0.0000], Avg: [-471.706 -471.706 -471.706] (1.000)
Step: 83349, Reward: [-345.73 -345.73 -345.73] [0.0000], Avg: [-471.631 -471.631 -471.631] (1.000)
Step: 83399, Reward: [-407.881 -407.881 -407.881] [0.0000], Avg: [-471.593 -471.593 -471.593] (1.000)
Step: 83449, Reward: [-294.204 -294.204 -294.204] [0.0000], Avg: [-471.486 -471.486 -471.486] (1.000)
Step: 83499, Reward: [-330.23 -330.23 -330.23] [0.0000], Avg: [-471.402 -471.402 -471.402] (1.000)
Step: 83549, Reward: [-367.896 -367.896 -367.896] [0.0000], Avg: [-471.34 -471.34 -471.34] (1.000)
Step: 83599, Reward: [-492.322 -492.322 -492.322] [0.0000], Avg: [-471.352 -471.352 -471.352] (1.000)
Step: 83649, Reward: [-271.227 -271.227 -271.227] [0.0000], Avg: [-471.233 -471.233 -471.233] (1.000)
Step: 83699, Reward: [-470.641 -470.641 -470.641] [0.0000], Avg: [-471.232 -471.232 -471.232] (1.000)
Step: 83749, Reward: [-317.617 -317.617 -317.617] [0.0000], Avg: [-471.141 -471.141 -471.141] (1.000)
Step: 83799, Reward: [-285.378 -285.378 -285.378] [0.0000], Avg: [-471.03 -471.03 -471.03] (1.000)
Step: 83849, Reward: [-239.142 -239.142 -239.142] [0.0000], Avg: [-470.892 -470.892 -470.892] (1.000)
Step: 83899, Reward: [-300.25 -300.25 -300.25] [0.0000], Avg: [-470.79 -470.79 -470.79] (1.000)
Step: 83949, Reward: [-316.615 -316.615 -316.615] [0.0000], Avg: [-470.698 -470.698 -470.698] (1.000)
Step: 83999, Reward: [-415.427 -415.427 -415.427] [0.0000], Avg: [-470.665 -470.665 -470.665] (1.000)
Step: 84049, Reward: [-382.752 -382.752 -382.752] [0.0000], Avg: [-470.613 -470.613 -470.613] (1.000)
Step: 84099, Reward: [-295.569 -295.569 -295.569] [0.0000], Avg: [-470.509 -470.509 -470.509] (1.000)
Step: 84149, Reward: [-365.447 -365.447 -365.447] [0.0000], Avg: [-470.446 -470.446 -470.446] (1.000)
Step: 84199, Reward: [-419.91 -419.91 -419.91] [0.0000], Avg: [-470.416 -470.416 -470.416] (1.000)
Step: 84249, Reward: [-479.562 -479.562 -479.562] [0.0000], Avg: [-470.422 -470.422 -470.422] (1.000)
Step: 84299, Reward: [-309.842 -309.842 -309.842] [0.0000], Avg: [-470.326 -470.326 -470.326] (1.000)
Step: 84349, Reward: [-335.027 -335.027 -335.027] [0.0000], Avg: [-470.246 -470.246 -470.246] (1.000)
Step: 84399, Reward: [-317.536 -317.536 -317.536] [0.0000], Avg: [-470.156 -470.156 -470.156] (1.000)
Step: 84449, Reward: [-360.135 -360.135 -360.135] [0.0000], Avg: [-470.091 -470.091 -470.091] (1.000)
Step: 84499, Reward: [-329.121 -329.121 -329.121] [0.0000], Avg: [-470.007 -470.007 -470.007] (1.000)
Step: 84549, Reward: [-290.859 -290.859 -290.859] [0.0000], Avg: [-469.901 -469.901 -469.901] (1.000)
Step: 84599, Reward: [-300.46 -300.46 -300.46] [0.0000], Avg: [-469.801 -469.801 -469.801] (1.000)
Step: 84649, Reward: [-331.757 -331.757 -331.757] [0.0000], Avg: [-469.72 -469.72 -469.72] (1.000)
Step: 84699, Reward: [-397.073 -397.073 -397.073] [0.0000], Avg: [-469.677 -469.677 -469.677] (1.000)
Step: 84749, Reward: [-350.198 -350.198 -350.198] [0.0000], Avg: [-469.606 -469.606 -469.606] (1.000)
Step: 84799, Reward: [-477.993 -477.993 -477.993] [0.0000], Avg: [-469.611 -469.611 -469.611] (1.000)
Step: 84849, Reward: [-331.978 -331.978 -331.978] [0.0000], Avg: [-469.53 -469.53 -469.53] (1.000)
Step: 84899, Reward: [-335.848 -335.848 -335.848] [0.0000], Avg: [-469.451 -469.451 -469.451] (1.000)
Step: 84949, Reward: [-408.451 -408.451 -408.451] [0.0000], Avg: [-469.415 -469.415 -469.415] (1.000)
Step: 84999, Reward: [-404.973 -404.973 -404.973] [0.0000], Avg: [-469.378 -469.378 -469.378] (1.000)
Step: 85049, Reward: [-418.111 -418.111 -418.111] [0.0000], Avg: [-469.347 -469.347 -469.347] (1.000)
Step: 85099, Reward: [-354.497 -354.497 -354.497] [0.0000], Avg: [-469.28 -469.28 -469.28] (1.000)
Step: 85149, Reward: [-451.95 -451.95 -451.95] [0.0000], Avg: [-469.27 -469.27 -469.27] (1.000)
Step: 85199, Reward: [-297.033 -297.033 -297.033] [0.0000], Avg: [-469.169 -469.169 -469.169] (1.000)
Step: 85249, Reward: [-371.726 -371.726 -371.726] [0.0000], Avg: [-469.112 -469.112 -469.112] (1.000)
Step: 85299, Reward: [-350.986 -350.986 -350.986] [0.0000], Avg: [-469.042 -469.042 -469.042] (1.000)
Step: 85349, Reward: [-416.599 -416.599 -416.599] [0.0000], Avg: [-469.012 -469.012 -469.012] (1.000)
Step: 85399, Reward: [-378.889 -378.889 -378.889] [0.0000], Avg: [-468.959 -468.959 -468.959] (1.000)
Step: 85449, Reward: [-457.72 -457.72 -457.72] [0.0000], Avg: [-468.952 -468.952 -468.952] (1.000)
Step: 85499, Reward: [-336.84 -336.84 -336.84] [0.0000], Avg: [-468.875 -468.875 -468.875] (1.000)
Step: 85549, Reward: [-359.024 -359.024 -359.024] [0.0000], Avg: [-468.811 -468.811 -468.811] (1.000)
Step: 85599, Reward: [-378.18 -378.18 -378.18] [0.0000], Avg: [-468.758 -468.758 -468.758] (1.000)
Step: 85649, Reward: [-383.928 -383.928 -383.928] [0.0000], Avg: [-468.708 -468.708 -468.708] (1.000)
Step: 85699, Reward: [-330.238 -330.238 -330.238] [0.0000], Avg: [-468.628 -468.628 -468.628] (1.000)
Step: 85749, Reward: [-367.853 -367.853 -367.853] [0.0000], Avg: [-468.569 -468.569 -468.569] (1.000)
Step: 85799, Reward: [-318.321 -318.321 -318.321] [0.0000], Avg: [-468.481 -468.481 -468.481] (1.000)
Step: 85849, Reward: [-320.082 -320.082 -320.082] [0.0000], Avg: [-468.395 -468.395 -468.395] (1.000)
Step: 85899, Reward: [-312.829 -312.829 -312.829] [0.0000], Avg: [-468.304 -468.304 -468.304] (1.000)
Step: 85949, Reward: [-361.072 -361.072 -361.072] [0.0000], Avg: [-468.242 -468.242 -468.242] (1.000)
Step: 85999, Reward: [-259.867 -259.867 -259.867] [0.0000], Avg: [-468.121 -468.121 -468.121] (1.000)
Step: 86049, Reward: [-482.115 -482.115 -482.115] [0.0000], Avg: [-468.129 -468.129 -468.129] (1.000)
Step: 86099, Reward: [-404.007 -404.007 -404.007] [0.0000], Avg: [-468.092 -468.092 -468.092] (1.000)
Step: 86149, Reward: [-337.291 -337.291 -337.291] [0.0000], Avg: [-468.016 -468.016 -468.016] (1.000)
Step: 86199, Reward: [-427.884 -427.884 -427.884] [0.0000], Avg: [-467.992 -467.992 -467.992] (1.000)
Step: 86249, Reward: [-437.462 -437.462 -437.462] [0.0000], Avg: [-467.975 -467.975 -467.975] (1.000)
Step: 86299, Reward: [-461.789 -461.789 -461.789] [0.0000], Avg: [-467.971 -467.971 -467.971] (1.000)
Step: 86349, Reward: [-320.701 -320.701 -320.701] [0.0000], Avg: [-467.886 -467.886 -467.886] (1.000)
Step: 86399, Reward: [-241.656 -241.656 -241.656] [0.0000], Avg: [-467.755 -467.755 -467.755] (1.000)
Step: 86449, Reward: [-395.071 -395.071 -395.071] [0.0000], Avg: [-467.713 -467.713 -467.713] (1.000)
Step: 86499, Reward: [-287.946 -287.946 -287.946] [0.0000], Avg: [-467.609 -467.609 -467.609] (1.000)
Step: 86549, Reward: [-332.267 -332.267 -332.267] [0.0000], Avg: [-467.531 -467.531 -467.531] (1.000)
Step: 86599, Reward: [-322.925 -322.925 -322.925] [0.0000], Avg: [-467.447 -467.447 -467.447] (1.000)
Step: 86649, Reward: [-418.059 -418.059 -418.059] [0.0000], Avg: [-467.419 -467.419 -467.419] (1.000)
Step: 86699, Reward: [-310.598 -310.598 -310.598] [0.0000], Avg: [-467.328 -467.328 -467.328] (1.000)
Step: 86749, Reward: [-330.451 -330.451 -330.451] [0.0000], Avg: [-467.249 -467.249 -467.249] (1.000)
Step: 86799, Reward: [-311.153 -311.153 -311.153] [0.0000], Avg: [-467.16 -467.16 -467.16] (1.000)
Step: 86849, Reward: [-316.245 -316.245 -316.245] [0.0000], Avg: [-467.073 -467.073 -467.073] (1.000)
Step: 86899, Reward: [-362.47 -362.47 -362.47] [0.0000], Avg: [-467.012 -467.012 -467.012] (1.000)
Step: 86949, Reward: [-315.528 -315.528 -315.528] [0.0000], Avg: [-466.925 -466.925 -466.925] (1.000)
Step: 86999, Reward: [-443.999 -443.999 -443.999] [0.0000], Avg: [-466.912 -466.912 -466.912] (1.000)
Step: 87049, Reward: [-410.957 -410.957 -410.957] [0.0000], Avg: [-466.88 -466.88 -466.88] (1.000)
Step: 87099, Reward: [-324.038 -324.038 -324.038] [0.0000], Avg: [-466.798 -466.798 -466.798] (1.000)
Step: 87149, Reward: [-272.573 -272.573 -272.573] [0.0000], Avg: [-466.687 -466.687 -466.687] (1.000)
Step: 87199, Reward: [-463.453 -463.453 -463.453] [0.0000], Avg: [-466.685 -466.685 -466.685] (1.000)
Step: 87249, Reward: [-375.793 -375.793 -375.793] [0.0000], Avg: [-466.633 -466.633 -466.633] (1.000)
Step: 87299, Reward: [-408.936 -408.936 -408.936] [0.0000], Avg: [-466.6 -466.6 -466.6] (1.000)
Step: 87349, Reward: [-399.368 -399.368 -399.368] [0.0000], Avg: [-466.561 -466.561 -466.561] (1.000)
Step: 87399, Reward: [-361.078 -361.078 -361.078] [0.0000], Avg: [-466.501 -466.501 -466.501] (1.000)
Step: 87449, Reward: [-496.582 -496.582 -496.582] [0.0000], Avg: [-466.518 -466.518 -466.518] (1.000)
Step: 87499, Reward: [-408.284 -408.284 -408.284] [0.0000], Avg: [-466.485 -466.485 -466.485] (1.000)
Step: 87549, Reward: [-398.435 -398.435 -398.435] [0.0000], Avg: [-466.446 -466.446 -466.446] (1.000)
Step: 87599, Reward: [-419.425 -419.425 -419.425] [0.0000], Avg: [-466.419 -466.419 -466.419] (1.000)
Step: 87649, Reward: [-348.333 -348.333 -348.333] [0.0000], Avg: [-466.352 -466.352 -466.352] (1.000)
Step: 87699, Reward: [-301.466 -301.466 -301.466] [0.0000], Avg: [-466.258 -466.258 -466.258] (1.000)
Step: 87749, Reward: [-332.618 -332.618 -332.618] [0.0000], Avg: [-466.182 -466.182 -466.182] (1.000)
Step: 87799, Reward: [-421.054 -421.054 -421.054] [0.0000], Avg: [-466.156 -466.156 -466.156] (1.000)
Step: 87849, Reward: [-292.238 -292.238 -292.238] [0.0000], Avg: [-466.057 -466.057 -466.057] (1.000)
Step: 87899, Reward: [-324.296 -324.296 -324.296] [0.0000], Avg: [-465.976 -465.976 -465.976] (1.000)
Step: 87949, Reward: [-365.68 -365.68 -365.68] [0.0000], Avg: [-465.919 -465.919 -465.919] (1.000)
Step: 87999, Reward: [-333.114 -333.114 -333.114] [0.0000], Avg: [-465.844 -465.844 -465.844] (1.000)
Step: 88049, Reward: [-346.39 -346.39 -346.39] [0.0000], Avg: [-465.776 -465.776 -465.776] (1.000)
Step: 88099, Reward: [-399.485 -399.485 -399.485] [0.0000], Avg: [-465.738 -465.738 -465.738] (1.000)
Step: 88149, Reward: [-367.235 -367.235 -367.235] [0.0000], Avg: [-465.682 -465.682 -465.682] (1.000)
Step: 88199, Reward: [-306.296 -306.296 -306.296] [0.0000], Avg: [-465.592 -465.592 -465.592] (1.000)
Step: 88249, Reward: [-389.96 -389.96 -389.96] [0.0000], Avg: [-465.549 -465.549 -465.549] (1.000)
Step: 88299, Reward: [-327.779 -327.779 -327.779] [0.0000], Avg: [-465.471 -465.471 -465.471] (1.000)
Step: 88349, Reward: [-421.472 -421.472 -421.472] [0.0000], Avg: [-465.446 -465.446 -465.446] (1.000)
Step: 88399, Reward: [-370.802 -370.802 -370.802] [0.0000], Avg: [-465.393 -465.393 -465.393] (1.000)
Step: 88449, Reward: [-407.054 -407.054 -407.054] [0.0000], Avg: [-465.36 -465.36 -465.36] (1.000)
Step: 88499, Reward: [-382.154 -382.154 -382.154] [0.0000], Avg: [-465.313 -465.313 -465.313] (1.000)
Step: 88549, Reward: [-446.481 -446.481 -446.481] [0.0000], Avg: [-465.302 -465.302 -465.302] (1.000)
Step: 88599, Reward: [-396.359 -396.359 -396.359] [0.0000], Avg: [-465.263 -465.263 -465.263] (1.000)
Step: 88649, Reward: [-387.74 -387.74 -387.74] [0.0000], Avg: [-465.219 -465.219 -465.219] (1.000)
Step: 88699, Reward: [-298.368 -298.368 -298.368] [0.0000], Avg: [-465.125 -465.125 -465.125] (1.000)
Step: 88749, Reward: [-327.359 -327.359 -327.359] [0.0000], Avg: [-465.048 -465.048 -465.048] (1.000)
Step: 88799, Reward: [-332.134 -332.134 -332.134] [0.0000], Avg: [-464.973 -464.973 -464.973] (1.000)
Step: 88849, Reward: [-280.53 -280.53 -280.53] [0.0000], Avg: [-464.869 -464.869 -464.869] (1.000)
Step: 88899, Reward: [-352.117 -352.117 -352.117] [0.0000], Avg: [-464.806 -464.806 -464.806] (1.000)
Step: 88949, Reward: [-374.201 -374.201 -374.201] [0.0000], Avg: [-464.755 -464.755 -464.755] (1.000)
Step: 88999, Reward: [-315.93 -315.93 -315.93] [0.0000], Avg: [-464.671 -464.671 -464.671] (1.000)
Step: 89049, Reward: [-311.03 -311.03 -311.03] [0.0000], Avg: [-464.585 -464.585 -464.585] (1.000)
Step: 89099, Reward: [-262.863 -262.863 -262.863] [0.0000], Avg: [-464.472 -464.472 -464.472] (1.000)
Step: 89149, Reward: [-347.899 -347.899 -347.899] [0.0000], Avg: [-464.406 -464.406 -464.406] (1.000)
Step: 89199, Reward: [-384.838 -384.838 -384.838] [0.0000], Avg: [-464.362 -464.362 -464.362] (1.000)
Step: 89249, Reward: [-267.587 -267.587 -267.587] [0.0000], Avg: [-464.252 -464.252 -464.252] (1.000)
Step: 89299, Reward: [-482.543 -482.543 -482.543] [0.0000], Avg: [-464.262 -464.262 -464.262] (1.000)
Step: 89349, Reward: [-469.733 -469.733 -469.733] [0.0000], Avg: [-464.265 -464.265 -464.265] (1.000)
Step: 89399, Reward: [-362.312 -362.312 -362.312] [0.0000], Avg: [-464.208 -464.208 -464.208] (1.000)
Step: 89449, Reward: [-310.704 -310.704 -310.704] [0.0000], Avg: [-464.122 -464.122 -464.122] (1.000)
Step: 89499, Reward: [-338.532 -338.532 -338.532] [0.0000], Avg: [-464.052 -464.052 -464.052] (1.000)
Step: 89549, Reward: [-323.371 -323.371 -323.371] [0.0000], Avg: [-463.973 -463.973 -463.973] (1.000)
Step: 89599, Reward: [-392.519 -392.519 -392.519] [0.0000], Avg: [-463.933 -463.933 -463.933] (1.000)
Step: 89649, Reward: [-351.044 -351.044 -351.044] [0.0000], Avg: [-463.87 -463.87 -463.87] (1.000)
Step: 89699, Reward: [-324.376 -324.376 -324.376] [0.0000], Avg: [-463.793 -463.793 -463.793] (1.000)
Step: 89749, Reward: [-441.903 -441.903 -441.903] [0.0000], Avg: [-463.781 -463.781 -463.781] (1.000)
Step: 89799, Reward: [-374.134 -374.134 -374.134] [0.0000], Avg: [-463.731 -463.731 -463.731] (1.000)
Step: 89849, Reward: [-437.653 -437.653 -437.653] [0.0000], Avg: [-463.716 -463.716 -463.716] (1.000)
Step: 89899, Reward: [-460.708 -460.708 -460.708] [0.0000], Avg: [-463.714 -463.714 -463.714] (1.000)
Step: 89949, Reward: [-428.119 -428.119 -428.119] [0.0000], Avg: [-463.695 -463.695 -463.695] (1.000)
Step: 89999, Reward: [-388.973 -388.973 -388.973] [0.0000], Avg: [-463.653 -463.653 -463.653] (1.000)
Step: 90049, Reward: [-376.978 -376.978 -376.978] [0.0000], Avg: [-463.605 -463.605 -463.605] (1.000)
Step: 90099, Reward: [-509.12 -509.12 -509.12] [0.0000], Avg: [-463.63 -463.63 -463.63] (1.000)
Step: 90149, Reward: [-333.646 -333.646 -333.646] [0.0000], Avg: [-463.558 -463.558 -463.558] (1.000)
Step: 90199, Reward: [-348.655 -348.655 -348.655] [0.0000], Avg: [-463.494 -463.494 -463.494] (1.000)
Step: 90249, Reward: [-267.034 -267.034 -267.034] [0.0000], Avg: [-463.386 -463.386 -463.386] (1.000)
Step: 90299, Reward: [-351.414 -351.414 -351.414] [0.0000], Avg: [-463.324 -463.324 -463.324] (1.000)
Step: 90349, Reward: [-320.021 -320.021 -320.021] [0.0000], Avg: [-463.244 -463.244 -463.244] (1.000)
Step: 90399, Reward: [-319.876 -319.876 -319.876] [0.0000], Avg: [-463.165 -463.165 -463.165] (1.000)
Step: 90449, Reward: [-372.522 -372.522 -372.522] [0.0000], Avg: [-463.115 -463.115 -463.115] (1.000)
Step: 90499, Reward: [-300.512 -300.512 -300.512] [0.0000], Avg: [-463.025 -463.025 -463.025] (1.000)
Step: 90549, Reward: [-415.766 -415.766 -415.766] [0.0000], Avg: [-462.999 -462.999 -462.999] (1.000)
Step: 90599, Reward: [-294.186 -294.186 -294.186] [0.0000], Avg: [-462.906 -462.906 -462.906] (1.000)
Step: 90649, Reward: [-378.448 -378.448 -378.448] [0.0000], Avg: [-462.859 -462.859 -462.859] (1.000)
Step: 90699, Reward: [-363.144 -363.144 -363.144] [0.0000], Avg: [-462.804 -462.804 -462.804] (1.000)
Step: 90749, Reward: [-303.286 -303.286 -303.286] [0.0000], Avg: [-462.716 -462.716 -462.716] (1.000)
Step: 90799, Reward: [-457.415 -457.415 -457.415] [0.0000], Avg: [-462.713 -462.713 -462.713] (1.000)
Step: 90849, Reward: [-495.428 -495.428 -495.428] [0.0000], Avg: [-462.731 -462.731 -462.731] (1.000)
Step: 90899, Reward: [-325.345 -325.345 -325.345] [0.0000], Avg: [-462.656 -462.656 -462.656] (1.000)
Step: 90949, Reward: [-531.555 -531.555 -531.555] [0.0000], Avg: [-462.694 -462.694 -462.694] (1.000)
Step: 90999, Reward: [-286.371 -286.371 -286.371] [0.0000], Avg: [-462.597 -462.597 -462.597] (1.000)
Step: 91049, Reward: [-436.89 -436.89 -436.89] [0.0000], Avg: [-462.583 -462.583 -462.583] (1.000)
Step: 91099, Reward: [-456.956 -456.956 -456.956] [0.0000], Avg: [-462.58 -462.58 -462.58] (1.000)
Step: 91149, Reward: [-400.331 -400.331 -400.331] [0.0000], Avg: [-462.546 -462.546 -462.546] (1.000)
Step: 91199, Reward: [-272.125 -272.125 -272.125] [0.0000], Avg: [-462.441 -462.441 -462.441] (1.000)
Step: 91249, Reward: [-337.338 -337.338 -337.338] [0.0000], Avg: [-462.373 -462.373 -462.373] (1.000)
Step: 91299, Reward: [-284.114 -284.114 -284.114] [0.0000], Avg: [-462.275 -462.275 -462.275] (1.000)
Step: 91349, Reward: [-475.392 -475.392 -475.392] [0.0000], Avg: [-462.282 -462.282 -462.282] (1.000)
Step: 91399, Reward: [-397.087 -397.087 -397.087] [0.0000], Avg: [-462.246 -462.246 -462.246] (1.000)
Step: 91449, Reward: [-285.268 -285.268 -285.268] [0.0000], Avg: [-462.15 -462.15 -462.15] (1.000)
Step: 91499, Reward: [-373.119 -373.119 -373.119] [0.0000], Avg: [-462.101 -462.101 -462.101] (1.000)
Step: 91549, Reward: [-380.041 -380.041 -380.041] [0.0000], Avg: [-462.056 -462.056 -462.056] (1.000)
Step: 91599, Reward: [-400.177 -400.177 -400.177] [0.0000], Avg: [-462.022 -462.022 -462.022] (1.000)
Step: 91649, Reward: [-334.432 -334.432 -334.432] [0.0000], Avg: [-461.953 -461.953 -461.953] (1.000)
Step: 91699, Reward: [-332.25 -332.25 -332.25] [0.0000], Avg: [-461.882 -461.882 -461.882] (1.000)
Step: 91749, Reward: [-324.115 -324.115 -324.115] [0.0000], Avg: [-461.807 -461.807 -461.807] (1.000)
Step: 91799, Reward: [-377.514 -377.514 -377.514] [0.0000], Avg: [-461.761 -461.761 -461.761] (1.000)
Step: 91849, Reward: [-307.781 -307.781 -307.781] [0.0000], Avg: [-461.677 -461.677 -461.677] (1.000)
Step: 91899, Reward: [-346.54 -346.54 -346.54] [0.0000], Avg: [-461.615 -461.615 -461.615] (1.000)
Step: 91949, Reward: [-425.798 -425.798 -425.798] [0.0000], Avg: [-461.595 -461.595 -461.595] (1.000)
Step: 91999, Reward: [-358.724 -358.724 -358.724] [0.0000], Avg: [-461.539 -461.539 -461.539] (1.000)
Step: 92049, Reward: [-358.169 -358.169 -358.169] [0.0000], Avg: [-461.483 -461.483 -461.483] (1.000)
Step: 92099, Reward: [-434.213 -434.213 -434.213] [0.0000], Avg: [-461.468 -461.468 -461.468] (1.000)
Step: 92149, Reward: [-349.384 -349.384 -349.384] [0.0000], Avg: [-461.408 -461.408 -461.408] (1.000)
Step: 92199, Reward: [-329.419 -329.419 -329.419] [0.0000], Avg: [-461.336 -461.336 -461.336] (1.000)
Step: 92249, Reward: [-341.057 -341.057 -341.057] [0.0000], Avg: [-461.271 -461.271 -461.271] (1.000)
Step: 92299, Reward: [-328.521 -328.521 -328.521] [0.0000], Avg: [-461.199 -461.199 -461.199] (1.000)
Step: 92349, Reward: [-307.521 -307.521 -307.521] [0.0000], Avg: [-461.116 -461.116 -461.116] (1.000)
Step: 92399, Reward: [-325.098 -325.098 -325.098] [0.0000], Avg: [-461.042 -461.042 -461.042] (1.000)
Step: 92449, Reward: [-296.018 -296.018 -296.018] [0.0000], Avg: [-460.953 -460.953 -460.953] (1.000)
Step: 92499, Reward: [-324.443 -324.443 -324.443] [0.0000], Avg: [-460.879 -460.879 -460.879] (1.000)
Step: 92549, Reward: [-277.755 -277.755 -277.755] [0.0000], Avg: [-460.78 -460.78 -460.78] (1.000)
Step: 92599, Reward: [-312.312 -312.312 -312.312] [0.0000], Avg: [-460.7 -460.7 -460.7] (1.000)
Step: 92649, Reward: [-295.277 -295.277 -295.277] [0.0000], Avg: [-460.611 -460.611 -460.611] (1.000)
Step: 92699, Reward: [-434.834 -434.834 -434.834] [0.0000], Avg: [-460.597 -460.597 -460.597] (1.000)
Step: 92749, Reward: [-409.139 -409.139 -409.139] [0.0000], Avg: [-460.569 -460.569 -460.569] (1.000)
Step: 92799, Reward: [-460.844 -460.844 -460.844] [0.0000], Avg: [-460.569 -460.569 -460.569] (1.000)
Step: 92849, Reward: [-290.608 -290.608 -290.608] [0.0000], Avg: [-460.478 -460.478 -460.478] (1.000)
Step: 92899, Reward: [-304.04 -304.04 -304.04] [0.0000], Avg: [-460.393 -460.393 -460.393] (1.000)
Step: 92949, Reward: [-339.546 -339.546 -339.546] [0.0000], Avg: [-460.328 -460.328 -460.328] (1.000)
Step: 92999, Reward: [-385.475 -385.475 -385.475] [0.0000], Avg: [-460.288 -460.288 -460.288] (1.000)
Step: 93049, Reward: [-381.952 -381.952 -381.952] [0.0000], Avg: [-460.246 -460.246 -460.246] (1.000)
Step: 93099, Reward: [-319.94 -319.94 -319.94] [0.0000], Avg: [-460.171 -460.171 -460.171] (1.000)
Step: 93149, Reward: [-384.627 -384.627 -384.627] [0.0000], Avg: [-460.13 -460.13 -460.13] (1.000)
Step: 93199, Reward: [-385.541 -385.541 -385.541] [0.0000], Avg: [-460.09 -460.09 -460.09] (1.000)
Step: 93249, Reward: [-427.567 -427.567 -427.567] [0.0000], Avg: [-460.073 -460.073 -460.073] (1.000)
Step: 93299, Reward: [-333.458 -333.458 -333.458] [0.0000], Avg: [-460.005 -460.005 -460.005] (1.000)
Step: 93349, Reward: [-352.038 -352.038 -352.038] [0.0000], Avg: [-459.947 -459.947 -459.947] (1.000)
Step: 93399, Reward: [-367.627 -367.627 -367.627] [0.0000], Avg: [-459.898 -459.898 -459.898] (1.000)
Step: 93449, Reward: [-405.199 -405.199 -405.199] [0.0000], Avg: [-459.868 -459.868 -459.868] (1.000)
Step: 93499, Reward: [-396.446 -396.446 -396.446] [0.0000], Avg: [-459.834 -459.834 -459.834] (1.000)
Step: 93549, Reward: [-357.635 -357.635 -357.635] [0.0000], Avg: [-459.78 -459.78 -459.78] (1.000)
Step: 93599, Reward: [-363.132 -363.132 -363.132] [0.0000], Avg: [-459.728 -459.728 -459.728] (1.000)
Step: 93649, Reward: [-389.347 -389.347 -389.347] [0.0000], Avg: [-459.691 -459.691 -459.691] (1.000)
Step: 93699, Reward: [-301.62 -301.62 -301.62] [0.0000], Avg: [-459.606 -459.606 -459.606] (1.000)
Step: 93749, Reward: [-343.606 -343.606 -343.606] [0.0000], Avg: [-459.544 -459.544 -459.544] (1.000)
Step: 93799, Reward: [-308.941 -308.941 -308.941] [0.0000], Avg: [-459.464 -459.464 -459.464] (1.000)
Step: 93849, Reward: [-423.203 -423.203 -423.203] [0.0000], Avg: [-459.445 -459.445 -459.445] (1.000)
Step: 93899, Reward: [-413.186 -413.186 -413.186] [0.0000], Avg: [-459.42 -459.42 -459.42] (1.000)
Step: 93949, Reward: [-356.867 -356.867 -356.867] [0.0000], Avg: [-459.366 -459.366 -459.366] (1.000)
Step: 93999, Reward: [-349.547 -349.547 -349.547] [0.0000], Avg: [-459.307 -459.307 -459.307] (1.000)
Step: 94049, Reward: [-362.744 -362.744 -362.744] [0.0000], Avg: [-459.256 -459.256 -459.256] (1.000)
Step: 94099, Reward: [-494.406 -494.406 -494.406] [0.0000], Avg: [-459.275 -459.275 -459.275] (1.000)
Step: 94149, Reward: [-294. -294. -294.] [0.0000], Avg: [-459.187 -459.187 -459.187] (1.000)
Step: 94199, Reward: [-395.932 -395.932 -395.932] [0.0000], Avg: [-459.153 -459.153 -459.153] (1.000)
Step: 94249, Reward: [-301.204 -301.204 -301.204] [0.0000], Avg: [-459.069 -459.069 -459.069] (1.000)
Step: 94299, Reward: [-436.784 -436.784 -436.784] [0.0000], Avg: [-459.058 -459.058 -459.058] (1.000)
Step: 94349, Reward: [-416.361 -416.361 -416.361] [0.0000], Avg: [-459.035 -459.035 -459.035] (1.000)
Step: 94399, Reward: [-313.38 -313.38 -313.38] [0.0000], Avg: [-458.958 -458.958 -458.958] (1.000)
Step: 94449, Reward: [-209.226 -209.226 -209.226] [0.0000], Avg: [-458.826 -458.826 -458.826] (1.000)
Step: 94499, Reward: [-385.732 -385.732 -385.732] [0.0000], Avg: [-458.787 -458.787 -458.787] (1.000)
Step: 94549, Reward: [-384.445 -384.445 -384.445] [0.0000], Avg: [-458.748 -458.748 -458.748] (1.000)
Step: 94599, Reward: [-369.048 -369.048 -369.048] [0.0000], Avg: [-458.7 -458.7 -458.7] (1.000)
Step: 94649, Reward: [-337.071 -337.071 -337.071] [0.0000], Avg: [-458.636 -458.636 -458.636] (1.000)
Step: 94699, Reward: [-554.975 -554.975 -554.975] [0.0000], Avg: [-458.687 -458.687 -458.687] (1.000)
Step: 94749, Reward: [-348.554 -348.554 -348.554] [0.0000], Avg: [-458.629 -458.629 -458.629] (1.000)
Step: 94799, Reward: [-303.323 -303.323 -303.323] [0.0000], Avg: [-458.547 -458.547 -458.547] (1.000)
Step: 94849, Reward: [-324.819 -324.819 -324.819] [0.0000], Avg: [-458.476 -458.476 -458.476] (1.000)
Step: 94899, Reward: [-353.205 -353.205 -353.205] [0.0000], Avg: [-458.421 -458.421 -458.421] (1.000)
Step: 94949, Reward: [-354.339 -354.339 -354.339] [0.0000], Avg: [-458.366 -458.366 -458.366] (1.000)
Step: 94999, Reward: [-367.002 -367.002 -367.002] [0.0000], Avg: [-458.318 -458.318 -458.318] (1.000)
Step: 95049, Reward: [-280.838 -280.838 -280.838] [0.0000], Avg: [-458.225 -458.225 -458.225] (1.000)
Step: 95099, Reward: [-342.165 -342.165 -342.165] [0.0000], Avg: [-458.164 -458.164 -458.164] (1.000)
Step: 95149, Reward: [-391.023 -391.023 -391.023] [0.0000], Avg: [-458.128 -458.128 -458.128] (1.000)
Step: 95199, Reward: [-403.808 -403.808 -403.808] [0.0000], Avg: [-458.1 -458.1 -458.1] (1.000)
Step: 95249, Reward: [-396.607 -396.607 -396.607] [0.0000], Avg: [-458.067 -458.067 -458.067] (1.000)
Step: 95299, Reward: [-348.453 -348.453 -348.453] [0.0000], Avg: [-458.01 -458.01 -458.01] (1.000)
Step: 95349, Reward: [-343.454 -343.454 -343.454] [0.0000], Avg: [-457.95 -457.95 -457.95] (1.000)
Step: 95399, Reward: [-265.649 -265.649 -265.649] [0.0000], Avg: [-457.849 -457.849 -457.849] (1.000)
Step: 95449, Reward: [-383.372 -383.372 -383.372] [0.0000], Avg: [-457.81 -457.81 -457.81] (1.000)
Step: 95499, Reward: [-384.489 -384.489 -384.489] [0.0000], Avg: [-457.772 -457.772 -457.772] (1.000)
Step: 95549, Reward: [-270.522 -270.522 -270.522] [0.0000], Avg: [-457.674 -457.674 -457.674] (1.000)
Step: 95599, Reward: [-357.672 -357.672 -357.672] [0.0000], Avg: [-457.621 -457.621 -457.621] (1.000)
Step: 95649, Reward: [-338.519 -338.519 -338.519] [0.0000], Avg: [-457.559 -457.559 -457.559] (1.000)
Step: 95699, Reward: [-402.827 -402.827 -402.827] [0.0000], Avg: [-457.531 -457.531 -457.531] (1.000)
Step: 95749, Reward: [-336.719 -336.719 -336.719] [0.0000], Avg: [-457.467 -457.467 -457.467] (1.000)
Step: 95799, Reward: [-296.623 -296.623 -296.623] [0.0000], Avg: [-457.383 -457.383 -457.383] (1.000)
Step: 95849, Reward: [-318.811 -318.811 -318.811] [0.0000], Avg: [-457.311 -457.311 -457.311] (1.000)
Step: 95899, Reward: [-362.742 -362.742 -362.742] [0.0000], Avg: [-457.262 -457.262 -457.262] (1.000)
Step: 95949, Reward: [-342.927 -342.927 -342.927] [0.0000], Avg: [-457.202 -457.202 -457.202] (1.000)
Step: 95999, Reward: [-298.02 -298.02 -298.02] [0.0000], Avg: [-457.119 -457.119 -457.119] (1.000)
Step: 96049, Reward: [-447.146 -447.146 -447.146] [0.0000], Avg: [-457.114 -457.114 -457.114] (1.000)
Step: 96099, Reward: [-342.136 -342.136 -342.136] [0.0000], Avg: [-457.054 -457.054 -457.054] (1.000)
Step: 96149, Reward: [-327.49 -327.49 -327.49] [0.0000], Avg: [-456.987 -456.987 -456.987] (1.000)
Step: 96199, Reward: [-344.984 -344.984 -344.984] [0.0000], Avg: [-456.929 -456.929 -456.929] (1.000)
Step: 96249, Reward: [-434.845 -434.845 -434.845] [0.0000], Avg: [-456.917 -456.917 -456.917] (1.000)
Step: 96299, Reward: [-469.41 -469.41 -469.41] [0.0000], Avg: [-456.924 -456.924 -456.924] (1.000)
Step: 96349, Reward: [-223.828 -223.828 -223.828] [0.0000], Avg: [-456.803 -456.803 -456.803] (1.000)
Step: 96399, Reward: [-391. -391. -391.] [0.0000], Avg: [-456.769 -456.769 -456.769] (1.000)
Step: 96449, Reward: [-350.791 -350.791 -350.791] [0.0000], Avg: [-456.714 -456.714 -456.714] (1.000)
Step: 96499, Reward: [-369.163 -369.163 -369.163] [0.0000], Avg: [-456.668 -456.668 -456.668] (1.000)
Step: 96549, Reward: [-392.86 -392.86 -392.86] [0.0000], Avg: [-456.635 -456.635 -456.635] (1.000)
Step: 96599, Reward: [-386.405 -386.405 -386.405] [0.0000], Avg: [-456.599 -456.599 -456.599] (1.000)
Step: 96649, Reward: [-376.108 -376.108 -376.108] [0.0000], Avg: [-456.557 -456.557 -456.557] (1.000)
Step: 96699, Reward: [-322.587 -322.587 -322.587] [0.0000], Avg: [-456.488 -456.488 -456.488] (1.000)
Step: 96749, Reward: [-386.548 -386.548 -386.548] [0.0000], Avg: [-456.452 -456.452 -456.452] (1.000)
Step: 96799, Reward: [-484.477 -484.477 -484.477] [0.0000], Avg: [-456.466 -456.466 -456.466] (1.000)
Step: 96849, Reward: [-345.089 -345.089 -345.089] [0.0000], Avg: [-456.409 -456.409 -456.409] (1.000)
Step: 96899, Reward: [-293.186 -293.186 -293.186] [0.0000], Avg: [-456.325 -456.325 -456.325] (1.000)
Step: 96949, Reward: [-342.659 -342.659 -342.659] [0.0000], Avg: [-456.266 -456.266 -456.266] (1.000)
Step: 96999, Reward: [-323.082 -323.082 -323.082] [0.0000], Avg: [-456.197 -456.197 -456.197] (1.000)
Step: 97049, Reward: [-326.935 -326.935 -326.935] [0.0000], Avg: [-456.131 -456.131 -456.131] (1.000)
Step: 97099, Reward: [-340.041 -340.041 -340.041] [0.0000], Avg: [-456.071 -456.071 -456.071] (1.000)
Step: 97149, Reward: [-397.193 -397.193 -397.193] [0.0000], Avg: [-456.041 -456.041 -456.041] (1.000)
Step: 97199, Reward: [-361.319 -361.319 -361.319] [0.0000], Avg: [-455.992 -455.992 -455.992] (1.000)
Step: 97249, Reward: [-306.226 -306.226 -306.226] [0.0000], Avg: [-455.915 -455.915 -455.915] (1.000)
Step: 97299, Reward: [-316.902 -316.902 -316.902] [0.0000], Avg: [-455.844 -455.844 -455.844] (1.000)
Step: 97349, Reward: [-314.554 -314.554 -314.554] [0.0000], Avg: [-455.771 -455.771 -455.771] (1.000)
Step: 97399, Reward: [-284.882 -284.882 -284.882] [0.0000], Avg: [-455.683 -455.683 -455.683] (1.000)
Step: 97449, Reward: [-563.252 -563.252 -563.252] [0.0000], Avg: [-455.739 -455.739 -455.739] (1.000)
Step: 97499, Reward: [-366.556 -366.556 -366.556] [0.0000], Avg: [-455.693 -455.693 -455.693] (1.000)
Step: 97549, Reward: [-388.413 -388.413 -388.413] [0.0000], Avg: [-455.658 -455.658 -455.658] (1.000)
Step: 97599, Reward: [-367.018 -367.018 -367.018] [0.0000], Avg: [-455.613 -455.613 -455.613] (1.000)
Step: 97649, Reward: [-434.668 -434.668 -434.668] [0.0000], Avg: [-455.602 -455.602 -455.602] (1.000)
Step: 97699, Reward: [-489.949 -489.949 -489.949] [0.0000], Avg: [-455.62 -455.62 -455.62] (1.000)
Step: 97749, Reward: [-333.337 -333.337 -333.337] [0.0000], Avg: [-455.557 -455.557 -455.557] (1.000)
Step: 97799, Reward: [-486.55 -486.55 -486.55] [0.0000], Avg: [-455.573 -455.573 -455.573] (1.000)
Step: 97849, Reward: [-466.294 -466.294 -466.294] [0.0000], Avg: [-455.579 -455.579 -455.579] (1.000)
Step: 97899, Reward: [-394.944 -394.944 -394.944] [0.0000], Avg: [-455.548 -455.548 -455.548] (1.000)
Step: 97949, Reward: [-289.912 -289.912 -289.912] [0.0000], Avg: [-455.463 -455.463 -455.463] (1.000)
Step: 97999, Reward: [-309.967 -309.967 -309.967] [0.0000], Avg: [-455.389 -455.389 -455.389] (1.000)
Step: 98049, Reward: [-352.054 -352.054 -352.054] [0.0000], Avg: [-455.336 -455.336 -455.336] (1.000)
Step: 98099, Reward: [-324.637 -324.637 -324.637] [0.0000], Avg: [-455.269 -455.269 -455.269] (1.000)
Step: 98149, Reward: [-343.522 -343.522 -343.522] [0.0000], Avg: [-455.213 -455.213 -455.213] (1.000)
Step: 98199, Reward: [-309.103 -309.103 -309.103] [0.0000], Avg: [-455.138 -455.138 -455.138] (1.000)
Step: 98249, Reward: [-278.828 -278.828 -278.828] [0.0000], Avg: [-455.048 -455.048 -455.048] (1.000)
Step: 98299, Reward: [-324.886 -324.886 -324.886] [0.0000], Avg: [-454.982 -454.982 -454.982] (1.000)
Step: 98349, Reward: [-407.611 -407.611 -407.611] [0.0000], Avg: [-454.958 -454.958 -454.958] (1.000)
Step: 98399, Reward: [-339.685 -339.685 -339.685] [0.0000], Avg: [-454.9 -454.9 -454.9] (1.000)
Step: 98449, Reward: [-366.105 -366.105 -366.105] [0.0000], Avg: [-454.854 -454.854 -454.854] (1.000)
Step: 98499, Reward: [-314.225 -314.225 -314.225] [0.0000], Avg: [-454.783 -454.783 -454.783] (1.000)
Step: 98549, Reward: [-296.139 -296.139 -296.139] [0.0000], Avg: [-454.703 -454.703 -454.703] (1.000)
Step: 98599, Reward: [-341.659 -341.659 -341.659] [0.0000], Avg: [-454.645 -454.645 -454.645] (1.000)
Step: 98649, Reward: [-381.648 -381.648 -381.648] [0.0000], Avg: [-454.608 -454.608 -454.608] (1.000)
Step: 98699, Reward: [-293.419 -293.419 -293.419] [0.0000], Avg: [-454.527 -454.527 -454.527] (1.000)
Step: 98749, Reward: [-365.943 -365.943 -365.943] [0.0000], Avg: [-454.482 -454.482 -454.482] (1.000)
Step: 98799, Reward: [-419.514 -419.514 -419.514] [0.0000], Avg: [-454.464 -454.464 -454.464] (1.000)
Step: 98849, Reward: [-370.761 -370.761 -370.761] [0.0000], Avg: [-454.422 -454.422 -454.422] (1.000)
Step: 98899, Reward: [-523.037 -523.037 -523.037] [0.0000], Avg: [-454.456 -454.456 -454.456] (1.000)
Step: 98949, Reward: [-414.399 -414.399 -414.399] [0.0000], Avg: [-454.436 -454.436 -454.436] (1.000)
Step: 98999, Reward: [-399.176 -399.176 -399.176] [0.0000], Avg: [-454.408 -454.408 -454.408] (1.000)
Step: 99049, Reward: [-461.755 -461.755 -461.755] [0.0000], Avg: [-454.412 -454.412 -454.412] (1.000)
Step: 99099, Reward: [-352.316 -352.316 -352.316] [0.0000], Avg: [-454.36 -454.36 -454.36] (1.000)
Step: 99149, Reward: [-364.004 -364.004 -364.004] [0.0000], Avg: [-454.315 -454.315 -454.315] (1.000)
Step: 99199, Reward: [-339.135 -339.135 -339.135] [0.0000], Avg: [-454.257 -454.257 -454.257] (1.000)
Step: 99249, Reward: [-305.369 -305.369 -305.369] [0.0000], Avg: [-454.182 -454.182 -454.182] (1.000)
Step: 99299, Reward: [-315.318 -315.318 -315.318] [0.0000], Avg: [-454.112 -454.112 -454.112] (1.000)
Step: 99349, Reward: [-437.422 -437.422 -437.422] [0.0000], Avg: [-454.104 -454.104 -454.104] (1.000)
Step: 99399, Reward: [-456.387 -456.387 -456.387] [0.0000], Avg: [-454.105 -454.105 -454.105] (1.000)
Step: 99449, Reward: [-355.567 -355.567 -355.567] [0.0000], Avg: [-454.055 -454.055 -454.055] (1.000)
Step: 99499, Reward: [-287.787 -287.787 -287.787] [0.0000], Avg: [-453.972 -453.972 -453.972] (1.000)
Step: 99549, Reward: [-366.911 -366.911 -366.911] [0.0000], Avg: [-453.928 -453.928 -453.928] (1.000)
Step: 99599, Reward: [-431.465 -431.465 -431.465] [0.0000], Avg: [-453.917 -453.917 -453.917] (1.000)
Step: 99649, Reward: [-291.934 -291.934 -291.934] [0.0000], Avg: [-453.835 -453.835 -453.835] (1.000)
Step: 99699, Reward: [-308.005 -308.005 -308.005] [0.0000], Avg: [-453.762 -453.762 -453.762] (1.000)
Step: 99749, Reward: [-355.705 -355.705 -355.705] [0.0000], Avg: [-453.713 -453.713 -453.713] (1.000)
Step: 99799, Reward: [-316.564 -316.564 -316.564] [0.0000], Avg: [-453.644 -453.644 -453.644] (1.000)
Step: 99849, Reward: [-325.43 -325.43 -325.43] [0.0000], Avg: [-453.58 -453.58 -453.58] (1.000)
Step: 99899, Reward: [-342.36 -342.36 -342.36] [0.0000], Avg: [-453.524 -453.524 -453.524] (1.000)
Step: 99949, Reward: [-276.241 -276.241 -276.241] [0.0000], Avg: [-453.436 -453.436 -453.436] (1.000)
Step: 99999, Reward: [-378.779 -378.779 -378.779] [0.0000], Avg: [-453.398 -453.398 -453.398] (1.000)
