Model: <class 'multiagent.maddpg.MADDPGAgent'>, Dir: simple_spread
num_envs: 1, state_size: [(1, 18), (1, 18), (1, 18)], action_size: [[1, 5], [1, 5], [1, 5]], action_space: [<gym.spaces.multi_discrete.MultiDiscrete object at 0x7f3d7342eef0>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f3d7342ef98>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f3d73436048>],

import torch
import random
import numpy as np
from models.rand import MultiagentReplayBuffer
from models.ddpg import DDPGActor, DDPGCritic, DDPGNetwork
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACAgent, LEARN_RATE, NUM_STEPS, EPS_MIN, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, MAX_BUFFER_SIZE, gumbel_softmax, one_hot

REPLAY_BATCH_SIZE = 8
ENTROPY_WEIGHT = 0.001			# The weight for the entropy term of the Actor loss
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64
LEARN_RATE = 0.01
TARGET_UPDATE_RATE = 0.01

class MADDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, sample=True):
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		action_mu = self.action_mu(state)
		action = gumbel_softmax(action_mu, hard=True)
		action = action.view(*out_dims, -1)
		return action
	
class MADDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1]+action_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1]+action_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, action):
		state = torch.cat([state, action], -1)
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		q_value = self.q_value(state)
		q_value = q_value.view(*out_dims, -1)
		return q_value

class MADDPGNetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=True, load=None):
		super().__init__(tau=tau, gpu=gpu)
		self.state_size = state_size
		self.action_size = action_size
		self.critic = MADDPGCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.models = [DDPGNetwork(s_size, a_size, MADDPGActor, lambda s,a: self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		
	def get_action_probs(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [model.get_action(s, use_target, grad, numpy, sample) for s,model in zip(state, self.models)]
			return action

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_value = [model.get_q_value(state, action, use_target, grad, numpy) for model in self.models]
			return q_value

	def optimize(self, states, actions, states_joint, actions_joint, q_targets, e_weight=ENTROPY_WEIGHT):
		for (i,model),state,q_target in zip(enumerate(self.models), states, q_targets):
			q_values = model.get_q_value(states_joint, actions_joint, grad=True, numpy=False)
			critic_error = q_values[:q_target.size(0)] - q_target.detach()
			critic_loss = critic_error.pow(2)
			model.step(model.critic_optimizer, critic_loss.mean(), param_norm=model.critic_local.parameters())
			model.soft_copy(model.critic_local, model.critic_target)

			actor_action = model.get_action(state, grad=True, numpy=False)
			critic_action = [actor_action if j==i else other.get_action(states[j], numpy=False) for j,other in enumerate(self.models)]
			action_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(critic_action, self.action_size)], dim=-1)
			q_actions = model.critic_local(states_joint, action_joint)
			actor_loss = -q_actions.mean() + e_weight*actor_action.pow(2).mean()
			model.step(model.actor_optimizer, actor_loss.mean(), param_norm=model.actor_local.parameters())
			model.soft_copy(model.actor_local, model.actor_target)

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class MADDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, MADDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		agent_init_params = []
		for acsp, obsp in zip(action_size, state_size):
			num_in_pol = obsp[-1]
			num_out_pol = acsp[-1]
			num_in_critic = 0
			for oobsp in state_size:
				num_in_critic += oobsp[-1]
			for oacsp in action_size:
				num_in_critic += oacsp[-1]
			agent_init_params.append({'num_in_pol': num_in_pol, 'num_out_pol': num_out_pol, 'num_in_critic': num_in_critic})
		self.agent = MADDPG(agent_init_params, ["MADDPG"] * len(state_size))
		self.replay_buffer = MultiagentReplayBuffer(MAX_BUFFER_SIZE, self.agent.nagents, [obsp[-1] for obsp in state_size], [acsp[-1] for acsp in action_size])

	def get_action(self, state, eps=None, sample=True, numpy=True):
		state = [torch.autograd.Variable(torch.Tensor(np.vstack(state[i])), requires_grad=False) for i in range(self.agent.nagents)]
		torch_agent_actions = self.agent.step(state, explore=True)
		agent_actions = [ac.data.numpy() for ac in torch_agent_actions]
		return agent_actions
		# eps = self.eps if eps is None else eps
		# action_random = super().get_action(state)
		# action_greedy = self.network.get_action_probs(self.to_tensor(state), sample=sample, numpy=numpy)
		# action = [(1-eps)*a_greedy + eps*a_random for a_greedy,a_random in zip(action_greedy, action_random)]
		# return action

	def train(self, state, action, next_state, reward, done):
		if not hasattr(self, "t"): self.t = 0
		self.replay_buffer.push(state, action, next_state, reward, done)
		if (len(self.replay_buffer) >= 1024 and (self.t % 100)==0):
			self.agent.prep_training(device='cpu')
			for a_i in range(self.agent.nagents):
				sample = self.replay_buffer.sample(1024, to_gpu=False)
				self.agent.update(sample, a_i)
			self.agent.update_all_targets()
			self.agent.prep_rollouts(device='cpu')
		self.t += 1
		# self.buffer.append((state, action, reward, done))
		# if np.any(done[0]) or len(self.buffer) >= self.update_freq:
		# 	states, actions, rewards, dones = map(lambda x: self.to_tensor(x), zip(*self.buffer))
		# 	self.buffer.clear()
		# 	next_state = self.to_tensor(next_state)
		# 	states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, next_state)]
		# 	actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.network.get_action_probs(next_state, use_target=True))]
		# 	states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
		# 	actions_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions, self.action_size)], dim=-1)
		# 	q_values = self.network.get_q_value(states_joint, actions_joint, use_target=True)
		# 	q_targets = [self.compute_gae(q_value[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_value[:-1])[0] for q_value,reward,done in zip(q_values, rewards, dones)]
			
		# 	to_stack = lambda items: list(zip(*[x.view(-1, *x.shape[2:]).cpu().numpy() for x in items]))
		# 	states, actions, states_joint, actions_joint = map(lambda items: [x[:-1] for x in items], [states, actions, [states_joint], [actions_joint]])
		# 	states, actions, states_joint, actions_joint, q_targets = map(to_stack, [states, actions, states_joint, actions_joint, q_targets])
		# 	self.replay_buffer.extend(list(zip(states, actions, states_joint, actions_joint, q_targets)), shuffle=False)	
		# if len(self.replay_buffer) > REPLAY_BATCH_SIZE:
		# 	states, actions, states_joint, actions_joint, q_targets = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
		# 	self.network.optimize(states, actions, states_joint[0], actions_joint[0], q_targets)
		# if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)

MSELoss = torch.nn.MSELoss()


class MADDPG():
	"""
	Wrapper class for DDPG-esque (i.e. also MADDPG) agents in multi-agent task
	"""
	def __init__(self, agent_init_params, alg_types, gamma=0.95, tau=0.01, lr=0.01, hidden_dim=64, discrete_action=True):
		self.nagents = len(alg_types)
		self.alg_types = alg_types
		self.agents = [DDPGAgent(lr=lr, discrete_action=discrete_action, hidden_dim=hidden_dim, **params) for params in agent_init_params]
		self.agent_init_params = agent_init_params
		self.gamma = gamma
		self.tau = tau
		self.lr = lr
		self.pol_dev = 'cpu'  # device for policies
		self.critic_dev = 'cpu'  # device for critics
		self.trgt_pol_dev = 'cpu'  # device for target policies
		self.trgt_critic_dev = 'cpu'  # device for target critics
		self.niter = 0

	@property
	def policies(self):
		return [a.policy for a in self.agents]

	@property
	def target_policies(self):
		return [a.target_policy for a in self.agents]

	def step(self, observations, explore=False):
		return [a.step(obs, explore=explore) for a, obs in zip(self.agents, observations)]

	def update(self, sample, agent_i, parallel=False, logger=None):
		obs, acs, rews, next_obs, dones = sample
		curr_agent = self.agents[agent_i]

		all_trgt_acs = [one_hot(pi(nobs)) for pi, nobs in zip(self.target_policies, next_obs)]
		trgt_vf_in = torch.cat((*next_obs, *all_trgt_acs), dim=1)
		target_value = (rews[agent_i].view(-1, 1) + self.gamma * curr_agent.target_critic(trgt_vf_in) * (1 - dones[agent_i].view(-1, 1)))

		critic_inputs = torch.cat((*obs, *acs), dim=1)
		actual_value = curr_agent.critic(critic_inputs)

		curr_agent.critic_optimizer.zero_grad()
		vf_loss = (actual_value - target_value.detach()).pow(2).mean()
		vf_loss.backward()
		torch.nn.utils.clip_grad_norm(curr_agent.critic.parameters(), 0.5)
		curr_agent.critic_optimizer.step()

		curr_agent.policy_optimizer.zero_grad()
		curr_pol_out = curr_agent.policy(obs[agent_i])
		curr_pol_vf_in = gumbel_softmax(curr_pol_out, hard=True)
		all_pol_acs = [curr_pol_vf_in if i==agent_i else one_hot(pi(ob)) for i, pi, ob in zip(range(self.nagents), self.policies, obs)]
		critic_inputs = torch.cat((*obs, *all_pol_acs), dim=1)
		pol_loss = -curr_agent.critic(critic_inputs).mean()
		pol_loss += (curr_pol_out**2).mean() * 1e-3
		pol_loss.backward()
		torch.nn.utils.clip_grad_norm(curr_agent.policy.parameters(), 0.5)
		curr_agent.policy_optimizer.step()

	def update_all_targets(self):
		for a in self.agents:
			# PTNetwork.soft_copy(a.critic, a.target_critic)
			# PTNetwork.soft_copy(a.policy, a.target_policy)
			for target_param, param in zip(a.target_critic.parameters(), a.critic.parameters()):
				target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)
			for target_param, param in zip(a.target_policy.parameters(), a.policy.parameters()):
				target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)
		self.niter += 1

	def prep_training(self, device='gpu'):
		for a in self.agents:
			a.policy.train()
			a.critic.train()
			a.target_policy.train()
			a.target_critic.train()

	def prep_rollouts(self, device='cpu'):
		for a in self.agents:
			a.policy.eval()

class DDPGAgent(object):
	def __init__(self, num_in_pol, num_out_pol, num_in_critic, hidden_dim=64, lr=0.01, discrete_action=True):
		self.policy = MLPNetwork(num_in_pol, num_out_pol,hidden_dim=hidden_dim, constrain_out=True, discrete_action=discrete_action)
		self.critic = MLPNetwork(num_in_critic, 1,hidden_dim=hidden_dim, constrain_out=False)
		self.target_policy = MLPNetwork(num_in_pol, num_out_pol,hidden_dim=hidden_dim, constrain_out=True, discrete_action=discrete_action)
		self.target_critic = MLPNetwork(num_in_critic, 1,hidden_dim=hidden_dim, constrain_out=False)
		for target_param, param in zip(self.target_policy.parameters(), self.policy.parameters()):
			target_param.data.copy_(param.data)
		for target_param, param in zip(self.target_critic.parameters(), self.critic.parameters()):
			target_param.data.copy_(param.data)
		self.policy_optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr)
		self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr)

	def step(self, obs, explore=False):
		action = self.policy(obs)
		if explore:
			action = gumbel_softmax(action, hard=True)
		else:
			action = one_hot(action)
		return action

class MLPNetwork(torch.nn.Module):
	def __init__(self, input_dim, out_dim, hidden_dim=64, nonlin=torch.relu, constrain_out=False, norm_in=False, discrete_action=True):
		super(MLPNetwork, self).__init__()

		if norm_in:  # normalize inputs
			self.in_fn = nn.BatchNorm1d(input_dim)
			self.in_fn.weight.data.fill_(1)
			self.in_fn.bias.data.fill_(0)
		else:
			self.in_fn = lambda x: x
		self.fc1 = torch.nn.Linear(input_dim, hidden_dim)
		self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)
		self.fc3 = torch.nn.Linear(hidden_dim, out_dim)
		self.nonlin = nonlin
		if constrain_out and not discrete_action:
			self.fc3.weight.data.uniform_(-3e-3, 3e-3)
			self.out_fn = torch.tanh
			raise EnvironmentError()
		else:  # logits for discrete action (will softmax later)
			self.out_fn = lambda x: x

	def forward(self, X):
		h1 = self.nonlin(self.fc1(self.in_fn(X)))
		h2 = self.nonlin(self.fc2(h1))
		out = self.out_fn(self.fc3(h2))
		return out
REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.900             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)
# np.random.seed(1)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return gym.make(env_name)
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":0} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env)

def run(model, steps=10000, ports=16, env_name=env_name, eval_at=1000, checkpoint=False, save_best=False, log=True, render=True):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports, render=False, env_name=env_name)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, num_envs=num_envs, gpu=False, agent2=RandomAgent) 
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if np.any(dones[0]):
			rollouts = [rollout(envs.env, agent.reset(1), render=render) for _ in range(1)]
			test_reward = np.mean(rollouts, axis=0) - np.std(rollouts, axis=0)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if save_best and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts, axis=0)} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")
			agent.reset(num_envs)

def trial(model):
	envs = EnsembleEnv(make_env, 0, log=True, render=True)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, load=f"{env_name}")
	print(f"Reward: {rollout(envs.env, agent, eps=0.02, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[1], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="maddpg", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--test", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.test:
		trial(model)
	elif args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		run(model, args.steps, args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)

Step: 49, Reward: [-538.185 -538.185 -538.185] [0.0000], Avg: [-538.185 -538.185 -538.185] (1.000)
Step: 99, Reward: [-619.905 -619.905 -619.905] [0.0000], Avg: [-579.045 -579.045 -579.045] (1.000)
Step: 149, Reward: [-592.227 -592.227 -592.227] [0.0000], Avg: [-583.439 -583.439 -583.439] (1.000)
Step: 199, Reward: [-392.231 -392.231 -392.231] [0.0000], Avg: [-535.637 -535.637 -535.637] (1.000)
Step: 249, Reward: [-388.972 -388.972 -388.972] [0.0000], Avg: [-506.304 -506.304 -506.304] (1.000)
Step: 299, Reward: [-431.981 -431.981 -431.981] [0.0000], Avg: [-493.917 -493.917 -493.917] (1.000)
Step: 349, Reward: [-619.761 -619.761 -619.761] [0.0000], Avg: [-511.895 -511.895 -511.895] (1.000)
Step: 399, Reward: [-692.741 -692.741 -692.741] [0.0000], Avg: [-534.5 -534.5 -534.5] (1.000)
Step: 449, Reward: [-529.475 -529.475 -529.475] [0.0000], Avg: [-533.942 -533.942 -533.942] (1.000)
Step: 499, Reward: [-422.73 -422.73 -422.73] [0.0000], Avg: [-522.821 -522.821 -522.821] (1.000)
Step: 549, Reward: [-498.482 -498.482 -498.482] [0.0000], Avg: [-520.608 -520.608 -520.608] (1.000)
Step: 599, Reward: [-397.597 -397.597 -397.597] [0.0000], Avg: [-510.357 -510.357 -510.357] (1.000)
Step: 649, Reward: [-344.146 -344.146 -344.146] [0.0000], Avg: [-497.572 -497.572 -497.572] (1.000)
Step: 699, Reward: [-539.303 -539.303 -539.303] [0.0000], Avg: [-500.553 -500.553 -500.553] (1.000)
Step: 749, Reward: [-444.365 -444.365 -444.365] [0.0000], Avg: [-496.807 -496.807 -496.807] (1.000)
Step: 799, Reward: [-346.891 -346.891 -346.891] [0.0000], Avg: [-487.437 -487.437 -487.437] (1.000)
Step: 849, Reward: [-656.724 -656.724 -656.724] [0.0000], Avg: [-497.395 -497.395 -497.395] (1.000)
Step: 899, Reward: [-665.255 -665.255 -665.255] [0.0000], Avg: [-506.721 -506.721 -506.721] (1.000)
Step: 949, Reward: [-574.722 -574.722 -574.722] [0.0000], Avg: [-510.3 -510.3 -510.3] (1.000)
Step: 999, Reward: [-599.538 -599.538 -599.538] [0.0000], Avg: [-514.762 -514.762 -514.762] (1.000)
Step: 1049, Reward: [-400.887 -400.887 -400.887] [0.0000], Avg: [-509.339 -509.339 -509.339] (1.000)
Step: 1099, Reward: [-425.848 -425.848 -425.848] [0.0000], Avg: [-505.544 -505.544 -505.544] (1.000)
Step: 1149, Reward: [-437.313 -437.313 -437.313] [0.0000], Avg: [-502.577 -502.577 -502.577] (1.000)
Step: 1199, Reward: [-516.057 -516.057 -516.057] [0.0000], Avg: [-503.139 -503.139 -503.139] (1.000)
Step: 1249, Reward: [-497.433 -497.433 -497.433] [0.0000], Avg: [-502.911 -502.911 -502.911] (1.000)
Step: 1299, Reward: [-363.423 -363.423 -363.423] [0.0000], Avg: [-497.546 -497.546 -497.546] (1.000)
Step: 1349, Reward: [-593.101 -593.101 -593.101] [0.0000], Avg: [-501.085 -501.085 -501.085] (1.000)
Step: 1399, Reward: [-377.784 -377.784 -377.784] [0.0000], Avg: [-496.681 -496.681 -496.681] (1.000)
Step: 1449, Reward: [-393.118 -393.118 -393.118] [0.0000], Avg: [-493.11 -493.11 -493.11] (1.000)
Step: 1499, Reward: [-487.762 -487.762 -487.762] [0.0000], Avg: [-492.932 -492.932 -492.932] (1.000)
Step: 1549, Reward: [-550.611 -550.611 -550.611] [0.0000], Avg: [-494.793 -494.793 -494.793] (1.000)
Step: 1599, Reward: [-339.14 -339.14 -339.14] [0.0000], Avg: [-489.928 -489.928 -489.928] (1.000)
Step: 1649, Reward: [-616.572 -616.572 -616.572] [0.0000], Avg: [-493.766 -493.766 -493.766] (1.000)
Step: 1699, Reward: [-535.174 -535.174 -535.174] [0.0000], Avg: [-494.984 -494.984 -494.984] (1.000)
Step: 1749, Reward: [-658.758 -658.758 -658.758] [0.0000], Avg: [-499.663 -499.663 -499.663] (1.000)
Step: 1799, Reward: [-555.004 -555.004 -555.004] [0.0000], Avg: [-501.2 -501.2 -501.2] (1.000)
Step: 1849, Reward: [-522.378 -522.378 -522.378] [0.0000], Avg: [-501.773 -501.773 -501.773] (1.000)
Step: 1899, Reward: [-554.116 -554.116 -554.116] [0.0000], Avg: [-503.15 -503.15 -503.15] (1.000)
Step: 1949, Reward: [-435.99 -435.99 -435.99] [0.0000], Avg: [-501.428 -501.428 -501.428] (1.000)
Step: 1999, Reward: [-584.735 -584.735 -584.735] [0.0000], Avg: [-503.511 -503.511 -503.511] (1.000)
Step: 2049, Reward: [-607.309 -607.309 -607.309] [0.0000], Avg: [-506.043 -506.043 -506.043] (1.000)
Step: 2099, Reward: [-533.317 -533.317 -533.317] [0.0000], Avg: [-506.692 -506.692 -506.692] (1.000)
Step: 2149, Reward: [-450.348 -450.348 -450.348] [0.0000], Avg: [-505.382 -505.382 -505.382] (1.000)
Step: 2199, Reward: [-748.308 -748.308 -748.308] [0.0000], Avg: [-510.903 -510.903 -510.903] (1.000)
Step: 2249, Reward: [-579.033 -579.033 -579.033] [0.0000], Avg: [-512.417 -512.417 -512.417] (1.000)
Step: 2299, Reward: [-650.019 -650.019 -650.019] [0.0000], Avg: [-515.408 -515.408 -515.408] (1.000)
Step: 2349, Reward: [-717.862 -717.862 -717.862] [0.0000], Avg: [-519.716 -519.716 -519.716] (1.000)
Step: 2399, Reward: [-530.428 -530.428 -530.428] [0.0000], Avg: [-519.939 -519.939 -519.939] (1.000)
Step: 2449, Reward: [-569.499 -569.499 -569.499] [0.0000], Avg: [-520.95 -520.95 -520.95] (1.000)
Step: 2499, Reward: [-541.949 -541.949 -541.949] [0.0000], Avg: [-521.37 -521.37 -521.37] (1.000)
Step: 2549, Reward: [-660.92 -660.92 -660.92] [0.0000], Avg: [-524.106 -524.106 -524.106] (1.000)
Step: 2599, Reward: [-953.645 -953.645 -953.645] [0.0000], Avg: [-532.367 -532.367 -532.367] (1.000)
Step: 2649, Reward: [-754.656 -754.656 -754.656] [0.0000], Avg: [-536.561 -536.561 -536.561] (1.000)
Step: 2699, Reward: [-819.215 -819.215 -819.215] [0.0000], Avg: [-541.795 -541.795 -541.795] (1.000)
Step: 2749, Reward: [-1037.623 -1037.623 -1037.623] [0.0000], Avg: [-550.81 -550.81 -550.81] (1.000)
Step: 2799, Reward: [-728.756 -728.756 -728.756] [0.0000], Avg: [-553.988 -553.988 -553.988] (1.000)
Step: 2849, Reward: [-956.21 -956.21 -956.21] [0.0000], Avg: [-561.044 -561.044 -561.044] (1.000)
Step: 2899, Reward: [-1192.846 -1192.846 -1192.846] [0.0000], Avg: [-571.938 -571.938 -571.938] (1.000)
Step: 2949, Reward: [-670.475 -670.475 -670.475] [0.0000], Avg: [-573.608 -573.608 -573.608] (1.000)
Step: 2999, Reward: [-771.073 -771.073 -771.073] [0.0000], Avg: [-576.899 -576.899 -576.899] (1.000)
Step: 3049, Reward: [-833.956 -833.956 -833.956] [0.0000], Avg: [-581.113 -581.113 -581.113] (1.000)
Step: 3099, Reward: [-1157.986 -1157.986 -1157.986] [0.0000], Avg: [-590.417 -590.417 -590.417] (1.000)
Step: 3149, Reward: [-822.083 -822.083 -822.083] [0.0000], Avg: [-594.095 -594.095 -594.095] (1.000)
Step: 3199, Reward: [-575.864 -575.864 -575.864] [0.0000], Avg: [-593.81 -593.81 -593.81] (1.000)
Step: 3249, Reward: [-1311.331 -1311.331 -1311.331] [0.0000], Avg: [-604.848 -604.848 -604.848] (1.000)
Step: 3299, Reward: [-1104.277 -1104.277 -1104.277] [0.0000], Avg: [-612.416 -612.416 -612.416] (1.000)
Step: 3349, Reward: [-765.135 -765.135 -765.135] [0.0000], Avg: [-614.695 -614.695 -614.695] (1.000)
Step: 3399, Reward: [-1368.539 -1368.539 -1368.539] [0.0000], Avg: [-625.781 -625.781 -625.781] (1.000)
Step: 3449, Reward: [-1205.824 -1205.824 -1205.824] [0.0000], Avg: [-634.187 -634.187 -634.187] (1.000)
Step: 3499, Reward: [-974.749 -974.749 -974.749] [0.0000], Avg: [-639.052 -639.052 -639.052] (1.000)
Step: 3549, Reward: [-1402.886 -1402.886 -1402.886] [0.0000], Avg: [-649.811 -649.811 -649.811] (1.000)
Step: 3599, Reward: [-750.012 -750.012 -750.012] [0.0000], Avg: [-651.202 -651.202 -651.202] (1.000)
Step: 3649, Reward: [-1483.069 -1483.069 -1483.069] [0.0000], Avg: [-662.598 -662.598 -662.598] (1.000)
Step: 3699, Reward: [-676.371 -676.371 -676.371] [0.0000], Avg: [-662.784 -662.784 -662.784] (1.000)
Step: 3749, Reward: [-512.734 -512.734 -512.734] [0.0000], Avg: [-660.783 -660.783 -660.783] (1.000)
Step: 3799, Reward: [-873.563 -873.563 -873.563] [0.0000], Avg: [-663.583 -663.583 -663.583] (1.000)
Step: 3849, Reward: [-759.164 -759.164 -759.164] [0.0000], Avg: [-664.824 -664.824 -664.824] (1.000)
Step: 3899, Reward: [-550.901 -550.901 -550.901] [0.0000], Avg: [-663.364 -663.364 -663.364] (1.000)
Step: 3949, Reward: [-656.133 -656.133 -656.133] [0.0000], Avg: [-663.272 -663.272 -663.272] (1.000)
Step: 3999, Reward: [-763.27 -763.27 -763.27] [0.0000], Avg: [-664.522 -664.522 -664.522] (1.000)
Step: 4049, Reward: [-1380.829 -1380.829 -1380.829] [0.0000], Avg: [-673.365 -673.365 -673.365] (1.000)
Step: 4099, Reward: [-665.23 -665.23 -665.23] [0.0000], Avg: [-673.266 -673.266 -673.266] (1.000)
Step: 4149, Reward: [-2100.254 -2100.254 -2100.254] [0.0000], Avg: [-690.459 -690.459 -690.459] (1.000)
Step: 4199, Reward: [-982.257 -982.257 -982.257] [0.0000], Avg: [-693.933 -693.933 -693.933] (1.000)
Step: 4249, Reward: [-1390.759 -1390.759 -1390.759] [0.0000], Avg: [-702.131 -702.131 -702.131] (1.000)
Step: 4299, Reward: [-958.662 -958.662 -958.662] [0.0000], Avg: [-705.114 -705.114 -705.114] (1.000)
Step: 4349, Reward: [-726.455 -726.455 -726.455] [0.0000], Avg: [-705.359 -705.359 -705.359] (1.000)
Step: 4399, Reward: [-603.155 -603.155 -603.155] [0.0000], Avg: [-704.197 -704.197 -704.197] (1.000)
Step: 4449, Reward: [-1723.209 -1723.209 -1723.209] [0.0000], Avg: [-715.647 -715.647 -715.647] (1.000)
Step: 4499, Reward: [-1523.836 -1523.836 -1523.836] [0.0000], Avg: [-724.627 -724.627 -724.627] (1.000)
Step: 4549, Reward: [-1282.453 -1282.453 -1282.453] [0.0000], Avg: [-730.757 -730.757 -730.757] (1.000)
Step: 4599, Reward: [-565.591 -565.591 -565.591] [0.0000], Avg: [-728.962 -728.962 -728.962] (1.000)
Step: 4649, Reward: [-1256.784 -1256.784 -1256.784] [0.0000], Avg: [-734.637 -734.637 -734.637] (1.000)
Step: 4699, Reward: [-427.37 -427.37 -427.37] [0.0000], Avg: [-731.368 -731.368 -731.368] (1.000)
Step: 4749, Reward: [-552.61 -552.61 -552.61] [0.0000], Avg: [-729.487 -729.487 -729.487] (1.000)
Step: 4799, Reward: [-564.96 -564.96 -564.96] [0.0000], Avg: [-727.773 -727.773 -727.773] (1.000)
Step: 4849, Reward: [-1628.28 -1628.28 -1628.28] [0.0000], Avg: [-737.056 -737.056 -737.056] (1.000)
Step: 4899, Reward: [-1476.157 -1476.157 -1476.157] [0.0000], Avg: [-744.598 -744.598 -744.598] (1.000)
Step: 4949, Reward: [-1819.748 -1819.748 -1819.748] [0.0000], Avg: [-755.458 -755.458 -755.458] (1.000)
Step: 4999, Reward: [-612.27 -612.27 -612.27] [0.0000], Avg: [-754.026 -754.026 -754.026] (1.000)
Step: 5049, Reward: [-537.386 -537.386 -537.386] [0.0000], Avg: [-751.881 -751.881 -751.881] (1.000)
Step: 5099, Reward: [-724.982 -724.982 -724.982] [0.0000], Avg: [-751.618 -751.618 -751.618] (1.000)
Step: 5149, Reward: [-501.055 -501.055 -501.055] [0.0000], Avg: [-749.185 -749.185 -749.185] (1.000)
Step: 5199, Reward: [-418.867 -418.867 -418.867] [0.0000], Avg: [-746.009 -746.009 -746.009] (1.000)
Step: 5249, Reward: [-586.278 -586.278 -586.278] [0.0000], Avg: [-744.488 -744.488 -744.488] (1.000)
Step: 5299, Reward: [-542.96 -542.96 -542.96] [0.0000], Avg: [-742.587 -742.587 -742.587] (1.000)
Step: 5349, Reward: [-650.105 -650.105 -650.105] [0.0000], Avg: [-741.722 -741.722 -741.722] (1.000)
Step: 5399, Reward: [-551.264 -551.264 -551.264] [0.0000], Avg: [-739.959 -739.959 -739.959] (1.000)
Step: 5449, Reward: [-555.405 -555.405 -555.405] [0.0000], Avg: [-738.266 -738.266 -738.266] (1.000)
Step: 5499, Reward: [-477.838 -477.838 -477.838] [0.0000], Avg: [-735.898 -735.898 -735.898] (1.000)
Step: 5549, Reward: [-362.459 -362.459 -362.459] [0.0000], Avg: [-732.534 -732.534 -732.534] (1.000)
Step: 5599, Reward: [-653.439 -653.439 -653.439] [0.0000], Avg: [-731.828 -731.828 -731.828] (1.000)
Step: 5649, Reward: [-486.643 -486.643 -486.643] [0.0000], Avg: [-729.658 -729.658 -729.658] (1.000)
Step: 5699, Reward: [-320.499 -320.499 -320.499] [0.0000], Avg: [-726.069 -726.069 -726.069] (1.000)
Step: 5749, Reward: [-847.312 -847.312 -847.312] [0.0000], Avg: [-727.123 -727.123 -727.123] (1.000)
Step: 5799, Reward: [-717.022 -717.022 -717.022] [0.0000], Avg: [-727.036 -727.036 -727.036] (1.000)
Step: 5849, Reward: [-827.837 -827.837 -827.837] [0.0000], Avg: [-727.897 -727.897 -727.897] (1.000)
Step: 5899, Reward: [-460.083 -460.083 -460.083] [0.0000], Avg: [-725.628 -725.628 -725.628] (1.000)
Step: 5949, Reward: [-621.9 -621.9 -621.9] [0.0000], Avg: [-724.756 -724.756 -724.756] (1.000)
Step: 5999, Reward: [-499.587 -499.587 -499.587] [0.0000], Avg: [-722.88 -722.88 -722.88] (1.000)
Step: 6049, Reward: [-430.974 -430.974 -430.974] [0.0000], Avg: [-720.467 -720.467 -720.467] (1.000)
Step: 6099, Reward: [-581.544 -581.544 -581.544] [0.0000], Avg: [-719.329 -719.329 -719.329] (1.000)
Step: 6149, Reward: [-465.701 -465.701 -465.701] [0.0000], Avg: [-717.267 -717.267 -717.267] (1.000)
Step: 6199, Reward: [-322.659 -322.659 -322.659] [0.0000], Avg: [-714.084 -714.084 -714.084] (1.000)
Step: 6249, Reward: [-397.434 -397.434 -397.434] [0.0000], Avg: [-711.551 -711.551 -711.551] (1.000)
Step: 6299, Reward: [-407.571 -407.571 -407.571] [0.0000], Avg: [-709.138 -709.138 -709.138] (1.000)
Step: 6349, Reward: [-410.386 -410.386 -410.386] [0.0000], Avg: [-706.786 -706.786 -706.786] (1.000)
Step: 6399, Reward: [-586.829 -586.829 -586.829] [0.0000], Avg: [-705.849 -705.849 -705.849] (1.000)
Step: 6449, Reward: [-530.842 -530.842 -530.842] [0.0000], Avg: [-704.492 -704.492 -704.492] (1.000)
Step: 6499, Reward: [-565.024 -565.024 -565.024] [0.0000], Avg: [-703.419 -703.419 -703.419] (1.000)
Step: 6549, Reward: [-779.892 -779.892 -779.892] [0.0000], Avg: [-704.003 -704.003 -704.003] (1.000)
Step: 6599, Reward: [-350.847 -350.847 -350.847] [0.0000], Avg: [-701.328 -701.328 -701.328] (1.000)
Step: 6649, Reward: [-558.427 -558.427 -558.427] [0.0000], Avg: [-700.253 -700.253 -700.253] (1.000)
Step: 6699, Reward: [-508.755 -508.755 -508.755] [0.0000], Avg: [-698.824 -698.824 -698.824] (1.000)
Step: 6749, Reward: [-504.47 -504.47 -504.47] [0.0000], Avg: [-697.385 -697.385 -697.385] (1.000)
Step: 6799, Reward: [-404.03 -404.03 -404.03] [0.0000], Avg: [-695.228 -695.228 -695.228] (1.000)
Step: 6849, Reward: [-305.343 -305.343 -305.343] [0.0000], Avg: [-692.382 -692.382 -692.382] (1.000)
Step: 6899, Reward: [-497.974 -497.974 -497.974] [0.0000], Avg: [-690.973 -690.973 -690.973] (1.000)
Step: 6949, Reward: [-417.267 -417.267 -417.267] [0.0000], Avg: [-689.004 -689.004 -689.004] (1.000)
Step: 6999, Reward: [-561.864 -561.864 -561.864] [0.0000], Avg: [-688.096 -688.096 -688.096] (1.000)
Step: 7049, Reward: [-509.484 -509.484 -509.484] [0.0000], Avg: [-686.829 -686.829 -686.829] (1.000)
Step: 7099, Reward: [-487.187 -487.187 -487.187] [0.0000], Avg: [-685.423 -685.423 -685.423] (1.000)
Step: 7149, Reward: [-555.576 -555.576 -555.576] [0.0000], Avg: [-684.515 -684.515 -684.515] (1.000)
Step: 7199, Reward: [-501.856 -501.856 -501.856] [0.0000], Avg: [-683.247 -683.247 -683.247] (1.000)
Step: 7249, Reward: [-407.724 -407.724 -407.724] [0.0000], Avg: [-681.346 -681.346 -681.346] (1.000)
Step: 7299, Reward: [-410.357 -410.357 -410.357] [0.0000], Avg: [-679.49 -679.49 -679.49] (1.000)
Step: 7349, Reward: [-579.338 -579.338 -579.338] [0.0000], Avg: [-678.809 -678.809 -678.809] (1.000)
Step: 7399, Reward: [-610.693 -610.693 -610.693] [0.0000], Avg: [-678.349 -678.349 -678.349] (1.000)
Step: 7449, Reward: [-479.407 -479.407 -479.407] [0.0000], Avg: [-677.014 -677.014 -677.014] (1.000)
Step: 7499, Reward: [-593.419 -593.419 -593.419] [0.0000], Avg: [-676.456 -676.456 -676.456] (1.000)
Step: 7549, Reward: [-428.624 -428.624 -428.624] [0.0000], Avg: [-674.815 -674.815 -674.815] (1.000)
Step: 7599, Reward: [-451.985 -451.985 -451.985] [0.0000], Avg: [-673.349 -673.349 -673.349] (1.000)
Step: 7649, Reward: [-565.594 -565.594 -565.594] [0.0000], Avg: [-672.645 -672.645 -672.645] (1.000)
Step: 7699, Reward: [-487.057 -487.057 -487.057] [0.0000], Avg: [-671.44 -671.44 -671.44] (1.000)
Step: 7749, Reward: [-392.46 -392.46 -392.46] [0.0000], Avg: [-669.64 -669.64 -669.64] (1.000)
Step: 7799, Reward: [-633.885 -633.885 -633.885] [0.0000], Avg: [-669.411 -669.411 -669.411] (1.000)
Step: 7849, Reward: [-697.305 -697.305 -697.305] [0.0000], Avg: [-669.588 -669.588 -669.588] (1.000)
Step: 7899, Reward: [-344.524 -344.524 -344.524] [0.0000], Avg: [-667.531 -667.531 -667.531] (1.000)
Step: 7949, Reward: [-634.531 -634.531 -634.531] [0.0000], Avg: [-667.323 -667.323 -667.323] (1.000)
Step: 7999, Reward: [-472.209 -472.209 -472.209] [0.0000], Avg: [-666.104 -666.104 -666.104] (1.000)
Step: 8049, Reward: [-614.628 -614.628 -614.628] [0.0000], Avg: [-665.784 -665.784 -665.784] (1.000)
Step: 8099, Reward: [-383.693 -383.693 -383.693] [0.0000], Avg: [-664.043 -664.043 -664.043] (1.000)
Step: 8149, Reward: [-577.333 -577.333 -577.333] [0.0000], Avg: [-663.511 -663.511 -663.511] (1.000)
Step: 8199, Reward: [-476.798 -476.798 -476.798] [0.0000], Avg: [-662.372 -662.372 -662.372] (1.000)
Step: 8249, Reward: [-571.574 -571.574 -571.574] [0.0000], Avg: [-661.822 -661.822 -661.822] (1.000)
Step: 8299, Reward: [-455.287 -455.287 -455.287] [0.0000], Avg: [-660.578 -660.578 -660.578] (1.000)
Step: 8349, Reward: [-568.664 -568.664 -568.664] [0.0000], Avg: [-660.027 -660.027 -660.027] (1.000)
Step: 8399, Reward: [-418.263 -418.263 -418.263] [0.0000], Avg: [-658.588 -658.588 -658.588] (1.000)
Step: 8449, Reward: [-511.37 -511.37 -511.37] [0.0000], Avg: [-657.717 -657.717 -657.717] (1.000)
Step: 8499, Reward: [-475.74 -475.74 -475.74] [0.0000], Avg: [-656.647 -656.647 -656.647] (1.000)
Step: 8549, Reward: [-439.406 -439.406 -439.406] [0.0000], Avg: [-655.376 -655.376 -655.376] (1.000)
Step: 8599, Reward: [-700.519 -700.519 -700.519] [0.0000], Avg: [-655.639 -655.639 -655.639] (1.000)
Step: 8649, Reward: [-444.082 -444.082 -444.082] [0.0000], Avg: [-654.416 -654.416 -654.416] (1.000)
Step: 8699, Reward: [-719.73 -719.73 -719.73] [0.0000], Avg: [-654.791 -654.791 -654.791] (1.000)
Step: 8749, Reward: [-487.875 -487.875 -487.875] [0.0000], Avg: [-653.838 -653.838 -653.838] (1.000)
Step: 8799, Reward: [-410.682 -410.682 -410.682] [0.0000], Avg: [-652.456 -652.456 -652.456] (1.000)
Step: 8849, Reward: [-366.605 -366.605 -366.605] [0.0000], Avg: [-650.841 -650.841 -650.841] (1.000)
Step: 8899, Reward: [-779.847 -779.847 -779.847] [0.0000], Avg: [-651.566 -651.566 -651.566] (1.000)
Step: 8949, Reward: [-435.29 -435.29 -435.29] [0.0000], Avg: [-650.358 -650.358 -650.358] (1.000)
Step: 8999, Reward: [-573.493 -573.493 -573.493] [0.0000], Avg: [-649.93 -649.93 -649.93] (1.000)
Step: 9049, Reward: [-323.281 -323.281 -323.281] [0.0000], Avg: [-648.126 -648.126 -648.126] (1.000)
Step: 9099, Reward: [-646.329 -646.329 -646.329] [0.0000], Avg: [-648.116 -648.116 -648.116] (1.000)
Step: 9149, Reward: [-788.311 -788.311 -788.311] [0.0000], Avg: [-648.882 -648.882 -648.882] (1.000)
Step: 9199, Reward: [-509.685 -509.685 -509.685] [0.0000], Avg: [-648.126 -648.126 -648.126] (1.000)
Step: 9249, Reward: [-690.348 -690.348 -690.348] [0.0000], Avg: [-648.354 -648.354 -648.354] (1.000)
Step: 9299, Reward: [-829.612 -829.612 -829.612] [0.0000], Avg: [-649.328 -649.328 -649.328] (1.000)
Step: 9349, Reward: [-696.767 -696.767 -696.767] [0.0000], Avg: [-649.582 -649.582 -649.582] (1.000)
Step: 9399, Reward: [-537.187 -537.187 -537.187] [0.0000], Avg: [-648.984 -648.984 -648.984] (1.000)
Step: 9449, Reward: [-840.426 -840.426 -840.426] [0.0000], Avg: [-649.997 -649.997 -649.997] (1.000)
Step: 9499, Reward: [-521.406 -521.406 -521.406] [0.0000], Avg: [-649.32 -649.32 -649.32] (1.000)
Step: 9549, Reward: [-681.952 -681.952 -681.952] [0.0000], Avg: [-649.491 -649.491 -649.491] (1.000)
Step: 9599, Reward: [-977.979 -977.979 -977.979] [0.0000], Avg: [-651.202 -651.202 -651.202] (1.000)
Step: 9649, Reward: [-517.945 -517.945 -517.945] [0.0000], Avg: [-650.511 -650.511 -650.511] (1.000)
Step: 9699, Reward: [-430.122 -430.122 -430.122] [0.0000], Avg: [-649.375 -649.375 -649.375] (1.000)
Step: 9749, Reward: [-725.25 -725.25 -725.25] [0.0000], Avg: [-649.765 -649.765 -649.765] (1.000)
Step: 9799, Reward: [-438.64 -438.64 -438.64] [0.0000], Avg: [-648.687 -648.687 -648.687] (1.000)
Step: 9849, Reward: [-461.893 -461.893 -461.893] [0.0000], Avg: [-647.739 -647.739 -647.739] (1.000)
Step: 9899, Reward: [-480.941 -480.941 -480.941] [0.0000], Avg: [-646.897 -646.897 -646.897] (1.000)
Step: 9949, Reward: [-1156.36 -1156.36 -1156.36] [0.0000], Avg: [-649.457 -649.457 -649.457] (1.000)
Step: 9999, Reward: [-827.047 -827.047 -827.047] [0.0000], Avg: [-650.345 -650.345 -650.345] (1.000)
Step: 10049, Reward: [-1195.674 -1195.674 -1195.674] [0.0000], Avg: [-653.058 -653.058 -653.058] (1.000)
Step: 10099, Reward: [-873.63 -873.63 -873.63] [0.0000], Avg: [-654.15 -654.15 -654.15] (1.000)
Step: 10149, Reward: [-696.993 -696.993 -696.993] [0.0000], Avg: [-654.361 -654.361 -654.361] (1.000)
Step: 10199, Reward: [-510.755 -510.755 -510.755] [0.0000], Avg: [-653.657 -653.657 -653.657] (1.000)
Step: 10249, Reward: [-592.88 -592.88 -592.88] [0.0000], Avg: [-653.36 -653.36 -653.36] (1.000)
Step: 10299, Reward: [-667.857 -667.857 -667.857] [0.0000], Avg: [-653.431 -653.431 -653.431] (1.000)
Step: 10349, Reward: [-596.042 -596.042 -596.042] [0.0000], Avg: [-653.154 -653.154 -653.154] (1.000)
Step: 10399, Reward: [-455.889 -455.889 -455.889] [0.0000], Avg: [-652.205 -652.205 -652.205] (1.000)
Step: 10449, Reward: [-701.293 -701.293 -701.293] [0.0000], Avg: [-652.44 -652.44 -652.44] (1.000)
Step: 10499, Reward: [-620.84 -620.84 -620.84] [0.0000], Avg: [-652.29 -652.29 -652.29] (1.000)
Step: 10549, Reward: [-648.43 -648.43 -648.43] [0.0000], Avg: [-652.271 -652.271 -652.271] (1.000)
Step: 10599, Reward: [-411.336 -411.336 -411.336] [0.0000], Avg: [-651.135 -651.135 -651.135] (1.000)
Step: 10649, Reward: [-516.491 -516.491 -516.491] [0.0000], Avg: [-650.503 -650.503 -650.503] (1.000)
Step: 10699, Reward: [-574.37 -574.37 -574.37] [0.0000], Avg: [-650.147 -650.147 -650.147] (1.000)
Step: 10749, Reward: [-1131.321 -1131.321 -1131.321] [0.0000], Avg: [-652.385 -652.385 -652.385] (1.000)
Step: 10799, Reward: [-810.987 -810.987 -810.987] [0.0000], Avg: [-653.119 -653.119 -653.119] (1.000)
Step: 10849, Reward: [-553.7 -553.7 -553.7] [0.0000], Avg: [-652.661 -652.661 -652.661] (1.000)
Step: 10899, Reward: [-1487.66 -1487.66 -1487.66] [0.0000], Avg: [-656.491 -656.491 -656.491] (1.000)
Step: 10949, Reward: [-690.063 -690.063 -690.063] [0.0000], Avg: [-656.645 -656.645 -656.645] (1.000)
Step: 10999, Reward: [-543.578 -543.578 -543.578] [0.0000], Avg: [-656.131 -656.131 -656.131] (1.000)
Step: 11049, Reward: [-1386.929 -1386.929 -1386.929] [0.0000], Avg: [-659.437 -659.437 -659.437] (1.000)
Step: 11099, Reward: [-405.287 -405.287 -405.287] [0.0000], Avg: [-658.293 -658.293 -658.293] (1.000)
Step: 11149, Reward: [-604.081 -604.081 -604.081] [0.0000], Avg: [-658.05 -658.05 -658.05] (1.000)
Step: 11199, Reward: [-513.027 -513.027 -513.027] [0.0000], Avg: [-657.402 -657.402 -657.402] (1.000)
Step: 11249, Reward: [-807.117 -807.117 -807.117] [0.0000], Avg: [-658.068 -658.068 -658.068] (1.000)
Step: 11299, Reward: [-567.944 -567.944 -567.944] [0.0000], Avg: [-657.669 -657.669 -657.669] (1.000)
Step: 11349, Reward: [-612.217 -612.217 -612.217] [0.0000], Avg: [-657.469 -657.469 -657.469] (1.000)
Step: 11399, Reward: [-541.53 -541.53 -541.53] [0.0000], Avg: [-656.96 -656.96 -656.96] (1.000)
Step: 11449, Reward: [-483.813 -483.813 -483.813] [0.0000], Avg: [-656.204 -656.204 -656.204] (1.000)
Step: 11499, Reward: [-392.197 -392.197 -392.197] [0.0000], Avg: [-655.056 -655.056 -655.056] (1.000)
Step: 11549, Reward: [-819.648 -819.648 -819.648] [0.0000], Avg: [-655.769 -655.769 -655.769] (1.000)
Step: 11599, Reward: [-874.252 -874.252 -874.252] [0.0000], Avg: [-656.71 -656.71 -656.71] (1.000)
Step: 11649, Reward: [-1677.231 -1677.231 -1677.231] [0.0000], Avg: [-661.09 -661.09 -661.09] (1.000)
Step: 11699, Reward: [-1182.045 -1182.045 -1182.045] [0.0000], Avg: [-663.317 -663.317 -663.317] (1.000)
Step: 11749, Reward: [-1077.685 -1077.685 -1077.685] [0.0000], Avg: [-665.08 -665.08 -665.08] (1.000)
Step: 11799, Reward: [-1316.365 -1316.365 -1316.365] [0.0000], Avg: [-667.84 -667.84 -667.84] (1.000)
Step: 11849, Reward: [-512.308 -512.308 -512.308] [0.0000], Avg: [-667.183 -667.183 -667.183] (1.000)
Step: 11899, Reward: [-1032.965 -1032.965 -1032.965] [0.0000], Avg: [-668.72 -668.72 -668.72] (1.000)
Step: 11949, Reward: [-984.07 -984.07 -984.07] [0.0000], Avg: [-670.04 -670.04 -670.04] (1.000)
Step: 11999, Reward: [-1495.654 -1495.654 -1495.654] [0.0000], Avg: [-673.48 -673.48 -673.48] (1.000)
Step: 12049, Reward: [-722.697 -722.697 -722.697] [0.0000], Avg: [-673.684 -673.684 -673.684] (1.000)
Step: 12099, Reward: [-445.139 -445.139 -445.139] [0.0000], Avg: [-672.739 -672.739 -672.739] (1.000)
Step: 12149, Reward: [-637.659 -637.659 -637.659] [0.0000], Avg: [-672.595 -672.595 -672.595] (1.000)
Step: 12199, Reward: [-687.771 -687.771 -687.771] [0.0000], Avg: [-672.657 -672.657 -672.657] (1.000)
Step: 12249, Reward: [-1602.637 -1602.637 -1602.637] [0.0000], Avg: [-676.453 -676.453 -676.453] (1.000)
Step: 12299, Reward: [-596.949 -596.949 -596.949] [0.0000], Avg: [-676.13 -676.13 -676.13] (1.000)
Step: 12349, Reward: [-922.189 -922.189 -922.189] [0.0000], Avg: [-677.126 -677.126 -677.126] (1.000)
Step: 12399, Reward: [-476.688 -476.688 -476.688] [0.0000], Avg: [-676.318 -676.318 -676.318] (1.000)
Step: 12449, Reward: [-529.723 -529.723 -529.723] [0.0000], Avg: [-675.729 -675.729 -675.729] (1.000)
Step: 12499, Reward: [-1253.43 -1253.43 -1253.43] [0.0000], Avg: [-678.04 -678.04 -678.04] (1.000)
Step: 12549, Reward: [-611.998 -611.998 -611.998] [0.0000], Avg: [-677.777 -677.777 -677.777] (1.000)
Step: 12599, Reward: [-527.887 -527.887 -527.887] [0.0000], Avg: [-677.182 -677.182 -677.182] (1.000)
Step: 12649, Reward: [-416.988 -416.988 -416.988] [0.0000], Avg: [-676.154 -676.154 -676.154] (1.000)
Step: 12699, Reward: [-695.963 -695.963 -695.963] [0.0000], Avg: [-676.232 -676.232 -676.232] (1.000)
Step: 12749, Reward: [-1005.931 -1005.931 -1005.931] [0.0000], Avg: [-677.525 -677.525 -677.525] (1.000)
Step: 12799, Reward: [-1054.368 -1054.368 -1054.368] [0.0000], Avg: [-678.997 -678.997 -678.997] (1.000)
Step: 12849, Reward: [-692.167 -692.167 -692.167] [0.0000], Avg: [-679.048 -679.048 -679.048] (1.000)
Step: 12899, Reward: [-1020.353 -1020.353 -1020.353] [0.0000], Avg: [-680.371 -680.371 -680.371] (1.000)
Step: 12949, Reward: [-436.438 -436.438 -436.438] [0.0000], Avg: [-679.429 -679.429 -679.429] (1.000)
Step: 12999, Reward: [-770.906 -770.906 -770.906] [0.0000], Avg: [-679.781 -679.781 -679.781] (1.000)
Step: 13049, Reward: [-1297.452 -1297.452 -1297.452] [0.0000], Avg: [-682.147 -682.147 -682.147] (1.000)
Step: 13099, Reward: [-537.769 -537.769 -537.769] [0.0000], Avg: [-681.596 -681.596 -681.596] (1.000)
Step: 13149, Reward: [-325.485 -325.485 -325.485] [0.0000], Avg: [-680.242 -680.242 -680.242] (1.000)
Step: 13199, Reward: [-324.935 -324.935 -324.935] [0.0000], Avg: [-678.896 -678.896 -678.896] (1.000)
Step: 13249, Reward: [-554.021 -554.021 -554.021] [0.0000], Avg: [-678.425 -678.425 -678.425] (1.000)
Step: 13299, Reward: [-536.323 -536.323 -536.323] [0.0000], Avg: [-677.891 -677.891 -677.891] (1.000)
Step: 13349, Reward: [-333.706 -333.706 -333.706] [0.0000], Avg: [-676.602 -676.602 -676.602] (1.000)
Step: 13399, Reward: [-547.296 -547.296 -547.296] [0.0000], Avg: [-676.119 -676.119 -676.119] (1.000)
Step: 13449, Reward: [-552.506 -552.506 -552.506] [0.0000], Avg: [-675.66 -675.66 -675.66] (1.000)
Step: 13499, Reward: [-531.595 -531.595 -531.595] [0.0000], Avg: [-675.126 -675.126 -675.126] (1.000)
Step: 13549, Reward: [-469.721 -469.721 -469.721] [0.0000], Avg: [-674.368 -674.368 -674.368] (1.000)
Step: 13599, Reward: [-327.193 -327.193 -327.193] [0.0000], Avg: [-673.092 -673.092 -673.092] (1.000)
Step: 13649, Reward: [-427.283 -427.283 -427.283] [0.0000], Avg: [-672.192 -672.192 -672.192] (1.000)
Step: 13699, Reward: [-354.669 -354.669 -354.669] [0.0000], Avg: [-671.033 -671.033 -671.033] (1.000)
Step: 13749, Reward: [-351.091 -351.091 -351.091] [0.0000], Avg: [-669.869 -669.869 -669.869] (1.000)
Step: 13799, Reward: [-560.466 -560.466 -560.466] [0.0000], Avg: [-669.473 -669.473 -669.473] (1.000)
Step: 13849, Reward: [-560.181 -560.181 -560.181] [0.0000], Avg: [-669.078 -669.078 -669.078] (1.000)
Step: 13899, Reward: [-459.714 -459.714 -459.714] [0.0000], Avg: [-668.325 -668.325 -668.325] (1.000)
Step: 13949, Reward: [-464.253 -464.253 -464.253] [0.0000], Avg: [-667.594 -667.594 -667.594] (1.000)
Step: 13999, Reward: [-360.752 -360.752 -360.752] [0.0000], Avg: [-666.498 -666.498 -666.498] (1.000)
Step: 14049, Reward: [-394.41 -394.41 -394.41] [0.0000], Avg: [-665.53 -665.53 -665.53] (1.000)
Step: 14099, Reward: [-427.419 -427.419 -427.419] [0.0000], Avg: [-664.685 -664.685 -664.685] (1.000)
Step: 14149, Reward: [-401.425 -401.425 -401.425] [0.0000], Avg: [-663.755 -663.755 -663.755] (1.000)
Step: 14199, Reward: [-433.075 -433.075 -433.075] [0.0000], Avg: [-662.943 -662.943 -662.943] (1.000)
Step: 14249, Reward: [-415.553 -415.553 -415.553] [0.0000], Avg: [-662.075 -662.075 -662.075] (1.000)
Step: 14299, Reward: [-732.057 -732.057 -732.057] [0.0000], Avg: [-662.319 -662.319 -662.319] (1.000)
Step: 14349, Reward: [-475.644 -475.644 -475.644] [0.0000], Avg: [-661.669 -661.669 -661.669] (1.000)
Step: 14399, Reward: [-543.95 -543.95 -543.95] [0.0000], Avg: [-661.26 -661.26 -661.26] (1.000)
Step: 14449, Reward: [-441.07 -441.07 -441.07] [0.0000], Avg: [-660.498 -660.498 -660.498] (1.000)
Step: 14499, Reward: [-549.169 -549.169 -549.169] [0.0000], Avg: [-660.114 -660.114 -660.114] (1.000)
Step: 14549, Reward: [-483.85 -483.85 -483.85] [0.0000], Avg: [-659.509 -659.509 -659.509] (1.000)
Step: 14599, Reward: [-532.367 -532.367 -532.367] [0.0000], Avg: [-659.073 -659.073 -659.073] (1.000)
Step: 14649, Reward: [-463.346 -463.346 -463.346] [0.0000], Avg: [-658.405 -658.405 -658.405] (1.000)
Step: 14699, Reward: [-362.041 -362.041 -362.041] [0.0000], Avg: [-657.397 -657.397 -657.397] (1.000)
Step: 14749, Reward: [-490.203 -490.203 -490.203] [0.0000], Avg: [-656.83 -656.83 -656.83] (1.000)
Step: 14799, Reward: [-480.045 -480.045 -480.045] [0.0000], Avg: [-656.233 -656.233 -656.233] (1.000)
Step: 14849, Reward: [-427.917 -427.917 -427.917] [0.0000], Avg: [-655.464 -655.464 -655.464] (1.000)
Step: 14899, Reward: [-317.254 -317.254 -317.254] [0.0000], Avg: [-654.33 -654.33 -654.33] (1.000)
Step: 14949, Reward: [-492.174 -492.174 -492.174] [0.0000], Avg: [-653.787 -653.787 -653.787] (1.000)
Step: 14999, Reward: [-541.69 -541.69 -541.69] [0.0000], Avg: [-653.414 -653.414 -653.414] (1.000)
Step: 15049, Reward: [-457.228 -457.228 -457.228] [0.0000], Avg: [-652.762 -652.762 -652.762] (1.000)
Step: 15099, Reward: [-419.064 -419.064 -419.064] [0.0000], Avg: [-651.988 -651.988 -651.988] (1.000)
Step: 15149, Reward: [-401.05 -401.05 -401.05] [0.0000], Avg: [-651.16 -651.16 -651.16] (1.000)
Step: 15199, Reward: [-486.132 -486.132 -486.132] [0.0000], Avg: [-650.617 -650.617 -650.617] (1.000)
Step: 15249, Reward: [-535.451 -535.451 -535.451] [0.0000], Avg: [-650.239 -650.239 -650.239] (1.000)
Step: 15299, Reward: [-537.121 -537.121 -537.121] [0.0000], Avg: [-649.87 -649.87 -649.87] (1.000)
Step: 15349, Reward: [-639.046 -639.046 -639.046] [0.0000], Avg: [-649.834 -649.834 -649.834] (1.000)
Step: 15399, Reward: [-414.827 -414.827 -414.827] [0.0000], Avg: [-649.071 -649.071 -649.071] (1.000)
Step: 15449, Reward: [-436.631 -436.631 -436.631] [0.0000], Avg: [-648.384 -648.384 -648.384] (1.000)
Step: 15499, Reward: [-415.728 -415.728 -415.728] [0.0000], Avg: [-647.633 -647.633 -647.633] (1.000)
Step: 15549, Reward: [-763.334 -763.334 -763.334] [0.0000], Avg: [-648.005 -648.005 -648.005] (1.000)
Step: 15599, Reward: [-780.078 -780.078 -780.078] [0.0000], Avg: [-648.429 -648.429 -648.429] (1.000)
Step: 15649, Reward: [-818.863 -818.863 -818.863] [0.0000], Avg: [-648.973 -648.973 -648.973] (1.000)
Step: 15699, Reward: [-585.596 -585.596 -585.596] [0.0000], Avg: [-648.771 -648.771 -648.771] (1.000)
Step: 15749, Reward: [-639.974 -639.974 -639.974] [0.0000], Avg: [-648.743 -648.743 -648.743] (1.000)
Step: 15799, Reward: [-469.775 -469.775 -469.775] [0.0000], Avg: [-648.177 -648.177 -648.177] (1.000)
Step: 15849, Reward: [-301.103 -301.103 -301.103] [0.0000], Avg: [-647.082 -647.082 -647.082] (1.000)
Step: 15899, Reward: [-722.495 -722.495 -722.495] [0.0000], Avg: [-647.319 -647.319 -647.319] (1.000)
Step: 15949, Reward: [-601.008 -601.008 -601.008] [0.0000], Avg: [-647.174 -647.174 -647.174] (1.000)
Step: 15999, Reward: [-650.504 -650.504 -650.504] [0.0000], Avg: [-647.185 -647.185 -647.185] (1.000)
Step: 16049, Reward: [-344.661 -344.661 -344.661] [0.0000], Avg: [-646.242 -646.242 -646.242] (1.000)
Step: 16099, Reward: [-699.21 -699.21 -699.21] [0.0000], Avg: [-646.407 -646.407 -646.407] (1.000)
Step: 16149, Reward: [-402.517 -402.517 -402.517] [0.0000], Avg: [-645.652 -645.652 -645.652] (1.000)
Step: 16199, Reward: [-471.604 -471.604 -471.604] [0.0000], Avg: [-645.114 -645.114 -645.114] (1.000)
Step: 16249, Reward: [-472.281 -472.281 -472.281] [0.0000], Avg: [-644.583 -644.583 -644.583] (1.000)
Step: 16299, Reward: [-691.972 -691.972 -691.972] [0.0000], Avg: [-644.728 -644.728 -644.728] (1.000)
Step: 16349, Reward: [-616.649 -616.649 -616.649] [0.0000], Avg: [-644.642 -644.642 -644.642] (1.000)
Step: 16399, Reward: [-437.771 -437.771 -437.771] [0.0000], Avg: [-644.011 -644.011 -644.011] (1.000)
Step: 16449, Reward: [-487.772 -487.772 -487.772] [0.0000], Avg: [-643.537 -643.537 -643.537] (1.000)
Step: 16499, Reward: [-596.873 -596.873 -596.873] [0.0000], Avg: [-643.395 -643.395 -643.395] (1.000)
Step: 16549, Reward: [-684.414 -684.414 -684.414] [0.0000], Avg: [-643.519 -643.519 -643.519] (1.000)
Step: 16599, Reward: [-466.837 -466.837 -466.837] [0.0000], Avg: [-642.987 -642.987 -642.987] (1.000)
Step: 16649, Reward: [-784.361 -784.361 -784.361] [0.0000], Avg: [-643.411 -643.411 -643.411] (1.000)
Step: 16699, Reward: [-752.795 -752.795 -752.795] [0.0000], Avg: [-643.739 -643.739 -643.739] (1.000)
Step: 16749, Reward: [-440.165 -440.165 -440.165] [0.0000], Avg: [-643.131 -643.131 -643.131] (1.000)
Step: 16799, Reward: [-490.551 -490.551 -490.551] [0.0000], Avg: [-642.677 -642.677 -642.677] (1.000)
Step: 16849, Reward: [-551.949 -551.949 -551.949] [0.0000], Avg: [-642.408 -642.408 -642.408] (1.000)
Step: 16899, Reward: [-615.435 -615.435 -615.435] [0.0000], Avg: [-642.328 -642.328 -642.328] (1.000)
Step: 16949, Reward: [-712.911 -712.911 -712.911] [0.0000], Avg: [-642.536 -642.536 -642.536] (1.000)
Step: 16999, Reward: [-466.672 -466.672 -466.672] [0.0000], Avg: [-642.019 -642.019 -642.019] (1.000)
Step: 17049, Reward: [-527.846 -527.846 -527.846] [0.0000], Avg: [-641.684 -641.684 -641.684] (1.000)
Step: 17099, Reward: [-936.211 -936.211 -936.211] [0.0000], Avg: [-642.545 -642.545 -642.545] (1.000)
Step: 17149, Reward: [-873.634 -873.634 -873.634] [0.0000], Avg: [-643.219 -643.219 -643.219] (1.000)
Step: 17199, Reward: [-502.594 -502.594 -502.594] [0.0000], Avg: [-642.81 -642.81 -642.81] (1.000)
Step: 17249, Reward: [-507.963 -507.963 -507.963] [0.0000], Avg: [-642.419 -642.419 -642.419] (1.000)
Step: 17299, Reward: [-591.681 -591.681 -591.681] [0.0000], Avg: [-642.273 -642.273 -642.273] (1.000)
Step: 17349, Reward: [-542.421 -542.421 -542.421] [0.0000], Avg: [-641.985 -641.985 -641.985] (1.000)
Step: 17399, Reward: [-605.116 -605.116 -605.116] [0.0000], Avg: [-641.879 -641.879 -641.879] (1.000)
Step: 17449, Reward: [-458.389 -458.389 -458.389] [0.0000], Avg: [-641.353 -641.353 -641.353] (1.000)
Step: 17499, Reward: [-543.1 -543.1 -543.1] [0.0000], Avg: [-641.073 -641.073 -641.073] (1.000)
Step: 17549, Reward: [-409.983 -409.983 -409.983] [0.0000], Avg: [-640.414 -640.414 -640.414] (1.000)
Step: 17599, Reward: [-546.247 -546.247 -546.247] [0.0000], Avg: [-640.147 -640.147 -640.147] (1.000)
Step: 17649, Reward: [-783.518 -783.518 -783.518] [0.0000], Avg: [-640.553 -640.553 -640.553] (1.000)
Step: 17699, Reward: [-688.377 -688.377 -688.377] [0.0000], Avg: [-640.688 -640.688 -640.688] (1.000)
Step: 17749, Reward: [-625.014 -625.014 -625.014] [0.0000], Avg: [-640.644 -640.644 -640.644] (1.000)
Step: 17799, Reward: [-562.845 -562.845 -562.845] [0.0000], Avg: [-640.425 -640.425 -640.425] (1.000)
Step: 17849, Reward: [-554.858 -554.858 -554.858] [0.0000], Avg: [-640.186 -640.186 -640.186] (1.000)
Step: 17899, Reward: [-428.675 -428.675 -428.675] [0.0000], Avg: [-639.595 -639.595 -639.595] (1.000)
Step: 17949, Reward: [-807.051 -807.051 -807.051] [0.0000], Avg: [-640.061 -640.061 -640.061] (1.000)
Step: 17999, Reward: [-654.434 -654.434 -654.434] [0.0000], Avg: [-640.101 -640.101 -640.101] (1.000)
Step: 18049, Reward: [-664.533 -664.533 -664.533] [0.0000], Avg: [-640.169 -640.169 -640.169] (1.000)
Step: 18099, Reward: [-470.36 -470.36 -470.36] [0.0000], Avg: [-639.7 -639.7 -639.7] (1.000)
Step: 18149, Reward: [-766.81 -766.81 -766.81] [0.0000], Avg: [-640.05 -640.05 -640.05] (1.000)
Step: 18199, Reward: [-496.598 -496.598 -496.598] [0.0000], Avg: [-639.656 -639.656 -639.656] (1.000)
Step: 18249, Reward: [-482.985 -482.985 -482.985] [0.0000], Avg: [-639.227 -639.227 -639.227] (1.000)
Step: 18299, Reward: [-554.269 -554.269 -554.269] [0.0000], Avg: [-638.995 -638.995 -638.995] (1.000)
Step: 18349, Reward: [-638.075 -638.075 -638.075] [0.0000], Avg: [-638.992 -638.992 -638.992] (1.000)
Step: 18399, Reward: [-451.239 -451.239 -451.239] [0.0000], Avg: [-638.482 -638.482 -638.482] (1.000)
Step: 18449, Reward: [-659.517 -659.517 -659.517] [0.0000], Avg: [-638.539 -638.539 -638.539] (1.000)
Step: 18499, Reward: [-324.74 -324.74 -324.74] [0.0000], Avg: [-637.691 -637.691 -637.691] (1.000)
Step: 18549, Reward: [-481.936 -481.936 -481.936] [0.0000], Avg: [-637.271 -637.271 -637.271] (1.000)
Step: 18599, Reward: [-469.478 -469.478 -469.478] [0.0000], Avg: [-636.82 -636.82 -636.82] (1.000)
Step: 18649, Reward: [-372.32 -372.32 -372.32] [0.0000], Avg: [-636.111 -636.111 -636.111] (1.000)
Step: 18699, Reward: [-358.307 -358.307 -358.307] [0.0000], Avg: [-635.368 -635.368 -635.368] (1.000)
Step: 18749, Reward: [-343.324 -343.324 -343.324] [0.0000], Avg: [-634.589 -634.589 -634.589] (1.000)
Step: 18799, Reward: [-598.263 -598.263 -598.263] [0.0000], Avg: [-634.493 -634.493 -634.493] (1.000)
Step: 18849, Reward: [-472.587 -472.587 -472.587] [0.0000], Avg: [-634.063 -634.063 -634.063] (1.000)
Step: 18899, Reward: [-666.755 -666.755 -666.755] [0.0000], Avg: [-634.15 -634.15 -634.15] (1.000)
Step: 18949, Reward: [-466.655 -466.655 -466.655] [0.0000], Avg: [-633.708 -633.708 -633.708] (1.000)
Step: 18999, Reward: [-354.355 -354.355 -354.355] [0.0000], Avg: [-632.972 -632.972 -632.972] (1.000)
Step: 19049, Reward: [-476.152 -476.152 -476.152] [0.0000], Avg: [-632.561 -632.561 -632.561] (1.000)
Step: 19099, Reward: [-323.937 -323.937 -323.937] [0.0000], Avg: [-631.753 -631.753 -631.753] (1.000)
Step: 19149, Reward: [-689.823 -689.823 -689.823] [0.0000], Avg: [-631.905 -631.905 -631.905] (1.000)
Step: 19199, Reward: [-523.779 -523.779 -523.779] [0.0000], Avg: [-631.623 -631.623 -631.623] (1.000)
Step: 19249, Reward: [-422.319 -422.319 -422.319] [0.0000], Avg: [-631.079 -631.079 -631.079] (1.000)
Step: 19299, Reward: [-319.003 -319.003 -319.003] [0.0000], Avg: [-630.271 -630.271 -630.271] (1.000)
Step: 19349, Reward: [-433.118 -433.118 -433.118] [0.0000], Avg: [-629.761 -629.761 -629.761] (1.000)
Step: 19399, Reward: [-578.315 -578.315 -578.315] [0.0000], Avg: [-629.629 -629.629 -629.629] (1.000)
Step: 19449, Reward: [-396.163 -396.163 -396.163] [0.0000], Avg: [-629.029 -629.029 -629.029] (1.000)
Step: 19499, Reward: [-381.16 -381.16 -381.16] [0.0000], Avg: [-628.393 -628.393 -628.393] (1.000)
Step: 19549, Reward: [-531.627 -531.627 -531.627] [0.0000], Avg: [-628.146 -628.146 -628.146] (1.000)
Step: 19599, Reward: [-541.182 -541.182 -541.182] [0.0000], Avg: [-627.924 -627.924 -627.924] (1.000)
Step: 19649, Reward: [-562.257 -562.257 -562.257] [0.0000], Avg: [-627.757 -627.757 -627.757] (1.000)
Step: 19699, Reward: [-375.525 -375.525 -375.525] [0.0000], Avg: [-627.116 -627.116 -627.116] (1.000)
Step: 19749, Reward: [-338.958 -338.958 -338.958] [0.0000], Avg: [-626.387 -626.387 -626.387] (1.000)
Step: 19799, Reward: [-490.906 -490.906 -490.906] [0.0000], Avg: [-626.045 -626.045 -626.045] (1.000)
Step: 19849, Reward: [-427.366 -427.366 -427.366] [0.0000], Avg: [-625.544 -625.544 -625.544] (1.000)
Step: 19899, Reward: [-304.088 -304.088 -304.088] [0.0000], Avg: [-624.737 -624.737 -624.737] (1.000)
Step: 19949, Reward: [-402.343 -402.343 -402.343] [0.0000], Avg: [-624.179 -624.179 -624.179] (1.000)
Step: 19999, Reward: [-418.722 -418.722 -418.722] [0.0000], Avg: [-623.666 -623.666 -623.666] (1.000)
Step: 20049, Reward: [-377.276 -377.276 -377.276] [0.0000], Avg: [-623.051 -623.051 -623.051] (1.000)
Step: 20099, Reward: [-468.252 -468.252 -468.252] [0.0000], Avg: [-622.666 -622.666 -622.666] (1.000)
Step: 20149, Reward: [-455.117 -455.117 -455.117] [0.0000], Avg: [-622.25 -622.25 -622.25] (1.000)
Step: 20199, Reward: [-539.569 -539.569 -539.569] [0.0000], Avg: [-622.046 -622.046 -622.046] (1.000)
Step: 20249, Reward: [-487.945 -487.945 -487.945] [0.0000], Avg: [-621.715 -621.715 -621.715] (1.000)
Step: 20299, Reward: [-370.751 -370.751 -370.751] [0.0000], Avg: [-621.097 -621.097 -621.097] (1.000)
Step: 20349, Reward: [-439.636 -439.636 -439.636] [0.0000], Avg: [-620.651 -620.651 -620.651] (1.000)
Step: 20399, Reward: [-367.986 -367.986 -367.986] [0.0000], Avg: [-620.031 -620.031 -620.031] (1.000)
Step: 20449, Reward: [-457.216 -457.216 -457.216] [0.0000], Avg: [-619.633 -619.633 -619.633] (1.000)
Step: 20499, Reward: [-397.183 -397.183 -397.183] [0.0000], Avg: [-619.091 -619.091 -619.091] (1.000)
Step: 20549, Reward: [-476.384 -476.384 -476.384] [0.0000], Avg: [-618.744 -618.744 -618.744] (1.000)
Step: 20599, Reward: [-514.656 -514.656 -514.656] [0.0000], Avg: [-618.491 -618.491 -618.491] (1.000)
Step: 20649, Reward: [-479.488 -479.488 -479.488] [0.0000], Avg: [-618.154 -618.154 -618.154] (1.000)
Step: 20699, Reward: [-658.293 -658.293 -658.293] [0.0000], Avg: [-618.251 -618.251 -618.251] (1.000)
Step: 20749, Reward: [-412.542 -412.542 -412.542] [0.0000], Avg: [-617.756 -617.756 -617.756] (1.000)
Step: 20799, Reward: [-487.8 -487.8 -487.8] [0.0000], Avg: [-617.443 -617.443 -617.443] (1.000)
Step: 20849, Reward: [-426.508 -426.508 -426.508] [0.0000], Avg: [-616.985 -616.985 -616.985] (1.000)
Step: 20899, Reward: [-457.641 -457.641 -457.641] [0.0000], Avg: [-616.604 -616.604 -616.604] (1.000)
Step: 20949, Reward: [-471.24 -471.24 -471.24] [0.0000], Avg: [-616.257 -616.257 -616.257] (1.000)
Step: 20999, Reward: [-382.408 -382.408 -382.408] [0.0000], Avg: [-615.7 -615.7 -615.7] (1.000)
Step: 21049, Reward: [-497.437 -497.437 -497.437] [0.0000], Avg: [-615.42 -615.42 -615.42] (1.000)
Step: 21099, Reward: [-387.911 -387.911 -387.911] [0.0000], Avg: [-614.88 -614.88 -614.88] (1.000)
Step: 21149, Reward: [-497.819 -497.819 -497.819] [0.0000], Avg: [-614.604 -614.604 -614.604] (1.000)
Step: 21199, Reward: [-504.545 -504.545 -504.545] [0.0000], Avg: [-614.344 -614.344 -614.344] (1.000)
Step: 21249, Reward: [-380.463 -380.463 -380.463] [0.0000], Avg: [-613.794 -613.794 -613.794] (1.000)
Step: 21299, Reward: [-393.174 -393.174 -393.174] [0.0000], Avg: [-613.276 -613.276 -613.276] (1.000)
Step: 21349, Reward: [-369.085 -369.085 -369.085] [0.0000], Avg: [-612.704 -612.704 -612.704] (1.000)
Step: 21399, Reward: [-338.53 -338.53 -338.53] [0.0000], Avg: [-612.063 -612.063 -612.063] (1.000)
Step: 21449, Reward: [-421.251 -421.251 -421.251] [0.0000], Avg: [-611.619 -611.619 -611.619] (1.000)
Step: 21499, Reward: [-557.867 -557.867 -557.867] [0.0000], Avg: [-611.494 -611.494 -611.494] (1.000)
Step: 21549, Reward: [-434.502 -434.502 -434.502] [0.0000], Avg: [-611.083 -611.083 -611.083] (1.000)
Step: 21599, Reward: [-652.62 -652.62 -652.62] [0.0000], Avg: [-611.179 -611.179 -611.179] (1.000)
Step: 21649, Reward: [-441.604 -441.604 -441.604] [0.0000], Avg: [-610.787 -610.787 -610.787] (1.000)
Step: 21699, Reward: [-432.184 -432.184 -432.184] [0.0000], Avg: [-610.376 -610.376 -610.376] (1.000)
Step: 21749, Reward: [-557.748 -557.748 -557.748] [0.0000], Avg: [-610.255 -610.255 -610.255] (1.000)
Step: 21799, Reward: [-535.238 -535.238 -535.238] [0.0000], Avg: [-610.083 -610.083 -610.083] (1.000)
Step: 21849, Reward: [-427.853 -427.853 -427.853] [0.0000], Avg: [-609.666 -609.666 -609.666] (1.000)
Step: 21899, Reward: [-488.841 -488.841 -488.841] [0.0000], Avg: [-609.39 -609.39 -609.39] (1.000)
Step: 21949, Reward: [-534.888 -534.888 -534.888] [0.0000], Avg: [-609.22 -609.22 -609.22] (1.000)
Step: 21999, Reward: [-437.823 -437.823 -437.823] [0.0000], Avg: [-608.831 -608.831 -608.831] (1.000)
Step: 22049, Reward: [-523.903 -523.903 -523.903] [0.0000], Avg: [-608.638 -608.638 -608.638] (1.000)
Step: 22099, Reward: [-503.319 -503.319 -503.319] [0.0000], Avg: [-608.4 -608.4 -608.4] (1.000)
Step: 22149, Reward: [-494.896 -494.896 -494.896] [0.0000], Avg: [-608.144 -608.144 -608.144] (1.000)
Step: 22199, Reward: [-374.612 -374.612 -374.612] [0.0000], Avg: [-607.618 -607.618 -607.618] (1.000)
Step: 22249, Reward: [-469.84 -469.84 -469.84] [0.0000], Avg: [-607.308 -607.308 -607.308] (1.000)
Step: 22299, Reward: [-509.533 -509.533 -509.533] [0.0000], Avg: [-607.089 -607.089 -607.089] (1.000)
Step: 22349, Reward: [-809.295 -809.295 -809.295] [0.0000], Avg: [-607.541 -607.541 -607.541] (1.000)
Step: 22399, Reward: [-634.464 -634.464 -634.464] [0.0000], Avg: [-607.601 -607.601 -607.601] (1.000)
Step: 22449, Reward: [-482.921 -482.921 -482.921] [0.0000], Avg: [-607.324 -607.324 -607.324] (1.000)
Step: 22499, Reward: [-941.564 -941.564 -941.564] [0.0000], Avg: [-608.066 -608.066 -608.066] (1.000)
Step: 22549, Reward: [-661.239 -661.239 -661.239] [0.0000], Avg: [-608.184 -608.184 -608.184] (1.000)
Step: 22599, Reward: [-671.993 -671.993 -671.993] [0.0000], Avg: [-608.326 -608.326 -608.326] (1.000)
Step: 22649, Reward: [-595.982 -595.982 -595.982] [0.0000], Avg: [-608.298 -608.298 -608.298] (1.000)
Step: 22699, Reward: [-432.172 -432.172 -432.172] [0.0000], Avg: [-607.91 -607.91 -607.91] (1.000)
Step: 22749, Reward: [-365.195 -365.195 -365.195] [0.0000], Avg: [-607.377 -607.377 -607.377] (1.000)
Step: 22799, Reward: [-574.172 -574.172 -574.172] [0.0000], Avg: [-607.304 -607.304 -607.304] (1.000)
Step: 22849, Reward: [-367.064 -367.064 -367.064] [0.0000], Avg: [-606.778 -606.778 -606.778] (1.000)
Step: 22899, Reward: [-507.71 -507.71 -507.71] [0.0000], Avg: [-606.562 -606.562 -606.562] (1.000)
Step: 22949, Reward: [-398.649 -398.649 -398.649] [0.0000], Avg: [-606.109 -606.109 -606.109] (1.000)
Step: 22999, Reward: [-465.293 -465.293 -465.293] [0.0000], Avg: [-605.803 -605.803 -605.803] (1.000)
Step: 23049, Reward: [-497.285 -497.285 -497.285] [0.0000], Avg: [-605.568 -605.568 -605.568] (1.000)
Step: 23099, Reward: [-457.87 -457.87 -457.87] [0.0000], Avg: [-605.248 -605.248 -605.248] (1.000)
Step: 23149, Reward: [-365.867 -365.867 -365.867] [0.0000], Avg: [-604.731 -604.731 -604.731] (1.000)
Step: 23199, Reward: [-552.445 -552.445 -552.445] [0.0000], Avg: [-604.618 -604.618 -604.618] (1.000)
Step: 23249, Reward: [-596.265 -596.265 -596.265] [0.0000], Avg: [-604.6 -604.6 -604.6] (1.000)
Step: 23299, Reward: [-535.931 -535.931 -535.931] [0.0000], Avg: [-604.453 -604.453 -604.453] (1.000)
Step: 23349, Reward: [-740.233 -740.233 -740.233] [0.0000], Avg: [-604.744 -604.744 -604.744] (1.000)
Step: 23399, Reward: [-396.228 -396.228 -396.228] [0.0000], Avg: [-604.298 -604.298 -604.298] (1.000)
Step: 23449, Reward: [-543.797 -543.797 -543.797] [0.0000], Avg: [-604.169 -604.169 -604.169] (1.000)
Step: 23499, Reward: [-484.513 -484.513 -484.513] [0.0000], Avg: [-603.914 -603.914 -603.914] (1.000)
Step: 23549, Reward: [-574.019 -574.019 -574.019] [0.0000], Avg: [-603.851 -603.851 -603.851] (1.000)
Step: 23599, Reward: [-416.855 -416.855 -416.855] [0.0000], Avg: [-603.455 -603.455 -603.455] (1.000)
Step: 23649, Reward: [-283.468 -283.468 -283.468] [0.0000], Avg: [-602.778 -602.778 -602.778] (1.000)
Step: 23699, Reward: [-537.339 -537.339 -537.339] [0.0000], Avg: [-602.64 -602.64 -602.64] (1.000)
Step: 23749, Reward: [-581.553 -581.553 -581.553] [0.0000], Avg: [-602.596 -602.596 -602.596] (1.000)
Step: 23799, Reward: [-415.107 -415.107 -415.107] [0.0000], Avg: [-602.202 -602.202 -602.202] (1.000)
Step: 23849, Reward: [-427.61 -427.61 -427.61] [0.0000], Avg: [-601.836 -601.836 -601.836] (1.000)
Step: 23899, Reward: [-633.355 -633.355 -633.355] [0.0000], Avg: [-601.902 -601.902 -601.902] (1.000)
Step: 23949, Reward: [-405.3 -405.3 -405.3] [0.0000], Avg: [-601.491 -601.491 -601.491] (1.000)
Step: 23999, Reward: [-421.336 -421.336 -421.336] [0.0000], Avg: [-601.116 -601.116 -601.116] (1.000)
Step: 24049, Reward: [-559.471 -559.471 -559.471] [0.0000], Avg: [-601.03 -601.03 -601.03] (1.000)
Step: 24099, Reward: [-467.513 -467.513 -467.513] [0.0000], Avg: [-600.753 -600.753 -600.753] (1.000)
Step: 24149, Reward: [-452.404 -452.404 -452.404] [0.0000], Avg: [-600.445 -600.445 -600.445] (1.000)
Step: 24199, Reward: [-492.854 -492.854 -492.854] [0.0000], Avg: [-600.223 -600.223 -600.223] (1.000)
Step: 24249, Reward: [-459.964 -459.964 -459.964] [0.0000], Avg: [-599.934 -599.934 -599.934] (1.000)
Step: 24299, Reward: [-469.698 -469.698 -469.698] [0.0000], Avg: [-599.666 -599.666 -599.666] (1.000)
Step: 24349, Reward: [-469.065 -469.065 -469.065] [0.0000], Avg: [-599.398 -599.398 -599.398] (1.000)
Step: 24399, Reward: [-456.531 -456.531 -456.531] [0.0000], Avg: [-599.105 -599.105 -599.105] (1.000)
Step: 24449, Reward: [-577.569 -577.569 -577.569] [0.0000], Avg: [-599.061 -599.061 -599.061] (1.000)
Step: 24499, Reward: [-375.509 -375.509 -375.509] [0.0000], Avg: [-598.605 -598.605 -598.605] (1.000)
Step: 24549, Reward: [-511.625 -511.625 -511.625] [0.0000], Avg: [-598.428 -598.428 -598.428] (1.000)
Step: 24599, Reward: [-468.101 -468.101 -468.101] [0.0000], Avg: [-598.163 -598.163 -598.163] (1.000)
Step: 24649, Reward: [-389.599 -389.599 -389.599] [0.0000], Avg: [-597.74 -597.74 -597.74] (1.000)
Step: 24699, Reward: [-753.131 -753.131 -753.131] [0.0000], Avg: [-598.054 -598.054 -598.054] (1.000)
Step: 24749, Reward: [-486.22 -486.22 -486.22] [0.0000], Avg: [-597.828 -597.828 -597.828] (1.000)
Step: 24799, Reward: [-439.608 -439.608 -439.608] [0.0000], Avg: [-597.509 -597.509 -597.509] (1.000)
Step: 24849, Reward: [-501.717 -501.717 -501.717] [0.0000], Avg: [-597.317 -597.317 -597.317] (1.000)
Step: 24899, Reward: [-431.098 -431.098 -431.098] [0.0000], Avg: [-596.983 -596.983 -596.983] (1.000)
Step: 24949, Reward: [-449.641 -449.641 -449.641] [0.0000], Avg: [-596.688 -596.688 -596.688] (1.000)
Step: 24999, Reward: [-465.853 -465.853 -465.853] [0.0000], Avg: [-596.426 -596.426 -596.426] (1.000)
Step: 25049, Reward: [-419.991 -419.991 -419.991] [0.0000], Avg: [-596.074 -596.074 -596.074] (1.000)
Step: 25099, Reward: [-511.526 -511.526 -511.526] [0.0000], Avg: [-595.905 -595.905 -595.905] (1.000)
Step: 25149, Reward: [-446.375 -446.375 -446.375] [0.0000], Avg: [-595.608 -595.608 -595.608] (1.000)
Step: 25199, Reward: [-433.354 -433.354 -433.354] [0.0000], Avg: [-595.286 -595.286 -595.286] (1.000)
Step: 25249, Reward: [-331.964 -331.964 -331.964] [0.0000], Avg: [-594.765 -594.765 -594.765] (1.000)
Step: 25299, Reward: [-349.947 -349.947 -349.947] [0.0000], Avg: [-594.281 -594.281 -594.281] (1.000)
Step: 25349, Reward: [-355.649 -355.649 -355.649] [0.0000], Avg: [-593.81 -593.81 -593.81] (1.000)
Step: 25399, Reward: [-552.676 -552.676 -552.676] [0.0000], Avg: [-593.729 -593.729 -593.729] (1.000)
Step: 25449, Reward: [-412.387 -412.387 -412.387] [0.0000], Avg: [-593.373 -593.373 -593.373] (1.000)
Step: 25499, Reward: [-407.247 -407.247 -407.247] [0.0000], Avg: [-593.008 -593.008 -593.008] (1.000)
Step: 25549, Reward: [-588.343 -588.343 -588.343] [0.0000], Avg: [-592.999 -592.999 -592.999] (1.000)
Step: 25599, Reward: [-487.962 -487.962 -487.962] [0.0000], Avg: [-592.794 -592.794 -592.794] (1.000)
Step: 25649, Reward: [-476.339 -476.339 -476.339] [0.0000], Avg: [-592.567 -592.567 -592.567] (1.000)
Step: 25699, Reward: [-354.907 -354.907 -354.907] [0.0000], Avg: [-592.104 -592.104 -592.104] (1.000)
Step: 25749, Reward: [-434.659 -434.659 -434.659] [0.0000], Avg: [-591.799 -591.799 -591.799] (1.000)
Step: 25799, Reward: [-505.014 -505.014 -505.014] [0.0000], Avg: [-591.63 -591.63 -591.63] (1.000)
Step: 25849, Reward: [-334.808 -334.808 -334.808] [0.0000], Avg: [-591.134 -591.134 -591.134] (1.000)
Step: 25899, Reward: [-333.938 -333.938 -333.938] [0.0000], Avg: [-590.637 -590.637 -590.637] (1.000)
Step: 25949, Reward: [-570.886 -570.886 -570.886] [0.0000], Avg: [-590.599 -590.599 -590.599] (1.000)
Step: 25999, Reward: [-532.222 -532.222 -532.222] [0.0000], Avg: [-590.487 -590.487 -590.487] (1.000)
Step: 26049, Reward: [-405.654 -405.654 -405.654] [0.0000], Avg: [-590.132 -590.132 -590.132] (1.000)
Step: 26099, Reward: [-399.204 -399.204 -399.204] [0.0000], Avg: [-589.766 -589.766 -589.766] (1.000)
Step: 26149, Reward: [-428.676 -428.676 -428.676] [0.0000], Avg: [-589.458 -589.458 -589.458] (1.000)
Step: 26199, Reward: [-548.345 -548.345 -548.345] [0.0000], Avg: [-589.38 -589.38 -589.38] (1.000)
Step: 26249, Reward: [-327.495 -327.495 -327.495] [0.0000], Avg: [-588.881 -588.881 -588.881] (1.000)
Step: 26299, Reward: [-471.536 -471.536 -471.536] [0.0000], Avg: [-588.658 -588.658 -588.658] (1.000)
Step: 26349, Reward: [-380.989 -380.989 -380.989] [0.0000], Avg: [-588.264 -588.264 -588.264] (1.000)
Step: 26399, Reward: [-366.589 -366.589 -366.589] [0.0000], Avg: [-587.844 -587.844 -587.844] (1.000)
Step: 26449, Reward: [-545.624 -545.624 -545.624] [0.0000], Avg: [-587.764 -587.764 -587.764] (1.000)
Step: 26499, Reward: [-379.782 -379.782 -379.782] [0.0000], Avg: [-587.372 -587.372 -587.372] (1.000)
Step: 26549, Reward: [-501.413 -501.413 -501.413] [0.0000], Avg: [-587.21 -587.21 -587.21] (1.000)
Step: 26599, Reward: [-668.552 -668.552 -668.552] [0.0000], Avg: [-587.363 -587.363 -587.363] (1.000)
Step: 26649, Reward: [-407.102 -407.102 -407.102] [0.0000], Avg: [-587.025 -587.025 -587.025] (1.000)
Step: 26699, Reward: [-444.817 -444.817 -444.817] [0.0000], Avg: [-586.758 -586.758 -586.758] (1.000)
Step: 26749, Reward: [-557.637 -557.637 -557.637] [0.0000], Avg: [-586.704 -586.704 -586.704] (1.000)
Step: 26799, Reward: [-460.384 -460.384 -460.384] [0.0000], Avg: [-586.468 -586.468 -586.468] (1.000)
Step: 26849, Reward: [-472.563 -472.563 -472.563] [0.0000], Avg: [-586.256 -586.256 -586.256] (1.000)
Step: 26899, Reward: [-467.198 -467.198 -467.198] [0.0000], Avg: [-586.035 -586.035 -586.035] (1.000)
Step: 26949, Reward: [-628.341 -628.341 -628.341] [0.0000], Avg: [-586.113 -586.113 -586.113] (1.000)
Step: 26999, Reward: [-497.469 -497.469 -497.469] [0.0000], Avg: [-585.949 -585.949 -585.949] (1.000)
Step: 27049, Reward: [-404.194 -404.194 -404.194] [0.0000], Avg: [-585.613 -585.613 -585.613] (1.000)
Step: 27099, Reward: [-348.128 -348.128 -348.128] [0.0000], Avg: [-585.175 -585.175 -585.175] (1.000)
Step: 27149, Reward: [-565.176 -565.176 -565.176] [0.0000], Avg: [-585.138 -585.138 -585.138] (1.000)
Step: 27199, Reward: [-394.22 -394.22 -394.22] [0.0000], Avg: [-584.787 -584.787 -584.787] (1.000)
Step: 27249, Reward: [-383.762 -383.762 -383.762] [0.0000], Avg: [-584.418 -584.418 -584.418] (1.000)
Step: 27299, Reward: [-326.433 -326.433 -326.433] [0.0000], Avg: [-583.946 -583.946 -583.946] (1.000)
Step: 27349, Reward: [-397.213 -397.213 -397.213] [0.0000], Avg: [-583.604 -583.604 -583.604] (1.000)
Step: 27399, Reward: [-448.993 -448.993 -448.993] [0.0000], Avg: [-583.359 -583.359 -583.359] (1.000)
Step: 27449, Reward: [-499.246 -499.246 -499.246] [0.0000], Avg: [-583.206 -583.206 -583.206] (1.000)
Step: 27499, Reward: [-489.111 -489.111 -489.111] [0.0000], Avg: [-583.034 -583.034 -583.034] (1.000)
Step: 27549, Reward: [-285.513 -285.513 -285.513] [0.0000], Avg: [-582.495 -582.495 -582.495] (1.000)
Step: 27599, Reward: [-444.85 -444.85 -444.85] [0.0000], Avg: [-582.245 -582.245 -582.245] (1.000)
Step: 27649, Reward: [-414.677 -414.677 -414.677] [0.0000], Avg: [-581.942 -581.942 -581.942] (1.000)
Step: 27699, Reward: [-542.256 -542.256 -542.256] [0.0000], Avg: [-581.871 -581.871 -581.871] (1.000)
Step: 27749, Reward: [-393.207 -393.207 -393.207] [0.0000], Avg: [-581.531 -581.531 -581.531] (1.000)
Step: 27799, Reward: [-421.977 -421.977 -421.977] [0.0000], Avg: [-581.244 -581.244 -581.244] (1.000)
Step: 27849, Reward: [-453.746 -453.746 -453.746] [0.0000], Avg: [-581.015 -581.015 -581.015] (1.000)
Step: 27899, Reward: [-473.108 -473.108 -473.108] [0.0000], Avg: [-580.821 -580.821 -580.821] (1.000)
Step: 27949, Reward: [-357.458 -357.458 -357.458] [0.0000], Avg: [-580.422 -580.422 -580.422] (1.000)
Step: 27999, Reward: [-410.344 -410.344 -410.344] [0.0000], Avg: [-580.118 -580.118 -580.118] (1.000)
Step: 28049, Reward: [-676.101 -676.101 -676.101] [0.0000], Avg: [-580.289 -580.289 -580.289] (1.000)
Step: 28099, Reward: [-456.349 -456.349 -456.349] [0.0000], Avg: [-580.069 -580.069 -580.069] (1.000)
Step: 28149, Reward: [-498.868 -498.868 -498.868] [0.0000], Avg: [-579.924 -579.924 -579.924] (1.000)
Step: 28199, Reward: [-344.905 -344.905 -344.905] [0.0000], Avg: [-579.508 -579.508 -579.508] (1.000)
Step: 28249, Reward: [-303.082 -303.082 -303.082] [0.0000], Avg: [-579.018 -579.018 -579.018] (1.000)
Step: 28299, Reward: [-440.432 -440.432 -440.432] [0.0000], Avg: [-578.774 -578.774 -578.774] (1.000)
Step: 28349, Reward: [-449.646 -449.646 -449.646] [0.0000], Avg: [-578.546 -578.546 -578.546] (1.000)
Step: 28399, Reward: [-417.678 -417.678 -417.678] [0.0000], Avg: [-578.263 -578.263 -578.263] (1.000)
Step: 28449, Reward: [-517.039 -517.039 -517.039] [0.0000], Avg: [-578.155 -578.155 -578.155] (1.000)
Step: 28499, Reward: [-462.682 -462.682 -462.682] [0.0000], Avg: [-577.952 -577.952 -577.952] (1.000)
Step: 28549, Reward: [-425.393 -425.393 -425.393] [0.0000], Avg: [-577.685 -577.685 -577.685] (1.000)
Step: 28599, Reward: [-354.03 -354.03 -354.03] [0.0000], Avg: [-577.294 -577.294 -577.294] (1.000)
Step: 28649, Reward: [-401.357 -401.357 -401.357] [0.0000], Avg: [-576.987 -576.987 -576.987] (1.000)
Step: 28699, Reward: [-400.643 -400.643 -400.643] [0.0000], Avg: [-576.68 -576.68 -576.68] (1.000)
Step: 28749, Reward: [-433.945 -433.945 -433.945] [0.0000], Avg: [-576.432 -576.432 -576.432] (1.000)
Step: 28799, Reward: [-355.348 -355.348 -355.348] [0.0000], Avg: [-576.048 -576.048 -576.048] (1.000)
Step: 28849, Reward: [-398.275 -398.275 -398.275] [0.0000], Avg: [-575.74 -575.74 -575.74] (1.000)
Step: 28899, Reward: [-327.885 -327.885 -327.885] [0.0000], Avg: [-575.311 -575.311 -575.311] (1.000)
Step: 28949, Reward: [-381.085 -381.085 -381.085] [0.0000], Avg: [-574.976 -574.976 -574.976] (1.000)
Step: 28999, Reward: [-362.059 -362.059 -362.059] [0.0000], Avg: [-574.608 -574.608 -574.608] (1.000)
Step: 29049, Reward: [-311.678 -311.678 -311.678] [0.0000], Avg: [-574.156 -574.156 -574.156] (1.000)
Step: 29099, Reward: [-550.22 -550.22 -550.22] [0.0000], Avg: [-574.115 -574.115 -574.115] (1.000)
Step: 29149, Reward: [-436.26 -436.26 -436.26] [0.0000], Avg: [-573.878 -573.878 -573.878] (1.000)
Step: 29199, Reward: [-372.796 -372.796 -372.796] [0.0000], Avg: [-573.534 -573.534 -573.534] (1.000)
Step: 29249, Reward: [-388.531 -388.531 -388.531] [0.0000], Avg: [-573.218 -573.218 -573.218] (1.000)
Step: 29299, Reward: [-486.62 -486.62 -486.62] [0.0000], Avg: [-573.07 -573.07 -573.07] (1.000)
Step: 29349, Reward: [-420.634 -420.634 -420.634] [0.0000], Avg: [-572.81 -572.81 -572.81] (1.000)
Step: 29399, Reward: [-362.373 -362.373 -362.373] [0.0000], Avg: [-572.452 -572.452 -572.452] (1.000)
Step: 29449, Reward: [-392.42 -392.42 -392.42] [0.0000], Avg: [-572.147 -572.147 -572.147] (1.000)
Step: 29499, Reward: [-363.192 -363.192 -363.192] [0.0000], Avg: [-571.793 -571.793 -571.793] (1.000)
Step: 29549, Reward: [-357.652 -357.652 -357.652] [0.0000], Avg: [-571.43 -571.43 -571.43] (1.000)
Step: 29599, Reward: [-299.576 -299.576 -299.576] [0.0000], Avg: [-570.971 -570.971 -570.971] (1.000)
Step: 29649, Reward: [-391.495 -391.495 -391.495] [0.0000], Avg: [-570.668 -570.668 -570.668] (1.000)
Step: 29699, Reward: [-396.93 -396.93 -396.93] [0.0000], Avg: [-570.376 -570.376 -570.376] (1.000)
Step: 29749, Reward: [-399.136 -399.136 -399.136] [0.0000], Avg: [-570.088 -570.088 -570.088] (1.000)
Step: 29799, Reward: [-367.084 -367.084 -367.084] [0.0000], Avg: [-569.747 -569.747 -569.747] (1.000)
Step: 29849, Reward: [-411.325 -411.325 -411.325] [0.0000], Avg: [-569.482 -569.482 -569.482] (1.000)
Step: 29899, Reward: [-385.972 -385.972 -385.972] [0.0000], Avg: [-569.175 -569.175 -569.175] (1.000)
Step: 29949, Reward: [-461.811 -461.811 -461.811] [0.0000], Avg: [-568.996 -568.996 -568.996] (1.000)
Step: 29999, Reward: [-421.306 -421.306 -421.306] [0.0000], Avg: [-568.75 -568.75 -568.75] (1.000)
Step: 30049, Reward: [-354.891 -354.891 -354.891] [0.0000], Avg: [-568.394 -568.394 -568.394] (1.000)
Step: 30099, Reward: [-390.729 -390.729 -390.729] [0.0000], Avg: [-568.099 -568.099 -568.099] (1.000)
Step: 30149, Reward: [-408.952 -408.952 -408.952] [0.0000], Avg: [-567.835 -567.835 -567.835] (1.000)
Step: 30199, Reward: [-357.463 -357.463 -357.463] [0.0000], Avg: [-567.487 -567.487 -567.487] (1.000)
Step: 30249, Reward: [-458.163 -458.163 -458.163] [0.0000], Avg: [-567.306 -567.306 -567.306] (1.000)
Step: 30299, Reward: [-407.512 -407.512 -407.512] [0.0000], Avg: [-567.042 -567.042 -567.042] (1.000)
Step: 30349, Reward: [-507.276 -507.276 -507.276] [0.0000], Avg: [-566.944 -566.944 -566.944] (1.000)
Step: 30399, Reward: [-409.26 -409.26 -409.26] [0.0000], Avg: [-566.684 -566.684 -566.684] (1.000)
Step: 30449, Reward: [-401.838 -401.838 -401.838] [0.0000], Avg: [-566.414 -566.414 -566.414] (1.000)
Step: 30499, Reward: [-418.037 -418.037 -418.037] [0.0000], Avg: [-566.171 -566.171 -566.171] (1.000)
Step: 30549, Reward: [-490.621 -490.621 -490.621] [0.0000], Avg: [-566.047 -566.047 -566.047] (1.000)
Step: 30599, Reward: [-292.696 -292.696 -292.696] [0.0000], Avg: [-565.6 -565.6 -565.6] (1.000)
Step: 30649, Reward: [-530.502 -530.502 -530.502] [0.0000], Avg: [-565.543 -565.543 -565.543] (1.000)
Step: 30699, Reward: [-403.62 -403.62 -403.62] [0.0000], Avg: [-565.279 -565.279 -565.279] (1.000)
Step: 30749, Reward: [-375.237 -375.237 -375.237] [0.0000], Avg: [-564.97 -564.97 -564.97] (1.000)
Step: 30799, Reward: [-466.92 -466.92 -466.92] [0.0000], Avg: [-564.811 -564.811 -564.811] (1.000)
Step: 30849, Reward: [-339.212 -339.212 -339.212] [0.0000], Avg: [-564.445 -564.445 -564.445] (1.000)
Step: 30899, Reward: [-505.298 -505.298 -505.298] [0.0000], Avg: [-564.35 -564.35 -564.35] (1.000)
Step: 30949, Reward: [-525.776 -525.776 -525.776] [0.0000], Avg: [-564.287 -564.287 -564.287] (1.000)
Step: 30999, Reward: [-386.929 -386.929 -386.929] [0.0000], Avg: [-564.001 -564.001 -564.001] (1.000)
Step: 31049, Reward: [-429.269 -429.269 -429.269] [0.0000], Avg: [-563.784 -563.784 -563.784] (1.000)
Step: 31099, Reward: [-397.17 -397.17 -397.17] [0.0000], Avg: [-563.517 -563.517 -563.517] (1.000)
Step: 31149, Reward: [-455.815 -455.815 -455.815] [0.0000], Avg: [-563.344 -563.344 -563.344] (1.000)
Step: 31199, Reward: [-293.927 -293.927 -293.927] [0.0000], Avg: [-562.912 -562.912 -562.912] (1.000)
Step: 31249, Reward: [-427. -427. -427.] [0.0000], Avg: [-562.694 -562.694 -562.694] (1.000)
Step: 31299, Reward: [-425.594 -425.594 -425.594] [0.0000], Avg: [-562.475 -562.475 -562.475] (1.000)
Step: 31349, Reward: [-360.856 -360.856 -360.856] [0.0000], Avg: [-562.154 -562.154 -562.154] (1.000)
Step: 31399, Reward: [-410.998 -410.998 -410.998] [0.0000], Avg: [-561.913 -561.913 -561.913] (1.000)
Step: 31449, Reward: [-247.042 -247.042 -247.042] [0.0000], Avg: [-561.413 -561.413 -561.413] (1.000)
Step: 31499, Reward: [-431.727 -431.727 -431.727] [0.0000], Avg: [-561.207 -561.207 -561.207] (1.000)
Step: 31549, Reward: [-367.507 -367.507 -367.507] [0.0000], Avg: [-560.9 -560.9 -560.9] (1.000)
Step: 31599, Reward: [-410.392 -410.392 -410.392] [0.0000], Avg: [-560.662 -560.662 -560.662] (1.000)
Step: 31649, Reward: [-337.461 -337.461 -337.461] [0.0000], Avg: [-560.309 -560.309 -560.309] (1.000)
Step: 31699, Reward: [-359.381 -359.381 -359.381] [0.0000], Avg: [-559.992 -559.992 -559.992] (1.000)
Step: 31749, Reward: [-440.94 -440.94 -440.94] [0.0000], Avg: [-559.805 -559.805 -559.805] (1.000)
Step: 31799, Reward: [-367.896 -367.896 -367.896] [0.0000], Avg: [-559.503 -559.503 -559.503] (1.000)
Step: 31849, Reward: [-307.253 -307.253 -307.253] [0.0000], Avg: [-559.107 -559.107 -559.107] (1.000)
Step: 31899, Reward: [-433.14 -433.14 -433.14] [0.0000], Avg: [-558.909 -558.909 -558.909] (1.000)
Step: 31949, Reward: [-581.231 -581.231 -581.231] [0.0000], Avg: [-558.944 -558.944 -558.944] (1.000)
Step: 31999, Reward: [-464.524 -464.524 -464.524] [0.0000], Avg: [-558.797 -558.797 -558.797] (1.000)
Step: 32049, Reward: [-529.801 -529.801 -529.801] [0.0000], Avg: [-558.752 -558.752 -558.752] (1.000)
Step: 32099, Reward: [-466.053 -466.053 -466.053] [0.0000], Avg: [-558.607 -558.607 -558.607] (1.000)
Step: 32149, Reward: [-396.437 -396.437 -396.437] [0.0000], Avg: [-558.355 -558.355 -558.355] (1.000)
Step: 32199, Reward: [-540.346 -540.346 -540.346] [0.0000], Avg: [-558.327 -558.327 -558.327] (1.000)
Step: 32249, Reward: [-325.349 -325.349 -325.349] [0.0000], Avg: [-557.966 -557.966 -557.966] (1.000)
Step: 32299, Reward: [-352.69 -352.69 -352.69] [0.0000], Avg: [-557.648 -557.648 -557.648] (1.000)
Step: 32349, Reward: [-515.694 -515.694 -515.694] [0.0000], Avg: [-557.583 -557.583 -557.583] (1.000)
Step: 32399, Reward: [-277.698 -277.698 -277.698] [0.0000], Avg: [-557.151 -557.151 -557.151] (1.000)
Step: 32449, Reward: [-332.948 -332.948 -332.948] [0.0000], Avg: [-556.806 -556.806 -556.806] (1.000)
Step: 32499, Reward: [-409.825 -409.825 -409.825] [0.0000], Avg: [-556.58 -556.58 -556.58] (1.000)
Step: 32549, Reward: [-475.215 -475.215 -475.215] [0.0000], Avg: [-556.455 -556.455 -556.455] (1.000)
Step: 32599, Reward: [-347.739 -347.739 -347.739] [0.0000], Avg: [-556.135 -556.135 -556.135] (1.000)
Step: 32649, Reward: [-382.441 -382.441 -382.441] [0.0000], Avg: [-555.869 -555.869 -555.869] (1.000)
Step: 32699, Reward: [-364.488 -364.488 -364.488] [0.0000], Avg: [-555.576 -555.576 -555.576] (1.000)
Step: 32749, Reward: [-446.297 -446.297 -446.297] [0.0000], Avg: [-555.409 -555.409 -555.409] (1.000)
Step: 32799, Reward: [-448.492 -448.492 -448.492] [0.0000], Avg: [-555.246 -555.246 -555.246] (1.000)
Step: 32849, Reward: [-346.081 -346.081 -346.081] [0.0000], Avg: [-554.928 -554.928 -554.928] (1.000)
Step: 32899, Reward: [-434.859 -434.859 -434.859] [0.0000], Avg: [-554.745 -554.745 -554.745] (1.000)
Step: 32949, Reward: [-498.926 -498.926 -498.926] [0.0000], Avg: [-554.661 -554.661 -554.661] (1.000)
Step: 32999, Reward: [-425.997 -425.997 -425.997] [0.0000], Avg: [-554.466 -554.466 -554.466] (1.000)
Step: 33049, Reward: [-446.497 -446.497 -446.497] [0.0000], Avg: [-554.302 -554.302 -554.302] (1.000)
Step: 33099, Reward: [-398.174 -398.174 -398.174] [0.0000], Avg: [-554.066 -554.066 -554.066] (1.000)
Step: 33149, Reward: [-458.17 -458.17 -458.17] [0.0000], Avg: [-553.922 -553.922 -553.922] (1.000)
Step: 33199, Reward: [-299.479 -299.479 -299.479] [0.0000], Avg: [-553.539 -553.539 -553.539] (1.000)
Step: 33249, Reward: [-425.564 -425.564 -425.564] [0.0000], Avg: [-553.346 -553.346 -553.346] (1.000)
Step: 33299, Reward: [-317.953 -317.953 -317.953] [0.0000], Avg: [-552.993 -552.993 -552.993] (1.000)
Step: 33349, Reward: [-379.758 -379.758 -379.758] [0.0000], Avg: [-552.733 -552.733 -552.733] (1.000)
Step: 33399, Reward: [-375.583 -375.583 -375.583] [0.0000], Avg: [-552.468 -552.468 -552.468] (1.000)
Step: 33449, Reward: [-327.615 -327.615 -327.615] [0.0000], Avg: [-552.132 -552.132 -552.132] (1.000)
Step: 33499, Reward: [-321.363 -321.363 -321.363] [0.0000], Avg: [-551.787 -551.787 -551.787] (1.000)
Step: 33549, Reward: [-402.304 -402.304 -402.304] [0.0000], Avg: [-551.565 -551.565 -551.565] (1.000)
Step: 33599, Reward: [-295.437 -295.437 -295.437] [0.0000], Avg: [-551.183 -551.183 -551.183] (1.000)
Step: 33649, Reward: [-523.205 -523.205 -523.205] [0.0000], Avg: [-551.142 -551.142 -551.142] (1.000)
Step: 33699, Reward: [-300.116 -300.116 -300.116] [0.0000], Avg: [-550.769 -550.769 -550.769] (1.000)
Step: 33749, Reward: [-414.809 -414.809 -414.809] [0.0000], Avg: [-550.568 -550.568 -550.568] (1.000)
Step: 33799, Reward: [-361.242 -361.242 -361.242] [0.0000], Avg: [-550.288 -550.288 -550.288] (1.000)
Step: 33849, Reward: [-358.809 -358.809 -358.809] [0.0000], Avg: [-550.005 -550.005 -550.005] (1.000)
Step: 33899, Reward: [-441.768 -441.768 -441.768] [0.0000], Avg: [-549.845 -549.845 -549.845] (1.000)
Step: 33949, Reward: [-358.467 -358.467 -358.467] [0.0000], Avg: [-549.564 -549.564 -549.564] (1.000)
Step: 33999, Reward: [-516.559 -516.559 -516.559] [0.0000], Avg: [-549.515 -549.515 -549.515] (1.000)
Step: 34049, Reward: [-339.819 -339.819 -339.819] [0.0000], Avg: [-549.207 -549.207 -549.207] (1.000)
Step: 34099, Reward: [-392.868 -392.868 -392.868] [0.0000], Avg: [-548.978 -548.978 -548.978] (1.000)
Step: 34149, Reward: [-465.364 -465.364 -465.364] [0.0000], Avg: [-548.855 -548.855 -548.855] (1.000)
Step: 34199, Reward: [-548.346 -548.346 -548.346] [0.0000], Avg: [-548.855 -548.855 -548.855] (1.000)
Step: 34249, Reward: [-434.29 -434.29 -434.29] [0.0000], Avg: [-548.687 -548.687 -548.687] (1.000)
Step: 34299, Reward: [-340.689 -340.689 -340.689] [0.0000], Avg: [-548.384 -548.384 -548.384] (1.000)
Step: 34349, Reward: [-455.576 -455.576 -455.576] [0.0000], Avg: [-548.249 -548.249 -548.249] (1.000)
Step: 34399, Reward: [-325.547 -325.547 -325.547] [0.0000], Avg: [-547.925 -547.925 -547.925] (1.000)
Step: 34449, Reward: [-499.837 -499.837 -499.837] [0.0000], Avg: [-547.856 -547.856 -547.856] (1.000)
Step: 34499, Reward: [-420.313 -420.313 -420.313] [0.0000], Avg: [-547.671 -547.671 -547.671] (1.000)
Step: 34549, Reward: [-413.598 -413.598 -413.598] [0.0000], Avg: [-547.477 -547.477 -547.477] (1.000)
Step: 34599, Reward: [-351.239 -351.239 -351.239] [0.0000], Avg: [-547.193 -547.193 -547.193] (1.000)
Step: 34649, Reward: [-371.767 -371.767 -371.767] [0.0000], Avg: [-546.94 -546.94 -546.94] (1.000)
Step: 34699, Reward: [-473.158 -473.158 -473.158] [0.0000], Avg: [-546.834 -546.834 -546.834] (1.000)
Step: 34749, Reward: [-418.342 -418.342 -418.342] [0.0000], Avg: [-546.649 -546.649 -546.649] (1.000)
Step: 34799, Reward: [-361.926 -361.926 -361.926] [0.0000], Avg: [-546.383 -546.383 -546.383] (1.000)
Step: 34849, Reward: [-465.288 -465.288 -465.288] [0.0000], Avg: [-546.267 -546.267 -546.267] (1.000)
Step: 34899, Reward: [-479.825 -479.825 -479.825] [0.0000], Avg: [-546.172 -546.172 -546.172] (1.000)
Step: 34949, Reward: [-395.302 -395.302 -395.302] [0.0000], Avg: [-545.956 -545.956 -545.956] (1.000)
Step: 34999, Reward: [-326.681 -326.681 -326.681] [0.0000], Avg: [-545.643 -545.643 -545.643] (1.000)
Step: 35049, Reward: [-447.705 -447.705 -447.705] [0.0000], Avg: [-545.503 -545.503 -545.503] (1.000)
Step: 35099, Reward: [-461.184 -461.184 -461.184] [0.0000], Avg: [-545.383 -545.383 -545.383] (1.000)
Step: 35149, Reward: [-558.456 -558.456 -558.456] [0.0000], Avg: [-545.402 -545.402 -545.402] (1.000)
Step: 35199, Reward: [-439.016 -439.016 -439.016] [0.0000], Avg: [-545.25 -545.25 -545.25] (1.000)
Step: 35249, Reward: [-277.666 -277.666 -277.666] [0.0000], Avg: [-544.871 -544.871 -544.871] (1.000)
Step: 35299, Reward: [-328.563 -328.563 -328.563] [0.0000], Avg: [-544.565 -544.565 -544.565] (1.000)
Step: 35349, Reward: [-418.442 -418.442 -418.442] [0.0000], Avg: [-544.386 -544.386 -544.386] (1.000)
Step: 35399, Reward: [-477.579 -477.579 -477.579] [0.0000], Avg: [-544.292 -544.292 -544.292] (1.000)
Step: 35449, Reward: [-520.912 -520.912 -520.912] [0.0000], Avg: [-544.259 -544.259 -544.259] (1.000)
Step: 35499, Reward: [-474.449 -474.449 -474.449] [0.0000], Avg: [-544.161 -544.161 -544.161] (1.000)
Step: 35549, Reward: [-316.069 -316.069 -316.069] [0.0000], Avg: [-543.84 -543.84 -543.84] (1.000)
Step: 35599, Reward: [-372.258 -372.258 -372.258] [0.0000], Avg: [-543.599 -543.599 -543.599] (1.000)
Step: 35649, Reward: [-306.015 -306.015 -306.015] [0.0000], Avg: [-543.266 -543.266 -543.266] (1.000)
Step: 35699, Reward: [-400.62 -400.62 -400.62] [0.0000], Avg: [-543.066 -543.066 -543.066] (1.000)
Step: 35749, Reward: [-370.631 -370.631 -370.631] [0.0000], Avg: [-542.825 -542.825 -542.825] (1.000)
Step: 35799, Reward: [-340.157 -340.157 -340.157] [0.0000], Avg: [-542.541 -542.541 -542.541] (1.000)
Step: 35849, Reward: [-452.276 -452.276 -452.276] [0.0000], Avg: [-542.416 -542.416 -542.416] (1.000)
Step: 35899, Reward: [-449.516 -449.516 -449.516] [0.0000], Avg: [-542.286 -542.286 -542.286] (1.000)
Step: 35949, Reward: [-573.193 -573.193 -573.193] [0.0000], Avg: [-542.329 -542.329 -542.329] (1.000)
Step: 35999, Reward: [-422.988 -422.988 -422.988] [0.0000], Avg: [-542.163 -542.163 -542.163] (1.000)
Step: 36049, Reward: [-352.28 -352.28 -352.28] [0.0000], Avg: [-541.9 -541.9 -541.9] (1.000)
Step: 36099, Reward: [-350.63 -350.63 -350.63] [0.0000], Avg: [-541.635 -541.635 -541.635] (1.000)
Step: 36149, Reward: [-326.827 -326.827 -326.827] [0.0000], Avg: [-541.338 -541.338 -541.338] (1.000)
Step: 36199, Reward: [-491.272 -491.272 -491.272] [0.0000], Avg: [-541.269 -541.269 -541.269] (1.000)
Step: 36249, Reward: [-312.99 -312.99 -312.99] [0.0000], Avg: [-540.954 -540.954 -540.954] (1.000)
Step: 36299, Reward: [-392.678 -392.678 -392.678] [0.0000], Avg: [-540.75 -540.75 -540.75] (1.000)
Step: 36349, Reward: [-419.244 -419.244 -419.244] [0.0000], Avg: [-540.583 -540.583 -540.583] (1.000)
Step: 36399, Reward: [-409.137 -409.137 -409.137] [0.0000], Avg: [-540.402 -540.402 -540.402] (1.000)
Step: 36449, Reward: [-347.229 -347.229 -347.229] [0.0000], Avg: [-540.137 -540.137 -540.137] (1.000)
Step: 36499, Reward: [-405.455 -405.455 -405.455] [0.0000], Avg: [-539.953 -539.953 -539.953] (1.000)
Step: 36549, Reward: [-513.301 -513.301 -513.301] [0.0000], Avg: [-539.916 -539.916 -539.916] (1.000)
Step: 36599, Reward: [-464.772 -464.772 -464.772] [0.0000], Avg: [-539.814 -539.814 -539.814] (1.000)
Step: 36649, Reward: [-311.433 -311.433 -311.433] [0.0000], Avg: [-539.502 -539.502 -539.502] (1.000)
Step: 36699, Reward: [-375.408 -375.408 -375.408] [0.0000], Avg: [-539.278 -539.278 -539.278] (1.000)
Step: 36749, Reward: [-385.132 -385.132 -385.132] [0.0000], Avg: [-539.069 -539.069 -539.069] (1.000)
Step: 36799, Reward: [-416.284 -416.284 -416.284] [0.0000], Avg: [-538.902 -538.902 -538.902] (1.000)
Step: 36849, Reward: [-431.593 -431.593 -431.593] [0.0000], Avg: [-538.756 -538.756 -538.756] (1.000)
Step: 36899, Reward: [-463.015 -463.015 -463.015] [0.0000], Avg: [-538.654 -538.654 -538.654] (1.000)
Step: 36949, Reward: [-303.135 -303.135 -303.135] [0.0000], Avg: [-538.335 -538.335 -538.335] (1.000)
Step: 36999, Reward: [-340.055 -340.055 -340.055] [0.0000], Avg: [-538.067 -538.067 -538.067] (1.000)
Step: 37049, Reward: [-320.64 -320.64 -320.64] [0.0000], Avg: [-537.774 -537.774 -537.774] (1.000)
Step: 37099, Reward: [-423.572 -423.572 -423.572] [0.0000], Avg: [-537.62 -537.62 -537.62] (1.000)
Step: 37149, Reward: [-411.432 -411.432 -411.432] [0.0000], Avg: [-537.45 -537.45 -537.45] (1.000)
Step: 37199, Reward: [-383.861 -383.861 -383.861] [0.0000], Avg: [-537.243 -537.243 -537.243] (1.000)
Step: 37249, Reward: [-355.423 -355.423 -355.423] [0.0000], Avg: [-536.999 -536.999 -536.999] (1.000)
Step: 37299, Reward: [-309.474 -309.474 -309.474] [0.0000], Avg: [-536.694 -536.694 -536.694] (1.000)
Step: 37349, Reward: [-334.572 -334.572 -334.572] [0.0000], Avg: [-536.424 -536.424 -536.424] (1.000)
Step: 37399, Reward: [-383.481 -383.481 -383.481] [0.0000], Avg: [-536.219 -536.219 -536.219] (1.000)
Step: 37449, Reward: [-365.968 -365.968 -365.968] [0.0000], Avg: [-535.992 -535.992 -535.992] (1.000)
Step: 37499, Reward: [-296.835 -296.835 -296.835] [0.0000], Avg: [-535.673 -535.673 -535.673] (1.000)
Step: 37549, Reward: [-530.331 -530.331 -530.331] [0.0000], Avg: [-535.666 -535.666 -535.666] (1.000)
Step: 37599, Reward: [-407.368 -407.368 -407.368] [0.0000], Avg: [-535.495 -535.495 -535.495] (1.000)
Step: 37649, Reward: [-396.992 -396.992 -396.992] [0.0000], Avg: [-535.311 -535.311 -535.311] (1.000)
Step: 37699, Reward: [-421.995 -421.995 -421.995] [0.0000], Avg: [-535.161 -535.161 -535.161] (1.000)
Step: 37749, Reward: [-387.239 -387.239 -387.239] [0.0000], Avg: [-534.965 -534.965 -534.965] (1.000)
Step: 37799, Reward: [-403.193 -403.193 -403.193] [0.0000], Avg: [-534.791 -534.791 -534.791] (1.000)
Step: 37849, Reward: [-356.74 -356.74 -356.74] [0.0000], Avg: [-534.556 -534.556 -534.556] (1.000)
Step: 37899, Reward: [-404.839 -404.839 -404.839] [0.0000], Avg: [-534.385 -534.385 -534.385] (1.000)
Step: 37949, Reward: [-452.289 -452.289 -452.289] [0.0000], Avg: [-534.276 -534.276 -534.276] (1.000)
Step: 37999, Reward: [-501.794 -501.794 -501.794] [0.0000], Avg: [-534.234 -534.234 -534.234] (1.000)
Step: 38049, Reward: [-367.966 -367.966 -367.966] [0.0000], Avg: [-534.015 -534.015 -534.015] (1.000)
Step: 38099, Reward: [-459.168 -459.168 -459.168] [0.0000], Avg: [-533.917 -533.917 -533.917] (1.000)
Step: 38149, Reward: [-354.38 -354.38 -354.38] [0.0000], Avg: [-533.682 -533.682 -533.682] (1.000)
Step: 38199, Reward: [-453.063 -453.063 -453.063] [0.0000], Avg: [-533.576 -533.576 -533.576] (1.000)
Step: 38249, Reward: [-409.991 -409.991 -409.991] [0.0000], Avg: [-533.415 -533.415 -533.415] (1.000)
Step: 38299, Reward: [-407.774 -407.774 -407.774] [0.0000], Avg: [-533.251 -533.251 -533.251] (1.000)
Step: 38349, Reward: [-381.952 -381.952 -381.952] [0.0000], Avg: [-533.053 -533.053 -533.053] (1.000)
Step: 38399, Reward: [-373.582 -373.582 -373.582] [0.0000], Avg: [-532.846 -532.846 -532.846] (1.000)
Step: 38449, Reward: [-455.381 -455.381 -455.381] [0.0000], Avg: [-532.745 -532.745 -532.745] (1.000)
Step: 38499, Reward: [-447.031 -447.031 -447.031] [0.0000], Avg: [-532.634 -532.634 -532.634] (1.000)
Step: 38549, Reward: [-375.714 -375.714 -375.714] [0.0000], Avg: [-532.43 -532.43 -532.43] (1.000)
Step: 38599, Reward: [-342.772 -342.772 -342.772] [0.0000], Avg: [-532.184 -532.184 -532.184] (1.000)
Step: 38649, Reward: [-296.424 -296.424 -296.424] [0.0000], Avg: [-531.879 -531.879 -531.879] (1.000)
Step: 38699, Reward: [-455.808 -455.808 -455.808] [0.0000], Avg: [-531.781 -531.781 -531.781] (1.000)
Step: 38749, Reward: [-337.932 -337.932 -337.932] [0.0000], Avg: [-531.531 -531.531 -531.531] (1.000)
Step: 38799, Reward: [-454.381 -454.381 -454.381] [0.0000], Avg: [-531.432 -531.432 -531.432] (1.000)
Step: 38849, Reward: [-443.996 -443.996 -443.996] [0.0000], Avg: [-531.319 -531.319 -531.319] (1.000)
Step: 38899, Reward: [-407.433 -407.433 -407.433] [0.0000], Avg: [-531.16 -531.16 -531.16] (1.000)
Step: 38949, Reward: [-465.315 -465.315 -465.315] [0.0000], Avg: [-531.075 -531.075 -531.075] (1.000)
Step: 38999, Reward: [-355.879 -355.879 -355.879] [0.0000], Avg: [-530.851 -530.851 -530.851] (1.000)
Step: 39049, Reward: [-298.161 -298.161 -298.161] [0.0000], Avg: [-530.553 -530.553 -530.553] (1.000)
Step: 39099, Reward: [-516.996 -516.996 -516.996] [0.0000], Avg: [-530.535 -530.535 -530.535] (1.000)
Step: 39149, Reward: [-436.071 -436.071 -436.071] [0.0000], Avg: [-530.415 -530.415 -530.415] (1.000)
Step: 39199, Reward: [-397.675 -397.675 -397.675] [0.0000], Avg: [-530.245 -530.245 -530.245] (1.000)
Step: 39249, Reward: [-425.528 -425.528 -425.528] [0.0000], Avg: [-530.112 -530.112 -530.112] (1.000)
Step: 39299, Reward: [-402.147 -402.147 -402.147] [0.0000], Avg: [-529.949 -529.949 -529.949] (1.000)
Step: 39349, Reward: [-449.27 -449.27 -449.27] [0.0000], Avg: [-529.847 -529.847 -529.847] (1.000)
Step: 39399, Reward: [-363.948 -363.948 -363.948] [0.0000], Avg: [-529.636 -529.636 -529.636] (1.000)
Step: 39449, Reward: [-551.114 -551.114 -551.114] [0.0000], Avg: [-529.663 -529.663 -529.663] (1.000)
Step: 39499, Reward: [-347.419 -347.419 -347.419] [0.0000], Avg: [-529.433 -529.433 -529.433] (1.000)
Step: 39549, Reward: [-425.454 -425.454 -425.454] [0.0000], Avg: [-529.301 -529.301 -529.301] (1.000)
Step: 39599, Reward: [-479.033 -479.033 -479.033] [0.0000], Avg: [-529.238 -529.238 -529.238] (1.000)
Step: 39649, Reward: [-400.749 -400.749 -400.749] [0.0000], Avg: [-529.076 -529.076 -529.076] (1.000)
Step: 39699, Reward: [-402.767 -402.767 -402.767] [0.0000], Avg: [-528.917 -528.917 -528.917] (1.000)
Step: 39749, Reward: [-461.193 -461.193 -461.193] [0.0000], Avg: [-528.832 -528.832 -528.832] (1.000)
Step: 39799, Reward: [-386.98 -386.98 -386.98] [0.0000], Avg: [-528.653 -528.653 -528.653] (1.000)
Step: 39849, Reward: [-400.639 -400.639 -400.639] [0.0000], Avg: [-528.493 -528.493 -528.493] (1.000)
Step: 39899, Reward: [-605.487 -605.487 -605.487] [0.0000], Avg: [-528.589 -528.589 -528.589] (1.000)
Step: 39949, Reward: [-422.539 -422.539 -422.539] [0.0000], Avg: [-528.456 -528.456 -528.456] (1.000)
Step: 39999, Reward: [-468.645 -468.645 -468.645] [0.0000], Avg: [-528.382 -528.382 -528.382] (1.000)
Step: 40049, Reward: [-362.15 -362.15 -362.15] [0.0000], Avg: [-528.174 -528.174 -528.174] (1.000)
Step: 40099, Reward: [-461.165 -461.165 -461.165] [0.0000], Avg: [-528.091 -528.091 -528.091] (1.000)
Step: 40149, Reward: [-535.482 -535.482 -535.482] [0.0000], Avg: [-528.1 -528.1 -528.1] (1.000)
Step: 40199, Reward: [-282.721 -282.721 -282.721] [0.0000], Avg: [-527.795 -527.795 -527.795] (1.000)
Step: 40249, Reward: [-448.992 -448.992 -448.992] [0.0000], Avg: [-527.697 -527.697 -527.697] (1.000)
Step: 40299, Reward: [-303.352 -303.352 -303.352] [0.0000], Avg: [-527.418 -527.418 -527.418] (1.000)
Step: 40349, Reward: [-312.958 -312.958 -312.958] [0.0000], Avg: [-527.153 -527.153 -527.153] (1.000)
Step: 40399, Reward: [-373.823 -373.823 -373.823] [0.0000], Avg: [-526.963 -526.963 -526.963] (1.000)
Step: 40449, Reward: [-310.112 -310.112 -310.112] [0.0000], Avg: [-526.695 -526.695 -526.695] (1.000)
Step: 40499, Reward: [-368.962 -368.962 -368.962] [0.0000], Avg: [-526.5 -526.5 -526.5] (1.000)
Step: 40549, Reward: [-311.908 -311.908 -311.908] [0.0000], Avg: [-526.235 -526.235 -526.235] (1.000)
Step: 40599, Reward: [-459.706 -459.706 -459.706] [0.0000], Avg: [-526.154 -526.154 -526.154] (1.000)
Step: 40649, Reward: [-417.632 -417.632 -417.632] [0.0000], Avg: [-526.02 -526.02 -526.02] (1.000)
Step: 40699, Reward: [-402.318 -402.318 -402.318] [0.0000], Avg: [-525.868 -525.868 -525.868] (1.000)
Step: 40749, Reward: [-239.239 -239.239 -239.239] [0.0000], Avg: [-525.516 -525.516 -525.516] (1.000)
Step: 40799, Reward: [-451.923 -451.923 -451.923] [0.0000], Avg: [-525.426 -525.426 -525.426] (1.000)
Step: 40849, Reward: [-401.992 -401.992 -401.992] [0.0000], Avg: [-525.275 -525.275 -525.275] (1.000)
Step: 40899, Reward: [-390.378 -390.378 -390.378] [0.0000], Avg: [-525.11 -525.11 -525.11] (1.000)
Step: 40949, Reward: [-408.882 -408.882 -408.882] [0.0000], Avg: [-524.968 -524.968 -524.968] (1.000)
Step: 40999, Reward: [-440.954 -440.954 -440.954] [0.0000], Avg: [-524.866 -524.866 -524.866] (1.000)
Step: 41049, Reward: [-399.79 -399.79 -399.79] [0.0000], Avg: [-524.714 -524.714 -524.714] (1.000)
Step: 41099, Reward: [-463.773 -463.773 -463.773] [0.0000], Avg: [-524.639 -524.639 -524.639] (1.000)
Step: 41149, Reward: [-294.03 -294.03 -294.03] [0.0000], Avg: [-524.359 -524.359 -524.359] (1.000)
Step: 41199, Reward: [-379.289 -379.289 -379.289] [0.0000], Avg: [-524.183 -524.183 -524.183] (1.000)
Step: 41249, Reward: [-298.929 -298.929 -298.929] [0.0000], Avg: [-523.91 -523.91 -523.91] (1.000)
Step: 41299, Reward: [-474.569 -474.569 -474.569] [0.0000], Avg: [-523.85 -523.85 -523.85] (1.000)
Step: 41349, Reward: [-391.577 -391.577 -391.577] [0.0000], Avg: [-523.69 -523.69 -523.69] (1.000)
Step: 41399, Reward: [-515.569 -515.569 -515.569] [0.0000], Avg: [-523.681 -523.681 -523.681] (1.000)
Step: 41449, Reward: [-434.596 -434.596 -434.596] [0.0000], Avg: [-523.573 -523.573 -523.573] (1.000)
Step: 41499, Reward: [-470.79 -470.79 -470.79] [0.0000], Avg: [-523.51 -523.51 -523.51] (1.000)
Step: 41549, Reward: [-363.021 -363.021 -363.021] [0.0000], Avg: [-523.316 -523.316 -523.316] (1.000)
Step: 41599, Reward: [-381.749 -381.749 -381.749] [0.0000], Avg: [-523.146 -523.146 -523.146] (1.000)
Step: 41649, Reward: [-323.695 -323.695 -323.695] [0.0000], Avg: [-522.907 -522.907 -522.907] (1.000)
Step: 41699, Reward: [-280.696 -280.696 -280.696] [0.0000], Avg: [-522.616 -522.616 -522.616] (1.000)
Step: 41749, Reward: [-334.052 -334.052 -334.052] [0.0000], Avg: [-522.391 -522.391 -522.391] (1.000)
Step: 41799, Reward: [-364.724 -364.724 -364.724] [0.0000], Avg: [-522.202 -522.202 -522.202] (1.000)
Step: 41849, Reward: [-405.276 -405.276 -405.276] [0.0000], Avg: [-522.062 -522.062 -522.062] (1.000)
Step: 41899, Reward: [-427.086 -427.086 -427.086] [0.0000], Avg: [-521.949 -521.949 -521.949] (1.000)
Step: 41949, Reward: [-390.881 -390.881 -390.881] [0.0000], Avg: [-521.793 -521.793 -521.793] (1.000)
Step: 41999, Reward: [-348.56 -348.56 -348.56] [0.0000], Avg: [-521.586 -521.586 -521.586] (1.000)
Step: 42049, Reward: [-307.154 -307.154 -307.154] [0.0000], Avg: [-521.332 -521.332 -521.332] (1.000)
Step: 42099, Reward: [-350.276 -350.276 -350.276] [0.0000], Avg: [-521.128 -521.128 -521.128] (1.000)
Step: 42149, Reward: [-275.556 -275.556 -275.556] [0.0000], Avg: [-520.837 -520.837 -520.837] (1.000)
Step: 42199, Reward: [-346.15 -346.15 -346.15] [0.0000], Avg: [-520.63 -520.63 -520.63] (1.000)
Step: 42249, Reward: [-413.839 -413.839 -413.839] [0.0000], Avg: [-520.504 -520.504 -520.504] (1.000)
Step: 42299, Reward: [-292.211 -292.211 -292.211] [0.0000], Avg: [-520.234 -520.234 -520.234] (1.000)
Step: 42349, Reward: [-369.913 -369.913 -369.913] [0.0000], Avg: [-520.056 -520.056 -520.056] (1.000)
Step: 42399, Reward: [-470.155 -470.155 -470.155] [0.0000], Avg: [-519.998 -519.998 -519.998] (1.000)
Step: 42449, Reward: [-392.553 -392.553 -392.553] [0.0000], Avg: [-519.847 -519.847 -519.847] (1.000)
Step: 42499, Reward: [-386.507 -386.507 -386.507] [0.0000], Avg: [-519.691 -519.691 -519.691] (1.000)
Step: 42549, Reward: [-476.927 -476.927 -476.927] [0.0000], Avg: [-519.64 -519.64 -519.64] (1.000)
Step: 42599, Reward: [-409.046 -409.046 -409.046] [0.0000], Avg: [-519.51 -519.51 -519.51] (1.000)
Step: 42649, Reward: [-440.592 -440.592 -440.592] [0.0000], Avg: [-519.418 -519.418 -519.418] (1.000)
Step: 42699, Reward: [-456.359 -456.359 -456.359] [0.0000], Avg: [-519.344 -519.344 -519.344] (1.000)
Step: 42749, Reward: [-289.022 -289.022 -289.022] [0.0000], Avg: [-519.075 -519.075 -519.075] (1.000)
Step: 42799, Reward: [-280.95 -280.95 -280.95] [0.0000], Avg: [-518.797 -518.797 -518.797] (1.000)
Step: 42849, Reward: [-307.137 -307.137 -307.137] [0.0000], Avg: [-518.55 -518.55 -518.55] (1.000)
Step: 42899, Reward: [-455.232 -455.232 -455.232] [0.0000], Avg: [-518.476 -518.476 -518.476] (1.000)
Step: 42949, Reward: [-307.947 -307.947 -307.947] [0.0000], Avg: [-518.231 -518.231 -518.231] (1.000)
Step: 42999, Reward: [-288.53 -288.53 -288.53] [0.0000], Avg: [-517.964 -517.964 -517.964] (1.000)
Step: 43049, Reward: [-280.607 -280.607 -280.607] [0.0000], Avg: [-517.688 -517.688 -517.688] (1.000)
Step: 43099, Reward: [-337.043 -337.043 -337.043] [0.0000], Avg: [-517.478 -517.478 -517.478] (1.000)
Step: 43149, Reward: [-352.685 -352.685 -352.685] [0.0000], Avg: [-517.287 -517.287 -517.287] (1.000)
Step: 43199, Reward: [-451.905 -451.905 -451.905] [0.0000], Avg: [-517.212 -517.212 -517.212] (1.000)
Step: 43249, Reward: [-487.435 -487.435 -487.435] [0.0000], Avg: [-517.177 -517.177 -517.177] (1.000)
Step: 43299, Reward: [-438.761 -438.761 -438.761] [0.0000], Avg: [-517.087 -517.087 -517.087] (1.000)
Step: 43349, Reward: [-594.635 -594.635 -594.635] [0.0000], Avg: [-517.176 -517.176 -517.176] (1.000)
Step: 43399, Reward: [-367.821 -367.821 -367.821] [0.0000], Avg: [-517.004 -517.004 -517.004] (1.000)
Step: 43449, Reward: [-306.407 -306.407 -306.407] [0.0000], Avg: [-516.762 -516.762 -516.762] (1.000)
Step: 43499, Reward: [-401.817 -401.817 -401.817] [0.0000], Avg: [-516.63 -516.63 -516.63] (1.000)
Step: 43549, Reward: [-501.017 -501.017 -501.017] [0.0000], Avg: [-516.612 -516.612 -516.612] (1.000)
Step: 43599, Reward: [-512.049 -512.049 -512.049] [0.0000], Avg: [-516.607 -516.607 -516.607] (1.000)
Step: 43649, Reward: [-433.012 -433.012 -433.012] [0.0000], Avg: [-516.511 -516.511 -516.511] (1.000)
Step: 43699, Reward: [-465.802 -465.802 -465.802] [0.0000], Avg: [-516.453 -516.453 -516.453] (1.000)
Step: 43749, Reward: [-585.865 -585.865 -585.865] [0.0000], Avg: [-516.532 -516.532 -516.532] (1.000)
Step: 43799, Reward: [-445.108 -445.108 -445.108] [0.0000], Avg: [-516.451 -516.451 -516.451] (1.000)
Step: 43849, Reward: [-502.694 -502.694 -502.694] [0.0000], Avg: [-516.435 -516.435 -516.435] (1.000)
Step: 43899, Reward: [-394.441 -394.441 -394.441] [0.0000], Avg: [-516.296 -516.296 -516.296] (1.000)
Step: 43949, Reward: [-381.42 -381.42 -381.42] [0.0000], Avg: [-516.142 -516.142 -516.142] (1.000)
Step: 43999, Reward: [-492.569 -492.569 -492.569] [0.0000], Avg: [-516.116 -516.116 -516.116] (1.000)
Step: 44049, Reward: [-386.864 -386.864 -386.864] [0.0000], Avg: [-515.969 -515.969 -515.969] (1.000)
Step: 44099, Reward: [-499.54 -499.54 -499.54] [0.0000], Avg: [-515.95 -515.95 -515.95] (1.000)
Step: 44149, Reward: [-360.504 -360.504 -360.504] [0.0000], Avg: [-515.774 -515.774 -515.774] (1.000)
Step: 44199, Reward: [-354.171 -354.171 -354.171] [0.0000], Avg: [-515.591 -515.591 -515.591] (1.000)
Step: 44249, Reward: [-346.565 -346.565 -346.565] [0.0000], Avg: [-515.4 -515.4 -515.4] (1.000)
Step: 44299, Reward: [-421.121 -421.121 -421.121] [0.0000], Avg: [-515.294 -515.294 -515.294] (1.000)
Step: 44349, Reward: [-308.349 -308.349 -308.349] [0.0000], Avg: [-515.061 -515.061 -515.061] (1.000)
Step: 44399, Reward: [-408.674 -408.674 -408.674] [0.0000], Avg: [-514.941 -514.941 -514.941] (1.000)
Step: 44449, Reward: [-344.033 -344.033 -344.033] [0.0000], Avg: [-514.749 -514.749 -514.749] (1.000)
Step: 44499, Reward: [-311.532 -311.532 -311.532] [0.0000], Avg: [-514.52 -514.52 -514.52] (1.000)
Step: 44549, Reward: [-443.038 -443.038 -443.038] [0.0000], Avg: [-514.44 -514.44 -514.44] (1.000)
Step: 44599, Reward: [-404.932 -404.932 -404.932] [0.0000], Avg: [-514.317 -514.317 -514.317] (1.000)
Step: 44649, Reward: [-327.72 -327.72 -327.72] [0.0000], Avg: [-514.108 -514.108 -514.108] (1.000)
Step: 44699, Reward: [-346.88 -346.88 -346.88] [0.0000], Avg: [-513.921 -513.921 -513.921] (1.000)
Step: 44749, Reward: [-358.807 -358.807 -358.807] [0.0000], Avg: [-513.748 -513.748 -513.748] (1.000)
Step: 44799, Reward: [-349.092 -349.092 -349.092] [0.0000], Avg: [-513.564 -513.564 -513.564] (1.000)
Step: 44849, Reward: [-367.452 -367.452 -367.452] [0.0000], Avg: [-513.401 -513.401 -513.401] (1.000)
Step: 44899, Reward: [-578.043 -578.043 -578.043] [0.0000], Avg: [-513.473 -513.473 -513.473] (1.000)
Step: 44949, Reward: [-518.725 -518.725 -518.725] [0.0000], Avg: [-513.479 -513.479 -513.479] (1.000)
Step: 44999, Reward: [-364.001 -364.001 -364.001] [0.0000], Avg: [-513.313 -513.313 -513.313] (1.000)
Step: 45049, Reward: [-368.403 -368.403 -368.403] [0.0000], Avg: [-513.152 -513.152 -513.152] (1.000)
Step: 45099, Reward: [-322.223 -322.223 -322.223] [0.0000], Avg: [-512.941 -512.941 -512.941] (1.000)
Step: 45149, Reward: [-455.445 -455.445 -455.445] [0.0000], Avg: [-512.877 -512.877 -512.877] (1.000)
Step: 45199, Reward: [-313.159 -313.159 -313.159] [0.0000], Avg: [-512.656 -512.656 -512.656] (1.000)
Step: 45249, Reward: [-474.564 -474.564 -474.564] [0.0000], Avg: [-512.614 -512.614 -512.614] (1.000)
Step: 45299, Reward: [-479.515 -479.515 -479.515] [0.0000], Avg: [-512.577 -512.577 -512.577] (1.000)
Step: 45349, Reward: [-437.112 -437.112 -437.112] [0.0000], Avg: [-512.494 -512.494 -512.494] (1.000)
Step: 45399, Reward: [-337.971 -337.971 -337.971] [0.0000], Avg: [-512.302 -512.302 -512.302] (1.000)
Step: 45449, Reward: [-400.839 -400.839 -400.839] [0.0000], Avg: [-512.179 -512.179 -512.179] (1.000)
Step: 45499, Reward: [-446.965 -446.965 -446.965] [0.0000], Avg: [-512.108 -512.108 -512.108] (1.000)
Step: 45549, Reward: [-418.5 -418.5 -418.5] [0.0000], Avg: [-512.005 -512.005 -512.005] (1.000)
Step: 45599, Reward: [-388.712 -388.712 -388.712] [0.0000], Avg: [-511.87 -511.87 -511.87] (1.000)
Step: 45649, Reward: [-422.895 -422.895 -422.895] [0.0000], Avg: [-511.772 -511.772 -511.772] (1.000)
Step: 45699, Reward: [-422.702 -422.702 -422.702] [0.0000], Avg: [-511.675 -511.675 -511.675] (1.000)
Step: 45749, Reward: [-461.616 -461.616 -461.616] [0.0000], Avg: [-511.62 -511.62 -511.62] (1.000)
Step: 45799, Reward: [-550.592 -550.592 -550.592] [0.0000], Avg: [-511.663 -511.663 -511.663] (1.000)
Step: 45849, Reward: [-332.01 -332.01 -332.01] [0.0000], Avg: [-511.467 -511.467 -511.467] (1.000)
Step: 45899, Reward: [-477.57 -477.57 -477.57] [0.0000], Avg: [-511.43 -511.43 -511.43] (1.000)
Step: 45949, Reward: [-441.822 -441.822 -441.822] [0.0000], Avg: [-511.354 -511.354 -511.354] (1.000)
Step: 45999, Reward: [-419.621 -419.621 -419.621] [0.0000], Avg: [-511.254 -511.254 -511.254] (1.000)
Step: 46049, Reward: [-435.546 -435.546 -435.546] [0.0000], Avg: [-511.172 -511.172 -511.172] (1.000)
Step: 46099, Reward: [-360.175 -360.175 -360.175] [0.0000], Avg: [-511.008 -511.008 -511.008] (1.000)
Step: 46149, Reward: [-412.905 -412.905 -412.905] [0.0000], Avg: [-510.902 -510.902 -510.902] (1.000)
Step: 46199, Reward: [-427.127 -427.127 -427.127] [0.0000], Avg: [-510.812 -510.812 -510.812] (1.000)
Step: 46249, Reward: [-346.662 -346.662 -346.662] [0.0000], Avg: [-510.634 -510.634 -510.634] (1.000)
Step: 46299, Reward: [-362.139 -362.139 -362.139] [0.0000], Avg: [-510.474 -510.474 -510.474] (1.000)
Step: 46349, Reward: [-311.617 -311.617 -311.617] [0.0000], Avg: [-510.259 -510.259 -510.259] (1.000)
Step: 46399, Reward: [-432.537 -432.537 -432.537] [0.0000], Avg: [-510.175 -510.175 -510.175] (1.000)
Step: 46449, Reward: [-311.453 -311.453 -311.453] [0.0000], Avg: [-509.962 -509.962 -509.962] (1.000)
Step: 46499, Reward: [-397.187 -397.187 -397.187] [0.0000], Avg: [-509.84 -509.84 -509.84] (1.000)
Step: 46549, Reward: [-409.03 -409.03 -409.03] [0.0000], Avg: [-509.732 -509.732 -509.732] (1.000)
Step: 46599, Reward: [-359.029 -359.029 -359.029] [0.0000], Avg: [-509.57 -509.57 -509.57] (1.000)
Step: 46649, Reward: [-323.341 -323.341 -323.341] [0.0000], Avg: [-509.371 -509.371 -509.371] (1.000)
Step: 46699, Reward: [-392.973 -392.973 -392.973] [0.0000], Avg: [-509.246 -509.246 -509.246] (1.000)
Step: 46749, Reward: [-436.431 -436.431 -436.431] [0.0000], Avg: [-509.168 -509.168 -509.168] (1.000)
Step: 46799, Reward: [-355.305 -355.305 -355.305] [0.0000], Avg: [-509.004 -509.004 -509.004] (1.000)
Step: 46849, Reward: [-547.432 -547.432 -547.432] [0.0000], Avg: [-509.045 -509.045 -509.045] (1.000)
Step: 46899, Reward: [-535.176 -535.176 -535.176] [0.0000], Avg: [-509.073 -509.073 -509.073] (1.000)
Step: 46949, Reward: [-298.843 -298.843 -298.843] [0.0000], Avg: [-508.849 -508.849 -508.849] (1.000)
Step: 46999, Reward: [-374.84 -374.84 -374.84] [0.0000], Avg: [-508.706 -508.706 -508.706] (1.000)
Step: 47049, Reward: [-411.543 -411.543 -411.543] [0.0000], Avg: [-508.603 -508.603 -508.603] (1.000)
Step: 47099, Reward: [-420.955 -420.955 -420.955] [0.0000], Avg: [-508.51 -508.51 -508.51] (1.000)
Step: 47149, Reward: [-415.433 -415.433 -415.433] [0.0000], Avg: [-508.411 -508.411 -508.411] (1.000)
Step: 47199, Reward: [-403.551 -403.551 -403.551] [0.0000], Avg: [-508.3 -508.3 -508.3] (1.000)
Step: 47249, Reward: [-343.169 -343.169 -343.169] [0.0000], Avg: [-508.125 -508.125 -508.125] (1.000)
Step: 47299, Reward: [-446.205 -446.205 -446.205] [0.0000], Avg: [-508.06 -508.06 -508.06] (1.000)
Step: 47349, Reward: [-376.903 -376.903 -376.903] [0.0000], Avg: [-507.921 -507.921 -507.921] (1.000)
Step: 47399, Reward: [-337.355 -337.355 -337.355] [0.0000], Avg: [-507.741 -507.741 -507.741] (1.000)
Step: 47449, Reward: [-371. -371. -371.] [0.0000], Avg: [-507.597 -507.597 -507.597] (1.000)
Step: 47499, Reward: [-326.055 -326.055 -326.055] [0.0000], Avg: [-507.406 -507.406 -507.406] (1.000)
Step: 47549, Reward: [-379.189 -379.189 -379.189] [0.0000], Avg: [-507.271 -507.271 -507.271] (1.000)
Step: 47599, Reward: [-347.278 -347.278 -347.278] [0.0000], Avg: [-507.103 -507.103 -507.103] (1.000)
Step: 47649, Reward: [-416.904 -416.904 -416.904] [0.0000], Avg: [-507.009 -507.009 -507.009] (1.000)
Step: 47699, Reward: [-319.068 -319.068 -319.068] [0.0000], Avg: [-506.812 -506.812 -506.812] (1.000)
Step: 47749, Reward: [-469.524 -469.524 -469.524] [0.0000], Avg: [-506.773 -506.773 -506.773] (1.000)
Step: 47799, Reward: [-389.739 -389.739 -389.739] [0.0000], Avg: [-506.65 -506.65 -506.65] (1.000)
Step: 47849, Reward: [-398.546 -398.546 -398.546] [0.0000], Avg: [-506.537 -506.537 -506.537] (1.000)
Step: 47899, Reward: [-318.532 -318.532 -318.532] [0.0000], Avg: [-506.341 -506.341 -506.341] (1.000)
Step: 47949, Reward: [-410.533 -410.533 -410.533] [0.0000], Avg: [-506.241 -506.241 -506.241] (1.000)
Step: 47999, Reward: [-567.359 -567.359 -567.359] [0.0000], Avg: [-506.305 -506.305 -506.305] (1.000)
Step: 48049, Reward: [-433.543 -433.543 -433.543] [0.0000], Avg: [-506.229 -506.229 -506.229] (1.000)
Step: 48099, Reward: [-417.547 -417.547 -417.547] [0.0000], Avg: [-506.137 -506.137 -506.137] (1.000)
Step: 48149, Reward: [-386.742 -386.742 -386.742] [0.0000], Avg: [-506.013 -506.013 -506.013] (1.000)
Step: 48199, Reward: [-467.755 -467.755 -467.755] [0.0000], Avg: [-505.973 -505.973 -505.973] (1.000)
Step: 48249, Reward: [-326.593 -326.593 -326.593] [0.0000], Avg: [-505.787 -505.787 -505.787] (1.000)
Step: 48299, Reward: [-356.633 -356.633 -356.633] [0.0000], Avg: [-505.633 -505.633 -505.633] (1.000)
Step: 48349, Reward: [-451.544 -451.544 -451.544] [0.0000], Avg: [-505.577 -505.577 -505.577] (1.000)
Step: 48399, Reward: [-496.159 -496.159 -496.159] [0.0000], Avg: [-505.567 -505.567 -505.567] (1.000)
Step: 48449, Reward: [-490.882 -490.882 -490.882] [0.0000], Avg: [-505.552 -505.552 -505.552] (1.000)
Step: 48499, Reward: [-315.248 -315.248 -315.248] [0.0000], Avg: [-505.356 -505.356 -505.356] (1.000)
Step: 48549, Reward: [-439.847 -439.847 -439.847] [0.0000], Avg: [-505.289 -505.289 -505.289] (1.000)
Step: 48599, Reward: [-323.539 -323.539 -323.539] [0.0000], Avg: [-505.102 -505.102 -505.102] (1.000)
Step: 48649, Reward: [-349.957 -349.957 -349.957] [0.0000], Avg: [-504.942 -504.942 -504.942] (1.000)
Step: 48699, Reward: [-304.675 -304.675 -304.675] [0.0000], Avg: [-504.736 -504.736 -504.736] (1.000)
Step: 48749, Reward: [-410.456 -410.456 -410.456] [0.0000], Avg: [-504.64 -504.64 -504.64] (1.000)
Step: 48799, Reward: [-453.178 -453.178 -453.178] [0.0000], Avg: [-504.587 -504.587 -504.587] (1.000)
Step: 48849, Reward: [-374.281 -374.281 -374.281] [0.0000], Avg: [-504.454 -504.454 -504.454] (1.000)
Step: 48899, Reward: [-396.363 -396.363 -396.363] [0.0000], Avg: [-504.343 -504.343 -504.343] (1.000)
Step: 48949, Reward: [-397.872 -397.872 -397.872] [0.0000], Avg: [-504.234 -504.234 -504.234] (1.000)
Step: 48999, Reward: [-365.478 -365.478 -365.478] [0.0000], Avg: [-504.093 -504.093 -504.093] (1.000)
Step: 49049, Reward: [-360.902 -360.902 -360.902] [0.0000], Avg: [-503.947 -503.947 -503.947] (1.000)
Step: 49099, Reward: [-338.125 -338.125 -338.125] [0.0000], Avg: [-503.778 -503.778 -503.778] (1.000)
Step: 49149, Reward: [-389.957 -389.957 -389.957] [0.0000], Avg: [-503.662 -503.662 -503.662] (1.000)
Step: 49199, Reward: [-305.021 -305.021 -305.021] [0.0000], Avg: [-503.46 -503.46 -503.46] (1.000)
Step: 49249, Reward: [-480.859 -480.859 -480.859] [0.0000], Avg: [-503.437 -503.437 -503.437] (1.000)
Step: 49299, Reward: [-410.02 -410.02 -410.02] [0.0000], Avg: [-503.343 -503.343 -503.343] (1.000)
Step: 49349, Reward: [-327.462 -327.462 -327.462] [0.0000], Avg: [-503.164 -503.164 -503.164] (1.000)
Step: 49399, Reward: [-522.343 -522.343 -522.343] [0.0000], Avg: [-503.184 -503.184 -503.184] (1.000)
Step: 49449, Reward: [-365.623 -365.623 -365.623] [0.0000], Avg: [-503.045 -503.045 -503.045] (1.000)
Step: 49499, Reward: [-392.813 -392.813 -392.813] [0.0000], Avg: [-502.933 -502.933 -502.933] (1.000)
Step: 49549, Reward: [-394.151 -394.151 -394.151] [0.0000], Avg: [-502.824 -502.824 -502.824] (1.000)
Step: 49599, Reward: [-476.502 -476.502 -476.502] [0.0000], Avg: [-502.797 -502.797 -502.797] (1.000)
Step: 49649, Reward: [-413.724 -413.724 -413.724] [0.0000], Avg: [-502.707 -502.707 -502.707] (1.000)
Step: 49699, Reward: [-352.135 -352.135 -352.135] [0.0000], Avg: [-502.556 -502.556 -502.556] (1.000)
Step: 49749, Reward: [-298.235 -298.235 -298.235] [0.0000], Avg: [-502.351 -502.351 -502.351] (1.000)
Step: 49799, Reward: [-333.765 -333.765 -333.765] [0.0000], Avg: [-502.181 -502.181 -502.181] (1.000)
Step: 49849, Reward: [-416.189 -416.189 -416.189] [0.0000], Avg: [-502.095 -502.095 -502.095] (1.000)
Step: 49899, Reward: [-367.186 -367.186 -367.186] [0.0000], Avg: [-501.96 -501.96 -501.96] (1.000)
Step: 49949, Reward: [-296.641 -296.641 -296.641] [0.0000], Avg: [-501.754 -501.754 -501.754] (1.000)
Step: 49999, Reward: [-426.681 -426.681 -426.681] [0.0000], Avg: [-501.679 -501.679 -501.679] (1.000)
Step: 50049, Reward: [-310.927 -310.927 -310.927] [0.0000], Avg: [-501.489 -501.489 -501.489] (1.000)
Step: 50099, Reward: [-329.95 -329.95 -329.95] [0.0000], Avg: [-501.318 -501.318 -501.318] (1.000)
Step: 50149, Reward: [-569.871 -569.871 -569.871] [0.0000], Avg: [-501.386 -501.386 -501.386] (1.000)
Step: 50199, Reward: [-252.069 -252.069 -252.069] [0.0000], Avg: [-501.138 -501.138 -501.138] (1.000)
Step: 50249, Reward: [-461.981 -461.981 -461.981] [0.0000], Avg: [-501.099 -501.099 -501.099] (1.000)
Step: 50299, Reward: [-312.37 -312.37 -312.37] [0.0000], Avg: [-500.911 -500.911 -500.911] (1.000)
Step: 50349, Reward: [-350.396 -350.396 -350.396] [0.0000], Avg: [-500.762 -500.762 -500.762] (1.000)
Step: 50399, Reward: [-367.269 -367.269 -367.269] [0.0000], Avg: [-500.629 -500.629 -500.629] (1.000)
Step: 50449, Reward: [-389.845 -389.845 -389.845] [0.0000], Avg: [-500.519 -500.519 -500.519] (1.000)
Step: 50499, Reward: [-410.037 -410.037 -410.037] [0.0000], Avg: [-500.43 -500.43 -500.43] (1.000)
Step: 50549, Reward: [-318.003 -318.003 -318.003] [0.0000], Avg: [-500.249 -500.249 -500.249] (1.000)
Step: 50599, Reward: [-248.736 -248.736 -248.736] [0.0000], Avg: [-500.001 -500.001 -500.001] (1.000)
Step: 50649, Reward: [-469.007 -469.007 -469.007] [0.0000], Avg: [-499.97 -499.97 -499.97] (1.000)
Step: 50699, Reward: [-412.409 -412.409 -412.409] [0.0000], Avg: [-499.884 -499.884 -499.884] (1.000)
Step: 50749, Reward: [-322.167 -322.167 -322.167] [0.0000], Avg: [-499.709 -499.709 -499.709] (1.000)
Step: 50799, Reward: [-306.187 -306.187 -306.187] [0.0000], Avg: [-499.518 -499.518 -499.518] (1.000)
Step: 50849, Reward: [-494.813 -494.813 -494.813] [0.0000], Avg: [-499.514 -499.514 -499.514] (1.000)
Step: 50899, Reward: [-363.642 -363.642 -363.642] [0.0000], Avg: [-499.38 -499.38 -499.38] (1.000)
Step: 50949, Reward: [-311.486 -311.486 -311.486] [0.0000], Avg: [-499.196 -499.196 -499.196] (1.000)
Step: 50999, Reward: [-285.745 -285.745 -285.745] [0.0000], Avg: [-498.986 -498.986 -498.986] (1.000)
Step: 51049, Reward: [-450.673 -450.673 -450.673] [0.0000], Avg: [-498.939 -498.939 -498.939] (1.000)
Step: 51099, Reward: [-366.414 -366.414 -366.414] [0.0000], Avg: [-498.809 -498.809 -498.809] (1.000)
Step: 51149, Reward: [-425.788 -425.788 -425.788] [0.0000], Avg: [-498.738 -498.738 -498.738] (1.000)
Step: 51199, Reward: [-478.917 -478.917 -478.917] [0.0000], Avg: [-498.719 -498.719 -498.719] (1.000)
Step: 51249, Reward: [-519.864 -519.864 -519.864] [0.0000], Avg: [-498.739 -498.739 -498.739] (1.000)
Step: 51299, Reward: [-459.028 -459.028 -459.028] [0.0000], Avg: [-498.701 -498.701 -498.701] (1.000)
Step: 51349, Reward: [-361.752 -361.752 -361.752] [0.0000], Avg: [-498.567 -498.567 -498.567] (1.000)
Step: 51399, Reward: [-388.042 -388.042 -388.042] [0.0000], Avg: [-498.46 -498.46 -498.46] (1.000)
Step: 51449, Reward: [-427.315 -427.315 -427.315] [0.0000], Avg: [-498.391 -498.391 -498.391] (1.000)
Step: 51499, Reward: [-301.7 -301.7 -301.7] [0.0000], Avg: [-498.2 -498.2 -498.2] (1.000)
Step: 51549, Reward: [-309.519 -309.519 -309.519] [0.0000], Avg: [-498.017 -498.017 -498.017] (1.000)
Step: 51599, Reward: [-372.302 -372.302 -372.302] [0.0000], Avg: [-497.895 -497.895 -497.895] (1.000)
Step: 51649, Reward: [-335.715 -335.715 -335.715] [0.0000], Avg: [-497.738 -497.738 -497.738] (1.000)
Step: 51699, Reward: [-439.376 -439.376 -439.376] [0.0000], Avg: [-497.681 -497.681 -497.681] (1.000)
Step: 51749, Reward: [-321.156 -321.156 -321.156] [0.0000], Avg: [-497.511 -497.511 -497.511] (1.000)
Step: 51799, Reward: [-415.052 -415.052 -415.052] [0.0000], Avg: [-497.431 -497.431 -497.431] (1.000)
Step: 51849, Reward: [-324.491 -324.491 -324.491] [0.0000], Avg: [-497.265 -497.265 -497.265] (1.000)
Step: 51899, Reward: [-422.009 -422.009 -422.009] [0.0000], Avg: [-497.192 -497.192 -497.192] (1.000)
Step: 51949, Reward: [-387.181 -387.181 -387.181] [0.0000], Avg: [-497.086 -497.086 -497.086] (1.000)
Step: 51999, Reward: [-299.055 -299.055 -299.055] [0.0000], Avg: [-496.896 -496.896 -496.896] (1.000)
Step: 52049, Reward: [-337.406 -337.406 -337.406] [0.0000], Avg: [-496.743 -496.743 -496.743] (1.000)
Step: 52099, Reward: [-400.594 -400.594 -400.594] [0.0000], Avg: [-496.65 -496.65 -496.65] (1.000)
Step: 52149, Reward: [-370.821 -370.821 -370.821] [0.0000], Avg: [-496.53 -496.53 -496.53] (1.000)
Step: 52199, Reward: [-377.487 -377.487 -377.487] [0.0000], Avg: [-496.416 -496.416 -496.416] (1.000)
Step: 52249, Reward: [-380.413 -380.413 -380.413] [0.0000], Avg: [-496.305 -496.305 -496.305] (1.000)
Step: 52299, Reward: [-396.74 -396.74 -396.74] [0.0000], Avg: [-496.209 -496.209 -496.209] (1.000)
Step: 52349, Reward: [-378.944 -378.944 -378.944] [0.0000], Avg: [-496.097 -496.097 -496.097] (1.000)
Step: 52399, Reward: [-495.772 -495.772 -495.772] [0.0000], Avg: [-496.097 -496.097 -496.097] (1.000)
Step: 52449, Reward: [-338.443 -338.443 -338.443] [0.0000], Avg: [-495.947 -495.947 -495.947] (1.000)
Step: 52499, Reward: [-475.192 -475.192 -475.192] [0.0000], Avg: [-495.927 -495.927 -495.927] (1.000)
Step: 52549, Reward: [-391.616 -391.616 -391.616] [0.0000], Avg: [-495.828 -495.828 -495.828] (1.000)
Step: 52599, Reward: [-346.147 -346.147 -346.147] [0.0000], Avg: [-495.685 -495.685 -495.685] (1.000)
Step: 52649, Reward: [-403.579 -403.579 -403.579] [0.0000], Avg: [-495.598 -495.598 -495.598] (1.000)
Step: 52699, Reward: [-376.39 -376.39 -376.39] [0.0000], Avg: [-495.485 -495.485 -495.485] (1.000)
Step: 52749, Reward: [-411.308 -411.308 -411.308] [0.0000], Avg: [-495.405 -495.405 -495.405] (1.000)
Step: 52799, Reward: [-270.77 -270.77 -270.77] [0.0000], Avg: [-495.192 -495.192 -495.192] (1.000)
Step: 52849, Reward: [-466.328 -466.328 -466.328] [0.0000], Avg: [-495.165 -495.165 -495.165] (1.000)
Step: 52899, Reward: [-367.109 -367.109 -367.109] [0.0000], Avg: [-495.044 -495.044 -495.044] (1.000)
Step: 52949, Reward: [-310.558 -310.558 -310.558] [0.0000], Avg: [-494.87 -494.87 -494.87] (1.000)
Step: 52999, Reward: [-353.627 -353.627 -353.627] [0.0000], Avg: [-494.737 -494.737 -494.737] (1.000)
Step: 53049, Reward: [-444.641 -444.641 -444.641] [0.0000], Avg: [-494.689 -494.689 -494.689] (1.000)
Step: 53099, Reward: [-335.264 -335.264 -335.264] [0.0000], Avg: [-494.539 -494.539 -494.539] (1.000)
Step: 53149, Reward: [-336.151 -336.151 -336.151] [0.0000], Avg: [-494.39 -494.39 -494.39] (1.000)
Step: 53199, Reward: [-409.063 -409.063 -409.063] [0.0000], Avg: [-494.31 -494.31 -494.31] (1.000)
Step: 53249, Reward: [-355.438 -355.438 -355.438] [0.0000], Avg: [-494.18 -494.18 -494.18] (1.000)
Step: 53299, Reward: [-389.149 -389.149 -389.149] [0.0000], Avg: [-494.081 -494.081 -494.081] (1.000)
Step: 53349, Reward: [-340.939 -340.939 -340.939] [0.0000], Avg: [-493.938 -493.938 -493.938] (1.000)
Step: 53399, Reward: [-420.072 -420.072 -420.072] [0.0000], Avg: [-493.868 -493.868 -493.868] (1.000)
Step: 53449, Reward: [-379.532 -379.532 -379.532] [0.0000], Avg: [-493.761 -493.761 -493.761] (1.000)
Step: 53499, Reward: [-388.473 -388.473 -388.473] [0.0000], Avg: [-493.663 -493.663 -493.663] (1.000)
Step: 53549, Reward: [-394.793 -394.793 -394.793] [0.0000], Avg: [-493.571 -493.571 -493.571] (1.000)
Step: 53599, Reward: [-346.14 -346.14 -346.14] [0.0000], Avg: [-493.433 -493.433 -493.433] (1.000)
Step: 53649, Reward: [-431.804 -431.804 -431.804] [0.0000], Avg: [-493.376 -493.376 -493.376] (1.000)
Step: 53699, Reward: [-312.882 -312.882 -312.882] [0.0000], Avg: [-493.208 -493.208 -493.208] (1.000)
Step: 53749, Reward: [-597.144 -597.144 -597.144] [0.0000], Avg: [-493.304 -493.304 -493.304] (1.000)
Step: 53799, Reward: [-366.401 -366.401 -366.401] [0.0000], Avg: [-493.187 -493.187 -493.187] (1.000)
Step: 53849, Reward: [-413.062 -413.062 -413.062] [0.0000], Avg: [-493.112 -493.112 -493.112] (1.000)
Step: 53899, Reward: [-491.947 -491.947 -491.947] [0.0000], Avg: [-493.111 -493.111 -493.111] (1.000)
Step: 53949, Reward: [-404.464 -404.464 -404.464] [0.0000], Avg: [-493.029 -493.029 -493.029] (1.000)
Step: 53999, Reward: [-338.015 -338.015 -338.015] [0.0000], Avg: [-492.885 -492.885 -492.885] (1.000)
Step: 54049, Reward: [-301.527 -301.527 -301.527] [0.0000], Avg: [-492.708 -492.708 -492.708] (1.000)
Step: 54099, Reward: [-454.595 -454.595 -454.595] [0.0000], Avg: [-492.673 -492.673 -492.673] (1.000)
Step: 54149, Reward: [-436.661 -436.661 -436.661] [0.0000], Avg: [-492.621 -492.621 -492.621] (1.000)
Step: 54199, Reward: [-503.798 -503.798 -503.798] [0.0000], Avg: [-492.632 -492.632 -492.632] (1.000)
Step: 54249, Reward: [-360.545 -360.545 -360.545] [0.0000], Avg: [-492.51 -492.51 -492.51] (1.000)
Step: 54299, Reward: [-446.349 -446.349 -446.349] [0.0000], Avg: [-492.467 -492.467 -492.467] (1.000)
Step: 54349, Reward: [-357.042 -357.042 -357.042] [0.0000], Avg: [-492.343 -492.343 -492.343] (1.000)
Step: 54399, Reward: [-356.085 -356.085 -356.085] [0.0000], Avg: [-492.218 -492.218 -492.218] (1.000)
Step: 54449, Reward: [-366.837 -366.837 -366.837] [0.0000], Avg: [-492.102 -492.102 -492.102] (1.000)
Step: 54499, Reward: [-413.883 -413.883 -413.883] [0.0000], Avg: [-492.031 -492.031 -492.031] (1.000)
Step: 54549, Reward: [-420.306 -420.306 -420.306] [0.0000], Avg: [-491.965 -491.965 -491.965] (1.000)
Step: 54599, Reward: [-338.852 -338.852 -338.852] [0.0000], Avg: [-491.825 -491.825 -491.825] (1.000)
Step: 54649, Reward: [-338.194 -338.194 -338.194] [0.0000], Avg: [-491.684 -491.684 -491.684] (1.000)
Step: 54699, Reward: [-436.723 -436.723 -436.723] [0.0000], Avg: [-491.634 -491.634 -491.634] (1.000)
Step: 54749, Reward: [-351.174 -351.174 -351.174] [0.0000], Avg: [-491.506 -491.506 -491.506] (1.000)
Step: 54799, Reward: [-370.733 -370.733 -370.733] [0.0000], Avg: [-491.395 -491.395 -491.395] (1.000)
Step: 54849, Reward: [-379.866 -379.866 -379.866] [0.0000], Avg: [-491.294 -491.294 -491.294] (1.000)
Step: 54899, Reward: [-475.265 -475.265 -475.265] [0.0000], Avg: [-491.279 -491.279 -491.279] (1.000)
Step: 54949, Reward: [-294.511 -294.511 -294.511] [0.0000], Avg: [-491.1 -491.1 -491.1] (1.000)
Step: 54999, Reward: [-309.825 -309.825 -309.825] [0.0000], Avg: [-490.935 -490.935 -490.935] (1.000)
Step: 55049, Reward: [-477.207 -477.207 -477.207] [0.0000], Avg: [-490.923 -490.923 -490.923] (1.000)
Step: 55099, Reward: [-401.51 -401.51 -401.51] [0.0000], Avg: [-490.842 -490.842 -490.842] (1.000)
Step: 55149, Reward: [-299.758 -299.758 -299.758] [0.0000], Avg: [-490.669 -490.669 -490.669] (1.000)
Step: 55199, Reward: [-391.95 -391.95 -391.95] [0.0000], Avg: [-490.579 -490.579 -490.579] (1.000)
Step: 55249, Reward: [-369.032 -369.032 -369.032] [0.0000], Avg: [-490.469 -490.469 -490.469] (1.000)
Step: 55299, Reward: [-422.995 -422.995 -422.995] [0.0000], Avg: [-490.408 -490.408 -490.408] (1.000)
Step: 55349, Reward: [-426.327 -426.327 -426.327] [0.0000], Avg: [-490.35 -490.35 -490.35] (1.000)
Step: 55399, Reward: [-268.242 -268.242 -268.242] [0.0000], Avg: [-490.15 -490.15 -490.15] (1.000)
Step: 55449, Reward: [-290.066 -290.066 -290.066] [0.0000], Avg: [-489.969 -489.969 -489.969] (1.000)
Step: 55499, Reward: [-340.478 -340.478 -340.478] [0.0000], Avg: [-489.835 -489.835 -489.835] (1.000)
Step: 55549, Reward: [-388.043 -388.043 -388.043] [0.0000], Avg: [-489.743 -489.743 -489.743] (1.000)
Step: 55599, Reward: [-352.46 -352.46 -352.46] [0.0000], Avg: [-489.62 -489.62 -489.62] (1.000)
Step: 55649, Reward: [-469.955 -469.955 -469.955] [0.0000], Avg: [-489.602 -489.602 -489.602] (1.000)
Step: 55699, Reward: [-413.287 -413.287 -413.287] [0.0000], Avg: [-489.533 -489.533 -489.533] (1.000)
Step: 55749, Reward: [-306.657 -306.657 -306.657] [0.0000], Avg: [-489.369 -489.369 -489.369] (1.000)
Step: 55799, Reward: [-409.986 -409.986 -409.986] [0.0000], Avg: [-489.298 -489.298 -489.298] (1.000)
Step: 55849, Reward: [-455.252 -455.252 -455.252] [0.0000], Avg: [-489.268 -489.268 -489.268] (1.000)
Step: 55899, Reward: [-466.39 -466.39 -466.39] [0.0000], Avg: [-489.247 -489.247 -489.247] (1.000)
Step: 55949, Reward: [-373.356 -373.356 -373.356] [0.0000], Avg: [-489.144 -489.144 -489.144] (1.000)
Step: 55999, Reward: [-396.483 -396.483 -396.483] [0.0000], Avg: [-489.061 -489.061 -489.061] (1.000)
Step: 56049, Reward: [-331.897 -331.897 -331.897] [0.0000], Avg: [-488.921 -488.921 -488.921] (1.000)
Step: 56099, Reward: [-465.792 -465.792 -465.792] [0.0000], Avg: [-488.9 -488.9 -488.9] (1.000)
Step: 56149, Reward: [-457.637 -457.637 -457.637] [0.0000], Avg: [-488.872 -488.872 -488.872] (1.000)
Step: 56199, Reward: [-267.007 -267.007 -267.007] [0.0000], Avg: [-488.675 -488.675 -488.675] (1.000)
Step: 56249, Reward: [-352.516 -352.516 -352.516] [0.0000], Avg: [-488.554 -488.554 -488.554] (1.000)
Step: 56299, Reward: [-329.935 -329.935 -329.935] [0.0000], Avg: [-488.413 -488.413 -488.413] (1.000)
Step: 56349, Reward: [-391.748 -391.748 -391.748] [0.0000], Avg: [-488.327 -488.327 -488.327] (1.000)
Step: 56399, Reward: [-328.959 -328.959 -328.959] [0.0000], Avg: [-488.186 -488.186 -488.186] (1.000)
Step: 56449, Reward: [-312.22 -312.22 -312.22] [0.0000], Avg: [-488.03 -488.03 -488.03] (1.000)
Step: 56499, Reward: [-399.949 -399.949 -399.949] [0.0000], Avg: [-487.952 -487.952 -487.952] (1.000)
Step: 56549, Reward: [-360.149 -360.149 -360.149] [0.0000], Avg: [-487.839 -487.839 -487.839] (1.000)
Step: 56599, Reward: [-353.847 -353.847 -353.847] [0.0000], Avg: [-487.721 -487.721 -487.721] (1.000)
Step: 56649, Reward: [-450.828 -450.828 -450.828] [0.0000], Avg: [-487.688 -487.688 -487.688] (1.000)
Step: 56699, Reward: [-514.83 -514.83 -514.83] [0.0000], Avg: [-487.712 -487.712 -487.712] (1.000)
Step: 56749, Reward: [-346.887 -346.887 -346.887] [0.0000], Avg: [-487.588 -487.588 -487.588] (1.000)
Step: 56799, Reward: [-366.363 -366.363 -366.363] [0.0000], Avg: [-487.481 -487.481 -487.481] (1.000)
Step: 56849, Reward: [-412.553 -412.553 -412.553] [0.0000], Avg: [-487.416 -487.416 -487.416] (1.000)
Step: 56899, Reward: [-478.645 -478.645 -478.645] [0.0000], Avg: [-487.408 -487.408 -487.408] (1.000)
Step: 56949, Reward: [-431.51 -431.51 -431.51] [0.0000], Avg: [-487.359 -487.359 -487.359] (1.000)
Step: 56999, Reward: [-323.795 -323.795 -323.795] [0.0000], Avg: [-487.215 -487.215 -487.215] (1.000)
Step: 57049, Reward: [-397.929 -397.929 -397.929] [0.0000], Avg: [-487.137 -487.137 -487.137] (1.000)
Step: 57099, Reward: [-416.683 -416.683 -416.683] [0.0000], Avg: [-487.075 -487.075 -487.075] (1.000)
Step: 57149, Reward: [-344.955 -344.955 -344.955] [0.0000], Avg: [-486.951 -486.951 -486.951] (1.000)
Step: 57199, Reward: [-421.425 -421.425 -421.425] [0.0000], Avg: [-486.894 -486.894 -486.894] (1.000)
Step: 57249, Reward: [-332.944 -332.944 -332.944] [0.0000], Avg: [-486.759 -486.759 -486.759] (1.000)
Step: 57299, Reward: [-414.359 -414.359 -414.359] [0.0000], Avg: [-486.696 -486.696 -486.696] (1.000)
Step: 57349, Reward: [-462.322 -462.322 -462.322] [0.0000], Avg: [-486.675 -486.675 -486.675] (1.000)
Step: 57399, Reward: [-431.1 -431.1 -431.1] [0.0000], Avg: [-486.626 -486.626 -486.626] (1.000)
Step: 57449, Reward: [-441.176 -441.176 -441.176] [0.0000], Avg: [-486.587 -486.587 -486.587] (1.000)
Step: 57499, Reward: [-330.424 -330.424 -330.424] [0.0000], Avg: [-486.451 -486.451 -486.451] (1.000)
Step: 57549, Reward: [-434.137 -434.137 -434.137] [0.0000], Avg: [-486.406 -486.406 -486.406] (1.000)
Step: 57599, Reward: [-422.998 -422.998 -422.998] [0.0000], Avg: [-486.351 -486.351 -486.351] (1.000)
Step: 57649, Reward: [-446.947 -446.947 -446.947] [0.0000], Avg: [-486.316 -486.316 -486.316] (1.000)
Step: 57699, Reward: [-406.356 -406.356 -406.356] [0.0000], Avg: [-486.247 -486.247 -486.247] (1.000)
Step: 57749, Reward: [-351.882 -351.882 -351.882] [0.0000], Avg: [-486.131 -486.131 -486.131] (1.000)
Step: 57799, Reward: [-361.548 -361.548 -361.548] [0.0000], Avg: [-486.023 -486.023 -486.023] (1.000)
Step: 57849, Reward: [-267.601 -267.601 -267.601] [0.0000], Avg: [-485.834 -485.834 -485.834] (1.000)
Step: 57899, Reward: [-331.955 -331.955 -331.955] [0.0000], Avg: [-485.701 -485.701 -485.701] (1.000)
Step: 57949, Reward: [-369.603 -369.603 -369.603] [0.0000], Avg: [-485.601 -485.601 -485.601] (1.000)
Step: 57999, Reward: [-385.757 -385.757 -385.757] [0.0000], Avg: [-485.515 -485.515 -485.515] (1.000)
Step: 58049, Reward: [-424.662 -424.662 -424.662] [0.0000], Avg: [-485.463 -485.463 -485.463] (1.000)
Step: 58099, Reward: [-398.575 -398.575 -398.575] [0.0000], Avg: [-485.388 -485.388 -485.388] (1.000)
Step: 58149, Reward: [-310.928 -310.928 -310.928] [0.0000], Avg: [-485.238 -485.238 -485.238] (1.000)
Step: 58199, Reward: [-349.061 -349.061 -349.061] [0.0000], Avg: [-485.121 -485.121 -485.121] (1.000)
Step: 58249, Reward: [-404.02 -404.02 -404.02] [0.0000], Avg: [-485.051 -485.051 -485.051] (1.000)
Step: 58299, Reward: [-718.038 -718.038 -718.038] [0.0000], Avg: [-485.251 -485.251 -485.251] (1.000)
Step: 58349, Reward: [-357.25 -357.25 -357.25] [0.0000], Avg: [-485.141 -485.141 -485.141] (1.000)
Step: 58399, Reward: [-458.961 -458.961 -458.961] [0.0000], Avg: [-485.119 -485.119 -485.119] (1.000)
Step: 58449, Reward: [-396.172 -396.172 -396.172] [0.0000], Avg: [-485.043 -485.043 -485.043] (1.000)
Step: 58499, Reward: [-398.263 -398.263 -398.263] [0.0000], Avg: [-484.969 -484.969 -484.969] (1.000)
Step: 58549, Reward: [-296.724 -296.724 -296.724] [0.0000], Avg: [-484.808 -484.808 -484.808] (1.000)
Step: 58599, Reward: [-326.781 -326.781 -326.781] [0.0000], Avg: [-484.673 -484.673 -484.673] (1.000)
Step: 58649, Reward: [-332.768 -332.768 -332.768] [0.0000], Avg: [-484.544 -484.544 -484.544] (1.000)
Step: 58699, Reward: [-351.907 -351.907 -351.907] [0.0000], Avg: [-484.431 -484.431 -484.431] (1.000)
Step: 58749, Reward: [-364.919 -364.919 -364.919] [0.0000], Avg: [-484.329 -484.329 -484.329] (1.000)
Step: 58799, Reward: [-511.253 -511.253 -511.253] [0.0000], Avg: [-484.352 -484.352 -484.352] (1.000)
Step: 58849, Reward: [-339.793 -339.793 -339.793] [0.0000], Avg: [-484.229 -484.229 -484.229] (1.000)
Step: 58899, Reward: [-336.812 -336.812 -336.812] [0.0000], Avg: [-484.104 -484.104 -484.104] (1.000)
Step: 58949, Reward: [-444.672 -444.672 -444.672] [0.0000], Avg: [-484.07 -484.07 -484.07] (1.000)
Step: 58999, Reward: [-521.974 -521.974 -521.974] [0.0000], Avg: [-484.103 -484.103 -484.103] (1.000)
Step: 59049, Reward: [-484.949 -484.949 -484.949] [0.0000], Avg: [-484.103 -484.103 -484.103] (1.000)
Step: 59099, Reward: [-333.943 -333.943 -333.943] [0.0000], Avg: [-483.976 -483.976 -483.976] (1.000)
Step: 59149, Reward: [-423.612 -423.612 -423.612] [0.0000], Avg: [-483.925 -483.925 -483.925] (1.000)
Step: 59199, Reward: [-481.813 -481.813 -481.813] [0.0000], Avg: [-483.923 -483.923 -483.923] (1.000)
Step: 59249, Reward: [-414.163 -414.163 -414.163] [0.0000], Avg: [-483.865 -483.865 -483.865] (1.000)
Step: 59299, Reward: [-385.782 -385.782 -385.782] [0.0000], Avg: [-483.782 -483.782 -483.782] (1.000)
Step: 59349, Reward: [-401.915 -401.915 -401.915] [0.0000], Avg: [-483.713 -483.713 -483.713] (1.000)
Step: 59399, Reward: [-448.004 -448.004 -448.004] [0.0000], Avg: [-483.683 -483.683 -483.683] (1.000)
Step: 59449, Reward: [-368.063 -368.063 -368.063] [0.0000], Avg: [-483.586 -483.586 -483.586] (1.000)
Step: 59499, Reward: [-400.679 -400.679 -400.679] [0.0000], Avg: [-483.516 -483.516 -483.516] (1.000)
Step: 59549, Reward: [-550.111 -550.111 -550.111] [0.0000], Avg: [-483.572 -483.572 -483.572] (1.000)
Step: 59599, Reward: [-311.982 -311.982 -311.982] [0.0000], Avg: [-483.428 -483.428 -483.428] (1.000)
Step: 59649, Reward: [-331.43 -331.43 -331.43] [0.0000], Avg: [-483.301 -483.301 -483.301] (1.000)
Step: 59699, Reward: [-400.365 -400.365 -400.365] [0.0000], Avg: [-483.231 -483.231 -483.231] (1.000)
Step: 59749, Reward: [-402.889 -402.889 -402.889] [0.0000], Avg: [-483.164 -483.164 -483.164] (1.000)
Step: 59799, Reward: [-403.371 -403.371 -403.371] [0.0000], Avg: [-483.097 -483.097 -483.097] (1.000)
Step: 59849, Reward: [-473.601 -473.601 -473.601] [0.0000], Avg: [-483.089 -483.089 -483.089] (1.000)
Step: 59899, Reward: [-412.387 -412.387 -412.387] [0.0000], Avg: [-483.03 -483.03 -483.03] (1.000)
Step: 59949, Reward: [-425.336 -425.336 -425.336] [0.0000], Avg: [-482.982 -482.982 -482.982] (1.000)
Step: 59999, Reward: [-471.644 -471.644 -471.644] [0.0000], Avg: [-482.973 -482.973 -482.973] (1.000)
Step: 60049, Reward: [-406.072 -406.072 -406.072] [0.0000], Avg: [-482.909 -482.909 -482.909] (1.000)
Step: 60099, Reward: [-428.141 -428.141 -428.141] [0.0000], Avg: [-482.863 -482.863 -482.863] (1.000)
Step: 60149, Reward: [-487.389 -487.389 -487.389] [0.0000], Avg: [-482.867 -482.867 -482.867] (1.000)
Step: 60199, Reward: [-428.109 -428.109 -428.109] [0.0000], Avg: [-482.821 -482.821 -482.821] (1.000)
Step: 60249, Reward: [-269.753 -269.753 -269.753] [0.0000], Avg: [-482.644 -482.644 -482.644] (1.000)
Step: 60299, Reward: [-478.316 -478.316 -478.316] [0.0000], Avg: [-482.641 -482.641 -482.641] (1.000)
Step: 60349, Reward: [-427.337 -427.337 -427.337] [0.0000], Avg: [-482.595 -482.595 -482.595] (1.000)
Step: 60399, Reward: [-541.407 -541.407 -541.407] [0.0000], Avg: [-482.644 -482.644 -482.644] (1.000)
Step: 60449, Reward: [-439.749 -439.749 -439.749] [0.0000], Avg: [-482.608 -482.608 -482.608] (1.000)
Step: 60499, Reward: [-382.682 -382.682 -382.682] [0.0000], Avg: [-482.526 -482.526 -482.526] (1.000)
Step: 60549, Reward: [-412.748 -412.748 -412.748] [0.0000], Avg: [-482.468 -482.468 -482.468] (1.000)
Step: 60599, Reward: [-373.583 -373.583 -373.583] [0.0000], Avg: [-482.378 -482.378 -482.378] (1.000)
Step: 60649, Reward: [-330.776 -330.776 -330.776] [0.0000], Avg: [-482.253 -482.253 -482.253] (1.000)
Step: 60699, Reward: [-381.362 -381.362 -381.362] [0.0000], Avg: [-482.17 -482.17 -482.17] (1.000)
Step: 60749, Reward: [-313.968 -313.968 -313.968] [0.0000], Avg: [-482.032 -482.032 -482.032] (1.000)
Step: 60799, Reward: [-314.242 -314.242 -314.242] [0.0000], Avg: [-481.894 -481.894 -481.894] (1.000)
Step: 60849, Reward: [-302.85 -302.85 -302.85] [0.0000], Avg: [-481.747 -481.747 -481.747] (1.000)
Step: 60899, Reward: [-441.243 -441.243 -441.243] [0.0000], Avg: [-481.713 -481.713 -481.713] (1.000)
Step: 60949, Reward: [-378.927 -378.927 -378.927] [0.0000], Avg: [-481.629 -481.629 -481.629] (1.000)
Step: 60999, Reward: [-372.96 -372.96 -372.96] [0.0000], Avg: [-481.54 -481.54 -481.54] (1.000)
Step: 61049, Reward: [-293.789 -293.789 -293.789] [0.0000], Avg: [-481.386 -481.386 -481.386] (1.000)
Step: 61099, Reward: [-440.415 -440.415 -440.415] [0.0000], Avg: [-481.353 -481.353 -481.353] (1.000)
Step: 61149, Reward: [-355.57 -355.57 -355.57] [0.0000], Avg: [-481.25 -481.25 -481.25] (1.000)
Step: 61199, Reward: [-383.57 -383.57 -383.57] [0.0000], Avg: [-481.17 -481.17 -481.17] (1.000)
Step: 61249, Reward: [-517.18 -517.18 -517.18] [0.0000], Avg: [-481.199 -481.199 -481.199] (1.000)
Step: 61299, Reward: [-304.739 -304.739 -304.739] [0.0000], Avg: [-481.055 -481.055 -481.055] (1.000)
Step: 61349, Reward: [-405.813 -405.813 -405.813] [0.0000], Avg: [-480.994 -480.994 -480.994] (1.000)
Step: 61399, Reward: [-303.436 -303.436 -303.436] [0.0000], Avg: [-480.85 -480.85 -480.85] (1.000)
Step: 61449, Reward: [-407.111 -407.111 -407.111] [0.0000], Avg: [-480.79 -480.79 -480.79] (1.000)
Step: 61499, Reward: [-390.839 -390.839 -390.839] [0.0000], Avg: [-480.716 -480.716 -480.716] (1.000)
Step: 61549, Reward: [-433.226 -433.226 -433.226] [0.0000], Avg: [-480.678 -480.678 -480.678] (1.000)
Step: 61599, Reward: [-432.877 -432.877 -432.877] [0.0000], Avg: [-480.639 -480.639 -480.639] (1.000)
Step: 61649, Reward: [-324.611 -324.611 -324.611] [0.0000], Avg: [-480.512 -480.512 -480.512] (1.000)
Step: 61699, Reward: [-346.344 -346.344 -346.344] [0.0000], Avg: [-480.404 -480.404 -480.404] (1.000)
Step: 61749, Reward: [-384.322 -384.322 -384.322] [0.0000], Avg: [-480.326 -480.326 -480.326] (1.000)
Step: 61799, Reward: [-264.029 -264.029 -264.029] [0.0000], Avg: [-480.151 -480.151 -480.151] (1.000)
Step: 61849, Reward: [-313.595 -313.595 -313.595] [0.0000], Avg: [-480.016 -480.016 -480.016] (1.000)
Step: 61899, Reward: [-391.018 -391.018 -391.018] [0.0000], Avg: [-479.944 -479.944 -479.944] (1.000)
Step: 61949, Reward: [-442.008 -442.008 -442.008] [0.0000], Avg: [-479.914 -479.914 -479.914] (1.000)
Step: 61999, Reward: [-315.066 -315.066 -315.066] [0.0000], Avg: [-479.781 -479.781 -479.781] (1.000)
Step: 62049, Reward: [-336.127 -336.127 -336.127] [0.0000], Avg: [-479.665 -479.665 -479.665] (1.000)
Step: 62099, Reward: [-278.816 -278.816 -278.816] [0.0000], Avg: [-479.503 -479.503 -479.503] (1.000)
Step: 62149, Reward: [-410. -410. -410.] [0.0000], Avg: [-479.447 -479.447 -479.447] (1.000)
Step: 62199, Reward: [-368.073 -368.073 -368.073] [0.0000], Avg: [-479.358 -479.358 -479.358] (1.000)
Step: 62249, Reward: [-507.042 -507.042 -507.042] [0.0000], Avg: [-479.38 -479.38 -479.38] (1.000)
Step: 62299, Reward: [-326.05 -326.05 -326.05] [0.0000], Avg: [-479.257 -479.257 -479.257] (1.000)
Step: 62349, Reward: [-343.086 -343.086 -343.086] [0.0000], Avg: [-479.148 -479.148 -479.148] (1.000)
Step: 62399, Reward: [-379.242 -379.242 -379.242] [0.0000], Avg: [-479.068 -479.068 -479.068] (1.000)
Step: 62449, Reward: [-338.822 -338.822 -338.822] [0.0000], Avg: [-478.956 -478.956 -478.956] (1.000)
Step: 62499, Reward: [-445.352 -445.352 -445.352] [0.0000], Avg: [-478.929 -478.929 -478.929] (1.000)
Step: 62549, Reward: [-398.095 -398.095 -398.095] [0.0000], Avg: [-478.864 -478.864 -478.864] (1.000)
Step: 62599, Reward: [-312.071 -312.071 -312.071] [0.0000], Avg: [-478.731 -478.731 -478.731] (1.000)
Step: 62649, Reward: [-333.81 -333.81 -333.81] [0.0000], Avg: [-478.615 -478.615 -478.615] (1.000)
Step: 62699, Reward: [-334.788 -334.788 -334.788] [0.0000], Avg: [-478.501 -478.501 -478.501] (1.000)
Step: 62749, Reward: [-383.006 -383.006 -383.006] [0.0000], Avg: [-478.424 -478.424 -478.424] (1.000)
Step: 62799, Reward: [-309.238 -309.238 -309.238] [0.0000], Avg: [-478.29 -478.29 -478.29] (1.000)
Step: 62849, Reward: [-311.965 -311.965 -311.965] [0.0000], Avg: [-478.157 -478.157 -478.157] (1.000)
Step: 62899, Reward: [-304.468 -304.468 -304.468] [0.0000], Avg: [-478.019 -478.019 -478.019] (1.000)
Step: 62949, Reward: [-303.18 -303.18 -303.18] [0.0000], Avg: [-477.88 -477.88 -477.88] (1.000)
Step: 62999, Reward: [-442.818 -442.818 -442.818] [0.0000], Avg: [-477.853 -477.853 -477.853] (1.000)
Step: 63049, Reward: [-374.86 -374.86 -374.86] [0.0000], Avg: [-477.771 -477.771 -477.771] (1.000)
Step: 63099, Reward: [-311.299 -311.299 -311.299] [0.0000], Avg: [-477.639 -477.639 -477.639] (1.000)
Step: 63149, Reward: [-341.027 -341.027 -341.027] [0.0000], Avg: [-477.531 -477.531 -477.531] (1.000)
Step: 63199, Reward: [-374.665 -374.665 -374.665] [0.0000], Avg: [-477.45 -477.45 -477.45] (1.000)
Step: 63249, Reward: [-270.155 -270.155 -270.155] [0.0000], Avg: [-477.286 -477.286 -477.286] (1.000)
Step: 63299, Reward: [-296.917 -296.917 -296.917] [0.0000], Avg: [-477.143 -477.143 -477.143] (1.000)
Step: 63349, Reward: [-377.473 -377.473 -377.473] [0.0000], Avg: [-477.064 -477.064 -477.064] (1.000)
Step: 63399, Reward: [-345.592 -345.592 -345.592] [0.0000], Avg: [-476.961 -476.961 -476.961] (1.000)
Step: 63449, Reward: [-316.135 -316.135 -316.135] [0.0000], Avg: [-476.834 -476.834 -476.834] (1.000)
Step: 63499, Reward: [-309.303 -309.303 -309.303] [0.0000], Avg: [-476.702 -476.702 -476.702] (1.000)
Step: 63549, Reward: [-344.866 -344.866 -344.866] [0.0000], Avg: [-476.598 -476.598 -476.598] (1.000)
Step: 63599, Reward: [-389.172 -389.172 -389.172] [0.0000], Avg: [-476.53 -476.53 -476.53] (1.000)
Step: 63649, Reward: [-223.293 -223.293 -223.293] [0.0000], Avg: [-476.331 -476.331 -476.331] (1.000)
Step: 63699, Reward: [-352.8 -352.8 -352.8] [0.0000], Avg: [-476.234 -476.234 -476.234] (1.000)
Step: 63749, Reward: [-355.773 -355.773 -355.773] [0.0000], Avg: [-476.139 -476.139 -476.139] (1.000)
Step: 63799, Reward: [-459.101 -459.101 -459.101] [0.0000], Avg: [-476.126 -476.126 -476.126] (1.000)
Step: 63849, Reward: [-404.726 -404.726 -404.726] [0.0000], Avg: [-476.07 -476.07 -476.07] (1.000)
Step: 63899, Reward: [-335.957 -335.957 -335.957] [0.0000], Avg: [-475.96 -475.96 -475.96] (1.000)
Step: 63949, Reward: [-415.753 -415.753 -415.753] [0.0000], Avg: [-475.913 -475.913 -475.913] (1.000)
Step: 63999, Reward: [-266.035 -266.035 -266.035] [0.0000], Avg: [-475.749 -475.749 -475.749] (1.000)
Step: 64049, Reward: [-491.606 -491.606 -491.606] [0.0000], Avg: [-475.762 -475.762 -475.762] (1.000)
Step: 64099, Reward: [-405.971 -405.971 -405.971] [0.0000], Avg: [-475.707 -475.707 -475.707] (1.000)
Step: 64149, Reward: [-404.212 -404.212 -404.212] [0.0000], Avg: [-475.652 -475.652 -475.652] (1.000)
Step: 64199, Reward: [-359.658 -359.658 -359.658] [0.0000], Avg: [-475.561 -475.561 -475.561] (1.000)
Step: 64249, Reward: [-442.613 -442.613 -442.613] [0.0000], Avg: [-475.536 -475.536 -475.536] (1.000)
Step: 64299, Reward: [-317.603 -317.603 -317.603] [0.0000], Avg: [-475.413 -475.413 -475.413] (1.000)
Step: 64349, Reward: [-352.193 -352.193 -352.193] [0.0000], Avg: [-475.317 -475.317 -475.317] (1.000)
Step: 64399, Reward: [-269.086 -269.086 -269.086] [0.0000], Avg: [-475.157 -475.157 -475.157] (1.000)
Step: 64449, Reward: [-399.465 -399.465 -399.465] [0.0000], Avg: [-475.098 -475.098 -475.098] (1.000)
Step: 64499, Reward: [-328.548 -328.548 -328.548] [0.0000], Avg: [-474.985 -474.985 -474.985] (1.000)
Step: 64549, Reward: [-311.1 -311.1 -311.1] [0.0000], Avg: [-474.858 -474.858 -474.858] (1.000)
Step: 64599, Reward: [-327.603 -327.603 -327.603] [0.0000], Avg: [-474.744 -474.744 -474.744] (1.000)
Step: 64649, Reward: [-388.421 -388.421 -388.421] [0.0000], Avg: [-474.677 -474.677 -474.677] (1.000)
Step: 64699, Reward: [-379.855 -379.855 -379.855] [0.0000], Avg: [-474.604 -474.604 -474.604] (1.000)
Step: 64749, Reward: [-422.086 -422.086 -422.086] [0.0000], Avg: [-474.563 -474.563 -474.563] (1.000)
Step: 64799, Reward: [-438.882 -438.882 -438.882] [0.0000], Avg: [-474.536 -474.536 -474.536] (1.000)
Step: 64849, Reward: [-451.922 -451.922 -451.922] [0.0000], Avg: [-474.518 -474.518 -474.518] (1.000)
Step: 64899, Reward: [-351.165 -351.165 -351.165] [0.0000], Avg: [-474.423 -474.423 -474.423] (1.000)
Step: 64949, Reward: [-415.805 -415.805 -415.805] [0.0000], Avg: [-474.378 -474.378 -474.378] (1.000)
Step: 64999, Reward: [-465.532 -465.532 -465.532] [0.0000], Avg: [-474.371 -474.371 -474.371] (1.000)
Step: 65049, Reward: [-293.001 -293.001 -293.001] [0.0000], Avg: [-474.232 -474.232 -474.232] (1.000)
Step: 65099, Reward: [-330.936 -330.936 -330.936] [0.0000], Avg: [-474.122 -474.122 -474.122] (1.000)
Step: 65149, Reward: [-465.28 -465.28 -465.28] [0.0000], Avg: [-474.115 -474.115 -474.115] (1.000)
Step: 65199, Reward: [-338.503 -338.503 -338.503] [0.0000], Avg: [-474.011 -474.011 -474.011] (1.000)
Step: 65249, Reward: [-292.618 -292.618 -292.618] [0.0000], Avg: [-473.872 -473.872 -473.872] (1.000)
Step: 65299, Reward: [-427.353 -427.353 -427.353] [0.0000], Avg: [-473.836 -473.836 -473.836] (1.000)
Step: 65349, Reward: [-362.393 -362.393 -362.393] [0.0000], Avg: [-473.751 -473.751 -473.751] (1.000)
Step: 65399, Reward: [-280.789 -280.789 -280.789] [0.0000], Avg: [-473.604 -473.604 -473.604] (1.000)
Step: 65449, Reward: [-330.538 -330.538 -330.538] [0.0000], Avg: [-473.494 -473.494 -473.494] (1.000)
Step: 65499, Reward: [-317.88 -317.88 -317.88] [0.0000], Avg: [-473.375 -473.375 -473.375] (1.000)
Step: 65549, Reward: [-371.022 -371.022 -371.022] [0.0000], Avg: [-473.297 -473.297 -473.297] (1.000)
Step: 65599, Reward: [-434.333 -434.333 -434.333] [0.0000], Avg: [-473.268 -473.268 -473.268] (1.000)
Step: 65649, Reward: [-395.702 -395.702 -395.702] [0.0000], Avg: [-473.209 -473.209 -473.209] (1.000)
Step: 65699, Reward: [-369.934 -369.934 -369.934] [0.0000], Avg: [-473.13 -473.13 -473.13] (1.000)
Step: 65749, Reward: [-368.437 -368.437 -368.437] [0.0000], Avg: [-473.05 -473.05 -473.05] (1.000)
Step: 65799, Reward: [-375.857 -375.857 -375.857] [0.0000], Avg: [-472.977 -472.977 -472.977] (1.000)
Step: 65849, Reward: [-301.316 -301.316 -301.316] [0.0000], Avg: [-472.846 -472.846 -472.846] (1.000)
Step: 65899, Reward: [-301.571 -301.571 -301.571] [0.0000], Avg: [-472.716 -472.716 -472.716] (1.000)
Step: 65949, Reward: [-367.234 -367.234 -367.234] [0.0000], Avg: [-472.636 -472.636 -472.636] (1.000)
Step: 65999, Reward: [-316.436 -316.436 -316.436] [0.0000], Avg: [-472.518 -472.518 -472.518] (1.000)
Step: 66049, Reward: [-302.382 -302.382 -302.382] [0.0000], Avg: [-472.389 -472.389 -472.389] (1.000)
Step: 66099, Reward: [-310.151 -310.151 -310.151] [0.0000], Avg: [-472.266 -472.266 -472.266] (1.000)
Step: 66149, Reward: [-382.233 -382.233 -382.233] [0.0000], Avg: [-472.198 -472.198 -472.198] (1.000)
Step: 66199, Reward: [-391.523 -391.523 -391.523] [0.0000], Avg: [-472.137 -472.137 -472.137] (1.000)
Step: 66249, Reward: [-465.468 -465.468 -465.468] [0.0000], Avg: [-472.132 -472.132 -472.132] (1.000)
Step: 66299, Reward: [-357.999 -357.999 -357.999] [0.0000], Avg: [-472.046 -472.046 -472.046] (1.000)
Step: 66349, Reward: [-438.287 -438.287 -438.287] [0.0000], Avg: [-472.021 -472.021 -472.021] (1.000)
Step: 66399, Reward: [-514.737 -514.737 -514.737] [0.0000], Avg: [-472.053 -472.053 -472.053] (1.000)
Step: 66449, Reward: [-347.48 -347.48 -347.48] [0.0000], Avg: [-471.959 -471.959 -471.959] (1.000)
Step: 66499, Reward: [-365.357 -365.357 -365.357] [0.0000], Avg: [-471.879 -471.879 -471.879] (1.000)
Step: 66549, Reward: [-392.179 -392.179 -392.179] [0.0000], Avg: [-471.819 -471.819 -471.819] (1.000)
Step: 66599, Reward: [-332.402 -332.402 -332.402] [0.0000], Avg: [-471.715 -471.715 -471.715] (1.000)
Step: 66649, Reward: [-323.524 -323.524 -323.524] [0.0000], Avg: [-471.603 -471.603 -471.603] (1.000)
Step: 66699, Reward: [-361.005 -361.005 -361.005] [0.0000], Avg: [-471.521 -471.521 -471.521] (1.000)
Step: 66749, Reward: [-345.38 -345.38 -345.38] [0.0000], Avg: [-471.426 -471.426 -471.426] (1.000)
Step: 66799, Reward: [-371.1 -371.1 -371.1] [0.0000], Avg: [-471.351 -471.351 -471.351] (1.000)
Step: 66849, Reward: [-296.501 -296.501 -296.501] [0.0000], Avg: [-471.22 -471.22 -471.22] (1.000)
Step: 66899, Reward: [-350.524 -350.524 -350.524] [0.0000], Avg: [-471.13 -471.13 -471.13] (1.000)
Step: 66949, Reward: [-400.242 -400.242 -400.242] [0.0000], Avg: [-471.077 -471.077 -471.077] (1.000)
Step: 66999, Reward: [-441.078 -441.078 -441.078] [0.0000], Avg: [-471.055 -471.055 -471.055] (1.000)
Step: 67049, Reward: [-306.526 -306.526 -306.526] [0.0000], Avg: [-470.932 -470.932 -470.932] (1.000)
Step: 67099, Reward: [-339.852 -339.852 -339.852] [0.0000], Avg: [-470.834 -470.834 -470.834] (1.000)
Step: 67149, Reward: [-358.381 -358.381 -358.381] [0.0000], Avg: [-470.751 -470.751 -470.751] (1.000)
Step: 67199, Reward: [-383.26 -383.26 -383.26] [0.0000], Avg: [-470.685 -470.685 -470.685] (1.000)
Step: 67249, Reward: [-439.899 -439.899 -439.899] [0.0000], Avg: [-470.663 -470.663 -470.663] (1.000)
Step: 67299, Reward: [-390.197 -390.197 -390.197] [0.0000], Avg: [-470.603 -470.603 -470.603] (1.000)
Step: 67349, Reward: [-425.6 -425.6 -425.6] [0.0000], Avg: [-470.569 -470.569 -470.569] (1.000)
Step: 67399, Reward: [-344.585 -344.585 -344.585] [0.0000], Avg: [-470.476 -470.476 -470.476] (1.000)
Step: 67449, Reward: [-361.587 -361.587 -361.587] [0.0000], Avg: [-470.395 -470.395 -470.395] (1.000)
Step: 67499, Reward: [-266.971 -266.971 -266.971] [0.0000], Avg: [-470.245 -470.245 -470.245] (1.000)
Step: 67549, Reward: [-401.17 -401.17 -401.17] [0.0000], Avg: [-470.193 -470.193 -470.193] (1.000)
Step: 67599, Reward: [-346.962 -346.962 -346.962] [0.0000], Avg: [-470.102 -470.102 -470.102] (1.000)
Step: 67649, Reward: [-347.586 -347.586 -347.586] [0.0000], Avg: [-470.012 -470.012 -470.012] (1.000)
Step: 67699, Reward: [-300.082 -300.082 -300.082] [0.0000], Avg: [-469.886 -469.886 -469.886] (1.000)
Step: 67749, Reward: [-372.242 -372.242 -372.242] [0.0000], Avg: [-469.814 -469.814 -469.814] (1.000)
Step: 67799, Reward: [-358.655 -358.655 -358.655] [0.0000], Avg: [-469.732 -469.732 -469.732] (1.000)
Step: 67849, Reward: [-298.231 -298.231 -298.231] [0.0000], Avg: [-469.606 -469.606 -469.606] (1.000)
Step: 67899, Reward: [-401.224 -401.224 -401.224] [0.0000], Avg: [-469.555 -469.555 -469.555] (1.000)
Step: 67949, Reward: [-393.773 -393.773 -393.773] [0.0000], Avg: [-469.5 -469.5 -469.5] (1.000)
Step: 67999, Reward: [-355.086 -355.086 -355.086] [0.0000], Avg: [-469.416 -469.416 -469.416] (1.000)
Step: 68049, Reward: [-384.838 -384.838 -384.838] [0.0000], Avg: [-469.353 -469.353 -469.353] (1.000)
Step: 68099, Reward: [-364.232 -364.232 -364.232] [0.0000], Avg: [-469.276 -469.276 -469.276] (1.000)
Step: 68149, Reward: [-352.752 -352.752 -352.752] [0.0000], Avg: [-469.191 -469.191 -469.191] (1.000)
Step: 68199, Reward: [-393.442 -393.442 -393.442] [0.0000], Avg: [-469.135 -469.135 -469.135] (1.000)
Step: 68249, Reward: [-313.041 -313.041 -313.041] [0.0000], Avg: [-469.021 -469.021 -469.021] (1.000)
Step: 68299, Reward: [-434.255 -434.255 -434.255] [0.0000], Avg: [-468.995 -468.995 -468.995] (1.000)
Step: 68349, Reward: [-419.567 -419.567 -419.567] [0.0000], Avg: [-468.959 -468.959 -468.959] (1.000)
Step: 68399, Reward: [-387.378 -387.378 -387.378] [0.0000], Avg: [-468.9 -468.9 -468.9] (1.000)
Step: 68449, Reward: [-379.345 -379.345 -379.345] [0.0000], Avg: [-468.834 -468.834 -468.834] (1.000)
Step: 68499, Reward: [-263.312 -263.312 -263.312] [0.0000], Avg: [-468.684 -468.684 -468.684] (1.000)
Step: 68549, Reward: [-314.342 -314.342 -314.342] [0.0000], Avg: [-468.572 -468.572 -468.572] (1.000)
Step: 68599, Reward: [-312.293 -312.293 -312.293] [0.0000], Avg: [-468.458 -468.458 -468.458] (1.000)
Step: 68649, Reward: [-305.65 -305.65 -305.65] [0.0000], Avg: [-468.339 -468.339 -468.339] (1.000)
Step: 68699, Reward: [-369.678 -369.678 -369.678] [0.0000], Avg: [-468.267 -468.267 -468.267] (1.000)
Step: 68749, Reward: [-416.035 -416.035 -416.035] [0.0000], Avg: [-468.229 -468.229 -468.229] (1.000)
Step: 68799, Reward: [-386.042 -386.042 -386.042] [0.0000], Avg: [-468.17 -468.17 -468.17] (1.000)
Step: 68849, Reward: [-265.431 -265.431 -265.431] [0.0000], Avg: [-468.022 -468.022 -468.022] (1.000)
Step: 68899, Reward: [-350.15 -350.15 -350.15] [0.0000], Avg: [-467.937 -467.937 -467.937] (1.000)
Step: 68949, Reward: [-478.204 -478.204 -478.204] [0.0000], Avg: [-467.944 -467.944 -467.944] (1.000)
Step: 68999, Reward: [-419.351 -419.351 -419.351] [0.0000], Avg: [-467.909 -467.909 -467.909] (1.000)
Step: 69049, Reward: [-338.192 -338.192 -338.192] [0.0000], Avg: [-467.815 -467.815 -467.815] (1.000)
Step: 69099, Reward: [-388.274 -388.274 -388.274] [0.0000], Avg: [-467.758 -467.758 -467.758] (1.000)
Step: 69149, Reward: [-388.901 -388.901 -388.901] [0.0000], Avg: [-467.701 -467.701 -467.701] (1.000)
Step: 69199, Reward: [-372.175 -372.175 -372.175] [0.0000], Avg: [-467.631 -467.631 -467.631] (1.000)
Step: 69249, Reward: [-392.099 -392.099 -392.099] [0.0000], Avg: [-467.577 -467.577 -467.577] (1.000)
Step: 69299, Reward: [-305.912 -305.912 -305.912] [0.0000], Avg: [-467.46 -467.46 -467.46] (1.000)
Step: 69349, Reward: [-395.409 -395.409 -395.409] [0.0000], Avg: [-467.408 -467.408 -467.408] (1.000)
Step: 69399, Reward: [-370.03 -370.03 -370.03] [0.0000], Avg: [-467.338 -467.338 -467.338] (1.000)
Step: 69449, Reward: [-453.049 -453.049 -453.049] [0.0000], Avg: [-467.328 -467.328 -467.328] (1.000)
Step: 69499, Reward: [-433.995 -433.995 -433.995] [0.0000], Avg: [-467.304 -467.304 -467.304] (1.000)
Step: 69549, Reward: [-424.808 -424.808 -424.808] [0.0000], Avg: [-467.273 -467.273 -467.273] (1.000)
Step: 69599, Reward: [-343.539 -343.539 -343.539] [0.0000], Avg: [-467.185 -467.185 -467.185] (1.000)
Step: 69649, Reward: [-381.678 -381.678 -381.678] [0.0000], Avg: [-467.123 -467.123 -467.123] (1.000)
Step: 69699, Reward: [-348.03 -348.03 -348.03] [0.0000], Avg: [-467.038 -467.038 -467.038] (1.000)
Step: 69749, Reward: [-325.064 -325.064 -325.064] [0.0000], Avg: [-466.936 -466.936 -466.936] (1.000)
Step: 69799, Reward: [-272.561 -272.561 -272.561] [0.0000], Avg: [-466.797 -466.797 -466.797] (1.000)
Step: 69849, Reward: [-333.857 -333.857 -333.857] [0.0000], Avg: [-466.702 -466.702 -466.702] (1.000)
Step: 69899, Reward: [-423.974 -423.974 -423.974] [0.0000], Avg: [-466.671 -466.671 -466.671] (1.000)
Step: 69949, Reward: [-302.242 -302.242 -302.242] [0.0000], Avg: [-466.553 -466.553 -466.553] (1.000)
Step: 69999, Reward: [-364.567 -364.567 -364.567] [0.0000], Avg: [-466.481 -466.481 -466.481] (1.000)
Step: 70049, Reward: [-420.593 -420.593 -420.593] [0.0000], Avg: [-466.448 -466.448 -466.448] (1.000)
Step: 70099, Reward: [-442.062 -442.062 -442.062] [0.0000], Avg: [-466.43 -466.43 -466.43] (1.000)
Step: 70149, Reward: [-276.874 -276.874 -276.874] [0.0000], Avg: [-466.295 -466.295 -466.295] (1.000)
Step: 70199, Reward: [-470.341 -470.341 -470.341] [0.0000], Avg: [-466.298 -466.298 -466.298] (1.000)
Step: 70249, Reward: [-378.195 -378.195 -378.195] [0.0000], Avg: [-466.235 -466.235 -466.235] (1.000)
Step: 70299, Reward: [-420.705 -420.705 -420.705] [0.0000], Avg: [-466.203 -466.203 -466.203] (1.000)
Step: 70349, Reward: [-420.015 -420.015 -420.015] [0.0000], Avg: [-466.17 -466.17 -466.17] (1.000)
Step: 70399, Reward: [-311.431 -311.431 -311.431] [0.0000], Avg: [-466.06 -466.06 -466.06] (1.000)
Step: 70449, Reward: [-354.621 -354.621 -354.621] [0.0000], Avg: [-465.981 -465.981 -465.981] (1.000)
Step: 70499, Reward: [-330.396 -330.396 -330.396] [0.0000], Avg: [-465.885 -465.885 -465.885] (1.000)
Step: 70549, Reward: [-416.78 -416.78 -416.78] [0.0000], Avg: [-465.85 -465.85 -465.85] (1.000)
Step: 70599, Reward: [-295.12 -295.12 -295.12] [0.0000], Avg: [-465.729 -465.729 -465.729] (1.000)
Step: 70649, Reward: [-366.037 -366.037 -366.037] [0.0000], Avg: [-465.659 -465.659 -465.659] (1.000)
Step: 70699, Reward: [-533.214 -533.214 -533.214] [0.0000], Avg: [-465.707 -465.707 -465.707] (1.000)
Step: 70749, Reward: [-300.852 -300.852 -300.852] [0.0000], Avg: [-465.59 -465.59 -465.59] (1.000)
Step: 70799, Reward: [-387.525 -387.525 -387.525] [0.0000], Avg: [-465.535 -465.535 -465.535] (1.000)
Step: 70849, Reward: [-476.309 -476.309 -476.309] [0.0000], Avg: [-465.543 -465.543 -465.543] (1.000)
Step: 70899, Reward: [-393.918 -393.918 -393.918] [0.0000], Avg: [-465.492 -465.492 -465.492] (1.000)
Step: 70949, Reward: [-404.854 -404.854 -404.854] [0.0000], Avg: [-465.449 -465.449 -465.449] (1.000)
Step: 70999, Reward: [-350.082 -350.082 -350.082] [0.0000], Avg: [-465.368 -465.368 -465.368] (1.000)
Step: 71049, Reward: [-410.264 -410.264 -410.264] [0.0000], Avg: [-465.329 -465.329 -465.329] (1.000)
Step: 71099, Reward: [-314.653 -314.653 -314.653] [0.0000], Avg: [-465.223 -465.223 -465.223] (1.000)
Step: 71149, Reward: [-320.169 -320.169 -320.169] [0.0000], Avg: [-465.121 -465.121 -465.121] (1.000)
Step: 71199, Reward: [-322.534 -322.534 -322.534] [0.0000], Avg: [-465.021 -465.021 -465.021] (1.000)
Step: 71249, Reward: [-314.932 -314.932 -314.932] [0.0000], Avg: [-464.916 -464.916 -464.916] (1.000)
Step: 71299, Reward: [-363.172 -363.172 -363.172] [0.0000], Avg: [-464.845 -464.845 -464.845] (1.000)
Step: 71349, Reward: [-283.449 -283.449 -283.449] [0.0000], Avg: [-464.718 -464.718 -464.718] (1.000)
Step: 71399, Reward: [-329.968 -329.968 -329.968] [0.0000], Avg: [-464.623 -464.623 -464.623] (1.000)
Step: 71449, Reward: [-265.486 -265.486 -265.486] [0.0000], Avg: [-464.484 -464.484 -464.484] (1.000)
Step: 71499, Reward: [-382.308 -382.308 -382.308] [0.0000], Avg: [-464.426 -464.426 -464.426] (1.000)
Step: 71549, Reward: [-314.848 -314.848 -314.848] [0.0000], Avg: [-464.322 -464.322 -464.322] (1.000)
Step: 71599, Reward: [-381.247 -381.247 -381.247] [0.0000], Avg: [-464.264 -464.264 -464.264] (1.000)
Step: 71649, Reward: [-329.502 -329.502 -329.502] [0.0000], Avg: [-464.17 -464.17 -464.17] (1.000)
Step: 71699, Reward: [-395.773 -395.773 -395.773] [0.0000], Avg: [-464.122 -464.122 -464.122] (1.000)
Step: 71749, Reward: [-390.958 -390.958 -390.958] [0.0000], Avg: [-464.071 -464.071 -464.071] (1.000)
Step: 71799, Reward: [-263.553 -263.553 -263.553] [0.0000], Avg: [-463.931 -463.931 -463.931] (1.000)
Step: 71849, Reward: [-319.309 -319.309 -319.309] [0.0000], Avg: [-463.831 -463.831 -463.831] (1.000)
Step: 71899, Reward: [-340.593 -340.593 -340.593] [0.0000], Avg: [-463.745 -463.745 -463.745] (1.000)
Step: 71949, Reward: [-362.988 -362.988 -362.988] [0.0000], Avg: [-463.675 -463.675 -463.675] (1.000)
Step: 71999, Reward: [-464.977 -464.977 -464.977] [0.0000], Avg: [-463.676 -463.676 -463.676] (1.000)
Step: 72049, Reward: [-362.509 -362.509 -362.509] [0.0000], Avg: [-463.606 -463.606 -463.606] (1.000)
Step: 72099, Reward: [-355.049 -355.049 -355.049] [0.0000], Avg: [-463.53 -463.53 -463.53] (1.000)
Step: 72149, Reward: [-394.14 -394.14 -394.14] [0.0000], Avg: [-463.482 -463.482 -463.482] (1.000)
Step: 72199, Reward: [-436.419 -436.419 -436.419] [0.0000], Avg: [-463.464 -463.464 -463.464] (1.000)
Step: 72249, Reward: [-315.447 -315.447 -315.447] [0.0000], Avg: [-463.361 -463.361 -463.361] (1.000)
Step: 72299, Reward: [-345.5 -345.5 -345.5] [0.0000], Avg: [-463.28 -463.28 -463.28] (1.000)
Step: 72349, Reward: [-358.65 -358.65 -358.65] [0.0000], Avg: [-463.207 -463.207 -463.207] (1.000)
Step: 72399, Reward: [-477.32 -477.32 -477.32] [0.0000], Avg: [-463.217 -463.217 -463.217] (1.000)
Step: 72449, Reward: [-357.505 -357.505 -357.505] [0.0000], Avg: [-463.144 -463.144 -463.144] (1.000)
Step: 72499, Reward: [-320.811 -320.811 -320.811] [0.0000], Avg: [-463.046 -463.046 -463.046] (1.000)
Step: 72549, Reward: [-362.9 -362.9 -362.9] [0.0000], Avg: [-462.977 -462.977 -462.977] (1.000)
Step: 72599, Reward: [-453.087 -453.087 -453.087] [0.0000], Avg: [-462.97 -462.97 -462.97] (1.000)
Step: 72649, Reward: [-443.368 -443.368 -443.368] [0.0000], Avg: [-462.957 -462.957 -462.957] (1.000)
Step: 72699, Reward: [-428.294 -428.294 -428.294] [0.0000], Avg: [-462.933 -462.933 -462.933] (1.000)
Step: 72749, Reward: [-463.44 -463.44 -463.44] [0.0000], Avg: [-462.933 -462.933 -462.933] (1.000)
Step: 72799, Reward: [-449.108 -449.108 -449.108] [0.0000], Avg: [-462.924 -462.924 -462.924] (1.000)
Step: 72849, Reward: [-426.909 -426.909 -426.909] [0.0000], Avg: [-462.899 -462.899 -462.899] (1.000)
Step: 72899, Reward: [-278.573 -278.573 -278.573] [0.0000], Avg: [-462.773 -462.773 -462.773] (1.000)
Step: 72949, Reward: [-426.065 -426.065 -426.065] [0.0000], Avg: [-462.747 -462.747 -462.747] (1.000)
Step: 72999, Reward: [-426.732 -426.732 -426.732] [0.0000], Avg: [-462.723 -462.723 -462.723] (1.000)
Step: 73049, Reward: [-359.848 -359.848 -359.848] [0.0000], Avg: [-462.652 -462.652 -462.652] (1.000)
Step: 73099, Reward: [-333.634 -333.634 -333.634] [0.0000], Avg: [-462.564 -462.564 -462.564] (1.000)
Step: 73149, Reward: [-356.805 -356.805 -356.805] [0.0000], Avg: [-462.492 -462.492 -462.492] (1.000)
Step: 73199, Reward: [-344.201 -344.201 -344.201] [0.0000], Avg: [-462.411 -462.411 -462.411] (1.000)
Step: 73249, Reward: [-293.29 -293.29 -293.29] [0.0000], Avg: [-462.296 -462.296 -462.296] (1.000)
Step: 73299, Reward: [-378.455 -378.455 -378.455] [0.0000], Avg: [-462.238 -462.238 -462.238] (1.000)
Step: 73349, Reward: [-354.024 -354.024 -354.024] [0.0000], Avg: [-462.165 -462.165 -462.165] (1.000)
Step: 73399, Reward: [-346.103 -346.103 -346.103] [0.0000], Avg: [-462.086 -462.086 -462.086] (1.000)
Step: 73449, Reward: [-447.835 -447.835 -447.835] [0.0000], Avg: [-462.076 -462.076 -462.076] (1.000)
Step: 73499, Reward: [-394.566 -394.566 -394.566] [0.0000], Avg: [-462.03 -462.03 -462.03] (1.000)
Step: 73549, Reward: [-308.836 -308.836 -308.836] [0.0000], Avg: [-461.926 -461.926 -461.926] (1.000)
Step: 73599, Reward: [-348.816 -348.816 -348.816] [0.0000], Avg: [-461.849 -461.849 -461.849] (1.000)
Step: 73649, Reward: [-326.127 -326.127 -326.127] [0.0000], Avg: [-461.757 -461.757 -461.757] (1.000)
Step: 73699, Reward: [-376.288 -376.288 -376.288] [0.0000], Avg: [-461.699 -461.699 -461.699] (1.000)
Step: 73749, Reward: [-375.038 -375.038 -375.038] [0.0000], Avg: [-461.64 -461.64 -461.64] (1.000)
Step: 73799, Reward: [-393.073 -393.073 -393.073] [0.0000], Avg: [-461.594 -461.594 -461.594] (1.000)
Step: 73849, Reward: [-383.84 -383.84 -383.84] [0.0000], Avg: [-461.541 -461.541 -461.541] (1.000)
Step: 73899, Reward: [-462.578 -462.578 -462.578] [0.0000], Avg: [-461.542 -461.542 -461.542] (1.000)
Step: 73949, Reward: [-265.981 -265.981 -265.981] [0.0000], Avg: [-461.409 -461.409 -461.409] (1.000)
Step: 73999, Reward: [-337.364 -337.364 -337.364] [0.0000], Avg: [-461.326 -461.326 -461.326] (1.000)
Step: 74049, Reward: [-493.4 -493.4 -493.4] [0.0000], Avg: [-461.347 -461.347 -461.347] (1.000)
Step: 74099, Reward: [-369.761 -369.761 -369.761] [0.0000], Avg: [-461.285 -461.285 -461.285] (1.000)
Step: 74149, Reward: [-351.358 -351.358 -351.358] [0.0000], Avg: [-461.211 -461.211 -461.211] (1.000)
Step: 74199, Reward: [-441.669 -441.669 -441.669] [0.0000], Avg: [-461.198 -461.198 -461.198] (1.000)
Step: 74249, Reward: [-306.28 -306.28 -306.28] [0.0000], Avg: [-461.094 -461.094 -461.094] (1.000)
Step: 74299, Reward: [-246.167 -246.167 -246.167] [0.0000], Avg: [-460.949 -460.949 -460.949] (1.000)
Step: 74349, Reward: [-306.974 -306.974 -306.974] [0.0000], Avg: [-460.846 -460.846 -460.846] (1.000)
Step: 74399, Reward: [-419.487 -419.487 -419.487] [0.0000], Avg: [-460.818 -460.818 -460.818] (1.000)
Step: 74449, Reward: [-389.736 -389.736 -389.736] [0.0000], Avg: [-460.77 -460.77 -460.77] (1.000)
Step: 74499, Reward: [-383.31 -383.31 -383.31] [0.0000], Avg: [-460.718 -460.718 -460.718] (1.000)
Step: 74549, Reward: [-319.525 -319.525 -319.525] [0.0000], Avg: [-460.623 -460.623 -460.623] (1.000)
Step: 74599, Reward: [-275.833 -275.833 -275.833] [0.0000], Avg: [-460.5 -460.5 -460.5] (1.000)
Step: 74649, Reward: [-397.558 -397.558 -397.558] [0.0000], Avg: [-460.457 -460.457 -460.457] (1.000)
Step: 74699, Reward: [-272.293 -272.293 -272.293] [0.0000], Avg: [-460.332 -460.332 -460.332] (1.000)
Step: 74749, Reward: [-297.903 -297.903 -297.903] [0.0000], Avg: [-460.223 -460.223 -460.223] (1.000)
Step: 74799, Reward: [-417.509 -417.509 -417.509] [0.0000], Avg: [-460.194 -460.194 -460.194] (1.000)
Step: 74849, Reward: [-373.975 -373.975 -373.975] [0.0000], Avg: [-460.137 -460.137 -460.137] (1.000)
Step: 74899, Reward: [-329.714 -329.714 -329.714] [0.0000], Avg: [-460.05 -460.05 -460.05] (1.000)
Step: 74949, Reward: [-364.55 -364.55 -364.55] [0.0000], Avg: [-459.986 -459.986 -459.986] (1.000)
Step: 74999, Reward: [-379.148 -379.148 -379.148] [0.0000], Avg: [-459.932 -459.932 -459.932] (1.000)
Step: 75049, Reward: [-325.55 -325.55 -325.55] [0.0000], Avg: [-459.843 -459.843 -459.843] (1.000)
Step: 75099, Reward: [-387.359 -387.359 -387.359] [0.0000], Avg: [-459.794 -459.794 -459.794] (1.000)
Step: 75149, Reward: [-425.422 -425.422 -425.422] [0.0000], Avg: [-459.771 -459.771 -459.771] (1.000)
Step: 75199, Reward: [-399.65 -399.65 -399.65] [0.0000], Avg: [-459.731 -459.731 -459.731] (1.000)
Step: 75249, Reward: [-332.899 -332.899 -332.899] [0.0000], Avg: [-459.647 -459.647 -459.647] (1.000)
Step: 75299, Reward: [-452.33 -452.33 -452.33] [0.0000], Avg: [-459.642 -459.642 -459.642] (1.000)
Step: 75349, Reward: [-371.888 -371.888 -371.888] [0.0000], Avg: [-459.584 -459.584 -459.584] (1.000)
Step: 75399, Reward: [-385.625 -385.625 -385.625] [0.0000], Avg: [-459.535 -459.535 -459.535] (1.000)
Step: 75449, Reward: [-295.406 -295.406 -295.406] [0.0000], Avg: [-459.426 -459.426 -459.426] (1.000)
Step: 75499, Reward: [-396.938 -396.938 -396.938] [0.0000], Avg: [-459.385 -459.385 -459.385] (1.000)
Step: 75549, Reward: [-402.89 -402.89 -402.89] [0.0000], Avg: [-459.347 -459.347 -459.347] (1.000)
Step: 75599, Reward: [-286.61 -286.61 -286.61] [0.0000], Avg: [-459.233 -459.233 -459.233] (1.000)
Step: 75649, Reward: [-298.918 -298.918 -298.918] [0.0000], Avg: [-459.127 -459.127 -459.127] (1.000)
Step: 75699, Reward: [-305.726 -305.726 -305.726] [0.0000], Avg: [-459.026 -459.026 -459.026] (1.000)
Step: 75749, Reward: [-475.389 -475.389 -475.389] [0.0000], Avg: [-459.037 -459.037 -459.037] (1.000)
Step: 75799, Reward: [-332.181 -332.181 -332.181] [0.0000], Avg: [-458.953 -458.953 -458.953] (1.000)
Step: 75849, Reward: [-386.597 -386.597 -386.597] [0.0000], Avg: [-458.905 -458.905 -458.905] (1.000)
Step: 75899, Reward: [-296.227 -296.227 -296.227] [0.0000], Avg: [-458.798 -458.798 -458.798] (1.000)
Step: 75949, Reward: [-420.611 -420.611 -420.611] [0.0000], Avg: [-458.773 -458.773 -458.773] (1.000)
Step: 75999, Reward: [-417.009 -417.009 -417.009] [0.0000], Avg: [-458.746 -458.746 -458.746] (1.000)
Step: 76049, Reward: [-358.19 -358.19 -358.19] [0.0000], Avg: [-458.679 -458.679 -458.679] (1.000)
Step: 76099, Reward: [-484.649 -484.649 -484.649] [0.0000], Avg: [-458.697 -458.697 -458.697] (1.000)
Step: 76149, Reward: [-474.997 -474.997 -474.997] [0.0000], Avg: [-458.707 -458.707 -458.707] (1.000)
Step: 76199, Reward: [-359.77 -359.77 -359.77] [0.0000], Avg: [-458.642 -458.642 -458.642] (1.000)
Step: 76249, Reward: [-400.657 -400.657 -400.657] [0.0000], Avg: [-458.604 -458.604 -458.604] (1.000)
Step: 76299, Reward: [-432.957 -432.957 -432.957] [0.0000], Avg: [-458.588 -458.588 -458.588] (1.000)
Step: 76349, Reward: [-392.48 -392.48 -392.48] [0.0000], Avg: [-458.544 -458.544 -458.544] (1.000)
Step: 76399, Reward: [-312.038 -312.038 -312.038] [0.0000], Avg: [-458.448 -458.448 -458.448] (1.000)
Step: 76449, Reward: [-340.953 -340.953 -340.953] [0.0000], Avg: [-458.371 -458.371 -458.371] (1.000)
Step: 76499, Reward: [-344.004 -344.004 -344.004] [0.0000], Avg: [-458.297 -458.297 -458.297] (1.000)
Step: 76549, Reward: [-331.638 -331.638 -331.638] [0.0000], Avg: [-458.214 -458.214 -458.214] (1.000)
Step: 76599, Reward: [-275.949 -275.949 -275.949] [0.0000], Avg: [-458.095 -458.095 -458.095] (1.000)
Step: 76649, Reward: [-367.007 -367.007 -367.007] [0.0000], Avg: [-458.036 -458.036 -458.036] (1.000)
Step: 76699, Reward: [-355.868 -355.868 -355.868] [0.0000], Avg: [-457.969 -457.969 -457.969] (1.000)
Step: 76749, Reward: [-482.111 -482.111 -482.111] [0.0000], Avg: [-457.985 -457.985 -457.985] (1.000)
Step: 76799, Reward: [-412.301 -412.301 -412.301] [0.0000], Avg: [-457.955 -457.955 -457.955] (1.000)
Step: 76849, Reward: [-457.995 -457.995 -457.995] [0.0000], Avg: [-457.955 -457.955 -457.955] (1.000)
Step: 76899, Reward: [-494.753 -494.753 -494.753] [0.0000], Avg: [-457.979 -457.979 -457.979] (1.000)
Step: 76949, Reward: [-419.991 -419.991 -419.991] [0.0000], Avg: [-457.954 -457.954 -457.954] (1.000)
Step: 76999, Reward: [-409.727 -409.727 -409.727] [0.0000], Avg: [-457.923 -457.923 -457.923] (1.000)
Step: 77049, Reward: [-476.172 -476.172 -476.172] [0.0000], Avg: [-457.935 -457.935 -457.935] (1.000)
Step: 77099, Reward: [-390.789 -390.789 -390.789] [0.0000], Avg: [-457.891 -457.891 -457.891] (1.000)
Step: 77149, Reward: [-319.438 -319.438 -319.438] [0.0000], Avg: [-457.802 -457.802 -457.802] (1.000)
Step: 77199, Reward: [-391.911 -391.911 -391.911] [0.0000], Avg: [-457.759 -457.759 -457.759] (1.000)
Step: 77249, Reward: [-340.331 -340.331 -340.331] [0.0000], Avg: [-457.683 -457.683 -457.683] (1.000)
Step: 77299, Reward: [-313.793 -313.793 -313.793] [0.0000], Avg: [-457.59 -457.59 -457.59] (1.000)
Step: 77349, Reward: [-375.5 -375.5 -375.5] [0.0000], Avg: [-457.537 -457.537 -457.537] (1.000)
Step: 77399, Reward: [-313.154 -313.154 -313.154] [0.0000], Avg: [-457.443 -457.443 -457.443] (1.000)
Step: 77449, Reward: [-382.691 -382.691 -382.691] [0.0000], Avg: [-457.395 -457.395 -457.395] (1.000)
Step: 77499, Reward: [-384.829 -384.829 -384.829] [0.0000], Avg: [-457.348 -457.348 -457.348] (1.000)
Step: 77549, Reward: [-425.232 -425.232 -425.232] [0.0000], Avg: [-457.328 -457.328 -457.328] (1.000)
Step: 77599, Reward: [-418.104 -418.104 -418.104] [0.0000], Avg: [-457.302 -457.302 -457.302] (1.000)
Step: 77649, Reward: [-375.31 -375.31 -375.31] [0.0000], Avg: [-457.25 -457.25 -457.25] (1.000)
Step: 77699, Reward: [-427.458 -427.458 -427.458] [0.0000], Avg: [-457.23 -457.23 -457.23] (1.000)
Step: 77749, Reward: [-307.076 -307.076 -307.076] [0.0000], Avg: [-457.134 -457.134 -457.134] (1.000)
Step: 77799, Reward: [-410.377 -410.377 -410.377] [0.0000], Avg: [-457.104 -457.104 -457.104] (1.000)
Step: 77849, Reward: [-306.93 -306.93 -306.93] [0.0000], Avg: [-457.007 -457.007 -457.007] (1.000)
Step: 77899, Reward: [-307.716 -307.716 -307.716] [0.0000], Avg: [-456.912 -456.912 -456.912] (1.000)
Step: 77949, Reward: [-402.91 -402.91 -402.91] [0.0000], Avg: [-456.877 -456.877 -456.877] (1.000)
Step: 77999, Reward: [-294.644 -294.644 -294.644] [0.0000], Avg: [-456.773 -456.773 -456.773] (1.000)
Step: 78049, Reward: [-330.646 -330.646 -330.646] [0.0000], Avg: [-456.692 -456.692 -456.692] (1.000)
Step: 78099, Reward: [-380.841 -380.841 -380.841] [0.0000], Avg: [-456.644 -456.644 -456.644] (1.000)
Step: 78149, Reward: [-390.877 -390.877 -390.877] [0.0000], Avg: [-456.601 -456.601 -456.601] (1.000)
Step: 78199, Reward: [-292.652 -292.652 -292.652] [0.0000], Avg: [-456.497 -456.497 -456.497] (1.000)
Step: 78249, Reward: [-332.252 -332.252 -332.252] [0.0000], Avg: [-456.417 -456.417 -456.417] (1.000)
Step: 78299, Reward: [-370.184 -370.184 -370.184] [0.0000], Avg: [-456.362 -456.362 -456.362] (1.000)
Step: 78349, Reward: [-339.06 -339.06 -339.06] [0.0000], Avg: [-456.287 -456.287 -456.287] (1.000)
Step: 78399, Reward: [-411.64 -411.64 -411.64] [0.0000], Avg: [-456.259 -456.259 -456.259] (1.000)
Step: 78449, Reward: [-287.047 -287.047 -287.047] [0.0000], Avg: [-456.151 -456.151 -456.151] (1.000)
Step: 78499, Reward: [-405.901 -405.901 -405.901] [0.0000], Avg: [-456.119 -456.119 -456.119] (1.000)
Step: 78549, Reward: [-338.382 -338.382 -338.382] [0.0000], Avg: [-456.044 -456.044 -456.044] (1.000)
Step: 78599, Reward: [-325.396 -325.396 -325.396] [0.0000], Avg: [-455.961 -455.961 -455.961] (1.000)
Step: 78649, Reward: [-369.515 -369.515 -369.515] [0.0000], Avg: [-455.906 -455.906 -455.906] (1.000)
Step: 78699, Reward: [-470.548 -470.548 -470.548] [0.0000], Avg: [-455.915 -455.915 -455.915] (1.000)
Step: 78749, Reward: [-327.91 -327.91 -327.91] [0.0000], Avg: [-455.834 -455.834 -455.834] (1.000)
Step: 78799, Reward: [-315.483 -315.483 -315.483] [0.0000], Avg: [-455.745 -455.745 -455.745] (1.000)
Step: 78849, Reward: [-382.343 -382.343 -382.343] [0.0000], Avg: [-455.698 -455.698 -455.698] (1.000)
Step: 78899, Reward: [-315.121 -315.121 -315.121] [0.0000], Avg: [-455.609 -455.609 -455.609] (1.000)
Step: 78949, Reward: [-359.741 -359.741 -359.741] [0.0000], Avg: [-455.549 -455.549 -455.549] (1.000)
Step: 78999, Reward: [-436.048 -436.048 -436.048] [0.0000], Avg: [-455.536 -455.536 -455.536] (1.000)
Step: 79049, Reward: [-332.942 -332.942 -332.942] [0.0000], Avg: [-455.459 -455.459 -455.459] (1.000)
Step: 79099, Reward: [-564.725 -564.725 -564.725] [0.0000], Avg: [-455.528 -455.528 -455.528] (1.000)
Step: 79149, Reward: [-323.236 -323.236 -323.236] [0.0000], Avg: [-455.444 -455.444 -455.444] (1.000)
Step: 79199, Reward: [-280.637 -280.637 -280.637] [0.0000], Avg: [-455.334 -455.334 -455.334] (1.000)
Step: 79249, Reward: [-483.327 -483.327 -483.327] [0.0000], Avg: [-455.352 -455.352 -455.352] (1.000)
Step: 79299, Reward: [-458.791 -458.791 -458.791] [0.0000], Avg: [-455.354 -455.354 -455.354] (1.000)
Step: 79349, Reward: [-369.841 -369.841 -369.841] [0.0000], Avg: [-455.3 -455.3 -455.3] (1.000)
Step: 79399, Reward: [-356.281 -356.281 -356.281] [0.0000], Avg: [-455.237 -455.237 -455.237] (1.000)
Step: 79449, Reward: [-369.756 -369.756 -369.756] [0.0000], Avg: [-455.184 -455.184 -455.184] (1.000)
Step: 79499, Reward: [-364.814 -364.814 -364.814] [0.0000], Avg: [-455.127 -455.127 -455.127] (1.000)
Step: 79549, Reward: [-395.457 -395.457 -395.457] [0.0000], Avg: [-455.089 -455.089 -455.089] (1.000)
Step: 79599, Reward: [-334.669 -334.669 -334.669] [0.0000], Avg: [-455.014 -455.014 -455.014] (1.000)
Step: 79649, Reward: [-465.619 -465.619 -465.619] [0.0000], Avg: [-455.02 -455.02 -455.02] (1.000)
Step: 79699, Reward: [-329.084 -329.084 -329.084] [0.0000], Avg: [-454.941 -454.941 -454.941] (1.000)
Step: 79749, Reward: [-428.614 -428.614 -428.614] [0.0000], Avg: [-454.925 -454.925 -454.925] (1.000)
Step: 79799, Reward: [-435.206 -435.206 -435.206] [0.0000], Avg: [-454.912 -454.912 -454.912] (1.000)
Step: 79849, Reward: [-499.055 -499.055 -499.055] [0.0000], Avg: [-454.94 -454.94 -454.94] (1.000)
Step: 79899, Reward: [-325.454 -325.454 -325.454] [0.0000], Avg: [-454.859 -454.859 -454.859] (1.000)
Step: 79949, Reward: [-394.133 -394.133 -394.133] [0.0000], Avg: [-454.821 -454.821 -454.821] (1.000)
Step: 79999, Reward: [-284.328 -284.328 -284.328] [0.0000], Avg: [-454.715 -454.715 -454.715] (1.000)
Step: 80049, Reward: [-466.775 -466.775 -466.775] [0.0000], Avg: [-454.722 -454.722 -454.722] (1.000)
Step: 80099, Reward: [-399.509 -399.509 -399.509] [0.0000], Avg: [-454.688 -454.688 -454.688] (1.000)
Step: 80149, Reward: [-350.803 -350.803 -350.803] [0.0000], Avg: [-454.623 -454.623 -454.623] (1.000)
Step: 80199, Reward: [-350.037 -350.037 -350.037] [0.0000], Avg: [-454.558 -454.558 -454.558] (1.000)
Step: 80249, Reward: [-388.339 -388.339 -388.339] [0.0000], Avg: [-454.516 -454.516 -454.516] (1.000)
Step: 80299, Reward: [-297.404 -297.404 -297.404] [0.0000], Avg: [-454.419 -454.419 -454.419] (1.000)
Step: 80349, Reward: [-309.687 -309.687 -309.687] [0.0000], Avg: [-454.328 -454.328 -454.328] (1.000)
Step: 80399, Reward: [-469.815 -469.815 -469.815] [0.0000], Avg: [-454.338 -454.338 -454.338] (1.000)
Step: 80449, Reward: [-298.999 -298.999 -298.999] [0.0000], Avg: [-454.242 -454.242 -454.242] (1.000)
Step: 80499, Reward: [-381.35 -381.35 -381.35] [0.0000], Avg: [-454.196 -454.196 -454.196] (1.000)
Step: 80549, Reward: [-398.546 -398.546 -398.546] [0.0000], Avg: [-454.162 -454.162 -454.162] (1.000)
Step: 80599, Reward: [-349.75 -349.75 -349.75] [0.0000], Avg: [-454.097 -454.097 -454.097] (1.000)
Step: 80649, Reward: [-461.685 -461.685 -461.685] [0.0000], Avg: [-454.102 -454.102 -454.102] (1.000)
Step: 80699, Reward: [-283.227 -283.227 -283.227] [0.0000], Avg: [-453.996 -453.996 -453.996] (1.000)
Step: 80749, Reward: [-360.912 -360.912 -360.912] [0.0000], Avg: [-453.938 -453.938 -453.938] (1.000)
Step: 80799, Reward: [-354.225 -354.225 -354.225] [0.0000], Avg: [-453.876 -453.876 -453.876] (1.000)
Step: 80849, Reward: [-354.204 -354.204 -354.204] [0.0000], Avg: [-453.815 -453.815 -453.815] (1.000)
Step: 80899, Reward: [-336.361 -336.361 -336.361] [0.0000], Avg: [-453.742 -453.742 -453.742] (1.000)
Step: 80949, Reward: [-396.371 -396.371 -396.371] [0.0000], Avg: [-453.707 -453.707 -453.707] (1.000)
Step: 80999, Reward: [-330.238 -330.238 -330.238] [0.0000], Avg: [-453.631 -453.631 -453.631] (1.000)
Step: 81049, Reward: [-391.383 -391.383 -391.383] [0.0000], Avg: [-453.592 -453.592 -453.592] (1.000)
Step: 81099, Reward: [-374.203 -374.203 -374.203] [0.0000], Avg: [-453.543 -453.543 -453.543] (1.000)
Step: 81149, Reward: [-542.579 -542.579 -542.579] [0.0000], Avg: [-453.598 -453.598 -453.598] (1.000)
Step: 81199, Reward: [-336.811 -336.811 -336.811] [0.0000], Avg: [-453.526 -453.526 -453.526] (1.000)
Step: 81249, Reward: [-327.952 -327.952 -327.952] [0.0000], Avg: [-453.449 -453.449 -453.449] (1.000)
Step: 81299, Reward: [-330.809 -330.809 -330.809] [0.0000], Avg: [-453.373 -453.373 -453.373] (1.000)
Step: 81349, Reward: [-382.055 -382.055 -382.055] [0.0000], Avg: [-453.33 -453.33 -453.33] (1.000)
Step: 81399, Reward: [-439.931 -439.931 -439.931] [0.0000], Avg: [-453.321 -453.321 -453.321] (1.000)
Step: 81449, Reward: [-290.865 -290.865 -290.865] [0.0000], Avg: [-453.222 -453.222 -453.222] (1.000)
Step: 81499, Reward: [-479.841 -479.841 -479.841] [0.0000], Avg: [-453.238 -453.238 -453.238] (1.000)
Step: 81549, Reward: [-351.021 -351.021 -351.021] [0.0000], Avg: [-453.175 -453.175 -453.175] (1.000)
Step: 81599, Reward: [-339.94 -339.94 -339.94] [0.0000], Avg: [-453.106 -453.106 -453.106] (1.000)
Step: 81649, Reward: [-385.666 -385.666 -385.666] [0.0000], Avg: [-453.065 -453.065 -453.065] (1.000)
Step: 81699, Reward: [-352.421 -352.421 -352.421] [0.0000], Avg: [-453.003 -453.003 -453.003] (1.000)
Step: 81749, Reward: [-341.49 -341.49 -341.49] [0.0000], Avg: [-452.935 -452.935 -452.935] (1.000)
Step: 81799, Reward: [-315.555 -315.555 -315.555] [0.0000], Avg: [-452.851 -452.851 -452.851] (1.000)
Step: 81849, Reward: [-335.006 -335.006 -335.006] [0.0000], Avg: [-452.779 -452.779 -452.779] (1.000)
Step: 81899, Reward: [-356.253 -356.253 -356.253] [0.0000], Avg: [-452.72 -452.72 -452.72] (1.000)
Step: 81949, Reward: [-279.642 -279.642 -279.642] [0.0000], Avg: [-452.614 -452.614 -452.614] (1.000)
Step: 81999, Reward: [-488.441 -488.441 -488.441] [0.0000], Avg: [-452.636 -452.636 -452.636] (1.000)
Step: 82049, Reward: [-285.665 -285.665 -285.665] [0.0000], Avg: [-452.534 -452.534 -452.534] (1.000)
Step: 82099, Reward: [-348.797 -348.797 -348.797] [0.0000], Avg: [-452.471 -452.471 -452.471] (1.000)
Step: 82149, Reward: [-346.693 -346.693 -346.693] [0.0000], Avg: [-452.407 -452.407 -452.407] (1.000)
Step: 82199, Reward: [-323.969 -323.969 -323.969] [0.0000], Avg: [-452.329 -452.329 -452.329] (1.000)
Step: 82249, Reward: [-350.352 -350.352 -350.352] [0.0000], Avg: [-452.267 -452.267 -452.267] (1.000)
Step: 82299, Reward: [-315.644 -315.644 -315.644] [0.0000], Avg: [-452.184 -452.184 -452.184] (1.000)
Step: 82349, Reward: [-363.258 -363.258 -363.258] [0.0000], Avg: [-452.13 -452.13 -452.13] (1.000)
Step: 82399, Reward: [-402.009 -402.009 -402.009] [0.0000], Avg: [-452.099 -452.099 -452.099] (1.000)
Step: 82449, Reward: [-272.871 -272.871 -272.871] [0.0000], Avg: [-451.991 -451.991 -451.991] (1.000)
Step: 82499, Reward: [-312.284 -312.284 -312.284] [0.0000], Avg: [-451.906 -451.906 -451.906] (1.000)
Step: 82549, Reward: [-327.635 -327.635 -327.635] [0.0000], Avg: [-451.831 -451.831 -451.831] (1.000)
Step: 82599, Reward: [-416.423 -416.423 -416.423] [0.0000], Avg: [-451.809 -451.809 -451.809] (1.000)
Step: 82649, Reward: [-435.655 -435.655 -435.655] [0.0000], Avg: [-451.8 -451.8 -451.8] (1.000)
Step: 82699, Reward: [-389.105 -389.105 -389.105] [0.0000], Avg: [-451.762 -451.762 -451.762] (1.000)
Step: 82749, Reward: [-396.121 -396.121 -396.121] [0.0000], Avg: [-451.728 -451.728 -451.728] (1.000)
Step: 82799, Reward: [-435.43 -435.43 -435.43] [0.0000], Avg: [-451.718 -451.718 -451.718] (1.000)
Step: 82849, Reward: [-363.816 -363.816 -363.816] [0.0000], Avg: [-451.665 -451.665 -451.665] (1.000)
Step: 82899, Reward: [-337.477 -337.477 -337.477] [0.0000], Avg: [-451.596 -451.596 -451.596] (1.000)
Step: 82949, Reward: [-380.871 -380.871 -380.871] [0.0000], Avg: [-451.554 -451.554 -451.554] (1.000)
Step: 82999, Reward: [-308.503 -308.503 -308.503] [0.0000], Avg: [-451.467 -451.467 -451.467] (1.000)
Step: 83049, Reward: [-367.367 -367.367 -367.367] [0.0000], Avg: [-451.417 -451.417 -451.417] (1.000)
Step: 83099, Reward: [-350.118 -350.118 -350.118] [0.0000], Avg: [-451.356 -451.356 -451.356] (1.000)
Step: 83149, Reward: [-294.268 -294.268 -294.268] [0.0000], Avg: [-451.261 -451.261 -451.261] (1.000)
Step: 83199, Reward: [-302.778 -302.778 -302.778] [0.0000], Avg: [-451.172 -451.172 -451.172] (1.000)
Step: 83249, Reward: [-456.089 -456.089 -456.089] [0.0000], Avg: [-451.175 -451.175 -451.175] (1.000)
Step: 83299, Reward: [-316.511 -316.511 -316.511] [0.0000], Avg: [-451.094 -451.094 -451.094] (1.000)
Step: 83349, Reward: [-253.502 -253.502 -253.502] [0.0000], Avg: [-450.976 -450.976 -450.976] (1.000)
Step: 83399, Reward: [-470.849 -470.849 -470.849] [0.0000], Avg: [-450.988 -450.988 -450.988] (1.000)
Step: 83449, Reward: [-438.422 -438.422 -438.422] [0.0000], Avg: [-450.98 -450.98 -450.98] (1.000)
Step: 83499, Reward: [-390.209 -390.209 -390.209] [0.0000], Avg: [-450.944 -450.944 -450.944] (1.000)
Step: 83549, Reward: [-379.948 -379.948 -379.948] [0.0000], Avg: [-450.901 -450.901 -450.901] (1.000)
Step: 83599, Reward: [-378.973 -378.973 -378.973] [0.0000], Avg: [-450.858 -450.858 -450.858] (1.000)
Step: 83649, Reward: [-427.987 -427.987 -427.987] [0.0000], Avg: [-450.845 -450.845 -450.845] (1.000)
Step: 83699, Reward: [-369.093 -369.093 -369.093] [0.0000], Avg: [-450.796 -450.796 -450.796] (1.000)
Step: 83749, Reward: [-410.716 -410.716 -410.716] [0.0000], Avg: [-450.772 -450.772 -450.772] (1.000)
Step: 83799, Reward: [-415.687 -415.687 -415.687] [0.0000], Avg: [-450.751 -450.751 -450.751] (1.000)
Step: 83849, Reward: [-410.278 -410.278 -410.278] [0.0000], Avg: [-450.727 -450.727 -450.727] (1.000)
Step: 83899, Reward: [-437.16 -437.16 -437.16] [0.0000], Avg: [-450.719 -450.719 -450.719] (1.000)
Step: 83949, Reward: [-325.142 -325.142 -325.142] [0.0000], Avg: [-450.644 -450.644 -450.644] (1.000)
Step: 83999, Reward: [-319.204 -319.204 -319.204] [0.0000], Avg: [-450.566 -450.566 -450.566] (1.000)
Step: 84049, Reward: [-275.321 -275.321 -275.321] [0.0000], Avg: [-450.461 -450.461 -450.461] (1.000)
Step: 84099, Reward: [-477.993 -477.993 -477.993] [0.0000], Avg: [-450.478 -450.478 -450.478] (1.000)
Step: 84149, Reward: [-350.302 -350.302 -350.302] [0.0000], Avg: [-450.418 -450.418 -450.418] (1.000)
Step: 84199, Reward: [-355.3 -355.3 -355.3] [0.0000], Avg: [-450.362 -450.362 -450.362] (1.000)
Step: 84249, Reward: [-463.175 -463.175 -463.175] [0.0000], Avg: [-450.369 -450.369 -450.369] (1.000)
Step: 84299, Reward: [-335.009 -335.009 -335.009] [0.0000], Avg: [-450.301 -450.301 -450.301] (1.000)
Step: 84349, Reward: [-352.353 -352.353 -352.353] [0.0000], Avg: [-450.243 -450.243 -450.243] (1.000)
Step: 84399, Reward: [-369.117 -369.117 -369.117] [0.0000], Avg: [-450.195 -450.195 -450.195] (1.000)
Step: 84449, Reward: [-397.1 -397.1 -397.1] [0.0000], Avg: [-450.163 -450.163 -450.163] (1.000)
Step: 84499, Reward: [-365. -365. -365.] [0.0000], Avg: [-450.113 -450.113 -450.113] (1.000)
Step: 84549, Reward: [-457.165 -457.165 -457.165] [0.0000], Avg: [-450.117 -450.117 -450.117] (1.000)
Step: 84599, Reward: [-338.664 -338.664 -338.664] [0.0000], Avg: [-450.051 -450.051 -450.051] (1.000)
Step: 84649, Reward: [-280.312 -280.312 -280.312] [0.0000], Avg: [-449.951 -449.951 -449.951] (1.000)
Step: 84699, Reward: [-394.268 -394.268 -394.268] [0.0000], Avg: [-449.918 -449.918 -449.918] (1.000)
Step: 84749, Reward: [-399.68 -399.68 -399.68] [0.0000], Avg: [-449.888 -449.888 -449.888] (1.000)
Step: 84799, Reward: [-456.493 -456.493 -456.493] [0.0000], Avg: [-449.892 -449.892 -449.892] (1.000)
Step: 84849, Reward: [-381.641 -381.641 -381.641] [0.0000], Avg: [-449.852 -449.852 -449.852] (1.000)
Step: 84899, Reward: [-352.842 -352.842 -352.842] [0.0000], Avg: [-449.795 -449.795 -449.795] (1.000)
Step: 84949, Reward: [-505.629 -505.629 -505.629] [0.0000], Avg: [-449.828 -449.828 -449.828] (1.000)
Step: 84999, Reward: [-283.02 -283.02 -283.02] [0.0000], Avg: [-449.73 -449.73 -449.73] (1.000)
Step: 85049, Reward: [-340.818 -340.818 -340.818] [0.0000], Avg: [-449.666 -449.666 -449.666] (1.000)
Step: 85099, Reward: [-356.902 -356.902 -356.902] [0.0000], Avg: [-449.611 -449.611 -449.611] (1.000)
Step: 85149, Reward: [-444.32 -444.32 -444.32] [0.0000], Avg: [-449.608 -449.608 -449.608] (1.000)
Step: 85199, Reward: [-455.337 -455.337 -455.337] [0.0000], Avg: [-449.612 -449.612 -449.612] (1.000)
Step: 85249, Reward: [-390.302 -390.302 -390.302] [0.0000], Avg: [-449.577 -449.577 -449.577] (1.000)
Step: 85299, Reward: [-286.848 -286.848 -286.848] [0.0000], Avg: [-449.481 -449.481 -449.481] (1.000)
Step: 85349, Reward: [-338.047 -338.047 -338.047] [0.0000], Avg: [-449.416 -449.416 -449.416] (1.000)
Step: 85399, Reward: [-340.866 -340.866 -340.866] [0.0000], Avg: [-449.352 -449.352 -449.352] (1.000)
Step: 85449, Reward: [-369.9 -369.9 -369.9] [0.0000], Avg: [-449.306 -449.306 -449.306] (1.000)
Step: 85499, Reward: [-484.133 -484.133 -484.133] [0.0000], Avg: [-449.326 -449.326 -449.326] (1.000)
Step: 85549, Reward: [-475.165 -475.165 -475.165] [0.0000], Avg: [-449.341 -449.341 -449.341] (1.000)
Step: 85599, Reward: [-343.03 -343.03 -343.03] [0.0000], Avg: [-449.279 -449.279 -449.279] (1.000)
Step: 85649, Reward: [-424.019 -424.019 -424.019] [0.0000], Avg: [-449.265 -449.265 -449.265] (1.000)
Step: 85699, Reward: [-308.139 -308.139 -308.139] [0.0000], Avg: [-449.182 -449.182 -449.182] (1.000)
Step: 85749, Reward: [-421.984 -421.984 -421.984] [0.0000], Avg: [-449.166 -449.166 -449.166] (1.000)
Step: 85799, Reward: [-415.385 -415.385 -415.385] [0.0000], Avg: [-449.147 -449.147 -449.147] (1.000)
Step: 85849, Reward: [-327.181 -327.181 -327.181] [0.0000], Avg: [-449.076 -449.076 -449.076] (1.000)
Step: 85899, Reward: [-348.424 -348.424 -348.424] [0.0000], Avg: [-449.017 -449.017 -449.017] (1.000)
Step: 85949, Reward: [-614.204 -614.204 -614.204] [0.0000], Avg: [-449.113 -449.113 -449.113] (1.000)
Step: 85999, Reward: [-439.163 -439.163 -439.163] [0.0000], Avg: [-449.107 -449.107 -449.107] (1.000)
Step: 86049, Reward: [-288.195 -288.195 -288.195] [0.0000], Avg: [-449.014 -449.014 -449.014] (1.000)
Step: 86099, Reward: [-494.873 -494.873 -494.873] [0.0000], Avg: [-449.041 -449.041 -449.041] (1.000)
Step: 86149, Reward: [-366.319 -366.319 -366.319] [0.0000], Avg: [-448.993 -448.993 -448.993] (1.000)
Step: 86199, Reward: [-290.307 -290.307 -290.307] [0.0000], Avg: [-448.901 -448.901 -448.901] (1.000)
Step: 86249, Reward: [-399.882 -399.882 -399.882] [0.0000], Avg: [-448.872 -448.872 -448.872] (1.000)
Step: 86299, Reward: [-480.14 -480.14 -480.14] [0.0000], Avg: [-448.89 -448.89 -448.89] (1.000)
Step: 86349, Reward: [-323.416 -323.416 -323.416] [0.0000], Avg: [-448.818 -448.818 -448.818] (1.000)
Step: 86399, Reward: [-322.721 -322.721 -322.721] [0.0000], Avg: [-448.745 -448.745 -448.745] (1.000)
Step: 86449, Reward: [-339.705 -339.705 -339.705] [0.0000], Avg: [-448.682 -448.682 -448.682] (1.000)
Step: 86499, Reward: [-339.956 -339.956 -339.956] [0.0000], Avg: [-448.619 -448.619 -448.619] (1.000)
Step: 86549, Reward: [-370.259 -370.259 -370.259] [0.0000], Avg: [-448.573 -448.573 -448.573] (1.000)
Step: 86599, Reward: [-298.497 -298.497 -298.497] [0.0000], Avg: [-448.487 -448.487 -448.487] (1.000)
Step: 86649, Reward: [-394.041 -394.041 -394.041] [0.0000], Avg: [-448.455 -448.455 -448.455] (1.000)
Step: 86699, Reward: [-276.509 -276.509 -276.509] [0.0000], Avg: [-448.356 -448.356 -448.356] (1.000)
Step: 86749, Reward: [-305.933 -305.933 -305.933] [0.0000], Avg: [-448.274 -448.274 -448.274] (1.000)
Step: 86799, Reward: [-397.247 -397.247 -397.247] [0.0000], Avg: [-448.245 -448.245 -448.245] (1.000)
Step: 86849, Reward: [-355.389 -355.389 -355.389] [0.0000], Avg: [-448.191 -448.191 -448.191] (1.000)
Step: 86899, Reward: [-362.326 -362.326 -362.326] [0.0000], Avg: [-448.142 -448.142 -448.142] (1.000)
Step: 86949, Reward: [-394.577 -394.577 -394.577] [0.0000], Avg: [-448.111 -448.111 -448.111] (1.000)
Step: 86999, Reward: [-528.5 -528.5 -528.5] [0.0000], Avg: [-448.157 -448.157 -448.157] (1.000)
Step: 87049, Reward: [-516.295 -516.295 -516.295] [0.0000], Avg: [-448.196 -448.196 -448.196] (1.000)
Step: 87099, Reward: [-533.211 -533.211 -533.211] [0.0000], Avg: [-448.245 -448.245 -448.245] (1.000)
Step: 87149, Reward: [-355.585 -355.585 -355.585] [0.0000], Avg: [-448.192 -448.192 -448.192] (1.000)
Step: 87199, Reward: [-366.124 -366.124 -366.124] [0.0000], Avg: [-448.145 -448.145 -448.145] (1.000)
Step: 87249, Reward: [-399.547 -399.547 -399.547] [0.0000], Avg: [-448.117 -448.117 -448.117] (1.000)
Step: 87299, Reward: [-454.042 -454.042 -454.042] [0.0000], Avg: [-448.12 -448.12 -448.12] (1.000)
Step: 87349, Reward: [-442.762 -442.762 -442.762] [0.0000], Avg: [-448.117 -448.117 -448.117] (1.000)
Step: 87399, Reward: [-372.925 -372.925 -372.925] [0.0000], Avg: [-448.074 -448.074 -448.074] (1.000)
Step: 87449, Reward: [-389.496 -389.496 -389.496] [0.0000], Avg: [-448.041 -448.041 -448.041] (1.000)
Step: 87499, Reward: [-356.152 -356.152 -356.152] [0.0000], Avg: [-447.988 -447.988 -447.988] (1.000)
Step: 87549, Reward: [-452.556 -452.556 -452.556] [0.0000], Avg: [-447.991 -447.991 -447.991] (1.000)
Step: 87599, Reward: [-244.454 -244.454 -244.454] [0.0000], Avg: [-447.875 -447.875 -447.875] (1.000)
Step: 87649, Reward: [-370.129 -370.129 -370.129] [0.0000], Avg: [-447.83 -447.83 -447.83] (1.000)
Step: 87699, Reward: [-375.143 -375.143 -375.143] [0.0000], Avg: [-447.789 -447.789 -447.789] (1.000)
Step: 87749, Reward: [-337.331 -337.331 -337.331] [0.0000], Avg: [-447.726 -447.726 -447.726] (1.000)
Step: 87799, Reward: [-414.685 -414.685 -414.685] [0.0000], Avg: [-447.707 -447.707 -447.707] (1.000)
Step: 87849, Reward: [-352.635 -352.635 -352.635] [0.0000], Avg: [-447.653 -447.653 -447.653] (1.000)
Step: 87899, Reward: [-388.722 -388.722 -388.722] [0.0000], Avg: [-447.62 -447.62 -447.62] (1.000)
Step: 87949, Reward: [-307.47 -307.47 -307.47] [0.0000], Avg: [-447.54 -447.54 -447.54] (1.000)
Step: 87999, Reward: [-315.018 -315.018 -315.018] [0.0000], Avg: [-447.465 -447.465 -447.465] (1.000)
Step: 88049, Reward: [-249.039 -249.039 -249.039] [0.0000], Avg: [-447.352 -447.352 -447.352] (1.000)
Step: 88099, Reward: [-409.949 -409.949 -409.949] [0.0000], Avg: [-447.331 -447.331 -447.331] (1.000)
Step: 88149, Reward: [-544.204 -544.204 -544.204] [0.0000], Avg: [-447.386 -447.386 -447.386] (1.000)
Step: 88199, Reward: [-318.723 -318.723 -318.723] [0.0000], Avg: [-447.313 -447.313 -447.313] (1.000)
Step: 88249, Reward: [-471.746 -471.746 -471.746] [0.0000], Avg: [-447.327 -447.327 -447.327] (1.000)
Step: 88299, Reward: [-478.255 -478.255 -478.255] [0.0000], Avg: [-447.344 -447.344 -447.344] (1.000)
Step: 88349, Reward: [-369.569 -369.569 -369.569] [0.0000], Avg: [-447.3 -447.3 -447.3] (1.000)
Step: 88399, Reward: [-355.173 -355.173 -355.173] [0.0000], Avg: [-447.248 -447.248 -447.248] (1.000)
Step: 88449, Reward: [-375.029 -375.029 -375.029] [0.0000], Avg: [-447.207 -447.207 -447.207] (1.000)
Step: 88499, Reward: [-350.179 -350.179 -350.179] [0.0000], Avg: [-447.152 -447.152 -447.152] (1.000)
Step: 88549, Reward: [-289.002 -289.002 -289.002] [0.0000], Avg: [-447.063 -447.063 -447.063] (1.000)
Step: 88599, Reward: [-309.205 -309.205 -309.205] [0.0000], Avg: [-446.985 -446.985 -446.985] (1.000)
Step: 88649, Reward: [-395.973 -395.973 -395.973] [0.0000], Avg: [-446.957 -446.957 -446.957] (1.000)
Step: 88699, Reward: [-371.255 -371.255 -371.255] [0.0000], Avg: [-446.914 -446.914 -446.914] (1.000)
Step: 88749, Reward: [-506.863 -506.863 -506.863] [0.0000], Avg: [-446.948 -446.948 -446.948] (1.000)
Step: 88799, Reward: [-441.012 -441.012 -441.012] [0.0000], Avg: [-446.944 -446.944 -446.944] (1.000)
Step: 88849, Reward: [-432.512 -432.512 -432.512] [0.0000], Avg: [-446.936 -446.936 -446.936] (1.000)
Step: 88899, Reward: [-461.845 -461.845 -461.845] [0.0000], Avg: [-446.945 -446.945 -446.945] (1.000)
Step: 88949, Reward: [-315.04 -315.04 -315.04] [0.0000], Avg: [-446.87 -446.87 -446.87] (1.000)
Step: 88999, Reward: [-449.378 -449.378 -449.378] [0.0000], Avg: [-446.872 -446.872 -446.872] (1.000)
Step: 89049, Reward: [-439.491 -439.491 -439.491] [0.0000], Avg: [-446.868 -446.868 -446.868] (1.000)
Step: 89099, Reward: [-427.691 -427.691 -427.691] [0.0000], Avg: [-446.857 -446.857 -446.857] (1.000)
Step: 89149, Reward: [-468.214 -468.214 -468.214] [0.0000], Avg: [-446.869 -446.869 -446.869] (1.000)
Step: 89199, Reward: [-286.579 -286.579 -286.579] [0.0000], Avg: [-446.779 -446.779 -446.779] (1.000)
Step: 89249, Reward: [-419.582 -419.582 -419.582] [0.0000], Avg: [-446.764 -446.764 -446.764] (1.000)
Step: 89299, Reward: [-367.926 -367.926 -367.926] [0.0000], Avg: [-446.72 -446.72 -446.72] (1.000)
Step: 89349, Reward: [-316.642 -316.642 -316.642] [0.0000], Avg: [-446.647 -446.647 -446.647] (1.000)
Step: 89399, Reward: [-472.237 -472.237 -472.237] [0.0000], Avg: [-446.661 -446.661 -446.661] (1.000)
Step: 89449, Reward: [-343.355 -343.355 -343.355] [0.0000], Avg: [-446.603 -446.603 -446.603] (1.000)
Step: 89499, Reward: [-376.125 -376.125 -376.125] [0.0000], Avg: [-446.564 -446.564 -446.564] (1.000)
Step: 89549, Reward: [-415.742 -415.742 -415.742] [0.0000], Avg: [-446.547 -446.547 -446.547] (1.000)
Step: 89599, Reward: [-384.088 -384.088 -384.088] [0.0000], Avg: [-446.512 -446.512 -446.512] (1.000)
Step: 89649, Reward: [-339.258 -339.258 -339.258] [0.0000], Avg: [-446.452 -446.452 -446.452] (1.000)
Step: 89699, Reward: [-289.202 -289.202 -289.202] [0.0000], Avg: [-446.365 -446.365 -446.365] (1.000)
Step: 89749, Reward: [-288.138 -288.138 -288.138] [0.0000], Avg: [-446.276 -446.276 -446.276] (1.000)
Step: 89799, Reward: [-369.333 -369.333 -369.333] [0.0000], Avg: [-446.234 -446.234 -446.234] (1.000)
Step: 89849, Reward: [-399.638 -399.638 -399.638] [0.0000], Avg: [-446.208 -446.208 -446.208] (1.000)
Step: 89899, Reward: [-418.143 -418.143 -418.143] [0.0000], Avg: [-446.192 -446.192 -446.192] (1.000)
Step: 89949, Reward: [-394.921 -394.921 -394.921] [0.0000], Avg: [-446.163 -446.163 -446.163] (1.000)
Step: 89999, Reward: [-484.297 -484.297 -484.297] [0.0000], Avg: [-446.185 -446.185 -446.185] (1.000)
Step: 90049, Reward: [-367.111 -367.111 -367.111] [0.0000], Avg: [-446.141 -446.141 -446.141] (1.000)
Step: 90099, Reward: [-314.254 -314.254 -314.254] [0.0000], Avg: [-446.068 -446.068 -446.068] (1.000)
Step: 90149, Reward: [-448.802 -448.802 -448.802] [0.0000], Avg: [-446.069 -446.069 -446.069] (1.000)
Step: 90199, Reward: [-346.276 -346.276 -346.276] [0.0000], Avg: [-446.014 -446.014 -446.014] (1.000)
Step: 90249, Reward: [-298.959 -298.959 -298.959] [0.0000], Avg: [-445.932 -445.932 -445.932] (1.000)
Step: 90299, Reward: [-426.139 -426.139 -426.139] [0.0000], Avg: [-445.921 -445.921 -445.921] (1.000)
Step: 90349, Reward: [-337.537 -337.537 -337.537] [0.0000], Avg: [-445.861 -445.861 -445.861] (1.000)
Step: 90399, Reward: [-363.056 -363.056 -363.056] [0.0000], Avg: [-445.816 -445.816 -445.816] (1.000)
Step: 90449, Reward: [-314.209 -314.209 -314.209] [0.0000], Avg: [-445.743 -445.743 -445.743] (1.000)
Step: 90499, Reward: [-253.172 -253.172 -253.172] [0.0000], Avg: [-445.636 -445.636 -445.636] (1.000)
Step: 90549, Reward: [-383.253 -383.253 -383.253] [0.0000], Avg: [-445.602 -445.602 -445.602] (1.000)
Step: 90599, Reward: [-502.724 -502.724 -502.724] [0.0000], Avg: [-445.634 -445.634 -445.634] (1.000)
Step: 90649, Reward: [-315.348 -315.348 -315.348] [0.0000], Avg: [-445.562 -445.562 -445.562] (1.000)
Step: 90699, Reward: [-322.074 -322.074 -322.074] [0.0000], Avg: [-445.494 -445.494 -445.494] (1.000)
Step: 90749, Reward: [-269.625 -269.625 -269.625] [0.0000], Avg: [-445.397 -445.397 -445.397] (1.000)
Step: 90799, Reward: [-299.973 -299.973 -299.973] [0.0000], Avg: [-445.317 -445.317 -445.317] (1.000)
Step: 90849, Reward: [-357.174 -357.174 -357.174] [0.0000], Avg: [-445.268 -445.268 -445.268] (1.000)
Step: 90899, Reward: [-453.282 -453.282 -453.282] [0.0000], Avg: [-445.272 -445.272 -445.272] (1.000)
Step: 90949, Reward: [-353.667 -353.667 -353.667] [0.0000], Avg: [-445.222 -445.222 -445.222] (1.000)
Step: 90999, Reward: [-302.281 -302.281 -302.281] [0.0000], Avg: [-445.144 -445.144 -445.144] (1.000)
Step: 91049, Reward: [-365.39 -365.39 -365.39] [0.0000], Avg: [-445.1 -445.1 -445.1] (1.000)
Step: 91099, Reward: [-308.656 -308.656 -308.656] [0.0000], Avg: [-445.025 -445.025 -445.025] (1.000)
Step: 91149, Reward: [-326.035 -326.035 -326.035] [0.0000], Avg: [-444.96 -444.96 -444.96] (1.000)
Step: 91199, Reward: [-369.377 -369.377 -369.377] [0.0000], Avg: [-444.918 -444.918 -444.918] (1.000)
Step: 91249, Reward: [-472.715 -472.715 -472.715] [0.0000], Avg: [-444.933 -444.933 -444.933] (1.000)
Step: 91299, Reward: [-444.887 -444.887 -444.887] [0.0000], Avg: [-444.933 -444.933 -444.933] (1.000)
Step: 91349, Reward: [-446.445 -446.445 -446.445] [0.0000], Avg: [-444.934 -444.934 -444.934] (1.000)
Step: 91399, Reward: [-386.035 -386.035 -386.035] [0.0000], Avg: [-444.902 -444.902 -444.902] (1.000)
Step: 91449, Reward: [-303.382 -303.382 -303.382] [0.0000], Avg: [-444.825 -444.825 -444.825] (1.000)
Step: 91499, Reward: [-274.121 -274.121 -274.121] [0.0000], Avg: [-444.731 -444.731 -444.731] (1.000)
Step: 91549, Reward: [-285.025 -285.025 -285.025] [0.0000], Avg: [-444.644 -444.644 -444.644] (1.000)
Step: 91599, Reward: [-301.992 -301.992 -301.992] [0.0000], Avg: [-444.566 -444.566 -444.566] (1.000)
Step: 91649, Reward: [-507.265 -507.265 -507.265] [0.0000], Avg: [-444.6 -444.6 -444.6] (1.000)
Step: 91699, Reward: [-378.94 -378.94 -378.94] [0.0000], Avg: [-444.565 -444.565 -444.565] (1.000)
Step: 91749, Reward: [-357.11 -357.11 -357.11] [0.0000], Avg: [-444.517 -444.517 -444.517] (1.000)
Step: 91799, Reward: [-290.175 -290.175 -290.175] [0.0000], Avg: [-444.433 -444.433 -444.433] (1.000)
Step: 91849, Reward: [-475.849 -475.849 -475.849] [0.0000], Avg: [-444.45 -444.45 -444.45] (1.000)
Step: 91899, Reward: [-301.888 -301.888 -301.888] [0.0000], Avg: [-444.372 -444.372 -444.372] (1.000)
Step: 91949, Reward: [-470.602 -470.602 -470.602] [0.0000], Avg: [-444.387 -444.387 -444.387] (1.000)
Step: 91999, Reward: [-317.604 -317.604 -317.604] [0.0000], Avg: [-444.318 -444.318 -444.318] (1.000)
Step: 92049, Reward: [-460.694 -460.694 -460.694] [0.0000], Avg: [-444.327 -444.327 -444.327] (1.000)
Step: 92099, Reward: [-374.278 -374.278 -374.278] [0.0000], Avg: [-444.289 -444.289 -444.289] (1.000)
Step: 92149, Reward: [-418.79 -418.79 -418.79] [0.0000], Avg: [-444.275 -444.275 -444.275] (1.000)
Step: 92199, Reward: [-461.185 -461.185 -461.185] [0.0000], Avg: [-444.284 -444.284 -444.284] (1.000)
Step: 92249, Reward: [-412.33 -412.33 -412.33] [0.0000], Avg: [-444.267 -444.267 -444.267] (1.000)
Step: 92299, Reward: [-319.482 -319.482 -319.482] [0.0000], Avg: [-444.199 -444.199 -444.199] (1.000)
Step: 92349, Reward: [-366.188 -366.188 -366.188] [0.0000], Avg: [-444.157 -444.157 -444.157] (1.000)
Step: 92399, Reward: [-258.923 -258.923 -258.923] [0.0000], Avg: [-444.057 -444.057 -444.057] (1.000)
Step: 92449, Reward: [-396.537 -396.537 -396.537] [0.0000], Avg: [-444.031 -444.031 -444.031] (1.000)
Step: 92499, Reward: [-329.77 -329.77 -329.77] [0.0000], Avg: [-443.969 -443.969 -443.969] (1.000)
Step: 92549, Reward: [-307.379 -307.379 -307.379] [0.0000], Avg: [-443.895 -443.895 -443.895] (1.000)
Step: 92599, Reward: [-410.514 -410.514 -410.514] [0.0000], Avg: [-443.877 -443.877 -443.877] (1.000)
Step: 92649, Reward: [-387.041 -387.041 -387.041] [0.0000], Avg: [-443.847 -443.847 -443.847] (1.000)
Step: 92699, Reward: [-428.061 -428.061 -428.061] [0.0000], Avg: [-443.838 -443.838 -443.838] (1.000)
Step: 92749, Reward: [-357.722 -357.722 -357.722] [0.0000], Avg: [-443.792 -443.792 -443.792] (1.000)
Step: 92799, Reward: [-327.265 -327.265 -327.265] [0.0000], Avg: [-443.729 -443.729 -443.729] (1.000)
Step: 92849, Reward: [-282.433 -282.433 -282.433] [0.0000], Avg: [-443.642 -443.642 -443.642] (1.000)
Step: 92899, Reward: [-307.128 -307.128 -307.128] [0.0000], Avg: [-443.569 -443.569 -443.569] (1.000)
Step: 92949, Reward: [-435.24 -435.24 -435.24] [0.0000], Avg: [-443.564 -443.564 -443.564] (1.000)
Step: 92999, Reward: [-394.449 -394.449 -394.449] [0.0000], Avg: [-443.538 -443.538 -443.538] (1.000)
Step: 93049, Reward: [-392.188 -392.188 -392.188] [0.0000], Avg: [-443.51 -443.51 -443.51] (1.000)
Step: 93099, Reward: [-315.197 -315.197 -315.197] [0.0000], Avg: [-443.441 -443.441 -443.441] (1.000)
Step: 93149, Reward: [-359.113 -359.113 -359.113] [0.0000], Avg: [-443.396 -443.396 -443.396] (1.000)
Step: 93199, Reward: [-416.792 -416.792 -416.792] [0.0000], Avg: [-443.382 -443.382 -443.382] (1.000)
Step: 93249, Reward: [-484.962 -484.962 -484.962] [0.0000], Avg: [-443.404 -443.404 -443.404] (1.000)
Step: 93299, Reward: [-353.307 -353.307 -353.307] [0.0000], Avg: [-443.356 -443.356 -443.356] (1.000)
Step: 93349, Reward: [-272.4 -272.4 -272.4] [0.0000], Avg: [-443.264 -443.264 -443.264] (1.000)
Step: 93399, Reward: [-357.007 -357.007 -357.007] [0.0000], Avg: [-443.218 -443.218 -443.218] (1.000)
Step: 93449, Reward: [-376.664 -376.664 -376.664] [0.0000], Avg: [-443.182 -443.182 -443.182] (1.000)
Step: 93499, Reward: [-365.742 -365.742 -365.742] [0.0000], Avg: [-443.141 -443.141 -443.141] (1.000)
Step: 93549, Reward: [-359.168 -359.168 -359.168] [0.0000], Avg: [-443.096 -443.096 -443.096] (1.000)
Step: 93599, Reward: [-312.571 -312.571 -312.571] [0.0000], Avg: [-443.026 -443.026 -443.026] (1.000)
Step: 93649, Reward: [-402.869 -402.869 -402.869] [0.0000], Avg: [-443.005 -443.005 -443.005] (1.000)
Step: 93699, Reward: [-366.481 -366.481 -366.481] [0.0000], Avg: [-442.964 -442.964 -442.964] (1.000)
Step: 93749, Reward: [-403.347 -403.347 -403.347] [0.0000], Avg: [-442.943 -442.943 -442.943] (1.000)
Step: 93799, Reward: [-397.265 -397.265 -397.265] [0.0000], Avg: [-442.919 -442.919 -442.919] (1.000)
Step: 93849, Reward: [-336.079 -336.079 -336.079] [0.0000], Avg: [-442.862 -442.862 -442.862] (1.000)
Step: 93899, Reward: [-330.081 -330.081 -330.081] [0.0000], Avg: [-442.802 -442.802 -442.802] (1.000)
Step: 93949, Reward: [-380.543 -380.543 -380.543] [0.0000], Avg: [-442.768 -442.768 -442.768] (1.000)
Step: 93999, Reward: [-255.068 -255.068 -255.068] [0.0000], Avg: [-442.669 -442.669 -442.669] (1.000)
Step: 94049, Reward: [-390.292 -390.292 -390.292] [0.0000], Avg: [-442.641 -442.641 -442.641] (1.000)
Step: 94099, Reward: [-334.139 -334.139 -334.139] [0.0000], Avg: [-442.583 -442.583 -442.583] (1.000)
Step: 94149, Reward: [-413.591 -413.591 -413.591] [0.0000], Avg: [-442.568 -442.568 -442.568] (1.000)
Step: 94199, Reward: [-409.594 -409.594 -409.594] [0.0000], Avg: [-442.55 -442.55 -442.55] (1.000)
Step: 94249, Reward: [-343.167 -343.167 -343.167] [0.0000], Avg: [-442.498 -442.498 -442.498] (1.000)
Step: 94299, Reward: [-302.553 -302.553 -302.553] [0.0000], Avg: [-442.423 -442.423 -442.423] (1.000)
Step: 94349, Reward: [-492.133 -492.133 -492.133] [0.0000], Avg: [-442.45 -442.45 -442.45] (1.000)
Step: 94399, Reward: [-405.989 -405.989 -405.989] [0.0000], Avg: [-442.43 -442.43 -442.43] (1.000)
Step: 94449, Reward: [-409.075 -409.075 -409.075] [0.0000], Avg: [-442.413 -442.413 -442.413] (1.000)
Step: 94499, Reward: [-312.271 -312.271 -312.271] [0.0000], Avg: [-442.344 -442.344 -442.344] (1.000)
Step: 94549, Reward: [-315.842 -315.842 -315.842] [0.0000], Avg: [-442.277 -442.277 -442.277] (1.000)
Step: 94599, Reward: [-441.474 -441.474 -441.474] [0.0000], Avg: [-442.277 -442.277 -442.277] (1.000)
Step: 94649, Reward: [-378.343 -378.343 -378.343] [0.0000], Avg: [-442.243 -442.243 -442.243] (1.000)
Step: 94699, Reward: [-378.277 -378.277 -378.277] [0.0000], Avg: [-442.209 -442.209 -442.209] (1.000)
Step: 94749, Reward: [-353.32 -353.32 -353.32] [0.0000], Avg: [-442.162 -442.162 -442.162] (1.000)
Step: 94799, Reward: [-408.039 -408.039 -408.039] [0.0000], Avg: [-442.144 -442.144 -442.144] (1.000)
Step: 94849, Reward: [-447.374 -447.374 -447.374] [0.0000], Avg: [-442.147 -442.147 -442.147] (1.000)
Step: 94899, Reward: [-408.572 -408.572 -408.572] [0.0000], Avg: [-442.129 -442.129 -442.129] (1.000)
Step: 94949, Reward: [-447.025 -447.025 -447.025] [0.0000], Avg: [-442.132 -442.132 -442.132] (1.000)
Step: 94999, Reward: [-452.038 -452.038 -452.038] [0.0000], Avg: [-442.137 -442.137 -442.137] (1.000)
Step: 95049, Reward: [-415.82 -415.82 -415.82] [0.0000], Avg: [-442.123 -442.123 -442.123] (1.000)
Step: 95099, Reward: [-370.579 -370.579 -370.579] [0.0000], Avg: [-442.085 -442.085 -442.085] (1.000)
Step: 95149, Reward: [-339.795 -339.795 -339.795] [0.0000], Avg: [-442.032 -442.032 -442.032] (1.000)
Step: 95199, Reward: [-394.532 -394.532 -394.532] [0.0000], Avg: [-442.007 -442.007 -442.007] (1.000)
Step: 95249, Reward: [-287.583 -287.583 -287.583] [0.0000], Avg: [-441.926 -441.926 -441.926] (1.000)
Step: 95299, Reward: [-400.29 -400.29 -400.29] [0.0000], Avg: [-441.904 -441.904 -441.904] (1.000)
Step: 95349, Reward: [-294.02 -294.02 -294.02] [0.0000], Avg: [-441.826 -441.826 -441.826] (1.000)
Step: 95399, Reward: [-425.894 -425.894 -425.894] [0.0000], Avg: [-441.818 -441.818 -441.818] (1.000)
Step: 95449, Reward: [-350.06 -350.06 -350.06] [0.0000], Avg: [-441.77 -441.77 -441.77] (1.000)
Step: 95499, Reward: [-371.194 -371.194 -371.194] [0.0000], Avg: [-441.733 -441.733 -441.733] (1.000)
Step: 95549, Reward: [-430.973 -430.973 -430.973] [0.0000], Avg: [-441.727 -441.727 -441.727] (1.000)
Step: 95599, Reward: [-457.108 -457.108 -457.108] [0.0000], Avg: [-441.735 -441.735 -441.735] (1.000)
Step: 95649, Reward: [-358.878 -358.878 -358.878] [0.0000], Avg: [-441.692 -441.692 -441.692] (1.000)
Step: 95699, Reward: [-302.938 -302.938 -302.938] [0.0000], Avg: [-441.62 -441.62 -441.62] (1.000)
Step: 95749, Reward: [-406.498 -406.498 -406.498] [0.0000], Avg: [-441.601 -441.601 -441.601] (1.000)
Step: 95799, Reward: [-490.047 -490.047 -490.047] [0.0000], Avg: [-441.627 -441.627 -441.627] (1.000)
Step: 95849, Reward: [-302.017 -302.017 -302.017] [0.0000], Avg: [-441.554 -441.554 -441.554] (1.000)
Step: 95899, Reward: [-275.853 -275.853 -275.853] [0.0000], Avg: [-441.467 -441.467 -441.467] (1.000)
Step: 95949, Reward: [-267.59 -267.59 -267.59] [0.0000], Avg: [-441.377 -441.377 -441.377] (1.000)
Step: 95999, Reward: [-261.519 -261.519 -261.519] [0.0000], Avg: [-441.283 -441.283 -441.283] (1.000)
Step: 96049, Reward: [-435.334 -435.334 -435.334] [0.0000], Avg: [-441.28 -441.28 -441.28] (1.000)
Step: 96099, Reward: [-386.018 -386.018 -386.018] [0.0000], Avg: [-441.251 -441.251 -441.251] (1.000)
Step: 96149, Reward: [-341.94 -341.94 -341.94] [0.0000], Avg: [-441.2 -441.2 -441.2] (1.000)
Step: 96199, Reward: [-326.646 -326.646 -326.646] [0.0000], Avg: [-441.14 -441.14 -441.14] (1.000)
Step: 96249, Reward: [-262.984 -262.984 -262.984] [0.0000], Avg: [-441.047 -441.047 -441.047] (1.000)
Step: 96299, Reward: [-298.729 -298.729 -298.729] [0.0000], Avg: [-440.974 -440.974 -440.974] (1.000)
Step: 96349, Reward: [-447.473 -447.473 -447.473] [0.0000], Avg: [-440.977 -440.977 -440.977] (1.000)
Step: 96399, Reward: [-315.889 -315.889 -315.889] [0.0000], Avg: [-440.912 -440.912 -440.912] (1.000)
Step: 96449, Reward: [-329.373 -329.373 -329.373] [0.0000], Avg: [-440.854 -440.854 -440.854] (1.000)
Step: 96499, Reward: [-367.167 -367.167 -367.167] [0.0000], Avg: [-440.816 -440.816 -440.816] (1.000)
Step: 96549, Reward: [-311.894 -311.894 -311.894] [0.0000], Avg: [-440.749 -440.749 -440.749] (1.000)
Step: 96599, Reward: [-421.639 -421.639 -421.639] [0.0000], Avg: [-440.739 -440.739 -440.739] (1.000)
Step: 96649, Reward: [-258.072 -258.072 -258.072] [0.0000], Avg: [-440.645 -440.645 -440.645] (1.000)
Step: 96699, Reward: [-455.058 -455.058 -455.058] [0.0000], Avg: [-440.652 -440.652 -440.652] (1.000)
Step: 96749, Reward: [-433.229 -433.229 -433.229] [0.0000], Avg: [-440.648 -440.648 -440.648] (1.000)
Step: 96799, Reward: [-292.002 -292.002 -292.002] [0.0000], Avg: [-440.572 -440.572 -440.572] (1.000)
Step: 96849, Reward: [-389.959 -389.959 -389.959] [0.0000], Avg: [-440.546 -440.546 -440.546] (1.000)
Step: 96899, Reward: [-426.165 -426.165 -426.165] [0.0000], Avg: [-440.538 -440.538 -440.538] (1.000)
Step: 96949, Reward: [-339.276 -339.276 -339.276] [0.0000], Avg: [-440.486 -440.486 -440.486] (1.000)
Step: 96999, Reward: [-248.914 -248.914 -248.914] [0.0000], Avg: [-440.387 -440.387 -440.387] (1.000)
Step: 97049, Reward: [-332.569 -332.569 -332.569] [0.0000], Avg: [-440.332 -440.332 -440.332] (1.000)
Step: 97099, Reward: [-392.769 -392.769 -392.769] [0.0000], Avg: [-440.307 -440.307 -440.307] (1.000)
Step: 97149, Reward: [-377.643 -377.643 -377.643] [0.0000], Avg: [-440.275 -440.275 -440.275] (1.000)
Step: 97199, Reward: [-400.378 -400.378 -400.378] [0.0000], Avg: [-440.254 -440.254 -440.254] (1.000)
Step: 97249, Reward: [-333.221 -333.221 -333.221] [0.0000], Avg: [-440.199 -440.199 -440.199] (1.000)
Step: 97299, Reward: [-303.525 -303.525 -303.525] [0.0000], Avg: [-440.129 -440.129 -440.129] (1.000)
Step: 97349, Reward: [-483.805 -483.805 -483.805] [0.0000], Avg: [-440.152 -440.152 -440.152] (1.000)
Step: 97399, Reward: [-353.495 -353.495 -353.495] [0.0000], Avg: [-440.107 -440.107 -440.107] (1.000)
Step: 97449, Reward: [-323.538 -323.538 -323.538] [0.0000], Avg: [-440.047 -440.047 -440.047] (1.000)
Step: 97499, Reward: [-354.499 -354.499 -354.499] [0.0000], Avg: [-440.003 -440.003 -440.003] (1.000)
Step: 97549, Reward: [-388.048 -388.048 -388.048] [0.0000], Avg: [-439.977 -439.977 -439.977] (1.000)
Step: 97599, Reward: [-458.177 -458.177 -458.177] [0.0000], Avg: [-439.986 -439.986 -439.986] (1.000)
Step: 97649, Reward: [-255.333 -255.333 -255.333] [0.0000], Avg: [-439.892 -439.892 -439.892] (1.000)
Step: 97699, Reward: [-371.261 -371.261 -371.261] [0.0000], Avg: [-439.856 -439.856 -439.856] (1.000)
Step: 97749, Reward: [-363.961 -363.961 -363.961] [0.0000], Avg: [-439.818 -439.818 -439.818] (1.000)
Step: 97799, Reward: [-335.289 -335.289 -335.289] [0.0000], Avg: [-439.764 -439.764 -439.764] (1.000)
Step: 97849, Reward: [-513.653 -513.653 -513.653] [0.0000], Avg: [-439.802 -439.802 -439.802] (1.000)
Step: 97899, Reward: [-394.636 -394.636 -394.636] [0.0000], Avg: [-439.779 -439.779 -439.779] (1.000)
Step: 97949, Reward: [-363.832 -363.832 -363.832] [0.0000], Avg: [-439.74 -439.74 -439.74] (1.000)
Step: 97999, Reward: [-384.15 -384.15 -384.15] [0.0000], Avg: [-439.712 -439.712 -439.712] (1.000)
Step: 98049, Reward: [-348.608 -348.608 -348.608] [0.0000], Avg: [-439.665 -439.665 -439.665] (1.000)
Step: 98099, Reward: [-406.123 -406.123 -406.123] [0.0000], Avg: [-439.648 -439.648 -439.648] (1.000)
Step: 98149, Reward: [-418.556 -418.556 -418.556] [0.0000], Avg: [-439.637 -439.637 -439.637] (1.000)
Step: 98199, Reward: [-421.197 -421.197 -421.197] [0.0000], Avg: [-439.628 -439.628 -439.628] (1.000)
Step: 98249, Reward: [-362.837 -362.837 -362.837] [0.0000], Avg: [-439.589 -439.589 -439.589] (1.000)
Step: 98299, Reward: [-412.395 -412.395 -412.395] [0.0000], Avg: [-439.575 -439.575 -439.575] (1.000)
Step: 98349, Reward: [-403.54 -403.54 -403.54] [0.0000], Avg: [-439.557 -439.557 -439.557] (1.000)
Step: 98399, Reward: [-302.106 -302.106 -302.106] [0.0000], Avg: [-439.487 -439.487 -439.487] (1.000)
Step: 98449, Reward: [-329.171 -329.171 -329.171] [0.0000], Avg: [-439.431 -439.431 -439.431] (1.000)
Step: 98499, Reward: [-381.446 -381.446 -381.446] [0.0000], Avg: [-439.401 -439.401 -439.401] (1.000)
Step: 98549, Reward: [-299.387 -299.387 -299.387] [0.0000], Avg: [-439.33 -439.33 -439.33] (1.000)
Step: 98599, Reward: [-360.618 -360.618 -360.618] [0.0000], Avg: [-439.291 -439.291 -439.291] (1.000)
Step: 98649, Reward: [-360.933 -360.933 -360.933] [0.0000], Avg: [-439.251 -439.251 -439.251] (1.000)
Step: 98699, Reward: [-357.873 -357.873 -357.873] [0.0000], Avg: [-439.21 -439.21 -439.21] (1.000)
Step: 98749, Reward: [-353.752 -353.752 -353.752] [0.0000], Avg: [-439.166 -439.166 -439.166] (1.000)
Step: 98799, Reward: [-409.963 -409.963 -409.963] [0.0000], Avg: [-439.152 -439.152 -439.152] (1.000)
Step: 98849, Reward: [-456.567 -456.567 -456.567] [0.0000], Avg: [-439.16 -439.16 -439.16] (1.000)
Step: 98899, Reward: [-432.686 -432.686 -432.686] [0.0000], Avg: [-439.157 -439.157 -439.157] (1.000)
Step: 98949, Reward: [-299.987 -299.987 -299.987] [0.0000], Avg: [-439.087 -439.087 -439.087] (1.000)
Step: 98999, Reward: [-297.092 -297.092 -297.092] [0.0000], Avg: [-439.015 -439.015 -439.015] (1.000)
Step: 99049, Reward: [-330.079 -330.079 -330.079] [0.0000], Avg: [-438.96 -438.96 -438.96] (1.000)
Step: 99099, Reward: [-412.166 -412.166 -412.166] [0.0000], Avg: [-438.947 -438.947 -438.947] (1.000)
Step: 99149, Reward: [-262.05 -262.05 -262.05] [0.0000], Avg: [-438.857 -438.857 -438.857] (1.000)
Step: 99199, Reward: [-328.532 -328.532 -328.532] [0.0000], Avg: [-438.802 -438.802 -438.802] (1.000)
Step: 99249, Reward: [-315.02 -315.02 -315.02] [0.0000], Avg: [-438.739 -438.739 -438.739] (1.000)
Step: 99299, Reward: [-353.304 -353.304 -353.304] [0.0000], Avg: [-438.696 -438.696 -438.696] (1.000)
Step: 99349, Reward: [-475.183 -475.183 -475.183] [0.0000], Avg: [-438.715 -438.715 -438.715] (1.000)
Step: 99399, Reward: [-343.342 -343.342 -343.342] [0.0000], Avg: [-438.667 -438.667 -438.667] (1.000)
Step: 99449, Reward: [-347.456 -347.456 -347.456] [0.0000], Avg: [-438.621 -438.621 -438.621] (1.000)
Step: 99499, Reward: [-350.433 -350.433 -350.433] [0.0000], Avg: [-438.577 -438.577 -438.577] (1.000)
Step: 99549, Reward: [-420.741 -420.741 -420.741] [0.0000], Avg: [-438.568 -438.568 -438.568] (1.000)
Step: 99599, Reward: [-392.198 -392.198 -392.198] [0.0000], Avg: [-438.544 -438.544 -438.544] (1.000)
Step: 99649, Reward: [-459.966 -459.966 -459.966] [0.0000], Avg: [-438.555 -438.555 -438.555] (1.000)
Step: 99699, Reward: [-333.652 -333.652 -333.652] [0.0000], Avg: [-438.502 -438.502 -438.502] (1.000)
Step: 99749, Reward: [-270.627 -270.627 -270.627] [0.0000], Avg: [-438.418 -438.418 -438.418] (1.000)
Step: 99799, Reward: [-485.203 -485.203 -485.203] [0.0000], Avg: [-438.442 -438.442 -438.442] (1.000)
Step: 99849, Reward: [-436.893 -436.893 -436.893] [0.0000], Avg: [-438.441 -438.441 -438.441] (1.000)
Step: 99899, Reward: [-381.125 -381.125 -381.125] [0.0000], Avg: [-438.412 -438.412 -438.412] (1.000)
Step: 99949, Reward: [-263.336 -263.336 -263.336] [0.0000], Avg: [-438.325 -438.325 -438.325] (1.000)
Step: 99999, Reward: [-390.201 -390.201 -390.201] [0.0000], Avg: [-438.301 -438.301 -438.301] (1.000)
