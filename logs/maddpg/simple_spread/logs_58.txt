Model: <class 'multiagent.maddpg.MADDPGAgent'>, Dir: simple_spread
num_envs: 1, state_size: [(1, 18), (1, 18), (1, 18)], action_size: [[1, 5], [1, 5], [1, 5]], action_space: [<gym.spaces.multi_discrete.MultiDiscrete object at 0x7f39c9e39be0>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f39c9e39c88>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f39c9e39cf8>],

import torch
import random
import numpy as np
from models.rand import MultiagentReplayBuffer
from models.ddpg import DDPGActor, DDPGCritic, DDPGNetwork
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACAgent, LEARN_RATE, NUM_STEPS, EPS_MIN, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, MAX_BUFFER_SIZE, gumbel_softmax, one_hot

REPLAY_BATCH_SIZE = 1024
ENTROPY_WEIGHT = 0.001			# The weight for the entropy term of the Actor loss
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64
LEARN_RATE = 0.01
TARGET_UPDATE_RATE = 0.01

class MADDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, sample=True):
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		action_mu = self.action_mu(state)
		action = gumbel_softmax(action_mu, hard=True)
		action = action.view(*out_dims, -1)
		return action
	
class MADDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1]+action_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1]+action_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, action):
		state = torch.cat([state, action], -1)
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		q_value = self.q_value(state)
		q_value = q_value.view(*out_dims, -1)
		return q_value

class MADDPGNetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=True, load=None):
		super().__init__(tau=tau, gpu=gpu)
		self.state_size = state_size
		self.action_size = action_size
		self.critic = MADDPGCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.models = [DDPGNetwork(s_size, a_size, MADDPGActor, lambda s,a: self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		
	def get_action_probs(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [model.get_action(s, use_target, grad, numpy, sample) for s,model in zip(state, self.models)]
			return action

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_value = [model.get_q_value(state, action, use_target, grad, numpy) for model in self.models]
			return q_value

	def optimize(self, states, actions, states_joint, actions_joint, q_targets, e_weight=ENTROPY_WEIGHT):
		for (i,model),state,q_target in zip(enumerate(self.models), states, q_targets):
			q_values = model.get_q_value(states_joint, actions_joint, grad=True, numpy=False)
			critic_error = q_values[:q_target.size(0)] - q_target.detach()
			critic_loss = critic_error.pow(2)
			model.step(model.critic_optimizer, critic_loss.mean(), param_norm=model.critic_local.parameters())
			model.soft_copy(model.critic_local, model.critic_target)

			actor_action = model.get_action(state, grad=True, numpy=False)
			critic_action = [actor_action if j==i else other.get_action(states[j], numpy=False) for j,other in enumerate(self.models)]
			action_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(critic_action, self.action_size)], dim=-1)
			q_actions = model.critic_local(states_joint, action_joint)
			actor_loss = -q_actions.mean() + e_weight*actor_action.pow(2).mean()
			model.step(model.actor_optimizer, actor_loss.mean(), param_norm=model.actor_local.parameters())
			model.soft_copy(model.actor_local, model.actor_target)

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class MADDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, MADDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.agent = MADDPG(state_size, action_size)
		self.replay_buffer = MultiagentReplayBuffer(MAX_BUFFER_SIZE, self.agent.nagents, [obsp[-1] for obsp in state_size], [acsp[-1] for acsp in action_size])

	def get_action(self, state, eps=None, sample=True, numpy=True):
		state = [torch.autograd.Variable(torch.Tensor(np.vstack(state[i])), requires_grad=False) for i in range(self.agent.nagents)]
		torch_agent_actions = self.agent.step(state)
		agent_actions = [ac.data.numpy() for ac in torch_agent_actions]
		return agent_actions
		# eps = self.eps if eps is None else eps
		# action_random = super().get_action(state)
		# action_greedy = self.network.get_action_probs(self.to_tensor(state), sample=sample, numpy=numpy)
		# action = [(1-eps)*a_greedy + eps*a_random for a_greedy,a_random in zip(action_greedy, action_random)]
		# return action

	def train(self, state, action, next_state, reward, done):
		if not hasattr(self, "t"): self.t = 0
		self.replay_buffer.push(state, action, next_state, reward, done)
		if (len(self.replay_buffer) >= 1024 and (self.t % 100)==0):
			for a_i in range(self.agent.nagents):
				sample = self.replay_buffer.sample(1024, to_gpu=False)
				self.agent.update(sample, a_i)
		self.t += 1
		"""
			# self.buffer.append((state, action, reward, done))
			# if np.any(done[0]) or len(self.buffer) >= self.update_freq:
			# 	states, actions, rewards, dones = map(lambda x: self.to_tensor(x), zip(*self.buffer))
			# 	self.buffer.clear()
			# 	next_state = self.to_tensor(next_state)
			# 	states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, next_state)]
			# 	actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.network.get_action_probs(next_state, use_target=True))]
			# 	states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			# 	actions_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions, self.action_size)], dim=-1)
			# 	q_values = self.network.get_q_value(states_joint, actions_joint, use_target=True)
			# 	q_targets = [self.compute_gae(q_value[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_value[:-1])[0] for q_value,reward,done in zip(q_values, rewards, dones)]
				
			# 	to_stack = lambda items: list(zip(*[x.view(-1, *x.shape[2:]).cpu().numpy() for x in items]))
			# 	states, actions, states_joint, actions_joint = map(lambda items: [x[:-1] for x in items], [states, actions, [states_joint], [actions_joint]])
			# 	states, actions, states_joint, actions_joint, q_targets = map(to_stack, [states, actions, states_joint, actions_joint, q_targets])
			# 	self.replay_buffer.extend(list(zip(states, actions, states_joint, actions_joint, q_targets)), shuffle=False)	
			# if len(self.replay_buffer) > REPLAY_BATCH_SIZE:
			# 	states, actions, states_joint, actions_joint, q_targets = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
			# 	self.network.optimize(states, actions, states_joint[0], actions_joint[0], q_targets)
			# if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)
		"""

class MADDPG():
	def __init__(self, state_size, action_size, gamma=0.95, tau=0.01, lr=0.01):
		self.tau = tau
		self.gamma = gamma
		self.nagents = len(state_size)
		num_in_critic = np.sum([np.prod(s) for s in state_size]) + np.sum([np.prod(a) for a in action_size])
		self.agents = [DDPGAgent(s_size[-1], a_size[-1], num_in_critic) for s_size, a_size in zip(state_size, action_size)]

	def step(self, states):
		return [gumbel_softmax(a.policy(obs), hard=True) for a, obs in zip(self.agents, states)]

	@property
	def policies(self):
		return [a.policy for a in self.agents]

	@property
	def target_policies(self):
		return [a.target_policy for a in self.agents]

	def update(self, sample, agent_i, parallel=False, logger=None):
		states, actions, next_states, rewards, dones = sample
		curr_agent = self.agents[agent_i]

		all_trgt_acs = [one_hot(pi(nobs)) for pi, nobs in zip(self.target_policies, next_states)]
		trgt_vf_in = torch.cat((*next_states, *all_trgt_acs), dim=1)
		target_value = (rewards[agent_i].view(-1, 1) + self.gamma * curr_agent.target_critic(trgt_vf_in) * (1 - dones[agent_i].view(-1, 1)))

		critic_inputs = torch.cat((*states, *actions), dim=1)
		actual_value = curr_agent.critic(critic_inputs)
		vf_loss = (actual_value - target_value.detach()).pow(2).mean()
		curr_agent.step(curr_agent.critic_optimizer, vf_loss, param_norm=curr_agent.critic.parameters())
		curr_agent.soft_copy(curr_agent.critic, curr_agent.target_critic)

		# curr_agent.critic_optimizer.zero_grad()
		# vf_loss.backward()
		# torch.nn.utils.clip_grad_norm_(curr_agent.critic.parameters(), 0.5)
		# curr_agent.critic_optimizer.step()

		curr_pol_out = curr_agent.policy(states[agent_i])
		curr_pol_vf_in = gumbel_softmax(curr_pol_out, hard=True)
		all_pol_acs = [curr_pol_vf_in if i==agent_i else one_hot(pi(ob)) for i, pi, ob in zip(range(self.nagents), self.policies, states)]
		critic_inputs = torch.cat((*states, *all_pol_acs), dim=1)
		pol_loss = -curr_agent.critic(critic_inputs).mean() + 0.001*(curr_pol_out**2).mean() 
		curr_agent.step(curr_agent.policy_optimizer, pol_loss, param_norm=curr_agent.policy.parameters())
		curr_agent.soft_copy(curr_agent.policy, curr_agent.target_policy)

		# curr_agent.policy_optimizer.zero_grad()
		# pol_loss.backward()
		# torch.nn.utils.clip_grad_norm_(curr_agent.policy.parameters(), 0.5)
		# curr_agent.policy_optimizer.step()

	# def update_all_targets(self):
	# 	for a in self.agents:
	# 		a.soft_copy(a.critic, a.target_critic)
	# 		a.soft_copy(a.policy, a.target_policy)
			# for target_param, param in zip(a.target_critic.parameters(), a.critic.parameters()):
			# 	target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)
			# for target_param, param in zip(a.target_policy.parameters(), a.policy.parameters()):
			# 	target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)
		# self.niter += 1

	# def prep_training(self, device='gpu'):
	# 	for a in self.agents:
	# 		a.policy.train()
	# 		a.critic.train()
	# 		a.target_policy.train()
	# 		a.target_critic.train()

	# def prep_rollouts(self, device='cpu'):
	# 	for a in self.agents:
	# 		a.policy.eval()

class DDPGAgent(object):
	def __init__(self, num_in_pol, num_out_pol, num_in_critic, hidden_dim=64, lr=0.01, tau=0.01):
		self.policy = MLPNetwork(num_in_pol, num_out_pol, hidden_dim=hidden_dim)
		self.target_policy = MLPNetwork(num_in_pol, num_out_pol, hidden_dim=hidden_dim)
		self.policy_optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr)
		
		self.critic = MLPNetwork(num_in_critic, 1, hidden_dim=hidden_dim)
		self.target_critic = MLPNetwork(num_in_critic, 1, hidden_dim=hidden_dim)
		self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr)
		
		self.tau = tau
		# for target_param, param in zip(self.target_policy.parameters(), self.policy.parameters()):
		# 	target_param.data.copy_(param.data)
		# for target_param, param in zip(self.target_critic.parameters(), self.critic.parameters()):
		# 	target_param.data.copy_(param.data)

	def soft_copy(self, local, target):
		for t,l in zip(target.parameters(), local.parameters()):
			t.data.copy_(t.data + self.tau*(l.data - t.data))

	def step(self, optimizer, loss, retain=False, param_norm=None):
		optimizer.zero_grad()
		loss.backward(retain_graph=retain)
		if param_norm is not None: torch.nn.utils.clip_grad_norm_(param_norm, 0.5)
		optimizer.step()

	# def step(self, obs, explore=False):
	# 	action = self.policy(obs)
	# 	if explore:
	# 		action = gumbel_softmax(action, hard=True)
	# 	else:
	# 		action = one_hot(action)
	# 	return action

class MLPNetwork(torch.nn.Module):
	def __init__(self, input_dim, out_dim, hidden_dim=64):
		super().__init__()

		# if norm_in:  # normalize inputs
		# 	self.in_fn = nn.BatchNorm1d(input_dim)
		# 	self.in_fn.weight.data.fill_(1)
		# 	self.in_fn.bias.data.fill_(0)
		# else:
		# 	self.in_fn = lambda x: x
		self.fc1 = torch.nn.Linear(input_dim, hidden_dim)
		self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)
		self.fc3 = torch.nn.Linear(hidden_dim, out_dim)
		# self.nonlin = nonlin
		# if constrain_out and not discrete_action:
		# 	self.fc3.weight.data.uniform_(-3e-3, 3e-3)
		# 	self.out_fn = torch.tanh
		# 	raise EnvironmentError()
		# else:  # logits for discrete action (will softmax later)
		# 	self.out_fn = lambda x: x

	def forward(self, X):
		h1 = self.fc1(X).relu()
		h2 = self.fc2(h1).relu()
		action = self.fc3(h2)
		return action
REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.900             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)
# np.random.seed(1)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return gym.make(env_name)
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":0} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env)

def run(model, steps=10000, ports=16, env_name=env_name, eval_at=1000, checkpoint=False, save_best=False, log=True, render=True):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports, render=False, env_name=env_name)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, num_envs=num_envs, gpu=False, agent2=RandomAgent) 
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if np.any(dones[0]):
			rollouts = [rollout(envs.env, agent.reset(1), render=render) for _ in range(1)]
			test_reward = np.mean(rollouts, axis=0) - np.std(rollouts, axis=0)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if save_best and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts, axis=0)} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")
			agent.reset(num_envs)

def trial(model):
	envs = EnsembleEnv(make_env, 0, log=True, render=True)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, load=f"{env_name}")
	print(f"Reward: {rollout(envs.env, agent, eps=0.02, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[1], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="maddpg", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--test", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.test:
		trial(model)
	elif args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		run(model, args.steps, args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)

Step: 49, Reward: [-597.582 -597.582 -597.582] [0.0000], Avg: [-597.582 -597.582 -597.582] (1.000)
Step: 99, Reward: [-395.051 -395.051 -395.051] [0.0000], Avg: [-496.317 -496.317 -496.317] (1.000)
Step: 149, Reward: [-382.595 -382.595 -382.595] [0.0000], Avg: [-458.41 -458.41 -458.41] (1.000)
Step: 199, Reward: [-479.834 -479.834 -479.834] [0.0000], Avg: [-463.766 -463.766 -463.766] (1.000)
Step: 249, Reward: [-462.174 -462.174 -462.174] [0.0000], Avg: [-463.447 -463.447 -463.447] (1.000)
Step: 299, Reward: [-524.483 -524.483 -524.483] [0.0000], Avg: [-473.62 -473.62 -473.62] (1.000)
Step: 349, Reward: [-551.637 -551.637 -551.637] [0.0000], Avg: [-484.765 -484.765 -484.765] (1.000)
Step: 399, Reward: [-315.829 -315.829 -315.829] [0.0000], Avg: [-463.648 -463.648 -463.648] (1.000)
Step: 449, Reward: [-411.526 -411.526 -411.526] [0.0000], Avg: [-457.857 -457.857 -457.857] (1.000)
Step: 499, Reward: [-399.455 -399.455 -399.455] [0.0000], Avg: [-452.017 -452.017 -452.017] (1.000)
Step: 549, Reward: [-538.086 -538.086 -538.086] [0.0000], Avg: [-459.841 -459.841 -459.841] (1.000)
Step: 599, Reward: [-384.3 -384.3 -384.3] [0.0000], Avg: [-453.546 -453.546 -453.546] (1.000)
Step: 649, Reward: [-426.644 -426.644 -426.644] [0.0000], Avg: [-451.477 -451.477 -451.477] (1.000)
Step: 699, Reward: [-515.555 -515.555 -515.555] [0.0000], Avg: [-456.054 -456.054 -456.054] (1.000)
Step: 749, Reward: [-436.328 -436.328 -436.328] [0.0000], Avg: [-454.739 -454.739 -454.739] (1.000)
Step: 799, Reward: [-417.929 -417.929 -417.929] [0.0000], Avg: [-452.438 -452.438 -452.438] (1.000)
Step: 849, Reward: [-679.164 -679.164 -679.164] [0.0000], Avg: [-465.775 -465.775 -465.775] (1.000)
Step: 899, Reward: [-588.397 -588.397 -588.397] [0.0000], Avg: [-472.587 -472.587 -472.587] (1.000)
Step: 949, Reward: [-515.757 -515.757 -515.757] [0.0000], Avg: [-474.859 -474.859 -474.859] (1.000)
Step: 999, Reward: [-422.855 -422.855 -422.855] [0.0000], Avg: [-472.259 -472.259 -472.259] (1.000)
Step: 1049, Reward: [-370.683 -370.683 -370.683] [0.0000], Avg: [-467.422 -467.422 -467.422] (1.000)
Step: 1099, Reward: [-509.196 -509.196 -509.196] [0.0000], Avg: [-469.321 -469.321 -469.321] (1.000)
Step: 1149, Reward: [-442.051 -442.051 -442.051] [0.0000], Avg: [-468.135 -468.135 -468.135] (1.000)
Step: 1199, Reward: [-703.349 -703.349 -703.349] [0.0000], Avg: [-477.936 -477.936 -477.936] (1.000)
Step: 1249, Reward: [-406.332 -406.332 -406.332] [0.0000], Avg: [-475.072 -475.072 -475.072] (1.000)
Step: 1299, Reward: [-747.877 -747.877 -747.877] [0.0000], Avg: [-485.564 -485.564 -485.564] (1.000)
Step: 1349, Reward: [-427.77 -427.77 -427.77] [0.0000], Avg: [-483.424 -483.424 -483.424] (1.000)
Step: 1399, Reward: [-614.562 -614.562 -614.562] [0.0000], Avg: [-488.107 -488.107 -488.107] (1.000)
Step: 1449, Reward: [-490.194 -490.194 -490.194] [0.0000], Avg: [-488.179 -488.179 -488.179] (1.000)
Step: 1499, Reward: [-578.415 -578.415 -578.415] [0.0000], Avg: [-491.187 -491.187 -491.187] (1.000)
Step: 1549, Reward: [-747.652 -747.652 -747.652] [0.0000], Avg: [-499.46 -499.46 -499.46] (1.000)
Step: 1599, Reward: [-462.289 -462.289 -462.289] [0.0000], Avg: [-498.298 -498.298 -498.298] (1.000)
Step: 1649, Reward: [-494.872 -494.872 -494.872] [0.0000], Avg: [-498.195 -498.195 -498.195] (1.000)
Step: 1699, Reward: [-879.11 -879.11 -879.11] [0.0000], Avg: [-509.398 -509.398 -509.398] (1.000)
Step: 1749, Reward: [-1689.777 -1689.777 -1689.777] [0.0000], Avg: [-543.123 -543.123 -543.123] (1.000)
Step: 1799, Reward: [-719.16 -719.16 -719.16] [0.0000], Avg: [-548.013 -548.013 -548.013] (1.000)
Step: 1849, Reward: [-917.264 -917.264 -917.264] [0.0000], Avg: [-557.993 -557.993 -557.993] (1.000)
Step: 1899, Reward: [-1556.98 -1556.98 -1556.98] [0.0000], Avg: [-584.282 -584.282 -584.282] (1.000)
Step: 1949, Reward: [-704.201 -704.201 -704.201] [0.0000], Avg: [-587.357 -587.357 -587.357] (1.000)
Step: 1999, Reward: [-688.667 -688.667 -688.667] [0.0000], Avg: [-589.89 -589.89 -589.89] (1.000)
Step: 2049, Reward: [-523.704 -523.704 -523.704] [0.0000], Avg: [-588.275 -588.275 -588.275] (1.000)
Step: 2099, Reward: [-536.722 -536.722 -536.722] [0.0000], Avg: [-587.048 -587.048 -587.048] (1.000)
Step: 2149, Reward: [-623.635 -623.635 -623.635] [0.0000], Avg: [-587.899 -587.899 -587.899] (1.000)
Step: 2199, Reward: [-545.339 -545.339 -545.339] [0.0000], Avg: [-586.931 -586.931 -586.931] (1.000)
Step: 2249, Reward: [-649.597 -649.597 -649.597] [0.0000], Avg: [-588.324 -588.324 -588.324] (1.000)
Step: 2299, Reward: [-469.193 -469.193 -469.193] [0.0000], Avg: [-585.734 -585.734 -585.734] (1.000)
Step: 2349, Reward: [-412.799 -412.799 -412.799] [0.0000], Avg: [-582.055 -582.055 -582.055] (1.000)
Step: 2399, Reward: [-710.992 -710.992 -710.992] [0.0000], Avg: [-584.741 -584.741 -584.741] (1.000)
Step: 2449, Reward: [-635.532 -635.532 -635.532] [0.0000], Avg: [-585.777 -585.777 -585.777] (1.000)
Step: 2499, Reward: [-581.216 -581.216 -581.216] [0.0000], Avg: [-585.686 -585.686 -585.686] (1.000)
Step: 2549, Reward: [-403.049 -403.049 -403.049] [0.0000], Avg: [-582.105 -582.105 -582.105] (1.000)
Step: 2599, Reward: [-775.555 -775.555 -775.555] [0.0000], Avg: [-585.825 -585.825 -585.825] (1.000)
Step: 2649, Reward: [-783.112 -783.112 -783.112] [0.0000], Avg: [-589.548 -589.548 -589.548] (1.000)
Step: 2699, Reward: [-605.496 -605.496 -605.496] [0.0000], Avg: [-589.843 -589.843 -589.843] (1.000)
Step: 2749, Reward: [-692.901 -692.901 -692.901] [0.0000], Avg: [-591.717 -591.717 -591.717] (1.000)
Step: 2799, Reward: [-629.781 -629.781 -629.781] [0.0000], Avg: [-592.397 -592.397 -592.397] (1.000)
Step: 2849, Reward: [-768.949 -768.949 -768.949] [0.0000], Avg: [-595.494 -595.494 -595.494] (1.000)
Step: 2899, Reward: [-900.695 -900.695 -900.695] [0.0000], Avg: [-600.756 -600.756 -600.756] (1.000)
Step: 2949, Reward: [-1053.033 -1053.033 -1053.033] [0.0000], Avg: [-608.422 -608.422 -608.422] (1.000)
Step: 2999, Reward: [-906.638 -906.638 -906.638] [0.0000], Avg: [-613.392 -613.392 -613.392] (1.000)
Step: 3049, Reward: [-1297.982 -1297.982 -1297.982] [0.0000], Avg: [-624.615 -624.615 -624.615] (1.000)
Step: 3099, Reward: [-1448.888 -1448.888 -1448.888] [0.0000], Avg: [-637.91 -637.91 -637.91] (1.000)
Step: 3149, Reward: [-881.301 -881.301 -881.301] [0.0000], Avg: [-641.773 -641.773 -641.773] (1.000)
Step: 3199, Reward: [-781.177 -781.177 -781.177] [0.0000], Avg: [-643.951 -643.951 -643.951] (1.000)
Step: 3249, Reward: [-1116.129 -1116.129 -1116.129] [0.0000], Avg: [-651.215 -651.215 -651.215] (1.000)
Step: 3299, Reward: [-1063.491 -1063.491 -1063.491] [0.0000], Avg: [-657.462 -657.462 -657.462] (1.000)
Step: 3349, Reward: [-922.57 -922.57 -922.57] [0.0000], Avg: [-661.419 -661.419 -661.419] (1.000)
Step: 3399, Reward: [-1097.782 -1097.782 -1097.782] [0.0000], Avg: [-667.836 -667.836 -667.836] (1.000)
Step: 3449, Reward: [-1196.493 -1196.493 -1196.493] [0.0000], Avg: [-675.498 -675.498 -675.498] (1.000)
Step: 3499, Reward: [-671.281 -671.281 -671.281] [0.0000], Avg: [-675.437 -675.437 -675.437] (1.000)
Step: 3549, Reward: [-1057.688 -1057.688 -1057.688] [0.0000], Avg: [-680.821 -680.821 -680.821] (1.000)
Step: 3599, Reward: [-1401.918 -1401.918 -1401.918] [0.0000], Avg: [-690.836 -690.836 -690.836] (1.000)
Step: 3649, Reward: [-1041.014 -1041.014 -1041.014] [0.0000], Avg: [-695.633 -695.633 -695.633] (1.000)
Step: 3699, Reward: [-774.686 -774.686 -774.686] [0.0000], Avg: [-696.702 -696.702 -696.702] (1.000)
Step: 3749, Reward: [-1068.25 -1068.25 -1068.25] [0.0000], Avg: [-701.656 -701.656 -701.656] (1.000)
Step: 3799, Reward: [-841.193 -841.193 -841.193] [0.0000], Avg: [-703.492 -703.492 -703.492] (1.000)
Step: 3849, Reward: [-931.594 -931.594 -931.594] [0.0000], Avg: [-706.454 -706.454 -706.454] (1.000)
Step: 3899, Reward: [-565.22 -565.22 -565.22] [0.0000], Avg: [-704.643 -704.643 -704.643] (1.000)
Step: 3949, Reward: [-915.462 -915.462 -915.462] [0.0000], Avg: [-707.312 -707.312 -707.312] (1.000)
Step: 3999, Reward: [-756.766 -756.766 -756.766] [0.0000], Avg: [-707.93 -707.93 -707.93] (1.000)
Step: 4049, Reward: [-805.154 -805.154 -805.154] [0.0000], Avg: [-709.13 -709.13 -709.13] (1.000)
Step: 4099, Reward: [-848.273 -848.273 -848.273] [0.0000], Avg: [-710.827 -710.827 -710.827] (1.000)
Step: 4149, Reward: [-849.002 -849.002 -849.002] [0.0000], Avg: [-712.492 -712.492 -712.492] (1.000)
Step: 4199, Reward: [-880.094 -880.094 -880.094] [0.0000], Avg: [-714.487 -714.487 -714.487] (1.000)
Step: 4249, Reward: [-1010.636 -1010.636 -1010.636] [0.0000], Avg: [-717.971 -717.971 -717.971] (1.000)
Step: 4299, Reward: [-973.549 -973.549 -973.549] [0.0000], Avg: [-720.943 -720.943 -720.943] (1.000)
Step: 4349, Reward: [-632.919 -632.919 -632.919] [0.0000], Avg: [-719.931 -719.931 -719.931] (1.000)
Step: 4399, Reward: [-1010.352 -1010.352 -1010.352] [0.0000], Avg: [-723.232 -723.232 -723.232] (1.000)
Step: 4449, Reward: [-1077.691 -1077.691 -1077.691] [0.0000], Avg: [-727.214 -727.214 -727.214] (1.000)
Step: 4499, Reward: [-767.369 -767.369 -767.369] [0.0000], Avg: [-727.661 -727.661 -727.661] (1.000)
Step: 4549, Reward: [-880.461 -880.461 -880.461] [0.0000], Avg: [-729.34 -729.34 -729.34] (1.000)
Step: 4599, Reward: [-792.338 -792.338 -792.338] [0.0000], Avg: [-730.024 -730.024 -730.024] (1.000)
Step: 4649, Reward: [-771.489 -771.489 -771.489] [0.0000], Avg: [-730.47 -730.47 -730.47] (1.000)
Step: 4699, Reward: [-622.187 -622.187 -622.187] [0.0000], Avg: [-729.318 -729.318 -729.318] (1.000)
Step: 4749, Reward: [-507.096 -507.096 -507.096] [0.0000], Avg: [-726.979 -726.979 -726.979] (1.000)
Step: 4799, Reward: [-680.788 -680.788 -680.788] [0.0000], Avg: [-726.498 -726.498 -726.498] (1.000)
Step: 4849, Reward: [-588.216 -588.216 -588.216] [0.0000], Avg: [-725.072 -725.072 -725.072] (1.000)
Step: 4899, Reward: [-924.605 -924.605 -924.605] [0.0000], Avg: [-727.108 -727.108 -727.108] (1.000)
Step: 4949, Reward: [-534.356 -534.356 -534.356] [0.0000], Avg: [-725.161 -725.161 -725.161] (1.000)
Step: 4999, Reward: [-778.643 -778.643 -778.643] [0.0000], Avg: [-725.696 -725.696 -725.696] (1.000)
Step: 5049, Reward: [-552.782 -552.782 -552.782] [0.0000], Avg: [-723.984 -723.984 -723.984] (1.000)
Step: 5099, Reward: [-592.507 -592.507 -592.507] [0.0000], Avg: [-722.695 -722.695 -722.695] (1.000)
Step: 5149, Reward: [-1096.079 -1096.079 -1096.079] [0.0000], Avg: [-726.32 -726.32 -726.32] (1.000)
Step: 5199, Reward: [-498.405 -498.405 -498.405] [0.0000], Avg: [-724.129 -724.129 -724.129] (1.000)
Step: 5249, Reward: [-862.528 -862.528 -862.528] [0.0000], Avg: [-725.447 -725.447 -725.447] (1.000)
Step: 5299, Reward: [-557.959 -557.959 -557.959] [0.0000], Avg: [-723.867 -723.867 -723.867] (1.000)
Step: 5349, Reward: [-793.698 -793.698 -793.698] [0.0000], Avg: [-724.519 -724.519 -724.519] (1.000)
Step: 5399, Reward: [-906.513 -906.513 -906.513] [0.0000], Avg: [-726.205 -726.205 -726.205] (1.000)
Step: 5449, Reward: [-582.788 -582.788 -582.788] [0.0000], Avg: [-724.889 -724.889 -724.889] (1.000)
Step: 5499, Reward: [-747.016 -747.016 -747.016] [0.0000], Avg: [-725.09 -725.09 -725.09] (1.000)
Step: 5549, Reward: [-797.196 -797.196 -797.196] [0.0000], Avg: [-725.74 -725.74 -725.74] (1.000)
Step: 5599, Reward: [-730.027 -730.027 -730.027] [0.0000], Avg: [-725.778 -725.778 -725.778] (1.000)
Step: 5649, Reward: [-972.852 -972.852 -972.852] [0.0000], Avg: [-727.964 -727.964 -727.964] (1.000)
Step: 5699, Reward: [-821.416 -821.416 -821.416] [0.0000], Avg: [-728.784 -728.784 -728.784] (1.000)
Step: 5749, Reward: [-466.466 -466.466 -466.466] [0.0000], Avg: [-726.503 -726.503 -726.503] (1.000)
Step: 5799, Reward: [-892.687 -892.687 -892.687] [0.0000], Avg: [-727.936 -727.936 -727.936] (1.000)
Step: 5849, Reward: [-518.514 -518.514 -518.514] [0.0000], Avg: [-726.146 -726.146 -726.146] (1.000)
Step: 5899, Reward: [-646.616 -646.616 -646.616] [0.0000], Avg: [-725.472 -725.472 -725.472] (1.000)
Step: 5949, Reward: [-560.527 -560.527 -560.527] [0.0000], Avg: [-724.086 -724.086 -724.086] (1.000)
Step: 5999, Reward: [-592.242 -592.242 -592.242] [0.0000], Avg: [-722.987 -722.987 -722.987] (1.000)
Step: 6049, Reward: [-576.109 -576.109 -576.109] [0.0000], Avg: [-721.773 -721.773 -721.773] (1.000)
Step: 6099, Reward: [-606.171 -606.171 -606.171] [0.0000], Avg: [-720.826 -720.826 -720.826] (1.000)
Step: 6149, Reward: [-778.01 -778.01 -778.01] [0.0000], Avg: [-721.291 -721.291 -721.291] (1.000)
Step: 6199, Reward: [-368.217 -368.217 -368.217] [0.0000], Avg: [-718.443 -718.443 -718.443] (1.000)
Step: 6249, Reward: [-750.876 -750.876 -750.876] [0.0000], Avg: [-718.703 -718.703 -718.703] (1.000)
Step: 6299, Reward: [-747.488 -747.488 -747.488] [0.0000], Avg: [-718.931 -718.931 -718.931] (1.000)
Step: 6349, Reward: [-506.514 -506.514 -506.514] [0.0000], Avg: [-717.258 -717.258 -717.258] (1.000)
Step: 6399, Reward: [-712.352 -712.352 -712.352] [0.0000], Avg: [-717.22 -717.22 -717.22] (1.000)
Step: 6449, Reward: [-826.353 -826.353 -826.353] [0.0000], Avg: [-718.066 -718.066 -718.066] (1.000)
Step: 6499, Reward: [-728.938 -728.938 -728.938] [0.0000], Avg: [-718.15 -718.15 -718.15] (1.000)
Step: 6549, Reward: [-627.206 -627.206 -627.206] [0.0000], Avg: [-717.456 -717.456 -717.456] (1.000)
Step: 6599, Reward: [-673.631 -673.631 -673.631] [0.0000], Avg: [-717.124 -717.124 -717.124] (1.000)
Step: 6649, Reward: [-669.604 -669.604 -669.604] [0.0000], Avg: [-716.766 -716.766 -716.766] (1.000)
Step: 6699, Reward: [-656.083 -656.083 -656.083] [0.0000], Avg: [-716.313 -716.313 -716.313] (1.000)
Step: 6749, Reward: [-907.208 -907.208 -907.208] [0.0000], Avg: [-717.727 -717.727 -717.727] (1.000)
Step: 6799, Reward: [-714.215 -714.215 -714.215] [0.0000], Avg: [-717.702 -717.702 -717.702] (1.000)
Step: 6849, Reward: [-955.412 -955.412 -955.412] [0.0000], Avg: [-719.437 -719.437 -719.437] (1.000)
Step: 6899, Reward: [-1007.12 -1007.12 -1007.12] [0.0000], Avg: [-721.521 -721.521 -721.521] (1.000)
Step: 6949, Reward: [-1022.262 -1022.262 -1022.262] [0.0000], Avg: [-723.685 -723.685 -723.685] (1.000)
Step: 6999, Reward: [-505.915 -505.915 -505.915] [0.0000], Avg: [-722.129 -722.129 -722.129] (1.000)
Step: 7049, Reward: [-419.929 -419.929 -419.929] [0.0000], Avg: [-719.986 -719.986 -719.986] (1.000)
Step: 7099, Reward: [-550.797 -550.797 -550.797] [0.0000], Avg: [-718.795 -718.795 -718.795] (1.000)
Step: 7149, Reward: [-817.183 -817.183 -817.183] [0.0000], Avg: [-719.483 -719.483 -719.483] (1.000)
Step: 7199, Reward: [-452.622 -452.622 -452.622] [0.0000], Avg: [-717.63 -717.63 -717.63] (1.000)
Step: 7249, Reward: [-345.188 -345.188 -345.188] [0.0000], Avg: [-715.061 -715.061 -715.061] (1.000)
Step: 7299, Reward: [-755.84 -755.84 -755.84] [0.0000], Avg: [-715.34 -715.34 -715.34] (1.000)
Step: 7349, Reward: [-430.483 -430.483 -430.483] [0.0000], Avg: [-713.402 -713.402 -713.402] (1.000)
Step: 7399, Reward: [-553.612 -553.612 -553.612] [0.0000], Avg: [-712.323 -712.323 -712.323] (1.000)
Step: 7449, Reward: [-418.411 -418.411 -418.411] [0.0000], Avg: [-710.35 -710.35 -710.35] (1.000)
Step: 7499, Reward: [-622.085 -622.085 -622.085] [0.0000], Avg: [-709.762 -709.762 -709.762] (1.000)
Step: 7549, Reward: [-393.376 -393.376 -393.376] [0.0000], Avg: [-707.667 -707.667 -707.667] (1.000)
Step: 7599, Reward: [-650.153 -650.153 -650.153] [0.0000], Avg: [-707.288 -707.288 -707.288] (1.000)
Step: 7649, Reward: [-474.094 -474.094 -474.094] [0.0000], Avg: [-705.764 -705.764 -705.764] (1.000)
Step: 7699, Reward: [-632.969 -632.969 -632.969] [0.0000], Avg: [-705.291 -705.291 -705.291] (1.000)
Step: 7749, Reward: [-542.296 -542.296 -542.296] [0.0000], Avg: [-704.24 -704.24 -704.24] (1.000)
Step: 7799, Reward: [-508.062 -508.062 -508.062] [0.0000], Avg: [-702.982 -702.982 -702.982] (1.000)
Step: 7849, Reward: [-398.377 -398.377 -398.377] [0.0000], Avg: [-701.042 -701.042 -701.042] (1.000)
Step: 7899, Reward: [-496.842 -496.842 -496.842] [0.0000], Avg: [-699.75 -699.75 -699.75] (1.000)
Step: 7949, Reward: [-439.64 -439.64 -439.64] [0.0000], Avg: [-698.114 -698.114 -698.114] (1.000)
Step: 7999, Reward: [-467.073 -467.073 -467.073] [0.0000], Avg: [-696.67 -696.67 -696.67] (1.000)
Step: 8049, Reward: [-409.528 -409.528 -409.528] [0.0000], Avg: [-694.886 -694.886 -694.886] (1.000)
Step: 8099, Reward: [-645.117 -645.117 -645.117] [0.0000], Avg: [-694.579 -694.579 -694.579] (1.000)
Step: 8149, Reward: [-459.604 -459.604 -459.604] [0.0000], Avg: [-693.137 -693.137 -693.137] (1.000)
Step: 8199, Reward: [-515.05 -515.05 -515.05] [0.0000], Avg: [-692.052 -692.052 -692.052] (1.000)
Step: 8249, Reward: [-473.77 -473.77 -473.77] [0.0000], Avg: [-690.729 -690.729 -690.729] (1.000)
Step: 8299, Reward: [-482.799 -482.799 -482.799] [0.0000], Avg: [-689.476 -689.476 -689.476] (1.000)
Step: 8349, Reward: [-416.482 -416.482 -416.482] [0.0000], Avg: [-687.841 -687.841 -687.841] (1.000)
Step: 8399, Reward: [-563.941 -563.941 -563.941] [0.0000], Avg: [-687.104 -687.104 -687.104] (1.000)
Step: 8449, Reward: [-439.748 -439.748 -439.748] [0.0000], Avg: [-685.64 -685.64 -685.64] (1.000)
Step: 8499, Reward: [-402.64 -402.64 -402.64] [0.0000], Avg: [-683.975 -683.975 -683.975] (1.000)
Step: 8549, Reward: [-630.112 -630.112 -630.112] [0.0000], Avg: [-683.661 -683.661 -683.661] (1.000)
Step: 8599, Reward: [-699.751 -699.751 -699.751] [0.0000], Avg: [-683.754 -683.754 -683.754] (1.000)
Step: 8649, Reward: [-554.425 -554.425 -554.425] [0.0000], Avg: [-683.006 -683.006 -683.006] (1.000)
Step: 8699, Reward: [-566.677 -566.677 -566.677] [0.0000], Avg: [-682.338 -682.338 -682.338] (1.000)
Step: 8749, Reward: [-365.044 -365.044 -365.044] [0.0000], Avg: [-680.525 -680.525 -680.525] (1.000)
Step: 8799, Reward: [-553.029 -553.029 -553.029] [0.0000], Avg: [-679.8 -679.8 -679.8] (1.000)
Step: 8849, Reward: [-542.525 -542.525 -542.525] [0.0000], Avg: [-679.025 -679.025 -679.025] (1.000)
Step: 8899, Reward: [-466.742 -466.742 -466.742] [0.0000], Avg: [-677.832 -677.832 -677.832] (1.000)
Step: 8949, Reward: [-584.312 -584.312 -584.312] [0.0000], Avg: [-677.31 -677.31 -677.31] (1.000)
Step: 8999, Reward: [-503.87 -503.87 -503.87] [0.0000], Avg: [-676.346 -676.346 -676.346] (1.000)
Step: 9049, Reward: [-554.302 -554.302 -554.302] [0.0000], Avg: [-675.672 -675.672 -675.672] (1.000)
Step: 9099, Reward: [-405.86 -405.86 -405.86] [0.0000], Avg: [-674.189 -674.189 -674.189] (1.000)
Step: 9149, Reward: [-425.089 -425.089 -425.089] [0.0000], Avg: [-672.828 -672.828 -672.828] (1.000)
Step: 9199, Reward: [-556.399 -556.399 -556.399] [0.0000], Avg: [-672.195 -672.195 -672.195] (1.000)
Step: 9249, Reward: [-493.181 -493.181 -493.181] [0.0000], Avg: [-671.228 -671.228 -671.228] (1.000)
Step: 9299, Reward: [-460.603 -460.603 -460.603] [0.0000], Avg: [-670.095 -670.095 -670.095] (1.000)
Step: 9349, Reward: [-559.571 -559.571 -559.571] [0.0000], Avg: [-669.504 -669.504 -669.504] (1.000)
Step: 9399, Reward: [-496.398 -496.398 -496.398] [0.0000], Avg: [-668.584 -668.584 -668.584] (1.000)
Step: 9449, Reward: [-1091.607 -1091.607 -1091.607] [0.0000], Avg: [-670.822 -670.822 -670.822] (1.000)
Step: 9499, Reward: [-680.522 -680.522 -680.522] [0.0000], Avg: [-670.873 -670.873 -670.873] (1.000)
Step: 9549, Reward: [-821.27 -821.27 -821.27] [0.0000], Avg: [-671.66 -671.66 -671.66] (1.000)
Step: 9599, Reward: [-541.89 -541.89 -541.89] [0.0000], Avg: [-670.984 -670.984 -670.984] (1.000)
Step: 9649, Reward: [-580.956 -580.956 -580.956] [0.0000], Avg: [-670.518 -670.518 -670.518] (1.000)
Step: 9699, Reward: [-472.07 -472.07 -472.07] [0.0000], Avg: [-669.495 -669.495 -669.495] (1.000)
Step: 9749, Reward: [-480.443 -480.443 -480.443] [0.0000], Avg: [-668.526 -668.526 -668.526] (1.000)
Step: 9799, Reward: [-744.27 -744.27 -744.27] [0.0000], Avg: [-668.912 -668.912 -668.912] (1.000)
Step: 9849, Reward: [-467.286 -467.286 -467.286] [0.0000], Avg: [-667.889 -667.889 -667.889] (1.000)
Step: 9899, Reward: [-844.399 -844.399 -844.399] [0.0000], Avg: [-668.78 -668.78 -668.78] (1.000)
Step: 9949, Reward: [-1684.227 -1684.227 -1684.227] [0.0000], Avg: [-673.883 -673.883 -673.883] (1.000)
Step: 9999, Reward: [-655.473 -655.473 -655.473] [0.0000], Avg: [-673.791 -673.791 -673.791] (1.000)
Step: 10049, Reward: [-519.963 -519.963 -519.963] [0.0000], Avg: [-673.025 -673.025 -673.025] (1.000)
Step: 10099, Reward: [-766.515 -766.515 -766.515] [0.0000], Avg: [-673.488 -673.488 -673.488] (1.000)
Step: 10149, Reward: [-488.462 -488.462 -488.462] [0.0000], Avg: [-672.577 -672.577 -672.577] (1.000)
Step: 10199, Reward: [-453.549 -453.549 -453.549] [0.0000], Avg: [-671.503 -671.503 -671.503] (1.000)
Step: 10249, Reward: [-380.946 -380.946 -380.946] [0.0000], Avg: [-670.086 -670.086 -670.086] (1.000)
Step: 10299, Reward: [-840.009 -840.009 -840.009] [0.0000], Avg: [-670.911 -670.911 -670.911] (1.000)
Step: 10349, Reward: [-1701.171 -1701.171 -1701.171] [0.0000], Avg: [-675.888 -675.888 -675.888] (1.000)
Step: 10399, Reward: [-507.351 -507.351 -507.351] [0.0000], Avg: [-675.077 -675.077 -675.077] (1.000)
Step: 10449, Reward: [-1938.539 -1938.539 -1938.539] [0.0000], Avg: [-681.123 -681.123 -681.123] (1.000)
Step: 10499, Reward: [-751.739 -751.739 -751.739] [0.0000], Avg: [-681.459 -681.459 -681.459] (1.000)
Step: 10549, Reward: [-606.881 -606.881 -606.881] [0.0000], Avg: [-681.106 -681.106 -681.106] (1.000)
Step: 10599, Reward: [-615.111 -615.111 -615.111] [0.0000], Avg: [-680.794 -680.794 -680.794] (1.000)
Step: 10649, Reward: [-1761.185 -1761.185 -1761.185] [0.0000], Avg: [-685.866 -685.866 -685.866] (1.000)
Step: 10699, Reward: [-664.358 -664.358 -664.358] [0.0000], Avg: [-685.766 -685.766 -685.766] (1.000)
Step: 10749, Reward: [-580.419 -580.419 -580.419] [0.0000], Avg: [-685.276 -685.276 -685.276] (1.000)
Step: 10799, Reward: [-838.213 -838.213 -838.213] [0.0000], Avg: [-685.984 -685.984 -685.984] (1.000)
Step: 10849, Reward: [-467.238 -467.238 -467.238] [0.0000], Avg: [-684.976 -684.976 -684.976] (1.000)
Step: 10899, Reward: [-685.603 -685.603 -685.603] [0.0000], Avg: [-684.979 -684.979 -684.979] (1.000)
Step: 10949, Reward: [-1371.998 -1371.998 -1371.998] [0.0000], Avg: [-688.116 -688.116 -688.116] (1.000)
Step: 10999, Reward: [-630.943 -630.943 -630.943] [0.0000], Avg: [-687.856 -687.856 -687.856] (1.000)
Step: 11049, Reward: [-504.036 -504.036 -504.036] [0.0000], Avg: [-687.024 -687.024 -687.024] (1.000)
Step: 11099, Reward: [-635.875 -635.875 -635.875] [0.0000], Avg: [-686.794 -686.794 -686.794] (1.000)
Step: 11149, Reward: [-752.826 -752.826 -752.826] [0.0000], Avg: [-687.09 -687.09 -687.09] (1.000)
Step: 11199, Reward: [-1255.219 -1255.219 -1255.219] [0.0000], Avg: [-689.626 -689.626 -689.626] (1.000)
Step: 11249, Reward: [-1128.901 -1128.901 -1128.901] [0.0000], Avg: [-691.579 -691.579 -691.579] (1.000)
Step: 11299, Reward: [-571.397 -571.397 -571.397] [0.0000], Avg: [-691.047 -691.047 -691.047] (1.000)
Step: 11349, Reward: [-523.188 -523.188 -523.188] [0.0000], Avg: [-690.307 -690.307 -690.307] (1.000)
Step: 11399, Reward: [-1068.478 -1068.478 -1068.478] [0.0000], Avg: [-691.966 -691.966 -691.966] (1.000)
Step: 11449, Reward: [-775.069 -775.069 -775.069] [0.0000], Avg: [-692.329 -692.329 -692.329] (1.000)
Step: 11499, Reward: [-420.129 -420.129 -420.129] [0.0000], Avg: [-691.145 -691.145 -691.145] (1.000)
Step: 11549, Reward: [-460.199 -460.199 -460.199] [0.0000], Avg: [-690.146 -690.146 -690.146] (1.000)
Step: 11599, Reward: [-860.085 -860.085 -860.085] [0.0000], Avg: [-690.878 -690.878 -690.878] (1.000)
Step: 11649, Reward: [-722.816 -722.816 -722.816] [0.0000], Avg: [-691.015 -691.015 -691.015] (1.000)
Step: 11699, Reward: [-570.958 -570.958 -570.958] [0.0000], Avg: [-690.502 -690.502 -690.502] (1.000)
Step: 11749, Reward: [-505.278 -505.278 -505.278] [0.0000], Avg: [-689.714 -689.714 -689.714] (1.000)
Step: 11799, Reward: [-485.75 -485.75 -485.75] [0.0000], Avg: [-688.85 -688.85 -688.85] (1.000)
Step: 11849, Reward: [-541.919 -541.919 -541.919] [0.0000], Avg: [-688.23 -688.23 -688.23] (1.000)
Step: 11899, Reward: [-346.728 -346.728 -346.728] [0.0000], Avg: [-686.795 -686.795 -686.795] (1.000)
Step: 11949, Reward: [-584.151 -584.151 -584.151] [0.0000], Avg: [-686.365 -686.365 -686.365] (1.000)
Step: 11999, Reward: [-600.978 -600.978 -600.978] [0.0000], Avg: [-686.01 -686.01 -686.01] (1.000)
Step: 12049, Reward: [-399.698 -399.698 -399.698] [0.0000], Avg: [-684.822 -684.822 -684.822] (1.000)
Step: 12099, Reward: [-606.876 -606.876 -606.876] [0.0000], Avg: [-684.5 -684.5 -684.5] (1.000)
Step: 12149, Reward: [-493.318 -493.318 -493.318] [0.0000], Avg: [-683.713 -683.713 -683.713] (1.000)
Step: 12199, Reward: [-478.58 -478.58 -478.58] [0.0000], Avg: [-682.872 -682.872 -682.872] (1.000)
Step: 12249, Reward: [-501.881 -501.881 -501.881] [0.0000], Avg: [-682.133 -682.133 -682.133] (1.000)
Step: 12299, Reward: [-554.171 -554.171 -554.171] [0.0000], Avg: [-681.613 -681.613 -681.613] (1.000)
Step: 12349, Reward: [-406.755 -406.755 -406.755] [0.0000], Avg: [-680.5 -680.5 -680.5] (1.000)
Step: 12399, Reward: [-439.001 -439.001 -439.001] [0.0000], Avg: [-679.527 -679.527 -679.527] (1.000)
Step: 12449, Reward: [-408.515 -408.515 -408.515] [0.0000], Avg: [-678.438 -678.438 -678.438] (1.000)
Step: 12499, Reward: [-526.872 -526.872 -526.872] [0.0000], Avg: [-677.832 -677.832 -677.832] (1.000)
Step: 12549, Reward: [-740.244 -740.244 -740.244] [0.0000], Avg: [-678.081 -678.081 -678.081] (1.000)
Step: 12599, Reward: [-820.687 -820.687 -820.687] [0.0000], Avg: [-678.646 -678.646 -678.646] (1.000)
Step: 12649, Reward: [-453.437 -453.437 -453.437] [0.0000], Avg: [-677.756 -677.756 -677.756] (1.000)
Step: 12699, Reward: [-567.969 -567.969 -567.969] [0.0000], Avg: [-677.324 -677.324 -677.324] (1.000)
Step: 12749, Reward: [-411.34 -411.34 -411.34] [0.0000], Avg: [-676.281 -676.281 -676.281] (1.000)
Step: 12799, Reward: [-451.295 -451.295 -451.295] [0.0000], Avg: [-675.402 -675.402 -675.402] (1.000)
Step: 12849, Reward: [-340.996 -340.996 -340.996] [0.0000], Avg: [-674.101 -674.101 -674.101] (1.000)
Step: 12899, Reward: [-491.575 -491.575 -491.575] [0.0000], Avg: [-673.394 -673.394 -673.394] (1.000)
Step: 12949, Reward: [-515.961 -515.961 -515.961] [0.0000], Avg: [-672.786 -672.786 -672.786] (1.000)
Step: 12999, Reward: [-496.218 -496.218 -496.218] [0.0000], Avg: [-672.107 -672.107 -672.107] (1.000)
Step: 13049, Reward: [-511.28 -511.28 -511.28] [0.0000], Avg: [-671.49 -671.49 -671.49] (1.000)
Step: 13099, Reward: [-485.063 -485.063 -485.063] [0.0000], Avg: [-670.779 -670.779 -670.779] (1.000)
Step: 13149, Reward: [-597.952 -597.952 -597.952] [0.0000], Avg: [-670.502 -670.502 -670.502] (1.000)
Step: 13199, Reward: [-431.663 -431.663 -431.663] [0.0000], Avg: [-669.597 -669.597 -669.597] (1.000)
Step: 13249, Reward: [-559.629 -559.629 -559.629] [0.0000], Avg: [-669.182 -669.182 -669.182] (1.000)
Step: 13299, Reward: [-412.66 -412.66 -412.66] [0.0000], Avg: [-668.218 -668.218 -668.218] (1.000)
Step: 13349, Reward: [-616.61 -616.61 -616.61] [0.0000], Avg: [-668.025 -668.025 -668.025] (1.000)
Step: 13399, Reward: [-589.051 -589.051 -589.051] [0.0000], Avg: [-667.73 -667.73 -667.73] (1.000)
Step: 13449, Reward: [-554.659 -554.659 -554.659] [0.0000], Avg: [-667.31 -667.31 -667.31] (1.000)
Step: 13499, Reward: [-459.403 -459.403 -459.403] [0.0000], Avg: [-666.54 -666.54 -666.54] (1.000)
Step: 13549, Reward: [-404.376 -404.376 -404.376] [0.0000], Avg: [-665.572 -665.572 -665.572] (1.000)
Step: 13599, Reward: [-335.957 -335.957 -335.957] [0.0000], Avg: [-664.36 -664.36 -664.36] (1.000)
Step: 13649, Reward: [-364.889 -364.889 -364.889] [0.0000], Avg: [-663.263 -663.263 -663.263] (1.000)
Step: 13699, Reward: [-403.067 -403.067 -403.067] [0.0000], Avg: [-662.314 -662.314 -662.314] (1.000)
Step: 13749, Reward: [-445.637 -445.637 -445.637] [0.0000], Avg: [-661.526 -661.526 -661.526] (1.000)
Step: 13799, Reward: [-547.825 -547.825 -547.825] [0.0000], Avg: [-661.114 -661.114 -661.114] (1.000)
Step: 13849, Reward: [-668.967 -668.967 -668.967] [0.0000], Avg: [-661.142 -661.142 -661.142] (1.000)
Step: 13899, Reward: [-491.059 -491.059 -491.059] [0.0000], Avg: [-660.53 -660.53 -660.53] (1.000)
Step: 13949, Reward: [-361.737 -361.737 -361.737] [0.0000], Avg: [-659.459 -659.459 -659.459] (1.000)
Step: 13999, Reward: [-513.536 -513.536 -513.536] [0.0000], Avg: [-658.938 -658.938 -658.938] (1.000)
Step: 14049, Reward: [-476.517 -476.517 -476.517] [0.0000], Avg: [-658.289 -658.289 -658.289] (1.000)
Step: 14099, Reward: [-555.019 -555.019 -555.019] [0.0000], Avg: [-657.923 -657.923 -657.923] (1.000)
Step: 14149, Reward: [-470.153 -470.153 -470.153] [0.0000], Avg: [-657.259 -657.259 -657.259] (1.000)
Step: 14199, Reward: [-475.241 -475.241 -475.241] [0.0000], Avg: [-656.618 -656.618 -656.618] (1.000)
Step: 14249, Reward: [-577.253 -577.253 -577.253] [0.0000], Avg: [-656.34 -656.34 -656.34] (1.000)
Step: 14299, Reward: [-571.819 -571.819 -571.819] [0.0000], Avg: [-656.044 -656.044 -656.044] (1.000)
Step: 14349, Reward: [-808.297 -808.297 -808.297] [0.0000], Avg: [-656.575 -656.575 -656.575] (1.000)
Step: 14399, Reward: [-634.292 -634.292 -634.292] [0.0000], Avg: [-656.498 -656.498 -656.498] (1.000)
Step: 14449, Reward: [-301.547 -301.547 -301.547] [0.0000], Avg: [-655.269 -655.269 -655.269] (1.000)
Step: 14499, Reward: [-411.153 -411.153 -411.153] [0.0000], Avg: [-654.428 -654.428 -654.428] (1.000)
Step: 14549, Reward: [-409.826 -409.826 -409.826] [0.0000], Avg: [-653.587 -653.587 -653.587] (1.000)
Step: 14599, Reward: [-533.885 -533.885 -533.885] [0.0000], Avg: [-653.177 -653.177 -653.177] (1.000)
Step: 14649, Reward: [-529.918 -529.918 -529.918] [0.0000], Avg: [-652.756 -652.756 -652.756] (1.000)
Step: 14699, Reward: [-380.227 -380.227 -380.227] [0.0000], Avg: [-651.829 -651.829 -651.829] (1.000)
Step: 14749, Reward: [-427.666 -427.666 -427.666] [0.0000], Avg: [-651.07 -651.07 -651.07] (1.000)
Step: 14799, Reward: [-818.613 -818.613 -818.613] [0.0000], Avg: [-651.636 -651.636 -651.636] (1.000)
Step: 14849, Reward: [-421.259 -421.259 -421.259] [0.0000], Avg: [-650.86 -650.86 -650.86] (1.000)
Step: 14899, Reward: [-535.176 -535.176 -535.176] [0.0000], Avg: [-650.472 -650.472 -650.472] (1.000)
Step: 14949, Reward: [-572.204 -572.204 -572.204] [0.0000], Avg: [-650.21 -650.21 -650.21] (1.000)
Step: 14999, Reward: [-946.814 -946.814 -946.814] [0.0000], Avg: [-651.199 -651.199 -651.199] (1.000)
Step: 15049, Reward: [-387.197 -387.197 -387.197] [0.0000], Avg: [-650.322 -650.322 -650.322] (1.000)
Step: 15099, Reward: [-606.664 -606.664 -606.664] [0.0000], Avg: [-650.177 -650.177 -650.177] (1.000)
Step: 15149, Reward: [-634.282 -634.282 -634.282] [0.0000], Avg: [-650.125 -650.125 -650.125] (1.000)
Step: 15199, Reward: [-559.755 -559.755 -559.755] [0.0000], Avg: [-649.827 -649.827 -649.827] (1.000)
Step: 15249, Reward: [-403.976 -403.976 -403.976] [0.0000], Avg: [-649.021 -649.021 -649.021] (1.000)
Step: 15299, Reward: [-505.702 -505.702 -505.702] [0.0000], Avg: [-648.553 -648.553 -648.553] (1.000)
Step: 15349, Reward: [-497.465 -497.465 -497.465] [0.0000], Avg: [-648.061 -648.061 -648.061] (1.000)
Step: 15399, Reward: [-671.496 -671.496 -671.496] [0.0000], Avg: [-648.137 -648.137 -648.137] (1.000)
Step: 15449, Reward: [-529.191 -529.191 -529.191] [0.0000], Avg: [-647.752 -647.752 -647.752] (1.000)
Step: 15499, Reward: [-349.597 -349.597 -349.597] [0.0000], Avg: [-646.79 -646.79 -646.79] (1.000)
Step: 15549, Reward: [-450.918 -450.918 -450.918] [0.0000], Avg: [-646.16 -646.16 -646.16] (1.000)
Step: 15599, Reward: [-619.282 -619.282 -619.282] [0.0000], Avg: [-646.074 -646.074 -646.074] (1.000)
Step: 15649, Reward: [-363.145 -363.145 -363.145] [0.0000], Avg: [-645.17 -645.17 -645.17] (1.000)
Step: 15699, Reward: [-469.419 -469.419 -469.419] [0.0000], Avg: [-644.61 -644.61 -644.61] (1.000)
Step: 15749, Reward: [-644.439 -644.439 -644.439] [0.0000], Avg: [-644.61 -644.61 -644.61] (1.000)
Step: 15799, Reward: [-519.974 -519.974 -519.974] [0.0000], Avg: [-644.216 -644.216 -644.216] (1.000)
Step: 15849, Reward: [-530.276 -530.276 -530.276] [0.0000], Avg: [-643.856 -643.856 -643.856] (1.000)
Step: 15899, Reward: [-452.211 -452.211 -452.211] [0.0000], Avg: [-643.253 -643.253 -643.253] (1.000)
Step: 15949, Reward: [-455.638 -455.638 -455.638] [0.0000], Avg: [-642.665 -642.665 -642.665] (1.000)
Step: 15999, Reward: [-558.458 -558.458 -558.458] [0.0000], Avg: [-642.402 -642.402 -642.402] (1.000)
Step: 16049, Reward: [-434.605 -434.605 -434.605] [0.0000], Avg: [-641.755 -641.755 -641.755] (1.000)
Step: 16099, Reward: [-717.243 -717.243 -717.243] [0.0000], Avg: [-641.989 -641.989 -641.989] (1.000)
Step: 16149, Reward: [-493.132 -493.132 -493.132] [0.0000], Avg: [-641.528 -641.528 -641.528] (1.000)
Step: 16199, Reward: [-530.147 -530.147 -530.147] [0.0000], Avg: [-641.185 -641.185 -641.185] (1.000)
Step: 16249, Reward: [-559.374 -559.374 -559.374] [0.0000], Avg: [-640.933 -640.933 -640.933] (1.000)
Step: 16299, Reward: [-520.104 -520.104 -520.104] [0.0000], Avg: [-640.562 -640.562 -640.562] (1.000)
Step: 16349, Reward: [-525.017 -525.017 -525.017] [0.0000], Avg: [-640.209 -640.209 -640.209] (1.000)
Step: 16399, Reward: [-605.558 -605.558 -605.558] [0.0000], Avg: [-640.103 -640.103 -640.103] (1.000)
Step: 16449, Reward: [-571.886 -571.886 -571.886] [0.0000], Avg: [-639.896 -639.896 -639.896] (1.000)
Step: 16499, Reward: [-578.479 -578.479 -578.479] [0.0000], Avg: [-639.71 -639.71 -639.71] (1.000)
Step: 16549, Reward: [-586.993 -586.993 -586.993] [0.0000], Avg: [-639.551 -639.551 -639.551] (1.000)
Step: 16599, Reward: [-619.47 -619.47 -619.47] [0.0000], Avg: [-639.49 -639.49 -639.49] (1.000)
Step: 16649, Reward: [-571.684 -571.684 -571.684] [0.0000], Avg: [-639.286 -639.286 -639.286] (1.000)
Step: 16699, Reward: [-506.845 -506.845 -506.845] [0.0000], Avg: [-638.89 -638.89 -638.89] (1.000)
Step: 16749, Reward: [-470.518 -470.518 -470.518] [0.0000], Avg: [-638.387 -638.387 -638.387] (1.000)
Step: 16799, Reward: [-461.683 -461.683 -461.683] [0.0000], Avg: [-637.861 -637.861 -637.861] (1.000)
Step: 16849, Reward: [-514.091 -514.091 -514.091] [0.0000], Avg: [-637.494 -637.494 -637.494] (1.000)
Step: 16899, Reward: [-503.559 -503.559 -503.559] [0.0000], Avg: [-637.098 -637.098 -637.098] (1.000)
Step: 16949, Reward: [-456.132 -456.132 -456.132] [0.0000], Avg: [-636.564 -636.564 -636.564] (1.000)
Step: 16999, Reward: [-285.039 -285.039 -285.039] [0.0000], Avg: [-635.53 -635.53 -635.53] (1.000)
Step: 17049, Reward: [-555.254 -555.254 -555.254] [0.0000], Avg: [-635.295 -635.295 -635.295] (1.000)
Step: 17099, Reward: [-486.178 -486.178 -486.178] [0.0000], Avg: [-634.859 -634.859 -634.859] (1.000)
Step: 17149, Reward: [-656.773 -656.773 -656.773] [0.0000], Avg: [-634.923 -634.923 -634.923] (1.000)
Step: 17199, Reward: [-717.623 -717.623 -717.623] [0.0000], Avg: [-635.163 -635.163 -635.163] (1.000)
Step: 17249, Reward: [-445.514 -445.514 -445.514] [0.0000], Avg: [-634.613 -634.613 -634.613] (1.000)
Step: 17299, Reward: [-415.56 -415.56 -415.56] [0.0000], Avg: [-633.98 -633.98 -633.98] (1.000)
Step: 17349, Reward: [-457.05 -457.05 -457.05] [0.0000], Avg: [-633.47 -633.47 -633.47] (1.000)
Step: 17399, Reward: [-575.169 -575.169 -575.169] [0.0000], Avg: [-633.303 -633.303 -633.303] (1.000)
Step: 17449, Reward: [-512.943 -512.943 -512.943] [0.0000], Avg: [-632.958 -632.958 -632.958] (1.000)
Step: 17499, Reward: [-636.487 -636.487 -636.487] [0.0000], Avg: [-632.968 -632.968 -632.968] (1.000)
Step: 17549, Reward: [-419.321 -419.321 -419.321] [0.0000], Avg: [-632.359 -632.359 -632.359] (1.000)
Step: 17599, Reward: [-326.165 -326.165 -326.165] [0.0000], Avg: [-631.489 -631.489 -631.489] (1.000)
Step: 17649, Reward: [-471.51 -471.51 -471.51] [0.0000], Avg: [-631.036 -631.036 -631.036] (1.000)
Step: 17699, Reward: [-879.108 -879.108 -879.108] [0.0000], Avg: [-631.737 -631.737 -631.737] (1.000)
Step: 17749, Reward: [-419.03 -419.03 -419.03] [0.0000], Avg: [-631.138 -631.138 -631.138] (1.000)
Step: 17799, Reward: [-523.443 -523.443 -523.443] [0.0000], Avg: [-630.835 -630.835 -630.835] (1.000)
Step: 17849, Reward: [-846.441 -846.441 -846.441] [0.0000], Avg: [-631.439 -631.439 -631.439] (1.000)
Step: 17899, Reward: [-586.872 -586.872 -586.872] [0.0000], Avg: [-631.315 -631.315 -631.315] (1.000)
Step: 17949, Reward: [-468.084 -468.084 -468.084] [0.0000], Avg: [-630.86 -630.86 -630.86] (1.000)
Step: 17999, Reward: [-442.185 -442.185 -442.185] [0.0000], Avg: [-630.336 -630.336 -630.336] (1.000)
Step: 18049, Reward: [-447.452 -447.452 -447.452] [0.0000], Avg: [-629.829 -629.829 -629.829] (1.000)
Step: 18099, Reward: [-491.219 -491.219 -491.219] [0.0000], Avg: [-629.446 -629.446 -629.446] (1.000)
Step: 18149, Reward: [-510.638 -510.638 -510.638] [0.0000], Avg: [-629.119 -629.119 -629.119] (1.000)
Step: 18199, Reward: [-563.915 -563.915 -563.915] [0.0000], Avg: [-628.94 -628.94 -628.94] (1.000)
Step: 18249, Reward: [-452.354 -452.354 -452.354] [0.0000], Avg: [-628.456 -628.456 -628.456] (1.000)
Step: 18299, Reward: [-489.28 -489.28 -489.28] [0.0000], Avg: [-628.076 -628.076 -628.076] (1.000)
Step: 18349, Reward: [-466.555 -466.555 -466.555] [0.0000], Avg: [-627.636 -627.636 -627.636] (1.000)
Step: 18399, Reward: [-475.644 -475.644 -475.644] [0.0000], Avg: [-627.223 -627.223 -627.223] (1.000)
Step: 18449, Reward: [-500.308 -500.308 -500.308] [0.0000], Avg: [-626.879 -626.879 -626.879] (1.000)
Step: 18499, Reward: [-383.371 -383.371 -383.371] [0.0000], Avg: [-626.221 -626.221 -626.221] (1.000)
Step: 18549, Reward: [-363.994 -363.994 -363.994] [0.0000], Avg: [-625.514 -625.514 -625.514] (1.000)
Step: 18599, Reward: [-528.307 -528.307 -528.307] [0.0000], Avg: [-625.253 -625.253 -625.253] (1.000)
Step: 18649, Reward: [-378.743 -378.743 -378.743] [0.0000], Avg: [-624.592 -624.592 -624.592] (1.000)
Step: 18699, Reward: [-381.018 -381.018 -381.018] [0.0000], Avg: [-623.941 -623.941 -623.941] (1.000)
Step: 18749, Reward: [-727.849 -727.849 -727.849] [0.0000], Avg: [-624.218 -624.218 -624.218] (1.000)
Step: 18799, Reward: [-512.892 -512.892 -512.892] [0.0000], Avg: [-623.922 -623.922 -623.922] (1.000)
Step: 18849, Reward: [-428.282 -428.282 -428.282] [0.0000], Avg: [-623.403 -623.403 -623.403] (1.000)
Step: 18899, Reward: [-552.512 -552.512 -552.512] [0.0000], Avg: [-623.215 -623.215 -623.215] (1.000)
Step: 18949, Reward: [-390.976 -390.976 -390.976] [0.0000], Avg: [-622.602 -622.602 -622.602] (1.000)
Step: 18999, Reward: [-416.198 -416.198 -416.198] [0.0000], Avg: [-622.059 -622.059 -622.059] (1.000)
Step: 19049, Reward: [-439.26 -439.26 -439.26] [0.0000], Avg: [-621.579 -621.579 -621.579] (1.000)
Step: 19099, Reward: [-292.149 -292.149 -292.149] [0.0000], Avg: [-620.717 -620.717 -620.717] (1.000)
Step: 19149, Reward: [-673.519 -673.519 -673.519] [0.0000], Avg: [-620.855 -620.855 -620.855] (1.000)
Step: 19199, Reward: [-461.872 -461.872 -461.872] [0.0000], Avg: [-620.441 -620.441 -620.441] (1.000)
Step: 19249, Reward: [-470.584 -470.584 -470.584] [0.0000], Avg: [-620.052 -620.052 -620.052] (1.000)
Step: 19299, Reward: [-497.25 -497.25 -497.25] [0.0000], Avg: [-619.733 -619.733 -619.733] (1.000)
Step: 19349, Reward: [-473.495 -473.495 -473.495] [0.0000], Avg: [-619.356 -619.356 -619.356] (1.000)
Step: 19399, Reward: [-557.049 -557.049 -557.049] [0.0000], Avg: [-619.195 -619.195 -619.195] (1.000)
Step: 19449, Reward: [-382.149 -382.149 -382.149] [0.0000], Avg: [-618.586 -618.586 -618.586] (1.000)
Step: 19499, Reward: [-339.629 -339.629 -339.629] [0.0000], Avg: [-617.87 -617.87 -617.87] (1.000)
Step: 19549, Reward: [-538.093 -538.093 -538.093] [0.0000], Avg: [-617.666 -617.666 -617.666] (1.000)
Step: 19599, Reward: [-421.845 -421.845 -421.845] [0.0000], Avg: [-617.167 -617.167 -617.167] (1.000)
Step: 19649, Reward: [-344.57 -344.57 -344.57] [0.0000], Avg: [-616.473 -616.473 -616.473] (1.000)
Step: 19699, Reward: [-486.163 -486.163 -486.163] [0.0000], Avg: [-616.142 -616.142 -616.142] (1.000)
Step: 19749, Reward: [-371.656 -371.656 -371.656] [0.0000], Avg: [-615.523 -615.523 -615.523] (1.000)
Step: 19799, Reward: [-438.402 -438.402 -438.402] [0.0000], Avg: [-615.076 -615.076 -615.076] (1.000)
Step: 19849, Reward: [-535.885 -535.885 -535.885] [0.0000], Avg: [-614.877 -614.877 -614.877] (1.000)
Step: 19899, Reward: [-280.804 -280.804 -280.804] [0.0000], Avg: [-614.037 -614.037 -614.037] (1.000)
Step: 19949, Reward: [-367.497 -367.497 -367.497] [0.0000], Avg: [-613.419 -613.419 -613.419] (1.000)
Step: 19999, Reward: [-466.804 -466.804 -466.804] [0.0000], Avg: [-613.053 -613.053 -613.053] (1.000)
Step: 20049, Reward: [-388.047 -388.047 -388.047] [0.0000], Avg: [-612.492 -612.492 -612.492] (1.000)
Step: 20099, Reward: [-561.818 -561.818 -561.818] [0.0000], Avg: [-612.366 -612.366 -612.366] (1.000)
Step: 20149, Reward: [-444.371 -444.371 -444.371] [0.0000], Avg: [-611.949 -611.949 -611.949] (1.000)
Step: 20199, Reward: [-443.366 -443.366 -443.366] [0.0000], Avg: [-611.532 -611.532 -611.532] (1.000)
Step: 20249, Reward: [-411.898 -411.898 -411.898] [0.0000], Avg: [-611.039 -611.039 -611.039] (1.000)
Step: 20299, Reward: [-379.727 -379.727 -379.727] [0.0000], Avg: [-610.469 -610.469 -610.469] (1.000)
Step: 20349, Reward: [-450.314 -450.314 -450.314] [0.0000], Avg: [-610.075 -610.075 -610.075] (1.000)
Step: 20399, Reward: [-427.576 -427.576 -427.576] [0.0000], Avg: [-609.628 -609.628 -609.628] (1.000)
Step: 20449, Reward: [-451.587 -451.587 -451.587] [0.0000], Avg: [-609.242 -609.242 -609.242] (1.000)
Step: 20499, Reward: [-543.408 -543.408 -543.408] [0.0000], Avg: [-609.081 -609.081 -609.081] (1.000)
Step: 20549, Reward: [-316.028 -316.028 -316.028] [0.0000], Avg: [-608.368 -608.368 -608.368] (1.000)
Step: 20599, Reward: [-489.129 -489.129 -489.129] [0.0000], Avg: [-608.079 -608.079 -608.079] (1.000)
Step: 20649, Reward: [-412.531 -412.531 -412.531] [0.0000], Avg: [-607.605 -607.605 -607.605] (1.000)
Step: 20699, Reward: [-502.942 -502.942 -502.942] [0.0000], Avg: [-607.352 -607.352 -607.352] (1.000)
Step: 20749, Reward: [-439.151 -439.151 -439.151] [0.0000], Avg: [-606.947 -606.947 -606.947] (1.000)
Step: 20799, Reward: [-370.738 -370.738 -370.738] [0.0000], Avg: [-606.379 -606.379 -606.379] (1.000)
Step: 20849, Reward: [-505.593 -505.593 -505.593] [0.0000], Avg: [-606.138 -606.138 -606.138] (1.000)
Step: 20899, Reward: [-389.522 -389.522 -389.522] [0.0000], Avg: [-605.619 -605.619 -605.619] (1.000)
Step: 20949, Reward: [-406.912 -406.912 -406.912] [0.0000], Avg: [-605.145 -605.145 -605.145] (1.000)
Step: 20999, Reward: [-507.779 -507.779 -507.779] [0.0000], Avg: [-604.913 -604.913 -604.913] (1.000)
Step: 21049, Reward: [-518.481 -518.481 -518.481] [0.0000], Avg: [-604.708 -604.708 -604.708] (1.000)
Step: 21099, Reward: [-471.702 -471.702 -471.702] [0.0000], Avg: [-604.393 -604.393 -604.393] (1.000)
Step: 21149, Reward: [-340.932 -340.932 -340.932] [0.0000], Avg: [-603.77 -603.77 -603.77] (1.000)
Step: 21199, Reward: [-341.978 -341.978 -341.978] [0.0000], Avg: [-603.153 -603.153 -603.153] (1.000)
Step: 21249, Reward: [-390.58 -390.58 -390.58] [0.0000], Avg: [-602.652 -602.652 -602.652] (1.000)
Step: 21299, Reward: [-449.159 -449.159 -449.159] [0.0000], Avg: [-602.292 -602.292 -602.292] (1.000)
Step: 21349, Reward: [-371.427 -371.427 -371.427] [0.0000], Avg: [-601.751 -601.751 -601.751] (1.000)
Step: 21399, Reward: [-419.958 -419.958 -419.958] [0.0000], Avg: [-601.327 -601.327 -601.327] (1.000)
Step: 21449, Reward: [-438.17 -438.17 -438.17] [0.0000], Avg: [-600.946 -600.946 -600.946] (1.000)
Step: 21499, Reward: [-399.977 -399.977 -399.977] [0.0000], Avg: [-600.479 -600.479 -600.479] (1.000)
Step: 21549, Reward: [-407.522 -407.522 -407.522] [0.0000], Avg: [-600.031 -600.031 -600.031] (1.000)
Step: 21599, Reward: [-376.748 -376.748 -376.748] [0.0000], Avg: [-599.514 -599.514 -599.514] (1.000)
Step: 21649, Reward: [-495.47 -495.47 -495.47] [0.0000], Avg: [-599.274 -599.274 -599.274] (1.000)
Step: 21699, Reward: [-478.959 -478.959 -478.959] [0.0000], Avg: [-598.997 -598.997 -598.997] (1.000)
Step: 21749, Reward: [-413.675 -413.675 -413.675] [0.0000], Avg: [-598.571 -598.571 -598.571] (1.000)
Step: 21799, Reward: [-380.337 -380.337 -380.337] [0.0000], Avg: [-598.07 -598.07 -598.07] (1.000)
Step: 21849, Reward: [-341.295 -341.295 -341.295] [0.0000], Avg: [-597.483 -597.483 -597.483] (1.000)
Step: 21899, Reward: [-364.181 -364.181 -364.181] [0.0000], Avg: [-596.95 -596.95 -596.95] (1.000)
Step: 21949, Reward: [-353.668 -353.668 -353.668] [0.0000], Avg: [-596.396 -596.396 -596.396] (1.000)
Step: 21999, Reward: [-347.205 -347.205 -347.205] [0.0000], Avg: [-595.83 -595.83 -595.83] (1.000)
Step: 22049, Reward: [-346.386 -346.386 -346.386] [0.0000], Avg: [-595.264 -595.264 -595.264] (1.000)
Step: 22099, Reward: [-373.627 -373.627 -373.627] [0.0000], Avg: [-594.762 -594.762 -594.762] (1.000)
Step: 22149, Reward: [-407.475 -407.475 -407.475] [0.0000], Avg: [-594.34 -594.34 -594.34] (1.000)
Step: 22199, Reward: [-351.346 -351.346 -351.346] [0.0000], Avg: [-593.792 -593.792 -593.792] (1.000)
Step: 22249, Reward: [-504.82 -504.82 -504.82] [0.0000], Avg: [-593.592 -593.592 -593.592] (1.000)
Step: 22299, Reward: [-382.732 -382.732 -382.732] [0.0000], Avg: [-593.12 -593.12 -593.12] (1.000)
Step: 22349, Reward: [-387.697 -387.697 -387.697] [0.0000], Avg: [-592.66 -592.66 -592.66] (1.000)
Step: 22399, Reward: [-377.004 -377.004 -377.004] [0.0000], Avg: [-592.179 -592.179 -592.179] (1.000)
Step: 22449, Reward: [-389.97 -389.97 -389.97] [0.0000], Avg: [-591.728 -591.728 -591.728] (1.000)
Step: 22499, Reward: [-325.669 -325.669 -325.669] [0.0000], Avg: [-591.137 -591.137 -591.137] (1.000)
Step: 22549, Reward: [-389.204 -389.204 -389.204] [0.0000], Avg: [-590.689 -590.689 -590.689] (1.000)
Step: 22599, Reward: [-441.438 -441.438 -441.438] [0.0000], Avg: [-590.359 -590.359 -590.359] (1.000)
Step: 22649, Reward: [-385.288 -385.288 -385.288] [0.0000], Avg: [-589.907 -589.907 -589.907] (1.000)
Step: 22699, Reward: [-417.073 -417.073 -417.073] [0.0000], Avg: [-589.526 -589.526 -589.526] (1.000)
Step: 22749, Reward: [-406.063 -406.063 -406.063] [0.0000], Avg: [-589.123 -589.123 -589.123] (1.000)
Step: 22799, Reward: [-426.074 -426.074 -426.074] [0.0000], Avg: [-588.765 -588.765 -588.765] (1.000)
Step: 22849, Reward: [-510.007 -510.007 -510.007] [0.0000], Avg: [-588.593 -588.593 -588.593] (1.000)
Step: 22899, Reward: [-444.341 -444.341 -444.341] [0.0000], Avg: [-588.278 -588.278 -588.278] (1.000)
Step: 22949, Reward: [-372.946 -372.946 -372.946] [0.0000], Avg: [-587.809 -587.809 -587.809] (1.000)
Step: 22999, Reward: [-430.674 -430.674 -430.674] [0.0000], Avg: [-587.467 -587.467 -587.467] (1.000)
Step: 23049, Reward: [-424.544 -424.544 -424.544] [0.0000], Avg: [-587.114 -587.114 -587.114] (1.000)
Step: 23099, Reward: [-395.933 -395.933 -395.933] [0.0000], Avg: [-586.7 -586.7 -586.7] (1.000)
Step: 23149, Reward: [-447.317 -447.317 -447.317] [0.0000], Avg: [-586.399 -586.399 -586.399] (1.000)
Step: 23199, Reward: [-472.74 -472.74 -472.74] [0.0000], Avg: [-586.154 -586.154 -586.154] (1.000)
Step: 23249, Reward: [-407.584 -407.584 -407.584] [0.0000], Avg: [-585.77 -585.77 -585.77] (1.000)
Step: 23299, Reward: [-517.828 -517.828 -517.828] [0.0000], Avg: [-585.624 -585.624 -585.624] (1.000)
Step: 23349, Reward: [-398.779 -398.779 -398.779] [0.0000], Avg: [-585.224 -585.224 -585.224] (1.000)
Step: 23399, Reward: [-460.233 -460.233 -460.233] [0.0000], Avg: [-584.957 -584.957 -584.957] (1.000)
Step: 23449, Reward: [-335.274 -335.274 -335.274] [0.0000], Avg: [-584.424 -584.424 -584.424] (1.000)
Step: 23499, Reward: [-399.627 -399.627 -399.627] [0.0000], Avg: [-584.031 -584.031 -584.031] (1.000)
Step: 23549, Reward: [-583.654 -583.654 -583.654] [0.0000], Avg: [-584.03 -584.03 -584.03] (1.000)
Step: 23599, Reward: [-424.73 -424.73 -424.73] [0.0000], Avg: [-583.693 -583.693 -583.693] (1.000)
Step: 23649, Reward: [-457.344 -457.344 -457.344] [0.0000], Avg: [-583.426 -583.426 -583.426] (1.000)
Step: 23699, Reward: [-336.792 -336.792 -336.792] [0.0000], Avg: [-582.906 -582.906 -582.906] (1.000)
Step: 23749, Reward: [-335.072 -335.072 -335.072] [0.0000], Avg: [-582.384 -582.384 -582.384] (1.000)
Step: 23799, Reward: [-498.818 -498.818 -498.818] [0.0000], Avg: [-582.208 -582.208 -582.208] (1.000)
Step: 23849, Reward: [-349.423 -349.423 -349.423] [0.0000], Avg: [-581.72 -581.72 -581.72] (1.000)
Step: 23899, Reward: [-312.964 -312.964 -312.964] [0.0000], Avg: [-581.158 -581.158 -581.158] (1.000)
Step: 23949, Reward: [-550.68 -550.68 -550.68] [0.0000], Avg: [-581.094 -581.094 -581.094] (1.000)
Step: 23999, Reward: [-480.099 -480.099 -480.099] [0.0000], Avg: [-580.884 -580.884 -580.884] (1.000)
Step: 24049, Reward: [-476.632 -476.632 -476.632] [0.0000], Avg: [-580.667 -580.667 -580.667] (1.000)
Step: 24099, Reward: [-391.555 -391.555 -391.555] [0.0000], Avg: [-580.275 -580.275 -580.275] (1.000)
Step: 24149, Reward: [-486.463 -486.463 -486.463] [0.0000], Avg: [-580.081 -580.081 -580.081] (1.000)
Step: 24199, Reward: [-380.253 -380.253 -380.253] [0.0000], Avg: [-579.668 -579.668 -579.668] (1.000)
Step: 24249, Reward: [-379.918 -379.918 -379.918] [0.0000], Avg: [-579.256 -579.256 -579.256] (1.000)
Step: 24299, Reward: [-452.169 -452.169 -452.169] [0.0000], Avg: [-578.994 -578.994 -578.994] (1.000)
Step: 24349, Reward: [-399.011 -399.011 -399.011] [0.0000], Avg: [-578.625 -578.625 -578.625] (1.000)
Step: 24399, Reward: [-515.015 -515.015 -515.015] [0.0000], Avg: [-578.494 -578.494 -578.494] (1.000)
Step: 24449, Reward: [-378.956 -378.956 -378.956] [0.0000], Avg: [-578.086 -578.086 -578.086] (1.000)
Step: 24499, Reward: [-382.103 -382.103 -382.103] [0.0000], Avg: [-577.686 -577.686 -577.686] (1.000)
Step: 24549, Reward: [-447.336 -447.336 -447.336] [0.0000], Avg: [-577.421 -577.421 -577.421] (1.000)
Step: 24599, Reward: [-513.527 -513.527 -513.527] [0.0000], Avg: [-577.291 -577.291 -577.291] (1.000)
Step: 24649, Reward: [-480.34 -480.34 -480.34] [0.0000], Avg: [-577.094 -577.094 -577.094] (1.000)
Step: 24699, Reward: [-528.099 -528.099 -528.099] [0.0000], Avg: [-576.995 -576.995 -576.995] (1.000)
Step: 24749, Reward: [-436.452 -436.452 -436.452] [0.0000], Avg: [-576.711 -576.711 -576.711] (1.000)
Step: 24799, Reward: [-479.027 -479.027 -479.027] [0.0000], Avg: [-576.514 -576.514 -576.514] (1.000)
Step: 24849, Reward: [-446.34 -446.34 -446.34] [0.0000], Avg: [-576.252 -576.252 -576.252] (1.000)
Step: 24899, Reward: [-522.088 -522.088 -522.088] [0.0000], Avg: [-576.144 -576.144 -576.144] (1.000)
Step: 24949, Reward: [-687.156 -687.156 -687.156] [0.0000], Avg: [-576.366 -576.366 -576.366] (1.000)
Step: 24999, Reward: [-382.338 -382.338 -382.338] [0.0000], Avg: [-575.978 -575.978 -575.978] (1.000)
Step: 25049, Reward: [-521.348 -521.348 -521.348] [0.0000], Avg: [-575.869 -575.869 -575.869] (1.000)
Step: 25099, Reward: [-552.836 -552.836 -552.836] [0.0000], Avg: [-575.823 -575.823 -575.823] (1.000)
Step: 25149, Reward: [-321.983 -321.983 -321.983] [0.0000], Avg: [-575.319 -575.319 -575.319] (1.000)
Step: 25199, Reward: [-644.425 -644.425 -644.425] [0.0000], Avg: [-575.456 -575.456 -575.456] (1.000)
Step: 25249, Reward: [-482.237 -482.237 -482.237] [0.0000], Avg: [-575.271 -575.271 -575.271] (1.000)
Step: 25299, Reward: [-437.144 -437.144 -437.144] [0.0000], Avg: [-574.998 -574.998 -574.998] (1.000)
Step: 25349, Reward: [-410.497 -410.497 -410.497] [0.0000], Avg: [-574.674 -574.674 -574.674] (1.000)
Step: 25399, Reward: [-505.079 -505.079 -505.079] [0.0000], Avg: [-574.537 -574.537 -574.537] (1.000)
Step: 25449, Reward: [-397.738 -397.738 -397.738] [0.0000], Avg: [-574.189 -574.189 -574.189] (1.000)
Step: 25499, Reward: [-511.368 -511.368 -511.368] [0.0000], Avg: [-574.066 -574.066 -574.066] (1.000)
Step: 25549, Reward: [-364.087 -364.087 -364.087] [0.0000], Avg: [-573.655 -573.655 -573.655] (1.000)
Step: 25599, Reward: [-320.12 -320.12 -320.12] [0.0000], Avg: [-573.16 -573.16 -573.16] (1.000)
Step: 25649, Reward: [-454.169 -454.169 -454.169] [0.0000], Avg: [-572.928 -572.928 -572.928] (1.000)
Step: 25699, Reward: [-426.573 -426.573 -426.573] [0.0000], Avg: [-572.643 -572.643 -572.643] (1.000)
Step: 25749, Reward: [-372.346 -372.346 -372.346] [0.0000], Avg: [-572.254 -572.254 -572.254] (1.000)
Step: 25799, Reward: [-462.473 -462.473 -462.473] [0.0000], Avg: [-572.042 -572.042 -572.042] (1.000)
Step: 25849, Reward: [-442.887 -442.887 -442.887] [0.0000], Avg: [-571.792 -571.792 -571.792] (1.000)
Step: 25899, Reward: [-338.666 -338.666 -338.666] [0.0000], Avg: [-571.342 -571.342 -571.342] (1.000)
Step: 25949, Reward: [-480.926 -480.926 -480.926] [0.0000], Avg: [-571.168 -571.168 -571.168] (1.000)
Step: 25999, Reward: [-348.349 -348.349 -348.349] [0.0000], Avg: [-570.739 -570.739 -570.739] (1.000)
Step: 26049, Reward: [-436.32 -436.32 -436.32] [0.0000], Avg: [-570.481 -570.481 -570.481] (1.000)
Step: 26099, Reward: [-387.922 -387.922 -387.922] [0.0000], Avg: [-570.131 -570.131 -570.131] (1.000)
Step: 26149, Reward: [-391.382 -391.382 -391.382] [0.0000], Avg: [-569.79 -569.79 -569.79] (1.000)
Step: 26199, Reward: [-516.76 -516.76 -516.76] [0.0000], Avg: [-569.688 -569.688 -569.688] (1.000)
Step: 26249, Reward: [-393.712 -393.712 -393.712] [0.0000], Avg: [-569.353 -569.353 -569.353] (1.000)
Step: 26299, Reward: [-429.269 -429.269 -429.269] [0.0000], Avg: [-569.087 -569.087 -569.087] (1.000)
Step: 26349, Reward: [-361.856 -361.856 -361.856] [0.0000], Avg: [-568.694 -568.694 -568.694] (1.000)
Step: 26399, Reward: [-438.629 -438.629 -438.629] [0.0000], Avg: [-568.447 -568.447 -568.447] (1.000)
Step: 26449, Reward: [-425.116 -425.116 -425.116] [0.0000], Avg: [-568.176 -568.176 -568.176] (1.000)
Step: 26499, Reward: [-354.577 -354.577 -354.577] [0.0000], Avg: [-567.773 -567.773 -567.773] (1.000)
Step: 26549, Reward: [-391.789 -391.789 -391.789] [0.0000], Avg: [-567.442 -567.442 -567.442] (1.000)
Step: 26599, Reward: [-460.183 -460.183 -460.183] [0.0000], Avg: [-567.24 -567.24 -567.24] (1.000)
Step: 26649, Reward: [-405.211 -405.211 -405.211] [0.0000], Avg: [-566.936 -566.936 -566.936] (1.000)
Step: 26699, Reward: [-429.653 -429.653 -429.653] [0.0000], Avg: [-566.679 -566.679 -566.679] (1.000)
Step: 26749, Reward: [-397.189 -397.189 -397.189] [0.0000], Avg: [-566.362 -566.362 -566.362] (1.000)
Step: 26799, Reward: [-385.498 -385.498 -385.498] [0.0000], Avg: [-566.025 -566.025 -566.025] (1.000)
Step: 26849, Reward: [-402.204 -402.204 -402.204] [0.0000], Avg: [-565.72 -565.72 -565.72] (1.000)
Step: 26899, Reward: [-380.891 -380.891 -380.891] [0.0000], Avg: [-565.376 -565.376 -565.376] (1.000)
Step: 26949, Reward: [-473.792 -473.792 -473.792] [0.0000], Avg: [-565.206 -565.206 -565.206] (1.000)
Step: 26999, Reward: [-436.081 -436.081 -436.081] [0.0000], Avg: [-564.967 -564.967 -564.967] (1.000)
Step: 27049, Reward: [-573.863 -573.863 -573.863] [0.0000], Avg: [-564.984 -564.984 -564.984] (1.000)
Step: 27099, Reward: [-426.519 -426.519 -426.519] [0.0000], Avg: [-564.728 -564.728 -564.728] (1.000)
Step: 27149, Reward: [-415.055 -415.055 -415.055] [0.0000], Avg: [-564.453 -564.453 -564.453] (1.000)
Step: 27199, Reward: [-397.92 -397.92 -397.92] [0.0000], Avg: [-564.146 -564.146 -564.146] (1.000)
Step: 27249, Reward: [-471.661 -471.661 -471.661] [0.0000], Avg: [-563.977 -563.977 -563.977] (1.000)
Step: 27299, Reward: [-589.735 -589.735 -589.735] [0.0000], Avg: [-564.024 -564.024 -564.024] (1.000)
Step: 27349, Reward: [-484.437 -484.437 -484.437] [0.0000], Avg: [-563.878 -563.878 -563.878] (1.000)
Step: 27399, Reward: [-425.356 -425.356 -425.356] [0.0000], Avg: [-563.626 -563.626 -563.626] (1.000)
Step: 27449, Reward: [-377.134 -377.134 -377.134] [0.0000], Avg: [-563.286 -563.286 -563.286] (1.000)
Step: 27499, Reward: [-355.542 -355.542 -355.542] [0.0000], Avg: [-562.908 -562.908 -562.908] (1.000)
Step: 27549, Reward: [-344.689 -344.689 -344.689] [0.0000], Avg: [-562.512 -562.512 -562.512] (1.000)
Step: 27599, Reward: [-311.683 -311.683 -311.683] [0.0000], Avg: [-562.058 -562.058 -562.058] (1.000)
Step: 27649, Reward: [-374.01 -374.01 -374.01] [0.0000], Avg: [-561.718 -561.718 -561.718] (1.000)
Step: 27699, Reward: [-360.347 -360.347 -360.347] [0.0000], Avg: [-561.354 -561.354 -561.354] (1.000)
Step: 27749, Reward: [-511.691 -511.691 -511.691] [0.0000], Avg: [-561.265 -561.265 -561.265] (1.000)
Step: 27799, Reward: [-440.219 -440.219 -440.219] [0.0000], Avg: [-561.047 -561.047 -561.047] (1.000)
Step: 27849, Reward: [-662.892 -662.892 -662.892] [0.0000], Avg: [-561.23 -561.23 -561.23] (1.000)
Step: 27899, Reward: [-401.564 -401.564 -401.564] [0.0000], Avg: [-560.944 -560.944 -560.944] (1.000)
Step: 27949, Reward: [-391.248 -391.248 -391.248] [0.0000], Avg: [-560.64 -560.64 -560.64] (1.000)
Step: 27999, Reward: [-511.509 -511.509 -511.509] [0.0000], Avg: [-560.553 -560.553 -560.553] (1.000)
Step: 28049, Reward: [-471.199 -471.199 -471.199] [0.0000], Avg: [-560.393 -560.393 -560.393] (1.000)
Step: 28099, Reward: [-481.128 -481.128 -481.128] [0.0000], Avg: [-560.252 -560.252 -560.252] (1.000)
Step: 28149, Reward: [-605.314 -605.314 -605.314] [0.0000], Avg: [-560.332 -560.332 -560.332] (1.000)
Step: 28199, Reward: [-471.503 -471.503 -471.503] [0.0000], Avg: [-560.175 -560.175 -560.175] (1.000)
Step: 28249, Reward: [-440.018 -440.018 -440.018] [0.0000], Avg: [-559.962 -559.962 -559.962] (1.000)
Step: 28299, Reward: [-449.357 -449.357 -449.357] [0.0000], Avg: [-559.767 -559.767 -559.767] (1.000)
Step: 28349, Reward: [-411.488 -411.488 -411.488] [0.0000], Avg: [-559.505 -559.505 -559.505] (1.000)
Step: 28399, Reward: [-444.577 -444.577 -444.577] [0.0000], Avg: [-559.303 -559.303 -559.303] (1.000)
Step: 28449, Reward: [-404.796 -404.796 -404.796] [0.0000], Avg: [-559.031 -559.031 -559.031] (1.000)
Step: 28499, Reward: [-455.304 -455.304 -455.304] [0.0000], Avg: [-558.849 -558.849 -558.849] (1.000)
Step: 28549, Reward: [-378.877 -378.877 -378.877] [0.0000], Avg: [-558.534 -558.534 -558.534] (1.000)
Step: 28599, Reward: [-390.724 -390.724 -390.724] [0.0000], Avg: [-558.241 -558.241 -558.241] (1.000)
Step: 28649, Reward: [-363.991 -363.991 -363.991] [0.0000], Avg: [-557.902 -557.902 -557.902] (1.000)
Step: 28699, Reward: [-470.458 -470.458 -470.458] [0.0000], Avg: [-557.749 -557.749 -557.749] (1.000)
Step: 28749, Reward: [-401.508 -401.508 -401.508] [0.0000], Avg: [-557.478 -557.478 -557.478] (1.000)
Step: 28799, Reward: [-411.937 -411.937 -411.937] [0.0000], Avg: [-557.225 -557.225 -557.225] (1.000)
Step: 28849, Reward: [-461.489 -461.489 -461.489] [0.0000], Avg: [-557.059 -557.059 -557.059] (1.000)
Step: 28899, Reward: [-452.256 -452.256 -452.256] [0.0000], Avg: [-556.878 -556.878 -556.878] (1.000)
Step: 28949, Reward: [-410.62 -410.62 -410.62] [0.0000], Avg: [-556.625 -556.625 -556.625] (1.000)
Step: 28999, Reward: [-346.872 -346.872 -346.872] [0.0000], Avg: [-556.263 -556.263 -556.263] (1.000)
Step: 29049, Reward: [-490.531 -490.531 -490.531] [0.0000], Avg: [-556.15 -556.15 -556.15] (1.000)
Step: 29099, Reward: [-424.115 -424.115 -424.115] [0.0000], Avg: [-555.923 -555.923 -555.923] (1.000)
Step: 29149, Reward: [-305.831 -305.831 -305.831] [0.0000], Avg: [-555.495 -555.495 -555.495] (1.000)
Step: 29199, Reward: [-491.563 -491.563 -491.563] [0.0000], Avg: [-555.385 -555.385 -555.385] (1.000)
Step: 29249, Reward: [-389.323 -389.323 -389.323] [0.0000], Avg: [-555.101 -555.101 -555.101] (1.000)
Step: 29299, Reward: [-343.576 -343.576 -343.576] [0.0000], Avg: [-554.74 -554.74 -554.74] (1.000)
Step: 29349, Reward: [-486.466 -486.466 -486.466] [0.0000], Avg: [-554.624 -554.624 -554.624] (1.000)
Step: 29399, Reward: [-486.798 -486.798 -486.798] [0.0000], Avg: [-554.509 -554.509 -554.509] (1.000)
Step: 29449, Reward: [-457.197 -457.197 -457.197] [0.0000], Avg: [-554.343 -554.343 -554.343] (1.000)
Step: 29499, Reward: [-432.458 -432.458 -432.458] [0.0000], Avg: [-554.137 -554.137 -554.137] (1.000)
Step: 29549, Reward: [-438.684 -438.684 -438.684] [0.0000], Avg: [-553.941 -553.941 -553.941] (1.000)
Step: 29599, Reward: [-448.907 -448.907 -448.907] [0.0000], Avg: [-553.764 -553.764 -553.764] (1.000)
Step: 29649, Reward: [-393.216 -393.216 -393.216] [0.0000], Avg: [-553.493 -553.493 -553.493] (1.000)
Step: 29699, Reward: [-456.409 -456.409 -456.409] [0.0000], Avg: [-553.33 -553.33 -553.33] (1.000)
Step: 29749, Reward: [-388.402 -388.402 -388.402] [0.0000], Avg: [-553.053 -553.053 -553.053] (1.000)
Step: 29799, Reward: [-341.304 -341.304 -341.304] [0.0000], Avg: [-552.697 -552.697 -552.697] (1.000)
Step: 29849, Reward: [-424.605 -424.605 -424.605] [0.0000], Avg: [-552.483 -552.483 -552.483] (1.000)
Step: 29899, Reward: [-301.901 -301.901 -301.901] [0.0000], Avg: [-552.064 -552.064 -552.064] (1.000)
Step: 29949, Reward: [-321.384 -321.384 -321.384] [0.0000], Avg: [-551.679 -551.679 -551.679] (1.000)
Step: 29999, Reward: [-470.114 -470.114 -470.114] [0.0000], Avg: [-551.543 -551.543 -551.543] (1.000)
Step: 30049, Reward: [-440.941 -440.941 -440.941] [0.0000], Avg: [-551.359 -551.359 -551.359] (1.000)
Step: 30099, Reward: [-433.599 -433.599 -433.599] [0.0000], Avg: [-551.163 -551.163 -551.163] (1.000)
Step: 30149, Reward: [-408.78 -408.78 -408.78] [0.0000], Avg: [-550.927 -550.927 -550.927] (1.000)
Step: 30199, Reward: [-425.231 -425.231 -425.231] [0.0000], Avg: [-550.719 -550.719 -550.719] (1.000)
Step: 30249, Reward: [-383.033 -383.033 -383.033] [0.0000], Avg: [-550.442 -550.442 -550.442] (1.000)
Step: 30299, Reward: [-434.876 -434.876 -434.876] [0.0000], Avg: [-550.251 -550.251 -550.251] (1.000)
Step: 30349, Reward: [-371.728 -371.728 -371.728] [0.0000], Avg: [-549.957 -549.957 -549.957] (1.000)
Step: 30399, Reward: [-384.254 -384.254 -384.254] [0.0000], Avg: [-549.684 -549.684 -549.684] (1.000)
Step: 30449, Reward: [-353.179 -353.179 -353.179] [0.0000], Avg: [-549.362 -549.362 -549.362] (1.000)
Step: 30499, Reward: [-419.979 -419.979 -419.979] [0.0000], Avg: [-549.15 -549.15 -549.15] (1.000)
Step: 30549, Reward: [-475.049 -475.049 -475.049] [0.0000], Avg: [-549.028 -549.028 -549.028] (1.000)
Step: 30599, Reward: [-522.916 -522.916 -522.916] [0.0000], Avg: [-548.986 -548.986 -548.986] (1.000)
Step: 30649, Reward: [-417.807 -417.807 -417.807] [0.0000], Avg: [-548.772 -548.772 -548.772] (1.000)
Step: 30699, Reward: [-369.134 -369.134 -369.134] [0.0000], Avg: [-548.479 -548.479 -548.479] (1.000)
Step: 30749, Reward: [-327.088 -327.088 -327.088] [0.0000], Avg: [-548.119 -548.119 -548.119] (1.000)
Step: 30799, Reward: [-518.003 -518.003 -518.003] [0.0000], Avg: [-548.07 -548.07 -548.07] (1.000)
Step: 30849, Reward: [-413.722 -413.722 -413.722] [0.0000], Avg: [-547.852 -547.852 -547.852] (1.000)
Step: 30899, Reward: [-588.135 -588.135 -588.135] [0.0000], Avg: [-547.918 -547.918 -547.918] (1.000)
Step: 30949, Reward: [-455.057 -455.057 -455.057] [0.0000], Avg: [-547.768 -547.768 -547.768] (1.000)
Step: 30999, Reward: [-407.282 -407.282 -407.282] [0.0000], Avg: [-547.541 -547.541 -547.541] (1.000)
Step: 31049, Reward: [-313.337 -313.337 -313.337] [0.0000], Avg: [-547.164 -547.164 -547.164] (1.000)
Step: 31099, Reward: [-358.481 -358.481 -358.481] [0.0000], Avg: [-546.86 -546.86 -546.86] (1.000)
Step: 31149, Reward: [-371.605 -371.605 -371.605] [0.0000], Avg: [-546.579 -546.579 -546.579] (1.000)
Step: 31199, Reward: [-398.451 -398.451 -398.451] [0.0000], Avg: [-546.342 -546.342 -546.342] (1.000)
Step: 31249, Reward: [-406.55 -406.55 -406.55] [0.0000], Avg: [-546.118 -546.118 -546.118] (1.000)
Step: 31299, Reward: [-440.339 -440.339 -440.339] [0.0000], Avg: [-545.949 -545.949 -545.949] (1.000)
Step: 31349, Reward: [-425.402 -425.402 -425.402] [0.0000], Avg: [-545.757 -545.757 -545.757] (1.000)
Step: 31399, Reward: [-482.173 -482.173 -482.173] [0.0000], Avg: [-545.656 -545.656 -545.656] (1.000)
Step: 31449, Reward: [-368.814 -368.814 -368.814] [0.0000], Avg: [-545.374 -545.374 -545.374] (1.000)
Step: 31499, Reward: [-448.392 -448.392 -448.392] [0.0000], Avg: [-545.221 -545.221 -545.221] (1.000)
Step: 31549, Reward: [-468.608 -468.608 -468.608] [0.0000], Avg: [-545.099 -545.099 -545.099] (1.000)
Step: 31599, Reward: [-529.308 -529.308 -529.308] [0.0000], Avg: [-545.074 -545.074 -545.074] (1.000)
Step: 31649, Reward: [-433.208 -433.208 -433.208] [0.0000], Avg: [-544.897 -544.897 -544.897] (1.000)
Step: 31699, Reward: [-460.997 -460.997 -460.997] [0.0000], Avg: [-544.765 -544.765 -544.765] (1.000)
Step: 31749, Reward: [-298.983 -298.983 -298.983] [0.0000], Avg: [-544.378 -544.378 -544.378] (1.000)
Step: 31799, Reward: [-465.729 -465.729 -465.729] [0.0000], Avg: [-544.254 -544.254 -544.254] (1.000)
Step: 31849, Reward: [-430.704 -430.704 -430.704] [0.0000], Avg: [-544.076 -544.076 -544.076] (1.000)
Step: 31899, Reward: [-421.518 -421.518 -421.518] [0.0000], Avg: [-543.884 -543.884 -543.884] (1.000)
Step: 31949, Reward: [-413.255 -413.255 -413.255] [0.0000], Avg: [-543.68 -543.68 -543.68] (1.000)
Step: 31999, Reward: [-338.362 -338.362 -338.362] [0.0000], Avg: [-543.359 -543.359 -543.359] (1.000)
Step: 32049, Reward: [-589.606 -589.606 -589.606] [0.0000], Avg: [-543.431 -543.431 -543.431] (1.000)
Step: 32099, Reward: [-502.592 -502.592 -502.592] [0.0000], Avg: [-543.367 -543.367 -543.367] (1.000)
Step: 32149, Reward: [-535.452 -535.452 -535.452] [0.0000], Avg: [-543.355 -543.355 -543.355] (1.000)
Step: 32199, Reward: [-421.449 -421.449 -421.449] [0.0000], Avg: [-543.166 -543.166 -543.166] (1.000)
Step: 32249, Reward: [-565.166 -565.166 -565.166] [0.0000], Avg: [-543.2 -543.2 -543.2] (1.000)
Step: 32299, Reward: [-597.129 -597.129 -597.129] [0.0000], Avg: [-543.283 -543.283 -543.283] (1.000)
Step: 32349, Reward: [-435.308 -435.308 -435.308] [0.0000], Avg: [-543.116 -543.116 -543.116] (1.000)
Step: 32399, Reward: [-371.658 -371.658 -371.658] [0.0000], Avg: [-542.852 -542.852 -542.852] (1.000)
Step: 32449, Reward: [-428.695 -428.695 -428.695] [0.0000], Avg: [-542.676 -542.676 -542.676] (1.000)
Step: 32499, Reward: [-339.365 -339.365 -339.365] [0.0000], Avg: [-542.363 -542.363 -542.363] (1.000)
Step: 32549, Reward: [-376.149 -376.149 -376.149] [0.0000], Avg: [-542.108 -542.108 -542.108] (1.000)
Step: 32599, Reward: [-390.734 -390.734 -390.734] [0.0000], Avg: [-541.876 -541.876 -541.876] (1.000)
Step: 32649, Reward: [-372.274 -372.274 -372.274] [0.0000], Avg: [-541.616 -541.616 -541.616] (1.000)
Step: 32699, Reward: [-426.565 -426.565 -426.565] [0.0000], Avg: [-541.44 -541.44 -541.44] (1.000)
Step: 32749, Reward: [-531.23 -531.23 -531.23] [0.0000], Avg: [-541.424 -541.424 -541.424] (1.000)
Step: 32799, Reward: [-351.221 -351.221 -351.221] [0.0000], Avg: [-541.134 -541.134 -541.134] (1.000)
Step: 32849, Reward: [-510.136 -510.136 -510.136] [0.0000], Avg: [-541.087 -541.087 -541.087] (1.000)
Step: 32899, Reward: [-409.531 -409.531 -409.531] [0.0000], Avg: [-540.887 -540.887 -540.887] (1.000)
Step: 32949, Reward: [-371.959 -371.959 -371.959] [0.0000], Avg: [-540.631 -540.631 -540.631] (1.000)
Step: 32999, Reward: [-329.121 -329.121 -329.121] [0.0000], Avg: [-540.311 -540.311 -540.311] (1.000)
Step: 33049, Reward: [-351.142 -351.142 -351.142] [0.0000], Avg: [-540.024 -540.024 -540.024] (1.000)
Step: 33099, Reward: [-552.435 -552.435 -552.435] [0.0000], Avg: [-540.043 -540.043 -540.043] (1.000)
Step: 33149, Reward: [-372.009 -372.009 -372.009] [0.0000], Avg: [-539.79 -539.79 -539.79] (1.000)
Step: 33199, Reward: [-453.851 -453.851 -453.851] [0.0000], Avg: [-539.66 -539.66 -539.66] (1.000)
Step: 33249, Reward: [-488.455 -488.455 -488.455] [0.0000], Avg: [-539.583 -539.583 -539.583] (1.000)
Step: 33299, Reward: [-508.306 -508.306 -508.306] [0.0000], Avg: [-539.536 -539.536 -539.536] (1.000)
Step: 33349, Reward: [-363.575 -363.575 -363.575] [0.0000], Avg: [-539.272 -539.272 -539.272] (1.000)
Step: 33399, Reward: [-436.997 -436.997 -436.997] [0.0000], Avg: [-539.119 -539.119 -539.119] (1.000)
Step: 33449, Reward: [-452.474 -452.474 -452.474] [0.0000], Avg: [-538.99 -538.99 -538.99] (1.000)
Step: 33499, Reward: [-421.828 -421.828 -421.828] [0.0000], Avg: [-538.815 -538.815 -538.815] (1.000)
Step: 33549, Reward: [-379.226 -379.226 -379.226] [0.0000], Avg: [-538.577 -538.577 -538.577] (1.000)
Step: 33599, Reward: [-671.076 -671.076 -671.076] [0.0000], Avg: [-538.774 -538.774 -538.774] (1.000)
Step: 33649, Reward: [-374.774 -374.774 -374.774] [0.0000], Avg: [-538.531 -538.531 -538.531] (1.000)
Step: 33699, Reward: [-494.285 -494.285 -494.285] [0.0000], Avg: [-538.465 -538.465 -538.465] (1.000)
Step: 33749, Reward: [-502.698 -502.698 -502.698] [0.0000], Avg: [-538.412 -538.412 -538.412] (1.000)
Step: 33799, Reward: [-357.792 -357.792 -357.792] [0.0000], Avg: [-538.145 -538.145 -538.145] (1.000)
Step: 33849, Reward: [-383.466 -383.466 -383.466] [0.0000], Avg: [-537.916 -537.916 -537.916] (1.000)
Step: 33899, Reward: [-441.185 -441.185 -441.185] [0.0000], Avg: [-537.774 -537.774 -537.774] (1.000)
Step: 33949, Reward: [-500.466 -500.466 -500.466] [0.0000], Avg: [-537.719 -537.719 -537.719] (1.000)
Step: 33999, Reward: [-355.958 -355.958 -355.958] [0.0000], Avg: [-537.451 -537.451 -537.451] (1.000)
Step: 34049, Reward: [-336.817 -336.817 -336.817] [0.0000], Avg: [-537.157 -537.157 -537.157] (1.000)
Step: 34099, Reward: [-390.873 -390.873 -390.873] [0.0000], Avg: [-536.942 -536.942 -536.942] (1.000)
Step: 34149, Reward: [-367.988 -367.988 -367.988] [0.0000], Avg: [-536.695 -536.695 -536.695] (1.000)
Step: 34199, Reward: [-371.413 -371.413 -371.413] [0.0000], Avg: [-536.453 -536.453 -536.453] (1.000)
Step: 34249, Reward: [-517.065 -517.065 -517.065] [0.0000], Avg: [-536.425 -536.425 -536.425] (1.000)
Step: 34299, Reward: [-461.7 -461.7 -461.7] [0.0000], Avg: [-536.316 -536.316 -536.316] (1.000)
Step: 34349, Reward: [-533.644 -533.644 -533.644] [0.0000], Avg: [-536.312 -536.312 -536.312] (1.000)
Step: 34399, Reward: [-262.784 -262.784 -262.784] [0.0000], Avg: [-535.915 -535.915 -535.915] (1.000)
Step: 34449, Reward: [-603.291 -603.291 -603.291] [0.0000], Avg: [-536.012 -536.012 -536.012] (1.000)
Step: 34499, Reward: [-421.909 -421.909 -421.909] [0.0000], Avg: [-535.847 -535.847 -535.847] (1.000)
Step: 34549, Reward: [-426.218 -426.218 -426.218] [0.0000], Avg: [-535.688 -535.688 -535.688] (1.000)
Step: 34599, Reward: [-413.818 -413.818 -413.818] [0.0000], Avg: [-535.512 -535.512 -535.512] (1.000)
Step: 34649, Reward: [-416.598 -416.598 -416.598] [0.0000], Avg: [-535.341 -535.341 -535.341] (1.000)
Step: 34699, Reward: [-491.414 -491.414 -491.414] [0.0000], Avg: [-535.277 -535.277 -535.277] (1.000)
Step: 34749, Reward: [-543.245 -543.245 -543.245] [0.0000], Avg: [-535.289 -535.289 -535.289] (1.000)
Step: 34799, Reward: [-342.294 -342.294 -342.294] [0.0000], Avg: [-535.012 -535.012 -535.012] (1.000)
Step: 34849, Reward: [-429.315 -429.315 -429.315] [0.0000], Avg: [-534.86 -534.86 -534.86] (1.000)
Step: 34899, Reward: [-518.527 -518.527 -518.527] [0.0000], Avg: [-534.836 -534.836 -534.836] (1.000)
Step: 34949, Reward: [-439.097 -439.097 -439.097] [0.0000], Avg: [-534.7 -534.7 -534.7] (1.000)
Step: 34999, Reward: [-505.599 -505.599 -505.599] [0.0000], Avg: [-534.658 -534.658 -534.658] (1.000)
Step: 35049, Reward: [-374.217 -374.217 -374.217] [0.0000], Avg: [-534.429 -534.429 -534.429] (1.000)
Step: 35099, Reward: [-448.757 -448.757 -448.757] [0.0000], Avg: [-534.307 -534.307 -534.307] (1.000)
Step: 35149, Reward: [-392.962 -392.962 -392.962] [0.0000], Avg: [-534.106 -534.106 -534.106] (1.000)
Step: 35199, Reward: [-488.175 -488.175 -488.175] [0.0000], Avg: [-534.041 -534.041 -534.041] (1.000)
Step: 35249, Reward: [-373.421 -373.421 -373.421] [0.0000], Avg: [-533.813 -533.813 -533.813] (1.000)
Step: 35299, Reward: [-348.139 -348.139 -348.139] [0.0000], Avg: [-533.55 -533.55 -533.55] (1.000)
Step: 35349, Reward: [-422.71 -422.71 -422.71] [0.0000], Avg: [-533.393 -533.393 -533.393] (1.000)
Step: 35399, Reward: [-353.506 -353.506 -353.506] [0.0000], Avg: [-533.139 -533.139 -533.139] (1.000)
Step: 35449, Reward: [-410.029 -410.029 -410.029] [0.0000], Avg: [-532.965 -532.965 -532.965] (1.000)
Step: 35499, Reward: [-455.647 -455.647 -455.647] [0.0000], Avg: [-532.857 -532.857 -532.857] (1.000)
Step: 35549, Reward: [-344.875 -344.875 -344.875] [0.0000], Avg: [-532.592 -532.592 -532.592] (1.000)
Step: 35599, Reward: [-443.173 -443.173 -443.173] [0.0000], Avg: [-532.467 -532.467 -532.467] (1.000)
Step: 35649, Reward: [-500.744 -500.744 -500.744] [0.0000], Avg: [-532.422 -532.422 -532.422] (1.000)
Step: 35699, Reward: [-442.311 -442.311 -442.311] [0.0000], Avg: [-532.296 -532.296 -532.296] (1.000)
Step: 35749, Reward: [-454.048 -454.048 -454.048] [0.0000], Avg: [-532.186 -532.186 -532.186] (1.000)
Step: 35799, Reward: [-576.478 -576.478 -576.478] [0.0000], Avg: [-532.248 -532.248 -532.248] (1.000)
Step: 35849, Reward: [-375.599 -375.599 -375.599] [0.0000], Avg: [-532.03 -532.03 -532.03] (1.000)
Step: 35899, Reward: [-420.94 -420.94 -420.94] [0.0000], Avg: [-531.875 -531.875 -531.875] (1.000)
Step: 35949, Reward: [-319.493 -319.493 -319.493] [0.0000], Avg: [-531.58 -531.58 -531.58] (1.000)
Step: 35999, Reward: [-481.365 -481.365 -481.365] [0.0000], Avg: [-531.51 -531.51 -531.51] (1.000)
Step: 36049, Reward: [-415.873 -415.873 -415.873] [0.0000], Avg: [-531.35 -531.35 -531.35] (1.000)
Step: 36099, Reward: [-438.663 -438.663 -438.663] [0.0000], Avg: [-531.221 -531.221 -531.221] (1.000)
Step: 36149, Reward: [-424.942 -424.942 -424.942] [0.0000], Avg: [-531.074 -531.074 -531.074] (1.000)
Step: 36199, Reward: [-391.23 -391.23 -391.23] [0.0000], Avg: [-530.881 -530.881 -530.881] (1.000)
Step: 36249, Reward: [-581.019 -581.019 -581.019] [0.0000], Avg: [-530.95 -530.95 -530.95] (1.000)
Step: 36299, Reward: [-433.1 -433.1 -433.1] [0.0000], Avg: [-530.815 -530.815 -530.815] (1.000)
Step: 36349, Reward: [-554.442 -554.442 -554.442] [0.0000], Avg: [-530.848 -530.848 -530.848] (1.000)
Step: 36399, Reward: [-540.277 -540.277 -540.277] [0.0000], Avg: [-530.861 -530.861 -530.861] (1.000)
Step: 36449, Reward: [-437.486 -437.486 -437.486] [0.0000], Avg: [-530.733 -530.733 -530.733] (1.000)
Step: 36499, Reward: [-390.417 -390.417 -390.417] [0.0000], Avg: [-530.541 -530.541 -530.541] (1.000)
Step: 36549, Reward: [-551.762 -551.762 -551.762] [0.0000], Avg: [-530.57 -530.57 -530.57] (1.000)
Step: 36599, Reward: [-378.304 -378.304 -378.304] [0.0000], Avg: [-530.362 -530.362 -530.362] (1.000)
Step: 36649, Reward: [-400.667 -400.667 -400.667] [0.0000], Avg: [-530.185 -530.185 -530.185] (1.000)
Step: 36699, Reward: [-447.664 -447.664 -447.664] [0.0000], Avg: [-530.072 -530.072 -530.072] (1.000)
Step: 36749, Reward: [-363.956 -363.956 -363.956] [0.0000], Avg: [-529.846 -529.846 -529.846] (1.000)
Step: 36799, Reward: [-382.866 -382.866 -382.866] [0.0000], Avg: [-529.647 -529.647 -529.647] (1.000)
Step: 36849, Reward: [-362.452 -362.452 -362.452] [0.0000], Avg: [-529.42 -529.42 -529.42] (1.000)
Step: 36899, Reward: [-357.701 -357.701 -357.701] [0.0000], Avg: [-529.187 -529.187 -529.187] (1.000)
Step: 36949, Reward: [-409.282 -409.282 -409.282] [0.0000], Avg: [-529.025 -529.025 -529.025] (1.000)
Step: 36999, Reward: [-427.108 -427.108 -427.108] [0.0000], Avg: [-528.887 -528.887 -528.887] (1.000)
Step: 37049, Reward: [-397.909 -397.909 -397.909] [0.0000], Avg: [-528.71 -528.71 -528.71] (1.000)
Step: 37099, Reward: [-376.33 -376.33 -376.33] [0.0000], Avg: [-528.505 -528.505 -528.505] (1.000)
Step: 37149, Reward: [-554.733 -554.733 -554.733] [0.0000], Avg: [-528.54 -528.54 -528.54] (1.000)
Step: 37199, Reward: [-304.082 -304.082 -304.082] [0.0000], Avg: [-528.238 -528.238 -528.238] (1.000)
Step: 37249, Reward: [-393.577 -393.577 -393.577] [0.0000], Avg: [-528.058 -528.058 -528.058] (1.000)
Step: 37299, Reward: [-380.222 -380.222 -380.222] [0.0000], Avg: [-527.86 -527.86 -527.86] (1.000)
Step: 37349, Reward: [-317.911 -317.911 -317.911] [0.0000], Avg: [-527.578 -527.578 -527.578] (1.000)
Step: 37399, Reward: [-416.021 -416.021 -416.021] [0.0000], Avg: [-527.429 -527.429 -527.429] (1.000)
Step: 37449, Reward: [-544.141 -544.141 -544.141] [0.0000], Avg: [-527.452 -527.452 -527.452] (1.000)
Step: 37499, Reward: [-298.434 -298.434 -298.434] [0.0000], Avg: [-527.146 -527.146 -527.146] (1.000)
Step: 37549, Reward: [-344.616 -344.616 -344.616] [0.0000], Avg: [-526.903 -526.903 -526.903] (1.000)
Step: 37599, Reward: [-552.99 -552.99 -552.99] [0.0000], Avg: [-526.938 -526.938 -526.938] (1.000)
Step: 37649, Reward: [-383.251 -383.251 -383.251] [0.0000], Avg: [-526.747 -526.747 -526.747] (1.000)
Step: 37699, Reward: [-417.778 -417.778 -417.778] [0.0000], Avg: [-526.603 -526.603 -526.603] (1.000)
Step: 37749, Reward: [-459.199 -459.199 -459.199] [0.0000], Avg: [-526.513 -526.513 -526.513] (1.000)
Step: 37799, Reward: [-423.551 -423.551 -423.551] [0.0000], Avg: [-526.377 -526.377 -526.377] (1.000)
Step: 37849, Reward: [-504.651 -504.651 -504.651] [0.0000], Avg: [-526.348 -526.348 -526.348] (1.000)
Step: 37899, Reward: [-528.626 -528.626 -528.626] [0.0000], Avg: [-526.351 -526.351 -526.351] (1.000)
Step: 37949, Reward: [-433.363 -433.363 -433.363] [0.0000], Avg: [-526.229 -526.229 -526.229] (1.000)
Step: 37999, Reward: [-325.445 -325.445 -325.445] [0.0000], Avg: [-525.965 -525.965 -525.965] (1.000)
Step: 38049, Reward: [-404.562 -404.562 -404.562] [0.0000], Avg: [-525.805 -525.805 -525.805] (1.000)
Step: 38099, Reward: [-425.688 -425.688 -425.688] [0.0000], Avg: [-525.674 -525.674 -525.674] (1.000)
Step: 38149, Reward: [-370.159 -370.159 -370.159] [0.0000], Avg: [-525.47 -525.47 -525.47] (1.000)
Step: 38199, Reward: [-491.939 -491.939 -491.939] [0.0000], Avg: [-525.426 -525.426 -525.426] (1.000)
Step: 38249, Reward: [-395.294 -395.294 -395.294] [0.0000], Avg: [-525.256 -525.256 -525.256] (1.000)
Step: 38299, Reward: [-425.705 -425.705 -425.705] [0.0000], Avg: [-525.126 -525.126 -525.126] (1.000)
Step: 38349, Reward: [-317. -317. -317.] [0.0000], Avg: [-524.855 -524.855 -524.855] (1.000)
Step: 38399, Reward: [-463.914 -463.914 -463.914] [0.0000], Avg: [-524.775 -524.775 -524.775] (1.000)
Step: 38449, Reward: [-416.277 -416.277 -416.277] [0.0000], Avg: [-524.634 -524.634 -524.634] (1.000)
Step: 38499, Reward: [-356.524 -356.524 -356.524] [0.0000], Avg: [-524.416 -524.416 -524.416] (1.000)
Step: 38549, Reward: [-368.141 -368.141 -368.141] [0.0000], Avg: [-524.213 -524.213 -524.213] (1.000)
Step: 38599, Reward: [-430.745 -430.745 -430.745] [0.0000], Avg: [-524.092 -524.092 -524.092] (1.000)
Step: 38649, Reward: [-350.143 -350.143 -350.143] [0.0000], Avg: [-523.867 -523.867 -523.867] (1.000)
Step: 38699, Reward: [-522.211 -522.211 -522.211] [0.0000], Avg: [-523.865 -523.865 -523.865] (1.000)
Step: 38749, Reward: [-525.37 -525.37 -525.37] [0.0000], Avg: [-523.867 -523.867 -523.867] (1.000)
Step: 38799, Reward: [-371.591 -371.591 -371.591] [0.0000], Avg: [-523.671 -523.671 -523.671] (1.000)
Step: 38849, Reward: [-467.213 -467.213 -467.213] [0.0000], Avg: [-523.598 -523.598 -523.598] (1.000)
Step: 38899, Reward: [-464.037 -464.037 -464.037] [0.0000], Avg: [-523.521 -523.521 -523.521] (1.000)
Step: 38949, Reward: [-387.256 -387.256 -387.256] [0.0000], Avg: [-523.347 -523.347 -523.347] (1.000)
Step: 38999, Reward: [-369.118 -369.118 -369.118] [0.0000], Avg: [-523.149 -523.149 -523.149] (1.000)
Step: 39049, Reward: [-537.967 -537.967 -537.967] [0.0000], Avg: [-523.168 -523.168 -523.168] (1.000)
Step: 39099, Reward: [-365.33 -365.33 -365.33] [0.0000], Avg: [-522.966 -522.966 -522.966] (1.000)
Step: 39149, Reward: [-373.295 -373.295 -373.295] [0.0000], Avg: [-522.775 -522.775 -522.775] (1.000)
Step: 39199, Reward: [-390.059 -390.059 -390.059] [0.0000], Avg: [-522.606 -522.606 -522.606] (1.000)
Step: 39249, Reward: [-277.98 -277.98 -277.98] [0.0000], Avg: [-522.294 -522.294 -522.294] (1.000)
Step: 39299, Reward: [-448.67 -448.67 -448.67] [0.0000], Avg: [-522.2 -522.2 -522.2] (1.000)
Step: 39349, Reward: [-308.162 -308.162 -308.162] [0.0000], Avg: [-521.928 -521.928 -521.928] (1.000)
Step: 39399, Reward: [-366.497 -366.497 -366.497] [0.0000], Avg: [-521.731 -521.731 -521.731] (1.000)
Step: 39449, Reward: [-375.174 -375.174 -375.174] [0.0000], Avg: [-521.545 -521.545 -521.545] (1.000)
Step: 39499, Reward: [-543.625 -543.625 -543.625] [0.0000], Avg: [-521.573 -521.573 -521.573] (1.000)
Step: 39549, Reward: [-324.358 -324.358 -324.358] [0.0000], Avg: [-521.324 -521.324 -521.324] (1.000)
Step: 39599, Reward: [-428.918 -428.918 -428.918] [0.0000], Avg: [-521.207 -521.207 -521.207] (1.000)
Step: 39649, Reward: [-321.174 -321.174 -321.174] [0.0000], Avg: [-520.955 -520.955 -520.955] (1.000)
Step: 39699, Reward: [-550.268 -550.268 -550.268] [0.0000], Avg: [-520.992 -520.992 -520.992] (1.000)
Step: 39749, Reward: [-418.812 -418.812 -418.812] [0.0000], Avg: [-520.863 -520.863 -520.863] (1.000)
Step: 39799, Reward: [-363.912 -363.912 -363.912] [0.0000], Avg: [-520.666 -520.666 -520.666] (1.000)
Step: 39849, Reward: [-512.077 -512.077 -512.077] [0.0000], Avg: [-520.655 -520.655 -520.655] (1.000)
Step: 39899, Reward: [-376.772 -376.772 -376.772] [0.0000], Avg: [-520.475 -520.475 -520.475] (1.000)
Step: 39949, Reward: [-443.924 -443.924 -443.924] [0.0000], Avg: [-520.379 -520.379 -520.379] (1.000)
Step: 39999, Reward: [-455.102 -455.102 -455.102] [0.0000], Avg: [-520.298 -520.298 -520.298] (1.000)
Step: 40049, Reward: [-343.681 -343.681 -343.681] [0.0000], Avg: [-520.077 -520.077 -520.077] (1.000)
Step: 40099, Reward: [-471.793 -471.793 -471.793] [0.0000], Avg: [-520.017 -520.017 -520.017] (1.000)
Step: 40149, Reward: [-330.514 -330.514 -330.514] [0.0000], Avg: [-519.781 -519.781 -519.781] (1.000)
Step: 40199, Reward: [-414.36 -414.36 -414.36] [0.0000], Avg: [-519.65 -519.65 -519.65] (1.000)
Step: 40249, Reward: [-462.064 -462.064 -462.064] [0.0000], Avg: [-519.578 -519.578 -519.578] (1.000)
Step: 40299, Reward: [-344.567 -344.567 -344.567] [0.0000], Avg: [-519.361 -519.361 -519.361] (1.000)
Step: 40349, Reward: [-445.371 -445.371 -445.371] [0.0000], Avg: [-519.27 -519.27 -519.27] (1.000)
Step: 40399, Reward: [-398.562 -398.562 -398.562] [0.0000], Avg: [-519.12 -519.12 -519.12] (1.000)
Step: 40449, Reward: [-317.711 -317.711 -317.711] [0.0000], Avg: [-518.871 -518.871 -518.871] (1.000)
Step: 40499, Reward: [-423.17 -423.17 -423.17] [0.0000], Avg: [-518.753 -518.753 -518.753] (1.000)
Step: 40549, Reward: [-370.536 -370.536 -370.536] [0.0000], Avg: [-518.57 -518.57 -518.57] (1.000)
Step: 40599, Reward: [-379.441 -379.441 -379.441] [0.0000], Avg: [-518.399 -518.399 -518.399] (1.000)
Step: 40649, Reward: [-449.613 -449.613 -449.613] [0.0000], Avg: [-518.314 -518.314 -518.314] (1.000)
Step: 40699, Reward: [-386.207 -386.207 -386.207] [0.0000], Avg: [-518.152 -518.152 -518.152] (1.000)
Step: 40749, Reward: [-418.405 -418.405 -418.405] [0.0000], Avg: [-518.03 -518.03 -518.03] (1.000)
Step: 40799, Reward: [-457.086 -457.086 -457.086] [0.0000], Avg: [-517.955 -517.955 -517.955] (1.000)
Step: 40849, Reward: [-410.723 -410.723 -410.723] [0.0000], Avg: [-517.824 -517.824 -517.824] (1.000)
Step: 40899, Reward: [-417.042 -417.042 -417.042] [0.0000], Avg: [-517.7 -517.7 -517.7] (1.000)
Step: 40949, Reward: [-449.676 -449.676 -449.676] [0.0000], Avg: [-517.617 -517.617 -517.617] (1.000)
Step: 40999, Reward: [-286.347 -286.347 -286.347] [0.0000], Avg: [-517.335 -517.335 -517.335] (1.000)
Step: 41049, Reward: [-335.334 -335.334 -335.334] [0.0000], Avg: [-517.114 -517.114 -517.114] (1.000)
Step: 41099, Reward: [-347.628 -347.628 -347.628] [0.0000], Avg: [-516.908 -516.908 -516.908] (1.000)
Step: 41149, Reward: [-387.849 -387.849 -387.849] [0.0000], Avg: [-516.751 -516.751 -516.751] (1.000)
Step: 41199, Reward: [-268.513 -268.513 -268.513] [0.0000], Avg: [-516.449 -516.449 -516.449] (1.000)
Step: 41249, Reward: [-307.069 -307.069 -307.069] [0.0000], Avg: [-516.196 -516.196 -516.196] (1.000)
Step: 41299, Reward: [-333.922 -333.922 -333.922] [0.0000], Avg: [-515.975 -515.975 -515.975] (1.000)
Step: 41349, Reward: [-326.599 -326.599 -326.599] [0.0000], Avg: [-515.746 -515.746 -515.746] (1.000)
Step: 41399, Reward: [-352.63 -352.63 -352.63] [0.0000], Avg: [-515.549 -515.549 -515.549] (1.000)
Step: 41449, Reward: [-465.754 -465.754 -465.754] [0.0000], Avg: [-515.489 -515.489 -515.489] (1.000)
Step: 41499, Reward: [-338.884 -338.884 -338.884] [0.0000], Avg: [-515.276 -515.276 -515.276] (1.000)
Step: 41549, Reward: [-457.051 -457.051 -457.051] [0.0000], Avg: [-515.206 -515.206 -515.206] (1.000)
Step: 41599, Reward: [-461.917 -461.917 -461.917] [0.0000], Avg: [-515.142 -515.142 -515.142] (1.000)
Step: 41649, Reward: [-370.405 -370.405 -370.405] [0.0000], Avg: [-514.968 -514.968 -514.968] (1.000)
Step: 41699, Reward: [-328.605 -328.605 -328.605] [0.0000], Avg: [-514.745 -514.745 -514.745] (1.000)
Step: 41749, Reward: [-340.923 -340.923 -340.923] [0.0000], Avg: [-514.537 -514.537 -514.537] (1.000)
Step: 41799, Reward: [-368.324 -368.324 -368.324] [0.0000], Avg: [-514.362 -514.362 -514.362] (1.000)
Step: 41849, Reward: [-477.39 -477.39 -477.39] [0.0000], Avg: [-514.318 -514.318 -514.318] (1.000)
Step: 41899, Reward: [-469.709 -469.709 -469.709] [0.0000], Avg: [-514.264 -514.264 -514.264] (1.000)
Step: 41949, Reward: [-468.767 -468.767 -468.767] [0.0000], Avg: [-514.21 -514.21 -514.21] (1.000)
Step: 41999, Reward: [-465.633 -465.633 -465.633] [0.0000], Avg: [-514.152 -514.152 -514.152] (1.000)
Step: 42049, Reward: [-432.158 -432.158 -432.158] [0.0000], Avg: [-514.055 -514.055 -514.055] (1.000)
Step: 42099, Reward: [-441.393 -441.393 -441.393] [0.0000], Avg: [-513.969 -513.969 -513.969] (1.000)
Step: 42149, Reward: [-430.644 -430.644 -430.644] [0.0000], Avg: [-513.87 -513.87 -513.87] (1.000)
Step: 42199, Reward: [-376.458 -376.458 -376.458] [0.0000], Avg: [-513.707 -513.707 -513.707] (1.000)
Step: 42249, Reward: [-408.145 -408.145 -408.145] [0.0000], Avg: [-513.582 -513.582 -513.582] (1.000)
Step: 42299, Reward: [-401.129 -401.129 -401.129] [0.0000], Avg: [-513.449 -513.449 -513.449] (1.000)
Step: 42349, Reward: [-298. -298. -298.] [0.0000], Avg: [-513.195 -513.195 -513.195] (1.000)
Step: 42399, Reward: [-511.403 -511.403 -511.403] [0.0000], Avg: [-513.193 -513.193 -513.193] (1.000)
Step: 42449, Reward: [-460.82 -460.82 -460.82] [0.0000], Avg: [-513.131 -513.131 -513.131] (1.000)
Step: 42499, Reward: [-390.43 -390.43 -390.43] [0.0000], Avg: [-512.986 -512.986 -512.986] (1.000)
Step: 42549, Reward: [-297.249 -297.249 -297.249] [0.0000], Avg: [-512.733 -512.733 -512.733] (1.000)
Step: 42599, Reward: [-431.531 -431.531 -431.531] [0.0000], Avg: [-512.638 -512.638 -512.638] (1.000)
Step: 42649, Reward: [-518.122 -518.122 -518.122] [0.0000], Avg: [-512.644 -512.644 -512.644] (1.000)
Step: 42699, Reward: [-389.333 -389.333 -389.333] [0.0000], Avg: [-512.5 -512.5 -512.5] (1.000)
Step: 42749, Reward: [-288.438 -288.438 -288.438] [0.0000], Avg: [-512.238 -512.238 -512.238] (1.000)
Step: 42799, Reward: [-523.395 -523.395 -523.395] [0.0000], Avg: [-512.251 -512.251 -512.251] (1.000)
Step: 42849, Reward: [-449.856 -449.856 -449.856] [0.0000], Avg: [-512.178 -512.178 -512.178] (1.000)
Step: 42899, Reward: [-408.995 -408.995 -408.995] [0.0000], Avg: [-512.058 -512.058 -512.058] (1.000)
Step: 42949, Reward: [-377.629 -377.629 -377.629] [0.0000], Avg: [-511.901 -511.901 -511.901] (1.000)
Step: 42999, Reward: [-498.015 -498.015 -498.015] [0.0000], Avg: [-511.885 -511.885 -511.885] (1.000)
Step: 43049, Reward: [-342.542 -342.542 -342.542] [0.0000], Avg: [-511.688 -511.688 -511.688] (1.000)
Step: 43099, Reward: [-501.382 -501.382 -501.382] [0.0000], Avg: [-511.676 -511.676 -511.676] (1.000)
Step: 43149, Reward: [-341.427 -341.427 -341.427] [0.0000], Avg: [-511.479 -511.479 -511.479] (1.000)
Step: 43199, Reward: [-339.676 -339.676 -339.676] [0.0000], Avg: [-511.28 -511.28 -511.28] (1.000)
Step: 43249, Reward: [-310.394 -310.394 -310.394] [0.0000], Avg: [-511.048 -511.048 -511.048] (1.000)
Step: 43299, Reward: [-480.326 -480.326 -480.326] [0.0000], Avg: [-511.012 -511.012 -511.012] (1.000)
Step: 43349, Reward: [-290.348 -290.348 -290.348] [0.0000], Avg: [-510.758 -510.758 -510.758] (1.000)
Step: 43399, Reward: [-439.384 -439.384 -439.384] [0.0000], Avg: [-510.676 -510.676 -510.676] (1.000)
Step: 43449, Reward: [-385.617 -385.617 -385.617] [0.0000], Avg: [-510.532 -510.532 -510.532] (1.000)
Step: 43499, Reward: [-407.239 -407.239 -407.239] [0.0000], Avg: [-510.413 -510.413 -510.413] (1.000)
Step: 43549, Reward: [-539.606 -539.606 -539.606] [0.0000], Avg: [-510.447 -510.447 -510.447] (1.000)
Step: 43599, Reward: [-366.838 -366.838 -366.838] [0.0000], Avg: [-510.282 -510.282 -510.282] (1.000)
Step: 43649, Reward: [-401.235 -401.235 -401.235] [0.0000], Avg: [-510.157 -510.157 -510.157] (1.000)
Step: 43699, Reward: [-461.393 -461.393 -461.393] [0.0000], Avg: [-510.101 -510.101 -510.101] (1.000)
Step: 43749, Reward: [-398.61 -398.61 -398.61] [0.0000], Avg: [-509.974 -509.974 -509.974] (1.000)
Step: 43799, Reward: [-339.439 -339.439 -339.439] [0.0000], Avg: [-509.779 -509.779 -509.779] (1.000)
Step: 43849, Reward: [-323.865 -323.865 -323.865] [0.0000], Avg: [-509.567 -509.567 -509.567] (1.000)
Step: 43899, Reward: [-380.815 -380.815 -380.815] [0.0000], Avg: [-509.421 -509.421 -509.421] (1.000)
Step: 43949, Reward: [-493.107 -493.107 -493.107] [0.0000], Avg: [-509.402 -509.402 -509.402] (1.000)
Step: 43999, Reward: [-345.852 -345.852 -345.852] [0.0000], Avg: [-509.216 -509.216 -509.216] (1.000)
Step: 44049, Reward: [-296.734 -296.734 -296.734] [0.0000], Avg: [-508.975 -508.975 -508.975] (1.000)
Step: 44099, Reward: [-358. -358. -358.] [0.0000], Avg: [-508.804 -508.804 -508.804] (1.000)
Step: 44149, Reward: [-407.382 -407.382 -407.382] [0.0000], Avg: [-508.689 -508.689 -508.689] (1.000)
Step: 44199, Reward: [-381.012 -381.012 -381.012] [0.0000], Avg: [-508.544 -508.544 -508.544] (1.000)
Step: 44249, Reward: [-392.426 -392.426 -392.426] [0.0000], Avg: [-508.413 -508.413 -508.413] (1.000)
Step: 44299, Reward: [-407.278 -407.278 -407.278] [0.0000], Avg: [-508.299 -508.299 -508.299] (1.000)
Step: 44349, Reward: [-375.788 -375.788 -375.788] [0.0000], Avg: [-508.15 -508.15 -508.15] (1.000)
Step: 44399, Reward: [-378.213 -378.213 -378.213] [0.0000], Avg: [-508.003 -508.003 -508.003] (1.000)
Step: 44449, Reward: [-345.758 -345.758 -345.758] [0.0000], Avg: [-507.821 -507.821 -507.821] (1.000)
Step: 44499, Reward: [-453.074 -453.074 -453.074] [0.0000], Avg: [-507.759 -507.759 -507.759] (1.000)
Step: 44549, Reward: [-383.864 -383.864 -383.864] [0.0000], Avg: [-507.62 -507.62 -507.62] (1.000)
Step: 44599, Reward: [-402.234 -402.234 -402.234] [0.0000], Avg: [-507.502 -507.502 -507.502] (1.000)
Step: 44649, Reward: [-467.439 -467.439 -467.439] [0.0000], Avg: [-507.457 -507.457 -507.457] (1.000)
Step: 44699, Reward: [-348.61 -348.61 -348.61] [0.0000], Avg: [-507.28 -507.28 -507.28] (1.000)
Step: 44749, Reward: [-407.265 -407.265 -407.265] [0.0000], Avg: [-507.168 -507.168 -507.168] (1.000)
Step: 44799, Reward: [-366.306 -366.306 -366.306] [0.0000], Avg: [-507.011 -507.011 -507.011] (1.000)
Step: 44849, Reward: [-466.096 -466.096 -466.096] [0.0000], Avg: [-506.965 -506.965 -506.965] (1.000)
Step: 44899, Reward: [-365.014 -365.014 -365.014] [0.0000], Avg: [-506.807 -506.807 -506.807] (1.000)
Step: 44949, Reward: [-321.38 -321.38 -321.38] [0.0000], Avg: [-506.601 -506.601 -506.601] (1.000)
Step: 44999, Reward: [-522.502 -522.502 -522.502] [0.0000], Avg: [-506.618 -506.618 -506.618] (1.000)
Step: 45049, Reward: [-411.06 -411.06 -411.06] [0.0000], Avg: [-506.512 -506.512 -506.512] (1.000)
Step: 45099, Reward: [-427.661 -427.661 -427.661] [0.0000], Avg: [-506.425 -506.425 -506.425] (1.000)
Step: 45149, Reward: [-465.788 -465.788 -465.788] [0.0000], Avg: [-506.38 -506.38 -506.38] (1.000)
Step: 45199, Reward: [-433.408 -433.408 -433.408] [0.0000], Avg: [-506.299 -506.299 -506.299] (1.000)
Step: 45249, Reward: [-451.05 -451.05 -451.05] [0.0000], Avg: [-506.238 -506.238 -506.238] (1.000)
Step: 45299, Reward: [-394.141 -394.141 -394.141] [0.0000], Avg: [-506.114 -506.114 -506.114] (1.000)
Step: 45349, Reward: [-474.845 -474.845 -474.845] [0.0000], Avg: [-506.08 -506.08 -506.08] (1.000)
Step: 45399, Reward: [-453.794 -453.794 -453.794] [0.0000], Avg: [-506.022 -506.022 -506.022] (1.000)
Step: 45449, Reward: [-410.79 -410.79 -410.79] [0.0000], Avg: [-505.918 -505.918 -505.918] (1.000)
Step: 45499, Reward: [-453.296 -453.296 -453.296] [0.0000], Avg: [-505.86 -505.86 -505.86] (1.000)
Step: 45549, Reward: [-438.181 -438.181 -438.181] [0.0000], Avg: [-505.785 -505.785 -505.785] (1.000)
Step: 45599, Reward: [-363.369 -363.369 -363.369] [0.0000], Avg: [-505.629 -505.629 -505.629] (1.000)
Step: 45649, Reward: [-505.963 -505.963 -505.963] [0.0000], Avg: [-505.63 -505.63 -505.63] (1.000)
Step: 45699, Reward: [-362.606 -362.606 -362.606] [0.0000], Avg: [-505.473 -505.473 -505.473] (1.000)
Step: 45749, Reward: [-508.919 -508.919 -508.919] [0.0000], Avg: [-505.477 -505.477 -505.477] (1.000)
Step: 45799, Reward: [-371.413 -371.413 -371.413] [0.0000], Avg: [-505.331 -505.331 -505.331] (1.000)
Step: 45849, Reward: [-355.774 -355.774 -355.774] [0.0000], Avg: [-505.168 -505.168 -505.168] (1.000)
Step: 45899, Reward: [-333.226 -333.226 -333.226] [0.0000], Avg: [-504.98 -504.98 -504.98] (1.000)
Step: 45949, Reward: [-411.696 -411.696 -411.696] [0.0000], Avg: [-504.879 -504.879 -504.879] (1.000)
Step: 45999, Reward: [-338.674 -338.674 -338.674] [0.0000], Avg: [-504.698 -504.698 -504.698] (1.000)
Step: 46049, Reward: [-357.743 -357.743 -357.743] [0.0000], Avg: [-504.538 -504.538 -504.538] (1.000)
Step: 46099, Reward: [-388.779 -388.779 -388.779] [0.0000], Avg: [-504.413 -504.413 -504.413] (1.000)
Step: 46149, Reward: [-502.029 -502.029 -502.029] [0.0000], Avg: [-504.41 -504.41 -504.41] (1.000)
Step: 46199, Reward: [-392.481 -392.481 -392.481] [0.0000], Avg: [-504.289 -504.289 -504.289] (1.000)
Step: 46249, Reward: [-408.21 -408.21 -408.21] [0.0000], Avg: [-504.185 -504.185 -504.185] (1.000)
Step: 46299, Reward: [-508.01 -508.01 -508.01] [0.0000], Avg: [-504.189 -504.189 -504.189] (1.000)
Step: 46349, Reward: [-442.648 -442.648 -442.648] [0.0000], Avg: [-504.123 -504.123 -504.123] (1.000)
Step: 46399, Reward: [-430.541 -430.541 -430.541] [0.0000], Avg: [-504.044 -504.044 -504.044] (1.000)
Step: 46449, Reward: [-366.49 -366.49 -366.49] [0.0000], Avg: [-503.896 -503.896 -503.896] (1.000)
Step: 46499, Reward: [-406.578 -406.578 -406.578] [0.0000], Avg: [-503.791 -503.791 -503.791] (1.000)
Step: 46549, Reward: [-509.874 -509.874 -509.874] [0.0000], Avg: [-503.798 -503.798 -503.798] (1.000)
Step: 46599, Reward: [-561.816 -561.816 -561.816] [0.0000], Avg: [-503.86 -503.86 -503.86] (1.000)
Step: 46649, Reward: [-377.056 -377.056 -377.056] [0.0000], Avg: [-503.724 -503.724 -503.724] (1.000)
Step: 46699, Reward: [-491.891 -491.891 -491.891] [0.0000], Avg: [-503.711 -503.711 -503.711] (1.000)
Step: 46749, Reward: [-338.985 -338.985 -338.985] [0.0000], Avg: [-503.535 -503.535 -503.535] (1.000)
Step: 46799, Reward: [-444.494 -444.494 -444.494] [0.0000], Avg: [-503.472 -503.472 -503.472] (1.000)
Step: 46849, Reward: [-453.29 -453.29 -453.29] [0.0000], Avg: [-503.418 -503.418 -503.418] (1.000)
Step: 46899, Reward: [-411.696 -411.696 -411.696] [0.0000], Avg: [-503.321 -503.321 -503.321] (1.000)
Step: 46949, Reward: [-427.625 -427.625 -427.625] [0.0000], Avg: [-503.24 -503.24 -503.24] (1.000)
Step: 46999, Reward: [-492.678 -492.678 -492.678] [0.0000], Avg: [-503.229 -503.229 -503.229] (1.000)
Step: 47049, Reward: [-461.474 -461.474 -461.474] [0.0000], Avg: [-503.184 -503.184 -503.184] (1.000)
Step: 47099, Reward: [-378.223 -378.223 -378.223] [0.0000], Avg: [-503.052 -503.052 -503.052] (1.000)
Step: 47149, Reward: [-349.508 -349.508 -349.508] [0.0000], Avg: [-502.889 -502.889 -502.889] (1.000)
Step: 47199, Reward: [-384.363 -384.363 -384.363] [0.0000], Avg: [-502.763 -502.763 -502.763] (1.000)
Step: 47249, Reward: [-438.555 -438.555 -438.555] [0.0000], Avg: [-502.695 -502.695 -502.695] (1.000)
Step: 47299, Reward: [-401.552 -401.552 -401.552] [0.0000], Avg: [-502.589 -502.589 -502.589] (1.000)
Step: 47349, Reward: [-368.474 -368.474 -368.474] [0.0000], Avg: [-502.447 -502.447 -502.447] (1.000)
Step: 47399, Reward: [-461.43 -461.43 -461.43] [0.0000], Avg: [-502.404 -502.404 -502.404] (1.000)
Step: 47449, Reward: [-414.374 -414.374 -414.374] [0.0000], Avg: [-502.311 -502.311 -502.311] (1.000)
Step: 47499, Reward: [-381.631 -381.631 -381.631] [0.0000], Avg: [-502.184 -502.184 -502.184] (1.000)
Step: 47549, Reward: [-445.899 -445.899 -445.899] [0.0000], Avg: [-502.125 -502.125 -502.125] (1.000)
Step: 47599, Reward: [-309.873 -309.873 -309.873] [0.0000], Avg: [-501.923 -501.923 -501.923] (1.000)
Step: 47649, Reward: [-465.15 -465.15 -465.15] [0.0000], Avg: [-501.884 -501.884 -501.884] (1.000)
Step: 47699, Reward: [-338.093 -338.093 -338.093] [0.0000], Avg: [-501.712 -501.712 -501.712] (1.000)
Step: 47749, Reward: [-376.957 -376.957 -376.957] [0.0000], Avg: [-501.582 -501.582 -501.582] (1.000)
Step: 47799, Reward: [-478.739 -478.739 -478.739] [0.0000], Avg: [-501.558 -501.558 -501.558] (1.000)
Step: 47849, Reward: [-423.016 -423.016 -423.016] [0.0000], Avg: [-501.476 -501.476 -501.476] (1.000)
Step: 47899, Reward: [-346.33 -346.33 -346.33] [0.0000], Avg: [-501.314 -501.314 -501.314] (1.000)
Step: 47949, Reward: [-432.008 -432.008 -432.008] [0.0000], Avg: [-501.242 -501.242 -501.242] (1.000)
Step: 47999, Reward: [-359.286 -359.286 -359.286] [0.0000], Avg: [-501.094 -501.094 -501.094] (1.000)
Step: 48049, Reward: [-304.522 -304.522 -304.522] [0.0000], Avg: [-500.889 -500.889 -500.889] (1.000)
Step: 48099, Reward: [-366.117 -366.117 -366.117] [0.0000], Avg: [-500.749 -500.749 -500.749] (1.000)
Step: 48149, Reward: [-520.484 -520.484 -520.484] [0.0000], Avg: [-500.77 -500.77 -500.77] (1.000)
Step: 48199, Reward: [-433.25 -433.25 -433.25] [0.0000], Avg: [-500.7 -500.7 -500.7] (1.000)
Step: 48249, Reward: [-464.402 -464.402 -464.402] [0.0000], Avg: [-500.662 -500.662 -500.662] (1.000)
Step: 48299, Reward: [-415.762 -415.762 -415.762] [0.0000], Avg: [-500.574 -500.574 -500.574] (1.000)
Step: 48349, Reward: [-438.025 -438.025 -438.025] [0.0000], Avg: [-500.509 -500.509 -500.509] (1.000)
Step: 48399, Reward: [-386.737 -386.737 -386.737] [0.0000], Avg: [-500.392 -500.392 -500.392] (1.000)
Step: 48449, Reward: [-512.966 -512.966 -512.966] [0.0000], Avg: [-500.405 -500.405 -500.405] (1.000)
Step: 48499, Reward: [-501.317 -501.317 -501.317] [0.0000], Avg: [-500.406 -500.406 -500.406] (1.000)
Step: 48549, Reward: [-385.014 -385.014 -385.014] [0.0000], Avg: [-500.287 -500.287 -500.287] (1.000)
Step: 48599, Reward: [-458.621 -458.621 -458.621] [0.0000], Avg: [-500.244 -500.244 -500.244] (1.000)
Step: 48649, Reward: [-494.77 -494.77 -494.77] [0.0000], Avg: [-500.238 -500.238 -500.238] (1.000)
Step: 48699, Reward: [-435.065 -435.065 -435.065] [0.0000], Avg: [-500.172 -500.172 -500.172] (1.000)
Step: 48749, Reward: [-374.957 -374.957 -374.957] [0.0000], Avg: [-500.043 -500.043 -500.043] (1.000)
Step: 48799, Reward: [-380.11 -380.11 -380.11] [0.0000], Avg: [-499.92 -499.92 -499.92] (1.000)
Step: 48849, Reward: [-322.543 -322.543 -322.543] [0.0000], Avg: [-499.739 -499.739 -499.739] (1.000)
Step: 48899, Reward: [-387.675 -387.675 -387.675] [0.0000], Avg: [-499.624 -499.624 -499.624] (1.000)
Step: 48949, Reward: [-527.727 -527.727 -527.727] [0.0000], Avg: [-499.653 -499.653 -499.653] (1.000)
Step: 48999, Reward: [-368.034 -368.034 -368.034] [0.0000], Avg: [-499.519 -499.519 -499.519] (1.000)
Step: 49049, Reward: [-382.279 -382.279 -382.279] [0.0000], Avg: [-499.399 -499.399 -499.399] (1.000)
Step: 49099, Reward: [-416.941 -416.941 -416.941] [0.0000], Avg: [-499.315 -499.315 -499.315] (1.000)
Step: 49149, Reward: [-407.843 -407.843 -407.843] [0.0000], Avg: [-499.222 -499.222 -499.222] (1.000)
Step: 49199, Reward: [-523.385 -523.385 -523.385] [0.0000], Avg: [-499.247 -499.247 -499.247] (1.000)
Step: 49249, Reward: [-404.575 -404.575 -404.575] [0.0000], Avg: [-499.15 -499.15 -499.15] (1.000)
Step: 49299, Reward: [-325.043 -325.043 -325.043] [0.0000], Avg: [-498.974 -498.974 -498.974] (1.000)
Step: 49349, Reward: [-422.204 -422.204 -422.204] [0.0000], Avg: [-498.896 -498.896 -498.896] (1.000)
Step: 49399, Reward: [-433.583 -433.583 -433.583] [0.0000], Avg: [-498.83 -498.83 -498.83] (1.000)
Step: 49449, Reward: [-380.691 -380.691 -380.691] [0.0000], Avg: [-498.711 -498.711 -498.711] (1.000)
Step: 49499, Reward: [-374.449 -374.449 -374.449] [0.0000], Avg: [-498.585 -498.585 -498.585] (1.000)
Step: 49549, Reward: [-370.186 -370.186 -370.186] [0.0000], Avg: [-498.455 -498.455 -498.455] (1.000)
Step: 49599, Reward: [-365.611 -365.611 -365.611] [0.0000], Avg: [-498.322 -498.322 -498.322] (1.000)
Step: 49649, Reward: [-426.662 -426.662 -426.662] [0.0000], Avg: [-498.249 -498.249 -498.249] (1.000)
Step: 49699, Reward: [-373.284 -373.284 -373.284] [0.0000], Avg: [-498.124 -498.124 -498.124] (1.000)
Step: 49749, Reward: [-347.53 -347.53 -347.53] [0.0000], Avg: [-497.972 -497.972 -497.972] (1.000)
Step: 49799, Reward: [-405.178 -405.178 -405.178] [0.0000], Avg: [-497.879 -497.879 -497.879] (1.000)
Step: 49849, Reward: [-433.661 -433.661 -433.661] [0.0000], Avg: [-497.815 -497.815 -497.815] (1.000)
Step: 49899, Reward: [-346.339 -346.339 -346.339] [0.0000], Avg: [-497.663 -497.663 -497.663] (1.000)
Step: 49949, Reward: [-437.527 -437.527 -437.527] [0.0000], Avg: [-497.603 -497.603 -497.603] (1.000)
Step: 49999, Reward: [-503.378 -503.378 -503.378] [0.0000], Avg: [-497.608 -497.608 -497.608] (1.000)
Step: 50049, Reward: [-509.27 -509.27 -509.27] [0.0000], Avg: [-497.62 -497.62 -497.62] (1.000)
Step: 50099, Reward: [-365.614 -365.614 -365.614] [0.0000], Avg: [-497.488 -497.488 -497.488] (1.000)
Step: 50149, Reward: [-463.944 -463.944 -463.944] [0.0000], Avg: [-497.455 -497.455 -497.455] (1.000)
Step: 50199, Reward: [-386.473 -386.473 -386.473] [0.0000], Avg: [-497.344 -497.344 -497.344] (1.000)
Step: 50249, Reward: [-369.958 -369.958 -369.958] [0.0000], Avg: [-497.218 -497.218 -497.218] (1.000)
Step: 50299, Reward: [-425.618 -425.618 -425.618] [0.0000], Avg: [-497.146 -497.146 -497.146] (1.000)
Step: 50349, Reward: [-371.977 -371.977 -371.977] [0.0000], Avg: [-497.022 -497.022 -497.022] (1.000)
Step: 50399, Reward: [-460.175 -460.175 -460.175] [0.0000], Avg: [-496.986 -496.986 -496.986] (1.000)
Step: 50449, Reward: [-517.449 -517.449 -517.449] [0.0000], Avg: [-497.006 -497.006 -497.006] (1.000)
Step: 50499, Reward: [-312.442 -312.442 -312.442] [0.0000], Avg: [-496.823 -496.823 -496.823] (1.000)
Step: 50549, Reward: [-475.046 -475.046 -475.046] [0.0000], Avg: [-496.802 -496.802 -496.802] (1.000)
Step: 50599, Reward: [-344.845 -344.845 -344.845] [0.0000], Avg: [-496.651 -496.651 -496.651] (1.000)
Step: 50649, Reward: [-377.392 -377.392 -377.392] [0.0000], Avg: [-496.534 -496.534 -496.534] (1.000)
Step: 50699, Reward: [-341.85 -341.85 -341.85] [0.0000], Avg: [-496.381 -496.381 -496.381] (1.000)
Step: 50749, Reward: [-464.893 -464.893 -464.893] [0.0000], Avg: [-496.35 -496.35 -496.35] (1.000)
Step: 50799, Reward: [-327.397 -327.397 -327.397] [0.0000], Avg: [-496.184 -496.184 -496.184] (1.000)
Step: 50849, Reward: [-485.106 -485.106 -485.106] [0.0000], Avg: [-496.173 -496.173 -496.173] (1.000)
Step: 50899, Reward: [-497.684 -497.684 -497.684] [0.0000], Avg: [-496.174 -496.174 -496.174] (1.000)
Step: 50949, Reward: [-354.165 -354.165 -354.165] [0.0000], Avg: [-496.035 -496.035 -496.035] (1.000)
Step: 50999, Reward: [-450.735 -450.735 -450.735] [0.0000], Avg: [-495.991 -495.991 -495.991] (1.000)
Step: 51049, Reward: [-348.384 -348.384 -348.384] [0.0000], Avg: [-495.846 -495.846 -495.846] (1.000)
Step: 51099, Reward: [-458.858 -458.858 -458.858] [0.0000], Avg: [-495.81 -495.81 -495.81] (1.000)
Step: 51149, Reward: [-537.763 -537.763 -537.763] [0.0000], Avg: [-495.851 -495.851 -495.851] (1.000)
Step: 51199, Reward: [-415.685 -415.685 -415.685] [0.0000], Avg: [-495.773 -495.773 -495.773] (1.000)
Step: 51249, Reward: [-360.765 -360.765 -360.765] [0.0000], Avg: [-495.641 -495.641 -495.641] (1.000)
Step: 51299, Reward: [-419.98 -419.98 -419.98] [0.0000], Avg: [-495.567 -495.567 -495.567] (1.000)
Step: 51349, Reward: [-384.353 -384.353 -384.353] [0.0000], Avg: [-495.459 -495.459 -495.459] (1.000)
Step: 51399, Reward: [-408.653 -408.653 -408.653] [0.0000], Avg: [-495.374 -495.374 -495.374] (1.000)
Step: 51449, Reward: [-359.192 -359.192 -359.192] [0.0000], Avg: [-495.242 -495.242 -495.242] (1.000)
Step: 51499, Reward: [-397.183 -397.183 -397.183] [0.0000], Avg: [-495.147 -495.147 -495.147] (1.000)
Step: 51549, Reward: [-414.403 -414.403 -414.403] [0.0000], Avg: [-495.069 -495.069 -495.069] (1.000)
Step: 51599, Reward: [-376.902 -376.902 -376.902] [0.0000], Avg: [-494.954 -494.954 -494.954] (1.000)
Step: 51649, Reward: [-474.124 -474.124 -474.124] [0.0000], Avg: [-494.934 -494.934 -494.934] (1.000)
Step: 51699, Reward: [-299.758 -299.758 -299.758] [0.0000], Avg: [-494.745 -494.745 -494.745] (1.000)
Step: 51749, Reward: [-288.997 -288.997 -288.997] [0.0000], Avg: [-494.546 -494.546 -494.546] (1.000)
Step: 51799, Reward: [-416.343 -416.343 -416.343] [0.0000], Avg: [-494.471 -494.471 -494.471] (1.000)
Step: 51849, Reward: [-296.68 -296.68 -296.68] [0.0000], Avg: [-494.28 -494.28 -494.28] (1.000)
Step: 51899, Reward: [-463.049 -463.049 -463.049] [0.0000], Avg: [-494.25 -494.25 -494.25] (1.000)
Step: 51949, Reward: [-333.696 -333.696 -333.696] [0.0000], Avg: [-494.096 -494.096 -494.096] (1.000)
Step: 51999, Reward: [-283.568 -283.568 -283.568] [0.0000], Avg: [-493.893 -493.893 -493.893] (1.000)
Step: 52049, Reward: [-399.352 -399.352 -399.352] [0.0000], Avg: [-493.802 -493.802 -493.802] (1.000)
Step: 52099, Reward: [-587.176 -587.176 -587.176] [0.0000], Avg: [-493.892 -493.892 -493.892] (1.000)
Step: 52149, Reward: [-336.148 -336.148 -336.148] [0.0000], Avg: [-493.741 -493.741 -493.741] (1.000)
Step: 52199, Reward: [-365.848 -365.848 -365.848] [0.0000], Avg: [-493.618 -493.618 -493.618] (1.000)
Step: 52249, Reward: [-457.437 -457.437 -457.437] [0.0000], Avg: [-493.584 -493.584 -493.584] (1.000)
Step: 52299, Reward: [-428.173 -428.173 -428.173] [0.0000], Avg: [-493.521 -493.521 -493.521] (1.000)
Step: 52349, Reward: [-361.906 -361.906 -361.906] [0.0000], Avg: [-493.395 -493.395 -493.395] (1.000)
Step: 52399, Reward: [-456.51 -456.51 -456.51] [0.0000], Avg: [-493.36 -493.36 -493.36] (1.000)
Step: 52449, Reward: [-426.503 -426.503 -426.503] [0.0000], Avg: [-493.296 -493.296 -493.296] (1.000)
Step: 52499, Reward: [-389.069 -389.069 -389.069] [0.0000], Avg: [-493.197 -493.197 -493.197] (1.000)
Step: 52549, Reward: [-353.367 -353.367 -353.367] [0.0000], Avg: [-493.064 -493.064 -493.064] (1.000)
Step: 52599, Reward: [-393.155 -393.155 -393.155] [0.0000], Avg: [-492.969 -492.969 -492.969] (1.000)
Step: 52649, Reward: [-375.581 -375.581 -375.581] [0.0000], Avg: [-492.858 -492.858 -492.858] (1.000)
Step: 52699, Reward: [-359.189 -359.189 -359.189] [0.0000], Avg: [-492.731 -492.731 -492.731] (1.000)
Step: 52749, Reward: [-539.573 -539.573 -539.573] [0.0000], Avg: [-492.775 -492.775 -492.775] (1.000)
Step: 52799, Reward: [-411.225 -411.225 -411.225] [0.0000], Avg: [-492.698 -492.698 -492.698] (1.000)
Step: 52849, Reward: [-384.547 -384.547 -384.547] [0.0000], Avg: [-492.596 -492.596 -492.596] (1.000)
Step: 52899, Reward: [-449.729 -449.729 -449.729] [0.0000], Avg: [-492.555 -492.555 -492.555] (1.000)
Step: 52949, Reward: [-379.708 -379.708 -379.708] [0.0000], Avg: [-492.449 -492.449 -492.449] (1.000)
Step: 52999, Reward: [-290.026 -290.026 -290.026] [0.0000], Avg: [-492.258 -492.258 -492.258] (1.000)
Step: 53049, Reward: [-460.821 -460.821 -460.821] [0.0000], Avg: [-492.228 -492.228 -492.228] (1.000)
Step: 53099, Reward: [-285.084 -285.084 -285.084] [0.0000], Avg: [-492.033 -492.033 -492.033] (1.000)
Step: 53149, Reward: [-337.359 -337.359 -337.359] [0.0000], Avg: [-491.887 -491.887 -491.887] (1.000)
Step: 53199, Reward: [-355.383 -355.383 -355.383] [0.0000], Avg: [-491.759 -491.759 -491.759] (1.000)
Step: 53249, Reward: [-456.1 -456.1 -456.1] [0.0000], Avg: [-491.726 -491.726 -491.726] (1.000)
Step: 53299, Reward: [-418.031 -418.031 -418.031] [0.0000], Avg: [-491.657 -491.657 -491.657] (1.000)
Step: 53349, Reward: [-391.389 -391.389 -391.389] [0.0000], Avg: [-491.563 -491.563 -491.563] (1.000)
Step: 53399, Reward: [-319.831 -319.831 -319.831] [0.0000], Avg: [-491.402 -491.402 -491.402] (1.000)
Step: 53449, Reward: [-462.294 -462.294 -462.294] [0.0000], Avg: [-491.375 -491.375 -491.375] (1.000)
Step: 53499, Reward: [-328.297 -328.297 -328.297] [0.0000], Avg: [-491.222 -491.222 -491.222] (1.000)
Step: 53549, Reward: [-483.14 -483.14 -483.14] [0.0000], Avg: [-491.215 -491.215 -491.215] (1.000)
Step: 53599, Reward: [-599.164 -599.164 -599.164] [0.0000], Avg: [-491.315 -491.315 -491.315] (1.000)
Step: 53649, Reward: [-379.243 -379.243 -379.243] [0.0000], Avg: [-491.211 -491.211 -491.211] (1.000)
Step: 53699, Reward: [-416.343 -416.343 -416.343] [0.0000], Avg: [-491.141 -491.141 -491.141] (1.000)
Step: 53749, Reward: [-371.19 -371.19 -371.19] [0.0000], Avg: [-491.03 -491.03 -491.03] (1.000)
Step: 53799, Reward: [-331.981 -331.981 -331.981] [0.0000], Avg: [-490.882 -490.882 -490.882] (1.000)
Step: 53849, Reward: [-407.897 -407.897 -407.897] [0.0000], Avg: [-490.805 -490.805 -490.805] (1.000)
Step: 53899, Reward: [-287.06 -287.06 -287.06] [0.0000], Avg: [-490.616 -490.616 -490.616] (1.000)
Step: 53949, Reward: [-352.897 -352.897 -352.897] [0.0000], Avg: [-490.488 -490.488 -490.488] (1.000)
Step: 53999, Reward: [-479.379 -479.379 -479.379] [0.0000], Avg: [-490.478 -490.478 -490.478] (1.000)
Step: 54049, Reward: [-365.506 -365.506 -365.506] [0.0000], Avg: [-490.362 -490.362 -490.362] (1.000)
Step: 54099, Reward: [-493.52 -493.52 -493.52] [0.0000], Avg: [-490.365 -490.365 -490.365] (1.000)
Step: 54149, Reward: [-357.921 -357.921 -357.921] [0.0000], Avg: [-490.243 -490.243 -490.243] (1.000)
Step: 54199, Reward: [-545.168 -545.168 -545.168] [0.0000], Avg: [-490.293 -490.293 -490.293] (1.000)
Step: 54249, Reward: [-373.867 -373.867 -373.867] [0.0000], Avg: [-490.186 -490.186 -490.186] (1.000)
Step: 54299, Reward: [-296.799 -296.799 -296.799] [0.0000], Avg: [-490.008 -490.008 -490.008] (1.000)
Step: 54349, Reward: [-341.995 -341.995 -341.995] [0.0000], Avg: [-489.872 -489.872 -489.872] (1.000)
Step: 54399, Reward: [-372.543 -372.543 -372.543] [0.0000], Avg: [-489.764 -489.764 -489.764] (1.000)
Step: 54449, Reward: [-323.11 -323.11 -323.11] [0.0000], Avg: [-489.611 -489.611 -489.611] (1.000)
Step: 54499, Reward: [-483.202 -483.202 -483.202] [0.0000], Avg: [-489.605 -489.605 -489.605] (1.000)
Step: 54549, Reward: [-436.109 -436.109 -436.109] [0.0000], Avg: [-489.556 -489.556 -489.556] (1.000)
Step: 54599, Reward: [-359.286 -359.286 -359.286] [0.0000], Avg: [-489.437 -489.437 -489.437] (1.000)
Step: 54649, Reward: [-398.636 -398.636 -398.636] [0.0000], Avg: [-489.354 -489.354 -489.354] (1.000)
Step: 54699, Reward: [-315.625 -315.625 -315.625] [0.0000], Avg: [-489.195 -489.195 -489.195] (1.000)
Step: 54749, Reward: [-381.603 -381.603 -381.603] [0.0000], Avg: [-489.097 -489.097 -489.097] (1.000)
Step: 54799, Reward: [-595.13 -595.13 -595.13] [0.0000], Avg: [-489.193 -489.193 -489.193] (1.000)
Step: 54849, Reward: [-514.689 -514.689 -514.689] [0.0000], Avg: [-489.217 -489.217 -489.217] (1.000)
Step: 54899, Reward: [-306.67 -306.67 -306.67] [0.0000], Avg: [-489.05 -489.05 -489.05] (1.000)
Step: 54949, Reward: [-316.088 -316.088 -316.088] [0.0000], Avg: [-488.893 -488.893 -488.893] (1.000)
Step: 54999, Reward: [-365.877 -365.877 -365.877] [0.0000], Avg: [-488.781 -488.781 -488.781] (1.000)
Step: 55049, Reward: [-416.265 -416.265 -416.265] [0.0000], Avg: [-488.715 -488.715 -488.715] (1.000)
Step: 55099, Reward: [-376.935 -376.935 -376.935] [0.0000], Avg: [-488.614 -488.614 -488.614] (1.000)
Step: 55149, Reward: [-357.066 -357.066 -357.066] [0.0000], Avg: [-488.495 -488.495 -488.495] (1.000)
Step: 55199, Reward: [-401.822 -401.822 -401.822] [0.0000], Avg: [-488.416 -488.416 -488.416] (1.000)
Step: 55249, Reward: [-298.669 -298.669 -298.669] [0.0000], Avg: [-488.244 -488.244 -488.244] (1.000)
Step: 55299, Reward: [-297.429 -297.429 -297.429] [0.0000], Avg: [-488.072 -488.072 -488.072] (1.000)
Step: 55349, Reward: [-306.798 -306.798 -306.798] [0.0000], Avg: [-487.908 -487.908 -487.908] (1.000)
Step: 55399, Reward: [-388.778 -388.778 -388.778] [0.0000], Avg: [-487.819 -487.819 -487.819] (1.000)
Step: 55449, Reward: [-375.185 -375.185 -375.185] [0.0000], Avg: [-487.717 -487.717 -487.717] (1.000)
Step: 55499, Reward: [-411.951 -411.951 -411.951] [0.0000], Avg: [-487.649 -487.649 -487.649] (1.000)
Step: 55549, Reward: [-368.764 -368.764 -368.764] [0.0000], Avg: [-487.542 -487.542 -487.542] (1.000)
Step: 55599, Reward: [-406.589 -406.589 -406.589] [0.0000], Avg: [-487.469 -487.469 -487.469] (1.000)
Step: 55649, Reward: [-300.362 -300.362 -300.362] [0.0000], Avg: [-487.301 -487.301 -487.301] (1.000)
Step: 55699, Reward: [-378.219 -378.219 -378.219] [0.0000], Avg: [-487.203 -487.203 -487.203] (1.000)
Step: 55749, Reward: [-424.689 -424.689 -424.689] [0.0000], Avg: [-487.147 -487.147 -487.147] (1.000)
Step: 55799, Reward: [-419.559 -419.559 -419.559] [0.0000], Avg: [-487.086 -487.086 -487.086] (1.000)
Step: 55849, Reward: [-430.59 -430.59 -430.59] [0.0000], Avg: [-487.036 -487.036 -487.036] (1.000)
Step: 55899, Reward: [-500.902 -500.902 -500.902] [0.0000], Avg: [-487.048 -487.048 -487.048] (1.000)
Step: 55949, Reward: [-411.814 -411.814 -411.814] [0.0000], Avg: [-486.981 -486.981 -486.981] (1.000)
Step: 55999, Reward: [-398.415 -398.415 -398.415] [0.0000], Avg: [-486.902 -486.902 -486.902] (1.000)
Step: 56049, Reward: [-444.718 -444.718 -444.718] [0.0000], Avg: [-486.864 -486.864 -486.864] (1.000)
Step: 56099, Reward: [-369.003 -369.003 -369.003] [0.0000], Avg: [-486.759 -486.759 -486.759] (1.000)
Step: 56149, Reward: [-416.176 -416.176 -416.176] [0.0000], Avg: [-486.696 -486.696 -486.696] (1.000)
Step: 56199, Reward: [-565.183 -565.183 -565.183] [0.0000], Avg: [-486.766 -486.766 -486.766] (1.000)
Step: 56249, Reward: [-443.993 -443.993 -443.993] [0.0000], Avg: [-486.728 -486.728 -486.728] (1.000)
Step: 56299, Reward: [-379.149 -379.149 -379.149] [0.0000], Avg: [-486.633 -486.633 -486.633] (1.000)
Step: 56349, Reward: [-407.126 -407.126 -407.126] [0.0000], Avg: [-486.562 -486.562 -486.562] (1.000)
Step: 56399, Reward: [-325.58 -325.58 -325.58] [0.0000], Avg: [-486.419 -486.419 -486.419] (1.000)
Step: 56449, Reward: [-370.336 -370.336 -370.336] [0.0000], Avg: [-486.317 -486.317 -486.317] (1.000)
Step: 56499, Reward: [-378.557 -378.557 -378.557] [0.0000], Avg: [-486.221 -486.221 -486.221] (1.000)
Step: 56549, Reward: [-336.693 -336.693 -336.693] [0.0000], Avg: [-486.089 -486.089 -486.089] (1.000)
Step: 56599, Reward: [-271.337 -271.337 -271.337] [0.0000], Avg: [-485.899 -485.899 -485.899] (1.000)
Step: 56649, Reward: [-392.191 -392.191 -392.191] [0.0000], Avg: [-485.817 -485.817 -485.817] (1.000)
Step: 56699, Reward: [-289.47 -289.47 -289.47] [0.0000], Avg: [-485.643 -485.643 -485.643] (1.000)
Step: 56749, Reward: [-405.179 -405.179 -405.179] [0.0000], Avg: [-485.573 -485.573 -485.573] (1.000)
Step: 56799, Reward: [-338.617 -338.617 -338.617] [0.0000], Avg: [-485.443 -485.443 -485.443] (1.000)
Step: 56849, Reward: [-443.118 -443.118 -443.118] [0.0000], Avg: [-485.406 -485.406 -485.406] (1.000)
Step: 56899, Reward: [-394.396 -394.396 -394.396] [0.0000], Avg: [-485.326 -485.326 -485.326] (1.000)
Step: 56949, Reward: [-439.637 -439.637 -439.637] [0.0000], Avg: [-485.286 -485.286 -485.286] (1.000)
Step: 56999, Reward: [-413.079 -413.079 -413.079] [0.0000], Avg: [-485.223 -485.223 -485.223] (1.000)
Step: 57049, Reward: [-302.373 -302.373 -302.373] [0.0000], Avg: [-485.062 -485.062 -485.062] (1.000)
Step: 57099, Reward: [-403.207 -403.207 -403.207] [0.0000], Avg: [-484.991 -484.991 -484.991] (1.000)
Step: 57149, Reward: [-330.043 -330.043 -330.043] [0.0000], Avg: [-484.855 -484.855 -484.855] (1.000)
Step: 57199, Reward: [-484.663 -484.663 -484.663] [0.0000], Avg: [-484.855 -484.855 -484.855] (1.000)
Step: 57249, Reward: [-384.197 -384.197 -384.197] [0.0000], Avg: [-484.767 -484.767 -484.767] (1.000)
Step: 57299, Reward: [-355.507 -355.507 -355.507] [0.0000], Avg: [-484.654 -484.654 -484.654] (1.000)
Step: 57349, Reward: [-252.806 -252.806 -252.806] [0.0000], Avg: [-484.452 -484.452 -484.452] (1.000)
Step: 57399, Reward: [-519.344 -519.344 -519.344] [0.0000], Avg: [-484.482 -484.482 -484.482] (1.000)
Step: 57449, Reward: [-271.915 -271.915 -271.915] [0.0000], Avg: [-484.297 -484.297 -484.297] (1.000)
Step: 57499, Reward: [-355.714 -355.714 -355.714] [0.0000], Avg: [-484.186 -484.186 -484.186] (1.000)
Step: 57549, Reward: [-399.404 -399.404 -399.404] [0.0000], Avg: [-484.112 -484.112 -484.112] (1.000)
Step: 57599, Reward: [-321.868 -321.868 -321.868] [0.0000], Avg: [-483.971 -483.971 -483.971] (1.000)
Step: 57649, Reward: [-431.794 -431.794 -431.794] [0.0000], Avg: [-483.926 -483.926 -483.926] (1.000)
Step: 57699, Reward: [-425.246 -425.246 -425.246] [0.0000], Avg: [-483.875 -483.875 -483.875] (1.000)
Step: 57749, Reward: [-516.129 -516.129 -516.129] [0.0000], Avg: [-483.903 -483.903 -483.903] (1.000)
Step: 57799, Reward: [-404.24 -404.24 -404.24] [0.0000], Avg: [-483.834 -483.834 -483.834] (1.000)
Step: 57849, Reward: [-387.691 -387.691 -387.691] [0.0000], Avg: [-483.751 -483.751 -483.751] (1.000)
Step: 57899, Reward: [-333.073 -333.073 -333.073] [0.0000], Avg: [-483.621 -483.621 -483.621] (1.000)
Step: 57949, Reward: [-546.756 -546.756 -546.756] [0.0000], Avg: [-483.675 -483.675 -483.675] (1.000)
Step: 57999, Reward: [-533.239 -533.239 -533.239] [0.0000], Avg: [-483.718 -483.718 -483.718] (1.000)
Step: 58049, Reward: [-463.181 -463.181 -463.181] [0.0000], Avg: [-483.7 -483.7 -483.7] (1.000)
Step: 58099, Reward: [-424.547 -424.547 -424.547] [0.0000], Avg: [-483.649 -483.649 -483.649] (1.000)
Step: 58149, Reward: [-394.341 -394.341 -394.341] [0.0000], Avg: [-483.573 -483.573 -483.573] (1.000)
Step: 58199, Reward: [-427.305 -427.305 -427.305] [0.0000], Avg: [-483.524 -483.524 -483.524] (1.000)
Step: 58249, Reward: [-529.102 -529.102 -529.102] [0.0000], Avg: [-483.563 -483.563 -483.563] (1.000)
Step: 58299, Reward: [-344.463 -344.463 -344.463] [0.0000], Avg: [-483.444 -483.444 -483.444] (1.000)
Step: 58349, Reward: [-365.027 -365.027 -365.027] [0.0000], Avg: [-483.343 -483.343 -483.343] (1.000)
Step: 58399, Reward: [-439.908 -439.908 -439.908] [0.0000], Avg: [-483.305 -483.305 -483.305] (1.000)
Step: 58449, Reward: [-476.066 -476.066 -476.066] [0.0000], Avg: [-483.299 -483.299 -483.299] (1.000)
Step: 58499, Reward: [-358.736 -358.736 -358.736] [0.0000], Avg: [-483.193 -483.193 -483.193] (1.000)
Step: 58549, Reward: [-411.244 -411.244 -411.244] [0.0000], Avg: [-483.131 -483.131 -483.131] (1.000)
Step: 58599, Reward: [-386.502 -386.502 -386.502] [0.0000], Avg: [-483.049 -483.049 -483.049] (1.000)
Step: 58649, Reward: [-395.236 -395.236 -395.236] [0.0000], Avg: [-482.974 -482.974 -482.974] (1.000)
Step: 58699, Reward: [-401.873 -401.873 -401.873] [0.0000], Avg: [-482.905 -482.905 -482.905] (1.000)
Step: 58749, Reward: [-529.392 -529.392 -529.392] [0.0000], Avg: [-482.945 -482.945 -482.945] (1.000)
Step: 58799, Reward: [-375.629 -375.629 -375.629] [0.0000], Avg: [-482.853 -482.853 -482.853] (1.000)
Step: 58849, Reward: [-354.106 -354.106 -354.106] [0.0000], Avg: [-482.744 -482.744 -482.744] (1.000)
Step: 58899, Reward: [-399.37 -399.37 -399.37] [0.0000], Avg: [-482.673 -482.673 -482.673] (1.000)
Step: 58949, Reward: [-315.469 -315.469 -315.469] [0.0000], Avg: [-482.531 -482.531 -482.531] (1.000)
Step: 58999, Reward: [-377.23 -377.23 -377.23] [0.0000], Avg: [-482.442 -482.442 -482.442] (1.000)
Step: 59049, Reward: [-292.006 -292.006 -292.006] [0.0000], Avg: [-482.281 -482.281 -482.281] (1.000)
Step: 59099, Reward: [-393.739 -393.739 -393.739] [0.0000], Avg: [-482.206 -482.206 -482.206] (1.000)
Step: 59149, Reward: [-303.214 -303.214 -303.214] [0.0000], Avg: [-482.055 -482.055 -482.055] (1.000)
Step: 59199, Reward: [-501.392 -501.392 -501.392] [0.0000], Avg: [-482.071 -482.071 -482.071] (1.000)
Step: 59249, Reward: [-407.072 -407.072 -407.072] [0.0000], Avg: [-482.008 -482.008 -482.008] (1.000)
Step: 59299, Reward: [-339.735 -339.735 -339.735] [0.0000], Avg: [-481.888 -481.888 -481.888] (1.000)
Step: 59349, Reward: [-412.636 -412.636 -412.636] [0.0000], Avg: [-481.829 -481.829 -481.829] (1.000)
Step: 59399, Reward: [-251.735 -251.735 -251.735] [0.0000], Avg: [-481.636 -481.636 -481.636] (1.000)
Step: 59449, Reward: [-482.342 -482.342 -482.342] [0.0000], Avg: [-481.636 -481.636 -481.636] (1.000)
Step: 59499, Reward: [-456.574 -456.574 -456.574] [0.0000], Avg: [-481.615 -481.615 -481.615] (1.000)
Step: 59549, Reward: [-372.93 -372.93 -372.93] [0.0000], Avg: [-481.524 -481.524 -481.524] (1.000)
Step: 59599, Reward: [-436.091 -436.091 -436.091] [0.0000], Avg: [-481.486 -481.486 -481.486] (1.000)
Step: 59649, Reward: [-435.805 -435.805 -435.805] [0.0000], Avg: [-481.447 -481.447 -481.447] (1.000)
Step: 59699, Reward: [-414.506 -414.506 -414.506] [0.0000], Avg: [-481.391 -481.391 -481.391] (1.000)
Step: 59749, Reward: [-420.317 -420.317 -420.317] [0.0000], Avg: [-481.34 -481.34 -481.34] (1.000)
Step: 59799, Reward: [-336.512 -336.512 -336.512] [0.0000], Avg: [-481.219 -481.219 -481.219] (1.000)
Step: 59849, Reward: [-429.296 -429.296 -429.296] [0.0000], Avg: [-481.176 -481.176 -481.176] (1.000)
Step: 59899, Reward: [-480.456 -480.456 -480.456] [0.0000], Avg: [-481.175 -481.175 -481.175] (1.000)
Step: 59949, Reward: [-350.229 -350.229 -350.229] [0.0000], Avg: [-481.066 -481.066 -481.066] (1.000)
Step: 59999, Reward: [-328.032 -328.032 -328.032] [0.0000], Avg: [-480.939 -480.939 -480.939] (1.000)
Step: 60049, Reward: [-379.28 -379.28 -379.28] [0.0000], Avg: [-480.854 -480.854 -480.854] (1.000)
Step: 60099, Reward: [-405.717 -405.717 -405.717] [0.0000], Avg: [-480.791 -480.791 -480.791] (1.000)
Step: 60149, Reward: [-451.089 -451.089 -451.089] [0.0000], Avg: [-480.767 -480.767 -480.767] (1.000)
Step: 60199, Reward: [-357.548 -357.548 -357.548] [0.0000], Avg: [-480.664 -480.664 -480.664] (1.000)
Step: 60249, Reward: [-404.133 -404.133 -404.133] [0.0000], Avg: [-480.601 -480.601 -480.601] (1.000)
Step: 60299, Reward: [-357.236 -357.236 -357.236] [0.0000], Avg: [-480.499 -480.499 -480.499] (1.000)
Step: 60349, Reward: [-353.672 -353.672 -353.672] [0.0000], Avg: [-480.393 -480.393 -480.393] (1.000)
Step: 60399, Reward: [-367.172 -367.172 -367.172] [0.0000], Avg: [-480.3 -480.3 -480.3] (1.000)
Step: 60449, Reward: [-391.479 -391.479 -391.479] [0.0000], Avg: [-480.226 -480.226 -480.226] (1.000)
Step: 60499, Reward: [-365.376 -365.376 -365.376] [0.0000], Avg: [-480.131 -480.131 -480.131] (1.000)
Step: 60549, Reward: [-374.943 -374.943 -374.943] [0.0000], Avg: [-480.044 -480.044 -480.044] (1.000)
Step: 60599, Reward: [-406.544 -406.544 -406.544] [0.0000], Avg: [-479.984 -479.984 -479.984] (1.000)
Step: 60649, Reward: [-437.172 -437.172 -437.172] [0.0000], Avg: [-479.949 -479.949 -479.949] (1.000)
Step: 60699, Reward: [-389.62 -389.62 -389.62] [0.0000], Avg: [-479.874 -479.874 -479.874] (1.000)
Step: 60749, Reward: [-318.564 -318.564 -318.564] [0.0000], Avg: [-479.741 -479.741 -479.741] (1.000)
Step: 60799, Reward: [-371.861 -371.861 -371.861] [0.0000], Avg: [-479.653 -479.653 -479.653] (1.000)
Step: 60849, Reward: [-511.456 -511.456 -511.456] [0.0000], Avg: [-479.679 -479.679 -479.679] (1.000)
Step: 60899, Reward: [-380.776 -380.776 -380.776] [0.0000], Avg: [-479.598 -479.598 -479.598] (1.000)
Step: 60949, Reward: [-387.23 -387.23 -387.23] [0.0000], Avg: [-479.522 -479.522 -479.522] (1.000)
Step: 60999, Reward: [-400.749 -400.749 -400.749] [0.0000], Avg: [-479.457 -479.457 -479.457] (1.000)
Step: 61049, Reward: [-425.463 -425.463 -425.463] [0.0000], Avg: [-479.413 -479.413 -479.413] (1.000)
Step: 61099, Reward: [-406.269 -406.269 -406.269] [0.0000], Avg: [-479.353 -479.353 -479.353] (1.000)
Step: 61149, Reward: [-321.51 -321.51 -321.51] [0.0000], Avg: [-479.224 -479.224 -479.224] (1.000)
Step: 61199, Reward: [-326.621 -326.621 -326.621] [0.0000], Avg: [-479.099 -479.099 -479.099] (1.000)
Step: 61249, Reward: [-398.154 -398.154 -398.154] [0.0000], Avg: [-479.033 -479.033 -479.033] (1.000)
Step: 61299, Reward: [-331.184 -331.184 -331.184] [0.0000], Avg: [-478.913 -478.913 -478.913] (1.000)
Step: 61349, Reward: [-454.768 -454.768 -454.768] [0.0000], Avg: [-478.893 -478.893 -478.893] (1.000)
Step: 61399, Reward: [-474.63 -474.63 -474.63] [0.0000], Avg: [-478.89 -478.89 -478.89] (1.000)
Step: 61449, Reward: [-365.675 -365.675 -365.675] [0.0000], Avg: [-478.797 -478.797 -478.797] (1.000)
Step: 61499, Reward: [-405.281 -405.281 -405.281] [0.0000], Avg: [-478.738 -478.738 -478.738] (1.000)
Step: 61549, Reward: [-425.165 -425.165 -425.165] [0.0000], Avg: [-478.694 -478.694 -478.694] (1.000)
Step: 61599, Reward: [-380.095 -380.095 -380.095] [0.0000], Avg: [-478.614 -478.614 -478.614] (1.000)
Step: 61649, Reward: [-439.329 -439.329 -439.329] [0.0000], Avg: [-478.582 -478.582 -478.582] (1.000)
Step: 61699, Reward: [-314.7 -314.7 -314.7] [0.0000], Avg: [-478.449 -478.449 -478.449] (1.000)
Step: 61749, Reward: [-348.597 -348.597 -348.597] [0.0000], Avg: [-478.344 -478.344 -478.344] (1.000)
Step: 61799, Reward: [-512.59 -512.59 -512.59] [0.0000], Avg: [-478.372 -478.372 -478.372] (1.000)
Step: 61849, Reward: [-341.152 -341.152 -341.152] [0.0000], Avg: [-478.261 -478.261 -478.261] (1.000)
Step: 61899, Reward: [-423.912 -423.912 -423.912] [0.0000], Avg: [-478.217 -478.217 -478.217] (1.000)
Step: 61949, Reward: [-421.718 -421.718 -421.718] [0.0000], Avg: [-478.172 -478.172 -478.172] (1.000)
Step: 61999, Reward: [-414.104 -414.104 -414.104] [0.0000], Avg: [-478.12 -478.12 -478.12] (1.000)
Step: 62049, Reward: [-469.675 -469.675 -469.675] [0.0000], Avg: [-478.113 -478.113 -478.113] (1.000)
Step: 62099, Reward: [-365.574 -365.574 -365.574] [0.0000], Avg: [-478.023 -478.023 -478.023] (1.000)
Step: 62149, Reward: [-379.731 -379.731 -379.731] [0.0000], Avg: [-477.943 -477.943 -477.943] (1.000)
Step: 62199, Reward: [-465.083 -465.083 -465.083] [0.0000], Avg: [-477.933 -477.933 -477.933] (1.000)
Step: 62249, Reward: [-405.299 -405.299 -405.299] [0.0000], Avg: [-477.875 -477.875 -477.875] (1.000)
Step: 62299, Reward: [-361.985 -361.985 -361.985] [0.0000], Avg: [-477.782 -477.782 -477.782] (1.000)
Step: 62349, Reward: [-343.27 -343.27 -343.27] [0.0000], Avg: [-477.674 -477.674 -477.674] (1.000)
Step: 62399, Reward: [-467.224 -467.224 -467.224] [0.0000], Avg: [-477.666 -477.666 -477.666] (1.000)
Step: 62449, Reward: [-441.698 -441.698 -441.698] [0.0000], Avg: [-477.637 -477.637 -477.637] (1.000)
Step: 62499, Reward: [-410.192 -410.192 -410.192] [0.0000], Avg: [-477.583 -477.583 -477.583] (1.000)
Step: 62549, Reward: [-290.272 -290.272 -290.272] [0.0000], Avg: [-477.433 -477.433 -477.433] (1.000)
Step: 62599, Reward: [-326.286 -326.286 -326.286] [0.0000], Avg: [-477.312 -477.312 -477.312] (1.000)
Step: 62649, Reward: [-422.857 -422.857 -422.857] [0.0000], Avg: [-477.269 -477.269 -477.269] (1.000)
Step: 62699, Reward: [-415.322 -415.322 -415.322] [0.0000], Avg: [-477.219 -477.219 -477.219] (1.000)
Step: 62749, Reward: [-289.278 -289.278 -289.278] [0.0000], Avg: [-477.07 -477.07 -477.07] (1.000)
Step: 62799, Reward: [-415.611 -415.611 -415.611] [0.0000], Avg: [-477.021 -477.021 -477.021] (1.000)
Step: 62849, Reward: [-407.764 -407.764 -407.764] [0.0000], Avg: [-476.966 -476.966 -476.966] (1.000)
Step: 62899, Reward: [-287.442 -287.442 -287.442] [0.0000], Avg: [-476.815 -476.815 -476.815] (1.000)
Step: 62949, Reward: [-535.616 -535.616 -535.616] [0.0000], Avg: [-476.862 -476.862 -476.862] (1.000)
Step: 62999, Reward: [-483.876 -483.876 -483.876] [0.0000], Avg: [-476.867 -476.867 -476.867] (1.000)
Step: 63049, Reward: [-375.784 -375.784 -375.784] [0.0000], Avg: [-476.787 -476.787 -476.787] (1.000)
Step: 63099, Reward: [-521.079 -521.079 -521.079] [0.0000], Avg: [-476.822 -476.822 -476.822] (1.000)
Step: 63149, Reward: [-322.236 -322.236 -322.236] [0.0000], Avg: [-476.7 -476.7 -476.7] (1.000)
Step: 63199, Reward: [-366.188 -366.188 -366.188] [0.0000], Avg: [-476.612 -476.612 -476.612] (1.000)
Step: 63249, Reward: [-427.202 -427.202 -427.202] [0.0000], Avg: [-476.573 -476.573 -476.573] (1.000)
Step: 63299, Reward: [-379.142 -379.142 -379.142] [0.0000], Avg: [-476.496 -476.496 -476.496] (1.000)
Step: 63349, Reward: [-460.558 -460.558 -460.558] [0.0000], Avg: [-476.484 -476.484 -476.484] (1.000)
Step: 63399, Reward: [-404.194 -404.194 -404.194] [0.0000], Avg: [-476.427 -476.427 -476.427] (1.000)
Step: 63449, Reward: [-512.029 -512.029 -512.029] [0.0000], Avg: [-476.455 -476.455 -476.455] (1.000)
Step: 63499, Reward: [-417.278 -417.278 -417.278] [0.0000], Avg: [-476.408 -476.408 -476.408] (1.000)
Step: 63549, Reward: [-348.925 -348.925 -348.925] [0.0000], Avg: [-476.308 -476.308 -476.308] (1.000)
Step: 63599, Reward: [-305.069 -305.069 -305.069] [0.0000], Avg: [-476.173 -476.173 -476.173] (1.000)
Step: 63649, Reward: [-416.201 -416.201 -416.201] [0.0000], Avg: [-476.126 -476.126 -476.126] (1.000)
Step: 63699, Reward: [-349.87 -349.87 -349.87] [0.0000], Avg: [-476.027 -476.027 -476.027] (1.000)
Step: 63749, Reward: [-317.129 -317.129 -317.129] [0.0000], Avg: [-475.902 -475.902 -475.902] (1.000)
Step: 63799, Reward: [-459.285 -459.285 -459.285] [0.0000], Avg: [-475.889 -475.889 -475.889] (1.000)
Step: 63849, Reward: [-405.259 -405.259 -405.259] [0.0000], Avg: [-475.834 -475.834 -475.834] (1.000)
Step: 63899, Reward: [-412.577 -412.577 -412.577] [0.0000], Avg: [-475.785 -475.785 -475.785] (1.000)
Step: 63949, Reward: [-466.709 -466.709 -466.709] [0.0000], Avg: [-475.778 -475.778 -475.778] (1.000)
Step: 63999, Reward: [-339.299 -339.299 -339.299] [0.0000], Avg: [-475.671 -475.671 -475.671] (1.000)
Step: 64049, Reward: [-358.01 -358.01 -358.01] [0.0000], Avg: [-475.579 -475.579 -475.579] (1.000)
Step: 64099, Reward: [-434.254 -434.254 -434.254] [0.0000], Avg: [-475.547 -475.547 -475.547] (1.000)
Step: 64149, Reward: [-373.339 -373.339 -373.339] [0.0000], Avg: [-475.467 -475.467 -475.467] (1.000)
Step: 64199, Reward: [-384.983 -384.983 -384.983] [0.0000], Avg: [-475.397 -475.397 -475.397] (1.000)
Step: 64249, Reward: [-505.744 -505.744 -505.744] [0.0000], Avg: [-475.42 -475.42 -475.42] (1.000)
Step: 64299, Reward: [-460.893 -460.893 -460.893] [0.0000], Avg: [-475.409 -475.409 -475.409] (1.000)
Step: 64349, Reward: [-321.103 -321.103 -321.103] [0.0000], Avg: [-475.289 -475.289 -475.289] (1.000)
Step: 64399, Reward: [-454.114 -454.114 -454.114] [0.0000], Avg: [-475.273 -475.273 -475.273] (1.000)
Step: 64449, Reward: [-341.894 -341.894 -341.894] [0.0000], Avg: [-475.169 -475.169 -475.169] (1.000)
Step: 64499, Reward: [-325.029 -325.029 -325.029] [0.0000], Avg: [-475.053 -475.053 -475.053] (1.000)
Step: 64549, Reward: [-404.964 -404.964 -404.964] [0.0000], Avg: [-474.999 -474.999 -474.999] (1.000)
Step: 64599, Reward: [-270.958 -270.958 -270.958] [0.0000], Avg: [-474.841 -474.841 -474.841] (1.000)
Step: 64649, Reward: [-337.508 -337.508 -337.508] [0.0000], Avg: [-474.734 -474.734 -474.734] (1.000)
Step: 64699, Reward: [-359.946 -359.946 -359.946] [0.0000], Avg: [-474.646 -474.646 -474.646] (1.000)
Step: 64749, Reward: [-501.309 -501.309 -501.309] [0.0000], Avg: [-474.666 -474.666 -474.666] (1.000)
Step: 64799, Reward: [-379.81 -379.81 -379.81] [0.0000], Avg: [-474.593 -474.593 -474.593] (1.000)
Step: 64849, Reward: [-359.185 -359.185 -359.185] [0.0000], Avg: [-474.504 -474.504 -474.504] (1.000)
Step: 64899, Reward: [-373.29 -373.29 -373.29] [0.0000], Avg: [-474.426 -474.426 -474.426] (1.000)
Step: 64949, Reward: [-408.712 -408.712 -408.712] [0.0000], Avg: [-474.376 -474.376 -474.376] (1.000)
Step: 64999, Reward: [-368.677 -368.677 -368.677] [0.0000], Avg: [-474.294 -474.294 -474.294] (1.000)
Step: 65049, Reward: [-418.179 -418.179 -418.179] [0.0000], Avg: [-474.251 -474.251 -474.251] (1.000)
Step: 65099, Reward: [-450.114 -450.114 -450.114] [0.0000], Avg: [-474.233 -474.233 -474.233] (1.000)
Step: 65149, Reward: [-500.871 -500.871 -500.871] [0.0000], Avg: [-474.253 -474.253 -474.253] (1.000)
Step: 65199, Reward: [-446.739 -446.739 -446.739] [0.0000], Avg: [-474.232 -474.232 -474.232] (1.000)
Step: 65249, Reward: [-318.59 -318.59 -318.59] [0.0000], Avg: [-474.113 -474.113 -474.113] (1.000)
Step: 65299, Reward: [-319.954 -319.954 -319.954] [0.0000], Avg: [-473.995 -473.995 -473.995] (1.000)
Step: 65349, Reward: [-529.409 -529.409 -529.409] [0.0000], Avg: [-474.037 -474.037 -474.037] (1.000)
Step: 65399, Reward: [-390.791 -390.791 -390.791] [0.0000], Avg: [-473.973 -473.973 -473.973] (1.000)
Step: 65449, Reward: [-444.087 -444.087 -444.087] [0.0000], Avg: [-473.951 -473.951 -473.951] (1.000)
Step: 65499, Reward: [-440.642 -440.642 -440.642] [0.0000], Avg: [-473.925 -473.925 -473.925] (1.000)
Step: 65549, Reward: [-314.448 -314.448 -314.448] [0.0000], Avg: [-473.803 -473.803 -473.803] (1.000)
Step: 65599, Reward: [-465.653 -465.653 -465.653] [0.0000], Avg: [-473.797 -473.797 -473.797] (1.000)
Step: 65649, Reward: [-437.586 -437.586 -437.586] [0.0000], Avg: [-473.77 -473.77 -473.77] (1.000)
Step: 65699, Reward: [-406.51 -406.51 -406.51] [0.0000], Avg: [-473.718 -473.718 -473.718] (1.000)
Step: 65749, Reward: [-410.924 -410.924 -410.924] [0.0000], Avg: [-473.671 -473.671 -473.671] (1.000)
Step: 65799, Reward: [-310.706 -310.706 -310.706] [0.0000], Avg: [-473.547 -473.547 -473.547] (1.000)
Step: 65849, Reward: [-291.399 -291.399 -291.399] [0.0000], Avg: [-473.409 -473.409 -473.409] (1.000)
Step: 65899, Reward: [-356.424 -356.424 -356.424] [0.0000], Avg: [-473.32 -473.32 -473.32] (1.000)
Step: 65949, Reward: [-394.535 -394.535 -394.535] [0.0000], Avg: [-473.26 -473.26 -473.26] (1.000)
Step: 65999, Reward: [-463.611 -463.611 -463.611] [0.0000], Avg: [-473.253 -473.253 -473.253] (1.000)
Step: 66049, Reward: [-460.76 -460.76 -460.76] [0.0000], Avg: [-473.243 -473.243 -473.243] (1.000)
Step: 66099, Reward: [-415.33 -415.33 -415.33] [0.0000], Avg: [-473.2 -473.2 -473.2] (1.000)
Step: 66149, Reward: [-360.492 -360.492 -360.492] [0.0000], Avg: [-473.114 -473.114 -473.114] (1.000)
Step: 66199, Reward: [-386.685 -386.685 -386.685] [0.0000], Avg: [-473.049 -473.049 -473.049] (1.000)
Step: 66249, Reward: [-346.588 -346.588 -346.588] [0.0000], Avg: [-472.954 -472.954 -472.954] (1.000)
Step: 66299, Reward: [-455.183 -455.183 -455.183] [0.0000], Avg: [-472.94 -472.94 -472.94] (1.000)
Step: 66349, Reward: [-304.091 -304.091 -304.091] [0.0000], Avg: [-472.813 -472.813 -472.813] (1.000)
Step: 66399, Reward: [-314.519 -314.519 -314.519] [0.0000], Avg: [-472.694 -472.694 -472.694] (1.000)
Step: 66449, Reward: [-380.861 -380.861 -380.861] [0.0000], Avg: [-472.625 -472.625 -472.625] (1.000)
Step: 66499, Reward: [-352.009 -352.009 -352.009] [0.0000], Avg: [-472.534 -472.534 -472.534] (1.000)
Step: 66549, Reward: [-355.498 -355.498 -355.498] [0.0000], Avg: [-472.446 -472.446 -472.446] (1.000)
Step: 66599, Reward: [-417.66 -417.66 -417.66] [0.0000], Avg: [-472.405 -472.405 -472.405] (1.000)
Step: 66649, Reward: [-418.079 -418.079 -418.079] [0.0000], Avg: [-472.364 -472.364 -472.364] (1.000)
Step: 66699, Reward: [-359.583 -359.583 -359.583] [0.0000], Avg: [-472.28 -472.28 -472.28] (1.000)
Step: 66749, Reward: [-435.86 -435.86 -435.86] [0.0000], Avg: [-472.252 -472.252 -472.252] (1.000)
Step: 66799, Reward: [-420.222 -420.222 -420.222] [0.0000], Avg: [-472.213 -472.213 -472.213] (1.000)
Step: 66849, Reward: [-367.93 -367.93 -367.93] [0.0000], Avg: [-472.135 -472.135 -472.135] (1.000)
Step: 66899, Reward: [-401.785 -401.785 -401.785] [0.0000], Avg: [-472.083 -472.083 -472.083] (1.000)
Step: 66949, Reward: [-395.242 -395.242 -395.242] [0.0000], Avg: [-472.025 -472.025 -472.025] (1.000)
Step: 66999, Reward: [-433.952 -433.952 -433.952] [0.0000], Avg: [-471.997 -471.997 -471.997] (1.000)
Step: 67049, Reward: [-388.047 -388.047 -388.047] [0.0000], Avg: [-471.934 -471.934 -471.934] (1.000)
Step: 67099, Reward: [-469.51 -469.51 -469.51] [0.0000], Avg: [-471.933 -471.933 -471.933] (1.000)
Step: 67149, Reward: [-497.109 -497.109 -497.109] [0.0000], Avg: [-471.951 -471.951 -471.951] (1.000)
Step: 67199, Reward: [-269.661 -269.661 -269.661] [0.0000], Avg: [-471.801 -471.801 -471.801] (1.000)
Step: 67249, Reward: [-396.465 -396.465 -396.465] [0.0000], Avg: [-471.745 -471.745 -471.745] (1.000)
Step: 67299, Reward: [-406.389 -406.389 -406.389] [0.0000], Avg: [-471.696 -471.696 -471.696] (1.000)
Step: 67349, Reward: [-343.753 -343.753 -343.753] [0.0000], Avg: [-471.601 -471.601 -471.601] (1.000)
Step: 67399, Reward: [-378.317 -378.317 -378.317] [0.0000], Avg: [-471.532 -471.532 -471.532] (1.000)
Step: 67449, Reward: [-456.362 -456.362 -456.362] [0.0000], Avg: [-471.521 -471.521 -471.521] (1.000)
Step: 67499, Reward: [-344.936 -344.936 -344.936] [0.0000], Avg: [-471.427 -471.427 -471.427] (1.000)
Step: 67549, Reward: [-355.511 -355.511 -355.511] [0.0000], Avg: [-471.341 -471.341 -471.341] (1.000)
Step: 67599, Reward: [-281.169 -281.169 -281.169] [0.0000], Avg: [-471.201 -471.201 -471.201] (1.000)
Step: 67649, Reward: [-379.763 -379.763 -379.763] [0.0000], Avg: [-471.133 -471.133 -471.133] (1.000)
Step: 67699, Reward: [-386.803 -386.803 -386.803] [0.0000], Avg: [-471.071 -471.071 -471.071] (1.000)
Step: 67749, Reward: [-361.318 -361.318 -361.318] [0.0000], Avg: [-470.99 -470.99 -470.99] (1.000)
Step: 67799, Reward: [-321.817 -321.817 -321.817] [0.0000], Avg: [-470.88 -470.88 -470.88] (1.000)
Step: 67849, Reward: [-444.689 -444.689 -444.689] [0.0000], Avg: [-470.86 -470.86 -470.86] (1.000)
Step: 67899, Reward: [-384.169 -384.169 -384.169] [0.0000], Avg: [-470.797 -470.797 -470.797] (1.000)
Step: 67949, Reward: [-328.861 -328.861 -328.861] [0.0000], Avg: [-470.692 -470.692 -470.692] (1.000)
Step: 67999, Reward: [-393.329 -393.329 -393.329] [0.0000], Avg: [-470.635 -470.635 -470.635] (1.000)
Step: 68049, Reward: [-459.108 -459.108 -459.108] [0.0000], Avg: [-470.627 -470.627 -470.627] (1.000)
Step: 68099, Reward: [-449.989 -449.989 -449.989] [0.0000], Avg: [-470.612 -470.612 -470.612] (1.000)
Step: 68149, Reward: [-450.784 -450.784 -450.784] [0.0000], Avg: [-470.597 -470.597 -470.597] (1.000)
Step: 68199, Reward: [-390.409 -390.409 -390.409] [0.0000], Avg: [-470.538 -470.538 -470.538] (1.000)
Step: 68249, Reward: [-394.91 -394.91 -394.91] [0.0000], Avg: [-470.483 -470.483 -470.483] (1.000)
Step: 68299, Reward: [-457.145 -457.145 -457.145] [0.0000], Avg: [-470.473 -470.473 -470.473] (1.000)
Step: 68349, Reward: [-300.764 -300.764 -300.764] [0.0000], Avg: [-470.349 -470.349 -470.349] (1.000)
Step: 68399, Reward: [-378.925 -378.925 -378.925] [0.0000], Avg: [-470.282 -470.282 -470.282] (1.000)
Step: 68449, Reward: [-268.878 -268.878 -268.878] [0.0000], Avg: [-470.135 -470.135 -470.135] (1.000)
Step: 68499, Reward: [-438.651 -438.651 -438.651] [0.0000], Avg: [-470.112 -470.112 -470.112] (1.000)
Step: 68549, Reward: [-349.698 -349.698 -349.698] [0.0000], Avg: [-470.024 -470.024 -470.024] (1.000)
Step: 68599, Reward: [-364.499 -364.499 -364.499] [0.0000], Avg: [-469.947 -469.947 -469.947] (1.000)
Step: 68649, Reward: [-495.019 -495.019 -495.019] [0.0000], Avg: [-469.966 -469.966 -469.966] (1.000)
Step: 68699, Reward: [-303.198 -303.198 -303.198] [0.0000], Avg: [-469.844 -469.844 -469.844] (1.000)
Step: 68749, Reward: [-334.066 -334.066 -334.066] [0.0000], Avg: [-469.745 -469.745 -469.745] (1.000)
Step: 68799, Reward: [-431.749 -431.749 -431.749] [0.0000], Avg: [-469.718 -469.718 -469.718] (1.000)
Step: 68849, Reward: [-314.224 -314.224 -314.224] [0.0000], Avg: [-469.605 -469.605 -469.605] (1.000)
Step: 68899, Reward: [-389.45 -389.45 -389.45] [0.0000], Avg: [-469.547 -469.547 -469.547] (1.000)
Step: 68949, Reward: [-337.931 -337.931 -337.931] [0.0000], Avg: [-469.451 -469.451 -469.451] (1.000)
Step: 68999, Reward: [-399.476 -399.476 -399.476] [0.0000], Avg: [-469.401 -469.401 -469.401] (1.000)
Step: 69049, Reward: [-428.037 -428.037 -428.037] [0.0000], Avg: [-469.371 -469.371 -469.371] (1.000)
Step: 69099, Reward: [-419.86 -419.86 -419.86] [0.0000], Avg: [-469.335 -469.335 -469.335] (1.000)
Step: 69149, Reward: [-415.124 -415.124 -415.124] [0.0000], Avg: [-469.296 -469.296 -469.296] (1.000)
Step: 69199, Reward: [-400.891 -400.891 -400.891] [0.0000], Avg: [-469.246 -469.246 -469.246] (1.000)
Step: 69249, Reward: [-297.416 -297.416 -297.416] [0.0000], Avg: [-469.122 -469.122 -469.122] (1.000)
Step: 69299, Reward: [-333.449 -333.449 -333.449] [0.0000], Avg: [-469.024 -469.024 -469.024] (1.000)
Step: 69349, Reward: [-335.781 -335.781 -335.781] [0.0000], Avg: [-468.928 -468.928 -468.928] (1.000)
Step: 69399, Reward: [-443.374 -443.374 -443.374] [0.0000], Avg: [-468.91 -468.91 -468.91] (1.000)
Step: 69449, Reward: [-397.487 -397.487 -397.487] [0.0000], Avg: [-468.858 -468.858 -468.858] (1.000)
Step: 69499, Reward: [-408.14 -408.14 -408.14] [0.0000], Avg: [-468.815 -468.815 -468.815] (1.000)
Step: 69549, Reward: [-380.148 -380.148 -380.148] [0.0000], Avg: [-468.751 -468.751 -468.751] (1.000)
Step: 69599, Reward: [-418.051 -418.051 -418.051] [0.0000], Avg: [-468.715 -468.715 -468.715] (1.000)
Step: 69649, Reward: [-436.41 -436.41 -436.41] [0.0000], Avg: [-468.691 -468.691 -468.691] (1.000)
Step: 69699, Reward: [-462.015 -462.015 -462.015] [0.0000], Avg: [-468.687 -468.687 -468.687] (1.000)
Step: 69749, Reward: [-685.603 -685.603 -685.603] [0.0000], Avg: [-468.842 -468.842 -468.842] (1.000)
Step: 69799, Reward: [-342.268 -342.268 -342.268] [0.0000], Avg: [-468.751 -468.751 -468.751] (1.000)
Step: 69849, Reward: [-344.937 -344.937 -344.937] [0.0000], Avg: [-468.663 -468.663 -468.663] (1.000)
Step: 69899, Reward: [-468.911 -468.911 -468.911] [0.0000], Avg: [-468.663 -468.663 -468.663] (1.000)
Step: 69949, Reward: [-455.135 -455.135 -455.135] [0.0000], Avg: [-468.653 -468.653 -468.653] (1.000)
Step: 69999, Reward: [-315.327 -315.327 -315.327] [0.0000], Avg: [-468.544 -468.544 -468.544] (1.000)
Step: 70049, Reward: [-345.997 -345.997 -345.997] [0.0000], Avg: [-468.456 -468.456 -468.456] (1.000)
Step: 70099, Reward: [-554.196 -554.196 -554.196] [0.0000], Avg: [-468.517 -468.517 -468.517] (1.000)
Step: 70149, Reward: [-448.568 -448.568 -448.568] [0.0000], Avg: [-468.503 -468.503 -468.503] (1.000)
Step: 70199, Reward: [-429.866 -429.866 -429.866] [0.0000], Avg: [-468.476 -468.476 -468.476] (1.000)
Step: 70249, Reward: [-454.562 -454.562 -454.562] [0.0000], Avg: [-468.466 -468.466 -468.466] (1.000)
Step: 70299, Reward: [-368.225 -368.225 -368.225] [0.0000], Avg: [-468.394 -468.394 -468.394] (1.000)
Step: 70349, Reward: [-456.866 -456.866 -456.866] [0.0000], Avg: [-468.386 -468.386 -468.386] (1.000)
Step: 70399, Reward: [-431.595 -431.595 -431.595] [0.0000], Avg: [-468.36 -468.36 -468.36] (1.000)
Step: 70449, Reward: [-359.931 -359.931 -359.931] [0.0000], Avg: [-468.283 -468.283 -468.283] (1.000)
Step: 70499, Reward: [-494.457 -494.457 -494.457] [0.0000], Avg: [-468.302 -468.302 -468.302] (1.000)
Step: 70549, Reward: [-299.167 -299.167 -299.167] [0.0000], Avg: [-468.182 -468.182 -468.182] (1.000)
Step: 70599, Reward: [-359.075 -359.075 -359.075] [0.0000], Avg: [-468.105 -468.105 -468.105] (1.000)
Step: 70649, Reward: [-353.934 -353.934 -353.934] [0.0000], Avg: [-468.024 -468.024 -468.024] (1.000)
Step: 70699, Reward: [-384.777 -384.777 -384.777] [0.0000], Avg: [-467.965 -467.965 -467.965] (1.000)
Step: 70749, Reward: [-332.026 -332.026 -332.026] [0.0000], Avg: [-467.869 -467.869 -467.869] (1.000)
Step: 70799, Reward: [-406.148 -406.148 -406.148] [0.0000], Avg: [-467.825 -467.825 -467.825] (1.000)
Step: 70849, Reward: [-374.654 -374.654 -374.654] [0.0000], Avg: [-467.76 -467.76 -467.76] (1.000)
Step: 70899, Reward: [-311.026 -311.026 -311.026] [0.0000], Avg: [-467.649 -467.649 -467.649] (1.000)
Step: 70949, Reward: [-360.447 -360.447 -360.447] [0.0000], Avg: [-467.573 -467.573 -467.573] (1.000)
Step: 70999, Reward: [-368.34 -368.34 -368.34] [0.0000], Avg: [-467.504 -467.504 -467.504] (1.000)
Step: 71049, Reward: [-455.843 -455.843 -455.843] [0.0000], Avg: [-467.495 -467.495 -467.495] (1.000)
Step: 71099, Reward: [-300.898 -300.898 -300.898] [0.0000], Avg: [-467.378 -467.378 -467.378] (1.000)
Step: 71149, Reward: [-376.991 -376.991 -376.991] [0.0000], Avg: [-467.315 -467.315 -467.315] (1.000)
Step: 71199, Reward: [-406.055 -406.055 -406.055] [0.0000], Avg: [-467.272 -467.272 -467.272] (1.000)
Step: 71249, Reward: [-378.883 -378.883 -378.883] [0.0000], Avg: [-467.21 -467.21 -467.21] (1.000)
Step: 71299, Reward: [-307.935 -307.935 -307.935] [0.0000], Avg: [-467.098 -467.098 -467.098] (1.000)
Step: 71349, Reward: [-339.675 -339.675 -339.675] [0.0000], Avg: [-467.009 -467.009 -467.009] (1.000)
Step: 71399, Reward: [-417.746 -417.746 -417.746] [0.0000], Avg: [-466.974 -466.974 -466.974] (1.000)
Step: 71449, Reward: [-310.534 -310.534 -310.534] [0.0000], Avg: [-466.865 -466.865 -466.865] (1.000)
Step: 71499, Reward: [-348.916 -348.916 -348.916] [0.0000], Avg: [-466.782 -466.782 -466.782] (1.000)
Step: 71549, Reward: [-391.385 -391.385 -391.385] [0.0000], Avg: [-466.73 -466.73 -466.73] (1.000)
Step: 71599, Reward: [-449.515 -449.515 -449.515] [0.0000], Avg: [-466.718 -466.718 -466.718] (1.000)
Step: 71649, Reward: [-353.13 -353.13 -353.13] [0.0000], Avg: [-466.638 -466.638 -466.638] (1.000)
Step: 71699, Reward: [-373.294 -373.294 -373.294] [0.0000], Avg: [-466.573 -466.573 -466.573] (1.000)
Step: 71749, Reward: [-328.753 -328.753 -328.753] [0.0000], Avg: [-466.477 -466.477 -466.477] (1.000)
Step: 71799, Reward: [-346.236 -346.236 -346.236] [0.0000], Avg: [-466.393 -466.393 -466.393] (1.000)
Step: 71849, Reward: [-369.577 -369.577 -369.577] [0.0000], Avg: [-466.326 -466.326 -466.326] (1.000)
Step: 71899, Reward: [-316.887 -316.887 -316.887] [0.0000], Avg: [-466.222 -466.222 -466.222] (1.000)
Step: 71949, Reward: [-302.03 -302.03 -302.03] [0.0000], Avg: [-466.108 -466.108 -466.108] (1.000)
Step: 71999, Reward: [-458.986 -458.986 -458.986] [0.0000], Avg: [-466.103 -466.103 -466.103] (1.000)
Step: 72049, Reward: [-385.038 -385.038 -385.038] [0.0000], Avg: [-466.047 -466.047 -466.047] (1.000)
Step: 72099, Reward: [-426.532 -426.532 -426.532] [0.0000], Avg: [-466.019 -466.019 -466.019] (1.000)
Step: 72149, Reward: [-451.457 -451.457 -451.457] [0.0000], Avg: [-466.009 -466.009 -466.009] (1.000)
Step: 72199, Reward: [-317.59 -317.59 -317.59] [0.0000], Avg: [-465.907 -465.907 -465.907] (1.000)
Step: 72249, Reward: [-351.171 -351.171 -351.171] [0.0000], Avg: [-465.827 -465.827 -465.827] (1.000)
Step: 72299, Reward: [-423.001 -423.001 -423.001] [0.0000], Avg: [-465.797 -465.797 -465.797] (1.000)
Step: 72349, Reward: [-525.38 -525.38 -525.38] [0.0000], Avg: [-465.839 -465.839 -465.839] (1.000)
Step: 72399, Reward: [-343.527 -343.527 -343.527] [0.0000], Avg: [-465.754 -465.754 -465.754] (1.000)
Step: 72449, Reward: [-374.039 -374.039 -374.039] [0.0000], Avg: [-465.691 -465.691 -465.691] (1.000)
Step: 72499, Reward: [-469.973 -469.973 -469.973] [0.0000], Avg: [-465.694 -465.694 -465.694] (1.000)
Step: 72549, Reward: [-375.64 -375.64 -375.64] [0.0000], Avg: [-465.632 -465.632 -465.632] (1.000)
Step: 72599, Reward: [-493.842 -493.842 -493.842] [0.0000], Avg: [-465.651 -465.651 -465.651] (1.000)
Step: 72649, Reward: [-437.807 -437.807 -437.807] [0.0000], Avg: [-465.632 -465.632 -465.632] (1.000)
Step: 72699, Reward: [-353.576 -353.576 -353.576] [0.0000], Avg: [-465.555 -465.555 -465.555] (1.000)
Step: 72749, Reward: [-418.374 -418.374 -418.374] [0.0000], Avg: [-465.523 -465.523 -465.523] (1.000)
Step: 72799, Reward: [-309.047 -309.047 -309.047] [0.0000], Avg: [-465.415 -465.415 -465.415] (1.000)
Step: 72849, Reward: [-266.813 -266.813 -266.813] [0.0000], Avg: [-465.279 -465.279 -465.279] (1.000)
Step: 72899, Reward: [-395.223 -395.223 -395.223] [0.0000], Avg: [-465.231 -465.231 -465.231] (1.000)
Step: 72949, Reward: [-442.413 -442.413 -442.413] [0.0000], Avg: [-465.215 -465.215 -465.215] (1.000)
Step: 72999, Reward: [-441.973 -441.973 -441.973] [0.0000], Avg: [-465.199 -465.199 -465.199] (1.000)
Step: 73049, Reward: [-421.094 -421.094 -421.094] [0.0000], Avg: [-465.169 -465.169 -465.169] (1.000)
Step: 73099, Reward: [-388.753 -388.753 -388.753] [0.0000], Avg: [-465.117 -465.117 -465.117] (1.000)
Step: 73149, Reward: [-515.913 -515.913 -515.913] [0.0000], Avg: [-465.151 -465.151 -465.151] (1.000)
Step: 73199, Reward: [-412.545 -412.545 -412.545] [0.0000], Avg: [-465.116 -465.116 -465.116] (1.000)
Step: 73249, Reward: [-294.752 -294.752 -294.752] [0.0000], Avg: [-464.999 -464.999 -464.999] (1.000)
Step: 73299, Reward: [-426.227 -426.227 -426.227] [0.0000], Avg: [-464.973 -464.973 -464.973] (1.000)
Step: 73349, Reward: [-460.727 -460.727 -460.727] [0.0000], Avg: [-464.97 -464.97 -464.97] (1.000)
Step: 73399, Reward: [-338.476 -338.476 -338.476] [0.0000], Avg: [-464.884 -464.884 -464.884] (1.000)
Step: 73449, Reward: [-370.168 -370.168 -370.168] [0.0000], Avg: [-464.819 -464.819 -464.819] (1.000)
Step: 73499, Reward: [-367.382 -367.382 -367.382] [0.0000], Avg: [-464.753 -464.753 -464.753] (1.000)
Step: 73549, Reward: [-369.182 -369.182 -369.182] [0.0000], Avg: [-464.688 -464.688 -464.688] (1.000)
Step: 73599, Reward: [-357.05 -357.05 -357.05] [0.0000], Avg: [-464.615 -464.615 -464.615] (1.000)
Step: 73649, Reward: [-452.017 -452.017 -452.017] [0.0000], Avg: [-464.606 -464.606 -464.606] (1.000)
Step: 73699, Reward: [-319.673 -319.673 -319.673] [0.0000], Avg: [-464.508 -464.508 -464.508] (1.000)
Step: 73749, Reward: [-353.466 -353.466 -353.466] [0.0000], Avg: [-464.433 -464.433 -464.433] (1.000)
Step: 73799, Reward: [-438.36 -438.36 -438.36] [0.0000], Avg: [-464.415 -464.415 -464.415] (1.000)
Step: 73849, Reward: [-468.938 -468.938 -468.938] [0.0000], Avg: [-464.418 -464.418 -464.418] (1.000)
Step: 73899, Reward: [-424.375 -424.375 -424.375] [0.0000], Avg: [-464.391 -464.391 -464.391] (1.000)
Step: 73949, Reward: [-440.499 -440.499 -440.499] [0.0000], Avg: [-464.375 -464.375 -464.375] (1.000)
Step: 73999, Reward: [-444.196 -444.196 -444.196] [0.0000], Avg: [-464.361 -464.361 -464.361] (1.000)
Step: 74049, Reward: [-321.242 -321.242 -321.242] [0.0000], Avg: [-464.265 -464.265 -464.265] (1.000)
Step: 74099, Reward: [-446.322 -446.322 -446.322] [0.0000], Avg: [-464.252 -464.252 -464.252] (1.000)
Step: 74149, Reward: [-496.403 -496.403 -496.403] [0.0000], Avg: [-464.274 -464.274 -464.274] (1.000)
Step: 74199, Reward: [-543.813 -543.813 -543.813] [0.0000], Avg: [-464.328 -464.328 -464.328] (1.000)
Step: 74249, Reward: [-437.902 -437.902 -437.902] [0.0000], Avg: [-464.31 -464.31 -464.31] (1.000)
Step: 74299, Reward: [-443.717 -443.717 -443.717] [0.0000], Avg: [-464.296 -464.296 -464.296] (1.000)
Step: 74349, Reward: [-413.231 -413.231 -413.231] [0.0000], Avg: [-464.262 -464.262 -464.262] (1.000)
Step: 74399, Reward: [-362.064 -362.064 -362.064] [0.0000], Avg: [-464.193 -464.193 -464.193] (1.000)
Step: 74449, Reward: [-484.356 -484.356 -484.356] [0.0000], Avg: [-464.207 -464.207 -464.207] (1.000)
Step: 74499, Reward: [-318.391 -318.391 -318.391] [0.0000], Avg: [-464.109 -464.109 -464.109] (1.000)
Step: 74549, Reward: [-369.936 -369.936 -369.936] [0.0000], Avg: [-464.046 -464.046 -464.046] (1.000)
Step: 74599, Reward: [-521.184 -521.184 -521.184] [0.0000], Avg: [-464.084 -464.084 -464.084] (1.000)
Step: 74649, Reward: [-448.931 -448.931 -448.931] [0.0000], Avg: [-464.074 -464.074 -464.074] (1.000)
Step: 74699, Reward: [-319.816 -319.816 -319.816] [0.0000], Avg: [-463.977 -463.977 -463.977] (1.000)
Step: 74749, Reward: [-521.448 -521.448 -521.448] [0.0000], Avg: [-464.016 -464.016 -464.016] (1.000)
Step: 74799, Reward: [-321.482 -321.482 -321.482] [0.0000], Avg: [-463.92 -463.92 -463.92] (1.000)
Step: 74849, Reward: [-309.696 -309.696 -309.696] [0.0000], Avg: [-463.817 -463.817 -463.817] (1.000)
Step: 74899, Reward: [-381.369 -381.369 -381.369] [0.0000], Avg: [-463.762 -463.762 -463.762] (1.000)
Step: 74949, Reward: [-370.368 -370.368 -370.368] [0.0000], Avg: [-463.7 -463.7 -463.7] (1.000)
Step: 74999, Reward: [-312.082 -312.082 -312.082] [0.0000], Avg: [-463.599 -463.599 -463.599] (1.000)
Step: 75049, Reward: [-360.34 -360.34 -360.34] [0.0000], Avg: [-463.53 -463.53 -463.53] (1.000)
Step: 75099, Reward: [-358.947 -358.947 -358.947] [0.0000], Avg: [-463.46 -463.46 -463.46] (1.000)
Step: 75149, Reward: [-352.457 -352.457 -352.457] [0.0000], Avg: [-463.387 -463.387 -463.387] (1.000)
Step: 75199, Reward: [-396.278 -396.278 -396.278] [0.0000], Avg: [-463.342 -463.342 -463.342] (1.000)
Step: 75249, Reward: [-349.752 -349.752 -349.752] [0.0000], Avg: [-463.267 -463.267 -463.267] (1.000)
Step: 75299, Reward: [-342.334 -342.334 -342.334] [0.0000], Avg: [-463.186 -463.186 -463.186] (1.000)
Step: 75349, Reward: [-294.508 -294.508 -294.508] [0.0000], Avg: [-463.074 -463.074 -463.074] (1.000)
Step: 75399, Reward: [-426.909 -426.909 -426.909] [0.0000], Avg: [-463.05 -463.05 -463.05] (1.000)
Step: 75449, Reward: [-422.025 -422.025 -422.025] [0.0000], Avg: [-463.023 -463.023 -463.023] (1.000)
Step: 75499, Reward: [-304.789 -304.789 -304.789] [0.0000], Avg: [-462.918 -462.918 -462.918] (1.000)
Step: 75549, Reward: [-423.674 -423.674 -423.674] [0.0000], Avg: [-462.892 -462.892 -462.892] (1.000)
Step: 75599, Reward: [-309.023 -309.023 -309.023] [0.0000], Avg: [-462.791 -462.791 -462.791] (1.000)
Step: 75649, Reward: [-360.56 -360.56 -360.56] [0.0000], Avg: [-462.723 -462.723 -462.723] (1.000)
Step: 75699, Reward: [-312.092 -312.092 -312.092] [0.0000], Avg: [-462.624 -462.624 -462.624] (1.000)
Step: 75749, Reward: [-469.411 -469.411 -469.411] [0.0000], Avg: [-462.628 -462.628 -462.628] (1.000)
Step: 75799, Reward: [-436.872 -436.872 -436.872] [0.0000], Avg: [-462.611 -462.611 -462.611] (1.000)
Step: 75849, Reward: [-375.432 -375.432 -375.432] [0.0000], Avg: [-462.554 -462.554 -462.554] (1.000)
Step: 75899, Reward: [-472.255 -472.255 -472.255] [0.0000], Avg: [-462.56 -462.56 -462.56] (1.000)
Step: 75949, Reward: [-404.648 -404.648 -404.648] [0.0000], Avg: [-462.522 -462.522 -462.522] (1.000)
Step: 75999, Reward: [-277.784 -277.784 -277.784] [0.0000], Avg: [-462.4 -462.4 -462.4] (1.000)
Step: 76049, Reward: [-297.195 -297.195 -297.195] [0.0000], Avg: [-462.292 -462.292 -462.292] (1.000)
Step: 76099, Reward: [-433.251 -433.251 -433.251] [0.0000], Avg: [-462.273 -462.273 -462.273] (1.000)
Step: 76149, Reward: [-347.364 -347.364 -347.364] [0.0000], Avg: [-462.197 -462.197 -462.197] (1.000)
Step: 76199, Reward: [-375.339 -375.339 -375.339] [0.0000], Avg: [-462.14 -462.14 -462.14] (1.000)
Step: 76249, Reward: [-369.092 -369.092 -369.092] [0.0000], Avg: [-462.079 -462.079 -462.079] (1.000)
Step: 76299, Reward: [-358.941 -358.941 -358.941] [0.0000], Avg: [-462.012 -462.012 -462.012] (1.000)
Step: 76349, Reward: [-512.731 -512.731 -512.731] [0.0000], Avg: [-462.045 -462.045 -462.045] (1.000)
Step: 76399, Reward: [-369.152 -369.152 -369.152] [0.0000], Avg: [-461.984 -461.984 -461.984] (1.000)
Step: 76449, Reward: [-395.536 -395.536 -395.536] [0.0000], Avg: [-461.941 -461.941 -461.941] (1.000)
Step: 76499, Reward: [-401.233 -401.233 -401.233] [0.0000], Avg: [-461.901 -461.901 -461.901] (1.000)
Step: 76549, Reward: [-397.435 -397.435 -397.435] [0.0000], Avg: [-461.859 -461.859 -461.859] (1.000)
Step: 76599, Reward: [-391.003 -391.003 -391.003] [0.0000], Avg: [-461.812 -461.812 -461.812] (1.000)
Step: 76649, Reward: [-267.272 -267.272 -267.272] [0.0000], Avg: [-461.686 -461.686 -461.686] (1.000)
Step: 76699, Reward: [-332.371 -332.371 -332.371] [0.0000], Avg: [-461.601 -461.601 -461.601] (1.000)
Step: 76749, Reward: [-374.711 -374.711 -374.711] [0.0000], Avg: [-461.545 -461.545 -461.545] (1.000)
Step: 76799, Reward: [-329.886 -329.886 -329.886] [0.0000], Avg: [-461.459 -461.459 -461.459] (1.000)
Step: 76849, Reward: [-409.381 -409.381 -409.381] [0.0000], Avg: [-461.425 -461.425 -461.425] (1.000)
Step: 76899, Reward: [-433.434 -433.434 -433.434] [0.0000], Avg: [-461.407 -461.407 -461.407] (1.000)
Step: 76949, Reward: [-412.301 -412.301 -412.301] [0.0000], Avg: [-461.375 -461.375 -461.375] (1.000)
Step: 76999, Reward: [-337.496 -337.496 -337.496] [0.0000], Avg: [-461.295 -461.295 -461.295] (1.000)
Step: 77049, Reward: [-410.241 -410.241 -410.241] [0.0000], Avg: [-461.261 -461.261 -461.261] (1.000)
Step: 77099, Reward: [-356.451 -356.451 -356.451] [0.0000], Avg: [-461.193 -461.193 -461.193] (1.000)
Step: 77149, Reward: [-293.813 -293.813 -293.813] [0.0000], Avg: [-461.085 -461.085 -461.085] (1.000)
Step: 77199, Reward: [-393.023 -393.023 -393.023] [0.0000], Avg: [-461.041 -461.041 -461.041] (1.000)
Step: 77249, Reward: [-319.736 -319.736 -319.736] [0.0000], Avg: [-460.949 -460.949 -460.949] (1.000)
Step: 77299, Reward: [-444.456 -444.456 -444.456] [0.0000], Avg: [-460.939 -460.939 -460.939] (1.000)
Step: 77349, Reward: [-358.725 -358.725 -358.725] [0.0000], Avg: [-460.873 -460.873 -460.873] (1.000)
Step: 77399, Reward: [-359.205 -359.205 -359.205] [0.0000], Avg: [-460.807 -460.807 -460.807] (1.000)
Step: 77449, Reward: [-346.267 -346.267 -346.267] [0.0000], Avg: [-460.733 -460.733 -460.733] (1.000)
Step: 77499, Reward: [-406.509 -406.509 -406.509] [0.0000], Avg: [-460.698 -460.698 -460.698] (1.000)
Step: 77549, Reward: [-306.087 -306.087 -306.087] [0.0000], Avg: [-460.598 -460.598 -460.598] (1.000)
Step: 77599, Reward: [-427.691 -427.691 -427.691] [0.0000], Avg: [-460.577 -460.577 -460.577] (1.000)
Step: 77649, Reward: [-278.407 -278.407 -278.407] [0.0000], Avg: [-460.46 -460.46 -460.46] (1.000)
Step: 77699, Reward: [-327.499 -327.499 -327.499] [0.0000], Avg: [-460.374 -460.374 -460.374] (1.000)
Step: 77749, Reward: [-416.287 -416.287 -416.287] [0.0000], Avg: [-460.346 -460.346 -460.346] (1.000)
Step: 77799, Reward: [-414.5 -414.5 -414.5] [0.0000], Avg: [-460.316 -460.316 -460.316] (1.000)
Step: 77849, Reward: [-298.901 -298.901 -298.901] [0.0000], Avg: [-460.213 -460.213 -460.213] (1.000)
Step: 77899, Reward: [-408.246 -408.246 -408.246] [0.0000], Avg: [-460.179 -460.179 -460.179] (1.000)
Step: 77949, Reward: [-284.363 -284.363 -284.363] [0.0000], Avg: [-460.067 -460.067 -460.067] (1.000)
Step: 77999, Reward: [-376.477 -376.477 -376.477] [0.0000], Avg: [-460.013 -460.013 -460.013] (1.000)
Step: 78049, Reward: [-374.169 -374.169 -374.169] [0.0000], Avg: [-459.958 -459.958 -459.958] (1.000)
Step: 78099, Reward: [-369.338 -369.338 -369.338] [0.0000], Avg: [-459.9 -459.9 -459.9] (1.000)
Step: 78149, Reward: [-361.608 -361.608 -361.608] [0.0000], Avg: [-459.837 -459.837 -459.837] (1.000)
Step: 78199, Reward: [-410.968 -410.968 -410.968] [0.0000], Avg: [-459.806 -459.806 -459.806] (1.000)
Step: 78249, Reward: [-382.475 -382.475 -382.475] [0.0000], Avg: [-459.757 -459.757 -459.757] (1.000)
Step: 78299, Reward: [-447.414 -447.414 -447.414] [0.0000], Avg: [-459.749 -459.749 -459.749] (1.000)
Step: 78349, Reward: [-441.259 -441.259 -441.259] [0.0000], Avg: [-459.737 -459.737 -459.737] (1.000)
Step: 78399, Reward: [-320.756 -320.756 -320.756] [0.0000], Avg: [-459.648 -459.648 -459.648] (1.000)
Step: 78449, Reward: [-351.86 -351.86 -351.86] [0.0000], Avg: [-459.58 -459.58 -459.58] (1.000)
Step: 78499, Reward: [-327.556 -327.556 -327.556] [0.0000], Avg: [-459.495 -459.495 -459.495] (1.000)
Step: 78549, Reward: [-503.089 -503.089 -503.089] [0.0000], Avg: [-459.523 -459.523 -459.523] (1.000)
Step: 78599, Reward: [-488.411 -488.411 -488.411] [0.0000], Avg: [-459.542 -459.542 -459.542] (1.000)
Step: 78649, Reward: [-353.065 -353.065 -353.065] [0.0000], Avg: [-459.474 -459.474 -459.474] (1.000)
Step: 78699, Reward: [-383.279 -383.279 -383.279] [0.0000], Avg: [-459.425 -459.425 -459.425] (1.000)
Step: 78749, Reward: [-324.605 -324.605 -324.605] [0.0000], Avg: [-459.34 -459.34 -459.34] (1.000)
Step: 78799, Reward: [-372.871 -372.871 -372.871] [0.0000], Avg: [-459.285 -459.285 -459.285] (1.000)
Step: 78849, Reward: [-391.331 -391.331 -391.331] [0.0000], Avg: [-459.242 -459.242 -459.242] (1.000)
Step: 78899, Reward: [-300.095 -300.095 -300.095] [0.0000], Avg: [-459.141 -459.141 -459.141] (1.000)
Step: 78949, Reward: [-445.102 -445.102 -445.102] [0.0000], Avg: [-459.132 -459.132 -459.132] (1.000)
Step: 78999, Reward: [-305.701 -305.701 -305.701] [0.0000], Avg: [-459.035 -459.035 -459.035] (1.000)
Step: 79049, Reward: [-403.73 -403.73 -403.73] [0.0000], Avg: [-459. -459. -459.] (1.000)
Step: 79099, Reward: [-329.828 -329.828 -329.828] [0.0000], Avg: [-458.918 -458.918 -458.918] (1.000)
Step: 79149, Reward: [-330.879 -330.879 -330.879] [0.0000], Avg: [-458.838 -458.838 -458.838] (1.000)
Step: 79199, Reward: [-328.868 -328.868 -328.868] [0.0000], Avg: [-458.755 -458.755 -458.755] (1.000)
Step: 79249, Reward: [-322.291 -322.291 -322.291] [0.0000], Avg: [-458.669 -458.669 -458.669] (1.000)
Step: 79299, Reward: [-367.399 -367.399 -367.399] [0.0000], Avg: [-458.612 -458.612 -458.612] (1.000)
Step: 79349, Reward: [-434.064 -434.064 -434.064] [0.0000], Avg: [-458.596 -458.596 -458.596] (1.000)
Step: 79399, Reward: [-325.979 -325.979 -325.979] [0.0000], Avg: [-458.513 -458.513 -458.513] (1.000)
Step: 79449, Reward: [-355.067 -355.067 -355.067] [0.0000], Avg: [-458.448 -458.448 -458.448] (1.000)
Step: 79499, Reward: [-299.424 -299.424 -299.424] [0.0000], Avg: [-458.348 -458.348 -458.348] (1.000)
Step: 79549, Reward: [-432.16 -432.16 -432.16] [0.0000], Avg: [-458.331 -458.331 -458.331] (1.000)
Step: 79599, Reward: [-412.26 -412.26 -412.26] [0.0000], Avg: [-458.302 -458.302 -458.302] (1.000)
Step: 79649, Reward: [-307.495 -307.495 -307.495] [0.0000], Avg: [-458.208 -458.208 -458.208] (1.000)
Step: 79699, Reward: [-381.725 -381.725 -381.725] [0.0000], Avg: [-458.16 -458.16 -458.16] (1.000)
Step: 79749, Reward: [-367.33 -367.33 -367.33] [0.0000], Avg: [-458.103 -458.103 -458.103] (1.000)
Step: 79799, Reward: [-381.993 -381.993 -381.993] [0.0000], Avg: [-458.055 -458.055 -458.055] (1.000)
Step: 79849, Reward: [-415.6 -415.6 -415.6] [0.0000], Avg: [-458.028 -458.028 -458.028] (1.000)
Step: 79899, Reward: [-313.308 -313.308 -313.308] [0.0000], Avg: [-457.938 -457.938 -457.938] (1.000)
Step: 79949, Reward: [-406.311 -406.311 -406.311] [0.0000], Avg: [-457.906 -457.906 -457.906] (1.000)
Step: 79999, Reward: [-445.185 -445.185 -445.185] [0.0000], Avg: [-457.898 -457.898 -457.898] (1.000)
Step: 80049, Reward: [-407.798 -407.798 -407.798] [0.0000], Avg: [-457.866 -457.866 -457.866] (1.000)
Step: 80099, Reward: [-457.475 -457.475 -457.475] [0.0000], Avg: [-457.866 -457.866 -457.866] (1.000)
Step: 80149, Reward: [-347.242 -347.242 -347.242] [0.0000], Avg: [-457.797 -457.797 -457.797] (1.000)
Step: 80199, Reward: [-409.66 -409.66 -409.66] [0.0000], Avg: [-457.767 -457.767 -457.767] (1.000)
Step: 80249, Reward: [-446.101 -446.101 -446.101] [0.0000], Avg: [-457.76 -457.76 -457.76] (1.000)
Step: 80299, Reward: [-358.836 -358.836 -358.836] [0.0000], Avg: [-457.698 -457.698 -457.698] (1.000)
Step: 80349, Reward: [-374.047 -374.047 -374.047] [0.0000], Avg: [-457.646 -457.646 -457.646] (1.000)
Step: 80399, Reward: [-434.397 -434.397 -434.397] [0.0000], Avg: [-457.632 -457.632 -457.632] (1.000)
Step: 80449, Reward: [-248.066 -248.066 -248.066] [0.0000], Avg: [-457.501 -457.501 -457.501] (1.000)
Step: 80499, Reward: [-453.838 -453.838 -453.838] [0.0000], Avg: [-457.499 -457.499 -457.499] (1.000)
Step: 80549, Reward: [-450.046 -450.046 -450.046] [0.0000], Avg: [-457.495 -457.495 -457.495] (1.000)
Step: 80599, Reward: [-472.565 -472.565 -472.565] [0.0000], Avg: [-457.504 -457.504 -457.504] (1.000)
Step: 80649, Reward: [-403.801 -403.801 -403.801] [0.0000], Avg: [-457.471 -457.471 -457.471] (1.000)
Step: 80699, Reward: [-332.384 -332.384 -332.384] [0.0000], Avg: [-457.393 -457.393 -457.393] (1.000)
Step: 80749, Reward: [-384.751 -384.751 -384.751] [0.0000], Avg: [-457.348 -457.348 -457.348] (1.000)
Step: 80799, Reward: [-409.715 -409.715 -409.715] [0.0000], Avg: [-457.319 -457.319 -457.319] (1.000)
Step: 80849, Reward: [-344.438 -344.438 -344.438] [0.0000], Avg: [-457.249 -457.249 -457.249] (1.000)
Step: 80899, Reward: [-389.941 -389.941 -389.941] [0.0000], Avg: [-457.207 -457.207 -457.207] (1.000)
Step: 80949, Reward: [-405.169 -405.169 -405.169] [0.0000], Avg: [-457.175 -457.175 -457.175] (1.000)
Step: 80999, Reward: [-423.774 -423.774 -423.774] [0.0000], Avg: [-457.155 -457.155 -457.155] (1.000)
Step: 81049, Reward: [-400.621 -400.621 -400.621] [0.0000], Avg: [-457.12 -457.12 -457.12] (1.000)
Step: 81099, Reward: [-338.975 -338.975 -338.975] [0.0000], Avg: [-457.047 -457.047 -457.047] (1.000)
Step: 81149, Reward: [-389.653 -389.653 -389.653] [0.0000], Avg: [-457.005 -457.005 -457.005] (1.000)
Step: 81199, Reward: [-505.798 -505.798 -505.798] [0.0000], Avg: [-457.035 -457.035 -457.035] (1.000)
Step: 81249, Reward: [-313.998 -313.998 -313.998] [0.0000], Avg: [-456.947 -456.947 -456.947] (1.000)
Step: 81299, Reward: [-391.472 -391.472 -391.472] [0.0000], Avg: [-456.907 -456.907 -456.907] (1.000)
Step: 81349, Reward: [-388.972 -388.972 -388.972] [0.0000], Avg: [-456.865 -456.865 -456.865] (1.000)
Step: 81399, Reward: [-448.778 -448.778 -448.778] [0.0000], Avg: [-456.86 -456.86 -456.86] (1.000)
Step: 81449, Reward: [-600.764 -600.764 -600.764] [0.0000], Avg: [-456.949 -456.949 -456.949] (1.000)
Step: 81499, Reward: [-414.812 -414.812 -414.812] [0.0000], Avg: [-456.923 -456.923 -456.923] (1.000)
Step: 81549, Reward: [-333.636 -333.636 -333.636] [0.0000], Avg: [-456.847 -456.847 -456.847] (1.000)
Step: 81599, Reward: [-348.159 -348.159 -348.159] [0.0000], Avg: [-456.781 -456.781 -456.781] (1.000)
Step: 81649, Reward: [-320. -320. -320.] [0.0000], Avg: [-456.697 -456.697 -456.697] (1.000)
Step: 81699, Reward: [-316.359 -316.359 -316.359] [0.0000], Avg: [-456.611 -456.611 -456.611] (1.000)
Step: 81749, Reward: [-312.724 -312.724 -312.724] [0.0000], Avg: [-456.523 -456.523 -456.523] (1.000)
Step: 81799, Reward: [-396.868 -396.868 -396.868] [0.0000], Avg: [-456.487 -456.487 -456.487] (1.000)
Step: 81849, Reward: [-318.109 -318.109 -318.109] [0.0000], Avg: [-456.402 -456.402 -456.402] (1.000)
Step: 81899, Reward: [-406.366 -406.366 -406.366] [0.0000], Avg: [-456.371 -456.371 -456.371] (1.000)
Step: 81949, Reward: [-365.76 -365.76 -365.76] [0.0000], Avg: [-456.316 -456.316 -456.316] (1.000)
Step: 81999, Reward: [-395.571 -395.571 -395.571] [0.0000], Avg: [-456.279 -456.279 -456.279] (1.000)
Step: 82049, Reward: [-363.84 -363.84 -363.84] [0.0000], Avg: [-456.223 -456.223 -456.223] (1.000)
Step: 82099, Reward: [-410.169 -410.169 -410.169] [0.0000], Avg: [-456.195 -456.195 -456.195] (1.000)
Step: 82149, Reward: [-356.889 -356.889 -356.889] [0.0000], Avg: [-456.134 -456.134 -456.134] (1.000)
Step: 82199, Reward: [-345.032 -345.032 -345.032] [0.0000], Avg: [-456.067 -456.067 -456.067] (1.000)
Step: 82249, Reward: [-459.354 -459.354 -459.354] [0.0000], Avg: [-456.069 -456.069 -456.069] (1.000)
Step: 82299, Reward: [-448.243 -448.243 -448.243] [0.0000], Avg: [-456.064 -456.064 -456.064] (1.000)
Step: 82349, Reward: [-320.673 -320.673 -320.673] [0.0000], Avg: [-455.982 -455.982 -455.982] (1.000)
Step: 82399, Reward: [-308.168 -308.168 -308.168] [0.0000], Avg: [-455.892 -455.892 -455.892] (1.000)
Step: 82449, Reward: [-446.452 -446.452 -446.452] [0.0000], Avg: [-455.886 -455.886 -455.886] (1.000)
Step: 82499, Reward: [-458.363 -458.363 -458.363] [0.0000], Avg: [-455.888 -455.888 -455.888] (1.000)
Step: 82549, Reward: [-413.247 -413.247 -413.247] [0.0000], Avg: [-455.862 -455.862 -455.862] (1.000)
Step: 82599, Reward: [-304.789 -304.789 -304.789] [0.0000], Avg: [-455.771 -455.771 -455.771] (1.000)
Step: 82649, Reward: [-408.251 -408.251 -408.251] [0.0000], Avg: [-455.742 -455.742 -455.742] (1.000)
Step: 82699, Reward: [-418.832 -418.832 -418.832] [0.0000], Avg: [-455.719 -455.719 -455.719] (1.000)
Step: 82749, Reward: [-314.382 -314.382 -314.382] [0.0000], Avg: [-455.634 -455.634 -455.634] (1.000)
Step: 82799, Reward: [-358.238 -358.238 -358.238] [0.0000], Avg: [-455.575 -455.575 -455.575] (1.000)
Step: 82849, Reward: [-366.816 -366.816 -366.816] [0.0000], Avg: [-455.522 -455.522 -455.522] (1.000)
Step: 82899, Reward: [-366.687 -366.687 -366.687] [0.0000], Avg: [-455.468 -455.468 -455.468] (1.000)
Step: 82949, Reward: [-460.448 -460.448 -460.448] [0.0000], Avg: [-455.471 -455.471 -455.471] (1.000)
Step: 82999, Reward: [-373.3 -373.3 -373.3] [0.0000], Avg: [-455.422 -455.422 -455.422] (1.000)
Step: 83049, Reward: [-286.658 -286.658 -286.658] [0.0000], Avg: [-455.32 -455.32 -455.32] (1.000)
Step: 83099, Reward: [-328.382 -328.382 -328.382] [0.0000], Avg: [-455.244 -455.244 -455.244] (1.000)
Step: 83149, Reward: [-413.473 -413.473 -413.473] [0.0000], Avg: [-455.219 -455.219 -455.219] (1.000)
Step: 83199, Reward: [-430.608 -430.608 -430.608] [0.0000], Avg: [-455.204 -455.204 -455.204] (1.000)
Step: 83249, Reward: [-483.476 -483.476 -483.476] [0.0000], Avg: [-455.221 -455.221 -455.221] (1.000)
Step: 83299, Reward: [-328.767 -328.767 -328.767] [0.0000], Avg: [-455.145 -455.145 -455.145] (1.000)
Step: 83349, Reward: [-366.657 -366.657 -366.657] [0.0000], Avg: [-455.092 -455.092 -455.092] (1.000)
Step: 83399, Reward: [-409.326 -409.326 -409.326] [0.0000], Avg: [-455.064 -455.064 -455.064] (1.000)
Step: 83449, Reward: [-369.948 -369.948 -369.948] [0.0000], Avg: [-455.013 -455.013 -455.013] (1.000)
Step: 83499, Reward: [-413.856 -413.856 -413.856] [0.0000], Avg: [-454.989 -454.989 -454.989] (1.000)
Step: 83549, Reward: [-334.621 -334.621 -334.621] [0.0000], Avg: [-454.917 -454.917 -454.917] (1.000)
Step: 83599, Reward: [-461.186 -461.186 -461.186] [0.0000], Avg: [-454.92 -454.92 -454.92] (1.000)
Step: 83649, Reward: [-511.276 -511.276 -511.276] [0.0000], Avg: [-454.954 -454.954 -454.954] (1.000)
Step: 83699, Reward: [-325.159 -325.159 -325.159] [0.0000], Avg: [-454.877 -454.877 -454.877] (1.000)
Step: 83749, Reward: [-434.401 -434.401 -434.401] [0.0000], Avg: [-454.864 -454.864 -454.864] (1.000)
Step: 83799, Reward: [-483.383 -483.383 -483.383] [0.0000], Avg: [-454.881 -454.881 -454.881] (1.000)
Step: 83849, Reward: [-341.009 -341.009 -341.009] [0.0000], Avg: [-454.813 -454.813 -454.813] (1.000)
Step: 83899, Reward: [-507.44 -507.44 -507.44] [0.0000], Avg: [-454.845 -454.845 -454.845] (1.000)
Step: 83949, Reward: [-376.861 -376.861 -376.861] [0.0000], Avg: [-454.798 -454.798 -454.798] (1.000)
Step: 83999, Reward: [-407.554 -407.554 -407.554] [0.0000], Avg: [-454.77 -454.77 -454.77] (1.000)
Step: 84049, Reward: [-496.834 -496.834 -496.834] [0.0000], Avg: [-454.795 -454.795 -454.795] (1.000)
Step: 84099, Reward: [-337.664 -337.664 -337.664] [0.0000], Avg: [-454.726 -454.726 -454.726] (1.000)
Step: 84149, Reward: [-320.654 -320.654 -320.654] [0.0000], Avg: [-454.646 -454.646 -454.646] (1.000)
Step: 84199, Reward: [-382.747 -382.747 -382.747] [0.0000], Avg: [-454.603 -454.603 -454.603] (1.000)
Step: 84249, Reward: [-433.234 -433.234 -433.234] [0.0000], Avg: [-454.591 -454.591 -454.591] (1.000)
Step: 84299, Reward: [-363.466 -363.466 -363.466] [0.0000], Avg: [-454.537 -454.537 -454.537] (1.000)
Step: 84349, Reward: [-411.291 -411.291 -411.291] [0.0000], Avg: [-454.511 -454.511 -454.511] (1.000)
Step: 84399, Reward: [-349.345 -349.345 -349.345] [0.0000], Avg: [-454.449 -454.449 -454.449] (1.000)
Step: 84449, Reward: [-423.703 -423.703 -423.703] [0.0000], Avg: [-454.43 -454.43 -454.43] (1.000)
Step: 84499, Reward: [-383.745 -383.745 -383.745] [0.0000], Avg: [-454.389 -454.389 -454.389] (1.000)
Step: 84549, Reward: [-399.047 -399.047 -399.047] [0.0000], Avg: [-454.356 -454.356 -454.356] (1.000)
Step: 84599, Reward: [-316.242 -316.242 -316.242] [0.0000], Avg: [-454.274 -454.274 -454.274] (1.000)
Step: 84649, Reward: [-393.576 -393.576 -393.576] [0.0000], Avg: [-454.238 -454.238 -454.238] (1.000)
Step: 84699, Reward: [-281.808 -281.808 -281.808] [0.0000], Avg: [-454.137 -454.137 -454.137] (1.000)
Step: 84749, Reward: [-394.47 -394.47 -394.47] [0.0000], Avg: [-454.101 -454.101 -454.101] (1.000)
Step: 84799, Reward: [-404.845 -404.845 -404.845] [0.0000], Avg: [-454.072 -454.072 -454.072] (1.000)
Step: 84849, Reward: [-353.237 -353.237 -353.237] [0.0000], Avg: [-454.013 -454.013 -454.013] (1.000)
Step: 84899, Reward: [-313.173 -313.173 -313.173] [0.0000], Avg: [-453.93 -453.93 -453.93] (1.000)
Step: 84949, Reward: [-357.089 -357.089 -357.089] [0.0000], Avg: [-453.873 -453.873 -453.873] (1.000)
Step: 84999, Reward: [-303.348 -303.348 -303.348] [0.0000], Avg: [-453.784 -453.784 -453.784] (1.000)
Step: 85049, Reward: [-463.168 -463.168 -463.168] [0.0000], Avg: [-453.79 -453.79 -453.79] (1.000)
Step: 85099, Reward: [-349.769 -349.769 -349.769] [0.0000], Avg: [-453.729 -453.729 -453.729] (1.000)
Step: 85149, Reward: [-343.29 -343.29 -343.29] [0.0000], Avg: [-453.664 -453.664 -453.664] (1.000)
Step: 85199, Reward: [-438.287 -438.287 -438.287] [0.0000], Avg: [-453.655 -453.655 -453.655] (1.000)
Step: 85249, Reward: [-306.644 -306.644 -306.644] [0.0000], Avg: [-453.569 -453.569 -453.569] (1.000)
Step: 85299, Reward: [-388.898 -388.898 -388.898] [0.0000], Avg: [-453.531 -453.531 -453.531] (1.000)
Step: 85349, Reward: [-328.343 -328.343 -328.343] [0.0000], Avg: [-453.457 -453.457 -453.457] (1.000)
Step: 85399, Reward: [-409.209 -409.209 -409.209] [0.0000], Avg: [-453.432 -453.432 -453.432] (1.000)
Step: 85449, Reward: [-547.838 -547.838 -547.838] [0.0000], Avg: [-453.487 -453.487 -453.487] (1.000)
Step: 85499, Reward: [-390.816 -390.816 -390.816] [0.0000], Avg: [-453.45 -453.45 -453.45] (1.000)
Step: 85549, Reward: [-339.961 -339.961 -339.961] [0.0000], Avg: [-453.384 -453.384 -453.384] (1.000)
Step: 85599, Reward: [-375.641 -375.641 -375.641] [0.0000], Avg: [-453.338 -453.338 -453.338] (1.000)
Step: 85649, Reward: [-397.006 -397.006 -397.006] [0.0000], Avg: [-453.306 -453.306 -453.306] (1.000)
Step: 85699, Reward: [-346.037 -346.037 -346.037] [0.0000], Avg: [-453.243 -453.243 -453.243] (1.000)
Step: 85749, Reward: [-387.022 -387.022 -387.022] [0.0000], Avg: [-453.204 -453.204 -453.204] (1.000)
Step: 85799, Reward: [-365.49 -365.49 -365.49] [0.0000], Avg: [-453.153 -453.153 -453.153] (1.000)
Step: 85849, Reward: [-299.658 -299.658 -299.658] [0.0000], Avg: [-453.064 -453.064 -453.064] (1.000)
Step: 85899, Reward: [-448.146 -448.146 -448.146] [0.0000], Avg: [-453.061 -453.061 -453.061] (1.000)
Step: 85949, Reward: [-378.684 -378.684 -378.684] [0.0000], Avg: [-453.018 -453.018 -453.018] (1.000)
Step: 85999, Reward: [-484.083 -484.083 -484.083] [0.0000], Avg: [-453.036 -453.036 -453.036] (1.000)
Step: 86049, Reward: [-357.282 -357.282 -357.282] [0.0000], Avg: [-452.98 -452.98 -452.98] (1.000)
Step: 86099, Reward: [-331.672 -331.672 -331.672] [0.0000], Avg: [-452.91 -452.91 -452.91] (1.000)
Step: 86149, Reward: [-391.934 -391.934 -391.934] [0.0000], Avg: [-452.874 -452.874 -452.874] (1.000)
Step: 86199, Reward: [-413.854 -413.854 -413.854] [0.0000], Avg: [-452.852 -452.852 -452.852] (1.000)
Step: 86249, Reward: [-282.527 -282.527 -282.527] [0.0000], Avg: [-452.753 -452.753 -452.753] (1.000)
Step: 86299, Reward: [-354.701 -354.701 -354.701] [0.0000], Avg: [-452.696 -452.696 -452.696] (1.000)
Step: 86349, Reward: [-488.864 -488.864 -488.864] [0.0000], Avg: [-452.717 -452.717 -452.717] (1.000)
Step: 86399, Reward: [-367.087 -367.087 -367.087] [0.0000], Avg: [-452.667 -452.667 -452.667] (1.000)
Step: 86449, Reward: [-298.599 -298.599 -298.599] [0.0000], Avg: [-452.578 -452.578 -452.578] (1.000)
Step: 86499, Reward: [-404.409 -404.409 -404.409] [0.0000], Avg: [-452.551 -452.551 -452.551] (1.000)
Step: 86549, Reward: [-411.655 -411.655 -411.655] [0.0000], Avg: [-452.527 -452.527 -452.527] (1.000)
Step: 86599, Reward: [-474.957 -474.957 -474.957] [0.0000], Avg: [-452.54 -452.54 -452.54] (1.000)
Step: 86649, Reward: [-367.825 -367.825 -367.825] [0.0000], Avg: [-452.491 -452.491 -452.491] (1.000)
Step: 86699, Reward: [-463.603 -463.603 -463.603] [0.0000], Avg: [-452.497 -452.497 -452.497] (1.000)
Step: 86749, Reward: [-370.761 -370.761 -370.761] [0.0000], Avg: [-452.45 -452.45 -452.45] (1.000)
Step: 86799, Reward: [-401.012 -401.012 -401.012] [0.0000], Avg: [-452.421 -452.421 -452.421] (1.000)
Step: 86849, Reward: [-451.691 -451.691 -451.691] [0.0000], Avg: [-452.42 -452.42 -452.42] (1.000)
Step: 86899, Reward: [-392.366 -392.366 -392.366] [0.0000], Avg: [-452.386 -452.386 -452.386] (1.000)
Step: 86949, Reward: [-306.637 -306.637 -306.637] [0.0000], Avg: [-452.302 -452.302 -452.302] (1.000)
Step: 86999, Reward: [-478.541 -478.541 -478.541] [0.0000], Avg: [-452.317 -452.317 -452.317] (1.000)
Step: 87049, Reward: [-312.822 -312.822 -312.822] [0.0000], Avg: [-452.237 -452.237 -452.237] (1.000)
Step: 87099, Reward: [-421.797 -421.797 -421.797] [0.0000], Avg: [-452.219 -452.219 -452.219] (1.000)
Step: 87149, Reward: [-311.059 -311.059 -311.059] [0.0000], Avg: [-452.138 -452.138 -452.138] (1.000)
Step: 87199, Reward: [-288.635 -288.635 -288.635] [0.0000], Avg: [-452.045 -452.045 -452.045] (1.000)
Step: 87249, Reward: [-404.74 -404.74 -404.74] [0.0000], Avg: [-452.017 -452.017 -452.017] (1.000)
Step: 87299, Reward: [-430.268 -430.268 -430.268] [0.0000], Avg: [-452.005 -452.005 -452.005] (1.000)
Step: 87349, Reward: [-237.556 -237.556 -237.556] [0.0000], Avg: [-451.882 -451.882 -451.882] (1.000)
Step: 87399, Reward: [-427.348 -427.348 -427.348] [0.0000], Avg: [-451.868 -451.868 -451.868] (1.000)
Step: 87449, Reward: [-358.129 -358.129 -358.129] [0.0000], Avg: [-451.815 -451.815 -451.815] (1.000)
Step: 87499, Reward: [-344.224 -344.224 -344.224] [0.0000], Avg: [-451.753 -451.753 -451.753] (1.000)
Step: 87549, Reward: [-454.664 -454.664 -454.664] [0.0000], Avg: [-451.755 -451.755 -451.755] (1.000)
Step: 87599, Reward: [-293.946 -293.946 -293.946] [0.0000], Avg: [-451.665 -451.665 -451.665] (1.000)
Step: 87649, Reward: [-326.633 -326.633 -326.633] [0.0000], Avg: [-451.593 -451.593 -451.593] (1.000)
Step: 87699, Reward: [-447.984 -447.984 -447.984] [0.0000], Avg: [-451.591 -451.591 -451.591] (1.000)
Step: 87749, Reward: [-365.506 -365.506 -365.506] [0.0000], Avg: [-451.542 -451.542 -451.542] (1.000)
Step: 87799, Reward: [-323.716 -323.716 -323.716] [0.0000], Avg: [-451.47 -451.47 -451.47] (1.000)
Step: 87849, Reward: [-380.502 -380.502 -380.502] [0.0000], Avg: [-451.429 -451.429 -451.429] (1.000)
Step: 87899, Reward: [-424.658 -424.658 -424.658] [0.0000], Avg: [-451.414 -451.414 -451.414] (1.000)
Step: 87949, Reward: [-315.398 -315.398 -315.398] [0.0000], Avg: [-451.337 -451.337 -451.337] (1.000)
Step: 87999, Reward: [-382.854 -382.854 -382.854] [0.0000], Avg: [-451.298 -451.298 -451.298] (1.000)
Step: 88049, Reward: [-365.587 -365.587 -365.587] [0.0000], Avg: [-451.249 -451.249 -451.249] (1.000)
Step: 88099, Reward: [-368.457 -368.457 -368.457] [0.0000], Avg: [-451.202 -451.202 -451.202] (1.000)
Step: 88149, Reward: [-356.523 -356.523 -356.523] [0.0000], Avg: [-451.148 -451.148 -451.148] (1.000)
Step: 88199, Reward: [-351.514 -351.514 -351.514] [0.0000], Avg: [-451.092 -451.092 -451.092] (1.000)
Step: 88249, Reward: [-423.964 -423.964 -423.964] [0.0000], Avg: [-451.076 -451.076 -451.076] (1.000)
Step: 88299, Reward: [-453.431 -453.431 -453.431] [0.0000], Avg: [-451.078 -451.078 -451.078] (1.000)
Step: 88349, Reward: [-334.534 -334.534 -334.534] [0.0000], Avg: [-451.012 -451.012 -451.012] (1.000)
Step: 88399, Reward: [-311.925 -311.925 -311.925] [0.0000], Avg: [-450.933 -450.933 -450.933] (1.000)
Step: 88449, Reward: [-332.838 -332.838 -332.838] [0.0000], Avg: [-450.866 -450.866 -450.866] (1.000)
Step: 88499, Reward: [-334.38 -334.38 -334.38] [0.0000], Avg: [-450.801 -450.801 -450.801] (1.000)
Step: 88549, Reward: [-310.675 -310.675 -310.675] [0.0000], Avg: [-450.721 -450.721 -450.721] (1.000)
Step: 88599, Reward: [-553.28 -553.28 -553.28] [0.0000], Avg: [-450.779 -450.779 -450.779] (1.000)
Step: 88649, Reward: [-332.36 -332.36 -332.36] [0.0000], Avg: [-450.713 -450.713 -450.713] (1.000)
Step: 88699, Reward: [-324.893 -324.893 -324.893] [0.0000], Avg: [-450.642 -450.642 -450.642] (1.000)
Step: 88749, Reward: [-317.715 -317.715 -317.715] [0.0000], Avg: [-450.567 -450.567 -450.567] (1.000)
Step: 88799, Reward: [-389.669 -389.669 -389.669] [0.0000], Avg: [-450.532 -450.532 -450.532] (1.000)
Step: 88849, Reward: [-387.631 -387.631 -387.631] [0.0000], Avg: [-450.497 -450.497 -450.497] (1.000)
Step: 88899, Reward: [-377.801 -377.801 -377.801] [0.0000], Avg: [-450.456 -450.456 -450.456] (1.000)
Step: 88949, Reward: [-330.985 -330.985 -330.985] [0.0000], Avg: [-450.389 -450.389 -450.389] (1.000)
Step: 88999, Reward: [-457.933 -457.933 -457.933] [0.0000], Avg: [-450.393 -450.393 -450.393] (1.000)
Step: 89049, Reward: [-396.422 -396.422 -396.422] [0.0000], Avg: [-450.363 -450.363 -450.363] (1.000)
Step: 89099, Reward: [-382.552 -382.552 -382.552] [0.0000], Avg: [-450.325 -450.325 -450.325] (1.000)
Step: 89149, Reward: [-484.699 -484.699 -484.699] [0.0000], Avg: [-450.344 -450.344 -450.344] (1.000)
Step: 89199, Reward: [-344.226 -344.226 -344.226] [0.0000], Avg: [-450.285 -450.285 -450.285] (1.000)
Step: 89249, Reward: [-359.449 -359.449 -359.449] [0.0000], Avg: [-450.234 -450.234 -450.234] (1.000)
Step: 89299, Reward: [-461.784 -461.784 -461.784] [0.0000], Avg: [-450.24 -450.24 -450.24] (1.000)
Step: 89349, Reward: [-356.4 -356.4 -356.4] [0.0000], Avg: [-450.188 -450.188 -450.188] (1.000)
Step: 89399, Reward: [-345.521 -345.521 -345.521] [0.0000], Avg: [-450.129 -450.129 -450.129] (1.000)
Step: 89449, Reward: [-382.579 -382.579 -382.579] [0.0000], Avg: [-450.091 -450.091 -450.091] (1.000)
Step: 89499, Reward: [-396.933 -396.933 -396.933] [0.0000], Avg: [-450.062 -450.062 -450.062] (1.000)
Step: 89549, Reward: [-399.828 -399.828 -399.828] [0.0000], Avg: [-450.034 -450.034 -450.034] (1.000)
Step: 89599, Reward: [-302.78 -302.78 -302.78] [0.0000], Avg: [-449.952 -449.952 -449.952] (1.000)
Step: 89649, Reward: [-404.153 -404.153 -404.153] [0.0000], Avg: [-449.926 -449.926 -449.926] (1.000)
Step: 89699, Reward: [-446.931 -446.931 -446.931] [0.0000], Avg: [-449.924 -449.924 -449.924] (1.000)
Step: 89749, Reward: [-336.824 -336.824 -336.824] [0.0000], Avg: [-449.861 -449.861 -449.861] (1.000)
Step: 89799, Reward: [-289.192 -289.192 -289.192] [0.0000], Avg: [-449.772 -449.772 -449.772] (1.000)
Step: 89849, Reward: [-444.658 -444.658 -444.658] [0.0000], Avg: [-449.769 -449.769 -449.769] (1.000)
Step: 89899, Reward: [-292.644 -292.644 -292.644] [0.0000], Avg: [-449.682 -449.682 -449.682] (1.000)
Step: 89949, Reward: [-347.531 -347.531 -347.531] [0.0000], Avg: [-449.625 -449.625 -449.625] (1.000)
Step: 89999, Reward: [-600.684 -600.684 -600.684] [0.0000], Avg: [-449.709 -449.709 -449.709] (1.000)
Step: 90049, Reward: [-378.273 -378.273 -378.273] [0.0000], Avg: [-449.669 -449.669 -449.669] (1.000)
Step: 90099, Reward: [-475.189 -475.189 -475.189] [0.0000], Avg: [-449.683 -449.683 -449.683] (1.000)
Step: 90149, Reward: [-390.946 -390.946 -390.946] [0.0000], Avg: [-449.651 -449.651 -449.651] (1.000)
Step: 90199, Reward: [-298.112 -298.112 -298.112] [0.0000], Avg: [-449.567 -449.567 -449.567] (1.000)
Step: 90249, Reward: [-369.847 -369.847 -369.847] [0.0000], Avg: [-449.523 -449.523 -449.523] (1.000)
Step: 90299, Reward: [-346.298 -346.298 -346.298] [0.0000], Avg: [-449.465 -449.465 -449.465] (1.000)
Step: 90349, Reward: [-404.086 -404.086 -404.086] [0.0000], Avg: [-449.44 -449.44 -449.44] (1.000)
Step: 90399, Reward: [-375.671 -375.671 -375.671] [0.0000], Avg: [-449.399 -449.399 -449.399] (1.000)
Step: 90449, Reward: [-397.33 -397.33 -397.33] [0.0000], Avg: [-449.371 -449.371 -449.371] (1.000)
Step: 90499, Reward: [-411.004 -411.004 -411.004] [0.0000], Avg: [-449.349 -449.349 -449.349] (1.000)
Step: 90549, Reward: [-392.835 -392.835 -392.835] [0.0000], Avg: [-449.318 -449.318 -449.318] (1.000)
Step: 90599, Reward: [-365.931 -365.931 -365.931] [0.0000], Avg: [-449.272 -449.272 -449.272] (1.000)
Step: 90649, Reward: [-493.426 -493.426 -493.426] [0.0000], Avg: [-449.297 -449.297 -449.297] (1.000)
Step: 90699, Reward: [-299.862 -299.862 -299.862] [0.0000], Avg: [-449.214 -449.214 -449.214] (1.000)
Step: 90749, Reward: [-475.82 -475.82 -475.82] [0.0000], Avg: [-449.229 -449.229 -449.229] (1.000)
Step: 90799, Reward: [-327.938 -327.938 -327.938] [0.0000], Avg: [-449.162 -449.162 -449.162] (1.000)
Step: 90849, Reward: [-516.06 -516.06 -516.06] [0.0000], Avg: [-449.199 -449.199 -449.199] (1.000)
Step: 90899, Reward: [-434.464 -434.464 -434.464] [0.0000], Avg: [-449.191 -449.191 -449.191] (1.000)
Step: 90949, Reward: [-480.378 -480.378 -480.378] [0.0000], Avg: [-449.208 -449.208 -449.208] (1.000)
Step: 90999, Reward: [-489.486 -489.486 -489.486] [0.0000], Avg: [-449.23 -449.23 -449.23] (1.000)
Step: 91049, Reward: [-431.953 -431.953 -431.953] [0.0000], Avg: [-449.221 -449.221 -449.221] (1.000)
Step: 91099, Reward: [-437.56 -437.56 -437.56] [0.0000], Avg: [-449.214 -449.214 -449.214] (1.000)
Step: 91149, Reward: [-288.856 -288.856 -288.856] [0.0000], Avg: [-449.126 -449.126 -449.126] (1.000)
Step: 91199, Reward: [-502.805 -502.805 -502.805] [0.0000], Avg: [-449.156 -449.156 -449.156] (1.000)
Step: 91249, Reward: [-332.254 -332.254 -332.254] [0.0000], Avg: [-449.092 -449.092 -449.092] (1.000)
Step: 91299, Reward: [-315.794 -315.794 -315.794] [0.0000], Avg: [-449.019 -449.019 -449.019] (1.000)
Step: 91349, Reward: [-379.823 -379.823 -379.823] [0.0000], Avg: [-448.981 -448.981 -448.981] (1.000)
Step: 91399, Reward: [-428.022 -428.022 -428.022] [0.0000], Avg: [-448.969 -448.969 -448.969] (1.000)
Step: 91449, Reward: [-400.611 -400.611 -400.611] [0.0000], Avg: [-448.943 -448.943 -448.943] (1.000)
Step: 91499, Reward: [-516.904 -516.904 -516.904] [0.0000], Avg: [-448.98 -448.98 -448.98] (1.000)
Step: 91549, Reward: [-266.845 -266.845 -266.845] [0.0000], Avg: [-448.88 -448.88 -448.88] (1.000)
Step: 91599, Reward: [-316.498 -316.498 -316.498] [0.0000], Avg: [-448.808 -448.808 -448.808] (1.000)
Step: 91649, Reward: [-301.623 -301.623 -301.623] [0.0000], Avg: [-448.728 -448.728 -448.728] (1.000)
Step: 91699, Reward: [-382.181 -382.181 -382.181] [0.0000], Avg: [-448.692 -448.692 -448.692] (1.000)
Step: 91749, Reward: [-309.179 -309.179 -309.179] [0.0000], Avg: [-448.616 -448.616 -448.616] (1.000)
Step: 91799, Reward: [-403.317 -403.317 -403.317] [0.0000], Avg: [-448.591 -448.591 -448.591] (1.000)
Step: 91849, Reward: [-501.614 -501.614 -501.614] [0.0000], Avg: [-448.62 -448.62 -448.62] (1.000)
Step: 91899, Reward: [-534.399 -534.399 -534.399] [0.0000], Avg: [-448.666 -448.666 -448.666] (1.000)
Step: 91949, Reward: [-451.536 -451.536 -451.536] [0.0000], Avg: [-448.668 -448.668 -448.668] (1.000)
Step: 91999, Reward: [-277.994 -277.994 -277.994] [0.0000], Avg: [-448.575 -448.575 -448.575] (1.000)
Step: 92049, Reward: [-346.446 -346.446 -346.446] [0.0000], Avg: [-448.52 -448.52 -448.52] (1.000)
Step: 92099, Reward: [-421.438 -421.438 -421.438] [0.0000], Avg: [-448.505 -448.505 -448.505] (1.000)
Step: 92149, Reward: [-332.126 -332.126 -332.126] [0.0000], Avg: [-448.442 -448.442 -448.442] (1.000)
Step: 92199, Reward: [-307.233 -307.233 -307.233] [0.0000], Avg: [-448.365 -448.365 -448.365] (1.000)
Step: 92249, Reward: [-266.546 -266.546 -266.546] [0.0000], Avg: [-448.267 -448.267 -448.267] (1.000)
Step: 92299, Reward: [-473.802 -473.802 -473.802] [0.0000], Avg: [-448.281 -448.281 -448.281] (1.000)
Step: 92349, Reward: [-439.691 -439.691 -439.691] [0.0000], Avg: [-448.276 -448.276 -448.276] (1.000)
Step: 92399, Reward: [-287.466 -287.466 -287.466] [0.0000], Avg: [-448.189 -448.189 -448.189] (1.000)
Step: 92449, Reward: [-351.722 -351.722 -351.722] [0.0000], Avg: [-448.137 -448.137 -448.137] (1.000)
Step: 92499, Reward: [-375.897 -375.897 -375.897] [0.0000], Avg: [-448.098 -448.098 -448.098] (1.000)
Step: 92549, Reward: [-515.32 -515.32 -515.32] [0.0000], Avg: [-448.134 -448.134 -448.134] (1.000)
Step: 92599, Reward: [-335.606 -335.606 -335.606] [0.0000], Avg: [-448.073 -448.073 -448.073] (1.000)
Step: 92649, Reward: [-298.118 -298.118 -298.118] [0.0000], Avg: [-447.992 -447.992 -447.992] (1.000)
Step: 92699, Reward: [-392.372 -392.372 -392.372] [0.0000], Avg: [-447.962 -447.962 -447.962] (1.000)
Step: 92749, Reward: [-285.039 -285.039 -285.039] [0.0000], Avg: [-447.875 -447.875 -447.875] (1.000)
Step: 92799, Reward: [-406.096 -406.096 -406.096] [0.0000], Avg: [-447.852 -447.852 -447.852] (1.000)
Step: 92849, Reward: [-423.736 -423.736 -423.736] [0.0000], Avg: [-447.839 -447.839 -447.839] (1.000)
Step: 92899, Reward: [-376.533 -376.533 -376.533] [0.0000], Avg: [-447.801 -447.801 -447.801] (1.000)
Step: 92949, Reward: [-340.235 -340.235 -340.235] [0.0000], Avg: [-447.743 -447.743 -447.743] (1.000)
Step: 92999, Reward: [-321.996 -321.996 -321.996] [0.0000], Avg: [-447.675 -447.675 -447.675] (1.000)
Step: 93049, Reward: [-409.551 -409.551 -409.551] [0.0000], Avg: [-447.655 -447.655 -447.655] (1.000)
Step: 93099, Reward: [-495.782 -495.782 -495.782] [0.0000], Avg: [-447.681 -447.681 -447.681] (1.000)
Step: 93149, Reward: [-357.947 -357.947 -357.947] [0.0000], Avg: [-447.632 -447.632 -447.632] (1.000)
Step: 93199, Reward: [-346.592 -346.592 -346.592] [0.0000], Avg: [-447.578 -447.578 -447.578] (1.000)
Step: 93249, Reward: [-441.872 -441.872 -441.872] [0.0000], Avg: [-447.575 -447.575 -447.575] (1.000)
Step: 93299, Reward: [-433.146 -433.146 -433.146] [0.0000], Avg: [-447.567 -447.567 -447.567] (1.000)
Step: 93349, Reward: [-439.091 -439.091 -439.091] [0.0000], Avg: [-447.563 -447.563 -447.563] (1.000)
Step: 93399, Reward: [-357.23 -357.23 -357.23] [0.0000], Avg: [-447.515 -447.515 -447.515] (1.000)
Step: 93449, Reward: [-411.188 -411.188 -411.188] [0.0000], Avg: [-447.495 -447.495 -447.495] (1.000)
Step: 93499, Reward: [-309.619 -309.619 -309.619] [0.0000], Avg: [-447.421 -447.421 -447.421] (1.000)
Step: 93549, Reward: [-362.422 -362.422 -362.422] [0.0000], Avg: [-447.376 -447.376 -447.376] (1.000)
Step: 93599, Reward: [-451.907 -451.907 -451.907] [0.0000], Avg: [-447.378 -447.378 -447.378] (1.000)
Step: 93649, Reward: [-372.333 -372.333 -372.333] [0.0000], Avg: [-447.338 -447.338 -447.338] (1.000)
Step: 93699, Reward: [-300.966 -300.966 -300.966] [0.0000], Avg: [-447.26 -447.26 -447.26] (1.000)
Step: 93749, Reward: [-395.146 -395.146 -395.146] [0.0000], Avg: [-447.232 -447.232 -447.232] (1.000)
Step: 93799, Reward: [-386.558 -386.558 -386.558] [0.0000], Avg: [-447.2 -447.2 -447.2] (1.000)
Step: 93849, Reward: [-280.525 -280.525 -280.525] [0.0000], Avg: [-447.111 -447.111 -447.111] (1.000)
Step: 93899, Reward: [-303.83 -303.83 -303.83] [0.0000], Avg: [-447.035 -447.035 -447.035] (1.000)
Step: 93949, Reward: [-365.807 -365.807 -365.807] [0.0000], Avg: [-446.992 -446.992 -446.992] (1.000)
Step: 93999, Reward: [-465.207 -465.207 -465.207] [0.0000], Avg: [-447.001 -447.001 -447.001] (1.000)
Step: 94049, Reward: [-370.903 -370.903 -370.903] [0.0000], Avg: [-446.961 -446.961 -446.961] (1.000)
Step: 94099, Reward: [-280.339 -280.339 -280.339] [0.0000], Avg: [-446.872 -446.872 -446.872] (1.000)
Step: 94149, Reward: [-325.652 -325.652 -325.652] [0.0000], Avg: [-446.808 -446.808 -446.808] (1.000)
Step: 94199, Reward: [-400.891 -400.891 -400.891] [0.0000], Avg: [-446.784 -446.784 -446.784] (1.000)
Step: 94249, Reward: [-387.173 -387.173 -387.173] [0.0000], Avg: [-446.752 -446.752 -446.752] (1.000)
Step: 94299, Reward: [-393.623 -393.623 -393.623] [0.0000], Avg: [-446.724 -446.724 -446.724] (1.000)
Step: 94349, Reward: [-438.9 -438.9 -438.9] [0.0000], Avg: [-446.72 -446.72 -446.72] (1.000)
Step: 94399, Reward: [-349.325 -349.325 -349.325] [0.0000], Avg: [-446.668 -446.668 -446.668] (1.000)
Step: 94449, Reward: [-297.508 -297.508 -297.508] [0.0000], Avg: [-446.589 -446.589 -446.589] (1.000)
Step: 94499, Reward: [-308.093 -308.093 -308.093] [0.0000], Avg: [-446.516 -446.516 -446.516] (1.000)
Step: 94549, Reward: [-287.113 -287.113 -287.113] [0.0000], Avg: [-446.432 -446.432 -446.432] (1.000)
Step: 94599, Reward: [-388.306 -388.306 -388.306] [0.0000], Avg: [-446.401 -446.401 -446.401] (1.000)
Step: 94649, Reward: [-402.532 -402.532 -402.532] [0.0000], Avg: [-446.378 -446.378 -446.378] (1.000)
Step: 94699, Reward: [-322.836 -322.836 -322.836] [0.0000], Avg: [-446.312 -446.312 -446.312] (1.000)
Step: 94749, Reward: [-427.544 -427.544 -427.544] [0.0000], Avg: [-446.303 -446.303 -446.303] (1.000)
Step: 94799, Reward: [-367.383 -367.383 -367.383] [0.0000], Avg: [-446.261 -446.261 -446.261] (1.000)
Step: 94849, Reward: [-367.743 -367.743 -367.743] [0.0000], Avg: [-446.22 -446.22 -446.22] (1.000)
Step: 94899, Reward: [-463.124 -463.124 -463.124] [0.0000], Avg: [-446.228 -446.228 -446.228] (1.000)
Step: 94949, Reward: [-471.727 -471.727 -471.727] [0.0000], Avg: [-446.242 -446.242 -446.242] (1.000)
Step: 94999, Reward: [-398.766 -398.766 -398.766] [0.0000], Avg: [-446.217 -446.217 -446.217] (1.000)
Step: 95049, Reward: [-494.59 -494.59 -494.59] [0.0000], Avg: [-446.242 -446.242 -446.242] (1.000)
Step: 95099, Reward: [-289.526 -289.526 -289.526] [0.0000], Avg: [-446.16 -446.16 -446.16] (1.000)
Step: 95149, Reward: [-317.382 -317.382 -317.382] [0.0000], Avg: [-446.092 -446.092 -446.092] (1.000)
Step: 95199, Reward: [-314.157 -314.157 -314.157] [0.0000], Avg: [-446.023 -446.023 -446.023] (1.000)
Step: 95249, Reward: [-345.698 -345.698 -345.698] [0.0000], Avg: [-445.97 -445.97 -445.97] (1.000)
Step: 95299, Reward: [-431.54 -431.54 -431.54] [0.0000], Avg: [-445.963 -445.963 -445.963] (1.000)
Step: 95349, Reward: [-320.098 -320.098 -320.098] [0.0000], Avg: [-445.897 -445.897 -445.897] (1.000)
Step: 95399, Reward: [-442.873 -442.873 -442.873] [0.0000], Avg: [-445.895 -445.895 -445.895] (1.000)
Step: 95449, Reward: [-384.721 -384.721 -384.721] [0.0000], Avg: [-445.863 -445.863 -445.863] (1.000)
Step: 95499, Reward: [-375.398 -375.398 -375.398] [0.0000], Avg: [-445.826 -445.826 -445.826] (1.000)
Step: 95549, Reward: [-397.193 -397.193 -397.193] [0.0000], Avg: [-445.801 -445.801 -445.801] (1.000)
Step: 95599, Reward: [-358.531 -358.531 -358.531] [0.0000], Avg: [-445.755 -445.755 -445.755] (1.000)
Step: 95649, Reward: [-323.338 -323.338 -323.338] [0.0000], Avg: [-445.691 -445.691 -445.691] (1.000)
Step: 95699, Reward: [-498.456 -498.456 -498.456] [0.0000], Avg: [-445.719 -445.719 -445.719] (1.000)
Step: 95749, Reward: [-318.117 -318.117 -318.117] [0.0000], Avg: [-445.652 -445.652 -445.652] (1.000)
Step: 95799, Reward: [-466.405 -466.405 -466.405] [0.0000], Avg: [-445.663 -445.663 -445.663] (1.000)
Step: 95849, Reward: [-344.039 -344.039 -344.039] [0.0000], Avg: [-445.61 -445.61 -445.61] (1.000)
Step: 95899, Reward: [-357.269 -357.269 -357.269] [0.0000], Avg: [-445.564 -445.564 -445.564] (1.000)
Step: 95949, Reward: [-446.291 -446.291 -446.291] [0.0000], Avg: [-445.564 -445.564 -445.564] (1.000)
Step: 95999, Reward: [-305.382 -305.382 -305.382] [0.0000], Avg: [-445.491 -445.491 -445.491] (1.000)
Step: 96049, Reward: [-299.024 -299.024 -299.024] [0.0000], Avg: [-445.415 -445.415 -445.415] (1.000)
Step: 96099, Reward: [-336.968 -336.968 -336.968] [0.0000], Avg: [-445.359 -445.359 -445.359] (1.000)
Step: 96149, Reward: [-324.821 -324.821 -324.821] [0.0000], Avg: [-445.296 -445.296 -445.296] (1.000)
Step: 96199, Reward: [-459.718 -459.718 -459.718] [0.0000], Avg: [-445.303 -445.303 -445.303] (1.000)
Step: 96249, Reward: [-420.831 -420.831 -420.831] [0.0000], Avg: [-445.291 -445.291 -445.291] (1.000)
Step: 96299, Reward: [-366.68 -366.68 -366.68] [0.0000], Avg: [-445.25 -445.25 -445.25] (1.000)
Step: 96349, Reward: [-439.081 -439.081 -439.081] [0.0000], Avg: [-445.247 -445.247 -445.247] (1.000)
Step: 96399, Reward: [-471.035 -471.035 -471.035] [0.0000], Avg: [-445.26 -445.26 -445.26] (1.000)
Step: 96449, Reward: [-351.675 -351.675 -351.675] [0.0000], Avg: [-445.211 -445.211 -445.211] (1.000)
Step: 96499, Reward: [-371.693 -371.693 -371.693] [0.0000], Avg: [-445.173 -445.173 -445.173] (1.000)
Step: 96549, Reward: [-391.25 -391.25 -391.25] [0.0000], Avg: [-445.145 -445.145 -445.145] (1.000)
Step: 96599, Reward: [-441.675 -441.675 -441.675] [0.0000], Avg: [-445.144 -445.144 -445.144] (1.000)
Step: 96649, Reward: [-502.748 -502.748 -502.748] [0.0000], Avg: [-445.173 -445.173 -445.173] (1.000)
Step: 96699, Reward: [-440.814 -440.814 -440.814] [0.0000], Avg: [-445.171 -445.171 -445.171] (1.000)
Step: 96749, Reward: [-473.898 -473.898 -473.898] [0.0000], Avg: [-445.186 -445.186 -445.186] (1.000)
Step: 96799, Reward: [-397.582 -397.582 -397.582] [0.0000], Avg: [-445.161 -445.161 -445.161] (1.000)
Step: 96849, Reward: [-339.8 -339.8 -339.8] [0.0000], Avg: [-445.107 -445.107 -445.107] (1.000)
Step: 96899, Reward: [-455.711 -455.711 -455.711] [0.0000], Avg: [-445.113 -445.113 -445.113] (1.000)
Step: 96949, Reward: [-373.861 -373.861 -373.861] [0.0000], Avg: [-445.076 -445.076 -445.076] (1.000)
Step: 96999, Reward: [-373.792 -373.792 -373.792] [0.0000], Avg: [-445.039 -445.039 -445.039] (1.000)
Step: 97049, Reward: [-381.895 -381.895 -381.895] [0.0000], Avg: [-445.007 -445.007 -445.007] (1.000)
Step: 97099, Reward: [-337.304 -337.304 -337.304] [0.0000], Avg: [-444.951 -444.951 -444.951] (1.000)
Step: 97149, Reward: [-319.648 -319.648 -319.648] [0.0000], Avg: [-444.887 -444.887 -444.887] (1.000)
Step: 97199, Reward: [-404.128 -404.128 -404.128] [0.0000], Avg: [-444.866 -444.866 -444.866] (1.000)
Step: 97249, Reward: [-412.721 -412.721 -412.721] [0.0000], Avg: [-444.849 -444.849 -444.849] (1.000)
Step: 97299, Reward: [-339.35 -339.35 -339.35] [0.0000], Avg: [-444.795 -444.795 -444.795] (1.000)
Step: 97349, Reward: [-361.476 -361.476 -361.476] [0.0000], Avg: [-444.752 -444.752 -444.752] (1.000)
Step: 97399, Reward: [-494.992 -494.992 -494.992] [0.0000], Avg: [-444.778 -444.778 -444.778] (1.000)
Step: 97449, Reward: [-370.319 -370.319 -370.319] [0.0000], Avg: [-444.74 -444.74 -444.74] (1.000)
Step: 97499, Reward: [-344.874 -344.874 -344.874] [0.0000], Avg: [-444.688 -444.688 -444.688] (1.000)
Step: 97549, Reward: [-366.365 -366.365 -366.365] [0.0000], Avg: [-444.648 -444.648 -444.648] (1.000)
Step: 97599, Reward: [-316.54 -316.54 -316.54] [0.0000], Avg: [-444.583 -444.583 -444.583] (1.000)
Step: 97649, Reward: [-389.063 -389.063 -389.063] [0.0000], Avg: [-444.554 -444.554 -444.554] (1.000)
Step: 97699, Reward: [-301.14 -301.14 -301.14] [0.0000], Avg: [-444.481 -444.481 -444.481] (1.000)
Step: 97749, Reward: [-421.889 -421.889 -421.889] [0.0000], Avg: [-444.469 -444.469 -444.469] (1.000)
Step: 97799, Reward: [-421.862 -421.862 -421.862] [0.0000], Avg: [-444.458 -444.458 -444.458] (1.000)
Step: 97849, Reward: [-341.127 -341.127 -341.127] [0.0000], Avg: [-444.405 -444.405 -444.405] (1.000)
Step: 97899, Reward: [-435.866 -435.866 -435.866] [0.0000], Avg: [-444.401 -444.401 -444.401] (1.000)
Step: 97949, Reward: [-341.139 -341.139 -341.139] [0.0000], Avg: [-444.348 -444.348 -444.348] (1.000)
Step: 97999, Reward: [-312.639 -312.639 -312.639] [0.0000], Avg: [-444.281 -444.281 -444.281] (1.000)
Step: 98049, Reward: [-352.817 -352.817 -352.817] [0.0000], Avg: [-444.234 -444.234 -444.234] (1.000)
Step: 98099, Reward: [-391.183 -391.183 -391.183] [0.0000], Avg: [-444.207 -444.207 -444.207] (1.000)
Step: 98149, Reward: [-393.031 -393.031 -393.031] [0.0000], Avg: [-444.181 -444.181 -444.181] (1.000)
Step: 98199, Reward: [-259.222 -259.222 -259.222] [0.0000], Avg: [-444.087 -444.087 -444.087] (1.000)
Step: 98249, Reward: [-308.272 -308.272 -308.272] [0.0000], Avg: [-444.018 -444.018 -444.018] (1.000)
Step: 98299, Reward: [-325.692 -325.692 -325.692] [0.0000], Avg: [-443.957 -443.957 -443.957] (1.000)
Step: 98349, Reward: [-274.337 -274.337 -274.337] [0.0000], Avg: [-443.871 -443.871 -443.871] (1.000)
Step: 98399, Reward: [-375.082 -375.082 -375.082] [0.0000], Avg: [-443.836 -443.836 -443.836] (1.000)
Step: 98449, Reward: [-362.752 -362.752 -362.752] [0.0000], Avg: [-443.795 -443.795 -443.795] (1.000)
Step: 98499, Reward: [-318.369 -318.369 -318.369] [0.0000], Avg: [-443.731 -443.731 -443.731] (1.000)
Step: 98549, Reward: [-461.984 -461.984 -461.984] [0.0000], Avg: [-443.741 -443.741 -443.741] (1.000)
Step: 98599, Reward: [-396.462 -396.462 -396.462] [0.0000], Avg: [-443.717 -443.717 -443.717] (1.000)
Step: 98649, Reward: [-369.168 -369.168 -369.168] [0.0000], Avg: [-443.679 -443.679 -443.679] (1.000)
Step: 98699, Reward: [-402.263 -402.263 -402.263] [0.0000], Avg: [-443.658 -443.658 -443.658] (1.000)
Step: 98749, Reward: [-440.056 -440.056 -440.056] [0.0000], Avg: [-443.656 -443.656 -443.656] (1.000)
Step: 98799, Reward: [-284.017 -284.017 -284.017] [0.0000], Avg: [-443.575 -443.575 -443.575] (1.000)
Step: 98849, Reward: [-413.252 -413.252 -413.252] [0.0000], Avg: [-443.56 -443.56 -443.56] (1.000)
Step: 98899, Reward: [-367.161 -367.161 -367.161] [0.0000], Avg: [-443.521 -443.521 -443.521] (1.000)
Step: 98949, Reward: [-378.331 -378.331 -378.331] [0.0000], Avg: [-443.488 -443.488 -443.488] (1.000)
Step: 98999, Reward: [-281.102 -281.102 -281.102] [0.0000], Avg: [-443.406 -443.406 -443.406] (1.000)
Step: 99049, Reward: [-290.447 -290.447 -290.447] [0.0000], Avg: [-443.329 -443.329 -443.329] (1.000)
Step: 99099, Reward: [-443.9 -443.9 -443.9] [0.0000], Avg: [-443.329 -443.329 -443.329] (1.000)
Step: 99149, Reward: [-434.532 -434.532 -434.532] [0.0000], Avg: [-443.325 -443.325 -443.325] (1.000)
Step: 99199, Reward: [-276.21 -276.21 -276.21] [0.0000], Avg: [-443.241 -443.241 -443.241] (1.000)
Step: 99249, Reward: [-418.318 -418.318 -418.318] [0.0000], Avg: [-443.228 -443.228 -443.228] (1.000)
Step: 99299, Reward: [-386.201 -386.201 -386.201] [0.0000], Avg: [-443.2 -443.2 -443.2] (1.000)
Step: 99349, Reward: [-344.167 -344.167 -344.167] [0.0000], Avg: [-443.15 -443.15 -443.15] (1.000)
Step: 99399, Reward: [-393.099 -393.099 -393.099] [0.0000], Avg: [-443.125 -443.125 -443.125] (1.000)
Step: 99449, Reward: [-477.142 -477.142 -477.142] [0.0000], Avg: [-443.142 -443.142 -443.142] (1.000)
Step: 99499, Reward: [-373.464 -373.464 -373.464] [0.0000], Avg: [-443.107 -443.107 -443.107] (1.000)
Step: 99549, Reward: [-282.276 -282.276 -282.276] [0.0000], Avg: [-443.026 -443.026 -443.026] (1.000)
Step: 99599, Reward: [-371.319 -371.319 -371.319] [0.0000], Avg: [-442.99 -442.99 -442.99] (1.000)
Step: 99649, Reward: [-353.567 -353.567 -353.567] [0.0000], Avg: [-442.945 -442.945 -442.945] (1.000)
Step: 99699, Reward: [-338.752 -338.752 -338.752] [0.0000], Avg: [-442.893 -442.893 -442.893] (1.000)
Step: 99749, Reward: [-315.766 -315.766 -315.766] [0.0000], Avg: [-442.829 -442.829 -442.829] (1.000)
Step: 99799, Reward: [-267.08 -267.08 -267.08] [0.0000], Avg: [-442.741 -442.741 -442.741] (1.000)
Step: 99849, Reward: [-292.783 -292.783 -292.783] [0.0000], Avg: [-442.666 -442.666 -442.666] (1.000)
Step: 99899, Reward: [-274.622 -274.622 -274.622] [0.0000], Avg: [-442.582 -442.582 -442.582] (1.000)
Step: 99949, Reward: [-328.394 -328.394 -328.394] [0.0000], Avg: [-442.525 -442.525 -442.525] (1.000)
Step: 99999, Reward: [-467.521 -467.521 -467.521] [0.0000], Avg: [-442.537 -442.537 -442.537] (1.000)
