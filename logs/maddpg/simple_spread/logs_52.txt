Model: <class 'multiagent.maddpg.MADDPGAgent'>, Dir: simple_spread
num_envs: 1, state_size: [(1, 18), (1, 18), (1, 18)], action_size: [[1, 5], [1, 5], [1, 5]], action_space: [<gym.spaces.multi_discrete.MultiDiscrete object at 0x7f44f29da940>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f44f29da9e8>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f44f29daa58>],

import torch
import random
import numpy as np
from models.rand import MultiagentReplayBuffer
from models.ddpg import DDPGActor, DDPGCritic, DDPGNetwork
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACAgent, LEARN_RATE, NUM_STEPS, EPS_MIN, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, MAX_BUFFER_SIZE, gumbel_softmax, one_hot

REPLAY_BATCH_SIZE = 1024
ENTROPY_WEIGHT = 0.001			# The weight for the entropy term of the Actor loss
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64
LEARN_RATE = 0.01
TARGET_UPDATE_RATE = 0.01

class MADDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, sample=True):
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		action_mu = self.action_mu(state)
		action = gumbel_softmax(action_mu, hard=True)
		action = action.view(*out_dims, -1)
		return action
	
class MADDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1]+action_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1]+action_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, action):
		state = torch.cat([state, action], -1)
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		q_value = self.q_value(state)
		q_value = q_value.view(*out_dims, -1)
		return q_value

class MADDPGNetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=True, load=None):
		super().__init__(tau=tau, gpu=gpu)
		self.state_size = state_size
		self.action_size = action_size
		self.critic = MADDPGCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.models = [DDPGNetwork(s_size, a_size, MADDPGActor, lambda s,a: self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		
	def get_action_probs(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [model.get_action(s, use_target, grad, numpy, sample) for s,model in zip(state, self.models)]
			return action

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_value = [model.get_q_value(state, action, use_target, grad, numpy) for model in self.models]
			return q_value

	def optimize(self, states, actions, states_joint, actions_joint, q_targets, e_weight=ENTROPY_WEIGHT):
		for (i,model),state,q_target in zip(enumerate(self.models), states, q_targets):
			q_values = model.get_q_value(states_joint, actions_joint, grad=True, numpy=False)
			critic_error = q_values[:q_target.size(0)] - q_target.detach()
			critic_loss = critic_error.pow(2)
			model.step(model.critic_optimizer, critic_loss.mean(), param_norm=model.critic_local.parameters())
			model.soft_copy(model.critic_local, model.critic_target)

			actor_action = model.get_action(state, grad=True, numpy=False)
			critic_action = [actor_action if j==i else other.get_action(states[j], numpy=False) for j,other in enumerate(self.models)]
			action_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(critic_action, self.action_size)], dim=-1)
			q_actions = model.critic_local(states_joint, action_joint)
			actor_loss = -q_actions.mean() + e_weight*actor_action.pow(2).mean()
			model.step(model.actor_optimizer, actor_loss.mean(), param_norm=model.actor_local.parameters())
			model.soft_copy(model.actor_local, model.actor_target)

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class MADDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, MADDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		# agent_init_params = []
		# for acsp, obsp in zip(action_size, state_size):
		# 	num_in_pol = obsp[-1]
		# 	num_out_pol = acsp[-1]
		# 	num_in_critic = sum([*[x[-1] for x in state_size], *[x.n for x in action_size]])
		# 	agent_init_params.append({'num_in_pol': num_in_pol, 'num_out_pol': num_out_pol, 'num_in_critic': num_in_critic})
		self.agent = MADDPG(state_size, action_size)
		self.replay_buffer = MultiagentReplayBuffer(MAX_BUFFER_SIZE, self.agent.nagents, [obsp[-1] for obsp in state_size], [acsp[-1] for acsp in action_size])

	def get_action(self, state, eps=None, sample=True, numpy=True):
		state = [torch.autograd.Variable(torch.Tensor(np.vstack(state[i])), requires_grad=False) for i in range(self.agent.nagents)]
		torch_agent_actions = self.agent.step(state)
		agent_actions = [ac.data.numpy() for ac in torch_agent_actions]
		return agent_actions
		# eps = self.eps if eps is None else eps
		# action_random = super().get_action(state)
		# action_greedy = self.network.get_action_probs(self.to_tensor(state), sample=sample, numpy=numpy)
		# action = [(1-eps)*a_greedy + eps*a_random for a_greedy,a_random in zip(action_greedy, action_random)]
		# return action

	def train(self, state, action, next_state, reward, done):
		if not hasattr(self, "t"): self.t = 0
		self.replay_buffer.push(state, action, next_state, reward, done)
		if (len(self.replay_buffer) >= 1024 and (self.t % 100)==0):
			# self.agent.prep_training(device='cpu')
			for a_i in range(self.agent.nagents):
				sample = self.replay_buffer.sample(1024, to_gpu=False)
				self.agent.update(sample, a_i)
			self.agent.update_all_targets()
			# self.agent.prep_rollouts(device='cpu')
		self.t += 1
		# self.buffer.append((state, action, reward, done))
		# if np.any(done[0]) or len(self.buffer) >= self.update_freq:
		# 	states, actions, rewards, dones = map(lambda x: self.to_tensor(x), zip(*self.buffer))
		# 	self.buffer.clear()
		# 	next_state = self.to_tensor(next_state)
		# 	states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, next_state)]
		# 	actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.network.get_action_probs(next_state, use_target=True))]
		# 	states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
		# 	actions_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions, self.action_size)], dim=-1)
		# 	q_values = self.network.get_q_value(states_joint, actions_joint, use_target=True)
		# 	q_targets = [self.compute_gae(q_value[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_value[:-1])[0] for q_value,reward,done in zip(q_values, rewards, dones)]
			
		# 	to_stack = lambda items: list(zip(*[x.view(-1, *x.shape[2:]).cpu().numpy() for x in items]))
		# 	states, actions, states_joint, actions_joint = map(lambda items: [x[:-1] for x in items], [states, actions, [states_joint], [actions_joint]])
		# 	states, actions, states_joint, actions_joint, q_targets = map(to_stack, [states, actions, states_joint, actions_joint, q_targets])
		# 	self.replay_buffer.extend(list(zip(states, actions, states_joint, actions_joint, q_targets)), shuffle=False)	
		# if len(self.replay_buffer) > REPLAY_BATCH_SIZE:
		# 	states, actions, states_joint, actions_joint, q_targets = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
		# 	self.network.optimize(states, actions, states_joint[0], actions_joint[0], q_targets)
		# if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)

MSELoss = torch.nn.MSELoss()


class MADDPG():
	def __init__(self, state_size, action_size, gamma=0.95, tau=0.01, lr=0.01, hidden_dim=64):
		num_in_critic = np.sum([np.prod(s) for s in state_size]) + np.sum([np.prod(a) for a in action_size])
		self.agents = [DDPGAgent(s_size[-1], a_size[-1], num_in_critic) for s_size, a_size in zip(state_size, action_size)]
		self.nagents = len(state_size)
		self.gamma = gamma
		self.tau = tau
		# self.niter = 0

	@property
	def policies(self):
		return [a.policy for a in self.agents]

	@property
	def target_policies(self):
		return [a.target_policy for a in self.agents]

	def step(self, observations, explore=False):
		return [a.policy(obs) for a, obs in zip(self.agents, observations)]

	def update(self, sample, agent_i, parallel=False, logger=None):
		obs, acs, rews, next_obs, dones = sample
		curr_agent = self.agents[agent_i]

		all_trgt_acs = [one_hot(pi(nobs)) for pi, nobs in zip(self.target_policies, next_obs)]
		trgt_vf_in = torch.cat((*next_obs, *all_trgt_acs), dim=1)
		target_value = (rews[agent_i].view(-1, 1) + self.gamma * curr_agent.target_critic(trgt_vf_in) * (1 - dones[agent_i].view(-1, 1)))

		critic_inputs = torch.cat((*obs, *acs), dim=1)
		actual_value = curr_agent.critic(critic_inputs)
		vf_loss = (actual_value - target_value.detach()).pow(2).mean()

		curr_agent.critic_optimizer.zero_grad()
		vf_loss.backward()
		torch.nn.utils.clip_grad_norm_(curr_agent.critic.parameters(), 0.5)
		curr_agent.critic_optimizer.step()

		curr_pol_out = curr_agent.policy(obs[agent_i])
		curr_pol_vf_in = gumbel_softmax(curr_pol_out, hard=True)
		all_pol_acs = [curr_pol_vf_in if i==agent_i else one_hot(pi(ob)) for i, pi, ob in zip(range(self.nagents), self.policies, obs)]
		critic_inputs = torch.cat((*obs, *all_pol_acs), dim=1)
		pol_loss = -curr_agent.critic(critic_inputs).mean()
		pol_loss += (curr_pol_out**2).mean() * 1e-3

		curr_agent.policy_optimizer.zero_grad()
		pol_loss.backward()
		torch.nn.utils.clip_grad_norm_(curr_agent.policy.parameters(), 0.5)
		curr_agent.policy_optimizer.step()

	def update_all_targets(self):
		for a in self.agents:
			a.soft_copy(a.critic, a.target_critic)
			a.soft_copy(a.policy, a.target_policy)
			# for target_param, param in zip(a.target_critic.parameters(), a.critic.parameters()):
			# 	target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)
			# for target_param, param in zip(a.target_policy.parameters(), a.policy.parameters()):
			# 	target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)
		# self.niter += 1

	# def prep_training(self, device='gpu'):
	# 	for a in self.agents:
	# 		a.policy.train()
	# 		a.critic.train()
	# 		a.target_policy.train()
	# 		a.target_critic.train()

	# def prep_rollouts(self, device='cpu'):
	# 	for a in self.agents:
	# 		a.policy.eval()

class DDPGAgent(object):
	def __init__(self, num_in_pol, num_out_pol, num_in_critic, hidden_dim=64, lr=0.01, tau=0.01):
		self.policy = MLPNetwork(num_in_pol, num_out_pol, hidden_dim=hidden_dim)
		self.target_policy = MLPNetwork(num_in_pol, num_out_pol, hidden_dim=hidden_dim)
		self.policy_optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr)
		
		self.critic = MLPNetwork(num_in_critic, 1, hidden_dim=hidden_dim)
		self.target_critic = MLPNetwork(num_in_critic, 1, hidden_dim=hidden_dim)
		self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr)
		
		self.tau = tau
		# for target_param, param in zip(self.target_policy.parameters(), self.policy.parameters()):
		# 	target_param.data.copy_(param.data)
		# for target_param, param in zip(self.target_critic.parameters(), self.critic.parameters()):
		# 	target_param.data.copy_(param.data)

	def soft_copy(self, local, target):
		for t,l in zip(target.parameters(), local.parameters()):
			t.data.copy_(t.data + self.tau*(l.data - t.data))

	# def step(self, obs, explore=False):
	# 	action = self.policy(obs)
	# 	if explore:
	# 		action = gumbel_softmax(action, hard=True)
	# 	else:
	# 		action = one_hot(action)
	# 	return action

class MLPNetwork(torch.nn.Module):
	def __init__(self, input_dim, out_dim, hidden_dim=64):
		super().__init__()

		# if norm_in:  # normalize inputs
		# 	self.in_fn = nn.BatchNorm1d(input_dim)
		# 	self.in_fn.weight.data.fill_(1)
		# 	self.in_fn.bias.data.fill_(0)
		# else:
		# 	self.in_fn = lambda x: x
		self.fc1 = torch.nn.Linear(input_dim, hidden_dim)
		self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)
		self.fc3 = torch.nn.Linear(hidden_dim, out_dim)
		# self.nonlin = nonlin
		# if constrain_out and not discrete_action:
		# 	self.fc3.weight.data.uniform_(-3e-3, 3e-3)
		# 	self.out_fn = torch.tanh
		# 	raise EnvironmentError()
		# else:  # logits for discrete action (will softmax later)
		# 	self.out_fn = lambda x: x

	def forward(self, X):
		h1 = self.fc1(X).relu()
		h2 = self.fc2(h1).relu()
		action = self.fc3(h2)
		return gumbel_softmax(action, hard=True)
REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.900             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)
# np.random.seed(1)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return gym.make(env_name)
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":0} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env)

def run(model, steps=10000, ports=16, env_name=env_name, eval_at=1000, checkpoint=False, save_best=False, log=True, render=True):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports, render=False, env_name=env_name)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, num_envs=num_envs, gpu=False, agent2=RandomAgent) 
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if np.any(dones[0]):
			rollouts = [rollout(envs.env, agent.reset(1), render=render) for _ in range(1)]
			test_reward = np.mean(rollouts, axis=0) - np.std(rollouts, axis=0)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if save_best and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts, axis=0)} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")
			agent.reset(num_envs)

def trial(model):
	envs = EnsembleEnv(make_env, 0, log=True, render=True)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, load=f"{env_name}")
	print(f"Reward: {rollout(envs.env, agent, eps=0.02, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[1], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="maddpg", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--test", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.test:
		trial(model)
	elif args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		run(model, args.steps, args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)

Step: 49, Reward: [-435.81 -435.81 -435.81] [0.0000], Avg: [-435.81 -435.81 -435.81] (1.000)
Step: 99, Reward: [-401.343 -401.343 -401.343] [0.0000], Avg: [-418.577 -418.577 -418.577] (1.000)
Step: 149, Reward: [-570.286 -570.286 -570.286] [0.0000], Avg: [-469.146 -469.146 -469.146] (1.000)
Step: 199, Reward: [-454.261 -454.261 -454.261] [0.0000], Avg: [-465.425 -465.425 -465.425] (1.000)
Step: 249, Reward: [-379.292 -379.292 -379.292] [0.0000], Avg: [-448.199 -448.199 -448.199] (1.000)
Step: 299, Reward: [-484.838 -484.838 -484.838] [0.0000], Avg: [-454.305 -454.305 -454.305] (1.000)
Step: 349, Reward: [-599.623 -599.623 -599.623] [0.0000], Avg: [-475.065 -475.065 -475.065] (1.000)
Step: 399, Reward: [-474.755 -474.755 -474.755] [0.0000], Avg: [-475.026 -475.026 -475.026] (1.000)
Step: 449, Reward: [-484.806 -484.806 -484.806] [0.0000], Avg: [-476.113 -476.113 -476.113] (1.000)
Step: 499, Reward: [-540.262 -540.262 -540.262] [0.0000], Avg: [-482.528 -482.528 -482.528] (1.000)
Step: 549, Reward: [-496.062 -496.062 -496.062] [0.0000], Avg: [-483.758 -483.758 -483.758] (1.000)
Step: 599, Reward: [-412.39 -412.39 -412.39] [0.0000], Avg: [-477.811 -477.811 -477.811] (1.000)
Step: 649, Reward: [-635.881 -635.881 -635.881] [0.0000], Avg: [-489.97 -489.97 -489.97] (1.000)
Step: 699, Reward: [-452.024 -452.024 -452.024] [0.0000], Avg: [-487.26 -487.26 -487.26] (1.000)
Step: 749, Reward: [-465.942 -465.942 -465.942] [0.0000], Avg: [-485.839 -485.839 -485.839] (1.000)
Step: 799, Reward: [-439.288 -439.288 -439.288] [0.0000], Avg: [-482.929 -482.929 -482.929] (1.000)
Step: 849, Reward: [-487.837 -487.837 -487.837] [0.0000], Avg: [-483.218 -483.218 -483.218] (1.000)
Step: 899, Reward: [-419.345 -419.345 -419.345] [0.0000], Avg: [-479.669 -479.669 -479.669] (1.000)
Step: 949, Reward: [-450.119 -450.119 -450.119] [0.0000], Avg: [-478.114 -478.114 -478.114] (1.000)
Step: 999, Reward: [-736.453 -736.453 -736.453] [0.0000], Avg: [-491.031 -491.031 -491.031] (1.000)
Step: 1049, Reward: [-479.601 -479.601 -479.601] [0.0000], Avg: [-490.487 -490.487 -490.487] (1.000)
Step: 1099, Reward: [-547.796 -547.796 -547.796] [0.0000], Avg: [-493.092 -493.092 -493.092] (1.000)
Step: 1149, Reward: [-624.428 -624.428 -624.428] [0.0000], Avg: [-498.802 -498.802 -498.802] (1.000)
Step: 1199, Reward: [-417.813 -417.813 -417.813] [0.0000], Avg: [-495.427 -495.427 -495.427] (1.000)
Step: 1249, Reward: [-518.536 -518.536 -518.536] [0.0000], Avg: [-496.352 -496.352 -496.352] (1.000)
Step: 1299, Reward: [-469.847 -469.847 -469.847] [0.0000], Avg: [-495.332 -495.332 -495.332] (1.000)
Step: 1349, Reward: [-489.293 -489.293 -489.293] [0.0000], Avg: [-495.109 -495.109 -495.109] (1.000)
Step: 1399, Reward: [-523.13 -523.13 -523.13] [0.0000], Avg: [-496.109 -496.109 -496.109] (1.000)
Step: 1449, Reward: [-472.377 -472.377 -472.377] [0.0000], Avg: [-495.291 -495.291 -495.291] (1.000)
Step: 1499, Reward: [-422.504 -422.504 -422.504] [0.0000], Avg: [-492.865 -492.865 -492.865] (1.000)
Step: 1549, Reward: [-434.629 -434.629 -434.629] [0.0000], Avg: [-490.986 -490.986 -490.986] (1.000)
Step: 1599, Reward: [-476.672 -476.672 -476.672] [0.0000], Avg: [-490.539 -490.539 -490.539] (1.000)
Step: 1649, Reward: [-564.458 -564.458 -564.458] [0.0000], Avg: [-492.779 -492.779 -492.779] (1.000)
Step: 1699, Reward: [-481.622 -481.622 -481.622] [0.0000], Avg: [-492.451 -492.451 -492.451] (1.000)
Step: 1749, Reward: [-366.282 -366.282 -366.282] [0.0000], Avg: [-488.846 -488.846 -488.846] (1.000)
Step: 1799, Reward: [-483.44 -483.44 -483.44] [0.0000], Avg: [-488.696 -488.696 -488.696] (1.000)
Step: 1849, Reward: [-530.981 -530.981 -530.981] [0.0000], Avg: [-489.839 -489.839 -489.839] (1.000)
Step: 1899, Reward: [-498.925 -498.925 -498.925] [0.0000], Avg: [-490.078 -490.078 -490.078] (1.000)
Step: 1949, Reward: [-570.775 -570.775 -570.775] [0.0000], Avg: [-492.147 -492.147 -492.147] (1.000)
Step: 1999, Reward: [-453.222 -453.222 -453.222] [0.0000], Avg: [-491.174 -491.174 -491.174] (1.000)
Step: 2049, Reward: [-449.625 -449.625 -449.625] [0.0000], Avg: [-490.16 -490.16 -490.16] (1.000)
Step: 2099, Reward: [-569.824 -569.824 -569.824] [0.0000], Avg: [-492.057 -492.057 -492.057] (1.000)
Step: 2149, Reward: [-814.095 -814.095 -814.095] [0.0000], Avg: [-499.546 -499.546 -499.546] (1.000)
Step: 2199, Reward: [-371.116 -371.116 -371.116] [0.0000], Avg: [-496.627 -496.627 -496.627] (1.000)
Step: 2249, Reward: [-647.816 -647.816 -647.816] [0.0000], Avg: [-499.987 -499.987 -499.987] (1.000)
Step: 2299, Reward: [-347.849 -347.849 -347.849] [0.0000], Avg: [-496.68 -496.68 -496.68] (1.000)
Step: 2349, Reward: [-557.077 -557.077 -557.077] [0.0000], Avg: [-497.965 -497.965 -497.965] (1.000)
Step: 2399, Reward: [-727.7 -727.7 -727.7] [0.0000], Avg: [-502.751 -502.751 -502.751] (1.000)
Step: 2449, Reward: [-549.276 -549.276 -549.276] [0.0000], Avg: [-503.701 -503.701 -503.701] (1.000)
Step: 2499, Reward: [-499.869 -499.869 -499.869] [0.0000], Avg: [-503.624 -503.624 -503.624] (1.000)
Step: 2549, Reward: [-412.707 -412.707 -412.707] [0.0000], Avg: [-501.841 -501.841 -501.841] (1.000)
Step: 2599, Reward: [-624.271 -624.271 -624.271] [0.0000], Avg: [-504.196 -504.196 -504.196] (1.000)
Step: 2649, Reward: [-365.275 -365.275 -365.275] [0.0000], Avg: [-501.574 -501.574 -501.574] (1.000)
Step: 2699, Reward: [-437.413 -437.413 -437.413] [0.0000], Avg: [-500.386 -500.386 -500.386] (1.000)
Step: 2749, Reward: [-536.222 -536.222 -536.222] [0.0000], Avg: [-501.038 -501.038 -501.038] (1.000)
Step: 2799, Reward: [-454.969 -454.969 -454.969] [0.0000], Avg: [-500.215 -500.215 -500.215] (1.000)
Step: 2849, Reward: [-467.014 -467.014 -467.014] [0.0000], Avg: [-499.633 -499.633 -499.633] (1.000)
Step: 2899, Reward: [-541.585 -541.585 -541.585] [0.0000], Avg: [-500.356 -500.356 -500.356] (1.000)
Step: 2949, Reward: [-523.8 -523.8 -523.8] [0.0000], Avg: [-500.753 -500.753 -500.753] (1.000)
Step: 2999, Reward: [-454.635 -454.635 -454.635] [0.0000], Avg: [-499.985 -499.985 -499.985] (1.000)
Step: 3049, Reward: [-491.835 -491.835 -491.835] [0.0000], Avg: [-499.851 -499.851 -499.851] (1.000)
Step: 3099, Reward: [-453.075 -453.075 -453.075] [0.0000], Avg: [-499.097 -499.097 -499.097] (1.000)
Step: 3149, Reward: [-501.593 -501.593 -501.593] [0.0000], Avg: [-499.136 -499.136 -499.136] (1.000)
Step: 3199, Reward: [-540.111 -540.111 -540.111] [0.0000], Avg: [-499.777 -499.777 -499.777] (1.000)
Step: 3249, Reward: [-493.299 -493.299 -493.299] [0.0000], Avg: [-499.677 -499.677 -499.677] (1.000)
Step: 3299, Reward: [-424.227 -424.227 -424.227] [0.0000], Avg: [-498.534 -498.534 -498.534] (1.000)
Step: 3349, Reward: [-417.909 -417.909 -417.909] [0.0000], Avg: [-497.33 -497.33 -497.33] (1.000)
Step: 3399, Reward: [-707.08 -707.08 -707.08] [0.0000], Avg: [-500.415 -500.415 -500.415] (1.000)
Step: 3449, Reward: [-581.591 -581.591 -581.591] [0.0000], Avg: [-501.591 -501.591 -501.591] (1.000)
Step: 3499, Reward: [-419.351 -419.351 -419.351] [0.0000], Avg: [-500.417 -500.417 -500.417] (1.000)
Step: 3549, Reward: [-682.106 -682.106 -682.106] [0.0000], Avg: [-502.976 -502.976 -502.976] (1.000)
Step: 3599, Reward: [-364.979 -364.979 -364.979] [0.0000], Avg: [-501.059 -501.059 -501.059] (1.000)
Step: 3649, Reward: [-894.967 -894.967 -894.967] [0.0000], Avg: [-506.455 -506.455 -506.455] (1.000)
Step: 3699, Reward: [-346.169 -346.169 -346.169] [0.0000], Avg: [-504.289 -504.289 -504.289] (1.000)
Step: 3749, Reward: [-449.533 -449.533 -449.533] [0.0000], Avg: [-503.559 -503.559 -503.559] (1.000)
Step: 3799, Reward: [-595.316 -595.316 -595.316] [0.0000], Avg: [-504.766 -504.766 -504.766] (1.000)
Step: 3849, Reward: [-659.352 -659.352 -659.352] [0.0000], Avg: [-506.774 -506.774 -506.774] (1.000)
Step: 3899, Reward: [-459.454 -459.454 -459.454] [0.0000], Avg: [-506.167 -506.167 -506.167] (1.000)
Step: 3949, Reward: [-424.375 -424.375 -424.375] [0.0000], Avg: [-505.132 -505.132 -505.132] (1.000)
Step: 3999, Reward: [-543.929 -543.929 -543.929] [0.0000], Avg: [-505.617 -505.617 -505.617] (1.000)
Step: 4049, Reward: [-572.573 -572.573 -572.573] [0.0000], Avg: [-506.443 -506.443 -506.443] (1.000)
Step: 4099, Reward: [-413.466 -413.466 -413.466] [0.0000], Avg: [-505.31 -505.31 -505.31] (1.000)
Step: 4149, Reward: [-382.863 -382.863 -382.863] [0.0000], Avg: [-503.834 -503.834 -503.834] (1.000)
Step: 4199, Reward: [-420.092 -420.092 -420.092] [0.0000], Avg: [-502.837 -502.837 -502.837] (1.000)
Step: 4249, Reward: [-766.592 -766.592 -766.592] [0.0000], Avg: [-505.94 -505.94 -505.94] (1.000)
Step: 4299, Reward: [-464.068 -464.068 -464.068] [0.0000], Avg: [-505.453 -505.453 -505.453] (1.000)
Step: 4349, Reward: [-568.394 -568.394 -568.394] [0.0000], Avg: [-506.177 -506.177 -506.177] (1.000)
Step: 4399, Reward: [-561.074 -561.074 -561.074] [0.0000], Avg: [-506.801 -506.801 -506.801] (1.000)
Step: 4449, Reward: [-443.783 -443.783 -443.783] [0.0000], Avg: [-506.093 -506.093 -506.093] (1.000)
Step: 4499, Reward: [-502.698 -502.698 -502.698] [0.0000], Avg: [-506.055 -506.055 -506.055] (1.000)
Step: 4549, Reward: [-455.14 -455.14 -455.14] [0.0000], Avg: [-505.495 -505.495 -505.495] (1.000)
Step: 4599, Reward: [-481.018 -481.018 -481.018] [0.0000], Avg: [-505.229 -505.229 -505.229] (1.000)
Step: 4649, Reward: [-475.321 -475.321 -475.321] [0.0000], Avg: [-504.908 -504.908 -504.908] (1.000)
Step: 4699, Reward: [-576.784 -576.784 -576.784] [0.0000], Avg: [-505.672 -505.672 -505.672] (1.000)
Step: 4749, Reward: [-560.68 -560.68 -560.68] [0.0000], Avg: [-506.251 -506.251 -506.251] (1.000)
Step: 4799, Reward: [-583.069 -583.069 -583.069] [0.0000], Avg: [-507.052 -507.052 -507.052] (1.000)
Step: 4849, Reward: [-436.911 -436.911 -436.911] [0.0000], Avg: [-506.329 -506.329 -506.329] (1.000)
Step: 4899, Reward: [-455.963 -455.963 -455.963] [0.0000], Avg: [-505.815 -505.815 -505.815] (1.000)
Step: 4949, Reward: [-424.815 -424.815 -424.815] [0.0000], Avg: [-504.996 -504.996 -504.996] (1.000)
Step: 4999, Reward: [-419.862 -419.862 -419.862] [0.0000], Avg: [-504.145 -504.145 -504.145] (1.000)
Step: 5049, Reward: [-473.169 -473.169 -473.169] [0.0000], Avg: [-503.838 -503.838 -503.838] (1.000)
Step: 5099, Reward: [-414.446 -414.446 -414.446] [0.0000], Avg: [-502.962 -502.962 -502.962] (1.000)
Step: 5149, Reward: [-514.084 -514.084 -514.084] [0.0000], Avg: [-503.07 -503.07 -503.07] (1.000)
Step: 5199, Reward: [-565.276 -565.276 -565.276] [0.0000], Avg: [-503.668 -503.668 -503.668] (1.000)
Step: 5249, Reward: [-549.447 -549.447 -549.447] [0.0000], Avg: [-504.104 -504.104 -504.104] (1.000)
Step: 5299, Reward: [-351.346 -351.346 -351.346] [0.0000], Avg: [-502.663 -502.663 -502.663] (1.000)
Step: 5349, Reward: [-390.828 -390.828 -390.828] [0.0000], Avg: [-501.618 -501.618 -501.618] (1.000)
Step: 5399, Reward: [-487.698 -487.698 -487.698] [0.0000], Avg: [-501.489 -501.489 -501.489] (1.000)
Step: 5449, Reward: [-451.161 -451.161 -451.161] [0.0000], Avg: [-501.027 -501.027 -501.027] (1.000)
Step: 5499, Reward: [-452.04 -452.04 -452.04] [0.0000], Avg: [-500.582 -500.582 -500.582] (1.000)
Step: 5549, Reward: [-429.476 -429.476 -429.476] [0.0000], Avg: [-499.941 -499.941 -499.941] (1.000)
Step: 5599, Reward: [-441.503 -441.503 -441.503] [0.0000], Avg: [-499.419 -499.419 -499.419] (1.000)
Step: 5649, Reward: [-479.022 -479.022 -479.022] [0.0000], Avg: [-499.239 -499.239 -499.239] (1.000)
Step: 5699, Reward: [-386.725 -386.725 -386.725] [0.0000], Avg: [-498.252 -498.252 -498.252] (1.000)
Step: 5749, Reward: [-503.999 -503.999 -503.999] [0.0000], Avg: [-498.302 -498.302 -498.302] (1.000)
Step: 5799, Reward: [-426.21 -426.21 -426.21] [0.0000], Avg: [-497.68 -497.68 -497.68] (1.000)
Step: 5849, Reward: [-639.169 -639.169 -639.169] [0.0000], Avg: [-498.89 -498.89 -498.89] (1.000)
Step: 5899, Reward: [-442.096 -442.096 -442.096] [0.0000], Avg: [-498.408 -498.408 -498.408] (1.000)
Step: 5949, Reward: [-399.591 -399.591 -399.591] [0.0000], Avg: [-497.578 -497.578 -497.578] (1.000)
Step: 5999, Reward: [-382.992 -382.992 -382.992] [0.0000], Avg: [-496.623 -496.623 -496.623] (1.000)
Step: 6049, Reward: [-542.042 -542.042 -542.042] [0.0000], Avg: [-496.999 -496.999 -496.999] (1.000)
Step: 6099, Reward: [-529.746 -529.746 -529.746] [0.0000], Avg: [-497.267 -497.267 -497.267] (1.000)
Step: 6149, Reward: [-534.628 -534.628 -534.628] [0.0000], Avg: [-497.571 -497.571 -497.571] (1.000)
Step: 6199, Reward: [-528.385 -528.385 -528.385] [0.0000], Avg: [-497.819 -497.819 -497.819] (1.000)
Step: 6249, Reward: [-458.003 -458.003 -458.003] [0.0000], Avg: [-497.501 -497.501 -497.501] (1.000)
Step: 6299, Reward: [-550.782 -550.782 -550.782] [0.0000], Avg: [-497.924 -497.924 -497.924] (1.000)
Step: 6349, Reward: [-730.211 -730.211 -730.211] [0.0000], Avg: [-499.753 -499.753 -499.753] (1.000)
Step: 6399, Reward: [-676.505 -676.505 -676.505] [0.0000], Avg: [-501.133 -501.133 -501.133] (1.000)
Step: 6449, Reward: [-560.546 -560.546 -560.546] [0.0000], Avg: [-501.594 -501.594 -501.594] (1.000)
Step: 6499, Reward: [-484.775 -484.775 -484.775] [0.0000], Avg: [-501.465 -501.465 -501.465] (1.000)
Step: 6549, Reward: [-488.527 -488.527 -488.527] [0.0000], Avg: [-501.366 -501.366 -501.366] (1.000)
Step: 6599, Reward: [-511.318 -511.318 -511.318] [0.0000], Avg: [-501.441 -501.441 -501.441] (1.000)
Step: 6649, Reward: [-635.652 -635.652 -635.652] [0.0000], Avg: [-502.45 -502.45 -502.45] (1.000)
Step: 6699, Reward: [-424.658 -424.658 -424.658] [0.0000], Avg: [-501.87 -501.87 -501.87] (1.000)
Step: 6749, Reward: [-443.568 -443.568 -443.568] [0.0000], Avg: [-501.438 -501.438 -501.438] (1.000)
Step: 6799, Reward: [-554.683 -554.683 -554.683] [0.0000], Avg: [-501.83 -501.83 -501.83] (1.000)
Step: 6849, Reward: [-559.876 -559.876 -559.876] [0.0000], Avg: [-502.253 -502.253 -502.253] (1.000)
Step: 6899, Reward: [-397.096 -397.096 -397.096] [0.0000], Avg: [-501.491 -501.491 -501.491] (1.000)
Step: 6949, Reward: [-467.817 -467.817 -467.817] [0.0000], Avg: [-501.249 -501.249 -501.249] (1.000)
Step: 6999, Reward: [-421.185 -421.185 -421.185] [0.0000], Avg: [-500.677 -500.677 -500.677] (1.000)
Step: 7049, Reward: [-457.909 -457.909 -457.909] [0.0000], Avg: [-500.374 -500.374 -500.374] (1.000)
Step: 7099, Reward: [-604.594 -604.594 -604.594] [0.0000], Avg: [-501.108 -501.108 -501.108] (1.000)
Step: 7149, Reward: [-504.382 -504.382 -504.382] [0.0000], Avg: [-501.131 -501.131 -501.131] (1.000)
Step: 7199, Reward: [-545.94 -545.94 -545.94] [0.0000], Avg: [-501.442 -501.442 -501.442] (1.000)
Step: 7249, Reward: [-437.262 -437.262 -437.262] [0.0000], Avg: [-500.999 -500.999 -500.999] (1.000)
Step: 7299, Reward: [-495.049 -495.049 -495.049] [0.0000], Avg: [-500.958 -500.958 -500.958] (1.000)
Step: 7349, Reward: [-697.585 -697.585 -697.585] [0.0000], Avg: [-502.296 -502.296 -502.296] (1.000)
Step: 7399, Reward: [-437.71 -437.71 -437.71] [0.0000], Avg: [-501.86 -501.86 -501.86] (1.000)
Step: 7449, Reward: [-514.499 -514.499 -514.499] [0.0000], Avg: [-501.944 -501.944 -501.944] (1.000)
Step: 7499, Reward: [-464.29 -464.29 -464.29] [0.0000], Avg: [-501.693 -501.693 -501.693] (1.000)
Step: 7549, Reward: [-615.412 -615.412 -615.412] [0.0000], Avg: [-502.446 -502.446 -502.446] (1.000)
Step: 7599, Reward: [-418.178 -418.178 -418.178] [0.0000], Avg: [-501.892 -501.892 -501.892] (1.000)
Step: 7649, Reward: [-507.531 -507.531 -507.531] [0.0000], Avg: [-501.929 -501.929 -501.929] (1.000)
Step: 7699, Reward: [-741.065 -741.065 -741.065] [0.0000], Avg: [-503.482 -503.482 -503.482] (1.000)
Step: 7749, Reward: [-389.449 -389.449 -389.449] [0.0000], Avg: [-502.746 -502.746 -502.746] (1.000)
Step: 7799, Reward: [-633.39 -633.39 -633.39] [0.0000], Avg: [-503.584 -503.584 -503.584] (1.000)
Step: 7849, Reward: [-467.889 -467.889 -467.889] [0.0000], Avg: [-503.356 -503.356 -503.356] (1.000)
Step: 7899, Reward: [-585.37 -585.37 -585.37] [0.0000], Avg: [-503.875 -503.875 -503.875] (1.000)
Step: 7949, Reward: [-457.432 -457.432 -457.432] [0.0000], Avg: [-503.583 -503.583 -503.583] (1.000)
Step: 7999, Reward: [-525.747 -525.747 -525.747] [0.0000], Avg: [-503.722 -503.722 -503.722] (1.000)
Step: 8049, Reward: [-322.274 -322.274 -322.274] [0.0000], Avg: [-502.595 -502.595 -502.595] (1.000)
Step: 8099, Reward: [-478.939 -478.939 -478.939] [0.0000], Avg: [-502.449 -502.449 -502.449] (1.000)
Step: 8149, Reward: [-418.062 -418.062 -418.062] [0.0000], Avg: [-501.931 -501.931 -501.931] (1.000)
Step: 8199, Reward: [-584.342 -584.342 -584.342] [0.0000], Avg: [-502.433 -502.433 -502.433] (1.000)
Step: 8249, Reward: [-535.018 -535.018 -535.018] [0.0000], Avg: [-502.631 -502.631 -502.631] (1.000)
Step: 8299, Reward: [-474.2 -474.2 -474.2] [0.0000], Avg: [-502.46 -502.46 -502.46] (1.000)
Step: 8349, Reward: [-502.847 -502.847 -502.847] [0.0000], Avg: [-502.462 -502.462 -502.462] (1.000)
Step: 8399, Reward: [-583.219 -583.219 -583.219] [0.0000], Avg: [-502.943 -502.943 -502.943] (1.000)
Step: 8449, Reward: [-497.685 -497.685 -497.685] [0.0000], Avg: [-502.912 -502.912 -502.912] (1.000)
Step: 8499, Reward: [-511.198 -511.198 -511.198] [0.0000], Avg: [-502.96 -502.96 -502.96] (1.000)
Step: 8549, Reward: [-640.914 -640.914 -640.914] [0.0000], Avg: [-503.767 -503.767 -503.767] (1.000)
Step: 8599, Reward: [-778.445 -778.445 -778.445] [0.0000], Avg: [-505.364 -505.364 -505.364] (1.000)
Step: 8649, Reward: [-330.964 -330.964 -330.964] [0.0000], Avg: [-504.356 -504.356 -504.356] (1.000)
Step: 8699, Reward: [-579.604 -579.604 -579.604] [0.0000], Avg: [-504.788 -504.788 -504.788] (1.000)
Step: 8749, Reward: [-356.613 -356.613 -356.613] [0.0000], Avg: [-503.942 -503.942 -503.942] (1.000)
Step: 8799, Reward: [-436.817 -436.817 -436.817] [0.0000], Avg: [-503.56 -503.56 -503.56] (1.000)
Step: 8849, Reward: [-591.404 -591.404 -591.404] [0.0000], Avg: [-504.057 -504.057 -504.057] (1.000)
Step: 8899, Reward: [-519.237 -519.237 -519.237] [0.0000], Avg: [-504.142 -504.142 -504.142] (1.000)
Step: 8949, Reward: [-512.489 -512.489 -512.489] [0.0000], Avg: [-504.188 -504.188 -504.188] (1.000)
Step: 8999, Reward: [-344.662 -344.662 -344.662] [0.0000], Avg: [-503.302 -503.302 -503.302] (1.000)
Step: 9049, Reward: [-408.165 -408.165 -408.165] [0.0000], Avg: [-502.777 -502.777 -502.777] (1.000)
Step: 9099, Reward: [-438.052 -438.052 -438.052] [0.0000], Avg: [-502.421 -502.421 -502.421] (1.000)
Step: 9149, Reward: [-671.177 -671.177 -671.177] [0.0000], Avg: [-503.343 -503.343 -503.343] (1.000)
Step: 9199, Reward: [-497.398 -497.398 -497.398] [0.0000], Avg: [-503.311 -503.311 -503.311] (1.000)
Step: 9249, Reward: [-451.132 -451.132 -451.132] [0.0000], Avg: [-503.029 -503.029 -503.029] (1.000)
Step: 9299, Reward: [-490.797 -490.797 -490.797] [0.0000], Avg: [-502.963 -502.963 -502.963] (1.000)
Step: 9349, Reward: [-496.598 -496.598 -496.598] [0.0000], Avg: [-502.929 -502.929 -502.929] (1.000)
Step: 9399, Reward: [-736.927 -736.927 -736.927] [0.0000], Avg: [-504.174 -504.174 -504.174] (1.000)
Step: 9449, Reward: [-389.214 -389.214 -389.214] [0.0000], Avg: [-503.565 -503.565 -503.565] (1.000)
Step: 9499, Reward: [-482.902 -482.902 -482.902] [0.0000], Avg: [-503.457 -503.457 -503.457] (1.000)
Step: 9549, Reward: [-522.192 -522.192 -522.192] [0.0000], Avg: [-503.555 -503.555 -503.555] (1.000)
Step: 9599, Reward: [-332.934 -332.934 -332.934] [0.0000], Avg: [-502.666 -502.666 -502.666] (1.000)
Step: 9649, Reward: [-558.919 -558.919 -558.919] [0.0000], Avg: [-502.958 -502.958 -502.958] (1.000)
Step: 9699, Reward: [-377.71 -377.71 -377.71] [0.0000], Avg: [-502.312 -502.312 -502.312] (1.000)
Step: 9749, Reward: [-467.855 -467.855 -467.855] [0.0000], Avg: [-502.135 -502.135 -502.135] (1.000)
Step: 9799, Reward: [-564.244 -564.244 -564.244] [0.0000], Avg: [-502.452 -502.452 -502.452] (1.000)
Step: 9849, Reward: [-427.879 -427.879 -427.879] [0.0000], Avg: [-502.074 -502.074 -502.074] (1.000)
Step: 9899, Reward: [-551.384 -551.384 -551.384] [0.0000], Avg: [-502.323 -502.323 -502.323] (1.000)
Step: 9949, Reward: [-447.02 -447.02 -447.02] [0.0000], Avg: [-502.045 -502.045 -502.045] (1.000)
Step: 9999, Reward: [-597.581 -597.581 -597.581] [0.0000], Avg: [-502.522 -502.522 -502.522] (1.000)
Step: 10049, Reward: [-560.983 -560.983 -560.983] [0.0000], Avg: [-502.813 -502.813 -502.813] (1.000)
Step: 10099, Reward: [-730.292 -730.292 -730.292] [0.0000], Avg: [-503.939 -503.939 -503.939] (1.000)
Step: 10149, Reward: [-567.039 -567.039 -567.039] [0.0000], Avg: [-504.25 -504.25 -504.25] (1.000)
Step: 10199, Reward: [-366.093 -366.093 -366.093] [0.0000], Avg: [-503.573 -503.573 -503.573] (1.000)
Step: 10249, Reward: [-410.774 -410.774 -410.774] [0.0000], Avg: [-503.12 -503.12 -503.12] (1.000)
Step: 10299, Reward: [-520.768 -520.768 -520.768] [0.0000], Avg: [-503.206 -503.206 -503.206] (1.000)
Step: 10349, Reward: [-361.757 -361.757 -361.757] [0.0000], Avg: [-502.523 -502.523 -502.523] (1.000)
Step: 10399, Reward: [-480.469 -480.469 -480.469] [0.0000], Avg: [-502.417 -502.417 -502.417] (1.000)
Step: 10449, Reward: [-642.807 -642.807 -642.807] [0.0000], Avg: [-503.088 -503.088 -503.088] (1.000)
Step: 10499, Reward: [-563.132 -563.132 -563.132] [0.0000], Avg: [-503.374 -503.374 -503.374] (1.000)
Step: 10549, Reward: [-549.603 -549.603 -549.603] [0.0000], Avg: [-503.593 -503.593 -503.593] (1.000)
Step: 10599, Reward: [-543.936 -543.936 -543.936] [0.0000], Avg: [-503.784 -503.784 -503.784] (1.000)
Step: 10649, Reward: [-521.433 -521.433 -521.433] [0.0000], Avg: [-503.867 -503.867 -503.867] (1.000)
Step: 10699, Reward: [-397.764 -397.764 -397.764] [0.0000], Avg: [-503.371 -503.371 -503.371] (1.000)
Step: 10749, Reward: [-475.382 -475.382 -475.382] [0.0000], Avg: [-503.241 -503.241 -503.241] (1.000)
Step: 10799, Reward: [-416.591 -416.591 -416.591] [0.0000], Avg: [-502.839 -502.839 -502.839] (1.000)
Step: 10849, Reward: [-394.899 -394.899 -394.899] [0.0000], Avg: [-502.342 -502.342 -502.342] (1.000)
Step: 10899, Reward: [-474.705 -474.705 -474.705] [0.0000], Avg: [-502.215 -502.215 -502.215] (1.000)
Step: 10949, Reward: [-342.073 -342.073 -342.073] [0.0000], Avg: [-501.484 -501.484 -501.484] (1.000)
Step: 10999, Reward: [-497.898 -497.898 -497.898] [0.0000], Avg: [-501.468 -501.468 -501.468] (1.000)
Step: 11049, Reward: [-548.814 -548.814 -548.814] [0.0000], Avg: [-501.682 -501.682 -501.682] (1.000)
Step: 11099, Reward: [-412.036 -412.036 -412.036] [0.0000], Avg: [-501.278 -501.278 -501.278] (1.000)
Step: 11149, Reward: [-331.774 -331.774 -331.774] [0.0000], Avg: [-500.518 -500.518 -500.518] (1.000)
Step: 11199, Reward: [-507.401 -507.401 -507.401] [0.0000], Avg: [-500.549 -500.549 -500.549] (1.000)
Step: 11249, Reward: [-610.335 -610.335 -610.335] [0.0000], Avg: [-501.037 -501.037 -501.037] (1.000)
Step: 11299, Reward: [-546.085 -546.085 -546.085] [0.0000], Avg: [-501.236 -501.236 -501.236] (1.000)
Step: 11349, Reward: [-451.241 -451.241 -451.241] [0.0000], Avg: [-501.016 -501.016 -501.016] (1.000)
Step: 11399, Reward: [-519.998 -519.998 -519.998] [0.0000], Avg: [-501.099 -501.099 -501.099] (1.000)
Step: 11449, Reward: [-401.082 -401.082 -401.082] [0.0000], Avg: [-500.662 -500.662 -500.662] (1.000)
Step: 11499, Reward: [-500.866 -500.866 -500.866] [0.0000], Avg: [-500.663 -500.663 -500.663] (1.000)
Step: 11549, Reward: [-477.693 -477.693 -477.693] [0.0000], Avg: [-500.564 -500.564 -500.564] (1.000)
Step: 11599, Reward: [-528.701 -528.701 -528.701] [0.0000], Avg: [-500.685 -500.685 -500.685] (1.000)
Step: 11649, Reward: [-470.896 -470.896 -470.896] [0.0000], Avg: [-500.557 -500.557 -500.557] (1.000)
Step: 11699, Reward: [-625.2 -625.2 -625.2] [0.0000], Avg: [-501.09 -501.09 -501.09] (1.000)
Step: 11749, Reward: [-548.887 -548.887 -548.887] [0.0000], Avg: [-501.293 -501.293 -501.293] (1.000)
Step: 11799, Reward: [-540.53 -540.53 -540.53] [0.0000], Avg: [-501.459 -501.459 -501.459] (1.000)
Step: 11849, Reward: [-542.388 -542.388 -542.388] [0.0000], Avg: [-501.632 -501.632 -501.632] (1.000)
Step: 11899, Reward: [-482.714 -482.714 -482.714] [0.0000], Avg: [-501.553 -501.553 -501.553] (1.000)
Step: 11949, Reward: [-512.478 -512.478 -512.478] [0.0000], Avg: [-501.598 -501.598 -501.598] (1.000)
Step: 11999, Reward: [-420.59 -420.59 -420.59] [0.0000], Avg: [-501.261 -501.261 -501.261] (1.000)
Step: 12049, Reward: [-415.897 -415.897 -415.897] [0.0000], Avg: [-500.907 -500.907 -500.907] (1.000)
Step: 12099, Reward: [-386.833 -386.833 -386.833] [0.0000], Avg: [-500.435 -500.435 -500.435] (1.000)
Step: 12149, Reward: [-589.659 -589.659 -589.659] [0.0000], Avg: [-500.802 -500.802 -500.802] (1.000)
Step: 12199, Reward: [-660.17 -660.17 -660.17] [0.0000], Avg: [-501.456 -501.456 -501.456] (1.000)
Step: 12249, Reward: [-398.836 -398.836 -398.836] [0.0000], Avg: [-501.037 -501.037 -501.037] (1.000)
Step: 12299, Reward: [-371.854 -371.854 -371.854] [0.0000], Avg: [-500.512 -500.512 -500.512] (1.000)
Step: 12349, Reward: [-404.661 -404.661 -404.661] [0.0000], Avg: [-500.123 -500.123 -500.123] (1.000)
Step: 12399, Reward: [-424.443 -424.443 -424.443] [0.0000], Avg: [-499.818 -499.818 -499.818] (1.000)
Step: 12449, Reward: [-440.194 -440.194 -440.194] [0.0000], Avg: [-499.579 -499.579 -499.579] (1.000)
Step: 12499, Reward: [-505.02 -505.02 -505.02] [0.0000], Avg: [-499.601 -499.601 -499.601] (1.000)
Step: 12549, Reward: [-512.122 -512.122 -512.122] [0.0000], Avg: [-499.651 -499.651 -499.651] (1.000)
Step: 12599, Reward: [-544.223 -544.223 -544.223] [0.0000], Avg: [-499.827 -499.827 -499.827] (1.000)
Step: 12649, Reward: [-583.464 -583.464 -583.464] [0.0000], Avg: [-500.158 -500.158 -500.158] (1.000)
Step: 12699, Reward: [-569.831 -569.831 -569.831] [0.0000], Avg: [-500.432 -500.432 -500.432] (1.000)
Step: 12749, Reward: [-571.042 -571.042 -571.042] [0.0000], Avg: [-500.709 -500.709 -500.709] (1.000)
Step: 12799, Reward: [-407.759 -407.759 -407.759] [0.0000], Avg: [-500.346 -500.346 -500.346] (1.000)
Step: 12849, Reward: [-420.273 -420.273 -420.273] [0.0000], Avg: [-500.035 -500.035 -500.035] (1.000)
Step: 12899, Reward: [-361.777 -361.777 -361.777] [0.0000], Avg: [-499.499 -499.499 -499.499] (1.000)
Step: 12949, Reward: [-528.394 -528.394 -528.394] [0.0000], Avg: [-499.61 -499.61 -499.61] (1.000)
Step: 12999, Reward: [-466.845 -466.845 -466.845] [0.0000], Avg: [-499.484 -499.484 -499.484] (1.000)
Step: 13049, Reward: [-308.212 -308.212 -308.212] [0.0000], Avg: [-498.751 -498.751 -498.751] (1.000)
Step: 13099, Reward: [-310.418 -310.418 -310.418] [0.0000], Avg: [-498.033 -498.033 -498.033] (1.000)
Step: 13149, Reward: [-364.837 -364.837 -364.837] [0.0000], Avg: [-497.526 -497.526 -497.526] (1.000)
Step: 13199, Reward: [-350.362 -350.362 -350.362] [0.0000], Avg: [-496.969 -496.969 -496.969] (1.000)
Step: 13249, Reward: [-376.285 -376.285 -376.285] [0.0000], Avg: [-496.513 -496.513 -496.513] (1.000)
Step: 13299, Reward: [-385.818 -385.818 -385.818] [0.0000], Avg: [-496.097 -496.097 -496.097] (1.000)
Step: 13349, Reward: [-416.894 -416.894 -416.894] [0.0000], Avg: [-495.8 -495.8 -495.8] (1.000)
Step: 13399, Reward: [-355.452 -355.452 -355.452] [0.0000], Avg: [-495.277 -495.277 -495.277] (1.000)
Step: 13449, Reward: [-406.955 -406.955 -406.955] [0.0000], Avg: [-494.948 -494.948 -494.948] (1.000)
Step: 13499, Reward: [-375.04 -375.04 -375.04] [0.0000], Avg: [-494.504 -494.504 -494.504] (1.000)
Step: 13549, Reward: [-554.889 -554.889 -554.889] [0.0000], Avg: [-494.727 -494.727 -494.727] (1.000)
Step: 13599, Reward: [-424.104 -424.104 -424.104] [0.0000], Avg: [-494.467 -494.467 -494.467] (1.000)
Step: 13649, Reward: [-472.557 -472.557 -472.557] [0.0000], Avg: [-494.387 -494.387 -494.387] (1.000)
Step: 13699, Reward: [-605.624 -605.624 -605.624] [0.0000], Avg: [-494.793 -494.793 -494.793] (1.000)
Step: 13749, Reward: [-461.984 -461.984 -461.984] [0.0000], Avg: [-494.674 -494.674 -494.674] (1.000)
Step: 13799, Reward: [-664.398 -664.398 -664.398] [0.0000], Avg: [-495.289 -495.289 -495.289] (1.000)
Step: 13849, Reward: [-485.598 -485.598 -485.598] [0.0000], Avg: [-495.254 -495.254 -495.254] (1.000)
Step: 13899, Reward: [-458.068 -458.068 -458.068] [0.0000], Avg: [-495.12 -495.12 -495.12] (1.000)
Step: 13949, Reward: [-423.872 -423.872 -423.872] [0.0000], Avg: [-494.865 -494.865 -494.865] (1.000)
Step: 13999, Reward: [-424.992 -424.992 -424.992] [0.0000], Avg: [-494.615 -494.615 -494.615] (1.000)
Step: 14049, Reward: [-358.751 -358.751 -358.751] [0.0000], Avg: [-494.132 -494.132 -494.132] (1.000)
Step: 14099, Reward: [-404.094 -404.094 -404.094] [0.0000], Avg: [-493.812 -493.812 -493.812] (1.000)
Step: 14149, Reward: [-434.038 -434.038 -434.038] [0.0000], Avg: [-493.601 -493.601 -493.601] (1.000)
Step: 14199, Reward: [-363.581 -363.581 -363.581] [0.0000], Avg: [-493.143 -493.143 -493.143] (1.000)
Step: 14249, Reward: [-484.456 -484.456 -484.456] [0.0000], Avg: [-493.113 -493.113 -493.113] (1.000)
Step: 14299, Reward: [-469.91 -469.91 -469.91] [0.0000], Avg: [-493.032 -493.032 -493.032] (1.000)
Step: 14349, Reward: [-438.344 -438.344 -438.344] [0.0000], Avg: [-492.841 -492.841 -492.841] (1.000)
Step: 14399, Reward: [-421.107 -421.107 -421.107] [0.0000], Avg: [-492.592 -492.592 -492.592] (1.000)
Step: 14449, Reward: [-523.133 -523.133 -523.133] [0.0000], Avg: [-492.698 -492.698 -492.698] (1.000)
Step: 14499, Reward: [-359.43 -359.43 -359.43] [0.0000], Avg: [-492.238 -492.238 -492.238] (1.000)
Step: 14549, Reward: [-478.819 -478.819 -478.819] [0.0000], Avg: [-492.192 -492.192 -492.192] (1.000)
Step: 14599, Reward: [-475.098 -475.098 -475.098] [0.0000], Avg: [-492.134 -492.134 -492.134] (1.000)
Step: 14649, Reward: [-510.453 -510.453 -510.453] [0.0000], Avg: [-492.196 -492.196 -492.196] (1.000)
Step: 14699, Reward: [-599.635 -599.635 -599.635] [0.0000], Avg: [-492.562 -492.562 -492.562] (1.000)
Step: 14749, Reward: [-519.367 -519.367 -519.367] [0.0000], Avg: [-492.652 -492.652 -492.652] (1.000)
Step: 14799, Reward: [-403.023 -403.023 -403.023] [0.0000], Avg: [-492.35 -492.35 -492.35] (1.000)
Step: 14849, Reward: [-380.393 -380.393 -380.393] [0.0000], Avg: [-491.973 -491.973 -491.973] (1.000)
Step: 14899, Reward: [-353.595 -353.595 -353.595] [0.0000], Avg: [-491.508 -491.508 -491.508] (1.000)
Step: 14949, Reward: [-566.718 -566.718 -566.718] [0.0000], Avg: [-491.76 -491.76 -491.76] (1.000)
Step: 14999, Reward: [-453.809 -453.809 -453.809] [0.0000], Avg: [-491.633 -491.633 -491.633] (1.000)
Step: 15049, Reward: [-427.776 -427.776 -427.776] [0.0000], Avg: [-491.421 -491.421 -491.421] (1.000)
Step: 15099, Reward: [-530.011 -530.011 -530.011] [0.0000], Avg: [-491.549 -491.549 -491.549] (1.000)
Step: 15149, Reward: [-451.386 -451.386 -451.386] [0.0000], Avg: [-491.416 -491.416 -491.416] (1.000)
Step: 15199, Reward: [-477.633 -477.633 -477.633] [0.0000], Avg: [-491.371 -491.371 -491.371] (1.000)
Step: 15249, Reward: [-367.299 -367.299 -367.299] [0.0000], Avg: [-490.964 -490.964 -490.964] (1.000)
Step: 15299, Reward: [-397.104 -397.104 -397.104] [0.0000], Avg: [-490.658 -490.658 -490.658] (1.000)
Step: 15349, Reward: [-589.166 -589.166 -589.166] [0.0000], Avg: [-490.978 -490.978 -490.978] (1.000)
Step: 15399, Reward: [-432.275 -432.275 -432.275] [0.0000], Avg: [-490.788 -490.788 -490.788] (1.000)
Step: 15449, Reward: [-337.505 -337.505 -337.505] [0.0000], Avg: [-490.292 -490.292 -490.292] (1.000)
Step: 15499, Reward: [-439.388 -439.388 -439.388] [0.0000], Avg: [-490.128 -490.128 -490.128] (1.000)
Step: 15549, Reward: [-395.017 -395.017 -395.017] [0.0000], Avg: [-489.822 -489.822 -489.822] (1.000)
Step: 15599, Reward: [-567.808 -567.808 -567.808] [0.0000], Avg: [-490.072 -490.072 -490.072] (1.000)
Step: 15649, Reward: [-429.015 -429.015 -429.015] [0.0000], Avg: [-489.877 -489.877 -489.877] (1.000)
Step: 15699, Reward: [-519.044 -519.044 -519.044] [0.0000], Avg: [-489.97 -489.97 -489.97] (1.000)
Step: 15749, Reward: [-471.389 -471.389 -471.389] [0.0000], Avg: [-489.911 -489.911 -489.911] (1.000)
Step: 15799, Reward: [-728.594 -728.594 -728.594] [0.0000], Avg: [-490.666 -490.666 -490.666] (1.000)
Step: 15849, Reward: [-497.484 -497.484 -497.484] [0.0000], Avg: [-490.687 -490.687 -490.687] (1.000)
Step: 15899, Reward: [-428.485 -428.485 -428.485] [0.0000], Avg: [-490.492 -490.492 -490.492] (1.000)
Step: 15949, Reward: [-508.072 -508.072 -508.072] [0.0000], Avg: [-490.547 -490.547 -490.547] (1.000)
Step: 15999, Reward: [-464.917 -464.917 -464.917] [0.0000], Avg: [-490.467 -490.467 -490.467] (1.000)
Step: 16049, Reward: [-409.4 -409.4 -409.4] [0.0000], Avg: [-490.214 -490.214 -490.214] (1.000)
Step: 16099, Reward: [-544.597 -544.597 -544.597] [0.0000], Avg: [-490.383 -490.383 -490.383] (1.000)
Step: 16149, Reward: [-462.849 -462.849 -462.849] [0.0000], Avg: [-490.298 -490.298 -490.298] (1.000)
Step: 16199, Reward: [-467.376 -467.376 -467.376] [0.0000], Avg: [-490.227 -490.227 -490.227] (1.000)
Step: 16249, Reward: [-500.095 -500.095 -500.095] [0.0000], Avg: [-490.258 -490.258 -490.258] (1.000)
Step: 16299, Reward: [-546.91 -546.91 -546.91] [0.0000], Avg: [-490.431 -490.431 -490.431] (1.000)
Step: 16349, Reward: [-460.074 -460.074 -460.074] [0.0000], Avg: [-490.338 -490.338 -490.338] (1.000)
Step: 16399, Reward: [-398.041 -398.041 -398.041] [0.0000], Avg: [-490.057 -490.057 -490.057] (1.000)
Step: 16449, Reward: [-489.002 -489.002 -489.002] [0.0000], Avg: [-490.054 -490.054 -490.054] (1.000)
Step: 16499, Reward: [-433.888 -433.888 -433.888] [0.0000], Avg: [-489.884 -489.884 -489.884] (1.000)
Step: 16549, Reward: [-696.415 -696.415 -696.415] [0.0000], Avg: [-490.508 -490.508 -490.508] (1.000)
Step: 16599, Reward: [-365.651 -365.651 -365.651] [0.0000], Avg: [-490.132 -490.132 -490.132] (1.000)
Step: 16649, Reward: [-518.669 -518.669 -518.669] [0.0000], Avg: [-490.217 -490.217 -490.217] (1.000)
Step: 16699, Reward: [-464.3 -464.3 -464.3] [0.0000], Avg: [-490.14 -490.14 -490.14] (1.000)
Step: 16749, Reward: [-582.245 -582.245 -582.245] [0.0000], Avg: [-490.415 -490.415 -490.415] (1.000)
Step: 16799, Reward: [-535.477 -535.477 -535.477] [0.0000], Avg: [-490.549 -490.549 -490.549] (1.000)
Step: 16849, Reward: [-596.887 -596.887 -596.887] [0.0000], Avg: [-490.864 -490.864 -490.864] (1.000)
Step: 16899, Reward: [-465.579 -465.579 -465.579] [0.0000], Avg: [-490.789 -490.789 -490.789] (1.000)
Step: 16949, Reward: [-440.955 -440.955 -440.955] [0.0000], Avg: [-490.642 -490.642 -490.642] (1.000)
Step: 16999, Reward: [-695.581 -695.581 -695.581] [0.0000], Avg: [-491.245 -491.245 -491.245] (1.000)
Step: 17049, Reward: [-681.807 -681.807 -681.807] [0.0000], Avg: [-491.804 -491.804 -491.804] (1.000)
Step: 17099, Reward: [-580.674 -580.674 -580.674] [0.0000], Avg: [-492.064 -492.064 -492.064] (1.000)
Step: 17149, Reward: [-392.522 -392.522 -392.522] [0.0000], Avg: [-491.774 -491.774 -491.774] (1.000)
Step: 17199, Reward: [-471.631 -471.631 -471.631] [0.0000], Avg: [-491.715 -491.715 -491.715] (1.000)
Step: 17249, Reward: [-538.502 -538.502 -538.502] [0.0000], Avg: [-491.851 -491.851 -491.851] (1.000)
Step: 17299, Reward: [-427.695 -427.695 -427.695] [0.0000], Avg: [-491.665 -491.665 -491.665] (1.000)
Step: 17349, Reward: [-403.946 -403.946 -403.946] [0.0000], Avg: [-491.413 -491.413 -491.413] (1.000)
Step: 17399, Reward: [-378.997 -378.997 -378.997] [0.0000], Avg: [-491.089 -491.089 -491.089] (1.000)
Step: 17449, Reward: [-424.466 -424.466 -424.466] [0.0000], Avg: [-490.899 -490.899 -490.899] (1.000)
Step: 17499, Reward: [-604.354 -604.354 -604.354] [0.0000], Avg: [-491.223 -491.223 -491.223] (1.000)
Step: 17549, Reward: [-343.901 -343.901 -343.901] [0.0000], Avg: [-490.803 -490.803 -490.803] (1.000)
Step: 17599, Reward: [-466.779 -466.779 -466.779] [0.0000], Avg: [-490.735 -490.735 -490.735] (1.000)
Step: 17649, Reward: [-503.06 -503.06 -503.06] [0.0000], Avg: [-490.77 -490.77 -490.77] (1.000)
Step: 17699, Reward: [-475.068 -475.068 -475.068] [0.0000], Avg: [-490.725 -490.725 -490.725] (1.000)
Step: 17749, Reward: [-356.4 -356.4 -356.4] [0.0000], Avg: [-490.347 -490.347 -490.347] (1.000)
Step: 17799, Reward: [-522.893 -522.893 -522.893] [0.0000], Avg: [-490.438 -490.438 -490.438] (1.000)
Step: 17849, Reward: [-405.928 -405.928 -405.928] [0.0000], Avg: [-490.202 -490.202 -490.202] (1.000)
Step: 17899, Reward: [-390.466 -390.466 -390.466] [0.0000], Avg: [-489.923 -489.923 -489.923] (1.000)
Step: 17949, Reward: [-513.934 -513.934 -513.934] [0.0000], Avg: [-489.99 -489.99 -489.99] (1.000)
Step: 17999, Reward: [-483.587 -483.587 -483.587] [0.0000], Avg: [-489.972 -489.972 -489.972] (1.000)
Step: 18049, Reward: [-654.697 -654.697 -654.697] [0.0000], Avg: [-490.428 -490.428 -490.428] (1.000)
Step: 18099, Reward: [-396.332 -396.332 -396.332] [0.0000], Avg: [-490.169 -490.169 -490.169] (1.000)
Step: 18149, Reward: [-468.914 -468.914 -468.914] [0.0000], Avg: [-490.11 -490.11 -490.11] (1.000)
Step: 18199, Reward: [-420.175 -420.175 -420.175] [0.0000], Avg: [-489.918 -489.918 -489.918] (1.000)
Step: 18249, Reward: [-471.141 -471.141 -471.141] [0.0000], Avg: [-489.866 -489.866 -489.866] (1.000)
Step: 18299, Reward: [-504.116 -504.116 -504.116] [0.0000], Avg: [-489.905 -489.905 -489.905] (1.000)
Step: 18349, Reward: [-345.342 -345.342 -345.342] [0.0000], Avg: [-489.511 -489.511 -489.511] (1.000)
Step: 18399, Reward: [-400.024 -400.024 -400.024] [0.0000], Avg: [-489.268 -489.268 -489.268] (1.000)
Step: 18449, Reward: [-483.64 -483.64 -483.64] [0.0000], Avg: [-489.253 -489.253 -489.253] (1.000)
Step: 18499, Reward: [-466.971 -466.971 -466.971] [0.0000], Avg: [-489.193 -489.193 -489.193] (1.000)
Step: 18549, Reward: [-633.321 -633.321 -633.321] [0.0000], Avg: [-489.581 -489.581 -489.581] (1.000)
Step: 18599, Reward: [-543.224 -543.224 -543.224] [0.0000], Avg: [-489.725 -489.725 -489.725] (1.000)
Step: 18649, Reward: [-540.504 -540.504 -540.504] [0.0000], Avg: [-489.862 -489.862 -489.862] (1.000)
Step: 18699, Reward: [-620.555 -620.555 -620.555] [0.0000], Avg: [-490.211 -490.211 -490.211] (1.000)
Step: 18749, Reward: [-586.734 -586.734 -586.734] [0.0000], Avg: [-490.468 -490.468 -490.468] (1.000)
Step: 18799, Reward: [-481.179 -481.179 -481.179] [0.0000], Avg: [-490.444 -490.444 -490.444] (1.000)
Step: 18849, Reward: [-417.37 -417.37 -417.37] [0.0000], Avg: [-490.25 -490.25 -490.25] (1.000)
Step: 18899, Reward: [-590.227 -590.227 -590.227] [0.0000], Avg: [-490.514 -490.514 -490.514] (1.000)
Step: 18949, Reward: [-520.355 -520.355 -520.355] [0.0000], Avg: [-490.593 -490.593 -490.593] (1.000)
Step: 18999, Reward: [-499.235 -499.235 -499.235] [0.0000], Avg: [-490.616 -490.616 -490.616] (1.000)
Step: 19049, Reward: [-510.612 -510.612 -510.612] [0.0000], Avg: [-490.668 -490.668 -490.668] (1.000)
Step: 19099, Reward: [-503.527 -503.527 -503.527] [0.0000], Avg: [-490.702 -490.702 -490.702] (1.000)
Step: 19149, Reward: [-460.34 -460.34 -460.34] [0.0000], Avg: [-490.623 -490.623 -490.623] (1.000)
Step: 19199, Reward: [-373.215 -373.215 -373.215] [0.0000], Avg: [-490.317 -490.317 -490.317] (1.000)
Step: 19249, Reward: [-406.089 -406.089 -406.089] [0.0000], Avg: [-490.098 -490.098 -490.098] (1.000)
Step: 19299, Reward: [-497.997 -497.997 -497.997] [0.0000], Avg: [-490.119 -490.119 -490.119] (1.000)
Step: 19349, Reward: [-460.901 -460.901 -460.901] [0.0000], Avg: [-490.043 -490.043 -490.043] (1.000)
Step: 19399, Reward: [-401.664 -401.664 -401.664] [0.0000], Avg: [-489.815 -489.815 -489.815] (1.000)
Step: 19449, Reward: [-463.819 -463.819 -463.819] [0.0000], Avg: [-489.749 -489.749 -489.749] (1.000)
Step: 19499, Reward: [-461.023 -461.023 -461.023] [0.0000], Avg: [-489.675 -489.675 -489.675] (1.000)
Step: 19549, Reward: [-710.519 -710.519 -710.519] [0.0000], Avg: [-490.24 -490.24 -490.24] (1.000)
Step: 19599, Reward: [-384.065 -384.065 -384.065] [0.0000], Avg: [-489.969 -489.969 -489.969] (1.000)
Step: 19649, Reward: [-436.458 -436.458 -436.458] [0.0000], Avg: [-489.833 -489.833 -489.833] (1.000)
Step: 19699, Reward: [-626.231 -626.231 -626.231] [0.0000], Avg: [-490.179 -490.179 -490.179] (1.000)
Step: 19749, Reward: [-371.238 -371.238 -371.238] [0.0000], Avg: [-489.878 -489.878 -489.878] (1.000)
Step: 19799, Reward: [-552.737 -552.737 -552.737] [0.0000], Avg: [-490.037 -490.037 -490.037] (1.000)
Step: 19849, Reward: [-397.729 -397.729 -397.729] [0.0000], Avg: [-489.804 -489.804 -489.804] (1.000)
Step: 19899, Reward: [-472.966 -472.966 -472.966] [0.0000], Avg: [-489.762 -489.762 -489.762] (1.000)
Step: 19949, Reward: [-627.381 -627.381 -627.381] [0.0000], Avg: [-490.107 -490.107 -490.107] (1.000)
Step: 19999, Reward: [-467.532 -467.532 -467.532] [0.0000], Avg: [-490.05 -490.05 -490.05] (1.000)
Step: 20049, Reward: [-642.133 -642.133 -642.133] [0.0000], Avg: [-490.429 -490.429 -490.429] (1.000)
Step: 20099, Reward: [-638.585 -638.585 -638.585] [0.0000], Avg: [-490.798 -490.798 -490.798] (1.000)
Step: 20149, Reward: [-411.351 -411.351 -411.351] [0.0000], Avg: [-490.601 -490.601 -490.601] (1.000)
Step: 20199, Reward: [-521.706 -521.706 -521.706] [0.0000], Avg: [-490.678 -490.678 -490.678] (1.000)
Step: 20249, Reward: [-432.286 -432.286 -432.286] [0.0000], Avg: [-490.534 -490.534 -490.534] (1.000)
Step: 20299, Reward: [-344.426 -344.426 -344.426] [0.0000], Avg: [-490.174 -490.174 -490.174] (1.000)
Step: 20349, Reward: [-572.404 -572.404 -572.404] [0.0000], Avg: [-490.376 -490.376 -490.376] (1.000)
Step: 20399, Reward: [-507.09 -507.09 -507.09] [0.0000], Avg: [-490.417 -490.417 -490.417] (1.000)
Step: 20449, Reward: [-481.401 -481.401 -481.401] [0.0000], Avg: [-490.395 -490.395 -490.395] (1.000)
Step: 20499, Reward: [-438.034 -438.034 -438.034] [0.0000], Avg: [-490.267 -490.267 -490.267] (1.000)
Step: 20549, Reward: [-374.857 -374.857 -374.857] [0.0000], Avg: [-489.986 -489.986 -489.986] (1.000)
Step: 20599, Reward: [-625.9 -625.9 -625.9] [0.0000], Avg: [-490.316 -490.316 -490.316] (1.000)
Step: 20649, Reward: [-482.414 -482.414 -482.414] [0.0000], Avg: [-490.297 -490.297 -490.297] (1.000)
Step: 20699, Reward: [-437.997 -437.997 -437.997] [0.0000], Avg: [-490.171 -490.171 -490.171] (1.000)
Step: 20749, Reward: [-379.133 -379.133 -379.133] [0.0000], Avg: [-489.903 -489.903 -489.903] (1.000)
Step: 20799, Reward: [-445.992 -445.992 -445.992] [0.0000], Avg: [-489.798 -489.798 -489.798] (1.000)
Step: 20849, Reward: [-398.62 -398.62 -398.62] [0.0000], Avg: [-489.579 -489.579 -489.579] (1.000)
Step: 20899, Reward: [-354.342 -354.342 -354.342] [0.0000], Avg: [-489.255 -489.255 -489.255] (1.000)
Step: 20949, Reward: [-515.941 -515.941 -515.941] [0.0000], Avg: [-489.319 -489.319 -489.319] (1.000)
Step: 20999, Reward: [-535.812 -535.812 -535.812] [0.0000], Avg: [-489.43 -489.43 -489.43] (1.000)
Step: 21049, Reward: [-788.949 -788.949 -788.949] [0.0000], Avg: [-490.141 -490.141 -490.141] (1.000)
Step: 21099, Reward: [-382.502 -382.502 -382.502] [0.0000], Avg: [-489.886 -489.886 -489.886] (1.000)
Step: 21149, Reward: [-423.816 -423.816 -423.816] [0.0000], Avg: [-489.73 -489.73 -489.73] (1.000)
Step: 21199, Reward: [-448.094 -448.094 -448.094] [0.0000], Avg: [-489.632 -489.632 -489.632] (1.000)
Step: 21249, Reward: [-384.542 -384.542 -384.542] [0.0000], Avg: [-489.384 -489.384 -489.384] (1.000)
Step: 21299, Reward: [-473.336 -473.336 -473.336] [0.0000], Avg: [-489.347 -489.347 -489.347] (1.000)
Step: 21349, Reward: [-463.493 -463.493 -463.493] [0.0000], Avg: [-489.286 -489.286 -489.286] (1.000)
Step: 21399, Reward: [-547.314 -547.314 -547.314] [0.0000], Avg: [-489.422 -489.422 -489.422] (1.000)
Step: 21449, Reward: [-492.239 -492.239 -492.239] [0.0000], Avg: [-489.428 -489.428 -489.428] (1.000)
Step: 21499, Reward: [-392.029 -392.029 -392.029] [0.0000], Avg: [-489.202 -489.202 -489.202] (1.000)
Step: 21549, Reward: [-670.117 -670.117 -670.117] [0.0000], Avg: [-489.622 -489.622 -489.622] (1.000)
Step: 21599, Reward: [-473.519 -473.519 -473.519] [0.0000], Avg: [-489.584 -489.584 -489.584] (1.000)
Step: 21649, Reward: [-571.678 -571.678 -571.678] [0.0000], Avg: [-489.774 -489.774 -489.774] (1.000)
Step: 21699, Reward: [-372.885 -372.885 -372.885] [0.0000], Avg: [-489.505 -489.505 -489.505] (1.000)
Step: 21749, Reward: [-514.261 -514.261 -514.261] [0.0000], Avg: [-489.562 -489.562 -489.562] (1.000)
Step: 21799, Reward: [-392.66 -392.66 -392.66] [0.0000], Avg: [-489.339 -489.339 -489.339] (1.000)
Step: 21849, Reward: [-379.246 -379.246 -379.246] [0.0000], Avg: [-489.087 -489.087 -489.087] (1.000)
Step: 21899, Reward: [-596.587 -596.587 -596.587] [0.0000], Avg: [-489.333 -489.333 -489.333] (1.000)
Step: 21949, Reward: [-388.923 -388.923 -388.923] [0.0000], Avg: [-489.104 -489.104 -489.104] (1.000)
Step: 21999, Reward: [-516.642 -516.642 -516.642] [0.0000], Avg: [-489.167 -489.167 -489.167] (1.000)
Step: 22049, Reward: [-653.922 -653.922 -653.922] [0.0000], Avg: [-489.54 -489.54 -489.54] (1.000)
Step: 22099, Reward: [-491.158 -491.158 -491.158] [0.0000], Avg: [-489.544 -489.544 -489.544] (1.000)
Step: 22149, Reward: [-686.24 -686.24 -686.24] [0.0000], Avg: [-489.988 -489.988 -489.988] (1.000)
Step: 22199, Reward: [-524.274 -524.274 -524.274] [0.0000], Avg: [-490.065 -490.065 -490.065] (1.000)
Step: 22249, Reward: [-512.718 -512.718 -512.718] [0.0000], Avg: [-490.116 -490.116 -490.116] (1.000)
Step: 22299, Reward: [-497.057 -497.057 -497.057] [0.0000], Avg: [-490.132 -490.132 -490.132] (1.000)
Step: 22349, Reward: [-568.521 -568.521 -568.521] [0.0000], Avg: [-490.307 -490.307 -490.307] (1.000)
Step: 22399, Reward: [-455.64 -455.64 -455.64] [0.0000], Avg: [-490.23 -490.23 -490.23] (1.000)
Step: 22449, Reward: [-375.685 -375.685 -375.685] [0.0000], Avg: [-489.974 -489.974 -489.974] (1.000)
Step: 22499, Reward: [-506.406 -506.406 -506.406] [0.0000], Avg: [-490.011 -490.011 -490.011] (1.000)
Step: 22549, Reward: [-573.43 -573.43 -573.43] [0.0000], Avg: [-490.196 -490.196 -490.196] (1.000)
Step: 22599, Reward: [-513.176 -513.176 -513.176] [0.0000], Avg: [-490.247 -490.247 -490.247] (1.000)
Step: 22649, Reward: [-467.401 -467.401 -467.401] [0.0000], Avg: [-490.196 -490.196 -490.196] (1.000)
Step: 22699, Reward: [-448.242 -448.242 -448.242] [0.0000], Avg: [-490.104 -490.104 -490.104] (1.000)
Step: 22749, Reward: [-499.376 -499.376 -499.376] [0.0000], Avg: [-490.124 -490.124 -490.124] (1.000)
Step: 22799, Reward: [-518.711 -518.711 -518.711] [0.0000], Avg: [-490.187 -490.187 -490.187] (1.000)
Step: 22849, Reward: [-547.753 -547.753 -547.753] [0.0000], Avg: [-490.313 -490.313 -490.313] (1.000)
Step: 22899, Reward: [-634.944 -634.944 -634.944] [0.0000], Avg: [-490.629 -490.629 -490.629] (1.000)
Step: 22949, Reward: [-527.583 -527.583 -527.583] [0.0000], Avg: [-490.709 -490.709 -490.709] (1.000)
Step: 22999, Reward: [-597.19 -597.19 -597.19] [0.0000], Avg: [-490.941 -490.941 -490.941] (1.000)
Step: 23049, Reward: [-439.48 -439.48 -439.48] [0.0000], Avg: [-490.829 -490.829 -490.829] (1.000)
Step: 23099, Reward: [-653.658 -653.658 -653.658] [0.0000], Avg: [-491.182 -491.182 -491.182] (1.000)
Step: 23149, Reward: [-380.586 -380.586 -380.586] [0.0000], Avg: [-490.943 -490.943 -490.943] (1.000)
Step: 23199, Reward: [-521.829 -521.829 -521.829] [0.0000], Avg: [-491.009 -491.009 -491.009] (1.000)
Step: 23249, Reward: [-440.454 -440.454 -440.454] [0.0000], Avg: [-490.901 -490.901 -490.901] (1.000)
Step: 23299, Reward: [-437.547 -437.547 -437.547] [0.0000], Avg: [-490.786 -490.786 -490.786] (1.000)
Step: 23349, Reward: [-430.851 -430.851 -430.851] [0.0000], Avg: [-490.658 -490.658 -490.658] (1.000)
Step: 23399, Reward: [-589.963 -589.963 -589.963] [0.0000], Avg: [-490.87 -490.87 -490.87] (1.000)
Step: 23449, Reward: [-787.67 -787.67 -787.67] [0.0000], Avg: [-491.503 -491.503 -491.503] (1.000)
Step: 23499, Reward: [-521.781 -521.781 -521.781] [0.0000], Avg: [-491.567 -491.567 -491.567] (1.000)
Step: 23549, Reward: [-544.537 -544.537 -544.537] [0.0000], Avg: [-491.68 -491.68 -491.68] (1.000)
Step: 23599, Reward: [-366.413 -366.413 -366.413] [0.0000], Avg: [-491.414 -491.414 -491.414] (1.000)
Step: 23649, Reward: [-412.267 -412.267 -412.267] [0.0000], Avg: [-491.247 -491.247 -491.247] (1.000)
Step: 23699, Reward: [-543.835 -543.835 -543.835] [0.0000], Avg: [-491.358 -491.358 -491.358] (1.000)
Step: 23749, Reward: [-444.819 -444.819 -444.819] [0.0000], Avg: [-491.26 -491.26 -491.26] (1.000)
Step: 23799, Reward: [-433.529 -433.529 -433.529] [0.0000], Avg: [-491.139 -491.139 -491.139] (1.000)
Step: 23849, Reward: [-491.732 -491.732 -491.732] [0.0000], Avg: [-491.14 -491.14 -491.14] (1.000)
Step: 23899, Reward: [-619.204 -619.204 -619.204] [0.0000], Avg: [-491.408 -491.408 -491.408] (1.000)
Step: 23949, Reward: [-333.379 -333.379 -333.379] [0.0000], Avg: [-491.078 -491.078 -491.078] (1.000)
Step: 23999, Reward: [-467.2 -467.2 -467.2] [0.0000], Avg: [-491.028 -491.028 -491.028] (1.000)
Step: 24049, Reward: [-516.587 -516.587 -516.587] [0.0000], Avg: [-491.081 -491.081 -491.081] (1.000)
Step: 24099, Reward: [-426.748 -426.748 -426.748] [0.0000], Avg: [-490.948 -490.948 -490.948] (1.000)
Step: 24149, Reward: [-363.981 -363.981 -363.981] [0.0000], Avg: [-490.685 -490.685 -490.685] (1.000)
Step: 24199, Reward: [-475.409 -475.409 -475.409] [0.0000], Avg: [-490.653 -490.653 -490.653] (1.000)
Step: 24249, Reward: [-525.545 -525.545 -525.545] [0.0000], Avg: [-490.725 -490.725 -490.725] (1.000)
Step: 24299, Reward: [-434.299 -434.299 -434.299] [0.0000], Avg: [-490.609 -490.609 -490.609] (1.000)
Step: 24349, Reward: [-417.591 -417.591 -417.591] [0.0000], Avg: [-490.459 -490.459 -490.459] (1.000)
Step: 24399, Reward: [-484.592 -484.592 -484.592] [0.0000], Avg: [-490.447 -490.447 -490.447] (1.000)
Step: 24449, Reward: [-415.866 -415.866 -415.866] [0.0000], Avg: [-490.295 -490.295 -490.295] (1.000)
Step: 24499, Reward: [-618.911 -618.911 -618.911] [0.0000], Avg: [-490.557 -490.557 -490.557] (1.000)
Step: 24549, Reward: [-482.863 -482.863 -482.863] [0.0000], Avg: [-490.542 -490.542 -490.542] (1.000)
Step: 24599, Reward: [-402.042 -402.042 -402.042] [0.0000], Avg: [-490.362 -490.362 -490.362] (1.000)
Step: 24649, Reward: [-556.974 -556.974 -556.974] [0.0000], Avg: [-490.497 -490.497 -490.497] (1.000)
Step: 24699, Reward: [-502.568 -502.568 -502.568] [0.0000], Avg: [-490.521 -490.521 -490.521] (1.000)
Step: 24749, Reward: [-616.204 -616.204 -616.204] [0.0000], Avg: [-490.775 -490.775 -490.775] (1.000)
Step: 24799, Reward: [-390.85 -390.85 -390.85] [0.0000], Avg: [-490.574 -490.574 -490.574] (1.000)
Step: 24849, Reward: [-365.32 -365.32 -365.32] [0.0000], Avg: [-490.322 -490.322 -490.322] (1.000)
Step: 24899, Reward: [-543.106 -543.106 -543.106] [0.0000], Avg: [-490.428 -490.428 -490.428] (1.000)
Step: 24949, Reward: [-610.782 -610.782 -610.782] [0.0000], Avg: [-490.669 -490.669 -490.669] (1.000)
Step: 24999, Reward: [-651.631 -651.631 -651.631] [0.0000], Avg: [-490.991 -490.991 -490.991] (1.000)
Step: 25049, Reward: [-477.168 -477.168 -477.168] [0.0000], Avg: [-490.963 -490.963 -490.963] (1.000)
Step: 25099, Reward: [-430.724 -430.724 -430.724] [0.0000], Avg: [-490.843 -490.843 -490.843] (1.000)
Step: 25149, Reward: [-563.166 -563.166 -563.166] [0.0000], Avg: [-490.987 -490.987 -490.987] (1.000)
Step: 25199, Reward: [-504.823 -504.823 -504.823] [0.0000], Avg: [-491.014 -491.014 -491.014] (1.000)
Step: 25249, Reward: [-762.121 -762.121 -762.121] [0.0000], Avg: [-491.551 -491.551 -491.551] (1.000)
Step: 25299, Reward: [-389.51 -389.51 -389.51] [0.0000], Avg: [-491.35 -491.35 -491.35] (1.000)
Step: 25349, Reward: [-494.148 -494.148 -494.148] [0.0000], Avg: [-491.355 -491.355 -491.355] (1.000)
Step: 25399, Reward: [-398.505 -398.505 -398.505] [0.0000], Avg: [-491.172 -491.172 -491.172] (1.000)
Step: 25449, Reward: [-549.695 -549.695 -549.695] [0.0000], Avg: [-491.287 -491.287 -491.287] (1.000)
Step: 25499, Reward: [-488.603 -488.603 -488.603] [0.0000], Avg: [-491.282 -491.282 -491.282] (1.000)
Step: 25549, Reward: [-488.997 -488.997 -488.997] [0.0000], Avg: [-491.278 -491.278 -491.278] (1.000)
Step: 25599, Reward: [-636.948 -636.948 -636.948] [0.0000], Avg: [-491.562 -491.562 -491.562] (1.000)
Step: 25649, Reward: [-554.967 -554.967 -554.967] [0.0000], Avg: [-491.686 -491.686 -491.686] (1.000)
Step: 25699, Reward: [-362.36 -362.36 -362.36] [0.0000], Avg: [-491.434 -491.434 -491.434] (1.000)
Step: 25749, Reward: [-493.743 -493.743 -493.743] [0.0000], Avg: [-491.439 -491.439 -491.439] (1.000)
Step: 25799, Reward: [-466.159 -466.159 -466.159] [0.0000], Avg: [-491.39 -491.39 -491.39] (1.000)
Step: 25849, Reward: [-426.138 -426.138 -426.138] [0.0000], Avg: [-491.263 -491.263 -491.263] (1.000)
Step: 25899, Reward: [-495.106 -495.106 -495.106] [0.0000], Avg: [-491.271 -491.271 -491.271] (1.000)
Step: 25949, Reward: [-446.968 -446.968 -446.968] [0.0000], Avg: [-491.185 -491.185 -491.185] (1.000)
Step: 25999, Reward: [-464.679 -464.679 -464.679] [0.0000], Avg: [-491.134 -491.134 -491.134] (1.000)
Step: 26049, Reward: [-668.675 -668.675 -668.675] [0.0000], Avg: [-491.475 -491.475 -491.475] (1.000)
Step: 26099, Reward: [-480.683 -480.683 -480.683] [0.0000], Avg: [-491.454 -491.454 -491.454] (1.000)
Step: 26149, Reward: [-462.946 -462.946 -462.946] [0.0000], Avg: [-491.4 -491.4 -491.4] (1.000)
Step: 26199, Reward: [-596.658 -596.658 -596.658] [0.0000], Avg: [-491.601 -491.601 -491.601] (1.000)
Step: 26249, Reward: [-486.233 -486.233 -486.233] [0.0000], Avg: [-491.591 -491.591 -491.591] (1.000)
Step: 26299, Reward: [-396.751 -396.751 -396.751] [0.0000], Avg: [-491.41 -491.41 -491.41] (1.000)
Step: 26349, Reward: [-396.236 -396.236 -396.236] [0.0000], Avg: [-491.23 -491.23 -491.23] (1.000)
Step: 26399, Reward: [-623.108 -623.108 -623.108] [0.0000], Avg: [-491.479 -491.479 -491.479] (1.000)
Step: 26449, Reward: [-623.264 -623.264 -623.264] [0.0000], Avg: [-491.729 -491.729 -491.729] (1.000)
Step: 26499, Reward: [-440.29 -440.29 -440.29] [0.0000], Avg: [-491.632 -491.632 -491.632] (1.000)
Step: 26549, Reward: [-635.634 -635.634 -635.634] [0.0000], Avg: [-491.903 -491.903 -491.903] (1.000)
Step: 26599, Reward: [-456.904 -456.904 -456.904] [0.0000], Avg: [-491.837 -491.837 -491.837] (1.000)
Step: 26649, Reward: [-436.054 -436.054 -436.054] [0.0000], Avg: [-491.732 -491.732 -491.732] (1.000)
Step: 26699, Reward: [-519.166 -519.166 -519.166] [0.0000], Avg: [-491.784 -491.784 -491.784] (1.000)
Step: 26749, Reward: [-351.515 -351.515 -351.515] [0.0000], Avg: [-491.521 -491.521 -491.521] (1.000)
Step: 26799, Reward: [-472.394 -472.394 -472.394] [0.0000], Avg: [-491.486 -491.486 -491.486] (1.000)
Step: 26849, Reward: [-431.389 -431.389 -431.389] [0.0000], Avg: [-491.374 -491.374 -491.374] (1.000)
Step: 26899, Reward: [-387.246 -387.246 -387.246] [0.0000], Avg: [-491.18 -491.18 -491.18] (1.000)
Step: 26949, Reward: [-482.268 -482.268 -482.268] [0.0000], Avg: [-491.164 -491.164 -491.164] (1.000)
Step: 26999, Reward: [-503.211 -503.211 -503.211] [0.0000], Avg: [-491.186 -491.186 -491.186] (1.000)
Step: 27049, Reward: [-523.853 -523.853 -523.853] [0.0000], Avg: [-491.247 -491.247 -491.247] (1.000)
Step: 27099, Reward: [-444.58 -444.58 -444.58] [0.0000], Avg: [-491.16 -491.16 -491.16] (1.000)
Step: 27149, Reward: [-546.529 -546.529 -546.529] [0.0000], Avg: [-491.262 -491.262 -491.262] (1.000)
Step: 27199, Reward: [-381.661 -381.661 -381.661] [0.0000], Avg: [-491.061 -491.061 -491.061] (1.000)
Step: 27249, Reward: [-363.321 -363.321 -363.321] [0.0000], Avg: [-490.827 -490.827 -490.827] (1.000)
Step: 27299, Reward: [-525.573 -525.573 -525.573] [0.0000], Avg: [-490.89 -490.89 -490.89] (1.000)
Step: 27349, Reward: [-488.956 -488.956 -488.956] [0.0000], Avg: [-490.887 -490.887 -490.887] (1.000)
Step: 27399, Reward: [-588.07 -588.07 -588.07] [0.0000], Avg: [-491.064 -491.064 -491.064] (1.000)
Step: 27449, Reward: [-432.837 -432.837 -432.837] [0.0000], Avg: [-490.958 -490.958 -490.958] (1.000)
Step: 27499, Reward: [-416.392 -416.392 -416.392] [0.0000], Avg: [-490.822 -490.822 -490.822] (1.000)
Step: 27549, Reward: [-345.177 -345.177 -345.177] [0.0000], Avg: [-490.558 -490.558 -490.558] (1.000)
Step: 27599, Reward: [-583.421 -583.421 -583.421] [0.0000], Avg: [-490.726 -490.726 -490.726] (1.000)
Step: 27649, Reward: [-426.113 -426.113 -426.113] [0.0000], Avg: [-490.609 -490.609 -490.609] (1.000)
Step: 27699, Reward: [-387.701 -387.701 -387.701] [0.0000], Avg: [-490.424 -490.424 -490.424] (1.000)
Step: 27749, Reward: [-440.49 -440.49 -440.49] [0.0000], Avg: [-490.334 -490.334 -490.334] (1.000)
Step: 27799, Reward: [-616.901 -616.901 -616.901] [0.0000], Avg: [-490.561 -490.561 -490.561] (1.000)
Step: 27849, Reward: [-526.869 -526.869 -526.869] [0.0000], Avg: [-490.626 -490.626 -490.626] (1.000)
Step: 27899, Reward: [-445.548 -445.548 -445.548] [0.0000], Avg: [-490.546 -490.546 -490.546] (1.000)
Step: 27949, Reward: [-722.095 -722.095 -722.095] [0.0000], Avg: [-490.96 -490.96 -490.96] (1.000)
Step: 27999, Reward: [-421.248 -421.248 -421.248] [0.0000], Avg: [-490.835 -490.835 -490.835] (1.000)
Step: 28049, Reward: [-461.422 -461.422 -461.422] [0.0000], Avg: [-490.783 -490.783 -490.783] (1.000)
Step: 28099, Reward: [-569.826 -569.826 -569.826] [0.0000], Avg: [-490.924 -490.924 -490.924] (1.000)
Step: 28149, Reward: [-523.311 -523.311 -523.311] [0.0000], Avg: [-490.981 -490.981 -490.981] (1.000)
Step: 28199, Reward: [-493.01 -493.01 -493.01] [0.0000], Avg: [-490.985 -490.985 -490.985] (1.000)
Step: 28249, Reward: [-406.718 -406.718 -406.718] [0.0000], Avg: [-490.836 -490.836 -490.836] (1.000)
Step: 28299, Reward: [-352.082 -352.082 -352.082] [0.0000], Avg: [-490.59 -490.59 -490.59] (1.000)
Step: 28349, Reward: [-326.212 -326.212 -326.212] [0.0000], Avg: [-490.301 -490.301 -490.301] (1.000)
Step: 28399, Reward: [-530.819 -530.819 -530.819] [0.0000], Avg: [-490.372 -490.372 -490.372] (1.000)
Step: 28449, Reward: [-411.63 -411.63 -411.63] [0.0000], Avg: [-490.234 -490.234 -490.234] (1.000)
Step: 28499, Reward: [-515.806 -515.806 -515.806] [0.0000], Avg: [-490.278 -490.278 -490.278] (1.000)
Step: 28549, Reward: [-506.097 -506.097 -506.097] [0.0000], Avg: [-490.306 -490.306 -490.306] (1.000)
Step: 28599, Reward: [-440.662 -440.662 -440.662] [0.0000], Avg: [-490.219 -490.219 -490.219] (1.000)
Step: 28649, Reward: [-396.785 -396.785 -396.785] [0.0000], Avg: [-490.056 -490.056 -490.056] (1.000)
Step: 28699, Reward: [-383.671 -383.671 -383.671] [0.0000], Avg: [-489.871 -489.871 -489.871] (1.000)
Step: 28749, Reward: [-490.174 -490.174 -490.174] [0.0000], Avg: [-489.871 -489.871 -489.871] (1.000)
Step: 28799, Reward: [-373.669 -373.669 -373.669] [0.0000], Avg: [-489.67 -489.67 -489.67] (1.000)
Step: 28849, Reward: [-431.595 -431.595 -431.595] [0.0000], Avg: [-489.569 -489.569 -489.569] (1.000)
Step: 28899, Reward: [-593.201 -593.201 -593.201] [0.0000], Avg: [-489.748 -489.748 -489.748] (1.000)
Step: 28949, Reward: [-495.069 -495.069 -495.069] [0.0000], Avg: [-489.758 -489.758 -489.758] (1.000)
Step: 28999, Reward: [-495.149 -495.149 -495.149] [0.0000], Avg: [-489.767 -489.767 -489.767] (1.000)
Step: 29049, Reward: [-433.198 -433.198 -433.198] [0.0000], Avg: [-489.669 -489.669 -489.669] (1.000)
Step: 29099, Reward: [-449.22 -449.22 -449.22] [0.0000], Avg: [-489.6 -489.6 -489.6] (1.000)
Step: 29149, Reward: [-670.93 -670.93 -670.93] [0.0000], Avg: [-489.911 -489.911 -489.911] (1.000)
Step: 29199, Reward: [-493.52 -493.52 -493.52] [0.0000], Avg: [-489.917 -489.917 -489.917] (1.000)
Step: 29249, Reward: [-410.21 -410.21 -410.21] [0.0000], Avg: [-489.781 -489.781 -489.781] (1.000)
Step: 29299, Reward: [-451.614 -451.614 -451.614] [0.0000], Avg: [-489.716 -489.716 -489.716] (1.000)
Step: 29349, Reward: [-541.733 -541.733 -541.733] [0.0000], Avg: [-489.804 -489.804 -489.804] (1.000)
Step: 29399, Reward: [-423.076 -423.076 -423.076] [0.0000], Avg: [-489.691 -489.691 -489.691] (1.000)
Step: 29449, Reward: [-514.982 -514.982 -514.982] [0.0000], Avg: [-489.734 -489.734 -489.734] (1.000)
Step: 29499, Reward: [-444.42 -444.42 -444.42] [0.0000], Avg: [-489.657 -489.657 -489.657] (1.000)
Step: 29549, Reward: [-577.847 -577.847 -577.847] [0.0000], Avg: [-489.806 -489.806 -489.806] (1.000)
Step: 29599, Reward: [-330.018 -330.018 -330.018] [0.0000], Avg: [-489.536 -489.536 -489.536] (1.000)
Step: 29649, Reward: [-420.52 -420.52 -420.52] [0.0000], Avg: [-489.42 -489.42 -489.42] (1.000)
Step: 29699, Reward: [-459.53 -459.53 -459.53] [0.0000], Avg: [-489.37 -489.37 -489.37] (1.000)
Step: 29749, Reward: [-554.449 -554.449 -554.449] [0.0000], Avg: [-489.479 -489.479 -489.479] (1.000)
Step: 29799, Reward: [-543.754 -543.754 -543.754] [0.0000], Avg: [-489.57 -489.57 -489.57] (1.000)
Step: 29849, Reward: [-459.782 -459.782 -459.782] [0.0000], Avg: [-489.52 -489.52 -489.52] (1.000)
Step: 29899, Reward: [-489.323 -489.323 -489.323] [0.0000], Avg: [-489.52 -489.52 -489.52] (1.000)
Step: 29949, Reward: [-908.029 -908.029 -908.029] [0.0000], Avg: [-490.219 -490.219 -490.219] (1.000)
Step: 29999, Reward: [-520.442 -520.442 -520.442] [0.0000], Avg: [-490.269 -490.269 -490.269] (1.000)
Step: 30049, Reward: [-446.179 -446.179 -446.179] [0.0000], Avg: [-490.196 -490.196 -490.196] (1.000)
Step: 30099, Reward: [-439.309 -439.309 -439.309] [0.0000], Avg: [-490.111 -490.111 -490.111] (1.000)
Step: 30149, Reward: [-474.112 -474.112 -474.112] [0.0000], Avg: [-490.084 -490.084 -490.084] (1.000)
Step: 30199, Reward: [-464.977 -464.977 -464.977] [0.0000], Avg: [-490.043 -490.043 -490.043] (1.000)
Step: 30249, Reward: [-481.46 -481.46 -481.46] [0.0000], Avg: [-490.029 -490.029 -490.029] (1.000)
Step: 30299, Reward: [-420.312 -420.312 -420.312] [0.0000], Avg: [-489.914 -489.914 -489.914] (1.000)
Step: 30349, Reward: [-492.064 -492.064 -492.064] [0.0000], Avg: [-489.917 -489.917 -489.917] (1.000)
Step: 30399, Reward: [-476.652 -476.652 -476.652] [0.0000], Avg: [-489.895 -489.895 -489.895] (1.000)
Step: 30449, Reward: [-538.51 -538.51 -538.51] [0.0000], Avg: [-489.975 -489.975 -489.975] (1.000)
Step: 30499, Reward: [-387.383 -387.383 -387.383] [0.0000], Avg: [-489.807 -489.807 -489.807] (1.000)
Step: 30549, Reward: [-809.47 -809.47 -809.47] [0.0000], Avg: [-490.33 -490.33 -490.33] (1.000)
Step: 30599, Reward: [-511.717 -511.717 -511.717] [0.0000], Avg: [-490.365 -490.365 -490.365] (1.000)
Step: 30649, Reward: [-496.975 -496.975 -496.975] [0.0000], Avg: [-490.376 -490.376 -490.376] (1.000)
Step: 30699, Reward: [-601.307 -601.307 -601.307] [0.0000], Avg: [-490.557 -490.557 -490.557] (1.000)
Step: 30749, Reward: [-626.312 -626.312 -626.312] [0.0000], Avg: [-490.777 -490.777 -490.777] (1.000)
Step: 30799, Reward: [-423.776 -423.776 -423.776] [0.0000], Avg: [-490.669 -490.669 -490.669] (1.000)
Step: 30849, Reward: [-367.876 -367.876 -367.876] [0.0000], Avg: [-490.47 -490.47 -490.47] (1.000)
Step: 30899, Reward: [-359.914 -359.914 -359.914] [0.0000], Avg: [-490.258 -490.258 -490.258] (1.000)
Step: 30949, Reward: [-441.901 -441.901 -441.901] [0.0000], Avg: [-490.18 -490.18 -490.18] (1.000)
Step: 30999, Reward: [-335.097 -335.097 -335.097] [0.0000], Avg: [-489.93 -489.93 -489.93] (1.000)
Step: 31049, Reward: [-413.072 -413.072 -413.072] [0.0000], Avg: [-489.806 -489.806 -489.806] (1.000)
Step: 31099, Reward: [-517.669 -517.669 -517.669] [0.0000], Avg: [-489.851 -489.851 -489.851] (1.000)
Step: 31149, Reward: [-460.638 -460.638 -460.638] [0.0000], Avg: [-489.804 -489.804 -489.804] (1.000)
Step: 31199, Reward: [-531.253 -531.253 -531.253] [0.0000], Avg: [-489.871 -489.871 -489.871] (1.000)
Step: 31249, Reward: [-524.225 -524.225 -524.225] [0.0000], Avg: [-489.926 -489.926 -489.926] (1.000)
Step: 31299, Reward: [-387.083 -387.083 -387.083] [0.0000], Avg: [-489.761 -489.761 -489.761] (1.000)
Step: 31349, Reward: [-414.975 -414.975 -414.975] [0.0000], Avg: [-489.642 -489.642 -489.642] (1.000)
Step: 31399, Reward: [-600.123 -600.123 -600.123] [0.0000], Avg: [-489.818 -489.818 -489.818] (1.000)
Step: 31449, Reward: [-398.264 -398.264 -398.264] [0.0000], Avg: [-489.672 -489.672 -489.672] (1.000)
Step: 31499, Reward: [-505.701 -505.701 -505.701] [0.0000], Avg: [-489.698 -489.698 -489.698] (1.000)
Step: 31549, Reward: [-608.639 -608.639 -608.639] [0.0000], Avg: [-489.886 -489.886 -489.886] (1.000)
Step: 31599, Reward: [-437.48 -437.48 -437.48] [0.0000], Avg: [-489.803 -489.803 -489.803] (1.000)
Step: 31649, Reward: [-328.713 -328.713 -328.713] [0.0000], Avg: [-489.549 -489.549 -489.549] (1.000)
Step: 31699, Reward: [-428.618 -428.618 -428.618] [0.0000], Avg: [-489.453 -489.453 -489.453] (1.000)
Step: 31749, Reward: [-612.462 -612.462 -612.462] [0.0000], Avg: [-489.647 -489.647 -489.647] (1.000)
Step: 31799, Reward: [-482.288 -482.288 -482.288] [0.0000], Avg: [-489.635 -489.635 -489.635] (1.000)
Step: 31849, Reward: [-536.621 -536.621 -536.621] [0.0000], Avg: [-489.709 -489.709 -489.709] (1.000)
Step: 31899, Reward: [-448.613 -448.613 -448.613] [0.0000], Avg: [-489.644 -489.644 -489.644] (1.000)
Step: 31949, Reward: [-531.592 -531.592 -531.592] [0.0000], Avg: [-489.71 -489.71 -489.71] (1.000)
Step: 31999, Reward: [-579.604 -579.604 -579.604] [0.0000], Avg: [-489.85 -489.85 -489.85] (1.000)
Step: 32049, Reward: [-726.431 -726.431 -726.431] [0.0000], Avg: [-490.22 -490.22 -490.22] (1.000)
Step: 32099, Reward: [-424.574 -424.574 -424.574] [0.0000], Avg: [-490.117 -490.117 -490.117] (1.000)
Step: 32149, Reward: [-517.704 -517.704 -517.704] [0.0000], Avg: [-490.16 -490.16 -490.16] (1.000)
Step: 32199, Reward: [-415.333 -415.333 -415.333] [0.0000], Avg: [-490.044 -490.044 -490.044] (1.000)
Step: 32249, Reward: [-644.982 -644.982 -644.982] [0.0000], Avg: [-490.284 -490.284 -490.284] (1.000)
Step: 32299, Reward: [-415.581 -415.581 -415.581] [0.0000], Avg: [-490.169 -490.169 -490.169] (1.000)
Step: 32349, Reward: [-348.297 -348.297 -348.297] [0.0000], Avg: [-489.949 -489.949 -489.949] (1.000)
Step: 32399, Reward: [-557.879 -557.879 -557.879] [0.0000], Avg: [-490.054 -490.054 -490.054] (1.000)
Step: 32449, Reward: [-632.448 -632.448 -632.448] [0.0000], Avg: [-490.274 -490.274 -490.274] (1.000)
Step: 32499, Reward: [-435.638 -435.638 -435.638] [0.0000], Avg: [-490.189 -490.189 -490.189] (1.000)
Step: 32549, Reward: [-616.878 -616.878 -616.878] [0.0000], Avg: [-490.384 -490.384 -490.384] (1.000)
Step: 32599, Reward: [-387.591 -387.591 -387.591] [0.0000], Avg: [-490.226 -490.226 -490.226] (1.000)
Step: 32649, Reward: [-505.18 -505.18 -505.18] [0.0000], Avg: [-490.249 -490.249 -490.249] (1.000)
Step: 32699, Reward: [-628.623 -628.623 -628.623] [0.0000], Avg: [-490.461 -490.461 -490.461] (1.000)
Step: 32749, Reward: [-416.65 -416.65 -416.65] [0.0000], Avg: [-490.348 -490.348 -490.348] (1.000)
Step: 32799, Reward: [-438.224 -438.224 -438.224] [0.0000], Avg: [-490.269 -490.269 -490.269] (1.000)
Step: 32849, Reward: [-510.185 -510.185 -510.185] [0.0000], Avg: [-490.299 -490.299 -490.299] (1.000)
Step: 32899, Reward: [-408.772 -408.772 -408.772] [0.0000], Avg: [-490.175 -490.175 -490.175] (1.000)
Step: 32949, Reward: [-531.877 -531.877 -531.877] [0.0000], Avg: [-490.238 -490.238 -490.238] (1.000)
Step: 32999, Reward: [-468.628 -468.628 -468.628] [0.0000], Avg: [-490.206 -490.206 -490.206] (1.000)
Step: 33049, Reward: [-535.198 -535.198 -535.198] [0.0000], Avg: [-490.274 -490.274 -490.274] (1.000)
Step: 33099, Reward: [-813.989 -813.989 -813.989] [0.0000], Avg: [-490.763 -490.763 -490.763] (1.000)
Step: 33149, Reward: [-430.256 -430.256 -430.256] [0.0000], Avg: [-490.671 -490.671 -490.671] (1.000)
Step: 33199, Reward: [-487.384 -487.384 -487.384] [0.0000], Avg: [-490.667 -490.667 -490.667] (1.000)
Step: 33249, Reward: [-513.863 -513.863 -513.863] [0.0000], Avg: [-490.701 -490.701 -490.701] (1.000)
Step: 33299, Reward: [-429.459 -429.459 -429.459] [0.0000], Avg: [-490.609 -490.609 -490.609] (1.000)
Step: 33349, Reward: [-486.041 -486.041 -486.041] [0.0000], Avg: [-490.603 -490.603 -490.603] (1.000)
Step: 33399, Reward: [-547.113 -547.113 -547.113] [0.0000], Avg: [-490.687 -490.687 -490.687] (1.000)
Step: 33449, Reward: [-455.458 -455.458 -455.458] [0.0000], Avg: [-490.635 -490.635 -490.635] (1.000)
Step: 33499, Reward: [-483.691 -483.691 -483.691] [0.0000], Avg: [-490.624 -490.624 -490.624] (1.000)
Step: 33549, Reward: [-449.803 -449.803 -449.803] [0.0000], Avg: [-490.563 -490.563 -490.563] (1.000)
Step: 33599, Reward: [-551.043 -551.043 -551.043] [0.0000], Avg: [-490.653 -490.653 -490.653] (1.000)
Step: 33649, Reward: [-416.669 -416.669 -416.669] [0.0000], Avg: [-490.543 -490.543 -490.543] (1.000)
Step: 33699, Reward: [-631.845 -631.845 -631.845] [0.0000], Avg: [-490.753 -490.753 -490.753] (1.000)
Step: 33749, Reward: [-427.736 -427.736 -427.736] [0.0000], Avg: [-490.66 -490.66 -490.66] (1.000)
Step: 33799, Reward: [-577.461 -577.461 -577.461] [0.0000], Avg: [-490.788 -490.788 -490.788] (1.000)
Step: 33849, Reward: [-443.511 -443.511 -443.511] [0.0000], Avg: [-490.718 -490.718 -490.718] (1.000)
Step: 33899, Reward: [-473.15 -473.15 -473.15] [0.0000], Avg: [-490.692 -490.692 -490.692] (1.000)
Step: 33949, Reward: [-463.841 -463.841 -463.841] [0.0000], Avg: [-490.653 -490.653 -490.653] (1.000)
Step: 33999, Reward: [-368.095 -368.095 -368.095] [0.0000], Avg: [-490.473 -490.473 -490.473] (1.000)
Step: 34049, Reward: [-628.59 -628.59 -628.59] [0.0000], Avg: [-490.675 -490.675 -490.675] (1.000)
Step: 34099, Reward: [-446.972 -446.972 -446.972] [0.0000], Avg: [-490.611 -490.611 -490.611] (1.000)
Step: 34149, Reward: [-739.194 -739.194 -739.194] [0.0000], Avg: [-490.975 -490.975 -490.975] (1.000)
Step: 34199, Reward: [-337.414 -337.414 -337.414] [0.0000], Avg: [-490.751 -490.751 -490.751] (1.000)
Step: 34249, Reward: [-372.038 -372.038 -372.038] [0.0000], Avg: [-490.577 -490.577 -490.577] (1.000)
Step: 34299, Reward: [-622.37 -622.37 -622.37] [0.0000], Avg: [-490.77 -490.77 -490.77] (1.000)
Step: 34349, Reward: [-456.22 -456.22 -456.22] [0.0000], Avg: [-490.719 -490.719 -490.719] (1.000)
Step: 34399, Reward: [-391.116 -391.116 -391.116] [0.0000], Avg: [-490.575 -490.575 -490.575] (1.000)
Step: 34449, Reward: [-356.193 -356.193 -356.193] [0.0000], Avg: [-490.379 -490.379 -490.379] (1.000)
Step: 34499, Reward: [-358.464 -358.464 -358.464] [0.0000], Avg: [-490.188 -490.188 -490.188] (1.000)
Step: 34549, Reward: [-432.472 -432.472 -432.472] [0.0000], Avg: [-490.105 -490.105 -490.105] (1.000)
Step: 34599, Reward: [-450.762 -450.762 -450.762] [0.0000], Avg: [-490.048 -490.048 -490.048] (1.000)
Step: 34649, Reward: [-825.977 -825.977 -825.977] [0.0000], Avg: [-490.533 -490.533 -490.533] (1.000)
Step: 34699, Reward: [-499.814 -499.814 -499.814] [0.0000], Avg: [-490.546 -490.546 -490.546] (1.000)
Step: 34749, Reward: [-529.699 -529.699 -529.699] [0.0000], Avg: [-490.602 -490.602 -490.602] (1.000)
Step: 34799, Reward: [-476.207 -476.207 -476.207] [0.0000], Avg: [-490.582 -490.582 -490.582] (1.000)
Step: 34849, Reward: [-612.401 -612.401 -612.401] [0.0000], Avg: [-490.756 -490.756 -490.756] (1.000)
Step: 34899, Reward: [-511.486 -511.486 -511.486] [0.0000], Avg: [-490.786 -490.786 -490.786] (1.000)
Step: 34949, Reward: [-480.815 -480.815 -480.815] [0.0000], Avg: [-490.772 -490.772 -490.772] (1.000)
Step: 34999, Reward: [-434.289 -434.289 -434.289] [0.0000], Avg: [-490.691 -490.691 -490.691] (1.000)
Step: 35049, Reward: [-434.009 -434.009 -434.009] [0.0000], Avg: [-490.61 -490.61 -490.61] (1.000)
Step: 35099, Reward: [-408.561 -408.561 -408.561] [0.0000], Avg: [-490.493 -490.493 -490.493] (1.000)
Step: 35149, Reward: [-655.771 -655.771 -655.771] [0.0000], Avg: [-490.729 -490.729 -490.729] (1.000)
Step: 35199, Reward: [-595.255 -595.255 -595.255] [0.0000], Avg: [-490.877 -490.877 -490.877] (1.000)
Step: 35249, Reward: [-439.533 -439.533 -439.533] [0.0000], Avg: [-490.804 -490.804 -490.804] (1.000)
Step: 35299, Reward: [-604.467 -604.467 -604.467] [0.0000], Avg: [-490.965 -490.965 -490.965] (1.000)
Step: 35349, Reward: [-409.81 -409.81 -409.81] [0.0000], Avg: [-490.85 -490.85 -490.85] (1.000)
Step: 35399, Reward: [-412.505 -412.505 -412.505] [0.0000], Avg: [-490.74 -490.74 -490.74] (1.000)
Step: 35449, Reward: [-371.702 -371.702 -371.702] [0.0000], Avg: [-490.572 -490.572 -490.572] (1.000)
Step: 35499, Reward: [-463.034 -463.034 -463.034] [0.0000], Avg: [-490.533 -490.533 -490.533] (1.000)
Step: 35549, Reward: [-302.245 -302.245 -302.245] [0.0000], Avg: [-490.268 -490.268 -490.268] (1.000)
Step: 35599, Reward: [-511.753 -511.753 -511.753] [0.0000], Avg: [-490.298 -490.298 -490.298] (1.000)
Step: 35649, Reward: [-409.495 -409.495 -409.495] [0.0000], Avg: [-490.185 -490.185 -490.185] (1.000)
Step: 35699, Reward: [-807.158 -807.158 -807.158] [0.0000], Avg: [-490.629 -490.629 -490.629] (1.000)
Step: 35749, Reward: [-675.426 -675.426 -675.426] [0.0000], Avg: [-490.888 -490.888 -490.888] (1.000)
Step: 35799, Reward: [-318.152 -318.152 -318.152] [0.0000], Avg: [-490.646 -490.646 -490.646] (1.000)
Step: 35849, Reward: [-481.616 -481.616 -481.616] [0.0000], Avg: [-490.634 -490.634 -490.634] (1.000)
Step: 35899, Reward: [-508.812 -508.812 -508.812] [0.0000], Avg: [-490.659 -490.659 -490.659] (1.000)
Step: 35949, Reward: [-482.772 -482.772 -482.772] [0.0000], Avg: [-490.648 -490.648 -490.648] (1.000)
Step: 35999, Reward: [-474.84 -474.84 -474.84] [0.0000], Avg: [-490.626 -490.626 -490.626] (1.000)
Step: 36049, Reward: [-393.656 -393.656 -393.656] [0.0000], Avg: [-490.492 -490.492 -490.492] (1.000)
Step: 36099, Reward: [-474.074 -474.074 -474.074] [0.0000], Avg: [-490.469 -490.469 -490.469] (1.000)
Step: 36149, Reward: [-395.965 -395.965 -395.965] [0.0000], Avg: [-490.338 -490.338 -490.338] (1.000)
Step: 36199, Reward: [-459.165 -459.165 -459.165] [0.0000], Avg: [-490.295 -490.295 -490.295] (1.000)
Step: 36249, Reward: [-452.581 -452.581 -452.581] [0.0000], Avg: [-490.243 -490.243 -490.243] (1.000)
Step: 36299, Reward: [-440.159 -440.159 -440.159] [0.0000], Avg: [-490.174 -490.174 -490.174] (1.000)
Step: 36349, Reward: [-418.622 -418.622 -418.622] [0.0000], Avg: [-490.076 -490.076 -490.076] (1.000)
Step: 36399, Reward: [-341.663 -341.663 -341.663] [0.0000], Avg: [-489.872 -489.872 -489.872] (1.000)
Step: 36449, Reward: [-365.009 -365.009 -365.009] [0.0000], Avg: [-489.701 -489.701 -489.701] (1.000)
Step: 36499, Reward: [-440.14 -440.14 -440.14] [0.0000], Avg: [-489.633 -489.633 -489.633] (1.000)
Step: 36549, Reward: [-432.715 -432.715 -432.715] [0.0000], Avg: [-489.555 -489.555 -489.555] (1.000)
Step: 36599, Reward: [-445.327 -445.327 -445.327] [0.0000], Avg: [-489.494 -489.494 -489.494] (1.000)
Step: 36649, Reward: [-438.369 -438.369 -438.369] [0.0000], Avg: [-489.425 -489.425 -489.425] (1.000)
Step: 36699, Reward: [-439.536 -439.536 -439.536] [0.0000], Avg: [-489.357 -489.357 -489.357] (1.000)
Step: 36749, Reward: [-437.799 -437.799 -437.799] [0.0000], Avg: [-489.286 -489.286 -489.286] (1.000)
Step: 36799, Reward: [-455.303 -455.303 -455.303] [0.0000], Avg: [-489.24 -489.24 -489.24] (1.000)
Step: 36849, Reward: [-548.565 -548.565 -548.565] [0.0000], Avg: [-489.321 -489.321 -489.321] (1.000)
Step: 36899, Reward: [-450.072 -450.072 -450.072] [0.0000], Avg: [-489.268 -489.268 -489.268] (1.000)
Step: 36949, Reward: [-788.068 -788.068 -788.068] [0.0000], Avg: [-489.672 -489.672 -489.672] (1.000)
Step: 36999, Reward: [-406.393 -406.393 -406.393] [0.0000], Avg: [-489.559 -489.559 -489.559] (1.000)
Step: 37049, Reward: [-455.296 -455.296 -455.296] [0.0000], Avg: [-489.513 -489.513 -489.513] (1.000)
Step: 37099, Reward: [-713.778 -713.778 -713.778] [0.0000], Avg: [-489.815 -489.815 -489.815] (1.000)
Step: 37149, Reward: [-412.258 -412.258 -412.258] [0.0000], Avg: [-489.711 -489.711 -489.711] (1.000)
Step: 37199, Reward: [-384.805 -384.805 -384.805] [0.0000], Avg: [-489.57 -489.57 -489.57] (1.000)
Step: 37249, Reward: [-511.127 -511.127 -511.127] [0.0000], Avg: [-489.599 -489.599 -489.599] (1.000)
Step: 37299, Reward: [-414.472 -414.472 -414.472] [0.0000], Avg: [-489.498 -489.498 -489.498] (1.000)
Step: 37349, Reward: [-418.434 -418.434 -418.434] [0.0000], Avg: [-489.403 -489.403 -489.403] (1.000)
Step: 37399, Reward: [-592.793 -592.793 -592.793] [0.0000], Avg: [-489.541 -489.541 -489.541] (1.000)
Step: 37449, Reward: [-431.105 -431.105 -431.105] [0.0000], Avg: [-489.463 -489.463 -489.463] (1.000)
Step: 37499, Reward: [-492.195 -492.195 -492.195] [0.0000], Avg: [-489.467 -489.467 -489.467] (1.000)
Step: 37549, Reward: [-617.006 -617.006 -617.006] [0.0000], Avg: [-489.637 -489.637 -489.637] (1.000)
Step: 37599, Reward: [-381.907 -381.907 -381.907] [0.0000], Avg: [-489.494 -489.494 -489.494] (1.000)
Step: 37649, Reward: [-403.611 -403.611 -403.611] [0.0000], Avg: [-489.379 -489.379 -489.379] (1.000)
Step: 37699, Reward: [-480.835 -480.835 -480.835] [0.0000], Avg: [-489.368 -489.368 -489.368] (1.000)
Step: 37749, Reward: [-612.431 -612.431 -612.431] [0.0000], Avg: [-489.531 -489.531 -489.531] (1.000)
Step: 37799, Reward: [-419.172 -419.172 -419.172] [0.0000], Avg: [-489.438 -489.438 -489.438] (1.000)
Step: 37849, Reward: [-319.382 -319.382 -319.382] [0.0000], Avg: [-489.213 -489.213 -489.213] (1.000)
Step: 37899, Reward: [-599.245 -599.245 -599.245] [0.0000], Avg: [-489.359 -489.359 -489.359] (1.000)
Step: 37949, Reward: [-511.898 -511.898 -511.898] [0.0000], Avg: [-489.388 -489.388 -489.388] (1.000)
Step: 37999, Reward: [-485.953 -485.953 -485.953] [0.0000], Avg: [-489.384 -489.384 -489.384] (1.000)
Step: 38049, Reward: [-512.204 -512.204 -512.204] [0.0000], Avg: [-489.414 -489.414 -489.414] (1.000)
Step: 38099, Reward: [-536.438 -536.438 -536.438] [0.0000], Avg: [-489.475 -489.475 -489.475] (1.000)
Step: 38149, Reward: [-586.471 -586.471 -586.471] [0.0000], Avg: [-489.603 -489.603 -489.603] (1.000)
Step: 38199, Reward: [-416.185 -416.185 -416.185] [0.0000], Avg: [-489.506 -489.506 -489.506] (1.000)
Step: 38249, Reward: [-461.355 -461.355 -461.355] [0.0000], Avg: [-489.47 -489.47 -489.47] (1.000)
Step: 38299, Reward: [-473.5 -473.5 -473.5] [0.0000], Avg: [-489.449 -489.449 -489.449] (1.000)
Step: 38349, Reward: [-518.22 -518.22 -518.22] [0.0000], Avg: [-489.486 -489.486 -489.486] (1.000)
Step: 38399, Reward: [-436.458 -436.458 -436.458] [0.0000], Avg: [-489.417 -489.417 -489.417] (1.000)
Step: 38449, Reward: [-460.475 -460.475 -460.475] [0.0000], Avg: [-489.38 -489.38 -489.38] (1.000)
Step: 38499, Reward: [-773.685 -773.685 -773.685] [0.0000], Avg: [-489.749 -489.749 -489.749] (1.000)
Step: 38549, Reward: [-387.494 -387.494 -387.494] [0.0000], Avg: [-489.616 -489.616 -489.616] (1.000)
Step: 38599, Reward: [-657.331 -657.331 -657.331] [0.0000], Avg: [-489.834 -489.834 -489.834] (1.000)
Step: 38649, Reward: [-465.841 -465.841 -465.841] [0.0000], Avg: [-489.802 -489.802 -489.802] (1.000)
Step: 38699, Reward: [-464.814 -464.814 -464.814] [0.0000], Avg: [-489.77 -489.77 -489.77] (1.000)
Step: 38749, Reward: [-407.771 -407.771 -407.771] [0.0000], Avg: [-489.664 -489.664 -489.664] (1.000)
Step: 38799, Reward: [-516.977 -516.977 -516.977] [0.0000], Avg: [-489.7 -489.7 -489.7] (1.000)
Step: 38849, Reward: [-429.058 -429.058 -429.058] [0.0000], Avg: [-489.622 -489.622 -489.622] (1.000)
Step: 38899, Reward: [-370.979 -370.979 -370.979] [0.0000], Avg: [-489.469 -489.469 -489.469] (1.000)
Step: 38949, Reward: [-503.022 -503.022 -503.022] [0.0000], Avg: [-489.486 -489.486 -489.486] (1.000)
Step: 38999, Reward: [-511.119 -511.119 -511.119] [0.0000], Avg: [-489.514 -489.514 -489.514] (1.000)
Step: 39049, Reward: [-392.704 -392.704 -392.704] [0.0000], Avg: [-489.39 -489.39 -489.39] (1.000)
Step: 39099, Reward: [-522.247 -522.247 -522.247] [0.0000], Avg: [-489.432 -489.432 -489.432] (1.000)
Step: 39149, Reward: [-368.58 -368.58 -368.58] [0.0000], Avg: [-489.278 -489.278 -489.278] (1.000)
Step: 39199, Reward: [-679.973 -679.973 -679.973] [0.0000], Avg: [-489.521 -489.521 -489.521] (1.000)
Step: 39249, Reward: [-423.316 -423.316 -423.316] [0.0000], Avg: [-489.437 -489.437 -489.437] (1.000)
Step: 39299, Reward: [-473.575 -473.575 -473.575] [0.0000], Avg: [-489.417 -489.417 -489.417] (1.000)
Step: 39349, Reward: [-506.116 -506.116 -506.116] [0.0000], Avg: [-489.438 -489.438 -489.438] (1.000)
Step: 39399, Reward: [-422.201 -422.201 -422.201] [0.0000], Avg: [-489.353 -489.353 -489.353] (1.000)
Step: 39449, Reward: [-413.945 -413.945 -413.945] [0.0000], Avg: [-489.257 -489.257 -489.257] (1.000)
Step: 39499, Reward: [-366.891 -366.891 -366.891] [0.0000], Avg: [-489.102 -489.102 -489.102] (1.000)
Step: 39549, Reward: [-488.823 -488.823 -488.823] [0.0000], Avg: [-489.102 -489.102 -489.102] (1.000)
Step: 39599, Reward: [-559.817 -559.817 -559.817] [0.0000], Avg: [-489.191 -489.191 -489.191] (1.000)
Step: 39649, Reward: [-350.263 -350.263 -350.263] [0.0000], Avg: [-489.016 -489.016 -489.016] (1.000)
Step: 39699, Reward: [-372.309 -372.309 -372.309] [0.0000], Avg: [-488.869 -488.869 -488.869] (1.000)
Step: 39749, Reward: [-465.604 -465.604 -465.604] [0.0000], Avg: [-488.84 -488.84 -488.84] (1.000)
Step: 39799, Reward: [-441.902 -441.902 -441.902] [0.0000], Avg: [-488.781 -488.781 -488.781] (1.000)
Step: 39849, Reward: [-706.789 -706.789 -706.789] [0.0000], Avg: [-489.054 -489.054 -489.054] (1.000)
Step: 39899, Reward: [-638.425 -638.425 -638.425] [0.0000], Avg: [-489.241 -489.241 -489.241] (1.000)
Step: 39949, Reward: [-599.015 -599.015 -599.015] [0.0000], Avg: [-489.379 -489.379 -489.379] (1.000)
Step: 39999, Reward: [-368.818 -368.818 -368.818] [0.0000], Avg: [-489.228 -489.228 -489.228] (1.000)
Step: 40049, Reward: [-573.608 -573.608 -573.608] [0.0000], Avg: [-489.333 -489.333 -489.333] (1.000)
Step: 40099, Reward: [-380.206 -380.206 -380.206] [0.0000], Avg: [-489.197 -489.197 -489.197] (1.000)
Step: 40149, Reward: [-498.964 -498.964 -498.964] [0.0000], Avg: [-489.209 -489.209 -489.209] (1.000)
Step: 40199, Reward: [-452.678 -452.678 -452.678] [0.0000], Avg: [-489.164 -489.164 -489.164] (1.000)
Step: 40249, Reward: [-365.618 -365.618 -365.618] [0.0000], Avg: [-489.01 -489.01 -489.01] (1.000)
Step: 40299, Reward: [-581.675 -581.675 -581.675] [0.0000], Avg: [-489.125 -489.125 -489.125] (1.000)
Step: 40349, Reward: [-557.839 -557.839 -557.839] [0.0000], Avg: [-489.211 -489.211 -489.211] (1.000)
Step: 40399, Reward: [-391.17 -391.17 -391.17] [0.0000], Avg: [-489.089 -489.089 -489.089] (1.000)
Step: 40449, Reward: [-616.78 -616.78 -616.78] [0.0000], Avg: [-489.247 -489.247 -489.247] (1.000)
Step: 40499, Reward: [-485.258 -485.258 -485.258] [0.0000], Avg: [-489.242 -489.242 -489.242] (1.000)
Step: 40549, Reward: [-592.102 -592.102 -592.102] [0.0000], Avg: [-489.369 -489.369 -489.369] (1.000)
Step: 40599, Reward: [-496.39 -496.39 -496.39] [0.0000], Avg: [-489.378 -489.378 -489.378] (1.000)
Step: 40649, Reward: [-598.76 -598.76 -598.76] [0.0000], Avg: [-489.512 -489.512 -489.512] (1.000)
Step: 40699, Reward: [-479.735 -479.735 -479.735] [0.0000], Avg: [-489.5 -489.5 -489.5] (1.000)
Step: 40749, Reward: [-548.377 -548.377 -548.377] [0.0000], Avg: [-489.572 -489.572 -489.572] (1.000)
Step: 40799, Reward: [-444.321 -444.321 -444.321] [0.0000], Avg: [-489.517 -489.517 -489.517] (1.000)
Step: 40849, Reward: [-770.238 -770.238 -770.238] [0.0000], Avg: [-489.861 -489.861 -489.861] (1.000)
Step: 40899, Reward: [-663. -663. -663.] [0.0000], Avg: [-490.072 -490.072 -490.072] (1.000)
Step: 40949, Reward: [-578.63 -578.63 -578.63] [0.0000], Avg: [-490.18 -490.18 -490.18] (1.000)
Step: 40999, Reward: [-589.107 -589.107 -589.107] [0.0000], Avg: [-490.301 -490.301 -490.301] (1.000)
Step: 41049, Reward: [-501.099 -501.099 -501.099] [0.0000], Avg: [-490.314 -490.314 -490.314] (1.000)
Step: 41099, Reward: [-381.725 -381.725 -381.725] [0.0000], Avg: [-490.182 -490.182 -490.182] (1.000)
Step: 41149, Reward: [-424.212 -424.212 -424.212] [0.0000], Avg: [-490.102 -490.102 -490.102] (1.000)
Step: 41199, Reward: [-498.89 -498.89 -498.89] [0.0000], Avg: [-490.113 -490.113 -490.113] (1.000)
Step: 41249, Reward: [-450.206 -450.206 -450.206] [0.0000], Avg: [-490.064 -490.064 -490.064] (1.000)
Step: 41299, Reward: [-480.682 -480.682 -480.682] [0.0000], Avg: [-490.053 -490.053 -490.053] (1.000)
Step: 41349, Reward: [-474.081 -474.081 -474.081] [0.0000], Avg: [-490.034 -490.034 -490.034] (1.000)
Step: 41399, Reward: [-777.793 -777.793 -777.793] [0.0000], Avg: [-490.381 -490.381 -490.381] (1.000)
Step: 41449, Reward: [-523.889 -523.889 -523.889] [0.0000], Avg: [-490.421 -490.421 -490.421] (1.000)
Step: 41499, Reward: [-550.803 -550.803 -550.803] [0.0000], Avg: [-490.494 -490.494 -490.494] (1.000)
Step: 41549, Reward: [-432.879 -432.879 -432.879] [0.0000], Avg: [-490.425 -490.425 -490.425] (1.000)
Step: 41599, Reward: [-538.209 -538.209 -538.209] [0.0000], Avg: [-490.482 -490.482 -490.482] (1.000)
Step: 41649, Reward: [-410.207 -410.207 -410.207] [0.0000], Avg: [-490.386 -490.386 -490.386] (1.000)
Step: 41699, Reward: [-625.534 -625.534 -625.534] [0.0000], Avg: [-490.548 -490.548 -490.548] (1.000)
Step: 41749, Reward: [-410.424 -410.424 -410.424] [0.0000], Avg: [-490.452 -490.452 -490.452] (1.000)
Step: 41799, Reward: [-467.488 -467.488 -467.488] [0.0000], Avg: [-490.425 -490.425 -490.425] (1.000)
Step: 41849, Reward: [-451.732 -451.732 -451.732] [0.0000], Avg: [-490.378 -490.378 -490.378] (1.000)
Step: 41899, Reward: [-497.814 -497.814 -497.814] [0.0000], Avg: [-490.387 -490.387 -490.387] (1.000)
Step: 41949, Reward: [-394.57 -394.57 -394.57] [0.0000], Avg: [-490.273 -490.273 -490.273] (1.000)
Step: 41999, Reward: [-317.349 -317.349 -317.349] [0.0000], Avg: [-490.067 -490.067 -490.067] (1.000)
Step: 42049, Reward: [-526.486 -526.486 -526.486] [0.0000], Avg: [-490.11 -490.11 -490.11] (1.000)
Step: 42099, Reward: [-556.394 -556.394 -556.394] [0.0000], Avg: [-490.189 -490.189 -490.189] (1.000)
Step: 42149, Reward: [-466.704 -466.704 -466.704] [0.0000], Avg: [-490.161 -490.161 -490.161] (1.000)
Step: 42199, Reward: [-561.888 -561.888 -561.888] [0.0000], Avg: [-490.246 -490.246 -490.246] (1.000)
Step: 42249, Reward: [-494.723 -494.723 -494.723] [0.0000], Avg: [-490.252 -490.252 -490.252] (1.000)
Step: 42299, Reward: [-486.345 -486.345 -486.345] [0.0000], Avg: [-490.247 -490.247 -490.247] (1.000)
Step: 42349, Reward: [-537.602 -537.602 -537.602] [0.0000], Avg: [-490.303 -490.303 -490.303] (1.000)
Step: 42399, Reward: [-458.802 -458.802 -458.802] [0.0000], Avg: [-490.266 -490.266 -490.266] (1.000)
Step: 42449, Reward: [-582.459 -582.459 -582.459] [0.0000], Avg: [-490.374 -490.374 -490.374] (1.000)
Step: 42499, Reward: [-506.161 -506.161 -506.161] [0.0000], Avg: [-490.393 -490.393 -490.393] (1.000)
Step: 42549, Reward: [-637.999 -637.999 -637.999] [0.0000], Avg: [-490.566 -490.566 -490.566] (1.000)
Step: 42599, Reward: [-432.819 -432.819 -432.819] [0.0000], Avg: [-490.499 -490.499 -490.499] (1.000)
Step: 42649, Reward: [-460.266 -460.266 -460.266] [0.0000], Avg: [-490.463 -490.463 -490.463] (1.000)
Step: 42699, Reward: [-431.187 -431.187 -431.187] [0.0000], Avg: [-490.394 -490.394 -490.394] (1.000)
Step: 42749, Reward: [-422.116 -422.116 -422.116] [0.0000], Avg: [-490.314 -490.314 -490.314] (1.000)
Step: 42799, Reward: [-721.426 -721.426 -721.426] [0.0000], Avg: [-490.584 -490.584 -490.584] (1.000)
Step: 42849, Reward: [-579.008 -579.008 -579.008] [0.0000], Avg: [-490.687 -490.687 -490.687] (1.000)
Step: 42899, Reward: [-417.335 -417.335 -417.335] [0.0000], Avg: [-490.602 -490.602 -490.602] (1.000)
Step: 42949, Reward: [-529.155 -529.155 -529.155] [0.0000], Avg: [-490.646 -490.646 -490.646] (1.000)
Step: 42999, Reward: [-377.122 -377.122 -377.122] [0.0000], Avg: [-490.514 -490.514 -490.514] (1.000)
Step: 43049, Reward: [-408.879 -408.879 -408.879] [0.0000], Avg: [-490.42 -490.42 -490.42] (1.000)
Step: 43099, Reward: [-550.536 -550.536 -550.536] [0.0000], Avg: [-490.489 -490.489 -490.489] (1.000)
Step: 43149, Reward: [-458.903 -458.903 -458.903] [0.0000], Avg: [-490.453 -490.453 -490.453] (1.000)
Step: 43199, Reward: [-532.434 -532.434 -532.434] [0.0000], Avg: [-490.501 -490.501 -490.501] (1.000)
Step: 43249, Reward: [-501.917 -501.917 -501.917] [0.0000], Avg: [-490.515 -490.515 -490.515] (1.000)
Step: 43299, Reward: [-610.974 -610.974 -610.974] [0.0000], Avg: [-490.654 -490.654 -490.654] (1.000)
Step: 43349, Reward: [-530.783 -530.783 -530.783] [0.0000], Avg: [-490.7 -490.7 -490.7] (1.000)
Step: 43399, Reward: [-403.231 -403.231 -403.231] [0.0000], Avg: [-490.599 -490.599 -490.599] (1.000)
Step: 43449, Reward: [-487.483 -487.483 -487.483] [0.0000], Avg: [-490.596 -490.596 -490.596] (1.000)
Step: 43499, Reward: [-466.19 -466.19 -466.19] [0.0000], Avg: [-490.568 -490.568 -490.568] (1.000)
Step: 43549, Reward: [-409.499 -409.499 -409.499] [0.0000], Avg: [-490.474 -490.474 -490.474] (1.000)
Step: 43599, Reward: [-478.943 -478.943 -478.943] [0.0000], Avg: [-490.461 -490.461 -490.461] (1.000)
Step: 43649, Reward: [-718.081 -718.081 -718.081] [0.0000], Avg: [-490.722 -490.722 -490.722] (1.000)
Step: 43699, Reward: [-544.723 -544.723 -544.723] [0.0000], Avg: [-490.784 -490.784 -490.784] (1.000)
Step: 43749, Reward: [-581.364 -581.364 -581.364] [0.0000], Avg: [-490.887 -490.887 -490.887] (1.000)
Step: 43799, Reward: [-389.805 -389.805 -389.805] [0.0000], Avg: [-490.772 -490.772 -490.772] (1.000)
Step: 43849, Reward: [-478.66 -478.66 -478.66] [0.0000], Avg: [-490.758 -490.758 -490.758] (1.000)
Step: 43899, Reward: [-345.534 -345.534 -345.534] [0.0000], Avg: [-490.593 -490.593 -490.593] (1.000)
Step: 43949, Reward: [-505.087 -505.087 -505.087] [0.0000], Avg: [-490.609 -490.609 -490.609] (1.000)
Step: 43999, Reward: [-634.213 -634.213 -634.213] [0.0000], Avg: [-490.772 -490.772 -490.772] (1.000)
Step: 44049, Reward: [-495.646 -495.646 -495.646] [0.0000], Avg: [-490.778 -490.778 -490.778] (1.000)
Step: 44099, Reward: [-461.09 -461.09 -461.09] [0.0000], Avg: [-490.744 -490.744 -490.744] (1.000)
Step: 44149, Reward: [-372.815 -372.815 -372.815] [0.0000], Avg: [-490.611 -490.611 -490.611] (1.000)
Step: 44199, Reward: [-452.04 -452.04 -452.04] [0.0000], Avg: [-490.567 -490.567 -490.567] (1.000)
Step: 44249, Reward: [-445.132 -445.132 -445.132] [0.0000], Avg: [-490.516 -490.516 -490.516] (1.000)
Step: 44299, Reward: [-389.975 -389.975 -389.975] [0.0000], Avg: [-490.402 -490.402 -490.402] (1.000)
Step: 44349, Reward: [-458.759 -458.759 -458.759] [0.0000], Avg: [-490.367 -490.367 -490.367] (1.000)
Step: 44399, Reward: [-483.32 -483.32 -483.32] [0.0000], Avg: [-490.359 -490.359 -490.359] (1.000)
Step: 44449, Reward: [-439.391 -439.391 -439.391] [0.0000], Avg: [-490.301 -490.301 -490.301] (1.000)
Step: 44499, Reward: [-460.263 -460.263 -460.263] [0.0000], Avg: [-490.268 -490.268 -490.268] (1.000)
Step: 44549, Reward: [-461.967 -461.967 -461.967] [0.0000], Avg: [-490.236 -490.236 -490.236] (1.000)
Step: 44599, Reward: [-593.65 -593.65 -593.65] [0.0000], Avg: [-490.352 -490.352 -490.352] (1.000)
Step: 44649, Reward: [-492.508 -492.508 -492.508] [0.0000], Avg: [-490.354 -490.354 -490.354] (1.000)
Step: 44699, Reward: [-489.824 -489.824 -489.824] [0.0000], Avg: [-490.353 -490.353 -490.353] (1.000)
Step: 44749, Reward: [-552.035 -552.035 -552.035] [0.0000], Avg: [-490.422 -490.422 -490.422] (1.000)
Step: 44799, Reward: [-426.196 -426.196 -426.196] [0.0000], Avg: [-490.351 -490.351 -490.351] (1.000)
Step: 44849, Reward: [-423.814 -423.814 -423.814] [0.0000], Avg: [-490.277 -490.277 -490.277] (1.000)
Step: 44899, Reward: [-464.607 -464.607 -464.607] [0.0000], Avg: [-490.248 -490.248 -490.248] (1.000)
Step: 44949, Reward: [-597.147 -597.147 -597.147] [0.0000], Avg: [-490.367 -490.367 -490.367] (1.000)
Step: 44999, Reward: [-659.025 -659.025 -659.025] [0.0000], Avg: [-490.554 -490.554 -490.554] (1.000)
Step: 45049, Reward: [-439.836 -439.836 -439.836] [0.0000], Avg: [-490.498 -490.498 -490.498] (1.000)
Step: 45099, Reward: [-393.562 -393.562 -393.562] [0.0000], Avg: [-490.391 -490.391 -490.391] (1.000)
Step: 45149, Reward: [-505.083 -505.083 -505.083] [0.0000], Avg: [-490.407 -490.407 -490.407] (1.000)
Step: 45199, Reward: [-511.151 -511.151 -511.151] [0.0000], Avg: [-490.43 -490.43 -490.43] (1.000)
Step: 45249, Reward: [-429.776 -429.776 -429.776] [0.0000], Avg: [-490.363 -490.363 -490.363] (1.000)
Step: 45299, Reward: [-356.945 -356.945 -356.945] [0.0000], Avg: [-490.215 -490.215 -490.215] (1.000)
Step: 45349, Reward: [-545.018 -545.018 -545.018] [0.0000], Avg: [-490.276 -490.276 -490.276] (1.000)
Step: 45399, Reward: [-587.711 -587.711 -587.711] [0.0000], Avg: [-490.383 -490.383 -490.383] (1.000)
Step: 45449, Reward: [-483.035 -483.035 -483.035] [0.0000], Avg: [-490.375 -490.375 -490.375] (1.000)
Step: 45499, Reward: [-480.825 -480.825 -480.825] [0.0000], Avg: [-490.365 -490.365 -490.365] (1.000)
Step: 45549, Reward: [-529.007 -529.007 -529.007] [0.0000], Avg: [-490.407 -490.407 -490.407] (1.000)
Step: 45599, Reward: [-348.308 -348.308 -348.308] [0.0000], Avg: [-490.251 -490.251 -490.251] (1.000)
Step: 45649, Reward: [-555.974 -555.974 -555.974] [0.0000], Avg: [-490.323 -490.323 -490.323] (1.000)
Step: 45699, Reward: [-451.952 -451.952 -451.952] [0.0000], Avg: [-490.281 -490.281 -490.281] (1.000)
Step: 45749, Reward: [-398.936 -398.936 -398.936] [0.0000], Avg: [-490.181 -490.181 -490.181] (1.000)
Step: 45799, Reward: [-515.312 -515.312 -515.312] [0.0000], Avg: [-490.209 -490.209 -490.209] (1.000)
Step: 45849, Reward: [-440.839 -440.839 -440.839] [0.0000], Avg: [-490.155 -490.155 -490.155] (1.000)
Step: 45899, Reward: [-490.846 -490.846 -490.846] [0.0000], Avg: [-490.156 -490.156 -490.156] (1.000)
Step: 45949, Reward: [-460.235 -460.235 -460.235] [0.0000], Avg: [-490.123 -490.123 -490.123] (1.000)
Step: 45999, Reward: [-473.032 -473.032 -473.032] [0.0000], Avg: [-490.105 -490.105 -490.105] (1.000)
Step: 46049, Reward: [-610.444 -610.444 -610.444] [0.0000], Avg: [-490.235 -490.235 -490.235] (1.000)
Step: 46099, Reward: [-544.14 -544.14 -544.14] [0.0000], Avg: [-490.294 -490.294 -490.294] (1.000)
Step: 46149, Reward: [-422.387 -422.387 -422.387] [0.0000], Avg: [-490.22 -490.22 -490.22] (1.000)
Step: 46199, Reward: [-476.341 -476.341 -476.341] [0.0000], Avg: [-490.205 -490.205 -490.205] (1.000)
Step: 46249, Reward: [-664.781 -664.781 -664.781] [0.0000], Avg: [-490.394 -490.394 -490.394] (1.000)
Step: 46299, Reward: [-722.289 -722.289 -722.289] [0.0000], Avg: [-490.644 -490.644 -490.644] (1.000)
Step: 46349, Reward: [-499.158 -499.158 -499.158] [0.0000], Avg: [-490.653 -490.653 -490.653] (1.000)
Step: 46399, Reward: [-487.238 -487.238 -487.238] [0.0000], Avg: [-490.65 -490.65 -490.65] (1.000)
Step: 46449, Reward: [-446.895 -446.895 -446.895] [0.0000], Avg: [-490.603 -490.603 -490.603] (1.000)
Step: 46499, Reward: [-646.818 -646.818 -646.818] [0.0000], Avg: [-490.771 -490.771 -490.771] (1.000)
Step: 46549, Reward: [-381.846 -381.846 -381.846] [0.0000], Avg: [-490.654 -490.654 -490.654] (1.000)
Step: 46599, Reward: [-516.478 -516.478 -516.478] [0.0000], Avg: [-490.681 -490.681 -490.681] (1.000)
Step: 46649, Reward: [-403.088 -403.088 -403.088] [0.0000], Avg: [-490.588 -490.588 -490.588] (1.000)
Step: 46699, Reward: [-409.849 -409.849 -409.849] [0.0000], Avg: [-490.501 -490.501 -490.501] (1.000)
Step: 46749, Reward: [-517.17 -517.17 -517.17] [0.0000], Avg: [-490.53 -490.53 -490.53] (1.000)
Step: 46799, Reward: [-454.367 -454.367 -454.367] [0.0000], Avg: [-490.491 -490.491 -490.491] (1.000)
Step: 46849, Reward: [-575.873 -575.873 -575.873] [0.0000], Avg: [-490.582 -490.582 -490.582] (1.000)
Step: 46899, Reward: [-444.152 -444.152 -444.152] [0.0000], Avg: [-490.533 -490.533 -490.533] (1.000)
Step: 46949, Reward: [-475.972 -475.972 -475.972] [0.0000], Avg: [-490.517 -490.517 -490.517] (1.000)
Step: 46999, Reward: [-571.196 -571.196 -571.196] [0.0000], Avg: [-490.603 -490.603 -490.603] (1.000)
Step: 47049, Reward: [-464.567 -464.567 -464.567] [0.0000], Avg: [-490.575 -490.575 -490.575] (1.000)
Step: 47099, Reward: [-413.697 -413.697 -413.697] [0.0000], Avg: [-490.494 -490.494 -490.494] (1.000)
Step: 47149, Reward: [-834.828 -834.828 -834.828] [0.0000], Avg: [-490.859 -490.859 -490.859] (1.000)
Step: 47199, Reward: [-457.471 -457.471 -457.471] [0.0000], Avg: [-490.823 -490.823 -490.823] (1.000)
Step: 47249, Reward: [-508.307 -508.307 -508.307] [0.0000], Avg: [-490.842 -490.842 -490.842] (1.000)
Step: 47299, Reward: [-471.123 -471.123 -471.123] [0.0000], Avg: [-490.821 -490.821 -490.821] (1.000)
Step: 47349, Reward: [-479.61 -479.61 -479.61] [0.0000], Avg: [-490.809 -490.809 -490.809] (1.000)
Step: 47399, Reward: [-396.199 -396.199 -396.199] [0.0000], Avg: [-490.709 -490.709 -490.709] (1.000)
Step: 47449, Reward: [-516.499 -516.499 -516.499] [0.0000], Avg: [-490.737 -490.737 -490.737] (1.000)
Step: 47499, Reward: [-569.838 -569.838 -569.838] [0.0000], Avg: [-490.82 -490.82 -490.82] (1.000)
Step: 47549, Reward: [-520.564 -520.564 -520.564] [0.0000], Avg: [-490.851 -490.851 -490.851] (1.000)
Step: 47599, Reward: [-650.286 -650.286 -650.286] [0.0000], Avg: [-491.019 -491.019 -491.019] (1.000)
Step: 47649, Reward: [-545.366 -545.366 -545.366] [0.0000], Avg: [-491.076 -491.076 -491.076] (1.000)
Step: 47699, Reward: [-394.106 -394.106 -394.106] [0.0000], Avg: [-490.974 -490.974 -490.974] (1.000)
Step: 47749, Reward: [-528.819 -528.819 -528.819] [0.0000], Avg: [-491.014 -491.014 -491.014] (1.000)
Step: 47799, Reward: [-747.768 -747.768 -747.768] [0.0000], Avg: [-491.282 -491.282 -491.282] (1.000)
Step: 47849, Reward: [-457.593 -457.593 -457.593] [0.0000], Avg: [-491.247 -491.247 -491.247] (1.000)
Step: 47899, Reward: [-476.887 -476.887 -476.887] [0.0000], Avg: [-491.232 -491.232 -491.232] (1.000)
Step: 47949, Reward: [-550.187 -550.187 -550.187] [0.0000], Avg: [-491.293 -491.293 -491.293] (1.000)
Step: 47999, Reward: [-478.307 -478.307 -478.307] [0.0000], Avg: [-491.28 -491.28 -491.28] (1.000)
Step: 48049, Reward: [-556.99 -556.99 -556.99] [0.0000], Avg: [-491.348 -491.348 -491.348] (1.000)
Step: 48099, Reward: [-377.996 -377.996 -377.996] [0.0000], Avg: [-491.23 -491.23 -491.23] (1.000)
Step: 48149, Reward: [-646.637 -646.637 -646.637] [0.0000], Avg: [-491.392 -491.392 -491.392] (1.000)
Step: 48199, Reward: [-599.37 -599.37 -599.37] [0.0000], Avg: [-491.504 -491.504 -491.504] (1.000)
Step: 48249, Reward: [-488.863 -488.863 -488.863] [0.0000], Avg: [-491.501 -491.501 -491.501] (1.000)
Step: 48299, Reward: [-423.961 -423.961 -423.961] [0.0000], Avg: [-491.431 -491.431 -491.431] (1.000)
Step: 48349, Reward: [-488.497 -488.497 -488.497] [0.0000], Avg: [-491.428 -491.428 -491.428] (1.000)
Step: 48399, Reward: [-462.275 -462.275 -462.275] [0.0000], Avg: [-491.398 -491.398 -491.398] (1.000)
Step: 48449, Reward: [-430.44 -430.44 -430.44] [0.0000], Avg: [-491.335 -491.335 -491.335] (1.000)
Step: 48499, Reward: [-557.79 -557.79 -557.79] [0.0000], Avg: [-491.404 -491.404 -491.404] (1.000)
Step: 48549, Reward: [-377.44 -377.44 -377.44] [0.0000], Avg: [-491.286 -491.286 -491.286] (1.000)
Step: 48599, Reward: [-581.858 -581.858 -581.858] [0.0000], Avg: [-491.379 -491.379 -491.379] (1.000)
Step: 48649, Reward: [-357.458 -357.458 -357.458] [0.0000], Avg: [-491.242 -491.242 -491.242] (1.000)
Step: 48699, Reward: [-310.299 -310.299 -310.299] [0.0000], Avg: [-491.056 -491.056 -491.056] (1.000)
Step: 48749, Reward: [-392.717 -392.717 -392.717] [0.0000], Avg: [-490.955 -490.955 -490.955] (1.000)
Step: 48799, Reward: [-420.638 -420.638 -420.638] [0.0000], Avg: [-490.883 -490.883 -490.883] (1.000)
Step: 48849, Reward: [-431.968 -431.968 -431.968] [0.0000], Avg: [-490.823 -490.823 -490.823] (1.000)
Step: 48899, Reward: [-505.989 -505.989 -505.989] [0.0000], Avg: [-490.838 -490.838 -490.838] (1.000)
Step: 48949, Reward: [-629.541 -629.541 -629.541] [0.0000], Avg: [-490.98 -490.98 -490.98] (1.000)
Step: 48999, Reward: [-557.854 -557.854 -557.854] [0.0000], Avg: [-491.048 -491.048 -491.048] (1.000)
Step: 49049, Reward: [-639.279 -639.279 -639.279] [0.0000], Avg: [-491.199 -491.199 -491.199] (1.000)
Step: 49099, Reward: [-432.975 -432.975 -432.975] [0.0000], Avg: [-491.14 -491.14 -491.14] (1.000)
Step: 49149, Reward: [-659.008 -659.008 -659.008] [0.0000], Avg: [-491.311 -491.311 -491.311] (1.000)
Step: 49199, Reward: [-782.693 -782.693 -782.693] [0.0000], Avg: [-491.607 -491.607 -491.607] (1.000)
Step: 49249, Reward: [-522.665 -522.665 -522.665] [0.0000], Avg: [-491.639 -491.639 -491.639] (1.000)
Step: 49299, Reward: [-375.622 -375.622 -375.622] [0.0000], Avg: [-491.521 -491.521 -491.521] (1.000)
Step: 49349, Reward: [-566.937 -566.937 -566.937] [0.0000], Avg: [-491.597 -491.597 -491.597] (1.000)
Step: 49399, Reward: [-451.589 -451.589 -451.589] [0.0000], Avg: [-491.557 -491.557 -491.557] (1.000)
Step: 49449, Reward: [-546.543 -546.543 -546.543] [0.0000], Avg: [-491.612 -491.612 -491.612] (1.000)
Step: 49499, Reward: [-374.504 -374.504 -374.504] [0.0000], Avg: [-491.494 -491.494 -491.494] (1.000)
Step: 49549, Reward: [-549.015 -549.015 -549.015] [0.0000], Avg: [-491.552 -491.552 -491.552] (1.000)
Step: 49599, Reward: [-437.705 -437.705 -437.705] [0.0000], Avg: [-491.498 -491.498 -491.498] (1.000)
Step: 49649, Reward: [-565.92 -565.92 -565.92] [0.0000], Avg: [-491.573 -491.573 -491.573] (1.000)
Step: 49699, Reward: [-528.385 -528.385 -528.385] [0.0000], Avg: [-491.61 -491.61 -491.61] (1.000)
Step: 49749, Reward: [-392.807 -392.807 -392.807] [0.0000], Avg: [-491.511 -491.511 -491.511] (1.000)
Step: 49799, Reward: [-524.882 -524.882 -524.882] [0.0000], Avg: [-491.544 -491.544 -491.544] (1.000)
Step: 49849, Reward: [-548.16 -548.16 -548.16] [0.0000], Avg: [-491.601 -491.601 -491.601] (1.000)
Step: 49899, Reward: [-448.471 -448.471 -448.471] [0.0000], Avg: [-491.558 -491.558 -491.558] (1.000)
Step: 49949, Reward: [-356.478 -356.478 -356.478] [0.0000], Avg: [-491.422 -491.422 -491.422] (1.000)
Step: 49999, Reward: [-536.528 -536.528 -536.528] [0.0000], Avg: [-491.467 -491.467 -491.467] (1.000)
Step: 50049, Reward: [-478.691 -478.691 -478.691] [0.0000], Avg: [-491.455 -491.455 -491.455] (1.000)
Step: 50099, Reward: [-547.9 -547.9 -547.9] [0.0000], Avg: [-491.511 -491.511 -491.511] (1.000)
Step: 50149, Reward: [-500.959 -500.959 -500.959] [0.0000], Avg: [-491.52 -491.52 -491.52] (1.000)
Step: 50199, Reward: [-714.606 -714.606 -714.606] [0.0000], Avg: [-491.743 -491.743 -491.743] (1.000)
Step: 50249, Reward: [-404.051 -404.051 -404.051] [0.0000], Avg: [-491.655 -491.655 -491.655] (1.000)
Step: 50299, Reward: [-468.652 -468.652 -468.652] [0.0000], Avg: [-491.633 -491.633 -491.633] (1.000)
Step: 50349, Reward: [-545.902 -545.902 -545.902] [0.0000], Avg: [-491.686 -491.686 -491.686] (1.000)
Step: 50399, Reward: [-348.284 -348.284 -348.284] [0.0000], Avg: [-491.544 -491.544 -491.544] (1.000)
Step: 50449, Reward: [-488.772 -488.772 -488.772] [0.0000], Avg: [-491.541 -491.541 -491.541] (1.000)
Step: 50499, Reward: [-442.961 -442.961 -442.961] [0.0000], Avg: [-491.493 -491.493 -491.493] (1.000)
Step: 50549, Reward: [-371.801 -371.801 -371.801] [0.0000], Avg: [-491.375 -491.375 -491.375] (1.000)
Step: 50599, Reward: [-401.654 -401.654 -401.654] [0.0000], Avg: [-491.286 -491.286 -491.286] (1.000)
Step: 50649, Reward: [-425.459 -425.459 -425.459] [0.0000], Avg: [-491.221 -491.221 -491.221] (1.000)
Step: 50699, Reward: [-436.4 -436.4 -436.4] [0.0000], Avg: [-491.167 -491.167 -491.167] (1.000)
Step: 50749, Reward: [-450.319 -450.319 -450.319] [0.0000], Avg: [-491.127 -491.127 -491.127] (1.000)
Step: 50799, Reward: [-525.885 -525.885 -525.885] [0.0000], Avg: [-491.161 -491.161 -491.161] (1.000)
Step: 50849, Reward: [-572.063 -572.063 -572.063] [0.0000], Avg: [-491.241 -491.241 -491.241] (1.000)
Step: 50899, Reward: [-556.312 -556.312 -556.312] [0.0000], Avg: [-491.305 -491.305 -491.305] (1.000)
Step: 50949, Reward: [-551.424 -551.424 -551.424] [0.0000], Avg: [-491.364 -491.364 -491.364] (1.000)
Step: 50999, Reward: [-672.726 -672.726 -672.726] [0.0000], Avg: [-491.541 -491.541 -491.541] (1.000)
Step: 51049, Reward: [-548.154 -548.154 -548.154] [0.0000], Avg: [-491.597 -491.597 -491.597] (1.000)
Step: 51099, Reward: [-539.216 -539.216 -539.216] [0.0000], Avg: [-491.644 -491.644 -491.644] (1.000)
Step: 51149, Reward: [-368.881 -368.881 -368.881] [0.0000], Avg: [-491.524 -491.524 -491.524] (1.000)
Step: 51199, Reward: [-483.005 -483.005 -483.005] [0.0000], Avg: [-491.515 -491.515 -491.515] (1.000)
Step: 51249, Reward: [-567.456 -567.456 -567.456] [0.0000], Avg: [-491.589 -491.589 -491.589] (1.000)
Step: 51299, Reward: [-446.964 -446.964 -446.964] [0.0000], Avg: [-491.546 -491.546 -491.546] (1.000)
Step: 51349, Reward: [-423.06 -423.06 -423.06] [0.0000], Avg: [-491.479 -491.479 -491.479] (1.000)
Step: 51399, Reward: [-419.652 -419.652 -419.652] [0.0000], Avg: [-491.409 -491.409 -491.409] (1.000)
Step: 51449, Reward: [-430.323 -430.323 -430.323] [0.0000], Avg: [-491.35 -491.35 -491.35] (1.000)
Step: 51499, Reward: [-410.754 -410.754 -410.754] [0.0000], Avg: [-491.272 -491.272 -491.272] (1.000)
Step: 51549, Reward: [-738.598 -738.598 -738.598] [0.0000], Avg: [-491.512 -491.512 -491.512] (1.000)
Step: 51599, Reward: [-397.832 -397.832 -397.832] [0.0000], Avg: [-491.421 -491.421 -491.421] (1.000)
Step: 51649, Reward: [-371.703 -371.703 -371.703] [0.0000], Avg: [-491.305 -491.305 -491.305] (1.000)
Step: 51699, Reward: [-490.469 -490.469 -490.469] [0.0000], Avg: [-491.304 -491.304 -491.304] (1.000)
Step: 51749, Reward: [-535.891 -535.891 -535.891] [0.0000], Avg: [-491.347 -491.347 -491.347] (1.000)
Step: 51799, Reward: [-347.939 -347.939 -347.939] [0.0000], Avg: [-491.209 -491.209 -491.209] (1.000)
Step: 51849, Reward: [-488.701 -488.701 -488.701] [0.0000], Avg: [-491.206 -491.206 -491.206] (1.000)
Step: 51899, Reward: [-607.29 -607.29 -607.29] [0.0000], Avg: [-491.318 -491.318 -491.318] (1.000)
Step: 51949, Reward: [-449.358 -449.358 -449.358] [0.0000], Avg: [-491.278 -491.278 -491.278] (1.000)
Step: 51999, Reward: [-479.671 -479.671 -479.671] [0.0000], Avg: [-491.267 -491.267 -491.267] (1.000)
Step: 52049, Reward: [-450.973 -450.973 -450.973] [0.0000], Avg: [-491.228 -491.228 -491.228] (1.000)
Step: 52099, Reward: [-567.298 -567.298 -567.298] [0.0000], Avg: [-491.301 -491.301 -491.301] (1.000)
Step: 52149, Reward: [-394.836 -394.836 -394.836] [0.0000], Avg: [-491.208 -491.208 -491.208] (1.000)
Step: 52199, Reward: [-331.996 -331.996 -331.996] [0.0000], Avg: [-491.056 -491.056 -491.056] (1.000)
Step: 52249, Reward: [-494.679 -494.679 -494.679] [0.0000], Avg: [-491.059 -491.059 -491.059] (1.000)
Step: 52299, Reward: [-821.138 -821.138 -821.138] [0.0000], Avg: [-491.375 -491.375 -491.375] (1.000)
Step: 52349, Reward: [-490.304 -490.304 -490.304] [0.0000], Avg: [-491.374 -491.374 -491.374] (1.000)
Step: 52399, Reward: [-523.666 -523.666 -523.666] [0.0000], Avg: [-491.405 -491.405 -491.405] (1.000)
Step: 52449, Reward: [-502.826 -502.826 -502.826] [0.0000], Avg: [-491.416 -491.416 -491.416] (1.000)
Step: 52499, Reward: [-523.411 -523.411 -523.411] [0.0000], Avg: [-491.446 -491.446 -491.446] (1.000)
Step: 52549, Reward: [-437.266 -437.266 -437.266] [0.0000], Avg: [-491.395 -491.395 -491.395] (1.000)
Step: 52599, Reward: [-383.173 -383.173 -383.173] [0.0000], Avg: [-491.292 -491.292 -491.292] (1.000)
Step: 52649, Reward: [-450.93 -450.93 -450.93] [0.0000], Avg: [-491.253 -491.253 -491.253] (1.000)
Step: 52699, Reward: [-599.189 -599.189 -599.189] [0.0000], Avg: [-491.356 -491.356 -491.356] (1.000)
Step: 52749, Reward: [-397.561 -397.561 -397.561] [0.0000], Avg: [-491.267 -491.267 -491.267] (1.000)
Step: 52799, Reward: [-688.582 -688.582 -688.582] [0.0000], Avg: [-491.454 -491.454 -491.454] (1.000)
Step: 52849, Reward: [-643.388 -643.388 -643.388] [0.0000], Avg: [-491.597 -491.597 -491.597] (1.000)
Step: 52899, Reward: [-458.985 -458.985 -458.985] [0.0000], Avg: [-491.567 -491.567 -491.567] (1.000)
Step: 52949, Reward: [-453.837 -453.837 -453.837] [0.0000], Avg: [-491.531 -491.531 -491.531] (1.000)
Step: 52999, Reward: [-386.591 -386.591 -386.591] [0.0000], Avg: [-491.432 -491.432 -491.432] (1.000)
Step: 53049, Reward: [-487.299 -487.299 -487.299] [0.0000], Avg: [-491.428 -491.428 -491.428] (1.000)
Step: 53099, Reward: [-515.617 -515.617 -515.617] [0.0000], Avg: [-491.451 -491.451 -491.451] (1.000)
Step: 53149, Reward: [-498.199 -498.199 -498.199] [0.0000], Avg: [-491.457 -491.457 -491.457] (1.000)
Step: 53199, Reward: [-447.325 -447.325 -447.325] [0.0000], Avg: [-491.416 -491.416 -491.416] (1.000)
Step: 53249, Reward: [-377.385 -377.385 -377.385] [0.0000], Avg: [-491.309 -491.309 -491.309] (1.000)
Step: 53299, Reward: [-480.442 -480.442 -480.442] [0.0000], Avg: [-491.298 -491.298 -491.298] (1.000)
Step: 53349, Reward: [-599.114 -599.114 -599.114] [0.0000], Avg: [-491.399 -491.399 -491.399] (1.000)
Step: 53399, Reward: [-541.628 -541.628 -541.628] [0.0000], Avg: [-491.447 -491.447 -491.447] (1.000)
Step: 53449, Reward: [-642.154 -642.154 -642.154] [0.0000], Avg: [-491.587 -491.587 -491.587] (1.000)
Step: 53499, Reward: [-497.111 -497.111 -497.111] [0.0000], Avg: [-491.593 -491.593 -491.593] (1.000)
Step: 53549, Reward: [-568.64 -568.64 -568.64] [0.0000], Avg: [-491.665 -491.665 -491.665] (1.000)
Step: 53599, Reward: [-502.223 -502.223 -502.223] [0.0000], Avg: [-491.674 -491.674 -491.674] (1.000)
Step: 53649, Reward: [-489.11 -489.11 -489.11] [0.0000], Avg: [-491.672 -491.672 -491.672] (1.000)
Step: 53699, Reward: [-667.266 -667.266 -667.266] [0.0000], Avg: [-491.836 -491.836 -491.836] (1.000)
Step: 53749, Reward: [-403.481 -403.481 -403.481] [0.0000], Avg: [-491.753 -491.753 -491.753] (1.000)
Step: 53799, Reward: [-592.016 -592.016 -592.016] [0.0000], Avg: [-491.847 -491.847 -491.847] (1.000)
Step: 53849, Reward: [-342.646 -342.646 -342.646] [0.0000], Avg: [-491.708 -491.708 -491.708] (1.000)
Step: 53899, Reward: [-425.534 -425.534 -425.534] [0.0000], Avg: [-491.647 -491.647 -491.647] (1.000)
Step: 53949, Reward: [-362.86 -362.86 -362.86] [0.0000], Avg: [-491.527 -491.527 -491.527] (1.000)
Step: 53999, Reward: [-446.043 -446.043 -446.043] [0.0000], Avg: [-491.485 -491.485 -491.485] (1.000)
Step: 54049, Reward: [-596.762 -596.762 -596.762] [0.0000], Avg: [-491.583 -491.583 -491.583] (1.000)
Step: 54099, Reward: [-402.352 -402.352 -402.352] [0.0000], Avg: [-491.5 -491.5 -491.5] (1.000)
Step: 54149, Reward: [-403.447 -403.447 -403.447] [0.0000], Avg: [-491.419 -491.419 -491.419] (1.000)
Step: 54199, Reward: [-669.768 -669.768 -669.768] [0.0000], Avg: [-491.583 -491.583 -491.583] (1.000)
Step: 54249, Reward: [-483.209 -483.209 -483.209] [0.0000], Avg: [-491.576 -491.576 -491.576] (1.000)
Step: 54299, Reward: [-463.269 -463.269 -463.269] [0.0000], Avg: [-491.55 -491.55 -491.55] (1.000)
Step: 54349, Reward: [-352.3 -352.3 -352.3] [0.0000], Avg: [-491.421 -491.421 -491.421] (1.000)
Step: 54399, Reward: [-528.57 -528.57 -528.57] [0.0000], Avg: [-491.456 -491.456 -491.456] (1.000)
Step: 54449, Reward: [-367.975 -367.975 -367.975] [0.0000], Avg: [-491.342 -491.342 -491.342] (1.000)
Step: 54499, Reward: [-486.116 -486.116 -486.116] [0.0000], Avg: [-491.337 -491.337 -491.337] (1.000)
Step: 54549, Reward: [-442.839 -442.839 -442.839] [0.0000], Avg: [-491.293 -491.293 -491.293] (1.000)
Step: 54599, Reward: [-634.606 -634.606 -634.606] [0.0000], Avg: [-491.424 -491.424 -491.424] (1.000)
Step: 54649, Reward: [-432.002 -432.002 -432.002] [0.0000], Avg: [-491.37 -491.37 -491.37] (1.000)
Step: 54699, Reward: [-761.303 -761.303 -761.303] [0.0000], Avg: [-491.617 -491.617 -491.617] (1.000)
Step: 54749, Reward: [-560.189 -560.189 -560.189] [0.0000], Avg: [-491.679 -491.679 -491.679] (1.000)
Step: 54799, Reward: [-371.51 -371.51 -371.51] [0.0000], Avg: [-491.569 -491.569 -491.569] (1.000)
Step: 54849, Reward: [-393.741 -393.741 -393.741] [0.0000], Avg: [-491.48 -491.48 -491.48] (1.000)
Step: 54899, Reward: [-619.589 -619.589 -619.589] [0.0000], Avg: [-491.597 -491.597 -491.597] (1.000)
Step: 54949, Reward: [-392.051 -392.051 -392.051] [0.0000], Avg: [-491.506 -491.506 -491.506] (1.000)
Step: 54999, Reward: [-682.686 -682.686 -682.686] [0.0000], Avg: [-491.68 -491.68 -491.68] (1.000)
Step: 55049, Reward: [-442.403 -442.403 -442.403] [0.0000], Avg: [-491.635 -491.635 -491.635] (1.000)
Step: 55099, Reward: [-523.212 -523.212 -523.212] [0.0000], Avg: [-491.664 -491.664 -491.664] (1.000)
Step: 55149, Reward: [-358.812 -358.812 -358.812] [0.0000], Avg: [-491.544 -491.544 -491.544] (1.000)
Step: 55199, Reward: [-447.992 -447.992 -447.992] [0.0000], Avg: [-491.504 -491.504 -491.504] (1.000)
Step: 55249, Reward: [-502.537 -502.537 -502.537] [0.0000], Avg: [-491.514 -491.514 -491.514] (1.000)
Step: 55299, Reward: [-372.16 -372.16 -372.16] [0.0000], Avg: [-491.406 -491.406 -491.406] (1.000)
Step: 55349, Reward: [-609.453 -609.453 -609.453] [0.0000], Avg: [-491.513 -491.513 -491.513] (1.000)
Step: 55399, Reward: [-475.822 -475.822 -475.822] [0.0000], Avg: [-491.499 -491.499 -491.499] (1.000)
Step: 55449, Reward: [-414.469 -414.469 -414.469] [0.0000], Avg: [-491.429 -491.429 -491.429] (1.000)
Step: 55499, Reward: [-543.772 -543.772 -543.772] [0.0000], Avg: [-491.476 -491.476 -491.476] (1.000)
Step: 55549, Reward: [-462.912 -462.912 -462.912] [0.0000], Avg: [-491.451 -491.451 -491.451] (1.000)
Step: 55599, Reward: [-513.229 -513.229 -513.229] [0.0000], Avg: [-491.47 -491.47 -491.47] (1.000)
Step: 55649, Reward: [-618.625 -618.625 -618.625] [0.0000], Avg: [-491.585 -491.585 -491.585] (1.000)
Step: 55699, Reward: [-314.299 -314.299 -314.299] [0.0000], Avg: [-491.425 -491.425 -491.425] (1.000)
Step: 55749, Reward: [-428.727 -428.727 -428.727] [0.0000], Avg: [-491.369 -491.369 -491.369] (1.000)
Step: 55799, Reward: [-574.868 -574.868 -574.868] [0.0000], Avg: [-491.444 -491.444 -491.444] (1.000)
Step: 55849, Reward: [-613.658 -613.658 -613.658] [0.0000], Avg: [-491.553 -491.553 -491.553] (1.000)
Step: 55899, Reward: [-364.467 -364.467 -364.467] [0.0000], Avg: [-491.44 -491.44 -491.44] (1.000)
Step: 55949, Reward: [-396.64 -396.64 -396.64] [0.0000], Avg: [-491.355 -491.355 -491.355] (1.000)
Step: 55999, Reward: [-492.7 -492.7 -492.7] [0.0000], Avg: [-491.356 -491.356 -491.356] (1.000)
Step: 56049, Reward: [-587.689 -587.689 -587.689] [0.0000], Avg: [-491.442 -491.442 -491.442] (1.000)
Step: 56099, Reward: [-440.305 -440.305 -440.305] [0.0000], Avg: [-491.397 -491.397 -491.397] (1.000)
Step: 56149, Reward: [-512.131 -512.131 -512.131] [0.0000], Avg: [-491.415 -491.415 -491.415] (1.000)
Step: 56199, Reward: [-736.955 -736.955 -736.955] [0.0000], Avg: [-491.634 -491.634 -491.634] (1.000)
Step: 56249, Reward: [-374.794 -374.794 -374.794] [0.0000], Avg: [-491.53 -491.53 -491.53] (1.000)
Step: 56299, Reward: [-545.799 -545.799 -545.799] [0.0000], Avg: [-491.578 -491.578 -491.578] (1.000)
Step: 56349, Reward: [-384.571 -384.571 -384.571] [0.0000], Avg: [-491.483 -491.483 -491.483] (1.000)
Step: 56399, Reward: [-417.741 -417.741 -417.741] [0.0000], Avg: [-491.418 -491.418 -491.418] (1.000)
Step: 56449, Reward: [-531.631 -531.631 -531.631] [0.0000], Avg: [-491.453 -491.453 -491.453] (1.000)
Step: 56499, Reward: [-331.798 -331.798 -331.798] [0.0000], Avg: [-491.312 -491.312 -491.312] (1.000)
Step: 56549, Reward: [-629.325 -629.325 -629.325] [0.0000], Avg: [-491.434 -491.434 -491.434] (1.000)
Step: 56599, Reward: [-531.695 -531.695 -531.695] [0.0000], Avg: [-491.469 -491.469 -491.469] (1.000)
Step: 56649, Reward: [-673.894 -673.894 -673.894] [0.0000], Avg: [-491.63 -491.63 -491.63] (1.000)
Step: 56699, Reward: [-576.678 -576.678 -576.678] [0.0000], Avg: [-491.705 -491.705 -491.705] (1.000)
Step: 56749, Reward: [-602.214 -602.214 -602.214] [0.0000], Avg: [-491.803 -491.803 -491.803] (1.000)
Step: 56799, Reward: [-421.456 -421.456 -421.456] [0.0000], Avg: [-491.741 -491.741 -491.741] (1.000)
Step: 56849, Reward: [-525.392 -525.392 -525.392] [0.0000], Avg: [-491.771 -491.771 -491.771] (1.000)
Step: 56899, Reward: [-385.856 -385.856 -385.856] [0.0000], Avg: [-491.677 -491.677 -491.677] (1.000)
Step: 56949, Reward: [-457.444 -457.444 -457.444] [0.0000], Avg: [-491.647 -491.647 -491.647] (1.000)
Step: 56999, Reward: [-397.444 -397.444 -397.444] [0.0000], Avg: [-491.565 -491.565 -491.565] (1.000)
Step: 57049, Reward: [-568.112 -568.112 -568.112] [0.0000], Avg: [-491.632 -491.632 -491.632] (1.000)
Step: 57099, Reward: [-511.849 -511.849 -511.849] [0.0000], Avg: [-491.65 -491.65 -491.65] (1.000)
Step: 57149, Reward: [-477.301 -477.301 -477.301] [0.0000], Avg: [-491.637 -491.637 -491.637] (1.000)
Step: 57199, Reward: [-549.904 -549.904 -549.904] [0.0000], Avg: [-491.688 -491.688 -491.688] (1.000)
Step: 57249, Reward: [-472.022 -472.022 -472.022] [0.0000], Avg: [-491.671 -491.671 -491.671] (1.000)
Step: 57299, Reward: [-368.531 -368.531 -368.531] [0.0000], Avg: [-491.563 -491.563 -491.563] (1.000)
Step: 57349, Reward: [-580.751 -580.751 -580.751] [0.0000], Avg: [-491.641 -491.641 -491.641] (1.000)
Step: 57399, Reward: [-489.078 -489.078 -489.078] [0.0000], Avg: [-491.639 -491.639 -491.639] (1.000)
Step: 57449, Reward: [-382.62 -382.62 -382.62] [0.0000], Avg: [-491.544 -491.544 -491.544] (1.000)
Step: 57499, Reward: [-462.245 -462.245 -462.245] [0.0000], Avg: [-491.518 -491.518 -491.518] (1.000)
Step: 57549, Reward: [-523.146 -523.146 -523.146] [0.0000], Avg: [-491.546 -491.546 -491.546] (1.000)
Step: 57599, Reward: [-445.438 -445.438 -445.438] [0.0000], Avg: [-491.506 -491.506 -491.506] (1.000)
Step: 57649, Reward: [-558.628 -558.628 -558.628] [0.0000], Avg: [-491.564 -491.564 -491.564] (1.000)
Step: 57699, Reward: [-554.547 -554.547 -554.547] [0.0000], Avg: [-491.619 -491.619 -491.619] (1.000)
Step: 57749, Reward: [-405.515 -405.515 -405.515] [0.0000], Avg: [-491.544 -491.544 -491.544] (1.000)
Step: 57799, Reward: [-517.975 -517.975 -517.975] [0.0000], Avg: [-491.567 -491.567 -491.567] (1.000)
Step: 57849, Reward: [-477.811 -477.811 -477.811] [0.0000], Avg: [-491.555 -491.555 -491.555] (1.000)
Step: 57899, Reward: [-450.944 -450.944 -450.944] [0.0000], Avg: [-491.52 -491.52 -491.52] (1.000)
Step: 57949, Reward: [-526.972 -526.972 -526.972] [0.0000], Avg: [-491.551 -491.551 -491.551] (1.000)
Step: 57999, Reward: [-314.091 -314.091 -314.091] [0.0000], Avg: [-491.398 -491.398 -491.398] (1.000)
Step: 58049, Reward: [-489.757 -489.757 -489.757] [0.0000], Avg: [-491.396 -491.396 -491.396] (1.000)
Step: 58099, Reward: [-410.493 -410.493 -410.493] [0.0000], Avg: [-491.327 -491.327 -491.327] (1.000)
Step: 58149, Reward: [-542.586 -542.586 -542.586] [0.0000], Avg: [-491.371 -491.371 -491.371] (1.000)
Step: 58199, Reward: [-625.214 -625.214 -625.214] [0.0000], Avg: [-491.486 -491.486 -491.486] (1.000)
Step: 58249, Reward: [-445.292 -445.292 -445.292] [0.0000], Avg: [-491.446 -491.446 -491.446] (1.000)
Step: 58299, Reward: [-534.973 -534.973 -534.973] [0.0000], Avg: [-491.483 -491.483 -491.483] (1.000)
Step: 58349, Reward: [-494.559 -494.559 -494.559] [0.0000], Avg: [-491.486 -491.486 -491.486] (1.000)
Step: 58399, Reward: [-372.266 -372.266 -372.266] [0.0000], Avg: [-491.384 -491.384 -491.384] (1.000)
Step: 58449, Reward: [-357.141 -357.141 -357.141] [0.0000], Avg: [-491.269 -491.269 -491.269] (1.000)
Step: 58499, Reward: [-521.378 -521.378 -521.378] [0.0000], Avg: [-491.295 -491.295 -491.295] (1.000)
Step: 58549, Reward: [-496.527 -496.527 -496.527] [0.0000], Avg: [-491.299 -491.299 -491.299] (1.000)
Step: 58599, Reward: [-697.415 -697.415 -697.415] [0.0000], Avg: [-491.475 -491.475 -491.475] (1.000)
Step: 58649, Reward: [-459.917 -459.917 -459.917] [0.0000], Avg: [-491.448 -491.448 -491.448] (1.000)
Step: 58699, Reward: [-513.296 -513.296 -513.296] [0.0000], Avg: [-491.467 -491.467 -491.467] (1.000)
Step: 58749, Reward: [-440.508 -440.508 -440.508] [0.0000], Avg: [-491.423 -491.423 -491.423] (1.000)
Step: 58799, Reward: [-772.782 -772.782 -772.782] [0.0000], Avg: [-491.663 -491.663 -491.663] (1.000)
Step: 58849, Reward: [-758.271 -758.271 -758.271] [0.0000], Avg: [-491.889 -491.889 -491.889] (1.000)
Step: 58899, Reward: [-680.457 -680.457 -680.457] [0.0000], Avg: [-492.049 -492.049 -492.049] (1.000)
Step: 58949, Reward: [-467.399 -467.399 -467.399] [0.0000], Avg: [-492.028 -492.028 -492.028] (1.000)
Step: 58999, Reward: [-667.947 -667.947 -667.947] [0.0000], Avg: [-492.178 -492.178 -492.178] (1.000)
Step: 59049, Reward: [-524.27 -524.27 -524.27] [0.0000], Avg: [-492.205 -492.205 -492.205] (1.000)
Step: 59099, Reward: [-401.825 -401.825 -401.825] [0.0000], Avg: [-492.128 -492.128 -492.128] (1.000)
Step: 59149, Reward: [-508.224 -508.224 -508.224] [0.0000], Avg: [-492.142 -492.142 -492.142] (1.000)
Step: 59199, Reward: [-519.093 -519.093 -519.093] [0.0000], Avg: [-492.165 -492.165 -492.165] (1.000)
Step: 59249, Reward: [-493.942 -493.942 -493.942] [0.0000], Avg: [-492.166 -492.166 -492.166] (1.000)
Step: 59299, Reward: [-419.996 -419.996 -419.996] [0.0000], Avg: [-492.105 -492.105 -492.105] (1.000)
Step: 59349, Reward: [-365.608 -365.608 -365.608] [0.0000], Avg: [-491.999 -491.999 -491.999] (1.000)
Step: 59399, Reward: [-476.826 -476.826 -476.826] [0.0000], Avg: [-491.986 -491.986 -491.986] (1.000)
Step: 59449, Reward: [-398.692 -398.692 -398.692] [0.0000], Avg: [-491.907 -491.907 -491.907] (1.000)
Step: 59499, Reward: [-352.432 -352.432 -352.432] [0.0000], Avg: [-491.79 -491.79 -491.79] (1.000)
Step: 59549, Reward: [-405.309 -405.309 -405.309] [0.0000], Avg: [-491.718 -491.718 -491.718] (1.000)
Step: 59599, Reward: [-436.131 -436.131 -436.131] [0.0000], Avg: [-491.671 -491.671 -491.671] (1.000)
Step: 59649, Reward: [-468.263 -468.263 -468.263] [0.0000], Avg: [-491.651 -491.651 -491.651] (1.000)
Step: 59699, Reward: [-516.356 -516.356 -516.356] [0.0000], Avg: [-491.672 -491.672 -491.672] (1.000)
Step: 59749, Reward: [-386.163 -386.163 -386.163] [0.0000], Avg: [-491.584 -491.584 -491.584] (1.000)
Step: 59799, Reward: [-492.726 -492.726 -492.726] [0.0000], Avg: [-491.585 -491.585 -491.585] (1.000)
Step: 59849, Reward: [-436.128 -436.128 -436.128] [0.0000], Avg: [-491.538 -491.538 -491.538] (1.000)
Step: 59899, Reward: [-542.6 -542.6 -542.6] [0.0000], Avg: [-491.581 -491.581 -491.581] (1.000)
Step: 59949, Reward: [-394.696 -394.696 -394.696] [0.0000], Avg: [-491.5 -491.5 -491.5] (1.000)
Step: 59999, Reward: [-584.382 -584.382 -584.382] [0.0000], Avg: [-491.578 -491.578 -491.578] (1.000)
Step: 60049, Reward: [-353.568 -353.568 -353.568] [0.0000], Avg: [-491.463 -491.463 -491.463] (1.000)
Step: 60099, Reward: [-414.099 -414.099 -414.099] [0.0000], Avg: [-491.398 -491.398 -491.398] (1.000)
Step: 60149, Reward: [-462.92 -462.92 -462.92] [0.0000], Avg: [-491.375 -491.375 -491.375] (1.000)
Step: 60199, Reward: [-578.801 -578.801 -578.801] [0.0000], Avg: [-491.447 -491.447 -491.447] (1.000)
Step: 60249, Reward: [-448.484 -448.484 -448.484] [0.0000], Avg: [-491.412 -491.412 -491.412] (1.000)
Step: 60299, Reward: [-694.526 -694.526 -694.526] [0.0000], Avg: [-491.58 -491.58 -491.58] (1.000)
Step: 60349, Reward: [-364.85 -364.85 -364.85] [0.0000], Avg: [-491.475 -491.475 -491.475] (1.000)
Step: 60399, Reward: [-469.692 -469.692 -469.692] [0.0000], Avg: [-491.457 -491.457 -491.457] (1.000)
Step: 60449, Reward: [-450.419 -450.419 -450.419] [0.0000], Avg: [-491.423 -491.423 -491.423] (1.000)
Step: 60499, Reward: [-654.987 -654.987 -654.987] [0.0000], Avg: [-491.558 -491.558 -491.558] (1.000)
Step: 60549, Reward: [-424.174 -424.174 -424.174] [0.0000], Avg: [-491.503 -491.503 -491.503] (1.000)
Step: 60599, Reward: [-445.563 -445.563 -445.563] [0.0000], Avg: [-491.465 -491.465 -491.465] (1.000)
Step: 60649, Reward: [-563.41 -563.41 -563.41] [0.0000], Avg: [-491.524 -491.524 -491.524] (1.000)
Step: 60699, Reward: [-467.857 -467.857 -467.857] [0.0000], Avg: [-491.505 -491.505 -491.505] (1.000)
Step: 60749, Reward: [-412.652 -412.652 -412.652] [0.0000], Avg: [-491.44 -491.44 -491.44] (1.000)
Step: 60799, Reward: [-381.761 -381.761 -381.761] [0.0000], Avg: [-491.349 -491.349 -491.349] (1.000)
Step: 60849, Reward: [-498.863 -498.863 -498.863] [0.0000], Avg: [-491.356 -491.356 -491.356] (1.000)
Step: 60899, Reward: [-597.192 -597.192 -597.192] [0.0000], Avg: [-491.442 -491.442 -491.442] (1.000)
Step: 60949, Reward: [-433.51 -433.51 -433.51] [0.0000], Avg: [-491.395 -491.395 -491.395] (1.000)
Step: 60999, Reward: [-472.899 -472.899 -472.899] [0.0000], Avg: [-491.38 -491.38 -491.38] (1.000)
Step: 61049, Reward: [-535.661 -535.661 -535.661] [0.0000], Avg: [-491.416 -491.416 -491.416] (1.000)
Step: 61099, Reward: [-577.87 -577.87 -577.87] [0.0000], Avg: [-491.487 -491.487 -491.487] (1.000)
Step: 61149, Reward: [-506.728 -506.728 -506.728] [0.0000], Avg: [-491.499 -491.499 -491.499] (1.000)
Step: 61199, Reward: [-497.097 -497.097 -497.097] [0.0000], Avg: [-491.504 -491.504 -491.504] (1.000)
Step: 61249, Reward: [-595.291 -595.291 -595.291] [0.0000], Avg: [-491.589 -491.589 -491.589] (1.000)
Step: 61299, Reward: [-395.229 -395.229 -395.229] [0.0000], Avg: [-491.51 -491.51 -491.51] (1.000)
Step: 61349, Reward: [-716.261 -716.261 -716.261] [0.0000], Avg: [-491.693 -491.693 -491.693] (1.000)
Step: 61399, Reward: [-342.901 -342.901 -342.901] [0.0000], Avg: [-491.572 -491.572 -491.572] (1.000)
Step: 61449, Reward: [-532.629 -532.629 -532.629] [0.0000], Avg: [-491.605 -491.605 -491.605] (1.000)
Step: 61499, Reward: [-468.496 -468.496 -468.496] [0.0000], Avg: [-491.587 -491.587 -491.587] (1.000)
Step: 61549, Reward: [-436.755 -436.755 -436.755] [0.0000], Avg: [-491.542 -491.542 -491.542] (1.000)
Step: 61599, Reward: [-528.336 -528.336 -528.336] [0.0000], Avg: [-491.572 -491.572 -491.572] (1.000)
Step: 61649, Reward: [-551.612 -551.612 -551.612] [0.0000], Avg: [-491.621 -491.621 -491.621] (1.000)
Step: 61699, Reward: [-431.489 -431.489 -431.489] [0.0000], Avg: [-491.572 -491.572 -491.572] (1.000)
Step: 61749, Reward: [-771.812 -771.812 -771.812] [0.0000], Avg: [-491.799 -491.799 -491.799] (1.000)
Step: 61799, Reward: [-360.325 -360.325 -360.325] [0.0000], Avg: [-491.692 -491.692 -491.692] (1.000)
Step: 61849, Reward: [-609.986 -609.986 -609.986] [0.0000], Avg: [-491.788 -491.788 -491.788] (1.000)
Step: 61899, Reward: [-799.745 -799.745 -799.745] [0.0000], Avg: [-492.037 -492.037 -492.037] (1.000)
Step: 61949, Reward: [-610.586 -610.586 -610.586] [0.0000], Avg: [-492.132 -492.132 -492.132] (1.000)
Step: 61999, Reward: [-429.426 -429.426 -429.426] [0.0000], Avg: [-492.082 -492.082 -492.082] (1.000)
Step: 62049, Reward: [-411.394 -411.394 -411.394] [0.0000], Avg: [-492.017 -492.017 -492.017] (1.000)
Step: 62099, Reward: [-534.602 -534.602 -534.602] [0.0000], Avg: [-492.051 -492.051 -492.051] (1.000)
Step: 62149, Reward: [-621.564 -621.564 -621.564] [0.0000], Avg: [-492.155 -492.155 -492.155] (1.000)
Step: 62199, Reward: [-501.541 -501.541 -501.541] [0.0000], Avg: [-492.163 -492.163 -492.163] (1.000)
Step: 62249, Reward: [-737.259 -737.259 -737.259] [0.0000], Avg: [-492.36 -492.36 -492.36] (1.000)
Step: 62299, Reward: [-667.156 -667.156 -667.156] [0.0000], Avg: [-492.5 -492.5 -492.5] (1.000)
Step: 62349, Reward: [-521.933 -521.933 -521.933] [0.0000], Avg: [-492.524 -492.524 -492.524] (1.000)
Step: 62399, Reward: [-410.196 -410.196 -410.196] [0.0000], Avg: [-492.458 -492.458 -492.458] (1.000)
Step: 62449, Reward: [-346.226 -346.226 -346.226] [0.0000], Avg: [-492.341 -492.341 -492.341] (1.000)
Step: 62499, Reward: [-618.988 -618.988 -618.988] [0.0000], Avg: [-492.442 -492.442 -492.442] (1.000)
Step: 62549, Reward: [-342.881 -342.881 -342.881] [0.0000], Avg: [-492.322 -492.322 -492.322] (1.000)
Step: 62599, Reward: [-422.927 -422.927 -422.927] [0.0000], Avg: [-492.267 -492.267 -492.267] (1.000)
Step: 62649, Reward: [-553.745 -553.745 -553.745] [0.0000], Avg: [-492.316 -492.316 -492.316] (1.000)
Step: 62699, Reward: [-381.554 -381.554 -381.554] [0.0000], Avg: [-492.228 -492.228 -492.228] (1.000)
Step: 62749, Reward: [-378.144 -378.144 -378.144] [0.0000], Avg: [-492.137 -492.137 -492.137] (1.000)
Step: 62799, Reward: [-349.884 -349.884 -349.884] [0.0000], Avg: [-492.024 -492.024 -492.024] (1.000)
Step: 62849, Reward: [-507.216 -507.216 -507.216] [0.0000], Avg: [-492.036 -492.036 -492.036] (1.000)
Step: 62899, Reward: [-320.172 -320.172 -320.172] [0.0000], Avg: [-491.899 -491.899 -491.899] (1.000)
Step: 62949, Reward: [-511.953 -511.953 -511.953] [0.0000], Avg: [-491.915 -491.915 -491.915] (1.000)
Step: 62999, Reward: [-505.361 -505.361 -505.361] [0.0000], Avg: [-491.926 -491.926 -491.926] (1.000)
Step: 63049, Reward: [-531.628 -531.628 -531.628] [0.0000], Avg: [-491.957 -491.957 -491.957] (1.000)
Step: 63099, Reward: [-517.586 -517.586 -517.586] [0.0000], Avg: [-491.977 -491.977 -491.977] (1.000)
Step: 63149, Reward: [-549.198 -549.198 -549.198] [0.0000], Avg: [-492.023 -492.023 -492.023] (1.000)
Step: 63199, Reward: [-380.789 -380.789 -380.789] [0.0000], Avg: [-491.935 -491.935 -491.935] (1.000)
Step: 63249, Reward: [-492.148 -492.148 -492.148] [0.0000], Avg: [-491.935 -491.935 -491.935] (1.000)
Step: 63299, Reward: [-559.719 -559.719 -559.719] [0.0000], Avg: [-491.988 -491.988 -491.988] (1.000)
Step: 63349, Reward: [-490.238 -490.238 -490.238] [0.0000], Avg: [-491.987 -491.987 -491.987] (1.000)
Step: 63399, Reward: [-635.576 -635.576 -635.576] [0.0000], Avg: [-492.1 -492.1 -492.1] (1.000)
Step: 63449, Reward: [-575.643 -575.643 -575.643] [0.0000], Avg: [-492.166 -492.166 -492.166] (1.000)
Step: 63499, Reward: [-481.023 -481.023 -481.023] [0.0000], Avg: [-492.157 -492.157 -492.157] (1.000)
Step: 63549, Reward: [-493.258 -493.258 -493.258] [0.0000], Avg: [-492.158 -492.158 -492.158] (1.000)
Step: 63599, Reward: [-537.461 -537.461 -537.461] [0.0000], Avg: [-492.194 -492.194 -492.194] (1.000)
Step: 63649, Reward: [-563.181 -563.181 -563.181] [0.0000], Avg: [-492.25 -492.25 -492.25] (1.000)
Step: 63699, Reward: [-416.637 -416.637 -416.637] [0.0000], Avg: [-492.19 -492.19 -492.19] (1.000)
Step: 63749, Reward: [-594.967 -594.967 -594.967] [0.0000], Avg: [-492.271 -492.271 -492.271] (1.000)
Step: 63799, Reward: [-539.456 -539.456 -539.456] [0.0000], Avg: [-492.308 -492.308 -492.308] (1.000)
Step: 63849, Reward: [-497.457 -497.457 -497.457] [0.0000], Avg: [-492.312 -492.312 -492.312] (1.000)
Step: 63899, Reward: [-456.297 -456.297 -456.297] [0.0000], Avg: [-492.284 -492.284 -492.284] (1.000)
Step: 63949, Reward: [-533.696 -533.696 -533.696] [0.0000], Avg: [-492.316 -492.316 -492.316] (1.000)
Step: 63999, Reward: [-566.429 -566.429 -566.429] [0.0000], Avg: [-492.374 -492.374 -492.374] (1.000)
Step: 64049, Reward: [-390.143 -390.143 -390.143] [0.0000], Avg: [-492.294 -492.294 -492.294] (1.000)
Step: 64099, Reward: [-488.01 -488.01 -488.01] [0.0000], Avg: [-492.291 -492.291 -492.291] (1.000)
Step: 64149, Reward: [-428.05 -428.05 -428.05] [0.0000], Avg: [-492.241 -492.241 -492.241] (1.000)
Step: 64199, Reward: [-630.049 -630.049 -630.049] [0.0000], Avg: [-492.348 -492.348 -492.348] (1.000)
Step: 64249, Reward: [-475.259 -475.259 -475.259] [0.0000], Avg: [-492.335 -492.335 -492.335] (1.000)
Step: 64299, Reward: [-339.459 -339.459 -339.459] [0.0000], Avg: [-492.216 -492.216 -492.216] (1.000)
Step: 64349, Reward: [-516.11 -516.11 -516.11] [0.0000], Avg: [-492.234 -492.234 -492.234] (1.000)
Step: 64399, Reward: [-519.475 -519.475 -519.475] [0.0000], Avg: [-492.256 -492.256 -492.256] (1.000)
Step: 64449, Reward: [-433.325 -433.325 -433.325] [0.0000], Avg: [-492.21 -492.21 -492.21] (1.000)
Step: 64499, Reward: [-505.468 -505.468 -505.468] [0.0000], Avg: [-492.22 -492.22 -492.22] (1.000)
Step: 64549, Reward: [-446.616 -446.616 -446.616] [0.0000], Avg: [-492.185 -492.185 -492.185] (1.000)
Step: 64599, Reward: [-442.878 -442.878 -442.878] [0.0000], Avg: [-492.147 -492.147 -492.147] (1.000)
Step: 64649, Reward: [-362.019 -362.019 -362.019] [0.0000], Avg: [-492.046 -492.046 -492.046] (1.000)
Step: 64699, Reward: [-495.573 -495.573 -495.573] [0.0000], Avg: [-492.049 -492.049 -492.049] (1.000)
Step: 64749, Reward: [-477.942 -477.942 -477.942] [0.0000], Avg: [-492.038 -492.038 -492.038] (1.000)
Step: 64799, Reward: [-461.766 -461.766 -461.766] [0.0000], Avg: [-492.015 -492.015 -492.015] (1.000)
Step: 64849, Reward: [-497.563 -497.563 -497.563] [0.0000], Avg: [-492.019 -492.019 -492.019] (1.000)
Step: 64899, Reward: [-483.528 -483.528 -483.528] [0.0000], Avg: [-492.012 -492.012 -492.012] (1.000)
Step: 64949, Reward: [-370.664 -370.664 -370.664] [0.0000], Avg: [-491.919 -491.919 -491.919] (1.000)
Step: 64999, Reward: [-422.951 -422.951 -422.951] [0.0000], Avg: [-491.866 -491.866 -491.866] (1.000)
Step: 65049, Reward: [-537.644 -537.644 -537.644] [0.0000], Avg: [-491.901 -491.901 -491.901] (1.000)
Step: 65099, Reward: [-553.803 -553.803 -553.803] [0.0000], Avg: [-491.949 -491.949 -491.949] (1.000)
Step: 65149, Reward: [-463.923 -463.923 -463.923] [0.0000], Avg: [-491.927 -491.927 -491.927] (1.000)
Step: 65199, Reward: [-427.165 -427.165 -427.165] [0.0000], Avg: [-491.877 -491.877 -491.877] (1.000)
Step: 65249, Reward: [-526.947 -526.947 -526.947] [0.0000], Avg: [-491.904 -491.904 -491.904] (1.000)
Step: 65299, Reward: [-376.126 -376.126 -376.126] [0.0000], Avg: [-491.816 -491.816 -491.816] (1.000)
Step: 65349, Reward: [-517.711 -517.711 -517.711] [0.0000], Avg: [-491.835 -491.835 -491.835] (1.000)
Step: 65399, Reward: [-472.852 -472.852 -472.852] [0.0000], Avg: [-491.821 -491.821 -491.821] (1.000)
Step: 65449, Reward: [-504.769 -504.769 -504.769] [0.0000], Avg: [-491.831 -491.831 -491.831] (1.000)
Step: 65499, Reward: [-473.881 -473.881 -473.881] [0.0000], Avg: [-491.817 -491.817 -491.817] (1.000)
Step: 65549, Reward: [-453.422 -453.422 -453.422] [0.0000], Avg: [-491.788 -491.788 -491.788] (1.000)
Step: 65599, Reward: [-735.069 -735.069 -735.069] [0.0000], Avg: [-491.973 -491.973 -491.973] (1.000)
Step: 65649, Reward: [-519.257 -519.257 -519.257] [0.0000], Avg: [-491.994 -491.994 -491.994] (1.000)
Step: 65699, Reward: [-723.417 -723.417 -723.417] [0.0000], Avg: [-492.17 -492.17 -492.17] (1.000)
Step: 65749, Reward: [-347.606 -347.606 -347.606] [0.0000], Avg: [-492.06 -492.06 -492.06] (1.000)
Step: 65799, Reward: [-525.795 -525.795 -525.795] [0.0000], Avg: [-492.086 -492.086 -492.086] (1.000)
Step: 65849, Reward: [-393.28 -393.28 -393.28] [0.0000], Avg: [-492.011 -492.011 -492.011] (1.000)
Step: 65899, Reward: [-419.349 -419.349 -419.349] [0.0000], Avg: [-491.956 -491.956 -491.956] (1.000)
Step: 65949, Reward: [-518.348 -518.348 -518.348] [0.0000], Avg: [-491.976 -491.976 -491.976] (1.000)
Step: 65999, Reward: [-494.888 -494.888 -494.888] [0.0000], Avg: [-491.978 -491.978 -491.978] (1.000)
Step: 66049, Reward: [-540.931 -540.931 -540.931] [0.0000], Avg: [-492.015 -492.015 -492.015] (1.000)
Step: 66099, Reward: [-366.436 -366.436 -366.436] [0.0000], Avg: [-491.92 -491.92 -491.92] (1.000)
Step: 66149, Reward: [-593.275 -593.275 -593.275] [0.0000], Avg: [-491.997 -491.997 -491.997] (1.000)
Step: 66199, Reward: [-409.216 -409.216 -409.216] [0.0000], Avg: [-491.934 -491.934 -491.934] (1.000)
Step: 66249, Reward: [-418.825 -418.825 -418.825] [0.0000], Avg: [-491.879 -491.879 -491.879] (1.000)
Step: 66299, Reward: [-814.886 -814.886 -814.886] [0.0000], Avg: [-492.122 -492.122 -492.122] (1.000)
Step: 66349, Reward: [-455.968 -455.968 -455.968] [0.0000], Avg: [-492.095 -492.095 -492.095] (1.000)
Step: 66399, Reward: [-477.259 -477.259 -477.259] [0.0000], Avg: [-492.084 -492.084 -492.084] (1.000)
Step: 66449, Reward: [-566.184 -566.184 -566.184] [0.0000], Avg: [-492.14 -492.14 -492.14] (1.000)
Step: 66499, Reward: [-603.812 -603.812 -603.812] [0.0000], Avg: [-492.224 -492.224 -492.224] (1.000)
Step: 66549, Reward: [-401.526 -401.526 -401.526] [0.0000], Avg: [-492.156 -492.156 -492.156] (1.000)
Step: 66599, Reward: [-416.986 -416.986 -416.986] [0.0000], Avg: [-492.099 -492.099 -492.099] (1.000)
Step: 66649, Reward: [-520.014 -520.014 -520.014] [0.0000], Avg: [-492.12 -492.12 -492.12] (1.000)
Step: 66699, Reward: [-644.246 -644.246 -644.246] [0.0000], Avg: [-492.234 -492.234 -492.234] (1.000)
Step: 66749, Reward: [-416.834 -416.834 -416.834] [0.0000], Avg: [-492.178 -492.178 -492.178] (1.000)
Step: 66799, Reward: [-513.981 -513.981 -513.981] [0.0000], Avg: [-492.194 -492.194 -492.194] (1.000)
Step: 66849, Reward: [-398.208 -398.208 -398.208] [0.0000], Avg: [-492.124 -492.124 -492.124] (1.000)
Step: 66899, Reward: [-467.11 -467.11 -467.11] [0.0000], Avg: [-492.105 -492.105 -492.105] (1.000)
Step: 66949, Reward: [-575.846 -575.846 -575.846] [0.0000], Avg: [-492.168 -492.168 -492.168] (1.000)
Step: 66999, Reward: [-427.29 -427.29 -427.29] [0.0000], Avg: [-492.119 -492.119 -492.119] (1.000)
Step: 67049, Reward: [-461.837 -461.837 -461.837] [0.0000], Avg: [-492.097 -492.097 -492.097] (1.000)
Step: 67099, Reward: [-557.742 -557.742 -557.742] [0.0000], Avg: [-492.145 -492.145 -492.145] (1.000)
Step: 67149, Reward: [-449.581 -449.581 -449.581] [0.0000], Avg: [-492.114 -492.114 -492.114] (1.000)
Step: 67199, Reward: [-335.334 -335.334 -335.334] [0.0000], Avg: [-491.997 -491.997 -491.997] (1.000)
Step: 67249, Reward: [-521.295 -521.295 -521.295] [0.0000], Avg: [-492.019 -492.019 -492.019] (1.000)
Step: 67299, Reward: [-471.837 -471.837 -471.837] [0.0000], Avg: [-492.004 -492.004 -492.004] (1.000)
Step: 67349, Reward: [-548.564 -548.564 -548.564] [0.0000], Avg: [-492.046 -492.046 -492.046] (1.000)
Step: 67399, Reward: [-833.75 -833.75 -833.75] [0.0000], Avg: [-492.299 -492.299 -492.299] (1.000)
Step: 67449, Reward: [-511.986 -511.986 -511.986] [0.0000], Avg: [-492.314 -492.314 -492.314] (1.000)
Step: 67499, Reward: [-423.221 -423.221 -423.221] [0.0000], Avg: [-492.263 -492.263 -492.263] (1.000)
Step: 67549, Reward: [-611.617 -611.617 -611.617] [0.0000], Avg: [-492.351 -492.351 -492.351] (1.000)
Step: 67599, Reward: [-507.019 -507.019 -507.019] [0.0000], Avg: [-492.362 -492.362 -492.362] (1.000)
Step: 67649, Reward: [-777.871 -777.871 -777.871] [0.0000], Avg: [-492.573 -492.573 -492.573] (1.000)
Step: 67699, Reward: [-381.668 -381.668 -381.668] [0.0000], Avg: [-492.491 -492.491 -492.491] (1.000)
Step: 67749, Reward: [-528.178 -528.178 -528.178] [0.0000], Avg: [-492.517 -492.517 -492.517] (1.000)
Step: 67799, Reward: [-750.395 -750.395 -750.395] [0.0000], Avg: [-492.708 -492.708 -492.708] (1.000)
Step: 67849, Reward: [-470.098 -470.098 -470.098] [0.0000], Avg: [-492.691 -492.691 -492.691] (1.000)
Step: 67899, Reward: [-386.878 -386.878 -386.878] [0.0000], Avg: [-492.613 -492.613 -492.613] (1.000)
Step: 67949, Reward: [-340.557 -340.557 -340.557] [0.0000], Avg: [-492.501 -492.501 -492.501] (1.000)
Step: 67999, Reward: [-482.539 -482.539 -482.539] [0.0000], Avg: [-492.494 -492.494 -492.494] (1.000)
Step: 68049, Reward: [-560.147 -560.147 -560.147] [0.0000], Avg: [-492.544 -492.544 -492.544] (1.000)
Step: 68099, Reward: [-721.669 -721.669 -721.669] [0.0000], Avg: [-492.712 -492.712 -492.712] (1.000)
Step: 68149, Reward: [-498.647 -498.647 -498.647] [0.0000], Avg: [-492.716 -492.716 -492.716] (1.000)
Step: 68199, Reward: [-505.816 -505.816 -505.816] [0.0000], Avg: [-492.726 -492.726 -492.726] (1.000)
Step: 68249, Reward: [-424.861 -424.861 -424.861] [0.0000], Avg: [-492.676 -492.676 -492.676] (1.000)
Step: 68299, Reward: [-537.47 -537.47 -537.47] [0.0000], Avg: [-492.709 -492.709 -492.709] (1.000)
Step: 68349, Reward: [-516.964 -516.964 -516.964] [0.0000], Avg: [-492.727 -492.727 -492.727] (1.000)
Step: 68399, Reward: [-645.194 -645.194 -645.194] [0.0000], Avg: [-492.838 -492.838 -492.838] (1.000)
Step: 68449, Reward: [-414.764 -414.764 -414.764] [0.0000], Avg: [-492.781 -492.781 -492.781] (1.000)
Step: 68499, Reward: [-340.193 -340.193 -340.193] [0.0000], Avg: [-492.67 -492.67 -492.67] (1.000)
Step: 68549, Reward: [-715.462 -715.462 -715.462] [0.0000], Avg: [-492.832 -492.832 -492.832] (1.000)
Step: 68599, Reward: [-434.631 -434.631 -434.631] [0.0000], Avg: [-492.79 -492.79 -492.79] (1.000)
Step: 68649, Reward: [-409.068 -409.068 -409.068] [0.0000], Avg: [-492.729 -492.729 -492.729] (1.000)
Step: 68699, Reward: [-588.409 -588.409 -588.409] [0.0000], Avg: [-492.798 -492.798 -492.798] (1.000)
Step: 68749, Reward: [-539.637 -539.637 -539.637] [0.0000], Avg: [-492.832 -492.832 -492.832] (1.000)
Step: 68799, Reward: [-440.244 -440.244 -440.244] [0.0000], Avg: [-492.794 -492.794 -492.794] (1.000)
Step: 68849, Reward: [-832.97 -832.97 -832.97] [0.0000], Avg: [-493.041 -493.041 -493.041] (1.000)
Step: 68899, Reward: [-480.079 -480.079 -480.079] [0.0000], Avg: [-493.032 -493.032 -493.032] (1.000)
Step: 68949, Reward: [-390.791 -390.791 -390.791] [0.0000], Avg: [-492.958 -492.958 -492.958] (1.000)
Step: 68999, Reward: [-387.416 -387.416 -387.416] [0.0000], Avg: [-492.881 -492.881 -492.881] (1.000)
Step: 69049, Reward: [-393.88 -393.88 -393.88] [0.0000], Avg: [-492.809 -492.809 -492.809] (1.000)
Step: 69099, Reward: [-348.021 -348.021 -348.021] [0.0000], Avg: [-492.705 -492.705 -492.705] (1.000)
Step: 69149, Reward: [-453.696 -453.696 -453.696] [0.0000], Avg: [-492.677 -492.677 -492.677] (1.000)
Step: 69199, Reward: [-579.685 -579.685 -579.685] [0.0000], Avg: [-492.739 -492.739 -492.739] (1.000)
Step: 69249, Reward: [-557.811 -557.811 -557.811] [0.0000], Avg: [-492.786 -492.786 -492.786] (1.000)
Step: 69299, Reward: [-588.108 -588.108 -588.108] [0.0000], Avg: [-492.855 -492.855 -492.855] (1.000)
Step: 69349, Reward: [-397.609 -397.609 -397.609] [0.0000], Avg: [-492.786 -492.786 -492.786] (1.000)
Step: 69399, Reward: [-527.029 -527.029 -527.029] [0.0000], Avg: [-492.811 -492.811 -492.811] (1.000)
Step: 69449, Reward: [-499.205 -499.205 -499.205] [0.0000], Avg: [-492.816 -492.816 -492.816] (1.000)
Step: 69499, Reward: [-507.407 -507.407 -507.407] [0.0000], Avg: [-492.826 -492.826 -492.826] (1.000)
Step: 69549, Reward: [-355.802 -355.802 -355.802] [0.0000], Avg: [-492.728 -492.728 -492.728] (1.000)
Step: 69599, Reward: [-640.205 -640.205 -640.205] [0.0000], Avg: [-492.834 -492.834 -492.834] (1.000)
Step: 69649, Reward: [-505.587 -505.587 -505.587] [0.0000], Avg: [-492.843 -492.843 -492.843] (1.000)
Step: 69699, Reward: [-481.222 -481.222 -481.222] [0.0000], Avg: [-492.834 -492.834 -492.834] (1.000)
Step: 69749, Reward: [-483.408 -483.408 -483.408] [0.0000], Avg: [-492.828 -492.828 -492.828] (1.000)
Step: 69799, Reward: [-479.895 -479.895 -479.895] [0.0000], Avg: [-492.818 -492.818 -492.818] (1.000)
Step: 69849, Reward: [-517.964 -517.964 -517.964] [0.0000], Avg: [-492.836 -492.836 -492.836] (1.000)
Step: 69899, Reward: [-446.627 -446.627 -446.627] [0.0000], Avg: [-492.803 -492.803 -492.803] (1.000)
Step: 69949, Reward: [-492.67 -492.67 -492.67] [0.0000], Avg: [-492.803 -492.803 -492.803] (1.000)
Step: 69999, Reward: [-548.31 -548.31 -548.31] [0.0000], Avg: [-492.843 -492.843 -492.843] (1.000)
Step: 70049, Reward: [-492.42 -492.42 -492.42] [0.0000], Avg: [-492.843 -492.843 -492.843] (1.000)
Step: 70099, Reward: [-533.184 -533.184 -533.184] [0.0000], Avg: [-492.871 -492.871 -492.871] (1.000)
Step: 70149, Reward: [-667.421 -667.421 -667.421] [0.0000], Avg: [-492.996 -492.996 -492.996] (1.000)
Step: 70199, Reward: [-445.683 -445.683 -445.683] [0.0000], Avg: [-492.962 -492.962 -492.962] (1.000)
Step: 70249, Reward: [-548.401 -548.401 -548.401] [0.0000], Avg: [-493.002 -493.002 -493.002] (1.000)
Step: 70299, Reward: [-524.124 -524.124 -524.124] [0.0000], Avg: [-493.024 -493.024 -493.024] (1.000)
Step: 70349, Reward: [-507.413 -507.413 -507.413] [0.0000], Avg: [-493.034 -493.034 -493.034] (1.000)
Step: 70399, Reward: [-483.355 -483.355 -483.355] [0.0000], Avg: [-493.027 -493.027 -493.027] (1.000)
Step: 70449, Reward: [-431.621 -431.621 -431.621] [0.0000], Avg: [-492.984 -492.984 -492.984] (1.000)
Step: 70499, Reward: [-536.76 -536.76 -536.76] [0.0000], Avg: [-493.015 -493.015 -493.015] (1.000)
Step: 70549, Reward: [-411.806 -411.806 -411.806] [0.0000], Avg: [-492.957 -492.957 -492.957] (1.000)
Step: 70599, Reward: [-401.379 -401.379 -401.379] [0.0000], Avg: [-492.892 -492.892 -492.892] (1.000)
Step: 70649, Reward: [-419.541 -419.541 -419.541] [0.0000], Avg: [-492.84 -492.84 -492.84] (1.000)
Step: 70699, Reward: [-522.769 -522.769 -522.769] [0.0000], Avg: [-492.861 -492.861 -492.861] (1.000)
Step: 70749, Reward: [-619.772 -619.772 -619.772] [0.0000], Avg: [-492.951 -492.951 -492.951] (1.000)
Step: 70799, Reward: [-585.702 -585.702 -585.702] [0.0000], Avg: [-493.017 -493.017 -493.017] (1.000)
Step: 70849, Reward: [-560.861 -560.861 -560.861] [0.0000], Avg: [-493.064 -493.064 -493.064] (1.000)
Step: 70899, Reward: [-335.93 -335.93 -335.93] [0.0000], Avg: [-492.954 -492.954 -492.954] (1.000)
Step: 70949, Reward: [-463.596 -463.596 -463.596] [0.0000], Avg: [-492.933 -492.933 -492.933] (1.000)
Step: 70999, Reward: [-430.685 -430.685 -430.685] [0.0000], Avg: [-492.889 -492.889 -492.889] (1.000)
Step: 71049, Reward: [-497.691 -497.691 -497.691] [0.0000], Avg: [-492.893 -492.893 -492.893] (1.000)
Step: 71099, Reward: [-448.535 -448.535 -448.535] [0.0000], Avg: [-492.861 -492.861 -492.861] (1.000)
Step: 71149, Reward: [-473.179 -473.179 -473.179] [0.0000], Avg: [-492.847 -492.847 -492.847] (1.000)
Step: 71199, Reward: [-378.332 -378.332 -378.332] [0.0000], Avg: [-492.767 -492.767 -492.767] (1.000)
Step: 71249, Reward: [-449.398 -449.398 -449.398] [0.0000], Avg: [-492.737 -492.737 -492.737] (1.000)
Step: 71299, Reward: [-307.488 -307.488 -307.488] [0.0000], Avg: [-492.607 -492.607 -492.607] (1.000)
Step: 71349, Reward: [-506.695 -506.695 -506.695] [0.0000], Avg: [-492.617 -492.617 -492.617] (1.000)
Step: 71399, Reward: [-486.562 -486.562 -486.562] [0.0000], Avg: [-492.612 -492.612 -492.612] (1.000)
Step: 71449, Reward: [-390.894 -390.894 -390.894] [0.0000], Avg: [-492.541 -492.541 -492.541] (1.000)
Step: 71499, Reward: [-462.49 -462.49 -462.49] [0.0000], Avg: [-492.52 -492.52 -492.52] (1.000)
Step: 71549, Reward: [-473.334 -473.334 -473.334] [0.0000], Avg: [-492.507 -492.507 -492.507] (1.000)
Step: 71599, Reward: [-424.056 -424.056 -424.056] [0.0000], Avg: [-492.459 -492.459 -492.459] (1.000)
Step: 71649, Reward: [-649.345 -649.345 -649.345] [0.0000], Avg: [-492.568 -492.568 -492.568] (1.000)
Step: 71699, Reward: [-514.013 -514.013 -514.013] [0.0000], Avg: [-492.583 -492.583 -492.583] (1.000)
Step: 71749, Reward: [-392.064 -392.064 -392.064] [0.0000], Avg: [-492.513 -492.513 -492.513] (1.000)
Step: 71799, Reward: [-527.272 -527.272 -527.272] [0.0000], Avg: [-492.538 -492.538 -492.538] (1.000)
Step: 71849, Reward: [-441.191 -441.191 -441.191] [0.0000], Avg: [-492.502 -492.502 -492.502] (1.000)
Step: 71899, Reward: [-555.17 -555.17 -555.17] [0.0000], Avg: [-492.545 -492.545 -492.545] (1.000)
Step: 71949, Reward: [-561.951 -561.951 -561.951] [0.0000], Avg: [-492.594 -492.594 -492.594] (1.000)
Step: 71999, Reward: [-570.948 -570.948 -570.948] [0.0000], Avg: [-492.648 -492.648 -492.648] (1.000)
Step: 72049, Reward: [-419.962 -419.962 -419.962] [0.0000], Avg: [-492.598 -492.598 -492.598] (1.000)
Step: 72099, Reward: [-417.158 -417.158 -417.158] [0.0000], Avg: [-492.545 -492.545 -492.545] (1.000)
Step: 72149, Reward: [-491.991 -491.991 -491.991] [0.0000], Avg: [-492.545 -492.545 -492.545] (1.000)
Step: 72199, Reward: [-538.883 -538.883 -538.883] [0.0000], Avg: [-492.577 -492.577 -492.577] (1.000)
Step: 72249, Reward: [-341.096 -341.096 -341.096] [0.0000], Avg: [-492.472 -492.472 -492.472] (1.000)
Step: 72299, Reward: [-509.425 -509.425 -509.425] [0.0000], Avg: [-492.484 -492.484 -492.484] (1.000)
Step: 72349, Reward: [-508.748 -508.748 -508.748] [0.0000], Avg: [-492.495 -492.495 -492.495] (1.000)
Step: 72399, Reward: [-522.537 -522.537 -522.537] [0.0000], Avg: [-492.516 -492.516 -492.516] (1.000)
Step: 72449, Reward: [-488.153 -488.153 -488.153] [0.0000], Avg: [-492.513 -492.513 -492.513] (1.000)
Step: 72499, Reward: [-550.276 -550.276 -550.276] [0.0000], Avg: [-492.553 -492.553 -492.553] (1.000)
Step: 72549, Reward: [-472.501 -472.501 -472.501] [0.0000], Avg: [-492.539 -492.539 -492.539] (1.000)
Step: 72599, Reward: [-432.009 -432.009 -432.009] [0.0000], Avg: [-492.497 -492.497 -492.497] (1.000)
Step: 72649, Reward: [-453.44 -453.44 -453.44] [0.0000], Avg: [-492.47 -492.47 -492.47] (1.000)
Step: 72699, Reward: [-475.132 -475.132 -475.132] [0.0000], Avg: [-492.458 -492.458 -492.458] (1.000)
Step: 72749, Reward: [-772.677 -772.677 -772.677] [0.0000], Avg: [-492.651 -492.651 -492.651] (1.000)
Step: 72799, Reward: [-370.183 -370.183 -370.183] [0.0000], Avg: [-492.567 -492.567 -492.567] (1.000)
Step: 72849, Reward: [-501.782 -501.782 -501.782] [0.0000], Avg: [-492.573 -492.573 -492.573] (1.000)
Step: 72899, Reward: [-411.992 -411.992 -411.992] [0.0000], Avg: [-492.518 -492.518 -492.518] (1.000)
Step: 72949, Reward: [-439.737 -439.737 -439.737] [0.0000], Avg: [-492.482 -492.482 -492.482] (1.000)
Step: 72999, Reward: [-454.178 -454.178 -454.178] [0.0000], Avg: [-492.456 -492.456 -492.456] (1.000)
Step: 73049, Reward: [-634.161 -634.161 -634.161] [0.0000], Avg: [-492.553 -492.553 -492.553] (1.000)
Step: 73099, Reward: [-555.386 -555.386 -555.386] [0.0000], Avg: [-492.595 -492.595 -492.595] (1.000)
Step: 73149, Reward: [-402.414 -402.414 -402.414] [0.0000], Avg: [-492.534 -492.534 -492.534] (1.000)
Step: 73199, Reward: [-373.416 -373.416 -373.416] [0.0000], Avg: [-492.452 -492.452 -492.452] (1.000)
Step: 73249, Reward: [-591.785 -591.785 -591.785] [0.0000], Avg: [-492.52 -492.52 -492.52] (1.000)
Step: 73299, Reward: [-522.061 -522.061 -522.061] [0.0000], Avg: [-492.54 -492.54 -492.54] (1.000)
Step: 73349, Reward: [-474.755 -474.755 -474.755] [0.0000], Avg: [-492.528 -492.528 -492.528] (1.000)
Step: 73399, Reward: [-355.399 -355.399 -355.399] [0.0000], Avg: [-492.435 -492.435 -492.435] (1.000)
Step: 73449, Reward: [-468.307 -468.307 -468.307] [0.0000], Avg: [-492.418 -492.418 -492.418] (1.000)
Step: 73499, Reward: [-532.461 -532.461 -532.461] [0.0000], Avg: [-492.446 -492.446 -492.446] (1.000)
Step: 73549, Reward: [-455.325 -455.325 -455.325] [0.0000], Avg: [-492.42 -492.42 -492.42] (1.000)
Step: 73599, Reward: [-386.738 -386.738 -386.738] [0.0000], Avg: [-492.349 -492.349 -492.349] (1.000)
Step: 73649, Reward: [-519.406 -519.406 -519.406] [0.0000], Avg: [-492.367 -492.367 -492.367] (1.000)
Step: 73699, Reward: [-487.498 -487.498 -487.498] [0.0000], Avg: [-492.364 -492.364 -492.364] (1.000)
Step: 73749, Reward: [-618.485 -618.485 -618.485] [0.0000], Avg: [-492.449 -492.449 -492.449] (1.000)
Step: 73799, Reward: [-508.484 -508.484 -508.484] [0.0000], Avg: [-492.46 -492.46 -492.46] (1.000)
Step: 73849, Reward: [-395.849 -395.849 -395.849] [0.0000], Avg: [-492.395 -492.395 -492.395] (1.000)
Step: 73899, Reward: [-342.292 -342.292 -342.292] [0.0000], Avg: [-492.293 -492.293 -492.293] (1.000)
Step: 73949, Reward: [-438.352 -438.352 -438.352] [0.0000], Avg: [-492.257 -492.257 -492.257] (1.000)
Step: 73999, Reward: [-523.622 -523.622 -523.622] [0.0000], Avg: [-492.278 -492.278 -492.278] (1.000)
Step: 74049, Reward: [-364.214 -364.214 -364.214] [0.0000], Avg: [-492.191 -492.191 -492.191] (1.000)
Step: 74099, Reward: [-455.589 -455.589 -455.589] [0.0000], Avg: [-492.167 -492.167 -492.167] (1.000)
Step: 74149, Reward: [-482.482 -482.482 -482.482] [0.0000], Avg: [-492.16 -492.16 -492.16] (1.000)
Step: 74199, Reward: [-664.943 -664.943 -664.943] [0.0000], Avg: [-492.277 -492.277 -492.277] (1.000)
Step: 74249, Reward: [-325.081 -325.081 -325.081] [0.0000], Avg: [-492.164 -492.164 -492.164] (1.000)
Step: 74299, Reward: [-455.051 -455.051 -455.051] [0.0000], Avg: [-492.139 -492.139 -492.139] (1.000)
Step: 74349, Reward: [-382.77 -382.77 -382.77] [0.0000], Avg: [-492.065 -492.065 -492.065] (1.000)
Step: 74399, Reward: [-450.539 -450.539 -450.539] [0.0000], Avg: [-492.038 -492.038 -492.038] (1.000)
Step: 74449, Reward: [-358.48 -358.48 -358.48] [0.0000], Avg: [-491.948 -491.948 -491.948] (1.000)
Step: 74499, Reward: [-477.286 -477.286 -477.286] [0.0000], Avg: [-491.938 -491.938 -491.938] (1.000)
Step: 74549, Reward: [-547.702 -547.702 -547.702] [0.0000], Avg: [-491.975 -491.975 -491.975] (1.000)
Step: 74599, Reward: [-371.459 -371.459 -371.459] [0.0000], Avg: [-491.895 -491.895 -491.895] (1.000)
Step: 74649, Reward: [-449.203 -449.203 -449.203] [0.0000], Avg: [-491.866 -491.866 -491.866] (1.000)
Step: 74699, Reward: [-488.274 -488.274 -488.274] [0.0000], Avg: [-491.864 -491.864 -491.864] (1.000)
Step: 74749, Reward: [-614.074 -614.074 -614.074] [0.0000], Avg: [-491.945 -491.945 -491.945] (1.000)
Step: 74799, Reward: [-429.084 -429.084 -429.084] [0.0000], Avg: [-491.903 -491.903 -491.903] (1.000)
Step: 74849, Reward: [-448.828 -448.828 -448.828] [0.0000], Avg: [-491.875 -491.875 -491.875] (1.000)
Step: 74899, Reward: [-406.528 -406.528 -406.528] [0.0000], Avg: [-491.818 -491.818 -491.818] (1.000)
Step: 74949, Reward: [-429.934 -429.934 -429.934] [0.0000], Avg: [-491.776 -491.776 -491.776] (1.000)
Step: 74999, Reward: [-393.666 -393.666 -393.666] [0.0000], Avg: [-491.711 -491.711 -491.711] (1.000)
Step: 75049, Reward: [-410.509 -410.509 -410.509] [0.0000], Avg: [-491.657 -491.657 -491.657] (1.000)
Step: 75099, Reward: [-435.048 -435.048 -435.048] [0.0000], Avg: [-491.619 -491.619 -491.619] (1.000)
Step: 75149, Reward: [-508.548 -508.548 -508.548] [0.0000], Avg: [-491.63 -491.63 -491.63] (1.000)
Step: 75199, Reward: [-542.897 -542.897 -542.897] [0.0000], Avg: [-491.665 -491.665 -491.665] (1.000)
Step: 75249, Reward: [-573.76 -573.76 -573.76] [0.0000], Avg: [-491.719 -491.719 -491.719] (1.000)
Step: 75299, Reward: [-486.409 -486.409 -486.409] [0.0000], Avg: [-491.716 -491.716 -491.716] (1.000)
Step: 75349, Reward: [-407.568 -407.568 -407.568] [0.0000], Avg: [-491.66 -491.66 -491.66] (1.000)
Step: 75399, Reward: [-562.704 -562.704 -562.704] [0.0000], Avg: [-491.707 -491.707 -491.707] (1.000)
Step: 75449, Reward: [-472.881 -472.881 -472.881] [0.0000], Avg: [-491.694 -491.694 -491.694] (1.000)
Step: 75499, Reward: [-371.278 -371.278 -371.278] [0.0000], Avg: [-491.615 -491.615 -491.615] (1.000)
Step: 75549, Reward: [-486.642 -486.642 -486.642] [0.0000], Avg: [-491.611 -491.611 -491.611] (1.000)
Step: 75599, Reward: [-519.848 -519.848 -519.848] [0.0000], Avg: [-491.63 -491.63 -491.63] (1.000)
Step: 75649, Reward: [-521.001 -521.001 -521.001] [0.0000], Avg: [-491.649 -491.649 -491.649] (1.000)
Step: 75699, Reward: [-506.017 -506.017 -506.017] [0.0000], Avg: [-491.659 -491.659 -491.659] (1.000)
Step: 75749, Reward: [-417.285 -417.285 -417.285] [0.0000], Avg: [-491.61 -491.61 -491.61] (1.000)
Step: 75799, Reward: [-493.925 -493.925 -493.925] [0.0000], Avg: [-491.611 -491.611 -491.611] (1.000)
Step: 75849, Reward: [-758.572 -758.572 -758.572] [0.0000], Avg: [-491.787 -491.787 -491.787] (1.000)
Step: 75899, Reward: [-415.313 -415.313 -415.313] [0.0000], Avg: [-491.737 -491.737 -491.737] (1.000)
Step: 75949, Reward: [-638.99 -638.99 -638.99] [0.0000], Avg: [-491.834 -491.834 -491.834] (1.000)
Step: 75999, Reward: [-437.469 -437.469 -437.469] [0.0000], Avg: [-491.798 -491.798 -491.798] (1.000)
Step: 76049, Reward: [-382.667 -382.667 -382.667] [0.0000], Avg: [-491.726 -491.726 -491.726] (1.000)
Step: 76099, Reward: [-489.603 -489.603 -489.603] [0.0000], Avg: [-491.725 -491.725 -491.725] (1.000)
Step: 76149, Reward: [-443.546 -443.546 -443.546] [0.0000], Avg: [-491.693 -491.693 -491.693] (1.000)
Step: 76199, Reward: [-481.287 -481.287 -481.287] [0.0000], Avg: [-491.686 -491.686 -491.686] (1.000)
Step: 76249, Reward: [-458.986 -458.986 -458.986] [0.0000], Avg: [-491.665 -491.665 -491.665] (1.000)
Step: 76299, Reward: [-587.562 -587.562 -587.562] [0.0000], Avg: [-491.728 -491.728 -491.728] (1.000)
Step: 76349, Reward: [-563.754 -563.754 -563.754] [0.0000], Avg: [-491.775 -491.775 -491.775] (1.000)
Step: 76399, Reward: [-523.255 -523.255 -523.255] [0.0000], Avg: [-491.796 -491.796 -491.796] (1.000)
Step: 76449, Reward: [-481.074 -481.074 -481.074] [0.0000], Avg: [-491.789 -491.789 -491.789] (1.000)
Step: 76499, Reward: [-999.007 -999.007 -999.007] [0.0000], Avg: [-492.12 -492.12 -492.12] (1.000)
Step: 76549, Reward: [-437.449 -437.449 -437.449] [0.0000], Avg: [-492.084 -492.084 -492.084] (1.000)
Step: 76599, Reward: [-376.646 -376.646 -376.646] [0.0000], Avg: [-492.009 -492.009 -492.009] (1.000)
Step: 76649, Reward: [-415.871 -415.871 -415.871] [0.0000], Avg: [-491.959 -491.959 -491.959] (1.000)
Step: 76699, Reward: [-605.714 -605.714 -605.714] [0.0000], Avg: [-492.034 -492.034 -492.034] (1.000)
Step: 76749, Reward: [-459.645 -459.645 -459.645] [0.0000], Avg: [-492.012 -492.012 -492.012] (1.000)
Step: 76799, Reward: [-560.308 -560.308 -560.308] [0.0000], Avg: [-492.057 -492.057 -492.057] (1.000)
Step: 76849, Reward: [-478.129 -478.129 -478.129] [0.0000], Avg: [-492.048 -492.048 -492.048] (1.000)
Step: 76899, Reward: [-419.868 -419.868 -419.868] [0.0000], Avg: [-492.001 -492.001 -492.001] (1.000)
Step: 76949, Reward: [-351.201 -351.201 -351.201] [0.0000], Avg: [-491.909 -491.909 -491.909] (1.000)
Step: 76999, Reward: [-356.943 -356.943 -356.943] [0.0000], Avg: [-491.822 -491.822 -491.822] (1.000)
Step: 77049, Reward: [-400.683 -400.683 -400.683] [0.0000], Avg: [-491.763 -491.763 -491.763] (1.000)
Step: 77099, Reward: [-495.453 -495.453 -495.453] [0.0000], Avg: [-491.765 -491.765 -491.765] (1.000)
Step: 77149, Reward: [-508.278 -508.278 -508.278] [0.0000], Avg: [-491.776 -491.776 -491.776] (1.000)
Step: 77199, Reward: [-556.739 -556.739 -556.739] [0.0000], Avg: [-491.818 -491.818 -491.818] (1.000)
Step: 77249, Reward: [-490.099 -490.099 -490.099] [0.0000], Avg: [-491.817 -491.817 -491.817] (1.000)
Step: 77299, Reward: [-498.992 -498.992 -498.992] [0.0000], Avg: [-491.821 -491.821 -491.821] (1.000)
Step: 77349, Reward: [-613.797 -613.797 -613.797] [0.0000], Avg: [-491.9 -491.9 -491.9] (1.000)
Step: 77399, Reward: [-601.452 -601.452 -601.452] [0.0000], Avg: [-491.971 -491.971 -491.971] (1.000)
Step: 77449, Reward: [-348.299 -348.299 -348.299] [0.0000], Avg: [-491.878 -491.878 -491.878] (1.000)
Step: 77499, Reward: [-376.548 -376.548 -376.548] [0.0000], Avg: [-491.804 -491.804 -491.804] (1.000)
Step: 77549, Reward: [-468.07 -468.07 -468.07] [0.0000], Avg: [-491.789 -491.789 -491.789] (1.000)
Step: 77599, Reward: [-507.862 -507.862 -507.862] [0.0000], Avg: [-491.799 -491.799 -491.799] (1.000)
Step: 77649, Reward: [-376.535 -376.535 -376.535] [0.0000], Avg: [-491.725 -491.725 -491.725] (1.000)
Step: 77699, Reward: [-403.724 -403.724 -403.724] [0.0000], Avg: [-491.668 -491.668 -491.668] (1.000)
Step: 77749, Reward: [-456.602 -456.602 -456.602] [0.0000], Avg: [-491.645 -491.645 -491.645] (1.000)
Step: 77799, Reward: [-528.654 -528.654 -528.654] [0.0000], Avg: [-491.669 -491.669 -491.669] (1.000)
Step: 77849, Reward: [-497.184 -497.184 -497.184] [0.0000], Avg: [-491.673 -491.673 -491.673] (1.000)
Step: 77899, Reward: [-390.027 -390.027 -390.027] [0.0000], Avg: [-491.608 -491.608 -491.608] (1.000)
Step: 77949, Reward: [-532.103 -532.103 -532.103] [0.0000], Avg: [-491.634 -491.634 -491.634] (1.000)
Step: 77999, Reward: [-538.175 -538.175 -538.175] [0.0000], Avg: [-491.663 -491.663 -491.663] (1.000)
Step: 78049, Reward: [-382.933 -382.933 -382.933] [0.0000], Avg: [-491.594 -491.594 -491.594] (1.000)
Step: 78099, Reward: [-640.561 -640.561 -640.561] [0.0000], Avg: [-491.689 -491.689 -491.689] (1.000)
Step: 78149, Reward: [-424.245 -424.245 -424.245] [0.0000], Avg: [-491.646 -491.646 -491.646] (1.000)
Step: 78199, Reward: [-567.252 -567.252 -567.252] [0.0000], Avg: [-491.694 -491.694 -491.694] (1.000)
Step: 78249, Reward: [-445.571 -445.571 -445.571] [0.0000], Avg: [-491.665 -491.665 -491.665] (1.000)
Step: 78299, Reward: [-721.288 -721.288 -721.288] [0.0000], Avg: [-491.811 -491.811 -491.811] (1.000)
Step: 78349, Reward: [-520.026 -520.026 -520.026] [0.0000], Avg: [-491.829 -491.829 -491.829] (1.000)
Step: 78399, Reward: [-417.043 -417.043 -417.043] [0.0000], Avg: [-491.782 -491.782 -491.782] (1.000)
Step: 78449, Reward: [-603.531 -603.531 -603.531] [0.0000], Avg: [-491.853 -491.853 -491.853] (1.000)
Step: 78499, Reward: [-398.174 -398.174 -398.174] [0.0000], Avg: [-491.793 -491.793 -491.793] (1.000)
Step: 78549, Reward: [-590.769 -590.769 -590.769] [0.0000], Avg: [-491.856 -491.856 -491.856] (1.000)
Step: 78599, Reward: [-480.272 -480.272 -480.272] [0.0000], Avg: [-491.849 -491.849 -491.849] (1.000)
Step: 78649, Reward: [-639.359 -639.359 -639.359] [0.0000], Avg: [-491.943 -491.943 -491.943] (1.000)
Step: 78699, Reward: [-533.754 -533.754 -533.754] [0.0000], Avg: [-491.969 -491.969 -491.969] (1.000)
Step: 78749, Reward: [-483.899 -483.899 -483.899] [0.0000], Avg: [-491.964 -491.964 -491.964] (1.000)
Step: 78799, Reward: [-429.265 -429.265 -429.265] [0.0000], Avg: [-491.924 -491.924 -491.924] (1.000)
Step: 78849, Reward: [-508.923 -508.923 -508.923] [0.0000], Avg: [-491.935 -491.935 -491.935] (1.000)
Step: 78899, Reward: [-547.318 -547.318 -547.318] [0.0000], Avg: [-491.97 -491.97 -491.97] (1.000)
Step: 78949, Reward: [-428.171 -428.171 -428.171] [0.0000], Avg: [-491.93 -491.93 -491.93] (1.000)
Step: 78999, Reward: [-558.766 -558.766 -558.766] [0.0000], Avg: [-491.972 -491.972 -491.972] (1.000)
Step: 79049, Reward: [-443.472 -443.472 -443.472] [0.0000], Avg: [-491.941 -491.941 -491.941] (1.000)
Step: 79099, Reward: [-611.58 -611.58 -611.58] [0.0000], Avg: [-492.017 -492.017 -492.017] (1.000)
Step: 79149, Reward: [-594.276 -594.276 -594.276] [0.0000], Avg: [-492.082 -492.082 -492.082] (1.000)
Step: 79199, Reward: [-393.433 -393.433 -393.433] [0.0000], Avg: [-492.019 -492.019 -492.019] (1.000)
Step: 79249, Reward: [-357.772 -357.772 -357.772] [0.0000], Avg: [-491.935 -491.935 -491.935] (1.000)
Step: 79299, Reward: [-528.708 -528.708 -528.708] [0.0000], Avg: [-491.958 -491.958 -491.958] (1.000)
Step: 79349, Reward: [-597.052 -597.052 -597.052] [0.0000], Avg: [-492.024 -492.024 -492.024] (1.000)
Step: 79399, Reward: [-737.959 -737.959 -737.959] [0.0000], Avg: [-492.179 -492.179 -492.179] (1.000)
Step: 79449, Reward: [-540.294 -540.294 -540.294] [0.0000], Avg: [-492.209 -492.209 -492.209] (1.000)
Step: 79499, Reward: [-433.252 -433.252 -433.252] [0.0000], Avg: [-492.172 -492.172 -492.172] (1.000)
Step: 79549, Reward: [-407.297 -407.297 -407.297] [0.0000], Avg: [-492.119 -492.119 -492.119] (1.000)
Step: 79599, Reward: [-508.678 -508.678 -508.678] [0.0000], Avg: [-492.129 -492.129 -492.129] (1.000)
Step: 79649, Reward: [-636.165 -636.165 -636.165] [0.0000], Avg: [-492.22 -492.22 -492.22] (1.000)
Step: 79699, Reward: [-416.971 -416.971 -416.971] [0.0000], Avg: [-492.172 -492.172 -492.172] (1.000)
Step: 79749, Reward: [-471.509 -471.509 -471.509] [0.0000], Avg: [-492.16 -492.16 -492.16] (1.000)
Step: 79799, Reward: [-485.142 -485.142 -485.142] [0.0000], Avg: [-492.155 -492.155 -492.155] (1.000)
Step: 79849, Reward: [-762.975 -762.975 -762.975] [0.0000], Avg: [-492.325 -492.325 -492.325] (1.000)
Step: 79899, Reward: [-370.255 -370.255 -370.255] [0.0000], Avg: [-492.248 -492.248 -492.248] (1.000)
Step: 79949, Reward: [-435.281 -435.281 -435.281] [0.0000], Avg: [-492.213 -492.213 -492.213] (1.000)
Step: 79999, Reward: [-398.49 -398.49 -398.49] [0.0000], Avg: [-492.154 -492.154 -492.154] (1.000)
Step: 80049, Reward: [-483.514 -483.514 -483.514] [0.0000], Avg: [-492.149 -492.149 -492.149] (1.000)
Step: 80099, Reward: [-759.613 -759.613 -759.613] [0.0000], Avg: [-492.316 -492.316 -492.316] (1.000)
Step: 80149, Reward: [-450.313 -450.313 -450.313] [0.0000], Avg: [-492.289 -492.289 -492.289] (1.000)
Step: 80199, Reward: [-366.194 -366.194 -366.194] [0.0000], Avg: [-492.211 -492.211 -492.211] (1.000)
Step: 80249, Reward: [-633.155 -633.155 -633.155] [0.0000], Avg: [-492.299 -492.299 -492.299] (1.000)
Step: 80299, Reward: [-379.744 -379.744 -379.744] [0.0000], Avg: [-492.229 -492.229 -492.229] (1.000)
Step: 80349, Reward: [-437.787 -437.787 -437.787] [0.0000], Avg: [-492.195 -492.195 -492.195] (1.000)
Step: 80399, Reward: [-669.915 -669.915 -669.915] [0.0000], Avg: [-492.305 -492.305 -492.305] (1.000)
Step: 80449, Reward: [-622.957 -622.957 -622.957] [0.0000], Avg: [-492.386 -492.386 -492.386] (1.000)
Step: 80499, Reward: [-494.412 -494.412 -494.412] [0.0000], Avg: [-492.388 -492.388 -492.388] (1.000)
Step: 80549, Reward: [-403.393 -403.393 -403.393] [0.0000], Avg: [-492.332 -492.332 -492.332] (1.000)
Step: 80599, Reward: [-370.765 -370.765 -370.765] [0.0000], Avg: [-492.257 -492.257 -492.257] (1.000)
Step: 80649, Reward: [-334.563 -334.563 -334.563] [0.0000], Avg: [-492.159 -492.159 -492.159] (1.000)
Step: 80699, Reward: [-503.349 -503.349 -503.349] [0.0000], Avg: [-492.166 -492.166 -492.166] (1.000)
Step: 80749, Reward: [-391.304 -391.304 -391.304] [0.0000], Avg: [-492.104 -492.104 -492.104] (1.000)
Step: 80799, Reward: [-582.004 -582.004 -582.004] [0.0000], Avg: [-492.159 -492.159 -492.159] (1.000)
Step: 80849, Reward: [-429.757 -429.757 -429.757] [0.0000], Avg: [-492.121 -492.121 -492.121] (1.000)
Step: 80899, Reward: [-587.656 -587.656 -587.656] [0.0000], Avg: [-492.18 -492.18 -492.18] (1.000)
Step: 80949, Reward: [-425.37 -425.37 -425.37] [0.0000], Avg: [-492.139 -492.139 -492.139] (1.000)
Step: 80999, Reward: [-531.748 -531.748 -531.748] [0.0000], Avg: [-492.163 -492.163 -492.163] (1.000)
Step: 81049, Reward: [-521.866 -521.866 -521.866] [0.0000], Avg: [-492.181 -492.181 -492.181] (1.000)
Step: 81099, Reward: [-335.113 -335.113 -335.113] [0.0000], Avg: [-492.084 -492.084 -492.084] (1.000)
Step: 81149, Reward: [-422.012 -422.012 -422.012] [0.0000], Avg: [-492.041 -492.041 -492.041] (1.000)
Step: 81199, Reward: [-360.012 -360.012 -360.012] [0.0000], Avg: [-491.96 -491.96 -491.96] (1.000)
Step: 81249, Reward: [-425.82 -425.82 -425.82] [0.0000], Avg: [-491.919 -491.919 -491.919] (1.000)
Step: 81299, Reward: [-414.674 -414.674 -414.674] [0.0000], Avg: [-491.872 -491.872 -491.872] (1.000)
Step: 81349, Reward: [-476.529 -476.529 -476.529] [0.0000], Avg: [-491.862 -491.862 -491.862] (1.000)
Step: 81399, Reward: [-472.091 -472.091 -472.091] [0.0000], Avg: [-491.85 -491.85 -491.85] (1.000)
Step: 81449, Reward: [-467.205 -467.205 -467.205] [0.0000], Avg: [-491.835 -491.835 -491.835] (1.000)
Step: 81499, Reward: [-558.662 -558.662 -558.662] [0.0000], Avg: [-491.876 -491.876 -491.876] (1.000)
Step: 81549, Reward: [-419.446 -419.446 -419.446] [0.0000], Avg: [-491.832 -491.832 -491.832] (1.000)
Step: 81599, Reward: [-721.948 -721.948 -721.948] [0.0000], Avg: [-491.973 -491.973 -491.973] (1.000)
Step: 81649, Reward: [-372.995 -372.995 -372.995] [0.0000], Avg: [-491.9 -491.9 -491.9] (1.000)
Step: 81699, Reward: [-341.866 -341.866 -341.866] [0.0000], Avg: [-491.808 -491.808 -491.808] (1.000)
Step: 81749, Reward: [-460.209 -460.209 -460.209] [0.0000], Avg: [-491.789 -491.789 -491.789] (1.000)
Step: 81799, Reward: [-458.166 -458.166 -458.166] [0.0000], Avg: [-491.768 -491.768 -491.768] (1.000)
Step: 81849, Reward: [-465.497 -465.497 -465.497] [0.0000], Avg: [-491.752 -491.752 -491.752] (1.000)
Step: 81899, Reward: [-666.96 -666.96 -666.96] [0.0000], Avg: [-491.859 -491.859 -491.859] (1.000)
Step: 81949, Reward: [-410.169 -410.169 -410.169] [0.0000], Avg: [-491.809 -491.809 -491.809] (1.000)
Step: 81999, Reward: [-521.287 -521.287 -521.287] [0.0000], Avg: [-491.827 -491.827 -491.827] (1.000)
Step: 82049, Reward: [-431.718 -431.718 -431.718] [0.0000], Avg: [-491.791 -491.791 -491.791] (1.000)
Step: 82099, Reward: [-442.581 -442.581 -442.581] [0.0000], Avg: [-491.761 -491.761 -491.761] (1.000)
Step: 82149, Reward: [-576.522 -576.522 -576.522] [0.0000], Avg: [-491.812 -491.812 -491.812] (1.000)
Step: 82199, Reward: [-453.154 -453.154 -453.154] [0.0000], Avg: [-491.789 -491.789 -491.789] (1.000)
Step: 82249, Reward: [-327.916 -327.916 -327.916] [0.0000], Avg: [-491.689 -491.689 -491.689] (1.000)
Step: 82299, Reward: [-357.529 -357.529 -357.529] [0.0000], Avg: [-491.608 -491.608 -491.608] (1.000)
Step: 82349, Reward: [-368.988 -368.988 -368.988] [0.0000], Avg: [-491.533 -491.533 -491.533] (1.000)
Step: 82399, Reward: [-320.257 -320.257 -320.257] [0.0000], Avg: [-491.429 -491.429 -491.429] (1.000)
Step: 82449, Reward: [-476.471 -476.471 -476.471] [0.0000], Avg: [-491.42 -491.42 -491.42] (1.000)
Step: 82499, Reward: [-418.781 -418.781 -418.781] [0.0000], Avg: [-491.376 -491.376 -491.376] (1.000)
Step: 82549, Reward: [-436.481 -436.481 -436.481] [0.0000], Avg: [-491.343 -491.343 -491.343] (1.000)
Step: 82599, Reward: [-560.972 -560.972 -560.972] [0.0000], Avg: [-491.385 -491.385 -491.385] (1.000)
Step: 82649, Reward: [-537.796 -537.796 -537.796] [0.0000], Avg: [-491.413 -491.413 -491.413] (1.000)
Step: 82699, Reward: [-663.568 -663.568 -663.568] [0.0000], Avg: [-491.517 -491.517 -491.517] (1.000)
Step: 82749, Reward: [-380.397 -380.397 -380.397] [0.0000], Avg: [-491.45 -491.45 -491.45] (1.000)
Step: 82799, Reward: [-628.821 -628.821 -628.821] [0.0000], Avg: [-491.533 -491.533 -491.533] (1.000)
Step: 82849, Reward: [-568.834 -568.834 -568.834] [0.0000], Avg: [-491.58 -491.58 -491.58] (1.000)
Step: 82899, Reward: [-396.456 -396.456 -396.456] [0.0000], Avg: [-491.522 -491.522 -491.522] (1.000)
Step: 82949, Reward: [-438.2 -438.2 -438.2] [0.0000], Avg: [-491.49 -491.49 -491.49] (1.000)
Step: 82999, Reward: [-536.817 -536.817 -536.817] [0.0000], Avg: [-491.517 -491.517 -491.517] (1.000)
Step: 83049, Reward: [-451.298 -451.298 -451.298] [0.0000], Avg: [-491.493 -491.493 -491.493] (1.000)
Step: 83099, Reward: [-456.797 -456.797 -456.797] [0.0000], Avg: [-491.472 -491.472 -491.472] (1.000)
Step: 83149, Reward: [-558.697 -558.697 -558.697] [0.0000], Avg: [-491.513 -491.513 -491.513] (1.000)
Step: 83199, Reward: [-520.682 -520.682 -520.682] [0.0000], Avg: [-491.53 -491.53 -491.53] (1.000)
Step: 83249, Reward: [-498.831 -498.831 -498.831] [0.0000], Avg: [-491.535 -491.535 -491.535] (1.000)
Step: 83299, Reward: [-609.746 -609.746 -609.746] [0.0000], Avg: [-491.606 -491.606 -491.606] (1.000)
Step: 83349, Reward: [-460.682 -460.682 -460.682] [0.0000], Avg: [-491.587 -491.587 -491.587] (1.000)
Step: 83399, Reward: [-434.869 -434.869 -434.869] [0.0000], Avg: [-491.553 -491.553 -491.553] (1.000)
Step: 83449, Reward: [-580.888 -580.888 -580.888] [0.0000], Avg: [-491.607 -491.607 -491.607] (1.000)
Step: 83499, Reward: [-607.319 -607.319 -607.319] [0.0000], Avg: [-491.676 -491.676 -491.676] (1.000)
Step: 83549, Reward: [-452.926 -452.926 -452.926] [0.0000], Avg: [-491.653 -491.653 -491.653] (1.000)
Step: 83599, Reward: [-445.109 -445.109 -445.109] [0.0000], Avg: [-491.625 -491.625 -491.625] (1.000)
Step: 83649, Reward: [-374.722 -374.722 -374.722] [0.0000], Avg: [-491.555 -491.555 -491.555] (1.000)
Step: 83699, Reward: [-516.774 -516.774 -516.774] [0.0000], Avg: [-491.57 -491.57 -491.57] (1.000)
Step: 83749, Reward: [-497.615 -497.615 -497.615] [0.0000], Avg: [-491.574 -491.574 -491.574] (1.000)
Step: 83799, Reward: [-571.924 -571.924 -571.924] [0.0000], Avg: [-491.622 -491.622 -491.622] (1.000)
Step: 83849, Reward: [-592.839 -592.839 -592.839] [0.0000], Avg: [-491.682 -491.682 -491.682] (1.000)
Step: 83899, Reward: [-482.572 -482.572 -482.572] [0.0000], Avg: [-491.676 -491.676 -491.676] (1.000)
Step: 83949, Reward: [-700.62 -700.62 -700.62] [0.0000], Avg: [-491.801 -491.801 -491.801] (1.000)
Step: 83999, Reward: [-488.844 -488.844 -488.844] [0.0000], Avg: [-491.799 -491.799 -491.799] (1.000)
Step: 84049, Reward: [-397.564 -397.564 -397.564] [0.0000], Avg: [-491.743 -491.743 -491.743] (1.000)
Step: 84099, Reward: [-495.791 -495.791 -495.791] [0.0000], Avg: [-491.746 -491.746 -491.746] (1.000)
Step: 84149, Reward: [-415.443 -415.443 -415.443] [0.0000], Avg: [-491.7 -491.7 -491.7] (1.000)
Step: 84199, Reward: [-475.024 -475.024 -475.024] [0.0000], Avg: [-491.69 -491.69 -491.69] (1.000)
Step: 84249, Reward: [-420.993 -420.993 -420.993] [0.0000], Avg: [-491.648 -491.648 -491.648] (1.000)
Step: 84299, Reward: [-820.975 -820.975 -820.975] [0.0000], Avg: [-491.844 -491.844 -491.844] (1.000)
Step: 84349, Reward: [-384.985 -384.985 -384.985] [0.0000], Avg: [-491.78 -491.78 -491.78] (1.000)
Step: 84399, Reward: [-464.995 -464.995 -464.995] [0.0000], Avg: [-491.764 -491.764 -491.764] (1.000)
Step: 84449, Reward: [-439.591 -439.591 -439.591] [0.0000], Avg: [-491.734 -491.734 -491.734] (1.000)
Step: 84499, Reward: [-464.21 -464.21 -464.21] [0.0000], Avg: [-491.717 -491.717 -491.717] (1.000)
Step: 84549, Reward: [-506.311 -506.311 -506.311] [0.0000], Avg: [-491.726 -491.726 -491.726] (1.000)
Step: 84599, Reward: [-458.536 -458.536 -458.536] [0.0000], Avg: [-491.706 -491.706 -491.706] (1.000)
Step: 84649, Reward: [-505.381 -505.381 -505.381] [0.0000], Avg: [-491.714 -491.714 -491.714] (1.000)
Step: 84699, Reward: [-397.617 -397.617 -397.617] [0.0000], Avg: [-491.659 -491.659 -491.659] (1.000)
Step: 84749, Reward: [-543.017 -543.017 -543.017] [0.0000], Avg: [-491.689 -491.689 -491.689] (1.000)
Step: 84799, Reward: [-412.314 -412.314 -412.314] [0.0000], Avg: [-491.642 -491.642 -491.642] (1.000)
Step: 84849, Reward: [-383.802 -383.802 -383.802] [0.0000], Avg: [-491.579 -491.579 -491.579] (1.000)
Step: 84899, Reward: [-587.073 -587.073 -587.073] [0.0000], Avg: [-491.635 -491.635 -491.635] (1.000)
Step: 84949, Reward: [-502.375 -502.375 -502.375] [0.0000], Avg: [-491.641 -491.641 -491.641] (1.000)
Step: 84999, Reward: [-381.049 -381.049 -381.049] [0.0000], Avg: [-491.576 -491.576 -491.576] (1.000)
Step: 85049, Reward: [-429.624 -429.624 -429.624] [0.0000], Avg: [-491.54 -491.54 -491.54] (1.000)
Step: 85099, Reward: [-623.574 -623.574 -623.574] [0.0000], Avg: [-491.617 -491.617 -491.617] (1.000)
Step: 85149, Reward: [-352.635 -352.635 -352.635] [0.0000], Avg: [-491.536 -491.536 -491.536] (1.000)
Step: 85199, Reward: [-581.553 -581.553 -581.553] [0.0000], Avg: [-491.589 -491.589 -491.589] (1.000)
Step: 85249, Reward: [-660.912 -660.912 -660.912] [0.0000], Avg: [-491.688 -491.688 -491.688] (1.000)
Step: 85299, Reward: [-541.693 -541.693 -541.693] [0.0000], Avg: [-491.717 -491.717 -491.717] (1.000)
Step: 85349, Reward: [-535.321 -535.321 -535.321] [0.0000], Avg: [-491.743 -491.743 -491.743] (1.000)
Step: 85399, Reward: [-303.852 -303.852 -303.852] [0.0000], Avg: [-491.633 -491.633 -491.633] (1.000)
Step: 85449, Reward: [-488.673 -488.673 -488.673] [0.0000], Avg: [-491.631 -491.631 -491.631] (1.000)
Step: 85499, Reward: [-398.679 -398.679 -398.679] [0.0000], Avg: [-491.577 -491.577 -491.577] (1.000)
Step: 85549, Reward: [-597.335 -597.335 -597.335] [0.0000], Avg: [-491.639 -491.639 -491.639] (1.000)
Step: 85599, Reward: [-475.89 -475.89 -475.89] [0.0000], Avg: [-491.629 -491.629 -491.629] (1.000)
Step: 85649, Reward: [-454.568 -454.568 -454.568] [0.0000], Avg: [-491.608 -491.608 -491.608] (1.000)
Step: 85699, Reward: [-500.883 -500.883 -500.883] [0.0000], Avg: [-491.613 -491.613 -491.613] (1.000)
Step: 85749, Reward: [-323.22 -323.22 -323.22] [0.0000], Avg: [-491.515 -491.515 -491.515] (1.000)
Step: 85799, Reward: [-327.133 -327.133 -327.133] [0.0000], Avg: [-491.419 -491.419 -491.419] (1.000)
Step: 85849, Reward: [-687.708 -687.708 -687.708] [0.0000], Avg: [-491.533 -491.533 -491.533] (1.000)
Step: 85899, Reward: [-378.524 -378.524 -378.524] [0.0000], Avg: [-491.468 -491.468 -491.468] (1.000)
Step: 85949, Reward: [-527.562 -527.562 -527.562] [0.0000], Avg: [-491.489 -491.489 -491.489] (1.000)
Step: 85999, Reward: [-562.603 -562.603 -562.603] [0.0000], Avg: [-491.53 -491.53 -491.53] (1.000)
Step: 86049, Reward: [-489.438 -489.438 -489.438] [0.0000], Avg: [-491.529 -491.529 -491.529] (1.000)
Step: 86099, Reward: [-471.829 -471.829 -471.829] [0.0000], Avg: [-491.517 -491.517 -491.517] (1.000)
Step: 86149, Reward: [-385.906 -385.906 -385.906] [0.0000], Avg: [-491.456 -491.456 -491.456] (1.000)
Step: 86199, Reward: [-614.314 -614.314 -614.314] [0.0000], Avg: [-491.527 -491.527 -491.527] (1.000)
Step: 86249, Reward: [-399.782 -399.782 -399.782] [0.0000], Avg: [-491.474 -491.474 -491.474] (1.000)
Step: 86299, Reward: [-712.49 -712.49 -712.49] [0.0000], Avg: [-491.602 -491.602 -491.602] (1.000)
Step: 86349, Reward: [-746.942 -746.942 -746.942] [0.0000], Avg: [-491.75 -491.75 -491.75] (1.000)
Step: 86399, Reward: [-436.095 -436.095 -436.095] [0.0000], Avg: [-491.718 -491.718 -491.718] (1.000)
Step: 86449, Reward: [-447.66 -447.66 -447.66] [0.0000], Avg: [-491.692 -491.692 -491.692] (1.000)
Step: 86499, Reward: [-483.625 -483.625 -483.625] [0.0000], Avg: [-491.688 -491.688 -491.688] (1.000)
Step: 86549, Reward: [-501.467 -501.467 -501.467] [0.0000], Avg: [-491.693 -491.693 -491.693] (1.000)
Step: 86599, Reward: [-1141.023 -1141.023 -1141.023] [0.0000], Avg: [-492.068 -492.068 -492.068] (1.000)
Step: 86649, Reward: [-416.516 -416.516 -416.516] [0.0000], Avg: [-492.025 -492.025 -492.025] (1.000)
Step: 86699, Reward: [-613.685 -613.685 -613.685] [0.0000], Avg: [-492.095 -492.095 -492.095] (1.000)
Step: 86749, Reward: [-402.295 -402.295 -402.295] [0.0000], Avg: [-492.043 -492.043 -492.043] (1.000)
Step: 86799, Reward: [-733.932 -733.932 -733.932] [0.0000], Avg: [-492.182 -492.182 -492.182] (1.000)
Step: 86849, Reward: [-540.628 -540.628 -540.628] [0.0000], Avg: [-492.21 -492.21 -492.21] (1.000)
Step: 86899, Reward: [-522.391 -522.391 -522.391] [0.0000], Avg: [-492.228 -492.228 -492.228] (1.000)
Step: 86949, Reward: [-444.308 -444.308 -444.308] [0.0000], Avg: [-492.2 -492.2 -492.2] (1.000)
Step: 86999, Reward: [-544.775 -544.775 -544.775] [0.0000], Avg: [-492.23 -492.23 -492.23] (1.000)
Step: 87049, Reward: [-552.417 -552.417 -552.417] [0.0000], Avg: [-492.265 -492.265 -492.265] (1.000)
Step: 87099, Reward: [-423.904 -423.904 -423.904] [0.0000], Avg: [-492.226 -492.226 -492.226] (1.000)
Step: 87149, Reward: [-573.388 -573.388 -573.388] [0.0000], Avg: [-492.272 -492.272 -492.272] (1.000)
Step: 87199, Reward: [-314.701 -314.701 -314.701] [0.0000], Avg: [-492.17 -492.17 -492.17] (1.000)
Step: 87249, Reward: [-499.92 -499.92 -499.92] [0.0000], Avg: [-492.175 -492.175 -492.175] (1.000)
Step: 87299, Reward: [-490.133 -490.133 -490.133] [0.0000], Avg: [-492.174 -492.174 -492.174] (1.000)
Step: 87349, Reward: [-604.413 -604.413 -604.413] [0.0000], Avg: [-492.238 -492.238 -492.238] (1.000)
Step: 87399, Reward: [-585.04 -585.04 -585.04] [0.0000], Avg: [-492.291 -492.291 -492.291] (1.000)
Step: 87449, Reward: [-507.525 -507.525 -507.525] [0.0000], Avg: [-492.3 -492.3 -492.3] (1.000)
Step: 87499, Reward: [-560.637 -560.637 -560.637] [0.0000], Avg: [-492.339 -492.339 -492.339] (1.000)
Step: 87549, Reward: [-477.457 -477.457 -477.457] [0.0000], Avg: [-492.33 -492.33 -492.33] (1.000)
Step: 87599, Reward: [-676.895 -676.895 -676.895] [0.0000], Avg: [-492.436 -492.436 -492.436] (1.000)
Step: 87649, Reward: [-473.03 -473.03 -473.03] [0.0000], Avg: [-492.425 -492.425 -492.425] (1.000)
Step: 87699, Reward: [-647.274 -647.274 -647.274] [0.0000], Avg: [-492.513 -492.513 -492.513] (1.000)
Step: 87749, Reward: [-455.264 -455.264 -455.264] [0.0000], Avg: [-492.492 -492.492 -492.492] (1.000)
Step: 87799, Reward: [-500.491 -500.491 -500.491] [0.0000], Avg: [-492.496 -492.496 -492.496] (1.000)
Step: 87849, Reward: [-438.123 -438.123 -438.123] [0.0000], Avg: [-492.465 -492.465 -492.465] (1.000)
Step: 87899, Reward: [-598.712 -598.712 -598.712] [0.0000], Avg: [-492.526 -492.526 -492.526] (1.000)
Step: 87949, Reward: [-560.436 -560.436 -560.436] [0.0000], Avg: [-492.564 -492.564 -492.564] (1.000)
Step: 87999, Reward: [-392.301 -392.301 -392.301] [0.0000], Avg: [-492.507 -492.507 -492.507] (1.000)
Step: 88049, Reward: [-405.462 -405.462 -405.462] [0.0000], Avg: [-492.458 -492.458 -492.458] (1.000)
Step: 88099, Reward: [-430.868 -430.868 -430.868] [0.0000], Avg: [-492.423 -492.423 -492.423] (1.000)
Step: 88149, Reward: [-496.537 -496.537 -496.537] [0.0000], Avg: [-492.425 -492.425 -492.425] (1.000)
Step: 88199, Reward: [-638.823 -638.823 -638.823] [0.0000], Avg: [-492.508 -492.508 -492.508] (1.000)
Step: 88249, Reward: [-537.355 -537.355 -537.355] [0.0000], Avg: [-492.534 -492.534 -492.534] (1.000)
Step: 88299, Reward: [-567.337 -567.337 -567.337] [0.0000], Avg: [-492.576 -492.576 -492.576] (1.000)
Step: 88349, Reward: [-441.228 -441.228 -441.228] [0.0000], Avg: [-492.547 -492.547 -492.547] (1.000)
Step: 88399, Reward: [-611.992 -611.992 -611.992] [0.0000], Avg: [-492.614 -492.614 -492.614] (1.000)
Step: 88449, Reward: [-373.881 -373.881 -373.881] [0.0000], Avg: [-492.547 -492.547 -492.547] (1.000)
Step: 88499, Reward: [-393.901 -393.901 -393.901] [0.0000], Avg: [-492.492 -492.492 -492.492] (1.000)
Step: 88549, Reward: [-420.417 -420.417 -420.417] [0.0000], Avg: [-492.451 -492.451 -492.451] (1.000)
Step: 88599, Reward: [-511.527 -511.527 -511.527] [0.0000], Avg: [-492.462 -492.462 -492.462] (1.000)
Step: 88649, Reward: [-427.075 -427.075 -427.075] [0.0000], Avg: [-492.425 -492.425 -492.425] (1.000)
Step: 88699, Reward: [-596.53 -596.53 -596.53] [0.0000], Avg: [-492.483 -492.483 -492.483] (1.000)
Step: 88749, Reward: [-364.008 -364.008 -364.008] [0.0000], Avg: [-492.411 -492.411 -492.411] (1.000)
Step: 88799, Reward: [-551.348 -551.348 -551.348] [0.0000], Avg: [-492.444 -492.444 -492.444] (1.000)
Step: 88849, Reward: [-474.702 -474.702 -474.702] [0.0000], Avg: [-492.434 -492.434 -492.434] (1.000)
Step: 88899, Reward: [-352.063 -352.063 -352.063] [0.0000], Avg: [-492.355 -492.355 -492.355] (1.000)
Step: 88949, Reward: [-465.64 -465.64 -465.64] [0.0000], Avg: [-492.34 -492.34 -492.34] (1.000)
Step: 88999, Reward: [-544.667 -544.667 -544.667] [0.0000], Avg: [-492.37 -492.37 -492.37] (1.000)
Step: 89049, Reward: [-419.531 -419.531 -419.531] [0.0000], Avg: [-492.329 -492.329 -492.329] (1.000)
Step: 89099, Reward: [-423.061 -423.061 -423.061] [0.0000], Avg: [-492.29 -492.29 -492.29] (1.000)
Step: 89149, Reward: [-384.071 -384.071 -384.071] [0.0000], Avg: [-492.229 -492.229 -492.229] (1.000)
Step: 89199, Reward: [-400.006 -400.006 -400.006] [0.0000], Avg: [-492.178 -492.178 -492.178] (1.000)
Step: 89249, Reward: [-599.623 -599.623 -599.623] [0.0000], Avg: [-492.238 -492.238 -492.238] (1.000)
Step: 89299, Reward: [-367.514 -367.514 -367.514] [0.0000], Avg: [-492.168 -492.168 -492.168] (1.000)
Step: 89349, Reward: [-598.025 -598.025 -598.025] [0.0000], Avg: [-492.227 -492.227 -492.227] (1.000)
Step: 89399, Reward: [-340.411 -340.411 -340.411] [0.0000], Avg: [-492.142 -492.142 -492.142] (1.000)
Step: 89449, Reward: [-329.236 -329.236 -329.236] [0.0000], Avg: [-492.051 -492.051 -492.051] (1.000)
Step: 89499, Reward: [-531.095 -531.095 -531.095] [0.0000], Avg: [-492.073 -492.073 -492.073] (1.000)
Step: 89549, Reward: [-474.045 -474.045 -474.045] [0.0000], Avg: [-492.063 -492.063 -492.063] (1.000)
Step: 89599, Reward: [-387.718 -387.718 -387.718] [0.0000], Avg: [-492.005 -492.005 -492.005] (1.000)
Step: 89649, Reward: [-354.604 -354.604 -354.604] [0.0000], Avg: [-491.928 -491.928 -491.928] (1.000)
Step: 89699, Reward: [-469.526 -469.526 -469.526] [0.0000], Avg: [-491.916 -491.916 -491.916] (1.000)
Step: 89749, Reward: [-563.217 -563.217 -563.217] [0.0000], Avg: [-491.955 -491.955 -491.955] (1.000)
Step: 89799, Reward: [-401.665 -401.665 -401.665] [0.0000], Avg: [-491.905 -491.905 -491.905] (1.000)
Step: 89849, Reward: [-502.761 -502.761 -502.761] [0.0000], Avg: [-491.911 -491.911 -491.911] (1.000)
Step: 89899, Reward: [-468.354 -468.354 -468.354] [0.0000], Avg: [-491.898 -491.898 -491.898] (1.000)
Step: 89949, Reward: [-451.634 -451.634 -451.634] [0.0000], Avg: [-491.876 -491.876 -491.876] (1.000)
Step: 89999, Reward: [-485.442 -485.442 -485.442] [0.0000], Avg: [-491.872 -491.872 -491.872] (1.000)
Step: 90049, Reward: [-628.719 -628.719 -628.719] [0.0000], Avg: [-491.948 -491.948 -491.948] (1.000)
Step: 90099, Reward: [-550.958 -550.958 -550.958] [0.0000], Avg: [-491.981 -491.981 -491.981] (1.000)
Step: 90149, Reward: [-559.24 -559.24 -559.24] [0.0000], Avg: [-492.018 -492.018 -492.018] (1.000)
Step: 90199, Reward: [-513.894 -513.894 -513.894] [0.0000], Avg: [-492.03 -492.03 -492.03] (1.000)
Step: 90249, Reward: [-604.933 -604.933 -604.933] [0.0000], Avg: [-492.093 -492.093 -492.093] (1.000)
Step: 90299, Reward: [-460.115 -460.115 -460.115] [0.0000], Avg: [-492.075 -492.075 -492.075] (1.000)
Step: 90349, Reward: [-635.532 -635.532 -635.532] [0.0000], Avg: [-492.154 -492.154 -492.154] (1.000)
Step: 90399, Reward: [-392.162 -392.162 -392.162] [0.0000], Avg: [-492.099 -492.099 -492.099] (1.000)
Step: 90449, Reward: [-814.007 -814.007 -814.007] [0.0000], Avg: [-492.277 -492.277 -492.277] (1.000)
Step: 90499, Reward: [-430.963 -430.963 -430.963] [0.0000], Avg: [-492.243 -492.243 -492.243] (1.000)
Step: 90549, Reward: [-565.89 -565.89 -565.89] [0.0000], Avg: [-492.284 -492.284 -492.284] (1.000)
Step: 90599, Reward: [-523.423 -523.423 -523.423] [0.0000], Avg: [-492.301 -492.301 -492.301] (1.000)
Step: 90649, Reward: [-379.16 -379.16 -379.16] [0.0000], Avg: [-492.239 -492.239 -492.239] (1.000)
Step: 90699, Reward: [-429.219 -429.219 -429.219] [0.0000], Avg: [-492.204 -492.204 -492.204] (1.000)
Step: 90749, Reward: [-471.67 -471.67 -471.67] [0.0000], Avg: [-492.193 -492.193 -492.193] (1.000)
Step: 90799, Reward: [-746.065 -746.065 -746.065] [0.0000], Avg: [-492.332 -492.332 -492.332] (1.000)
Step: 90849, Reward: [-359.489 -359.489 -359.489] [0.0000], Avg: [-492.259 -492.259 -492.259] (1.000)
Step: 90899, Reward: [-423.871 -423.871 -423.871] [0.0000], Avg: [-492.222 -492.222 -492.222] (1.000)
Step: 90949, Reward: [-584.417 -584.417 -584.417] [0.0000], Avg: [-492.272 -492.272 -492.272] (1.000)
Step: 90999, Reward: [-529.121 -529.121 -529.121] [0.0000], Avg: [-492.293 -492.293 -492.293] (1.000)
Step: 91049, Reward: [-533.233 -533.233 -533.233] [0.0000], Avg: [-492.315 -492.315 -492.315] (1.000)
Step: 91099, Reward: [-571.418 -571.418 -571.418] [0.0000], Avg: [-492.358 -492.358 -492.358] (1.000)
Step: 91149, Reward: [-589.69 -589.69 -589.69] [0.0000], Avg: [-492.412 -492.412 -492.412] (1.000)
Step: 91199, Reward: [-607.002 -607.002 -607.002] [0.0000], Avg: [-492.475 -492.475 -492.475] (1.000)
Step: 91249, Reward: [-421.972 -421.972 -421.972] [0.0000], Avg: [-492.436 -492.436 -492.436] (1.000)
Step: 91299, Reward: [-364.204 -364.204 -364.204] [0.0000], Avg: [-492.366 -492.366 -492.366] (1.000)
Step: 91349, Reward: [-516.447 -516.447 -516.447] [0.0000], Avg: [-492.379 -492.379 -492.379] (1.000)
Step: 91399, Reward: [-440.514 -440.514 -440.514] [0.0000], Avg: [-492.351 -492.351 -492.351] (1.000)
Step: 91449, Reward: [-528.56 -528.56 -528.56] [0.0000], Avg: [-492.37 -492.37 -492.37] (1.000)
Step: 91499, Reward: [-508.226 -508.226 -508.226] [0.0000], Avg: [-492.379 -492.379 -492.379] (1.000)
Step: 91549, Reward: [-376.714 -376.714 -376.714] [0.0000], Avg: [-492.316 -492.316 -492.316] (1.000)
Step: 91599, Reward: [-645.031 -645.031 -645.031] [0.0000], Avg: [-492.399 -492.399 -492.399] (1.000)
Step: 91649, Reward: [-572.683 -572.683 -572.683] [0.0000], Avg: [-492.443 -492.443 -492.443] (1.000)
Step: 91699, Reward: [-385.776 -385.776 -385.776] [0.0000], Avg: [-492.385 -492.385 -492.385] (1.000)
Step: 91749, Reward: [-461.808 -461.808 -461.808] [0.0000], Avg: [-492.368 -492.368 -492.368] (1.000)
Step: 91799, Reward: [-519.574 -519.574 -519.574] [0.0000], Avg: [-492.383 -492.383 -492.383] (1.000)
Step: 91849, Reward: [-672.207 -672.207 -672.207] [0.0000], Avg: [-492.481 -492.481 -492.481] (1.000)
Step: 91899, Reward: [-405.317 -405.317 -405.317] [0.0000], Avg: [-492.434 -492.434 -492.434] (1.000)
Step: 91949, Reward: [-390.5 -390.5 -390.5] [0.0000], Avg: [-492.378 -492.378 -492.378] (1.000)
Step: 91999, Reward: [-592.961 -592.961 -592.961] [0.0000], Avg: [-492.433 -492.433 -492.433] (1.000)
Step: 92049, Reward: [-518.078 -518.078 -518.078] [0.0000], Avg: [-492.447 -492.447 -492.447] (1.000)
Step: 92099, Reward: [-500.024 -500.024 -500.024] [0.0000], Avg: [-492.451 -492.451 -492.451] (1.000)
Step: 92149, Reward: [-664.996 -664.996 -664.996] [0.0000], Avg: [-492.544 -492.544 -492.544] (1.000)
Step: 92199, Reward: [-484.555 -484.555 -484.555] [0.0000], Avg: [-492.54 -492.54 -492.54] (1.000)
Step: 92249, Reward: [-420.68 -420.68 -420.68] [0.0000], Avg: [-492.501 -492.501 -492.501] (1.000)
Step: 92299, Reward: [-556.874 -556.874 -556.874] [0.0000], Avg: [-492.536 -492.536 -492.536] (1.000)
Step: 92349, Reward: [-739.747 -739.747 -739.747] [0.0000], Avg: [-492.67 -492.67 -492.67] (1.000)
Step: 92399, Reward: [-389.593 -389.593 -389.593] [0.0000], Avg: [-492.614 -492.614 -492.614] (1.000)
Step: 92449, Reward: [-547.202 -547.202 -547.202] [0.0000], Avg: [-492.644 -492.644 -492.644] (1.000)
Step: 92499, Reward: [-521.004 -521.004 -521.004] [0.0000], Avg: [-492.659 -492.659 -492.659] (1.000)
Step: 92549, Reward: [-704.846 -704.846 -704.846] [0.0000], Avg: [-492.774 -492.774 -492.774] (1.000)
Step: 92599, Reward: [-451.429 -451.429 -451.429] [0.0000], Avg: [-492.751 -492.751 -492.751] (1.000)
Step: 92649, Reward: [-578.627 -578.627 -578.627] [0.0000], Avg: [-492.798 -492.798 -492.798] (1.000)
Step: 92699, Reward: [-510.565 -510.565 -510.565] [0.0000], Avg: [-492.807 -492.807 -492.807] (1.000)
Step: 92749, Reward: [-642.144 -642.144 -642.144] [0.0000], Avg: [-492.888 -492.888 -492.888] (1.000)
Step: 92799, Reward: [-443.852 -443.852 -443.852] [0.0000], Avg: [-492.861 -492.861 -492.861] (1.000)
Step: 92849, Reward: [-548.92 -548.92 -548.92] [0.0000], Avg: [-492.891 -492.891 -492.891] (1.000)
Step: 92899, Reward: [-558.09 -558.09 -558.09] [0.0000], Avg: [-492.927 -492.927 -492.927] (1.000)
Step: 92949, Reward: [-592.29 -592.29 -592.29] [0.0000], Avg: [-492.98 -492.98 -492.98] (1.000)
Step: 92999, Reward: [-469.866 -469.866 -469.866] [0.0000], Avg: [-492.968 -492.968 -492.968] (1.000)
Step: 93049, Reward: [-554.67 -554.67 -554.67] [0.0000], Avg: [-493.001 -493.001 -493.001] (1.000)
Step: 93099, Reward: [-409.461 -409.461 -409.461] [0.0000], Avg: [-492.956 -492.956 -492.956] (1.000)
Step: 93149, Reward: [-624.446 -624.446 -624.446] [0.0000], Avg: [-493.026 -493.026 -493.026] (1.000)
Step: 93199, Reward: [-594.823 -594.823 -594.823] [0.0000], Avg: [-493.081 -493.081 -493.081] (1.000)
Step: 93249, Reward: [-478.109 -478.109 -478.109] [0.0000], Avg: [-493.073 -493.073 -493.073] (1.000)
Step: 93299, Reward: [-420.635 -420.635 -420.635] [0.0000], Avg: [-493.034 -493.034 -493.034] (1.000)
Step: 93349, Reward: [-419.348 -419.348 -419.348] [0.0000], Avg: [-492.995 -492.995 -492.995] (1.000)
Step: 93399, Reward: [-415.58 -415.58 -415.58] [0.0000], Avg: [-492.953 -492.953 -492.953] (1.000)
Step: 93449, Reward: [-736.265 -736.265 -736.265] [0.0000], Avg: [-493.084 -493.084 -493.084] (1.000)
Step: 93499, Reward: [-620.964 -620.964 -620.964] [0.0000], Avg: [-493.152 -493.152 -493.152] (1.000)
Step: 93549, Reward: [-559.971 -559.971 -559.971] [0.0000], Avg: [-493.188 -493.188 -493.188] (1.000)
Step: 93599, Reward: [-561.285 -561.285 -561.285] [0.0000], Avg: [-493.224 -493.224 -493.224] (1.000)
Step: 93649, Reward: [-486.1 -486.1 -486.1] [0.0000], Avg: [-493.22 -493.22 -493.22] (1.000)
Step: 93699, Reward: [-467.734 -467.734 -467.734] [0.0000], Avg: [-493.207 -493.207 -493.207] (1.000)
Step: 93749, Reward: [-536.448 -536.448 -536.448] [0.0000], Avg: [-493.23 -493.23 -493.23] (1.000)
Step: 93799, Reward: [-433.06 -433.06 -433.06] [0.0000], Avg: [-493.198 -493.198 -493.198] (1.000)
Step: 93849, Reward: [-485.753 -485.753 -485.753] [0.0000], Avg: [-493.194 -493.194 -493.194] (1.000)
Step: 93899, Reward: [-513.847 -513.847 -513.847] [0.0000], Avg: [-493.205 -493.205 -493.205] (1.000)
Step: 93949, Reward: [-340.658 -340.658 -340.658] [0.0000], Avg: [-493.123 -493.123 -493.123] (1.000)
Step: 93999, Reward: [-502.3 -502.3 -502.3] [0.0000], Avg: [-493.128 -493.128 -493.128] (1.000)
Step: 94049, Reward: [-689.96 -689.96 -689.96] [0.0000], Avg: [-493.233 -493.233 -493.233] (1.000)
Step: 94099, Reward: [-362.65 -362.65 -362.65] [0.0000], Avg: [-493.164 -493.164 -493.164] (1.000)
Step: 94149, Reward: [-524.292 -524.292 -524.292] [0.0000], Avg: [-493.18 -493.18 -493.18] (1.000)
Step: 94199, Reward: [-511.373 -511.373 -511.373] [0.0000], Avg: [-493.19 -493.19 -493.19] (1.000)
Step: 94249, Reward: [-419.081 -419.081 -419.081] [0.0000], Avg: [-493.15 -493.15 -493.15] (1.000)
Step: 94299, Reward: [-506.919 -506.919 -506.919] [0.0000], Avg: [-493.158 -493.158 -493.158] (1.000)
Step: 94349, Reward: [-521.374 -521.374 -521.374] [0.0000], Avg: [-493.173 -493.173 -493.173] (1.000)
Step: 94399, Reward: [-422.922 -422.922 -422.922] [0.0000], Avg: [-493.135 -493.135 -493.135] (1.000)
Step: 94449, Reward: [-488.471 -488.471 -488.471] [0.0000], Avg: [-493.133 -493.133 -493.133] (1.000)
Step: 94499, Reward: [-526.87 -526.87 -526.87] [0.0000], Avg: [-493.151 -493.151 -493.151] (1.000)
Step: 94549, Reward: [-456.191 -456.191 -456.191] [0.0000], Avg: [-493.131 -493.131 -493.131] (1.000)
Step: 94599, Reward: [-441.068 -441.068 -441.068] [0.0000], Avg: [-493.104 -493.104 -493.104] (1.000)
Step: 94649, Reward: [-484.531 -484.531 -484.531] [0.0000], Avg: [-493.099 -493.099 -493.099] (1.000)
Step: 94699, Reward: [-538.739 -538.739 -538.739] [0.0000], Avg: [-493.123 -493.123 -493.123] (1.000)
Step: 94749, Reward: [-497.776 -497.776 -497.776] [0.0000], Avg: [-493.126 -493.126 -493.126] (1.000)
Step: 94799, Reward: [-591.452 -591.452 -591.452] [0.0000], Avg: [-493.178 -493.178 -493.178] (1.000)
Step: 94849, Reward: [-885.486 -885.486 -885.486] [0.0000], Avg: [-493.384 -493.384 -493.384] (1.000)
Step: 94899, Reward: [-601.315 -601.315 -601.315] [0.0000], Avg: [-493.441 -493.441 -493.441] (1.000)
Step: 94949, Reward: [-422.074 -422.074 -422.074] [0.0000], Avg: [-493.404 -493.404 -493.404] (1.000)
Step: 94999, Reward: [-625.568 -625.568 -625.568] [0.0000], Avg: [-493.473 -493.473 -493.473] (1.000)
Step: 95049, Reward: [-454.222 -454.222 -454.222] [0.0000], Avg: [-493.453 -493.453 -493.453] (1.000)
Step: 95099, Reward: [-846.957 -846.957 -846.957] [0.0000], Avg: [-493.639 -493.639 -493.639] (1.000)
Step: 95149, Reward: [-346.106 -346.106 -346.106] [0.0000], Avg: [-493.561 -493.561 -493.561] (1.000)
Step: 95199, Reward: [-549.017 -549.017 -549.017] [0.0000], Avg: [-493.59 -493.59 -493.59] (1.000)
Step: 95249, Reward: [-564.885 -564.885 -564.885] [0.0000], Avg: [-493.628 -493.628 -493.628] (1.000)
Step: 95299, Reward: [-418.882 -418.882 -418.882] [0.0000], Avg: [-493.588 -493.588 -493.588] (1.000)
Step: 95349, Reward: [-410.644 -410.644 -410.644] [0.0000], Avg: [-493.545 -493.545 -493.545] (1.000)
Step: 95399, Reward: [-530.077 -530.077 -530.077] [0.0000], Avg: [-493.564 -493.564 -493.564] (1.000)
Step: 95449, Reward: [-522.031 -522.031 -522.031] [0.0000], Avg: [-493.579 -493.579 -493.579] (1.000)
Step: 95499, Reward: [-418.615 -418.615 -418.615] [0.0000], Avg: [-493.54 -493.54 -493.54] (1.000)
Step: 95549, Reward: [-402.894 -402.894 -402.894] [0.0000], Avg: [-493.492 -493.492 -493.492] (1.000)
Step: 95599, Reward: [-402.21 -402.21 -402.21] [0.0000], Avg: [-493.444 -493.444 -493.444] (1.000)
Step: 95649, Reward: [-435.788 -435.788 -435.788] [0.0000], Avg: [-493.414 -493.414 -493.414] (1.000)
Step: 95699, Reward: [-458.122 -458.122 -458.122] [0.0000], Avg: [-493.396 -493.396 -493.396] (1.000)
Step: 95749, Reward: [-604.605 -604.605 -604.605] [0.0000], Avg: [-493.454 -493.454 -493.454] (1.000)
Step: 95799, Reward: [-476.035 -476.035 -476.035] [0.0000], Avg: [-493.445 -493.445 -493.445] (1.000)
Step: 95849, Reward: [-560.249 -560.249 -560.249] [0.0000], Avg: [-493.48 -493.48 -493.48] (1.000)
Step: 95899, Reward: [-529.744 -529.744 -529.744] [0.0000], Avg: [-493.499 -493.499 -493.499] (1.000)
Step: 95949, Reward: [-455.423 -455.423 -455.423] [0.0000], Avg: [-493.479 -493.479 -493.479] (1.000)
Step: 95999, Reward: [-354.356 -354.356 -354.356] [0.0000], Avg: [-493.406 -493.406 -493.406] (1.000)
Step: 96049, Reward: [-414.21 -414.21 -414.21] [0.0000], Avg: [-493.365 -493.365 -493.365] (1.000)
Step: 96099, Reward: [-515.037 -515.037 -515.037] [0.0000], Avg: [-493.376 -493.376 -493.376] (1.000)
Step: 96149, Reward: [-459.635 -459.635 -459.635] [0.0000], Avg: [-493.359 -493.359 -493.359] (1.000)
Step: 96199, Reward: [-524.917 -524.917 -524.917] [0.0000], Avg: [-493.375 -493.375 -493.375] (1.000)
Step: 96249, Reward: [-541.219 -541.219 -541.219] [0.0000], Avg: [-493.4 -493.4 -493.4] (1.000)
Step: 96299, Reward: [-482.22 -482.22 -482.22] [0.0000], Avg: [-493.394 -493.394 -493.394] (1.000)
Step: 96349, Reward: [-442.029 -442.029 -442.029] [0.0000], Avg: [-493.368 -493.368 -493.368] (1.000)
Step: 96399, Reward: [-501.724 -501.724 -501.724] [0.0000], Avg: [-493.372 -493.372 -493.372] (1.000)
Step: 96449, Reward: [-402.687 -402.687 -402.687] [0.0000], Avg: [-493.325 -493.325 -493.325] (1.000)
Step: 96499, Reward: [-476.003 -476.003 -476.003] [0.0000], Avg: [-493.316 -493.316 -493.316] (1.000)
Step: 96549, Reward: [-432.228 -432.228 -432.228] [0.0000], Avg: [-493.284 -493.284 -493.284] (1.000)
Step: 96599, Reward: [-501.892 -501.892 -501.892] [0.0000], Avg: [-493.289 -493.289 -493.289] (1.000)
Step: 96649, Reward: [-394.951 -394.951 -394.951] [0.0000], Avg: [-493.238 -493.238 -493.238] (1.000)
Step: 96699, Reward: [-518.381 -518.381 -518.381] [0.0000], Avg: [-493.251 -493.251 -493.251] (1.000)
Step: 96749, Reward: [-384.68 -384.68 -384.68] [0.0000], Avg: [-493.195 -493.195 -493.195] (1.000)
Step: 96799, Reward: [-372.222 -372.222 -372.222] [0.0000], Avg: [-493.132 -493.132 -493.132] (1.000)
Step: 96849, Reward: [-524.033 -524.033 -524.033] [0.0000], Avg: [-493.148 -493.148 -493.148] (1.000)
Step: 96899, Reward: [-375.299 -375.299 -375.299] [0.0000], Avg: [-493.087 -493.087 -493.087] (1.000)
Step: 96949, Reward: [-412.467 -412.467 -412.467] [0.0000], Avg: [-493.046 -493.046 -493.046] (1.000)
Step: 96999, Reward: [-609.812 -609.812 -609.812] [0.0000], Avg: [-493.106 -493.106 -493.106] (1.000)
Step: 97049, Reward: [-453.511 -453.511 -453.511] [0.0000], Avg: [-493.086 -493.086 -493.086] (1.000)
Step: 97099, Reward: [-429.318 -429.318 -429.318] [0.0000], Avg: [-493.053 -493.053 -493.053] (1.000)
Step: 97149, Reward: [-427.607 -427.607 -427.607] [0.0000], Avg: [-493.019 -493.019 -493.019] (1.000)
Step: 97199, Reward: [-868.533 -868.533 -868.533] [0.0000], Avg: [-493.212 -493.212 -493.212] (1.000)
Step: 97249, Reward: [-404.556 -404.556 -404.556] [0.0000], Avg: [-493.167 -493.167 -493.167] (1.000)
Step: 97299, Reward: [-506.224 -506.224 -506.224] [0.0000], Avg: [-493.173 -493.173 -493.173] (1.000)
Step: 97349, Reward: [-642.419 -642.419 -642.419] [0.0000], Avg: [-493.25 -493.25 -493.25] (1.000)
Step: 97399, Reward: [-413.914 -413.914 -413.914] [0.0000], Avg: [-493.209 -493.209 -493.209] (1.000)
Step: 97449, Reward: [-459.647 -459.647 -459.647] [0.0000], Avg: [-493.192 -493.192 -493.192] (1.000)
Step: 97499, Reward: [-460.623 -460.623 -460.623] [0.0000], Avg: [-493.175 -493.175 -493.175] (1.000)
Step: 97549, Reward: [-364.488 -364.488 -364.488] [0.0000], Avg: [-493.11 -493.11 -493.11] (1.000)
Step: 97599, Reward: [-540.786 -540.786 -540.786] [0.0000], Avg: [-493.134 -493.134 -493.134] (1.000)
Step: 97649, Reward: [-393.82 -393.82 -393.82] [0.0000], Avg: [-493.083 -493.083 -493.083] (1.000)
Step: 97699, Reward: [-583.946 -583.946 -583.946] [0.0000], Avg: [-493.13 -493.13 -493.13] (1.000)
Step: 97749, Reward: [-431.58 -431.58 -431.58] [0.0000], Avg: [-493.098 -493.098 -493.098] (1.000)
Step: 97799, Reward: [-517.98 -517.98 -517.98] [0.0000], Avg: [-493.111 -493.111 -493.111] (1.000)
Step: 97849, Reward: [-582.144 -582.144 -582.144] [0.0000], Avg: [-493.156 -493.156 -493.156] (1.000)
Step: 97899, Reward: [-531.161 -531.161 -531.161] [0.0000], Avg: [-493.176 -493.176 -493.176] (1.000)
Step: 97949, Reward: [-322.264 -322.264 -322.264] [0.0000], Avg: [-493.088 -493.088 -493.088] (1.000)
Step: 97999, Reward: [-608.7 -608.7 -608.7] [0.0000], Avg: [-493.147 -493.147 -493.147] (1.000)
Step: 98049, Reward: [-386.458 -386.458 -386.458] [0.0000], Avg: [-493.093 -493.093 -493.093] (1.000)
Step: 98099, Reward: [-524.456 -524.456 -524.456] [0.0000], Avg: [-493.109 -493.109 -493.109] (1.000)
Step: 98149, Reward: [-405.627 -405.627 -405.627] [0.0000], Avg: [-493.064 -493.064 -493.064] (1.000)
Step: 98199, Reward: [-409.948 -409.948 -409.948] [0.0000], Avg: [-493.022 -493.022 -493.022] (1.000)
Step: 98249, Reward: [-354.614 -354.614 -354.614] [0.0000], Avg: [-492.952 -492.952 -492.952] (1.000)
Step: 98299, Reward: [-484.475 -484.475 -484.475] [0.0000], Avg: [-492.947 -492.947 -492.947] (1.000)
Step: 98349, Reward: [-416.025 -416.025 -416.025] [0.0000], Avg: [-492.908 -492.908 -492.908] (1.000)
Step: 98399, Reward: [-527.398 -527.398 -527.398] [0.0000], Avg: [-492.926 -492.926 -492.926] (1.000)
Step: 98449, Reward: [-482.683 -482.683 -482.683] [0.0000], Avg: [-492.921 -492.921 -492.921] (1.000)
Step: 98499, Reward: [-462.295 -462.295 -462.295] [0.0000], Avg: [-492.905 -492.905 -492.905] (1.000)
Step: 98549, Reward: [-540.869 -540.869 -540.869] [0.0000], Avg: [-492.929 -492.929 -492.929] (1.000)
Step: 98599, Reward: [-454.146 -454.146 -454.146] [0.0000], Avg: [-492.91 -492.91 -492.91] (1.000)
Step: 98649, Reward: [-444.588 -444.588 -444.588] [0.0000], Avg: [-492.885 -492.885 -492.885] (1.000)
Step: 98699, Reward: [-414.458 -414.458 -414.458] [0.0000], Avg: [-492.846 -492.846 -492.846] (1.000)
Step: 98749, Reward: [-452.792 -452.792 -452.792] [0.0000], Avg: [-492.825 -492.825 -492.825] (1.000)
Step: 98799, Reward: [-419.677 -419.677 -419.677] [0.0000], Avg: [-492.788 -492.788 -492.788] (1.000)
Step: 98849, Reward: [-557.208 -557.208 -557.208] [0.0000], Avg: [-492.821 -492.821 -492.821] (1.000)
Step: 98899, Reward: [-447.568 -447.568 -447.568] [0.0000], Avg: [-492.798 -492.798 -492.798] (1.000)
Step: 98949, Reward: [-618.72 -618.72 -618.72] [0.0000], Avg: [-492.862 -492.862 -492.862] (1.000)
Step: 98999, Reward: [-422.24 -422.24 -422.24] [0.0000], Avg: [-492.826 -492.826 -492.826] (1.000)
Step: 99049, Reward: [-429.465 -429.465 -429.465] [0.0000], Avg: [-492.794 -492.794 -492.794] (1.000)
Step: 99099, Reward: [-484.779 -484.779 -484.779] [0.0000], Avg: [-492.79 -492.79 -492.79] (1.000)
Step: 99149, Reward: [-692.976 -692.976 -692.976] [0.0000], Avg: [-492.891 -492.891 -492.891] (1.000)
Step: 99199, Reward: [-533.153 -533.153 -533.153] [0.0000], Avg: [-492.911 -492.911 -492.911] (1.000)
Step: 99249, Reward: [-457.338 -457.338 -457.338] [0.0000], Avg: [-492.893 -492.893 -492.893] (1.000)
Step: 99299, Reward: [-533.892 -533.892 -533.892] [0.0000], Avg: [-492.914 -492.914 -492.914] (1.000)
Step: 99349, Reward: [-539.075 -539.075 -539.075] [0.0000], Avg: [-492.937 -492.937 -492.937] (1.000)
Step: 99399, Reward: [-515.823 -515.823 -515.823] [0.0000], Avg: [-492.949 -492.949 -492.949] (1.000)
Step: 99449, Reward: [-574.546 -574.546 -574.546] [0.0000], Avg: [-492.99 -492.99 -492.99] (1.000)
Step: 99499, Reward: [-437.197 -437.197 -437.197] [0.0000], Avg: [-492.962 -492.962 -492.962] (1.000)
Step: 99549, Reward: [-466.513 -466.513 -466.513] [0.0000], Avg: [-492.948 -492.948 -492.948] (1.000)
Step: 99599, Reward: [-524.251 -524.251 -524.251] [0.0000], Avg: [-492.964 -492.964 -492.964] (1.000)
Step: 99649, Reward: [-574.332 -574.332 -574.332] [0.0000], Avg: [-493.005 -493.005 -493.005] (1.000)
Step: 99699, Reward: [-463.832 -463.832 -463.832] [0.0000], Avg: [-492.99 -492.99 -492.99] (1.000)
Step: 99749, Reward: [-612.658 -612.658 -612.658] [0.0000], Avg: [-493.05 -493.05 -493.05] (1.000)
Step: 99799, Reward: [-467.082 -467.082 -467.082] [0.0000], Avg: [-493.037 -493.037 -493.037] (1.000)
Step: 99849, Reward: [-506.335 -506.335 -506.335] [0.0000], Avg: [-493.044 -493.044 -493.044] (1.000)
Step: 99899, Reward: [-573.166 -573.166 -573.166] [0.0000], Avg: [-493.084 -493.084 -493.084] (1.000)
Step: 99949, Reward: [-419.675 -419.675 -419.675] [0.0000], Avg: [-493.047 -493.047 -493.047] (1.000)
Step: 99999, Reward: [-450.715 -450.715 -450.715] [0.0000], Avg: [-493.026 -493.026 -493.026] (1.000)
