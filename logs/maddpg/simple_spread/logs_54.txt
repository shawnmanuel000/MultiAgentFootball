Model: <class 'multiagent.maddpg.MADDPGAgent'>, Dir: simple_spread
num_envs: 1, state_size: [(1, 18), (1, 18), (1, 18)], action_size: [[1, 5], [1, 5], [1, 5]], action_space: [<gym.spaces.multi_discrete.MultiDiscrete object at 0x7f8ec881fa20>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f8ec881fac8>, <gym.spaces.multi_discrete.MultiDiscrete object at 0x7f8ec881fb38>],

import torch
import random
import numpy as np
from models.rand import MultiagentReplayBuffer
from models.ddpg import DDPGActor, DDPGCritic, DDPGNetwork
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACAgent, LEARN_RATE, NUM_STEPS, EPS_MIN, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, MAX_BUFFER_SIZE, gumbel_softmax, one_hot

REPLAY_BATCH_SIZE = 1024
ENTROPY_WEIGHT = 0.001			# The weight for the entropy term of the Actor loss
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64
LEARN_RATE = 0.01
TARGET_UPDATE_RATE = 0.01

class MADDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, sample=True):
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		action_mu = self.action_mu(state)
		action = gumbel_softmax(action_mu, hard=True)
		action = action.view(*out_dims, -1)
		return action
	
class MADDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1]+action_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.norm = torch.nn.BatchNorm1d(state_size[-1]+action_size[-1])
		self.norm.weight.data.fill_(1)
		self.norm.bias.data.fill_(0)

	def forward(self, state, action):
		state = torch.cat([state, action], -1)
		out_dims = state.size()[:-1]
		state = state.view(int(np.prod(out_dims)), -1)
		state = self.norm(state) if state.shape[0]>1 else state
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		q_value = self.q_value(state)
		q_value = q_value.view(*out_dims, -1)
		return q_value

class MADDPGNetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=True, load=None):
		super().__init__(tau=tau, gpu=gpu)
		self.state_size = state_size
		self.action_size = action_size
		self.critic = MADDPGCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.models = [DDPGNetwork(s_size, a_size, MADDPGActor, lambda s,a: self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		
	def get_action_probs(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [model.get_action(s, use_target, grad, numpy, sample) for s,model in zip(state, self.models)]
			return action

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_value = [model.get_q_value(state, action, use_target, grad, numpy) for model in self.models]
			return q_value

	def optimize(self, states, actions, states_joint, actions_joint, q_targets, e_weight=ENTROPY_WEIGHT):
		for (i,model),state,q_target in zip(enumerate(self.models), states, q_targets):
			q_values = model.get_q_value(states_joint, actions_joint, grad=True, numpy=False)
			critic_error = q_values[:q_target.size(0)] - q_target.detach()
			critic_loss = critic_error.pow(2)
			model.step(model.critic_optimizer, critic_loss.mean(), param_norm=model.critic_local.parameters())
			model.soft_copy(model.critic_local, model.critic_target)

			actor_action = model.get_action(state, grad=True, numpy=False)
			critic_action = [actor_action if j==i else other.get_action(states[j], numpy=False) for j,other in enumerate(self.models)]
			action_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(critic_action, self.action_size)], dim=-1)
			q_actions = model.critic_local(states_joint, action_joint)
			actor_loss = -q_actions.mean() + e_weight*actor_action.pow(2).mean()
			model.step(model.actor_optimizer, actor_loss.mean(), param_norm=model.actor_local.parameters())
			model.soft_copy(model.actor_local, model.actor_target)

	def save_model(self, dirname="pytorch", name="best"):
		[model.save_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="best"):
		[model.load_model("maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class MADDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, MADDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.agent = MADDPG(state_size, action_size)
		self.replay_buffer = MultiagentReplayBuffer(MAX_BUFFER_SIZE, self.agent.nagents, [obsp[-1] for obsp in state_size], [acsp[-1] for acsp in action_size])

	def get_action(self, state, eps=None, sample=True, numpy=True):
		state = [torch.autograd.Variable(torch.Tensor(np.vstack(state[i])), requires_grad=False) for i in range(self.agent.nagents)]
		torch_agent_actions = self.agent.step(state)
		agent_actions = [ac.data.numpy() for ac in torch_agent_actions]
		return agent_actions
		# eps = self.eps if eps is None else eps
		# action_random = super().get_action(state)
		# action_greedy = self.network.get_action_probs(self.to_tensor(state), sample=sample, numpy=numpy)
		# action = [(1-eps)*a_greedy + eps*a_random for a_greedy,a_random in zip(action_greedy, action_random)]
		# return action

	def train(self, state, action, next_state, reward, done):
		if not hasattr(self, "t"): self.t = 0
		self.replay_buffer.push(state, action, next_state, reward, done)
		if (len(self.replay_buffer) >= 1024 and (self.t % 100)==0):
			# self.agent.prep_training(device='cpu')
			sample = self.replay_buffer.sample(1024, to_gpu=False)
			for a_i in range(self.agent.nagents):
				self.agent.update(sample, a_i)
			# self.agent.update_all_targets()
			# self.agent.prep_rollouts(device='cpu')
		self.t += 1
		"""
			# self.buffer.append((state, action, reward, done))
			# if np.any(done[0]) or len(self.buffer) >= self.update_freq:
			# 	states, actions, rewards, dones = map(lambda x: self.to_tensor(x), zip(*self.buffer))
			# 	self.buffer.clear()
			# 	next_state = self.to_tensor(next_state)
			# 	states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, next_state)]
			# 	actions = [torch.cat([a, na.unsqueeze(0)], dim=0) for a,na in zip(actions, self.network.get_action_probs(next_state, use_target=True))]
			# 	states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			# 	actions_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions, self.action_size)], dim=-1)
			# 	q_values = self.network.get_q_value(states_joint, actions_joint, use_target=True)
			# 	q_targets = [self.compute_gae(q_value[-1], reward.unsqueeze(-1), done.unsqueeze(-1), q_value[:-1])[0] for q_value,reward,done in zip(q_values, rewards, dones)]
				
			# 	to_stack = lambda items: list(zip(*[x.view(-1, *x.shape[2:]).cpu().numpy() for x in items]))
			# 	states, actions, states_joint, actions_joint = map(lambda items: [x[:-1] for x in items], [states, actions, [states_joint], [actions_joint]])
			# 	states, actions, states_joint, actions_joint, q_targets = map(to_stack, [states, actions, states_joint, actions_joint, q_targets])
			# 	self.replay_buffer.extend(list(zip(states, actions, states_joint, actions_joint, q_targets)), shuffle=False)	
			# if len(self.replay_buffer) > REPLAY_BATCH_SIZE:
			# 	states, actions, states_joint, actions_joint, q_targets = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
			# 	self.network.optimize(states, actions, states_joint[0], actions_joint[0], q_targets)
			# if np.any(done[0]): self.eps = max(self.eps * self.decay, EPS_MIN)
		"""

class MADDPG():
	def __init__(self, state_size, action_size, gamma=0.95, tau=0.01, lr=0.01):
		self.tau = tau
		self.gamma = gamma
		self.nagents = len(state_size)
		num_in_critic = np.sum([np.prod(s) for s in state_size]) + np.sum([np.prod(a) for a in action_size])
		self.agents = [DDPGAgent(s_size[-1], a_size[-1], num_in_critic) for s_size, a_size in zip(state_size, action_size)]

	@property
	def policies(self):
		return [a.policy for a in self.agents]

	@property
	def target_policies(self):
		return [a.target_policy for a in self.agents]

	def step(self, states):
		return [gumbel_softmax(a.policy(obs), hard=True) for a, obs in zip(self.agents, states)]

	def update(self, sample, agent_i, parallel=False, logger=None):
		states, actions, next_states, rewards, dones = sample
		curr_agent = self.agents[agent_i]

		all_trgt_acs = [one_hot(pi(nobs)) for pi, nobs in zip(self.target_policies, next_states)]
		trgt_vf_in = torch.cat((*next_states, *all_trgt_acs), dim=1)
		target_value = (rewards[agent_i].view(-1, 1) + self.gamma * curr_agent.target_critic(trgt_vf_in) * (1 - dones[agent_i].view(-1, 1)))

		critic_inputs = torch.cat((*states, *actions), dim=1)
		actual_value = curr_agent.critic(critic_inputs)
		vf_loss = (actual_value - target_value.detach()).pow(2).mean()
		curr_agent.step(curr_agent.critic_optimizer, vf_loss, param_norm=curr_agent.critic.parameters())
		curr_agent.soft_copy(curr_agent.critic, curr_agent.target_critic)

		# curr_agent.critic_optimizer.zero_grad()
		# vf_loss.backward()
		# torch.nn.utils.clip_grad_norm_(curr_agent.critic.parameters(), 0.5)
		# curr_agent.critic_optimizer.step()

		curr_pol_out = curr_agent.policy(states[agent_i])
		curr_pol_vf_in = gumbel_softmax(curr_pol_out, hard=True)
		all_pol_acs = [curr_pol_vf_in if i==agent_i else one_hot(pi(ob)) for i, pi, ob in zip(range(self.nagents), self.policies, states)]
		critic_inputs = torch.cat((*states, *all_pol_acs), dim=1)
		pol_loss = -curr_agent.critic(critic_inputs).mean() + 0.001*(curr_pol_out**2).mean() 
		curr_agent.step(curr_agent.policy_optimizer, pol_loss, param_norm=curr_agent.policy.parameters())
		curr_agent.soft_copy(curr_agent.policy, curr_agent.target_policy)

		# curr_agent.policy_optimizer.zero_grad()
		# pol_loss.backward()
		# torch.nn.utils.clip_grad_norm_(curr_agent.policy.parameters(), 0.5)
		# curr_agent.policy_optimizer.step()

	def update_all_targets(self):
		for a in self.agents:
			a.soft_copy(a.critic, a.target_critic)
			a.soft_copy(a.policy, a.target_policy)
			# for target_param, param in zip(a.target_critic.parameters(), a.critic.parameters()):
			# 	target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)
			# for target_param, param in zip(a.target_policy.parameters(), a.policy.parameters()):
			# 	target_param.data.copy_(target_param.data * (1.0 - self.tau) + param.data * self.tau)
		# self.niter += 1

	# def prep_training(self, device='gpu'):
	# 	for a in self.agents:
	# 		a.policy.train()
	# 		a.critic.train()
	# 		a.target_policy.train()
	# 		a.target_critic.train()

	# def prep_rollouts(self, device='cpu'):
	# 	for a in self.agents:
	# 		a.policy.eval()

class DDPGAgent(object):
	def __init__(self, num_in_pol, num_out_pol, num_in_critic, hidden_dim=64, lr=0.01, tau=0.01):
		self.policy = MLPNetwork(num_in_pol, num_out_pol, hidden_dim=hidden_dim)
		self.target_policy = MLPNetwork(num_in_pol, num_out_pol, hidden_dim=hidden_dim)
		self.policy_optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr)
		
		self.critic = MLPNetwork(num_in_critic, 1, hidden_dim=hidden_dim)
		self.target_critic = MLPNetwork(num_in_critic, 1, hidden_dim=hidden_dim)
		self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr)
		
		self.tau = tau
		# for target_param, param in zip(self.target_policy.parameters(), self.policy.parameters()):
		# 	target_param.data.copy_(param.data)
		# for target_param, param in zip(self.target_critic.parameters(), self.critic.parameters()):
		# 	target_param.data.copy_(param.data)

	def soft_copy(self, local, target):
		for t,l in zip(target.parameters(), local.parameters()):
			t.data.copy_(t.data + self.tau*(l.data - t.data))

	def step(self, optimizer, loss, retain=False, param_norm=None):
		optimizer.zero_grad()
		loss.backward(retain_graph=retain)
		if param_norm is not None: torch.nn.utils.clip_grad_norm_(param_norm, 0.5)
		optimizer.step()

	# def step(self, obs, explore=False):
	# 	action = self.policy(obs)
	# 	if explore:
	# 		action = gumbel_softmax(action, hard=True)
	# 	else:
	# 		action = one_hot(action)
	# 	return action

class MLPNetwork(torch.nn.Module):
	def __init__(self, input_dim, out_dim, hidden_dim=64):
		super().__init__()

		# if norm_in:  # normalize inputs
		# 	self.in_fn = nn.BatchNorm1d(input_dim)
		# 	self.in_fn.weight.data.fill_(1)
		# 	self.in_fn.bias.data.fill_(0)
		# else:
		# 	self.in_fn = lambda x: x
		self.fc1 = torch.nn.Linear(input_dim, hidden_dim)
		self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)
		self.fc3 = torch.nn.Linear(hidden_dim, out_dim)
		# self.nonlin = nonlin
		# if constrain_out and not discrete_action:
		# 	self.fc3.weight.data.uniform_(-3e-3, 3e-3)
		# 	self.out_fn = torch.tanh
		# 	raise EnvironmentError()
		# else:  # logits for discrete action (will softmax later)
		# 	self.out_fn = lambda x: x

	def forward(self, X):
		h1 = self.fc1(X).relu()
		h2 = self.fc2(h1).relu()
		action = self.fc3(h2)
		return action
REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.900             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)
# np.random.seed(1)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return gym.make(env_name)
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":0} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env)

def run(model, steps=10000, ports=16, env_name=env_name, eval_at=1000, checkpoint=False, save_best=False, log=True, render=True):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports, render=False, env_name=env_name)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, num_envs=num_envs, gpu=False, agent2=RandomAgent) 
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if np.any(dones[0]):
			rollouts = [rollout(envs.env, agent.reset(1), render=render) for _ in range(1)]
			test_reward = np.mean(rollouts, axis=0) - np.std(rollouts, axis=0)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if save_best and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts, axis=0)} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")
			agent.reset(num_envs)

def trial(model):
	envs = EnsembleEnv(make_env, 0, log=True, render=True)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, load=f"{env_name}")
	print(f"Reward: {rollout(envs.env, agent, eps=0.02, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[1], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="maddpg", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--test", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.test:
		trial(model)
	elif args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		run(model, args.steps, args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)

Step: 49, Reward: [-533.621 -533.621 -533.621] [0.0000], Avg: [-533.621 -533.621 -533.621] (1.000)
Step: 99, Reward: [-414.586 -414.586 -414.586] [0.0000], Avg: [-474.103 -474.103 -474.103] (1.000)
Step: 149, Reward: [-610.247 -610.247 -610.247] [0.0000], Avg: [-519.485 -519.485 -519.485] (1.000)
Step: 199, Reward: [-493.719 -493.719 -493.719] [0.0000], Avg: [-513.043 -513.043 -513.043] (1.000)
Step: 249, Reward: [-444.756 -444.756 -444.756] [0.0000], Avg: [-499.386 -499.386 -499.386] (1.000)
Step: 299, Reward: [-364.246 -364.246 -364.246] [0.0000], Avg: [-476.862 -476.862 -476.862] (1.000)
Step: 349, Reward: [-428.637 -428.637 -428.637] [0.0000], Avg: [-469.973 -469.973 -469.973] (1.000)
Step: 399, Reward: [-380.301 -380.301 -380.301] [0.0000], Avg: [-458.764 -458.764 -458.764] (1.000)
Step: 449, Reward: [-607.632 -607.632 -607.632] [0.0000], Avg: [-475.305 -475.305 -475.305] (1.000)
Step: 499, Reward: [-502.973 -502.973 -502.973] [0.0000], Avg: [-478.072 -478.072 -478.072] (1.000)
Step: 549, Reward: [-516.947 -516.947 -516.947] [0.0000], Avg: [-481.606 -481.606 -481.606] (1.000)
Step: 599, Reward: [-537.807 -537.807 -537.807] [0.0000], Avg: [-486.289 -486.289 -486.289] (1.000)
Step: 649, Reward: [-430.003 -430.003 -430.003] [0.0000], Avg: [-481.96 -481.96 -481.96] (1.000)
Step: 699, Reward: [-547.662 -547.662 -547.662] [0.0000], Avg: [-486.653 -486.653 -486.653] (1.000)
Step: 749, Reward: [-515.429 -515.429 -515.429] [0.0000], Avg: [-488.571 -488.571 -488.571] (1.000)
Step: 799, Reward: [-443.884 -443.884 -443.884] [0.0000], Avg: [-485.778 -485.778 -485.778] (1.000)
Step: 849, Reward: [-492.413 -492.413 -492.413] [0.0000], Avg: [-486.168 -486.168 -486.168] (1.000)
Step: 899, Reward: [-441.332 -441.332 -441.332] [0.0000], Avg: [-483.678 -483.678 -483.678] (1.000)
Step: 949, Reward: [-445.021 -445.021 -445.021] [0.0000], Avg: [-481.643 -481.643 -481.643] (1.000)
Step: 999, Reward: [-583.337 -583.337 -583.337] [0.0000], Avg: [-486.728 -486.728 -486.728] (1.000)
Step: 1049, Reward: [-382.562 -382.562 -382.562] [0.0000], Avg: [-481.767 -481.767 -481.767] (1.000)
Step: 1099, Reward: [-495.198 -495.198 -495.198] [0.0000], Avg: [-482.378 -482.378 -482.378] (1.000)
Step: 1149, Reward: [-531.044 -531.044 -531.044] [0.0000], Avg: [-484.494 -484.494 -484.494] (1.000)
Step: 1199, Reward: [-378.276 -378.276 -378.276] [0.0000], Avg: [-480.068 -480.068 -480.068] (1.000)
Step: 1249, Reward: [-513.257 -513.257 -513.257] [0.0000], Avg: [-481.396 -481.396 -481.396] (1.000)
Step: 1299, Reward: [-550.879 -550.879 -550.879] [0.0000], Avg: [-484.068 -484.068 -484.068] (1.000)
Step: 1349, Reward: [-791.577 -791.577 -791.577] [0.0000], Avg: [-495.457 -495.457 -495.457] (1.000)
Step: 1399, Reward: [-910.357 -910.357 -910.357] [0.0000], Avg: [-510.275 -510.275 -510.275] (1.000)
Step: 1449, Reward: [-1101.535 -1101.535 -1101.535] [0.0000], Avg: [-530.663 -530.663 -530.663] (1.000)
Step: 1499, Reward: [-1084.701 -1084.701 -1084.701] [0.0000], Avg: [-549.131 -549.131 -549.131] (1.000)
Step: 1549, Reward: [-1697.801 -1697.801 -1697.801] [0.0000], Avg: [-586.185 -586.185 -586.185] (1.000)
Step: 1599, Reward: [-1350.507 -1350.507 -1350.507] [0.0000], Avg: [-610.07 -610.07 -610.07] (1.000)
Step: 1649, Reward: [-1450.707 -1450.707 -1450.707] [0.0000], Avg: [-635.544 -635.544 -635.544] (1.000)
Step: 1699, Reward: [-1503.188 -1503.188 -1503.188] [0.0000], Avg: [-661.063 -661.063 -661.063] (1.000)
Step: 1749, Reward: [-1689.38 -1689.38 -1689.38] [0.0000], Avg: [-690.444 -690.444 -690.444] (1.000)
Step: 1799, Reward: [-1872.515 -1872.515 -1872.515] [0.0000], Avg: [-723.279 -723.279 -723.279] (1.000)
Step: 1849, Reward: [-1816.881 -1816.881 -1816.881] [0.0000], Avg: [-752.836 -752.836 -752.836] (1.000)
Step: 1899, Reward: [-1693.558 -1693.558 -1693.558] [0.0000], Avg: [-777.592 -777.592 -777.592] (1.000)
Step: 1949, Reward: [-792.307 -792.307 -792.307] [0.0000], Avg: [-777.969 -777.969 -777.969] (1.000)
Step: 1999, Reward: [-734.342 -734.342 -734.342] [0.0000], Avg: [-776.878 -776.878 -776.878] (1.000)
Step: 2049, Reward: [-1458.954 -1458.954 -1458.954] [0.0000], Avg: [-793.514 -793.514 -793.514] (1.000)
Step: 2099, Reward: [-1226.377 -1226.377 -1226.377] [0.0000], Avg: [-803.82 -803.82 -803.82] (1.000)
Step: 2149, Reward: [-741.936 -741.936 -741.936] [0.0000], Avg: [-802.381 -802.381 -802.381] (1.000)
Step: 2199, Reward: [-936.612 -936.612 -936.612] [0.0000], Avg: [-805.432 -805.432 -805.432] (1.000)
Step: 2249, Reward: [-557.389 -557.389 -557.389] [0.0000], Avg: [-799.92 -799.92 -799.92] (1.000)
Step: 2299, Reward: [-634.917 -634.917 -634.917] [0.0000], Avg: [-796.333 -796.333 -796.333] (1.000)
Step: 2349, Reward: [-830.597 -830.597 -830.597] [0.0000], Avg: [-797.062 -797.062 -797.062] (1.000)
Step: 2399, Reward: [-1022.73 -1022.73 -1022.73] [0.0000], Avg: [-801.763 -801.763 -801.763] (1.000)
Step: 2449, Reward: [-974.662 -974.662 -974.662] [0.0000], Avg: [-805.292 -805.292 -805.292] (1.000)
Step: 2499, Reward: [-880.451 -880.451 -880.451] [0.0000], Avg: [-806.795 -806.795 -806.795] (1.000)
Step: 2549, Reward: [-732.41 -732.41 -732.41] [0.0000], Avg: [-805.336 -805.336 -805.336] (1.000)
Step: 2599, Reward: [-781.442 -781.442 -781.442] [0.0000], Avg: [-804.877 -804.877 -804.877] (1.000)
Step: 2649, Reward: [-1221.734 -1221.734 -1221.734] [0.0000], Avg: [-812.742 -812.742 -812.742] (1.000)
Step: 2699, Reward: [-525.014 -525.014 -525.014] [0.0000], Avg: [-807.414 -807.414 -807.414] (1.000)
Step: 2749, Reward: [-866.096 -866.096 -866.096] [0.0000], Avg: [-808.481 -808.481 -808.481] (1.000)
Step: 2799, Reward: [-784.809 -784.809 -784.809] [0.0000], Avg: [-808.058 -808.058 -808.058] (1.000)
Step: 2849, Reward: [-840.202 -840.202 -840.202] [0.0000], Avg: [-808.622 -808.622 -808.622] (1.000)
Step: 2899, Reward: [-1307.214 -1307.214 -1307.214] [0.0000], Avg: [-817.218 -817.218 -817.218] (1.000)
Step: 2949, Reward: [-799.709 -799.709 -799.709] [0.0000], Avg: [-816.922 -816.922 -816.922] (1.000)
Step: 2999, Reward: [-1157.908 -1157.908 -1157.908] [0.0000], Avg: [-822.605 -822.605 -822.605] (1.000)
Step: 3049, Reward: [-650.906 -650.906 -650.906] [0.0000], Avg: [-819.79 -819.79 -819.79] (1.000)
Step: 3099, Reward: [-1060.232 -1060.232 -1060.232] [0.0000], Avg: [-823.668 -823.668 -823.668] (1.000)
Step: 3149, Reward: [-999.75 -999.75 -999.75] [0.0000], Avg: [-826.463 -826.463 -826.463] (1.000)
Step: 3199, Reward: [-1195.46 -1195.46 -1195.46] [0.0000], Avg: [-832.229 -832.229 -832.229] (1.000)
Step: 3249, Reward: [-793.033 -793.033 -793.033] [0.0000], Avg: [-831.626 -831.626 -831.626] (1.000)
Step: 3299, Reward: [-1029.779 -1029.779 -1029.779] [0.0000], Avg: [-834.628 -834.628 -834.628] (1.000)
Step: 3349, Reward: [-1026.294 -1026.294 -1026.294] [0.0000], Avg: [-837.489 -837.489 -837.489] (1.000)
Step: 3399, Reward: [-1446.962 -1446.962 -1446.962] [0.0000], Avg: [-846.452 -846.452 -846.452] (1.000)
Step: 3449, Reward: [-1524.636 -1524.636 -1524.636] [0.0000], Avg: [-856.28 -856.28 -856.28] (1.000)
Step: 3499, Reward: [-1719.828 -1719.828 -1719.828] [0.0000], Avg: [-868.617 -868.617 -868.617] (1.000)
Step: 3549, Reward: [-960.952 -960.952 -960.952] [0.0000], Avg: [-869.917 -869.917 -869.917] (1.000)
Step: 3599, Reward: [-1512.973 -1512.973 -1512.973] [0.0000], Avg: [-878.849 -878.849 -878.849] (1.000)
Step: 3649, Reward: [-1633.58 -1633.58 -1633.58] [0.0000], Avg: [-889.187 -889.187 -889.187] (1.000)
Step: 3699, Reward: [-1894.689 -1894.689 -1894.689] [0.0000], Avg: [-902.775 -902.775 -902.775] (1.000)
Step: 3749, Reward: [-1781.416 -1781.416 -1781.416] [0.0000], Avg: [-914.49 -914.49 -914.49] (1.000)
Step: 3799, Reward: [-2108.512 -2108.512 -2108.512] [0.0000], Avg: [-930.201 -930.201 -930.201] (1.000)
Step: 3849, Reward: [-1207.867 -1207.867 -1207.867] [0.0000], Avg: [-933.807 -933.807 -933.807] (1.000)
Step: 3899, Reward: [-2037.696 -2037.696 -2037.696] [0.0000], Avg: [-947.96 -947.96 -947.96] (1.000)
Step: 3949, Reward: [-1740.153 -1740.153 -1740.153] [0.0000], Avg: [-957.987 -957.987 -957.987] (1.000)
Step: 3999, Reward: [-1731.35 -1731.35 -1731.35] [0.0000], Avg: [-967.654 -967.654 -967.654] (1.000)
Step: 4049, Reward: [-1810.112 -1810.112 -1810.112] [0.0000], Avg: [-978.055 -978.055 -978.055] (1.000)
Step: 4099, Reward: [-1679.07 -1679.07 -1679.07] [0.0000], Avg: [-986.604 -986.604 -986.604] (1.000)
Step: 4149, Reward: [-1499.879 -1499.879 -1499.879] [0.0000], Avg: [-992.788 -992.788 -992.788] (1.000)
Step: 4199, Reward: [-1448.042 -1448.042 -1448.042] [0.0000], Avg: [-998.208 -998.208 -998.208] (1.000)
Step: 4249, Reward: [-1162.924 -1162.924 -1162.924] [0.0000], Avg: [-1000.146 -1000.146 -1000.146] (1.000)
Step: 4299, Reward: [-1481.974 -1481.974 -1481.974] [0.0000], Avg: [-1005.748 -1005.748 -1005.748] (1.000)
Step: 4349, Reward: [-999.755 -999.755 -999.755] [0.0000], Avg: [-1005.679 -1005.679 -1005.679] (1.000)
Step: 4399, Reward: [-1254.406 -1254.406 -1254.406] [0.0000], Avg: [-1008.506 -1008.506 -1008.506] (1.000)
Step: 4449, Reward: [-1243.228 -1243.228 -1243.228] [0.0000], Avg: [-1011.143 -1011.143 -1011.143] (1.000)
Step: 4499, Reward: [-984.632 -984.632 -984.632] [0.0000], Avg: [-1010.849 -1010.849 -1010.849] (1.000)
Step: 4549, Reward: [-1261.109 -1261.109 -1261.109] [0.0000], Avg: [-1013.599 -1013.599 -1013.599] (1.000)
Step: 4599, Reward: [-1504.981 -1504.981 -1504.981] [0.0000], Avg: [-1018.94 -1018.94 -1018.94] (1.000)
Step: 4649, Reward: [-1646.267 -1646.267 -1646.267] [0.0000], Avg: [-1025.685 -1025.685 -1025.685] (1.000)
Step: 4699, Reward: [-1015.913 -1015.913 -1015.913] [0.0000], Avg: [-1025.581 -1025.581 -1025.581] (1.000)
Step: 4749, Reward: [-878.067 -878.067 -878.067] [0.0000], Avg: [-1024.029 -1024.029 -1024.029] (1.000)
Step: 4799, Reward: [-1283.955 -1283.955 -1283.955] [0.0000], Avg: [-1026.736 -1026.736 -1026.736] (1.000)
Step: 4849, Reward: [-1072.036 -1072.036 -1072.036] [0.0000], Avg: [-1027.203 -1027.203 -1027.203] (1.000)
Step: 4899, Reward: [-720.945 -720.945 -720.945] [0.0000], Avg: [-1024.078 -1024.078 -1024.078] (1.000)
Step: 4949, Reward: [-877.562 -877.562 -877.562] [0.0000], Avg: [-1022.598 -1022.598 -1022.598] (1.000)
Step: 4999, Reward: [-1000.121 -1000.121 -1000.121] [0.0000], Avg: [-1022.373 -1022.373 -1022.373] (1.000)
Step: 5049, Reward: [-1490.747 -1490.747 -1490.747] [0.0000], Avg: [-1027.011 -1027.011 -1027.011] (1.000)
Step: 5099, Reward: [-1194.443 -1194.443 -1194.443] [0.0000], Avg: [-1028.652 -1028.652 -1028.652] (1.000)
Step: 5149, Reward: [-2035.043 -2035.043 -2035.043] [0.0000], Avg: [-1038.423 -1038.423 -1038.423] (1.000)
Step: 5199, Reward: [-1805.742 -1805.742 -1805.742] [0.0000], Avg: [-1045.801 -1045.801 -1045.801] (1.000)
Step: 5249, Reward: [-2009.621 -2009.621 -2009.621] [0.0000], Avg: [-1054.98 -1054.98 -1054.98] (1.000)
Step: 5299, Reward: [-1645.591 -1645.591 -1645.591] [0.0000], Avg: [-1060.552 -1060.552 -1060.552] (1.000)
Step: 5349, Reward: [-1756.974 -1756.974 -1756.974] [0.0000], Avg: [-1067.061 -1067.061 -1067.061] (1.000)
Step: 5399, Reward: [-2191.532 -2191.532 -2191.532] [0.0000], Avg: [-1077.472 -1077.472 -1077.472] (1.000)
Step: 5449, Reward: [-1340.432 -1340.432 -1340.432] [0.0000], Avg: [-1079.885 -1079.885 -1079.885] (1.000)
Step: 5499, Reward: [-1829.048 -1829.048 -1829.048] [0.0000], Avg: [-1086.696 -1086.696 -1086.696] (1.000)
Step: 5549, Reward: [-1070.732 -1070.732 -1070.732] [0.0000], Avg: [-1086.552 -1086.552 -1086.552] (1.000)
Step: 5599, Reward: [-1735.373 -1735.373 -1735.373] [0.0000], Avg: [-1092.345 -1092.345 -1092.345] (1.000)
Step: 5649, Reward: [-1545.708 -1545.708 -1545.708] [0.0000], Avg: [-1096.357 -1096.357 -1096.357] (1.000)
Step: 5699, Reward: [-926.457 -926.457 -926.457] [0.0000], Avg: [-1094.866 -1094.866 -1094.866] (1.000)
Step: 5749, Reward: [-671.307 -671.307 -671.307] [0.0000], Avg: [-1091.183 -1091.183 -1091.183] (1.000)
Step: 5799, Reward: [-729.161 -729.161 -729.161] [0.0000], Avg: [-1088.062 -1088.062 -1088.062] (1.000)
Step: 5849, Reward: [-939.325 -939.325 -939.325] [0.0000], Avg: [-1086.791 -1086.791 -1086.791] (1.000)
Step: 5899, Reward: [-829.519 -829.519 -829.519] [0.0000], Avg: [-1084.611 -1084.611 -1084.611] (1.000)
Step: 5949, Reward: [-1017.596 -1017.596 -1017.596] [0.0000], Avg: [-1084.048 -1084.048 -1084.048] (1.000)
Step: 5999, Reward: [-970.268 -970.268 -970.268] [0.0000], Avg: [-1083.1 -1083.1 -1083.1] (1.000)
Step: 6049, Reward: [-600.902 -600.902 -600.902] [0.0000], Avg: [-1079.115 -1079.115 -1079.115] (1.000)
Step: 6099, Reward: [-894.826 -894.826 -894.826] [0.0000], Avg: [-1077.604 -1077.604 -1077.604] (1.000)
Step: 6149, Reward: [-704.102 -704.102 -704.102] [0.0000], Avg: [-1074.567 -1074.567 -1074.567] (1.000)
Step: 6199, Reward: [-796.082 -796.082 -796.082] [0.0000], Avg: [-1072.322 -1072.322 -1072.322] (1.000)
Step: 6249, Reward: [-1019.407 -1019.407 -1019.407] [0.0000], Avg: [-1071.898 -1071.898 -1071.898] (1.000)
Step: 6299, Reward: [-731.063 -731.063 -731.063] [0.0000], Avg: [-1069.193 -1069.193 -1069.193] (1.000)
Step: 6349, Reward: [-707.151 -707.151 -707.151] [0.0000], Avg: [-1066.342 -1066.342 -1066.342] (1.000)
Step: 6399, Reward: [-454.579 -454.579 -454.579] [0.0000], Avg: [-1061.563 -1061.563 -1061.563] (1.000)
Step: 6449, Reward: [-833.531 -833.531 -833.531] [0.0000], Avg: [-1059.795 -1059.795 -1059.795] (1.000)
Step: 6499, Reward: [-622.504 -622.504 -622.504] [0.0000], Avg: [-1056.432 -1056.432 -1056.432] (1.000)
Step: 6549, Reward: [-551.328 -551.328 -551.328] [0.0000], Avg: [-1052.576 -1052.576 -1052.576] (1.000)
Step: 6599, Reward: [-606.331 -606.331 -606.331] [0.0000], Avg: [-1049.195 -1049.195 -1049.195] (1.000)
Step: 6649, Reward: [-519.891 -519.891 -519.891] [0.0000], Avg: [-1045.215 -1045.215 -1045.215] (1.000)
Step: 6699, Reward: [-991.532 -991.532 -991.532] [0.0000], Avg: [-1044.815 -1044.815 -1044.815] (1.000)
Step: 6749, Reward: [-656.625 -656.625 -656.625] [0.0000], Avg: [-1041.939 -1041.939 -1041.939] (1.000)
Step: 6799, Reward: [-711.887 -711.887 -711.887] [0.0000], Avg: [-1039.512 -1039.512 -1039.512] (1.000)
Step: 6849, Reward: [-470.722 -470.722 -470.722] [0.0000], Avg: [-1035.361 -1035.361 -1035.361] (1.000)
Step: 6899, Reward: [-918.095 -918.095 -918.095] [0.0000], Avg: [-1034.511 -1034.511 -1034.511] (1.000)
Step: 6949, Reward: [-829.101 -829.101 -829.101] [0.0000], Avg: [-1033.033 -1033.033 -1033.033] (1.000)
Step: 6999, Reward: [-666.15 -666.15 -666.15] [0.0000], Avg: [-1030.413 -1030.413 -1030.413] (1.000)
Step: 7049, Reward: [-508.716 -508.716 -508.716] [0.0000], Avg: [-1026.713 -1026.713 -1026.713] (1.000)
Step: 7099, Reward: [-605.561 -605.561 -605.561] [0.0000], Avg: [-1023.747 -1023.747 -1023.747] (1.000)
Step: 7149, Reward: [-492.369 -492.369 -492.369] [0.0000], Avg: [-1020.031 -1020.031 -1020.031] (1.000)
Step: 7199, Reward: [-790.547 -790.547 -790.547] [0.0000], Avg: [-1018.437 -1018.437 -1018.437] (1.000)
Step: 7249, Reward: [-744.575 -744.575 -744.575] [0.0000], Avg: [-1016.548 -1016.548 -1016.548] (1.000)
Step: 7299, Reward: [-751.17 -751.17 -751.17] [0.0000], Avg: [-1014.731 -1014.731 -1014.731] (1.000)
Step: 7349, Reward: [-606.838 -606.838 -606.838] [0.0000], Avg: [-1011.956 -1011.956 -1011.956] (1.000)
Step: 7399, Reward: [-568.606 -568.606 -568.606] [0.0000], Avg: [-1008.96 -1008.96 -1008.96] (1.000)
Step: 7449, Reward: [-952.191 -952.191 -952.191] [0.0000], Avg: [-1008.579 -1008.579 -1008.579] (1.000)
Step: 7499, Reward: [-650.694 -650.694 -650.694] [0.0000], Avg: [-1006.194 -1006.194 -1006.194] (1.000)
Step: 7549, Reward: [-726.242 -726.242 -726.242] [0.0000], Avg: [-1004.34 -1004.34 -1004.34] (1.000)
Step: 7599, Reward: [-699.509 -699.509 -699.509] [0.0000], Avg: [-1002.334 -1002.334 -1002.334] (1.000)
Step: 7649, Reward: [-600.87 -600.87 -600.87] [0.0000], Avg: [-999.71 -999.71 -999.71] (1.000)
Step: 7699, Reward: [-507.875 -507.875 -507.875] [0.0000], Avg: [-996.516 -996.516 -996.516] (1.000)
Step: 7749, Reward: [-570.69 -570.69 -570.69] [0.0000], Avg: [-993.769 -993.769 -993.769] (1.000)
Step: 7799, Reward: [-731.34 -731.34 -731.34] [0.0000], Avg: [-992.087 -992.087 -992.087] (1.000)
Step: 7849, Reward: [-664.023 -664.023 -664.023] [0.0000], Avg: [-989.997 -989.997 -989.997] (1.000)
Step: 7899, Reward: [-569.075 -569.075 -569.075] [0.0000], Avg: [-987.333 -987.333 -987.333] (1.000)
Step: 7949, Reward: [-395.814 -395.814 -395.814] [0.0000], Avg: [-983.613 -983.613 -983.613] (1.000)
Step: 7999, Reward: [-764.487 -764.487 -764.487] [0.0000], Avg: [-982.243 -982.243 -982.243] (1.000)
Step: 8049, Reward: [-474.902 -474.902 -474.902] [0.0000], Avg: [-979.092 -979.092 -979.092] (1.000)
Step: 8099, Reward: [-710.931 -710.931 -710.931] [0.0000], Avg: [-977.437 -977.437 -977.437] (1.000)
Step: 8149, Reward: [-536.679 -536.679 -536.679] [0.0000], Avg: [-974.733 -974.733 -974.733] (1.000)
Step: 8199, Reward: [-574.527 -574.527 -574.527] [0.0000], Avg: [-972.293 -972.293 -972.293] (1.000)
Step: 8249, Reward: [-499.568 -499.568 -499.568] [0.0000], Avg: [-969.428 -969.428 -969.428] (1.000)
Step: 8299, Reward: [-448.414 -448.414 -448.414] [0.0000], Avg: [-966.289 -966.289 -966.289] (1.000)
Step: 8349, Reward: [-520.063 -520.063 -520.063] [0.0000], Avg: [-963.617 -963.617 -963.617] (1.000)
Step: 8399, Reward: [-614.521 -614.521 -614.521] [0.0000], Avg: [-961.539 -961.539 -961.539] (1.000)
Step: 8449, Reward: [-793.11 -793.11 -793.11] [0.0000], Avg: [-960.542 -960.542 -960.542] (1.000)
Step: 8499, Reward: [-573.714 -573.714 -573.714] [0.0000], Avg: [-958.267 -958.267 -958.267] (1.000)
Step: 8549, Reward: [-569.884 -569.884 -569.884] [0.0000], Avg: [-955.996 -955.996 -955.996] (1.000)
Step: 8599, Reward: [-565.172 -565.172 -565.172] [0.0000], Avg: [-953.723 -953.723 -953.723] (1.000)
Step: 8649, Reward: [-528.18 -528.18 -528.18] [0.0000], Avg: [-951.264 -951.264 -951.264] (1.000)
Step: 8699, Reward: [-612.281 -612.281 -612.281] [0.0000], Avg: [-949.316 -949.316 -949.316] (1.000)
Step: 8749, Reward: [-539.013 -539.013 -539.013] [0.0000], Avg: [-946.971 -946.971 -946.971] (1.000)
Step: 8799, Reward: [-733.543 -733.543 -733.543] [0.0000], Avg: [-945.758 -945.758 -945.758] (1.000)
Step: 8849, Reward: [-554.662 -554.662 -554.662] [0.0000], Avg: [-943.549 -943.549 -943.549] (1.000)
Step: 8899, Reward: [-647.165 -647.165 -647.165] [0.0000], Avg: [-941.884 -941.884 -941.884] (1.000)
Step: 8949, Reward: [-701.016 -701.016 -701.016] [0.0000], Avg: [-940.538 -940.538 -940.538] (1.000)
Step: 8999, Reward: [-458.004 -458.004 -458.004] [0.0000], Avg: [-937.857 -937.857 -937.857] (1.000)
Step: 9049, Reward: [-447.931 -447.931 -447.931] [0.0000], Avg: [-935.15 -935.15 -935.15] (1.000)
Step: 9099, Reward: [-442.911 -442.911 -442.911] [0.0000], Avg: [-932.446 -932.446 -932.446] (1.000)
Step: 9149, Reward: [-434.039 -434.039 -434.039] [0.0000], Avg: [-929.722 -929.722 -929.722] (1.000)
Step: 9199, Reward: [-722.868 -722.868 -722.868] [0.0000], Avg: [-928.598 -928.598 -928.598] (1.000)
Step: 9249, Reward: [-540.631 -540.631 -540.631] [0.0000], Avg: [-926.501 -926.501 -926.501] (1.000)
Step: 9299, Reward: [-343.937 -343.937 -343.937] [0.0000], Avg: [-923.369 -923.369 -923.369] (1.000)
Step: 9349, Reward: [-739.076 -739.076 -739.076] [0.0000], Avg: [-922.383 -922.383 -922.383] (1.000)
Step: 9399, Reward: [-374.222 -374.222 -374.222] [0.0000], Avg: [-919.468 -919.468 -919.468] (1.000)
Step: 9449, Reward: [-564.082 -564.082 -564.082] [0.0000], Avg: [-917.587 -917.587 -917.587] (1.000)
Step: 9499, Reward: [-578.108 -578.108 -578.108] [0.0000], Avg: [-915.801 -915.801 -915.801] (1.000)
Step: 9549, Reward: [-405.147 -405.147 -405.147] [0.0000], Avg: [-913.127 -913.127 -913.127] (1.000)
Step: 9599, Reward: [-692.666 -692.666 -692.666] [0.0000], Avg: [-911.979 -911.979 -911.979] (1.000)
Step: 9649, Reward: [-625.822 -625.822 -625.822] [0.0000], Avg: [-910.496 -910.496 -910.496] (1.000)
Step: 9699, Reward: [-441.572 -441.572 -441.572] [0.0000], Avg: [-908.079 -908.079 -908.079] (1.000)
Step: 9749, Reward: [-393.228 -393.228 -393.228] [0.0000], Avg: [-905.439 -905.439 -905.439] (1.000)
Step: 9799, Reward: [-318.27 -318.27 -318.27] [0.0000], Avg: [-902.443 -902.443 -902.443] (1.000)
Step: 9849, Reward: [-427.751 -427.751 -427.751] [0.0000], Avg: [-900.033 -900.033 -900.033] (1.000)
Step: 9899, Reward: [-367.839 -367.839 -367.839] [0.0000], Avg: [-897.345 -897.345 -897.345] (1.000)
Step: 9949, Reward: [-338.677 -338.677 -338.677] [0.0000], Avg: [-894.538 -894.538 -894.538] (1.000)
Step: 9999, Reward: [-394.056 -394.056 -394.056] [0.0000], Avg: [-892.036 -892.036 -892.036] (1.000)
Step: 10049, Reward: [-397.846 -397.846 -397.846] [0.0000], Avg: [-889.577 -889.577 -889.577] (1.000)
Step: 10099, Reward: [-562.484 -562.484 -562.484] [0.0000], Avg: [-887.958 -887.958 -887.958] (1.000)
Step: 10149, Reward: [-330.094 -330.094 -330.094] [0.0000], Avg: [-885.21 -885.21 -885.21] (1.000)
Step: 10199, Reward: [-434.518 -434.518 -434.518] [0.0000], Avg: [-883. -883. -883.] (1.000)
Step: 10249, Reward: [-793.348 -793.348 -793.348] [0.0000], Avg: [-882.563 -882.563 -882.563] (1.000)
Step: 10299, Reward: [-523.205 -523.205 -523.205] [0.0000], Avg: [-880.819 -880.819 -880.819] (1.000)
Step: 10349, Reward: [-493.756 -493.756 -493.756] [0.0000], Avg: [-878.949 -878.949 -878.949] (1.000)
Step: 10399, Reward: [-504.204 -504.204 -504.204] [0.0000], Avg: [-877.147 -877.147 -877.147] (1.000)
Step: 10449, Reward: [-324.092 -324.092 -324.092] [0.0000], Avg: [-874.501 -874.501 -874.501] (1.000)
Step: 10499, Reward: [-714.375 -714.375 -714.375] [0.0000], Avg: [-873.738 -873.738 -873.738] (1.000)
Step: 10549, Reward: [-447.055 -447.055 -447.055] [0.0000], Avg: [-871.716 -871.716 -871.716] (1.000)
Step: 10599, Reward: [-325.134 -325.134 -325.134] [0.0000], Avg: [-869.138 -869.138 -869.138] (1.000)
Step: 10649, Reward: [-297.616 -297.616 -297.616] [0.0000], Avg: [-866.455 -866.455 -866.455] (1.000)
Step: 10699, Reward: [-524.518 -524.518 -524.518] [0.0000], Avg: [-864.857 -864.857 -864.857] (1.000)
Step: 10749, Reward: [-644.649 -644.649 -644.649] [0.0000], Avg: [-863.833 -863.833 -863.833] (1.000)
Step: 10799, Reward: [-341.535 -341.535 -341.535] [0.0000], Avg: [-861.415 -861.415 -861.415] (1.000)
Step: 10849, Reward: [-659.38 -659.38 -659.38] [0.0000], Avg: [-860.484 -860.484 -860.484] (1.000)
Step: 10899, Reward: [-370.294 -370.294 -370.294] [0.0000], Avg: [-858.235 -858.235 -858.235] (1.000)
Step: 10949, Reward: [-520.811 -520.811 -520.811] [0.0000], Avg: [-856.694 -856.694 -856.694] (1.000)
Step: 10999, Reward: [-607.458 -607.458 -607.458] [0.0000], Avg: [-855.561 -855.561 -855.561] (1.000)
Step: 11049, Reward: [-575.729 -575.729 -575.729] [0.0000], Avg: [-854.295 -854.295 -854.295] (1.000)
Step: 11099, Reward: [-582.494 -582.494 -582.494] [0.0000], Avg: [-853.071 -853.071 -853.071] (1.000)
Step: 11149, Reward: [-580.334 -580.334 -580.334] [0.0000], Avg: [-851.848 -851.848 -851.848] (1.000)
Step: 11199, Reward: [-500.102 -500.102 -500.102] [0.0000], Avg: [-850.278 -850.278 -850.278] (1.000)
Step: 11249, Reward: [-362.516 -362.516 -362.516] [0.0000], Avg: [-848.11 -848.11 -848.11] (1.000)
Step: 11299, Reward: [-412.068 -412.068 -412.068] [0.0000], Avg: [-846.18 -846.18 -846.18] (1.000)
Step: 11349, Reward: [-481.461 -481.461 -481.461] [0.0000], Avg: [-844.574 -844.574 -844.574] (1.000)
Step: 11399, Reward: [-592.641 -592.641 -592.641] [0.0000], Avg: [-843.469 -843.469 -843.469] (1.000)
Step: 11449, Reward: [-536.846 -536.846 -536.846] [0.0000], Avg: [-842.13 -842.13 -842.13] (1.000)
Step: 11499, Reward: [-476.528 -476.528 -476.528] [0.0000], Avg: [-840.54 -840.54 -840.54] (1.000)
Step: 11549, Reward: [-329.843 -329.843 -329.843] [0.0000], Avg: [-838.329 -838.329 -838.329] (1.000)
Step: 11599, Reward: [-312.744 -312.744 -312.744] [0.0000], Avg: [-836.064 -836.064 -836.064] (1.000)
Step: 11649, Reward: [-411.211 -411.211 -411.211] [0.0000], Avg: [-834.24 -834.24 -834.24] (1.000)
Step: 11699, Reward: [-421.575 -421.575 -421.575] [0.0000], Avg: [-832.477 -832.477 -832.477] (1.000)
Step: 11749, Reward: [-571.072 -571.072 -571.072] [0.0000], Avg: [-831.365 -831.365 -831.365] (1.000)
Step: 11799, Reward: [-496.492 -496.492 -496.492] [0.0000], Avg: [-829.946 -829.946 -829.946] (1.000)
Step: 11849, Reward: [-338.177 -338.177 -338.177] [0.0000], Avg: [-827.871 -827.871 -827.871] (1.000)
Step: 11899, Reward: [-551.075 -551.075 -551.075] [0.0000], Avg: [-826.708 -826.708 -826.708] (1.000)
Step: 11949, Reward: [-380.275 -380.275 -380.275] [0.0000], Avg: [-824.84 -824.84 -824.84] (1.000)
Step: 11999, Reward: [-503.751 -503.751 -503.751] [0.0000], Avg: [-823.502 -823.502 -823.502] (1.000)
Step: 12049, Reward: [-686.197 -686.197 -686.197] [0.0000], Avg: [-822.932 -822.932 -822.932] (1.000)
Step: 12099, Reward: [-599.713 -599.713 -599.713] [0.0000], Avg: [-822.01 -822.01 -822.01] (1.000)
Step: 12149, Reward: [-481.318 -481.318 -481.318] [0.0000], Avg: [-820.608 -820.608 -820.608] (1.000)
Step: 12199, Reward: [-440.66 -440.66 -440.66] [0.0000], Avg: [-819.051 -819.051 -819.051] (1.000)
Step: 12249, Reward: [-504.544 -504.544 -504.544] [0.0000], Avg: [-817.767 -817.767 -817.767] (1.000)
Step: 12299, Reward: [-448.277 -448.277 -448.277] [0.0000], Avg: [-816.265 -816.265 -816.265] (1.000)
Step: 12349, Reward: [-479.931 -479.931 -479.931] [0.0000], Avg: [-814.903 -814.903 -814.903] (1.000)
Step: 12399, Reward: [-536.092 -536.092 -536.092] [0.0000], Avg: [-813.779 -813.779 -813.779] (1.000)
Step: 12449, Reward: [-516.683 -516.683 -516.683] [0.0000], Avg: [-812.586 -812.586 -812.586] (1.000)
Step: 12499, Reward: [-451.949 -451.949 -451.949] [0.0000], Avg: [-811.143 -811.143 -811.143] (1.000)
Step: 12549, Reward: [-584.417 -584.417 -584.417] [0.0000], Avg: [-810.24 -810.24 -810.24] (1.000)
Step: 12599, Reward: [-539.109 -539.109 -539.109] [0.0000], Avg: [-809.164 -809.164 -809.164] (1.000)
Step: 12649, Reward: [-464.875 -464.875 -464.875] [0.0000], Avg: [-807.803 -807.803 -807.803] (1.000)
Step: 12699, Reward: [-321.813 -321.813 -321.813] [0.0000], Avg: [-805.89 -805.89 -805.89] (1.000)
Step: 12749, Reward: [-513.553 -513.553 -513.553] [0.0000], Avg: [-804.743 -804.743 -804.743] (1.000)
Step: 12799, Reward: [-402.263 -402.263 -402.263] [0.0000], Avg: [-803.171 -803.171 -803.171] (1.000)
Step: 12849, Reward: [-480.854 -480.854 -480.854] [0.0000], Avg: [-801.917 -801.917 -801.917] (1.000)
Step: 12899, Reward: [-558.91 -558.91 -558.91] [0.0000], Avg: [-800.975 -800.975 -800.975] (1.000)
Step: 12949, Reward: [-352.057 -352.057 -352.057] [0.0000], Avg: [-799.242 -799.242 -799.242] (1.000)
Step: 12999, Reward: [-505.234 -505.234 -505.234] [0.0000], Avg: [-798.111 -798.111 -798.111] (1.000)
Step: 13049, Reward: [-320.841 -320.841 -320.841] [0.0000], Avg: [-796.283 -796.283 -796.283] (1.000)
Step: 13099, Reward: [-543.971 -543.971 -543.971] [0.0000], Avg: [-795.319 -795.319 -795.319] (1.000)
Step: 13149, Reward: [-480.128 -480.128 -480.128] [0.0000], Avg: [-794.121 -794.121 -794.121] (1.000)
Step: 13199, Reward: [-433.928 -433.928 -433.928] [0.0000], Avg: [-792.757 -792.757 -792.757] (1.000)
Step: 13249, Reward: [-549.427 -549.427 -549.427] [0.0000], Avg: [-791.838 -791.838 -791.838] (1.000)
Step: 13299, Reward: [-519.058 -519.058 -519.058] [0.0000], Avg: [-790.813 -790.813 -790.813] (1.000)
Step: 13349, Reward: [-448.472 -448.472 -448.472] [0.0000], Avg: [-789.531 -789.531 -789.531] (1.000)
Step: 13399, Reward: [-373.179 -373.179 -373.179] [0.0000], Avg: [-787.977 -787.977 -787.977] (1.000)
Step: 13449, Reward: [-599.759 -599.759 -599.759] [0.0000], Avg: [-787.278 -787.278 -787.278] (1.000)
Step: 13499, Reward: [-324.206 -324.206 -324.206] [0.0000], Avg: [-785.562 -785.562 -785.562] (1.000)
Step: 13549, Reward: [-465.835 -465.835 -465.835] [0.0000], Avg: [-784.383 -784.383 -784.383] (1.000)
Step: 13599, Reward: [-415.095 -415.095 -415.095] [0.0000], Avg: [-783.025 -783.025 -783.025] (1.000)
Step: 13649, Reward: [-387.284 -387.284 -387.284] [0.0000], Avg: [-781.575 -781.575 -781.575] (1.000)
Step: 13699, Reward: [-563.792 -563.792 -563.792] [0.0000], Avg: [-780.781 -780.781 -780.781] (1.000)
Step: 13749, Reward: [-525.127 -525.127 -525.127] [0.0000], Avg: [-779.851 -779.851 -779.851] (1.000)
Step: 13799, Reward: [-466.165 -466.165 -466.165] [0.0000], Avg: [-778.714 -778.714 -778.714] (1.000)
Step: 13849, Reward: [-289.59 -289.59 -289.59] [0.0000], Avg: [-776.949 -776.949 -776.949] (1.000)
Step: 13899, Reward: [-440.393 -440.393 -440.393] [0.0000], Avg: [-775.738 -775.738 -775.738] (1.000)
Step: 13949, Reward: [-380.828 -380.828 -380.828] [0.0000], Avg: [-774.322 -774.322 -774.322] (1.000)
Step: 13999, Reward: [-392.707 -392.707 -392.707] [0.0000], Avg: [-772.96 -772.96 -772.96] (1.000)
Step: 14049, Reward: [-652.236 -652.236 -652.236] [0.0000], Avg: [-772.53 -772.53 -772.53] (1.000)
Step: 14099, Reward: [-506.157 -506.157 -506.157] [0.0000], Avg: [-771.585 -771.585 -771.585] (1.000)
Step: 14149, Reward: [-528.553 -528.553 -528.553] [0.0000], Avg: [-770.727 -770.727 -770.727] (1.000)
Step: 14199, Reward: [-607.27 -607.27 -607.27] [0.0000], Avg: [-770.151 -770.151 -770.151] (1.000)
Step: 14249, Reward: [-518.267 -518.267 -518.267] [0.0000], Avg: [-769.267 -769.267 -769.267] (1.000)
Step: 14299, Reward: [-1021.841 -1021.841 -1021.841] [0.0000], Avg: [-770.15 -770.15 -770.15] (1.000)
Step: 14349, Reward: [-729.953 -729.953 -729.953] [0.0000], Avg: [-770.01 -770.01 -770.01] (1.000)
Step: 14399, Reward: [-376.682 -376.682 -376.682] [0.0000], Avg: [-768.645 -768.645 -768.645] (1.000)
Step: 14449, Reward: [-522.232 -522.232 -522.232] [0.0000], Avg: [-767.792 -767.792 -767.792] (1.000)
Step: 14499, Reward: [-419.59 -419.59 -419.59] [0.0000], Avg: [-766.591 -766.591 -766.591] (1.000)
Step: 14549, Reward: [-996.582 -996.582 -996.582] [0.0000], Avg: [-767.382 -767.382 -767.382] (1.000)
Step: 14599, Reward: [-721.26 -721.26 -721.26] [0.0000], Avg: [-767.224 -767.224 -767.224] (1.000)
Step: 14649, Reward: [-433.572 -433.572 -433.572] [0.0000], Avg: [-766.085 -766.085 -766.085] (1.000)
Step: 14699, Reward: [-558.924 -558.924 -558.924] [0.0000], Avg: [-765.38 -765.38 -765.38] (1.000)
Step: 14749, Reward: [-416.686 -416.686 -416.686] [0.0000], Avg: [-764.198 -764.198 -764.198] (1.000)
Step: 14799, Reward: [-407.515 -407.515 -407.515] [0.0000], Avg: [-762.993 -762.993 -762.993] (1.000)
Step: 14849, Reward: [-726.269 -726.269 -726.269] [0.0000], Avg: [-762.87 -762.87 -762.87] (1.000)
Step: 14899, Reward: [-771.098 -771.098 -771.098] [0.0000], Avg: [-762.897 -762.897 -762.897] (1.000)
Step: 14949, Reward: [-453.91 -453.91 -453.91] [0.0000], Avg: [-761.864 -761.864 -761.864] (1.000)
Step: 14999, Reward: [-402.042 -402.042 -402.042] [0.0000], Avg: [-760.664 -760.664 -760.664] (1.000)
Step: 15049, Reward: [-454.016 -454.016 -454.016] [0.0000], Avg: [-759.646 -759.646 -759.646] (1.000)
Step: 15099, Reward: [-386.221 -386.221 -386.221] [0.0000], Avg: [-758.409 -758.409 -758.409] (1.000)
Step: 15149, Reward: [-448.708 -448.708 -448.708] [0.0000], Avg: [-757.387 -757.387 -757.387] (1.000)
Step: 15199, Reward: [-340.353 -340.353 -340.353] [0.0000], Avg: [-756.015 -756.015 -756.015] (1.000)
Step: 15249, Reward: [-514.384 -514.384 -514.384] [0.0000], Avg: [-755.223 -755.223 -755.223] (1.000)
Step: 15299, Reward: [-299. -299. -299.] [0.0000], Avg: [-753.732 -753.732 -753.732] (1.000)
Step: 15349, Reward: [-492.058 -492.058 -492.058] [0.0000], Avg: [-752.88 -752.88 -752.88] (1.000)
Step: 15399, Reward: [-382.752 -382.752 -382.752] [0.0000], Avg: [-751.678 -751.678 -751.678] (1.000)
Step: 15449, Reward: [-455.391 -455.391 -455.391] [0.0000], Avg: [-750.719 -750.719 -750.719] (1.000)
Step: 15499, Reward: [-392.09 -392.09 -392.09] [0.0000], Avg: [-749.562 -749.562 -749.562] (1.000)
Step: 15549, Reward: [-444.507 -444.507 -444.507] [0.0000], Avg: [-748.581 -748.581 -748.581] (1.000)
Step: 15599, Reward: [-562.142 -562.142 -562.142] [0.0000], Avg: [-747.984 -747.984 -747.984] (1.000)
Step: 15649, Reward: [-383.515 -383.515 -383.515] [0.0000], Avg: [-746.819 -746.819 -746.819] (1.000)
Step: 15699, Reward: [-275.568 -275.568 -275.568] [0.0000], Avg: [-745.319 -745.319 -745.319] (1.000)
Step: 15749, Reward: [-335.231 -335.231 -335.231] [0.0000], Avg: [-744.017 -744.017 -744.017] (1.000)
Step: 15799, Reward: [-328.105 -328.105 -328.105] [0.0000], Avg: [-742.701 -742.701 -742.701] (1.000)
Step: 15849, Reward: [-414.304 -414.304 -414.304] [0.0000], Avg: [-741.665 -741.665 -741.665] (1.000)
Step: 15899, Reward: [-437.93 -437.93 -437.93] [0.0000], Avg: [-740.709 -740.709 -740.709] (1.000)
Step: 15949, Reward: [-370.313 -370.313 -370.313] [0.0000], Avg: [-739.548 -739.548 -739.548] (1.000)
Step: 15999, Reward: [-429.672 -429.672 -429.672] [0.0000], Avg: [-738.58 -738.58 -738.58] (1.000)
Step: 16049, Reward: [-434.548 -434.548 -434.548] [0.0000], Avg: [-737.633 -737.633 -737.633] (1.000)
Step: 16099, Reward: [-417.687 -417.687 -417.687] [0.0000], Avg: [-736.639 -736.639 -736.639] (1.000)
Step: 16149, Reward: [-448.012 -448.012 -448.012] [0.0000], Avg: [-735.746 -735.746 -735.746] (1.000)
Step: 16199, Reward: [-402.272 -402.272 -402.272] [0.0000], Avg: [-734.716 -734.716 -734.716] (1.000)
Step: 16249, Reward: [-380.471 -380.471 -380.471] [0.0000], Avg: [-733.626 -733.626 -733.626] (1.000)
Step: 16299, Reward: [-445.501 -445.501 -445.501] [0.0000], Avg: [-732.743 -732.743 -732.743] (1.000)
Step: 16349, Reward: [-401.377 -401.377 -401.377] [0.0000], Avg: [-731.729 -731.729 -731.729] (1.000)
Step: 16399, Reward: [-376.383 -376.383 -376.383] [0.0000], Avg: [-730.646 -730.646 -730.646] (1.000)
Step: 16449, Reward: [-462.083 -462.083 -462.083] [0.0000], Avg: [-729.83 -729.83 -729.83] (1.000)
Step: 16499, Reward: [-440.159 -440.159 -440.159] [0.0000], Avg: [-728.952 -728.952 -728.952] (1.000)
Step: 16549, Reward: [-557.045 -557.045 -557.045] [0.0000], Avg: [-728.432 -728.432 -728.432] (1.000)
Step: 16599, Reward: [-339.815 -339.815 -339.815] [0.0000], Avg: [-727.262 -727.262 -727.262] (1.000)
Step: 16649, Reward: [-443.685 -443.685 -443.685] [0.0000], Avg: [-726.41 -726.41 -726.41] (1.000)
Step: 16699, Reward: [-485.987 -485.987 -485.987] [0.0000], Avg: [-725.69 -725.69 -725.69] (1.000)
Step: 16749, Reward: [-413.928 -413.928 -413.928] [0.0000], Avg: [-724.76 -724.76 -724.76] (1.000)
Step: 16799, Reward: [-395.656 -395.656 -395.656] [0.0000], Avg: [-723.78 -723.78 -723.78] (1.000)
Step: 16849, Reward: [-362.232 -362.232 -362.232] [0.0000], Avg: [-722.707 -722.707 -722.707] (1.000)
Step: 16899, Reward: [-484.403 -484.403 -484.403] [0.0000], Avg: [-722.002 -722.002 -722.002] (1.000)
Step: 16949, Reward: [-440.67 -440.67 -440.67] [0.0000], Avg: [-721.173 -721.173 -721.173] (1.000)
Step: 16999, Reward: [-309.226 -309.226 -309.226] [0.0000], Avg: [-719.961 -719.961 -719.961] (1.000)
Step: 17049, Reward: [-713.629 -713.629 -713.629] [0.0000], Avg: [-719.942 -719.942 -719.942] (1.000)
Step: 17099, Reward: [-608.205 -608.205 -608.205] [0.0000], Avg: [-719.616 -719.616 -719.616] (1.000)
Step: 17149, Reward: [-411.422 -411.422 -411.422] [0.0000], Avg: [-718.717 -718.717 -718.717] (1.000)
Step: 17199, Reward: [-501.912 -501.912 -501.912] [0.0000], Avg: [-718.087 -718.087 -718.087] (1.000)
Step: 17249, Reward: [-488.072 -488.072 -488.072] [0.0000], Avg: [-717.42 -717.42 -717.42] (1.000)
Step: 17299, Reward: [-548.051 -548.051 -548.051] [0.0000], Avg: [-716.931 -716.931 -716.931] (1.000)
Step: 17349, Reward: [-446.731 -446.731 -446.731] [0.0000], Avg: [-716.152 -716.152 -716.152] (1.000)
Step: 17399, Reward: [-501.962 -501.962 -501.962] [0.0000], Avg: [-715.537 -715.537 -715.537] (1.000)
Step: 17449, Reward: [-399.347 -399.347 -399.347] [0.0000], Avg: [-714.631 -714.631 -714.631] (1.000)
Step: 17499, Reward: [-420.23 -420.23 -420.23] [0.0000], Avg: [-713.789 -713.789 -713.789] (1.000)
Step: 17549, Reward: [-387.383 -387.383 -387.383] [0.0000], Avg: [-712.859 -712.859 -712.859] (1.000)
Step: 17599, Reward: [-338.246 -338.246 -338.246] [0.0000], Avg: [-711.795 -711.795 -711.795] (1.000)
Step: 17649, Reward: [-450.472 -450.472 -450.472] [0.0000], Avg: [-711.055 -711.055 -711.055] (1.000)
Step: 17699, Reward: [-414.111 -414.111 -414.111] [0.0000], Avg: [-710.216 -710.216 -710.216] (1.000)
Step: 17749, Reward: [-552.178 -552.178 -552.178] [0.0000], Avg: [-709.771 -709.771 -709.771] (1.000)
Step: 17799, Reward: [-398.658 -398.658 -398.658] [0.0000], Avg: [-708.897 -708.897 -708.897] (1.000)
Step: 17849, Reward: [-414.304 -414.304 -414.304] [0.0000], Avg: [-708.072 -708.072 -708.072] (1.000)
Step: 17899, Reward: [-431.367 -431.367 -431.367] [0.0000], Avg: [-707.299 -707.299 -707.299] (1.000)
Step: 17949, Reward: [-471.746 -471.746 -471.746] [0.0000], Avg: [-706.643 -706.643 -706.643] (1.000)
Step: 17999, Reward: [-497.343 -497.343 -497.343] [0.0000], Avg: [-706.061 -706.061 -706.061] (1.000)
Step: 18049, Reward: [-324.712 -324.712 -324.712] [0.0000], Avg: [-705.005 -705.005 -705.005] (1.000)
Step: 18099, Reward: [-366.206 -366.206 -366.206] [0.0000], Avg: [-704.069 -704.069 -704.069] (1.000)
Step: 18149, Reward: [-433.2 -433.2 -433.2] [0.0000], Avg: [-703.323 -703.323 -703.323] (1.000)
Step: 18199, Reward: [-491.8 -491.8 -491.8] [0.0000], Avg: [-702.742 -702.742 -702.742] (1.000)
Step: 18249, Reward: [-457.156 -457.156 -457.156] [0.0000], Avg: [-702.069 -702.069 -702.069] (1.000)
Step: 18299, Reward: [-475.67 -475.67 -475.67] [0.0000], Avg: [-701.45 -701.45 -701.45] (1.000)
Step: 18349, Reward: [-426.211 -426.211 -426.211] [0.0000], Avg: [-700.7 -700.7 -700.7] (1.000)
Step: 18399, Reward: [-385.478 -385.478 -385.478] [0.0000], Avg: [-699.844 -699.844 -699.844] (1.000)
Step: 18449, Reward: [-384.2 -384.2 -384.2] [0.0000], Avg: [-698.988 -698.988 -698.988] (1.000)
Step: 18499, Reward: [-345.236 -345.236 -345.236] [0.0000], Avg: [-698.032 -698.032 -698.032] (1.000)
Step: 18549, Reward: [-344.351 -344.351 -344.351] [0.0000], Avg: [-697.079 -697.079 -697.079] (1.000)
Step: 18599, Reward: [-476.059 -476.059 -476.059] [0.0000], Avg: [-696.485 -696.485 -696.485] (1.000)
Step: 18649, Reward: [-561.786 -561.786 -561.786] [0.0000], Avg: [-696.124 -696.124 -696.124] (1.000)
Step: 18699, Reward: [-370.485 -370.485 -370.485] [0.0000], Avg: [-695.253 -695.253 -695.253] (1.000)
Step: 18749, Reward: [-499.873 -499.873 -499.873] [0.0000], Avg: [-694.732 -694.732 -694.732] (1.000)
Step: 18799, Reward: [-435.607 -435.607 -435.607] [0.0000], Avg: [-694.043 -694.043 -694.043] (1.000)
Step: 18849, Reward: [-450.668 -450.668 -450.668] [0.0000], Avg: [-693.397 -693.397 -693.397] (1.000)
Step: 18899, Reward: [-336.658 -336.658 -336.658] [0.0000], Avg: [-692.454 -692.454 -692.454] (1.000)
Step: 18949, Reward: [-328.289 -328.289 -328.289] [0.0000], Avg: [-691.493 -691.493 -691.493] (1.000)
Step: 18999, Reward: [-552.915 -552.915 -552.915] [0.0000], Avg: [-691.128 -691.128 -691.128] (1.000)
Step: 19049, Reward: [-494.147 -494.147 -494.147] [0.0000], Avg: [-690.611 -690.611 -690.611] (1.000)
Step: 19099, Reward: [-488.506 -488.506 -488.506] [0.0000], Avg: [-690.082 -690.082 -690.082] (1.000)
Step: 19149, Reward: [-428.693 -428.693 -428.693] [0.0000], Avg: [-689.399 -689.399 -689.399] (1.000)
Step: 19199, Reward: [-305.952 -305.952 -305.952] [0.0000], Avg: [-688.401 -688.401 -688.401] (1.000)
Step: 19249, Reward: [-458.192 -458.192 -458.192] [0.0000], Avg: [-687.803 -687.803 -687.803] (1.000)
Step: 19299, Reward: [-427.227 -427.227 -427.227] [0.0000], Avg: [-687.128 -687.128 -687.128] (1.000)
Step: 19349, Reward: [-417.099 -417.099 -417.099] [0.0000], Avg: [-686.43 -686.43 -686.43] (1.000)
Step: 19399, Reward: [-463.892 -463.892 -463.892] [0.0000], Avg: [-685.857 -685.857 -685.857] (1.000)
Step: 19449, Reward: [-472.93 -472.93 -472.93] [0.0000], Avg: [-685.309 -685.309 -685.309] (1.000)
Step: 19499, Reward: [-529.886 -529.886 -529.886] [0.0000], Avg: [-684.911 -684.911 -684.911] (1.000)
Step: 19549, Reward: [-436.884 -436.884 -436.884] [0.0000], Avg: [-684.276 -684.276 -684.276] (1.000)
Step: 19599, Reward: [-287.678 -287.678 -287.678] [0.0000], Avg: [-683.265 -683.265 -683.265] (1.000)
Step: 19649, Reward: [-346.562 -346.562 -346.562] [0.0000], Avg: [-682.408 -682.408 -682.408] (1.000)
Step: 19699, Reward: [-379.54 -379.54 -379.54] [0.0000], Avg: [-681.639 -681.639 -681.639] (1.000)
Step: 19749, Reward: [-467.233 -467.233 -467.233] [0.0000], Avg: [-681.096 -681.096 -681.096] (1.000)
Step: 19799, Reward: [-465.853 -465.853 -465.853] [0.0000], Avg: [-680.553 -680.553 -680.553] (1.000)
Step: 19849, Reward: [-399.643 -399.643 -399.643] [0.0000], Avg: [-679.845 -679.845 -679.845] (1.000)
Step: 19899, Reward: [-426.141 -426.141 -426.141] [0.0000], Avg: [-679.208 -679.208 -679.208] (1.000)
Step: 19949, Reward: [-383.449 -383.449 -383.449] [0.0000], Avg: [-678.467 -678.467 -678.467] (1.000)
Step: 19999, Reward: [-478.526 -478.526 -478.526] [0.0000], Avg: [-677.967 -677.967 -677.967] (1.000)
Step: 20049, Reward: [-317.189 -317.189 -317.189] [0.0000], Avg: [-677.067 -677.067 -677.067] (1.000)
Step: 20099, Reward: [-399.071 -399.071 -399.071] [0.0000], Avg: [-676.375 -676.375 -676.375] (1.000)
Step: 20149, Reward: [-478.569 -478.569 -478.569] [0.0000], Avg: [-675.885 -675.885 -675.885] (1.000)
Step: 20199, Reward: [-480.569 -480.569 -480.569] [0.0000], Avg: [-675.401 -675.401 -675.401] (1.000)
Step: 20249, Reward: [-412.759 -412.759 -412.759] [0.0000], Avg: [-674.753 -674.753 -674.753] (1.000)
Step: 20299, Reward: [-465.055 -465.055 -465.055] [0.0000], Avg: [-674.236 -674.236 -674.236] (1.000)
Step: 20349, Reward: [-400.444 -400.444 -400.444] [0.0000], Avg: [-673.563 -673.563 -673.563] (1.000)
Step: 20399, Reward: [-296.331 -296.331 -296.331] [0.0000], Avg: [-672.639 -672.639 -672.639] (1.000)
Step: 20449, Reward: [-414.963 -414.963 -414.963] [0.0000], Avg: [-672.009 -672.009 -672.009] (1.000)
Step: 20499, Reward: [-522.539 -522.539 -522.539] [0.0000], Avg: [-671.644 -671.644 -671.644] (1.000)
Step: 20549, Reward: [-364.843 -364.843 -364.843] [0.0000], Avg: [-670.898 -670.898 -670.898] (1.000)
Step: 20599, Reward: [-492.381 -492.381 -492.381] [0.0000], Avg: [-670.465 -670.465 -670.465] (1.000)
Step: 20649, Reward: [-432.862 -432.862 -432.862] [0.0000], Avg: [-669.889 -669.889 -669.889] (1.000)
Step: 20699, Reward: [-571.757 -571.757 -571.757] [0.0000], Avg: [-669.652 -669.652 -669.652] (1.000)
Step: 20749, Reward: [-322.114 -322.114 -322.114] [0.0000], Avg: [-668.815 -668.815 -668.815] (1.000)
Step: 20799, Reward: [-376.564 -376.564 -376.564] [0.0000], Avg: [-668.112 -668.112 -668.112] (1.000)
Step: 20849, Reward: [-547.866 -547.866 -547.866] [0.0000], Avg: [-667.824 -667.824 -667.824] (1.000)
Step: 20899, Reward: [-419.089 -419.089 -419.089] [0.0000], Avg: [-667.229 -667.229 -667.229] (1.000)
Step: 20949, Reward: [-508.945 -508.945 -508.945] [0.0000], Avg: [-666.851 -666.851 -666.851] (1.000)
Step: 20999, Reward: [-625.286 -625.286 -625.286] [0.0000], Avg: [-666.752 -666.752 -666.752] (1.000)
Step: 21049, Reward: [-473.092 -473.092 -473.092] [0.0000], Avg: [-666.292 -666.292 -666.292] (1.000)
Step: 21099, Reward: [-447.782 -447.782 -447.782] [0.0000], Avg: [-665.774 -665.774 -665.774] (1.000)
Step: 21149, Reward: [-651.076 -651.076 -651.076] [0.0000], Avg: [-665.74 -665.74 -665.74] (1.000)
Step: 21199, Reward: [-385.64 -385.64 -385.64] [0.0000], Avg: [-665.079 -665.079 -665.079] (1.000)
Step: 21249, Reward: [-568.751 -568.751 -568.751] [0.0000], Avg: [-664.852 -664.852 -664.852] (1.000)
Step: 21299, Reward: [-518.443 -518.443 -518.443] [0.0000], Avg: [-664.509 -664.509 -664.509] (1.000)
Step: 21349, Reward: [-467.935 -467.935 -467.935] [0.0000], Avg: [-664.048 -664.048 -664.048] (1.000)
Step: 21399, Reward: [-483.227 -483.227 -483.227] [0.0000], Avg: [-663.626 -663.626 -663.626] (1.000)
Step: 21449, Reward: [-319.103 -319.103 -319.103] [0.0000], Avg: [-662.823 -662.823 -662.823] (1.000)
Step: 21499, Reward: [-475.362 -475.362 -475.362] [0.0000], Avg: [-662.387 -662.387 -662.387] (1.000)
Step: 21549, Reward: [-359.31 -359.31 -359.31] [0.0000], Avg: [-661.684 -661.684 -661.684] (1.000)
Step: 21599, Reward: [-509.041 -509.041 -509.041] [0.0000], Avg: [-661.33 -661.33 -661.33] (1.000)
Step: 21649, Reward: [-410.992 -410.992 -410.992] [0.0000], Avg: [-660.752 -660.752 -660.752] (1.000)
Step: 21699, Reward: [-406.647 -406.647 -406.647] [0.0000], Avg: [-660.167 -660.167 -660.167] (1.000)
Step: 21749, Reward: [-397.304 -397.304 -397.304] [0.0000], Avg: [-659.562 -659.562 -659.562] (1.000)
Step: 21799, Reward: [-416.197 -416.197 -416.197] [0.0000], Avg: [-659.004 -659.004 -659.004] (1.000)
Step: 21849, Reward: [-452.644 -452.644 -452.644] [0.0000], Avg: [-658.532 -658.532 -658.532] (1.000)
Step: 21899, Reward: [-372.139 -372.139 -372.139] [0.0000], Avg: [-657.878 -657.878 -657.878] (1.000)
Step: 21949, Reward: [-459.697 -459.697 -459.697] [0.0000], Avg: [-657.427 -657.427 -657.427] (1.000)
Step: 21999, Reward: [-429.752 -429.752 -429.752] [0.0000], Avg: [-656.909 -656.909 -656.909] (1.000)
Step: 22049, Reward: [-309.533 -309.533 -309.533] [0.0000], Avg: [-656.121 -656.121 -656.121] (1.000)
Step: 22099, Reward: [-351.299 -351.299 -351.299] [0.0000], Avg: [-655.432 -655.432 -655.432] (1.000)
Step: 22149, Reward: [-386.625 -386.625 -386.625] [0.0000], Avg: [-654.825 -654.825 -654.825] (1.000)
Step: 22199, Reward: [-486.147 -486.147 -486.147] [0.0000], Avg: [-654.445 -654.445 -654.445] (1.000)
Step: 22249, Reward: [-348.47 -348.47 -348.47] [0.0000], Avg: [-653.757 -653.757 -653.757] (1.000)
Step: 22299, Reward: [-400.991 -400.991 -400.991] [0.0000], Avg: [-653.191 -653.191 -653.191] (1.000)
Step: 22349, Reward: [-510.193 -510.193 -510.193] [0.0000], Avg: [-652.871 -652.871 -652.871] (1.000)
Step: 22399, Reward: [-376.42 -376.42 -376.42] [0.0000], Avg: [-652.254 -652.254 -652.254] (1.000)
Step: 22449, Reward: [-358.61 -358.61 -358.61] [0.0000], Avg: [-651.6 -651.6 -651.6] (1.000)
Step: 22499, Reward: [-446.66 -446.66 -446.66] [0.0000], Avg: [-651.144 -651.144 -651.144] (1.000)
Step: 22549, Reward: [-476.748 -476.748 -476.748] [0.0000], Avg: [-650.758 -650.758 -650.758] (1.000)
Step: 22599, Reward: [-271.812 -271.812 -271.812] [0.0000], Avg: [-649.919 -649.919 -649.919] (1.000)
Step: 22649, Reward: [-405.884 -405.884 -405.884] [0.0000], Avg: [-649.381 -649.381 -649.381] (1.000)
Step: 22699, Reward: [-353.762 -353.762 -353.762] [0.0000], Avg: [-648.729 -648.729 -648.729] (1.000)
Step: 22749, Reward: [-511.57 -511.57 -511.57] [0.0000], Avg: [-648.428 -648.428 -648.428] (1.000)
Step: 22799, Reward: [-521.569 -521.569 -521.569] [0.0000], Avg: [-648.15 -648.15 -648.15] (1.000)
Step: 22849, Reward: [-578.315 -578.315 -578.315] [0.0000], Avg: [-647.997 -647.997 -647.997] (1.000)
Step: 22899, Reward: [-391.383 -391.383 -391.383] [0.0000], Avg: [-647.437 -647.437 -647.437] (1.000)
Step: 22949, Reward: [-465.718 -465.718 -465.718] [0.0000], Avg: [-647.041 -647.041 -647.041] (1.000)
Step: 22999, Reward: [-343.683 -343.683 -343.683] [0.0000], Avg: [-646.381 -646.381 -646.381] (1.000)
Step: 23049, Reward: [-344.635 -344.635 -344.635] [0.0000], Avg: [-645.727 -645.727 -645.727] (1.000)
Step: 23099, Reward: [-296.713 -296.713 -296.713] [0.0000], Avg: [-644.971 -644.971 -644.971] (1.000)
Step: 23149, Reward: [-380.638 -380.638 -380.638] [0.0000], Avg: [-644.4 -644.4 -644.4] (1.000)
Step: 23199, Reward: [-402.287 -402.287 -402.287] [0.0000], Avg: [-643.879 -643.879 -643.879] (1.000)
Step: 23249, Reward: [-411.954 -411.954 -411.954] [0.0000], Avg: [-643.38 -643.38 -643.38] (1.000)
Step: 23299, Reward: [-423.895 -423.895 -423.895] [0.0000], Avg: [-642.909 -642.909 -642.909] (1.000)
Step: 23349, Reward: [-408.222 -408.222 -408.222] [0.0000], Avg: [-642.406 -642.406 -642.406] (1.000)
Step: 23399, Reward: [-405.105 -405.105 -405.105] [0.0000], Avg: [-641.899 -641.899 -641.899] (1.000)
Step: 23449, Reward: [-471.299 -471.299 -471.299] [0.0000], Avg: [-641.536 -641.536 -641.536] (1.000)
Step: 23499, Reward: [-416.166 -416.166 -416.166] [0.0000], Avg: [-641.056 -641.056 -641.056] (1.000)
Step: 23549, Reward: [-424.359 -424.359 -424.359] [0.0000], Avg: [-640.596 -640.596 -640.596] (1.000)
Step: 23599, Reward: [-335.334 -335.334 -335.334] [0.0000], Avg: [-639.949 -639.949 -639.949] (1.000)
Step: 23649, Reward: [-358.396 -358.396 -358.396] [0.0000], Avg: [-639.354 -639.354 -639.354] (1.000)
Step: 23699, Reward: [-380.918 -380.918 -380.918] [0.0000], Avg: [-638.809 -638.809 -638.809] (1.000)
Step: 23749, Reward: [-409.236 -409.236 -409.236] [0.0000], Avg: [-638.325 -638.325 -638.325] (1.000)
Step: 23799, Reward: [-346.72 -346.72 -346.72] [0.0000], Avg: [-637.713 -637.713 -637.713] (1.000)
Step: 23849, Reward: [-530.184 -530.184 -530.184] [0.0000], Avg: [-637.487 -637.487 -637.487] (1.000)
Step: 23899, Reward: [-471.966 -471.966 -471.966] [0.0000], Avg: [-637.141 -637.141 -637.141] (1.000)
Step: 23949, Reward: [-423.278 -423.278 -423.278] [0.0000], Avg: [-636.695 -636.695 -636.695] (1.000)
Step: 23999, Reward: [-470.124 -470.124 -470.124] [0.0000], Avg: [-636.348 -636.348 -636.348] (1.000)
Step: 24049, Reward: [-456.619 -456.619 -456.619] [0.0000], Avg: [-635.974 -635.974 -635.974] (1.000)
Step: 24099, Reward: [-433.382 -433.382 -433.382] [0.0000], Avg: [-635.554 -635.554 -635.554] (1.000)
Step: 24149, Reward: [-401.848 -401.848 -401.848] [0.0000], Avg: [-635.07 -635.07 -635.07] (1.000)
Step: 24199, Reward: [-429.67 -429.67 -429.67] [0.0000], Avg: [-634.645 -634.645 -634.645] (1.000)
Step: 24249, Reward: [-376.041 -376.041 -376.041] [0.0000], Avg: [-634.112 -634.112 -634.112] (1.000)
Step: 24299, Reward: [-309.711 -309.711 -309.711] [0.0000], Avg: [-633.445 -633.445 -633.445] (1.000)
Step: 24349, Reward: [-438.421 -438.421 -438.421] [0.0000], Avg: [-633.044 -633.044 -633.044] (1.000)
Step: 24399, Reward: [-389.948 -389.948 -389.948] [0.0000], Avg: [-632.546 -632.546 -632.546] (1.000)
Step: 24449, Reward: [-414.109 -414.109 -414.109] [0.0000], Avg: [-632.099 -632.099 -632.099] (1.000)
Step: 24499, Reward: [-388.652 -388.652 -388.652] [0.0000], Avg: [-631.603 -631.603 -631.603] (1.000)
Step: 24549, Reward: [-484.67 -484.67 -484.67] [0.0000], Avg: [-631.303 -631.303 -631.303] (1.000)
Step: 24599, Reward: [-463.196 -463.196 -463.196] [0.0000], Avg: [-630.962 -630.962 -630.962] (1.000)
Step: 24649, Reward: [-569.13 -569.13 -569.13] [0.0000], Avg: [-630.836 -630.836 -630.836] (1.000)
Step: 24699, Reward: [-478.645 -478.645 -478.645] [0.0000], Avg: [-630.528 -630.528 -630.528] (1.000)
Step: 24749, Reward: [-339.536 -339.536 -339.536] [0.0000], Avg: [-629.94 -629.94 -629.94] (1.000)
Step: 24799, Reward: [-571.589 -571.589 -571.589] [0.0000], Avg: [-629.823 -629.823 -629.823] (1.000)
Step: 24849, Reward: [-633.279 -633.279 -633.279] [0.0000], Avg: [-629.83 -629.83 -629.83] (1.000)
Step: 24899, Reward: [-424.859 -424.859 -424.859] [0.0000], Avg: [-629.418 -629.418 -629.418] (1.000)
Step: 24949, Reward: [-439.532 -439.532 -439.532] [0.0000], Avg: [-629.037 -629.037 -629.037] (1.000)
Step: 24999, Reward: [-431.37 -431.37 -431.37] [0.0000], Avg: [-628.642 -628.642 -628.642] (1.000)
Step: 25049, Reward: [-604.382 -604.382 -604.382] [0.0000], Avg: [-628.594 -628.594 -628.594] (1.000)
Step: 25099, Reward: [-482.398 -482.398 -482.398] [0.0000], Avg: [-628.302 -628.302 -628.302] (1.000)
Step: 25149, Reward: [-466.16 -466.16 -466.16] [0.0000], Avg: [-627.98 -627.98 -627.98] (1.000)
Step: 25199, Reward: [-412.184 -412.184 -412.184] [0.0000], Avg: [-627.552 -627.552 -627.552] (1.000)
Step: 25249, Reward: [-596.279 -596.279 -596.279] [0.0000], Avg: [-627.49 -627.49 -627.49] (1.000)
Step: 25299, Reward: [-393.976 -393.976 -393.976] [0.0000], Avg: [-627.028 -627.028 -627.028] (1.000)
Step: 25349, Reward: [-398.978 -398.978 -398.978] [0.0000], Avg: [-626.579 -626.579 -626.579] (1.000)
Step: 25399, Reward: [-510.272 -510.272 -510.272] [0.0000], Avg: [-626.35 -626.35 -626.35] (1.000)
Step: 25449, Reward: [-655.442 -655.442 -655.442] [0.0000], Avg: [-626.407 -626.407 -626.407] (1.000)
Step: 25499, Reward: [-592.786 -592.786 -592.786] [0.0000], Avg: [-626.341 -626.341 -626.341] (1.000)
Step: 25549, Reward: [-554.637 -554.637 -554.637] [0.0000], Avg: [-626.201 -626.201 -626.201] (1.000)
Step: 25599, Reward: [-369.709 -369.709 -369.709] [0.0000], Avg: [-625.7 -625.7 -625.7] (1.000)
Step: 25649, Reward: [-420.656 -420.656 -420.656] [0.0000], Avg: [-625.3 -625.3 -625.3] (1.000)
Step: 25699, Reward: [-509.384 -509.384 -509.384] [0.0000], Avg: [-625.074 -625.074 -625.074] (1.000)
Step: 25749, Reward: [-562.324 -562.324 -562.324] [0.0000], Avg: [-624.953 -624.953 -624.953] (1.000)
Step: 25799, Reward: [-346.702 -346.702 -346.702] [0.0000], Avg: [-624.413 -624.413 -624.413] (1.000)
Step: 25849, Reward: [-349.461 -349.461 -349.461] [0.0000], Avg: [-623.882 -623.882 -623.882] (1.000)
Step: 25899, Reward: [-440.966 -440.966 -440.966] [0.0000], Avg: [-623.528 -623.528 -623.528] (1.000)
Step: 25949, Reward: [-432.386 -432.386 -432.386] [0.0000], Avg: [-623.16 -623.16 -623.16] (1.000)
Step: 25999, Reward: [-520.032 -520.032 -520.032] [0.0000], Avg: [-622.962 -622.962 -622.962] (1.000)
Step: 26049, Reward: [-499.05 -499.05 -499.05] [0.0000], Avg: [-622.724 -622.724 -622.724] (1.000)
Step: 26099, Reward: [-535.798 -535.798 -535.798] [0.0000], Avg: [-622.557 -622.557 -622.557] (1.000)
Step: 26149, Reward: [-460.633 -460.633 -460.633] [0.0000], Avg: [-622.248 -622.248 -622.248] (1.000)
Step: 26199, Reward: [-375.18 -375.18 -375.18] [0.0000], Avg: [-621.776 -621.776 -621.776] (1.000)
Step: 26249, Reward: [-397.515 -397.515 -397.515] [0.0000], Avg: [-621.349 -621.349 -621.349] (1.000)
Step: 26299, Reward: [-581.418 -581.418 -581.418] [0.0000], Avg: [-621.273 -621.273 -621.273] (1.000)
Step: 26349, Reward: [-498.603 -498.603 -498.603] [0.0000], Avg: [-621.041 -621.041 -621.041] (1.000)
Step: 26399, Reward: [-415.081 -415.081 -415.081] [0.0000], Avg: [-620.65 -620.65 -620.65] (1.000)
Step: 26449, Reward: [-430.447 -430.447 -430.447] [0.0000], Avg: [-620.291 -620.291 -620.291] (1.000)
Step: 26499, Reward: [-420.307 -420.307 -420.307] [0.0000], Avg: [-619.914 -619.914 -619.914] (1.000)
Step: 26549, Reward: [-394.673 -394.673 -394.673] [0.0000], Avg: [-619.489 -619.489 -619.489] (1.000)
Step: 26599, Reward: [-418.986 -418.986 -418.986] [0.0000], Avg: [-619.112 -619.112 -619.112] (1.000)
Step: 26649, Reward: [-395.401 -395.401 -395.401] [0.0000], Avg: [-618.693 -618.693 -618.693] (1.000)
Step: 26699, Reward: [-387.582 -387.582 -387.582] [0.0000], Avg: [-618.26 -618.26 -618.26] (1.000)
Step: 26749, Reward: [-456.925 -456.925 -456.925] [0.0000], Avg: [-617.958 -617.958 -617.958] (1.000)
Step: 26799, Reward: [-401.997 -401.997 -401.997] [0.0000], Avg: [-617.555 -617.555 -617.555] (1.000)
Step: 26849, Reward: [-545.03 -545.03 -545.03] [0.0000], Avg: [-617.42 -617.42 -617.42] (1.000)
Step: 26899, Reward: [-466.641 -466.641 -466.641] [0.0000], Avg: [-617.14 -617.14 -617.14] (1.000)
Step: 26949, Reward: [-364.807 -364.807 -364.807] [0.0000], Avg: [-616.672 -616.672 -616.672] (1.000)
Step: 26999, Reward: [-459.616 -459.616 -459.616] [0.0000], Avg: [-616.381 -616.381 -616.381] (1.000)
Step: 27049, Reward: [-424.944 -424.944 -424.944] [0.0000], Avg: [-616.027 -616.027 -616.027] (1.000)
Step: 27099, Reward: [-417.612 -417.612 -417.612] [0.0000], Avg: [-615.661 -615.661 -615.661] (1.000)
Step: 27149, Reward: [-456.01 -456.01 -456.01] [0.0000], Avg: [-615.367 -615.367 -615.367] (1.000)
Step: 27199, Reward: [-414.147 -414.147 -414.147] [0.0000], Avg: [-614.997 -614.997 -614.997] (1.000)
Step: 27249, Reward: [-515.091 -515.091 -515.091] [0.0000], Avg: [-614.814 -614.814 -614.814] (1.000)
Step: 27299, Reward: [-375.41 -375.41 -375.41] [0.0000], Avg: [-614.376 -614.376 -614.376] (1.000)
Step: 27349, Reward: [-458.073 -458.073 -458.073] [0.0000], Avg: [-614.09 -614.09 -614.09] (1.000)
Step: 27399, Reward: [-417.371 -417.371 -417.371] [0.0000], Avg: [-613.731 -613.731 -613.731] (1.000)
Step: 27449, Reward: [-438.86 -438.86 -438.86] [0.0000], Avg: [-613.412 -613.412 -613.412] (1.000)
Step: 27499, Reward: [-483.212 -483.212 -483.212] [0.0000], Avg: [-613.176 -613.176 -613.176] (1.000)
Step: 27549, Reward: [-488.893 -488.893 -488.893] [0.0000], Avg: [-612.95 -612.95 -612.95] (1.000)
Step: 27599, Reward: [-409.655 -409.655 -409.655] [0.0000], Avg: [-612.582 -612.582 -612.582] (1.000)
Step: 27649, Reward: [-585.302 -585.302 -585.302] [0.0000], Avg: [-612.532 -612.532 -612.532] (1.000)
Step: 27699, Reward: [-462.536 -462.536 -462.536] [0.0000], Avg: [-612.262 -612.262 -612.262] (1.000)
Step: 27749, Reward: [-478.581 -478.581 -478.581] [0.0000], Avg: [-612.021 -612.021 -612.021] (1.000)
Step: 27799, Reward: [-510.004 -510.004 -510.004] [0.0000], Avg: [-611.837 -611.837 -611.837] (1.000)
Step: 27849, Reward: [-538.313 -538.313 -538.313] [0.0000], Avg: [-611.705 -611.705 -611.705] (1.000)
Step: 27899, Reward: [-568.945 -568.945 -568.945] [0.0000], Avg: [-611.629 -611.629 -611.629] (1.000)
Step: 27949, Reward: [-505.065 -505.065 -505.065] [0.0000], Avg: [-611.438 -611.438 -611.438] (1.000)
Step: 27999, Reward: [-532.63 -532.63 -532.63] [0.0000], Avg: [-611.297 -611.297 -611.297] (1.000)
Step: 28049, Reward: [-558.748 -558.748 -558.748] [0.0000], Avg: [-611.204 -611.204 -611.204] (1.000)
Step: 28099, Reward: [-489.144 -489.144 -489.144] [0.0000], Avg: [-610.986 -610.986 -610.986] (1.000)
Step: 28149, Reward: [-553.427 -553.427 -553.427] [0.0000], Avg: [-610.884 -610.884 -610.884] (1.000)
Step: 28199, Reward: [-383.716 -383.716 -383.716] [0.0000], Avg: [-610.481 -610.481 -610.481] (1.000)
Step: 28249, Reward: [-383.094 -383.094 -383.094] [0.0000], Avg: [-610.079 -610.079 -610.079] (1.000)
Step: 28299, Reward: [-432.347 -432.347 -432.347] [0.0000], Avg: [-609.765 -609.765 -609.765] (1.000)
Step: 28349, Reward: [-539.277 -539.277 -539.277] [0.0000], Avg: [-609.641 -609.641 -609.641] (1.000)
Step: 28399, Reward: [-442.492 -442.492 -442.492] [0.0000], Avg: [-609.346 -609.346 -609.346] (1.000)
Step: 28449, Reward: [-382.782 -382.782 -382.782] [0.0000], Avg: [-608.948 -608.948 -608.948] (1.000)
Step: 28499, Reward: [-492.531 -492.531 -492.531] [0.0000], Avg: [-608.744 -608.744 -608.744] (1.000)
Step: 28549, Reward: [-483.411 -483.411 -483.411] [0.0000], Avg: [-608.524 -608.524 -608.524] (1.000)
Step: 28599, Reward: [-364.958 -364.958 -364.958] [0.0000], Avg: [-608.099 -608.099 -608.099] (1.000)
Step: 28649, Reward: [-508.179 -508.179 -508.179] [0.0000], Avg: [-607.924 -607.924 -607.924] (1.000)
Step: 28699, Reward: [-556.746 -556.746 -556.746] [0.0000], Avg: [-607.835 -607.835 -607.835] (1.000)
Step: 28749, Reward: [-361.524 -361.524 -361.524] [0.0000], Avg: [-607.407 -607.407 -607.407] (1.000)
Step: 28799, Reward: [-446.673 -446.673 -446.673] [0.0000], Avg: [-607.128 -607.128 -607.128] (1.000)
Step: 28849, Reward: [-436.879 -436.879 -436.879] [0.0000], Avg: [-606.833 -606.833 -606.833] (1.000)
Step: 28899, Reward: [-372.346 -372.346 -372.346] [0.0000], Avg: [-606.427 -606.427 -606.427] (1.000)
Step: 28949, Reward: [-376.846 -376.846 -376.846] [0.0000], Avg: [-606.03 -606.03 -606.03] (1.000)
Step: 28999, Reward: [-432.285 -432.285 -432.285] [0.0000], Avg: [-605.731 -605.731 -605.731] (1.000)
Step: 29049, Reward: [-428.961 -428.961 -428.961] [0.0000], Avg: [-605.427 -605.427 -605.427] (1.000)
Step: 29099, Reward: [-438.719 -438.719 -438.719] [0.0000], Avg: [-605.14 -605.14 -605.14] (1.000)
Step: 29149, Reward: [-529.346 -529.346 -529.346] [0.0000], Avg: [-605.01 -605.01 -605.01] (1.000)
Step: 29199, Reward: [-523.46 -523.46 -523.46] [0.0000], Avg: [-604.871 -604.871 -604.871] (1.000)
Step: 29249, Reward: [-433.495 -433.495 -433.495] [0.0000], Avg: [-604.578 -604.578 -604.578] (1.000)
Step: 29299, Reward: [-416.628 -416.628 -416.628] [0.0000], Avg: [-604.257 -604.257 -604.257] (1.000)
Step: 29349, Reward: [-410.951 -410.951 -410.951] [0.0000], Avg: [-603.928 -603.928 -603.928] (1.000)
Step: 29399, Reward: [-352.634 -352.634 -352.634] [0.0000], Avg: [-603.5 -603.5 -603.5] (1.000)
Step: 29449, Reward: [-432.461 -432.461 -432.461] [0.0000], Avg: [-603.21 -603.21 -603.21] (1.000)
Step: 29499, Reward: [-491.48 -491.48 -491.48] [0.0000], Avg: [-603.02 -603.02 -603.02] (1.000)
Step: 29549, Reward: [-355.103 -355.103 -355.103] [0.0000], Avg: [-602.601 -602.601 -602.601] (1.000)
Step: 29599, Reward: [-405.051 -405.051 -405.051] [0.0000], Avg: [-602.267 -602.267 -602.267] (1.000)
Step: 29649, Reward: [-390.536 -390.536 -390.536] [0.0000], Avg: [-601.91 -601.91 -601.91] (1.000)
Step: 29699, Reward: [-356.215 -356.215 -356.215] [0.0000], Avg: [-601.497 -601.497 -601.497] (1.000)
Step: 29749, Reward: [-367.058 -367.058 -367.058] [0.0000], Avg: [-601.103 -601.103 -601.103] (1.000)
Step: 29799, Reward: [-489.235 -489.235 -489.235] [0.0000], Avg: [-600.915 -600.915 -600.915] (1.000)
Step: 29849, Reward: [-303.791 -303.791 -303.791] [0.0000], Avg: [-600.417 -600.417 -600.417] (1.000)
Step: 29899, Reward: [-328.327 -328.327 -328.327] [0.0000], Avg: [-599.962 -599.962 -599.962] (1.000)
Step: 29949, Reward: [-349.539 -349.539 -349.539] [0.0000], Avg: [-599.544 -599.544 -599.544] (1.000)
Step: 29999, Reward: [-434.065 -434.065 -434.065] [0.0000], Avg: [-599.268 -599.268 -599.268] (1.000)
Step: 30049, Reward: [-359.062 -359.062 -359.062] [0.0000], Avg: [-598.869 -598.869 -598.869] (1.000)
Step: 30099, Reward: [-379.653 -379.653 -379.653] [0.0000], Avg: [-598.504 -598.504 -598.504] (1.000)
Step: 30149, Reward: [-518.391 -518.391 -518.391] [0.0000], Avg: [-598.372 -598.372 -598.372] (1.000)
Step: 30199, Reward: [-283.878 -283.878 -283.878] [0.0000], Avg: [-597.851 -597.851 -597.851] (1.000)
Step: 30249, Reward: [-425.722 -425.722 -425.722] [0.0000], Avg: [-597.566 -597.566 -597.566] (1.000)
Step: 30299, Reward: [-320.188 -320.188 -320.188] [0.0000], Avg: [-597.109 -597.109 -597.109] (1.000)
Step: 30349, Reward: [-447.423 -447.423 -447.423] [0.0000], Avg: [-596.862 -596.862 -596.862] (1.000)
Step: 30399, Reward: [-387.684 -387.684 -387.684] [0.0000], Avg: [-596.518 -596.518 -596.518] (1.000)
Step: 30449, Reward: [-466.48 -466.48 -466.48] [0.0000], Avg: [-596.305 -596.305 -596.305] (1.000)
Step: 30499, Reward: [-453.556 -453.556 -453.556] [0.0000], Avg: [-596.07 -596.07 -596.07] (1.000)
Step: 30549, Reward: [-493.315 -493.315 -493.315] [0.0000], Avg: [-595.902 -595.902 -595.902] (1.000)
Step: 30599, Reward: [-527.514 -527.514 -527.514] [0.0000], Avg: [-595.791 -595.791 -595.791] (1.000)
Step: 30649, Reward: [-448.363 -448.363 -448.363] [0.0000], Avg: [-595.55 -595.55 -595.55] (1.000)
Step: 30699, Reward: [-441.735 -441.735 -441.735] [0.0000], Avg: [-595.3 -595.3 -595.3] (1.000)
Step: 30749, Reward: [-356.925 -356.925 -356.925] [0.0000], Avg: [-594.912 -594.912 -594.912] (1.000)
Step: 30799, Reward: [-343.32 -343.32 -343.32] [0.0000], Avg: [-594.504 -594.504 -594.504] (1.000)
Step: 30849, Reward: [-409.796 -409.796 -409.796] [0.0000], Avg: [-594.204 -594.204 -594.204] (1.000)
Step: 30899, Reward: [-440.626 -440.626 -440.626] [0.0000], Avg: [-593.956 -593.956 -593.956] (1.000)
Step: 30949, Reward: [-325.855 -325.855 -325.855] [0.0000], Avg: [-593.523 -593.523 -593.523] (1.000)
Step: 30999, Reward: [-522.847 -522.847 -522.847] [0.0000], Avg: [-593.409 -593.409 -593.409] (1.000)
Step: 31049, Reward: [-338.748 -338.748 -338.748] [0.0000], Avg: [-592.998 -592.998 -592.998] (1.000)
Step: 31099, Reward: [-411.024 -411.024 -411.024] [0.0000], Avg: [-592.706 -592.706 -592.706] (1.000)
Step: 31149, Reward: [-320.675 -320.675 -320.675] [0.0000], Avg: [-592.269 -592.269 -592.269] (1.000)
Step: 31199, Reward: [-360.816 -360.816 -360.816] [0.0000], Avg: [-591.898 -591.898 -591.898] (1.000)
Step: 31249, Reward: [-413.052 -413.052 -413.052] [0.0000], Avg: [-591.612 -591.612 -591.612] (1.000)
Step: 31299, Reward: [-485.532 -485.532 -485.532] [0.0000], Avg: [-591.443 -591.443 -591.443] (1.000)
Step: 31349, Reward: [-263.507 -263.507 -263.507] [0.0000], Avg: [-590.92 -590.92 -590.92] (1.000)
Step: 31399, Reward: [-407.516 -407.516 -407.516] [0.0000], Avg: [-590.628 -590.628 -590.628] (1.000)
Step: 31449, Reward: [-432.467 -432.467 -432.467] [0.0000], Avg: [-590.376 -590.376 -590.376] (1.000)
Step: 31499, Reward: [-304.161 -304.161 -304.161] [0.0000], Avg: [-589.922 -589.922 -589.922] (1.000)
Step: 31549, Reward: [-455.219 -455.219 -455.219] [0.0000], Avg: [-589.708 -589.708 -589.708] (1.000)
Step: 31599, Reward: [-511.78 -511.78 -511.78] [0.0000], Avg: [-589.585 -589.585 -589.585] (1.000)
Step: 31649, Reward: [-372.569 -372.569 -372.569] [0.0000], Avg: [-589.242 -589.242 -589.242] (1.000)
Step: 31699, Reward: [-463.001 -463.001 -463.001] [0.0000], Avg: [-589.043 -589.043 -589.043] (1.000)
Step: 31749, Reward: [-443.759 -443.759 -443.759] [0.0000], Avg: [-588.814 -588.814 -588.814] (1.000)
Step: 31799, Reward: [-348.676 -348.676 -348.676] [0.0000], Avg: [-588.437 -588.437 -588.437] (1.000)
Step: 31849, Reward: [-423.777 -423.777 -423.777] [0.0000], Avg: [-588.178 -588.178 -588.178] (1.000)
Step: 31899, Reward: [-312.592 -312.592 -312.592] [0.0000], Avg: [-587.746 -587.746 -587.746] (1.000)
Step: 31949, Reward: [-421.17 -421.17 -421.17] [0.0000], Avg: [-587.486 -587.486 -587.486] (1.000)
Step: 31999, Reward: [-337.492 -337.492 -337.492] [0.0000], Avg: [-587.095 -587.095 -587.095] (1.000)
Step: 32049, Reward: [-348.648 -348.648 -348.648] [0.0000], Avg: [-586.723 -586.723 -586.723] (1.000)
Step: 32099, Reward: [-415.053 -415.053 -415.053] [0.0000], Avg: [-586.456 -586.456 -586.456] (1.000)
Step: 32149, Reward: [-431.567 -431.567 -431.567] [0.0000], Avg: [-586.215 -586.215 -586.215] (1.000)
Step: 32199, Reward: [-374.029 -374.029 -374.029] [0.0000], Avg: [-585.885 -585.885 -585.885] (1.000)
Step: 32249, Reward: [-339.913 -339.913 -339.913] [0.0000], Avg: [-585.504 -585.504 -585.504] (1.000)
Step: 32299, Reward: [-425.674 -425.674 -425.674] [0.0000], Avg: [-585.257 -585.257 -585.257] (1.000)
Step: 32349, Reward: [-535.748 -535.748 -535.748] [0.0000], Avg: [-585.18 -585.18 -585.18] (1.000)
Step: 32399, Reward: [-381.979 -381.979 -381.979] [0.0000], Avg: [-584.866 -584.866 -584.866] (1.000)
Step: 32449, Reward: [-427.251 -427.251 -427.251] [0.0000], Avg: [-584.624 -584.624 -584.624] (1.000)
Step: 32499, Reward: [-504.489 -504.489 -504.489] [0.0000], Avg: [-584.5 -584.5 -584.5] (1.000)
Step: 32549, Reward: [-414.583 -414.583 -414.583] [0.0000], Avg: [-584.239 -584.239 -584.239] (1.000)
Step: 32599, Reward: [-377.747 -377.747 -377.747] [0.0000], Avg: [-583.923 -583.923 -583.923] (1.000)
Step: 32649, Reward: [-394.647 -394.647 -394.647] [0.0000], Avg: [-583.633 -583.633 -583.633] (1.000)
Step: 32699, Reward: [-396.614 -396.614 -396.614] [0.0000], Avg: [-583.347 -583.347 -583.347] (1.000)
Step: 32749, Reward: [-289.185 -289.185 -289.185] [0.0000], Avg: [-582.898 -582.898 -582.898] (1.000)
Step: 32799, Reward: [-431.925 -431.925 -431.925] [0.0000], Avg: [-582.667 -582.667 -582.667] (1.000)
Step: 32849, Reward: [-456.939 -456.939 -456.939] [0.0000], Avg: [-582.476 -582.476 -582.476] (1.000)
Step: 32899, Reward: [-379.802 -379.802 -379.802] [0.0000], Avg: [-582.168 -582.168 -582.168] (1.000)
Step: 32949, Reward: [-493.772 -493.772 -493.772] [0.0000], Avg: [-582.034 -582.034 -582.034] (1.000)
Step: 32999, Reward: [-446.147 -446.147 -446.147] [0.0000], Avg: [-581.828 -581.828 -581.828] (1.000)
Step: 33049, Reward: [-300.61 -300.61 -300.61] [0.0000], Avg: [-581.403 -581.403 -581.403] (1.000)
Step: 33099, Reward: [-411.999 -411.999 -411.999] [0.0000], Avg: [-581.147 -581.147 -581.147] (1.000)
Step: 33149, Reward: [-424.396 -424.396 -424.396] [0.0000], Avg: [-580.91 -580.91 -580.91] (1.000)
Step: 33199, Reward: [-405.618 -405.618 -405.618] [0.0000], Avg: [-580.646 -580.646 -580.646] (1.000)
Step: 33249, Reward: [-423.792 -423.792 -423.792] [0.0000], Avg: [-580.41 -580.41 -580.41] (1.000)
Step: 33299, Reward: [-418.335 -418.335 -418.335] [0.0000], Avg: [-580.167 -580.167 -580.167] (1.000)
Step: 33349, Reward: [-351.212 -351.212 -351.212] [0.0000], Avg: [-579.824 -579.824 -579.824] (1.000)
Step: 33399, Reward: [-396.69 -396.69 -396.69] [0.0000], Avg: [-579.55 -579.55 -579.55] (1.000)
Step: 33449, Reward: [-505.237 -505.237 -505.237] [0.0000], Avg: [-579.439 -579.439 -579.439] (1.000)
Step: 33499, Reward: [-393.926 -393.926 -393.926] [0.0000], Avg: [-579.162 -579.162 -579.162] (1.000)
Step: 33549, Reward: [-444.777 -444.777 -444.777] [0.0000], Avg: [-578.961 -578.961 -578.961] (1.000)
Step: 33599, Reward: [-389.014 -389.014 -389.014] [0.0000], Avg: [-578.679 -578.679 -578.679] (1.000)
Step: 33649, Reward: [-434.891 -434.891 -434.891] [0.0000], Avg: [-578.465 -578.465 -578.465] (1.000)
Step: 33699, Reward: [-344.624 -344.624 -344.624] [0.0000], Avg: [-578.118 -578.118 -578.118] (1.000)
Step: 33749, Reward: [-544.251 -544.251 -544.251] [0.0000], Avg: [-578.068 -578.068 -578.068] (1.000)
Step: 33799, Reward: [-444.486 -444.486 -444.486] [0.0000], Avg: [-577.87 -577.87 -577.87] (1.000)
Step: 33849, Reward: [-474.657 -474.657 -474.657] [0.0000], Avg: [-577.718 -577.718 -577.718] (1.000)
Step: 33899, Reward: [-428.038 -428.038 -428.038] [0.0000], Avg: [-577.497 -577.497 -577.497] (1.000)
Step: 33949, Reward: [-400.329 -400.329 -400.329] [0.0000], Avg: [-577.236 -577.236 -577.236] (1.000)
Step: 33999, Reward: [-413.481 -413.481 -413.481] [0.0000], Avg: [-576.995 -576.995 -576.995] (1.000)
Step: 34049, Reward: [-439.55 -439.55 -439.55] [0.0000], Avg: [-576.794 -576.794 -576.794] (1.000)
Step: 34099, Reward: [-357.099 -357.099 -357.099] [0.0000], Avg: [-576.471 -576.471 -576.471] (1.000)
Step: 34149, Reward: [-310.353 -310.353 -310.353] [0.0000], Avg: [-576.082 -576.082 -576.082] (1.000)
Step: 34199, Reward: [-292.951 -292.951 -292.951] [0.0000], Avg: [-575.668 -575.668 -575.668] (1.000)
Step: 34249, Reward: [-508.667 -508.667 -508.667] [0.0000], Avg: [-575.57 -575.57 -575.57] (1.000)
Step: 34299, Reward: [-384.939 -384.939 -384.939] [0.0000], Avg: [-575.292 -575.292 -575.292] (1.000)
Step: 34349, Reward: [-374.32 -374.32 -374.32] [0.0000], Avg: [-575. -575. -575.] (1.000)
Step: 34399, Reward: [-363.354 -363.354 -363.354] [0.0000], Avg: [-574.692 -574.692 -574.692] (1.000)
Step: 34449, Reward: [-425.007 -425.007 -425.007] [0.0000], Avg: [-574.475 -574.475 -574.475] (1.000)
Step: 34499, Reward: [-466.123 -466.123 -466.123] [0.0000], Avg: [-574.318 -574.318 -574.318] (1.000)
Step: 34549, Reward: [-454.53 -454.53 -454.53] [0.0000], Avg: [-574.144 -574.144 -574.144] (1.000)
Step: 34599, Reward: [-277.288 -277.288 -277.288] [0.0000], Avg: [-573.715 -573.715 -573.715] (1.000)
Step: 34649, Reward: [-485.014 -485.014 -485.014] [0.0000], Avg: [-573.587 -573.587 -573.587] (1.000)
Step: 34699, Reward: [-356.666 -356.666 -356.666] [0.0000], Avg: [-573.275 -573.275 -573.275] (1.000)
Step: 34749, Reward: [-499.044 -499.044 -499.044] [0.0000], Avg: [-573.168 -573.168 -573.168] (1.000)
Step: 34799, Reward: [-474.285 -474.285 -474.285] [0.0000], Avg: [-573.026 -573.026 -573.026] (1.000)
Step: 34849, Reward: [-356.235 -356.235 -356.235] [0.0000], Avg: [-572.715 -572.715 -572.715] (1.000)
Step: 34899, Reward: [-414.021 -414.021 -414.021] [0.0000], Avg: [-572.488 -572.488 -572.488] (1.000)
Step: 34949, Reward: [-391.149 -391.149 -391.149] [0.0000], Avg: [-572.228 -572.228 -572.228] (1.000)
Step: 34999, Reward: [-389.054 -389.054 -389.054] [0.0000], Avg: [-571.967 -571.967 -571.967] (1.000)
Step: 35049, Reward: [-373.06 -373.06 -373.06] [0.0000], Avg: [-571.683 -571.683 -571.683] (1.000)
Step: 35099, Reward: [-293.543 -293.543 -293.543] [0.0000], Avg: [-571.287 -571.287 -571.287] (1.000)
Step: 35149, Reward: [-450.032 -450.032 -450.032] [0.0000], Avg: [-571.114 -571.114 -571.114] (1.000)
Step: 35199, Reward: [-452.689 -452.689 -452.689] [0.0000], Avg: [-570.946 -570.946 -570.946] (1.000)
Step: 35249, Reward: [-378.084 -378.084 -378.084] [0.0000], Avg: [-570.672 -570.672 -570.672] (1.000)
Step: 35299, Reward: [-299.196 -299.196 -299.196] [0.0000], Avg: [-570.288 -570.288 -570.288] (1.000)
Step: 35349, Reward: [-326.98 -326.98 -326.98] [0.0000], Avg: [-569.944 -569.944 -569.944] (1.000)
Step: 35399, Reward: [-459.872 -459.872 -459.872] [0.0000], Avg: [-569.788 -569.788 -569.788] (1.000)
Step: 35449, Reward: [-417.89 -417.89 -417.89] [0.0000], Avg: [-569.574 -569.574 -569.574] (1.000)
Step: 35499, Reward: [-331.709 -331.709 -331.709] [0.0000], Avg: [-569.239 -569.239 -569.239] (1.000)
Step: 35549, Reward: [-377.198 -377.198 -377.198] [0.0000], Avg: [-568.969 -568.969 -568.969] (1.000)
Step: 35599, Reward: [-437.644 -437.644 -437.644] [0.0000], Avg: [-568.784 -568.784 -568.784] (1.000)
Step: 35649, Reward: [-355.376 -355.376 -355.376] [0.0000], Avg: [-568.485 -568.485 -568.485] (1.000)
Step: 35699, Reward: [-308.952 -308.952 -308.952] [0.0000], Avg: [-568.122 -568.122 -568.122] (1.000)
Step: 35749, Reward: [-556.569 -556.569 -556.569] [0.0000], Avg: [-568.105 -568.105 -568.105] (1.000)
Step: 35799, Reward: [-352.569 -352.569 -352.569] [0.0000], Avg: [-567.804 -567.804 -567.804] (1.000)
Step: 35849, Reward: [-474.794 -474.794 -474.794] [0.0000], Avg: [-567.675 -567.675 -567.675] (1.000)
Step: 35899, Reward: [-304.88 -304.88 -304.88] [0.0000], Avg: [-567.309 -567.309 -567.309] (1.000)
Step: 35949, Reward: [-466.527 -466.527 -466.527] [0.0000], Avg: [-567.168 -567.168 -567.168] (1.000)
Step: 35999, Reward: [-435.91 -435.91 -435.91] [0.0000], Avg: [-566.986 -566.986 -566.986] (1.000)
Step: 36049, Reward: [-343.917 -343.917 -343.917] [0.0000], Avg: [-566.677 -566.677 -566.677] (1.000)
Step: 36099, Reward: [-278.404 -278.404 -278.404] [0.0000], Avg: [-566.277 -566.277 -566.277] (1.000)
Step: 36149, Reward: [-391.451 -391.451 -391.451] [0.0000], Avg: [-566.036 -566.036 -566.036] (1.000)
Step: 36199, Reward: [-401.211 -401.211 -401.211] [0.0000], Avg: [-565.808 -565.808 -565.808] (1.000)
Step: 36249, Reward: [-395.906 -395.906 -395.906] [0.0000], Avg: [-565.574 -565.574 -565.574] (1.000)
Step: 36299, Reward: [-366.868 -366.868 -366.868] [0.0000], Avg: [-565.3 -565.3 -565.3] (1.000)
Step: 36349, Reward: [-398.562 -398.562 -398.562] [0.0000], Avg: [-565.071 -565.071 -565.071] (1.000)
Step: 36399, Reward: [-403.618 -403.618 -403.618] [0.0000], Avg: [-564.849 -564.849 -564.849] (1.000)
Step: 36449, Reward: [-497.205 -497.205 -497.205] [0.0000], Avg: [-564.756 -564.756 -564.756] (1.000)
Step: 36499, Reward: [-455.163 -455.163 -455.163] [0.0000], Avg: [-564.606 -564.606 -564.606] (1.000)
Step: 36549, Reward: [-318.6 -318.6 -318.6] [0.0000], Avg: [-564.269 -564.269 -564.269] (1.000)
Step: 36599, Reward: [-335.91 -335.91 -335.91] [0.0000], Avg: [-563.957 -563.957 -563.957] (1.000)
Step: 36649, Reward: [-452.893 -452.893 -452.893] [0.0000], Avg: [-563.806 -563.806 -563.806] (1.000)
Step: 36699, Reward: [-374.922 -374.922 -374.922] [0.0000], Avg: [-563.549 -563.549 -563.549] (1.000)
Step: 36749, Reward: [-325.72 -325.72 -325.72] [0.0000], Avg: [-563.225 -563.225 -563.225] (1.000)
Step: 36799, Reward: [-539.338 -539.338 -539.338] [0.0000], Avg: [-563.193 -563.193 -563.193] (1.000)
Step: 36849, Reward: [-439.632 -439.632 -439.632] [0.0000], Avg: [-563.025 -563.025 -563.025] (1.000)
Step: 36899, Reward: [-410.729 -410.729 -410.729] [0.0000], Avg: [-562.819 -562.819 -562.819] (1.000)
Step: 36949, Reward: [-423.461 -423.461 -423.461] [0.0000], Avg: [-562.63 -562.63 -562.63] (1.000)
Step: 36999, Reward: [-396.682 -396.682 -396.682] [0.0000], Avg: [-562.406 -562.406 -562.406] (1.000)
Step: 37049, Reward: [-307.716 -307.716 -307.716] [0.0000], Avg: [-562.062 -562.062 -562.062] (1.000)
Step: 37099, Reward: [-390.192 -390.192 -390.192] [0.0000], Avg: [-561.83 -561.83 -561.83] (1.000)
Step: 37149, Reward: [-304.337 -304.337 -304.337] [0.0000], Avg: [-561.484 -561.484 -561.484] (1.000)
Step: 37199, Reward: [-396.239 -396.239 -396.239] [0.0000], Avg: [-561.262 -561.262 -561.262] (1.000)
Step: 37249, Reward: [-498.202 -498.202 -498.202] [0.0000], Avg: [-561.177 -561.177 -561.177] (1.000)
Step: 37299, Reward: [-462.307 -462.307 -462.307] [0.0000], Avg: [-561.045 -561.045 -561.045] (1.000)
Step: 37349, Reward: [-493.815 -493.815 -493.815] [0.0000], Avg: [-560.955 -560.955 -560.955] (1.000)
Step: 37399, Reward: [-507.516 -507.516 -507.516] [0.0000], Avg: [-560.883 -560.883 -560.883] (1.000)
Step: 37449, Reward: [-338.403 -338.403 -338.403] [0.0000], Avg: [-560.586 -560.586 -560.586] (1.000)
Step: 37499, Reward: [-375.768 -375.768 -375.768] [0.0000], Avg: [-560.34 -560.34 -560.34] (1.000)
Step: 37549, Reward: [-415.883 -415.883 -415.883] [0.0000], Avg: [-560.147 -560.147 -560.147] (1.000)
Step: 37599, Reward: [-442.966 -442.966 -442.966] [0.0000], Avg: [-559.991 -559.991 -559.991] (1.000)
Step: 37649, Reward: [-379.207 -379.207 -379.207] [0.0000], Avg: [-559.751 -559.751 -559.751] (1.000)
Step: 37699, Reward: [-281.943 -281.943 -281.943] [0.0000], Avg: [-559.383 -559.383 -559.383] (1.000)
Step: 37749, Reward: [-494.11 -494.11 -494.11] [0.0000], Avg: [-559.296 -559.296 -559.296] (1.000)
Step: 37799, Reward: [-298.534 -298.534 -298.534] [0.0000], Avg: [-558.952 -558.952 -558.952] (1.000)
Step: 37849, Reward: [-532.38 -532.38 -532.38] [0.0000], Avg: [-558.916 -558.916 -558.916] (1.000)
Step: 37899, Reward: [-370.334 -370.334 -370.334] [0.0000], Avg: [-558.668 -558.668 -558.668] (1.000)
Step: 37949, Reward: [-362.11 -362.11 -362.11] [0.0000], Avg: [-558.409 -558.409 -558.409] (1.000)
Step: 37999, Reward: [-452.652 -452.652 -452.652] [0.0000], Avg: [-558.27 -558.27 -558.27] (1.000)
Step: 38049, Reward: [-465.581 -465.581 -465.581] [0.0000], Avg: [-558.148 -558.148 -558.148] (1.000)
Step: 38099, Reward: [-462.004 -462.004 -462.004] [0.0000], Avg: [-558.022 -558.022 -558.022] (1.000)
Step: 38149, Reward: [-318.394 -318.394 -318.394] [0.0000], Avg: [-557.707 -557.707 -557.707] (1.000)
Step: 38199, Reward: [-386.108 -386.108 -386.108] [0.0000], Avg: [-557.483 -557.483 -557.483] (1.000)
Step: 38249, Reward: [-464.206 -464.206 -464.206] [0.0000], Avg: [-557.361 -557.361 -557.361] (1.000)
Step: 38299, Reward: [-386.083 -386.083 -386.083] [0.0000], Avg: [-557.137 -557.137 -557.137] (1.000)
Step: 38349, Reward: [-361.719 -361.719 -361.719] [0.0000], Avg: [-556.883 -556.883 -556.883] (1.000)
Step: 38399, Reward: [-342.328 -342.328 -342.328] [0.0000], Avg: [-556.603 -556.603 -556.603] (1.000)
Step: 38449, Reward: [-441.866 -441.866 -441.866] [0.0000], Avg: [-556.454 -556.454 -556.454] (1.000)
Step: 38499, Reward: [-439.342 -439.342 -439.342] [0.0000], Avg: [-556.302 -556.302 -556.302] (1.000)
Step: 38549, Reward: [-466.205 -466.205 -466.205] [0.0000], Avg: [-556.185 -556.185 -556.185] (1.000)
Step: 38599, Reward: [-412.502 -412.502 -412.502] [0.0000], Avg: [-555.999 -555.999 -555.999] (1.000)
Step: 38649, Reward: [-321.344 -321.344 -321.344] [0.0000], Avg: [-555.695 -555.695 -555.695] (1.000)
Step: 38699, Reward: [-357.239 -357.239 -357.239] [0.0000], Avg: [-555.439 -555.439 -555.439] (1.000)
Step: 38749, Reward: [-433.796 -433.796 -433.796] [0.0000], Avg: [-555.282 -555.282 -555.282] (1.000)
Step: 38799, Reward: [-425.244 -425.244 -425.244] [0.0000], Avg: [-555.114 -555.114 -555.114] (1.000)
Step: 38849, Reward: [-356.483 -356.483 -356.483] [0.0000], Avg: [-554.859 -554.859 -554.859] (1.000)
Step: 38899, Reward: [-304.085 -304.085 -304.085] [0.0000], Avg: [-554.536 -554.536 -554.536] (1.000)
Step: 38949, Reward: [-353.641 -353.641 -353.641] [0.0000], Avg: [-554.279 -554.279 -554.279] (1.000)
Step: 38999, Reward: [-425.504 -425.504 -425.504] [0.0000], Avg: [-554.113 -554.113 -554.113] (1.000)
Step: 39049, Reward: [-459.346 -459.346 -459.346] [0.0000], Avg: [-553.992 -553.992 -553.992] (1.000)
Step: 39099, Reward: [-388.757 -388.757 -388.757] [0.0000], Avg: [-553.781 -553.781 -553.781] (1.000)
Step: 39149, Reward: [-401.595 -401.595 -401.595] [0.0000], Avg: [-553.586 -553.586 -553.586] (1.000)
Step: 39199, Reward: [-414.569 -414.569 -414.569] [0.0000], Avg: [-553.409 -553.409 -553.409] (1.000)
Step: 39249, Reward: [-442.417 -442.417 -442.417] [0.0000], Avg: [-553.268 -553.268 -553.268] (1.000)
Step: 39299, Reward: [-444.747 -444.747 -444.747] [0.0000], Avg: [-553.13 -553.13 -553.13] (1.000)
Step: 39349, Reward: [-403.474 -403.474 -403.474] [0.0000], Avg: [-552.94 -552.94 -552.94] (1.000)
Step: 39399, Reward: [-438.013 -438.013 -438.013] [0.0000], Avg: [-552.794 -552.794 -552.794] (1.000)
Step: 39449, Reward: [-441.259 -441.259 -441.259] [0.0000], Avg: [-552.652 -552.652 -552.652] (1.000)
Step: 39499, Reward: [-501.787 -501.787 -501.787] [0.0000], Avg: [-552.588 -552.588 -552.588] (1.000)
Step: 39549, Reward: [-315.418 -315.418 -315.418] [0.0000], Avg: [-552.288 -552.288 -552.288] (1.000)
Step: 39599, Reward: [-472.528 -472.528 -472.528] [0.0000], Avg: [-552.187 -552.187 -552.187] (1.000)
Step: 39649, Reward: [-371.601 -371.601 -371.601] [0.0000], Avg: [-551.96 -551.96 -551.96] (1.000)
Step: 39699, Reward: [-387.294 -387.294 -387.294] [0.0000], Avg: [-551.752 -551.752 -551.752] (1.000)
Step: 39749, Reward: [-317.309 -317.309 -317.309] [0.0000], Avg: [-551.457 -551.457 -551.457] (1.000)
Step: 39799, Reward: [-318.562 -318.562 -318.562] [0.0000], Avg: [-551.165 -551.165 -551.165] (1.000)
Step: 39849, Reward: [-460.97 -460.97 -460.97] [0.0000], Avg: [-551.052 -551.052 -551.052] (1.000)
Step: 39899, Reward: [-487.874 -487.874 -487.874] [0.0000], Avg: [-550.972 -550.972 -550.972] (1.000)
Step: 39949, Reward: [-475.889 -475.889 -475.889] [0.0000], Avg: [-550.878 -550.878 -550.878] (1.000)
Step: 39999, Reward: [-370.64 -370.64 -370.64] [0.0000], Avg: [-550.653 -550.653 -550.653] (1.000)
Step: 40049, Reward: [-382.96 -382.96 -382.96] [0.0000], Avg: [-550.444 -550.444 -550.444] (1.000)
Step: 40099, Reward: [-368.611 -368.611 -368.611] [0.0000], Avg: [-550.217 -550.217 -550.217] (1.000)
Step: 40149, Reward: [-335.549 -335.549 -335.549] [0.0000], Avg: [-549.95 -549.95 -549.95] (1.000)
Step: 40199, Reward: [-363.421 -363.421 -363.421] [0.0000], Avg: [-549.718 -549.718 -549.718] (1.000)
Step: 40249, Reward: [-507.261 -507.261 -507.261] [0.0000], Avg: [-549.665 -549.665 -549.665] (1.000)
Step: 40299, Reward: [-439.301 -439.301 -439.301] [0.0000], Avg: [-549.528 -549.528 -549.528] (1.000)
Step: 40349, Reward: [-419.53 -419.53 -419.53] [0.0000], Avg: [-549.367 -549.367 -549.367] (1.000)
Step: 40399, Reward: [-342.965 -342.965 -342.965] [0.0000], Avg: [-549.112 -549.112 -549.112] (1.000)
Step: 40449, Reward: [-423.904 -423.904 -423.904] [0.0000], Avg: [-548.957 -548.957 -548.957] (1.000)
Step: 40499, Reward: [-616.215 -616.215 -616.215] [0.0000], Avg: [-549.04 -549.04 -549.04] (1.000)
Step: 40549, Reward: [-299.388 -299.388 -299.388] [0.0000], Avg: [-548.732 -548.732 -548.732] (1.000)
Step: 40599, Reward: [-489.542 -489.542 -489.542] [0.0000], Avg: [-548.659 -548.659 -548.659] (1.000)
Step: 40649, Reward: [-463.352 -463.352 -463.352] [0.0000], Avg: [-548.554 -548.554 -548.554] (1.000)
Step: 40699, Reward: [-475.803 -475.803 -475.803] [0.0000], Avg: [-548.465 -548.465 -548.465] (1.000)
Step: 40749, Reward: [-360.262 -360.262 -360.262] [0.0000], Avg: [-548.234 -548.234 -548.234] (1.000)
Step: 40799, Reward: [-316.823 -316.823 -316.823] [0.0000], Avg: [-547.95 -547.95 -547.95] (1.000)
Step: 40849, Reward: [-532.497 -532.497 -532.497] [0.0000], Avg: [-547.931 -547.931 -547.931] (1.000)
Step: 40899, Reward: [-336.438 -336.438 -336.438] [0.0000], Avg: [-547.673 -547.673 -547.673] (1.000)
Step: 40949, Reward: [-416.892 -416.892 -416.892] [0.0000], Avg: [-547.513 -547.513 -547.513] (1.000)
Step: 40999, Reward: [-365.159 -365.159 -365.159] [0.0000], Avg: [-547.291 -547.291 -547.291] (1.000)
Step: 41049, Reward: [-268.011 -268.011 -268.011] [0.0000], Avg: [-546.951 -546.951 -546.951] (1.000)
Step: 41099, Reward: [-375.523 -375.523 -375.523] [0.0000], Avg: [-546.742 -546.742 -546.742] (1.000)
Step: 41149, Reward: [-377.941 -377.941 -377.941] [0.0000], Avg: [-546.537 -546.537 -546.537] (1.000)
Step: 41199, Reward: [-442.951 -442.951 -442.951] [0.0000], Avg: [-546.411 -546.411 -546.411] (1.000)
Step: 41249, Reward: [-412.195 -412.195 -412.195] [0.0000], Avg: [-546.249 -546.249 -546.249] (1.000)
Step: 41299, Reward: [-440.293 -440.293 -440.293] [0.0000], Avg: [-546.12 -546.12 -546.12] (1.000)
Step: 41349, Reward: [-407.171 -407.171 -407.171] [0.0000], Avg: [-545.952 -545.952 -545.952] (1.000)
Step: 41399, Reward: [-341.5 -341.5 -341.5] [0.0000], Avg: [-545.705 -545.705 -545.705] (1.000)
Step: 41449, Reward: [-394.577 -394.577 -394.577] [0.0000], Avg: [-545.523 -545.523 -545.523] (1.000)
Step: 41499, Reward: [-358.585 -358.585 -358.585] [0.0000], Avg: [-545.298 -545.298 -545.298] (1.000)
Step: 41549, Reward: [-436.997 -436.997 -436.997] [0.0000], Avg: [-545.167 -545.167 -545.167] (1.000)
Step: 41599, Reward: [-379.7 -379.7 -379.7] [0.0000], Avg: [-544.969 -544.969 -544.969] (1.000)
Step: 41649, Reward: [-320.83 -320.83 -320.83] [0.0000], Avg: [-544.7 -544.7 -544.7] (1.000)
Step: 41699, Reward: [-340.937 -340.937 -340.937] [0.0000], Avg: [-544.455 -544.455 -544.455] (1.000)
Step: 41749, Reward: [-325.885 -325.885 -325.885] [0.0000], Avg: [-544.193 -544.193 -544.193] (1.000)
Step: 41799, Reward: [-383.219 -383.219 -383.219] [0.0000], Avg: [-544.001 -544.001 -544.001] (1.000)
Step: 41849, Reward: [-386.29 -386.29 -386.29] [0.0000], Avg: [-543.812 -543.812 -543.812] (1.000)
Step: 41899, Reward: [-440.51 -440.51 -440.51] [0.0000], Avg: [-543.689 -543.689 -543.689] (1.000)
Step: 41949, Reward: [-457.853 -457.853 -457.853] [0.0000], Avg: [-543.587 -543.587 -543.587] (1.000)
Step: 41999, Reward: [-471.883 -471.883 -471.883] [0.0000], Avg: [-543.502 -543.502 -543.502] (1.000)
Step: 42049, Reward: [-333.647 -333.647 -333.647] [0.0000], Avg: [-543.252 -543.252 -543.252] (1.000)
Step: 42099, Reward: [-404.358 -404.358 -404.358] [0.0000], Avg: [-543.087 -543.087 -543.087] (1.000)
Step: 42149, Reward: [-368.37 -368.37 -368.37] [0.0000], Avg: [-542.88 -542.88 -542.88] (1.000)
Step: 42199, Reward: [-349.047 -349.047 -349.047] [0.0000], Avg: [-542.65 -542.65 -542.65] (1.000)
Step: 42249, Reward: [-468.229 -468.229 -468.229] [0.0000], Avg: [-542.562 -542.562 -542.562] (1.000)
Step: 42299, Reward: [-363.343 -363.343 -363.343] [0.0000], Avg: [-542.35 -542.35 -542.35] (1.000)
Step: 42349, Reward: [-341.257 -341.257 -341.257] [0.0000], Avg: [-542.113 -542.113 -542.113] (1.000)
Step: 42399, Reward: [-375.578 -375.578 -375.578] [0.0000], Avg: [-541.916 -541.916 -541.916] (1.000)
Step: 42449, Reward: [-305.576 -305.576 -305.576] [0.0000], Avg: [-541.638 -541.638 -541.638] (1.000)
Step: 42499, Reward: [-453.816 -453.816 -453.816] [0.0000], Avg: [-541.535 -541.535 -541.535] (1.000)
Step: 42549, Reward: [-475.227 -475.227 -475.227] [0.0000], Avg: [-541.457 -541.457 -541.457] (1.000)
Step: 42599, Reward: [-441.685 -441.685 -441.685] [0.0000], Avg: [-541.34 -541.34 -541.34] (1.000)
Step: 42649, Reward: [-453.787 -453.787 -453.787] [0.0000], Avg: [-541.237 -541.237 -541.237] (1.000)
Step: 42699, Reward: [-385.482 -385.482 -385.482] [0.0000], Avg: [-541.055 -541.055 -541.055] (1.000)
Step: 42749, Reward: [-436.014 -436.014 -436.014] [0.0000], Avg: [-540.932 -540.932 -540.932] (1.000)
Step: 42799, Reward: [-285.928 -285.928 -285.928] [0.0000], Avg: [-540.634 -540.634 -540.634] (1.000)
Step: 42849, Reward: [-338.187 -338.187 -338.187] [0.0000], Avg: [-540.398 -540.398 -540.398] (1.000)
Step: 42899, Reward: [-347.442 -347.442 -347.442] [0.0000], Avg: [-540.173 -540.173 -540.173] (1.000)
Step: 42949, Reward: [-392.558 -392.558 -392.558] [0.0000], Avg: [-540.001 -540.001 -540.001] (1.000)
Step: 42999, Reward: [-346.545 -346.545 -346.545] [0.0000], Avg: [-539.776 -539.776 -539.776] (1.000)
Step: 43049, Reward: [-575.856 -575.856 -575.856] [0.0000], Avg: [-539.818 -539.818 -539.818] (1.000)
Step: 43099, Reward: [-491.041 -491.041 -491.041] [0.0000], Avg: [-539.761 -539.761 -539.761] (1.000)
Step: 43149, Reward: [-394.823 -394.823 -394.823] [0.0000], Avg: [-539.593 -539.593 -539.593] (1.000)
Step: 43199, Reward: [-468.682 -468.682 -468.682] [0.0000], Avg: [-539.511 -539.511 -539.511] (1.000)
Step: 43249, Reward: [-369.624 -369.624 -369.624] [0.0000], Avg: [-539.315 -539.315 -539.315] (1.000)
Step: 43299, Reward: [-426.687 -426.687 -426.687] [0.0000], Avg: [-539.185 -539.185 -539.185] (1.000)
Step: 43349, Reward: [-373.179 -373.179 -373.179] [0.0000], Avg: [-538.993 -538.993 -538.993] (1.000)
Step: 43399, Reward: [-401.534 -401.534 -401.534] [0.0000], Avg: [-538.835 -538.835 -538.835] (1.000)
Step: 43449, Reward: [-331.14 -331.14 -331.14] [0.0000], Avg: [-538.596 -538.596 -538.596] (1.000)
Step: 43499, Reward: [-462.09 -462.09 -462.09] [0.0000], Avg: [-538.508 -538.508 -538.508] (1.000)
Step: 43549, Reward: [-433.222 -433.222 -433.222] [0.0000], Avg: [-538.387 -538.387 -538.387] (1.000)
Step: 43599, Reward: [-292.827 -292.827 -292.827] [0.0000], Avg: [-538.106 -538.106 -538.106] (1.000)
Step: 43649, Reward: [-330.45 -330.45 -330.45] [0.0000], Avg: [-537.868 -537.868 -537.868] (1.000)
Step: 43699, Reward: [-385.48 -385.48 -385.48] [0.0000], Avg: [-537.693 -537.693 -537.693] (1.000)
Step: 43749, Reward: [-465.079 -465.079 -465.079] [0.0000], Avg: [-537.61 -537.61 -537.61] (1.000)
Step: 43799, Reward: [-386.345 -386.345 -386.345] [0.0000], Avg: [-537.438 -537.438 -537.438] (1.000)
Step: 43849, Reward: [-334.657 -334.657 -334.657] [0.0000], Avg: [-537.206 -537.206 -537.206] (1.000)
Step: 43899, Reward: [-459.097 -459.097 -459.097] [0.0000], Avg: [-537.117 -537.117 -537.117] (1.000)
Step: 43949, Reward: [-345.473 -345.473 -345.473] [0.0000], Avg: [-536.899 -536.899 -536.899] (1.000)
Step: 43999, Reward: [-334.589 -334.589 -334.589] [0.0000], Avg: [-536.67 -536.67 -536.67] (1.000)
Step: 44049, Reward: [-334.172 -334.172 -334.172] [0.0000], Avg: [-536.44 -536.44 -536.44] (1.000)
Step: 44099, Reward: [-487.036 -487.036 -487.036] [0.0000], Avg: [-536.384 -536.384 -536.384] (1.000)
Step: 44149, Reward: [-326.708 -326.708 -326.708] [0.0000], Avg: [-536.146 -536.146 -536.146] (1.000)
Step: 44199, Reward: [-388.554 -388.554 -388.554] [0.0000], Avg: [-535.979 -535.979 -535.979] (1.000)
Step: 44249, Reward: [-527.155 -527.155 -527.155] [0.0000], Avg: [-535.969 -535.969 -535.969] (1.000)
Step: 44299, Reward: [-375.235 -375.235 -375.235] [0.0000], Avg: [-535.788 -535.788 -535.788] (1.000)
Step: 44349, Reward: [-415.907 -415.907 -415.907] [0.0000], Avg: [-535.653 -535.653 -535.653] (1.000)
Step: 44399, Reward: [-447.267 -447.267 -447.267] [0.0000], Avg: [-535.553 -535.553 -535.553] (1.000)
Step: 44449, Reward: [-465.993 -465.993 -465.993] [0.0000], Avg: [-535.475 -535.475 -535.475] (1.000)
Step: 44499, Reward: [-390.242 -390.242 -390.242] [0.0000], Avg: [-535.312 -535.312 -535.312] (1.000)
Step: 44549, Reward: [-389.815 -389.815 -389.815] [0.0000], Avg: [-535.148 -535.148 -535.148] (1.000)
Step: 44599, Reward: [-419.236 -419.236 -419.236] [0.0000], Avg: [-535.019 -535.019 -535.019] (1.000)
Step: 44649, Reward: [-559.882 -559.882 -559.882] [0.0000], Avg: [-535.046 -535.046 -535.046] (1.000)
Step: 44699, Reward: [-477.945 -477.945 -477.945] [0.0000], Avg: [-534.983 -534.983 -534.983] (1.000)
Step: 44749, Reward: [-422.824 -422.824 -422.824] [0.0000], Avg: [-534.857 -534.857 -534.857] (1.000)
Step: 44799, Reward: [-409.055 -409.055 -409.055] [0.0000], Avg: [-534.717 -534.717 -534.717] (1.000)
Step: 44849, Reward: [-411.709 -411.709 -411.709] [0.0000], Avg: [-534.58 -534.58 -534.58] (1.000)
Step: 44899, Reward: [-440.995 -440.995 -440.995] [0.0000], Avg: [-534.475 -534.475 -534.475] (1.000)
Step: 44949, Reward: [-430.979 -430.979 -430.979] [0.0000], Avg: [-534.36 -534.36 -534.36] (1.000)
Step: 44999, Reward: [-470.761 -470.761 -470.761] [0.0000], Avg: [-534.29 -534.29 -534.29] (1.000)
Step: 45049, Reward: [-336.17 -336.17 -336.17] [0.0000], Avg: [-534.07 -534.07 -534.07] (1.000)
Step: 45099, Reward: [-476.424 -476.424 -476.424] [0.0000], Avg: [-534.006 -534.006 -534.006] (1.000)
Step: 45149, Reward: [-399.362 -399.362 -399.362] [0.0000], Avg: [-533.857 -533.857 -533.857] (1.000)
Step: 45199, Reward: [-342.903 -342.903 -342.903] [0.0000], Avg: [-533.646 -533.646 -533.646] (1.000)
Step: 45249, Reward: [-466.115 -466.115 -466.115] [0.0000], Avg: [-533.571 -533.571 -533.571] (1.000)
Step: 45299, Reward: [-430.974 -430.974 -430.974] [0.0000], Avg: [-533.458 -533.458 -533.458] (1.000)
Step: 45349, Reward: [-452.162 -452.162 -452.162] [0.0000], Avg: [-533.368 -533.368 -533.368] (1.000)
Step: 45399, Reward: [-535.736 -535.736 -535.736] [0.0000], Avg: [-533.371 -533.371 -533.371] (1.000)
Step: 45449, Reward: [-330.213 -330.213 -330.213] [0.0000], Avg: [-533.147 -533.147 -533.147] (1.000)
Step: 45499, Reward: [-427.794 -427.794 -427.794] [0.0000], Avg: [-533.031 -533.031 -533.031] (1.000)
Step: 45549, Reward: [-448.323 -448.323 -448.323] [0.0000], Avg: [-532.938 -532.938 -532.938] (1.000)
Step: 45599, Reward: [-370.569 -370.569 -370.569] [0.0000], Avg: [-532.76 -532.76 -532.76] (1.000)
Step: 45649, Reward: [-337.78 -337.78 -337.78] [0.0000], Avg: [-532.547 -532.547 -532.547] (1.000)
Step: 45699, Reward: [-334.956 -334.956 -334.956] [0.0000], Avg: [-532.331 -532.331 -532.331] (1.000)
Step: 45749, Reward: [-394.397 -394.397 -394.397] [0.0000], Avg: [-532.18 -532.18 -532.18] (1.000)
Step: 45799, Reward: [-316.024 -316.024 -316.024] [0.0000], Avg: [-531.944 -531.944 -531.944] (1.000)
Step: 45849, Reward: [-387.133 -387.133 -387.133] [0.0000], Avg: [-531.786 -531.786 -531.786] (1.000)
Step: 45899, Reward: [-520.046 -520.046 -520.046] [0.0000], Avg: [-531.773 -531.773 -531.773] (1.000)
Step: 45949, Reward: [-349.986 -349.986 -349.986] [0.0000], Avg: [-531.575 -531.575 -531.575] (1.000)
Step: 45999, Reward: [-431.921 -431.921 -431.921] [0.0000], Avg: [-531.467 -531.467 -531.467] (1.000)
Step: 46049, Reward: [-420.277 -420.277 -420.277] [0.0000], Avg: [-531.346 -531.346 -531.346] (1.000)
Step: 46099, Reward: [-433.703 -433.703 -433.703] [0.0000], Avg: [-531.24 -531.24 -531.24] (1.000)
Step: 46149, Reward: [-432.923 -432.923 -432.923] [0.0000], Avg: [-531.134 -531.134 -531.134] (1.000)
Step: 46199, Reward: [-415.646 -415.646 -415.646] [0.0000], Avg: [-531.009 -531.009 -531.009] (1.000)
Step: 46249, Reward: [-422.289 -422.289 -422.289] [0.0000], Avg: [-530.891 -530.891 -530.891] (1.000)
Step: 46299, Reward: [-443.719 -443.719 -443.719] [0.0000], Avg: [-530.797 -530.797 -530.797] (1.000)
Step: 46349, Reward: [-444.606 -444.606 -444.606] [0.0000], Avg: [-530.704 -530.704 -530.704] (1.000)
Step: 46399, Reward: [-493.054 -493.054 -493.054] [0.0000], Avg: [-530.664 -530.664 -530.664] (1.000)
Step: 46449, Reward: [-434.062 -434.062 -434.062] [0.0000], Avg: [-530.56 -530.56 -530.56] (1.000)
Step: 46499, Reward: [-515.203 -515.203 -515.203] [0.0000], Avg: [-530.543 -530.543 -530.543] (1.000)
Step: 46549, Reward: [-319.95 -319.95 -319.95] [0.0000], Avg: [-530.317 -530.317 -530.317] (1.000)
Step: 46599, Reward: [-408.594 -408.594 -408.594] [0.0000], Avg: [-530.186 -530.186 -530.186] (1.000)
Step: 46649, Reward: [-435.917 -435.917 -435.917] [0.0000], Avg: [-530.085 -530.085 -530.085] (1.000)
Step: 46699, Reward: [-413.48 -413.48 -413.48] [0.0000], Avg: [-529.96 -529.96 -529.96] (1.000)
Step: 46749, Reward: [-334.525 -334.525 -334.525] [0.0000], Avg: [-529.751 -529.751 -529.751] (1.000)
Step: 46799, Reward: [-467.249 -467.249 -467.249] [0.0000], Avg: [-529.685 -529.685 -529.685] (1.000)
Step: 46849, Reward: [-362.901 -362.901 -362.901] [0.0000], Avg: [-529.507 -529.507 -529.507] (1.000)
Step: 46899, Reward: [-262.357 -262.357 -262.357] [0.0000], Avg: [-529.222 -529.222 -529.222] (1.000)
Step: 46949, Reward: [-323.86 -323.86 -323.86] [0.0000], Avg: [-529.003 -529.003 -529.003] (1.000)
Step: 46999, Reward: [-350.201 -350.201 -350.201] [0.0000], Avg: [-528.813 -528.813 -528.813] (1.000)
Step: 47049, Reward: [-304.348 -304.348 -304.348] [0.0000], Avg: [-528.574 -528.574 -528.574] (1.000)
Step: 47099, Reward: [-285.999 -285.999 -285.999] [0.0000], Avg: [-528.317 -528.317 -528.317] (1.000)
Step: 47149, Reward: [-404.894 -404.894 -404.894] [0.0000], Avg: [-528.186 -528.186 -528.186] (1.000)
Step: 47199, Reward: [-314.977 -314.977 -314.977] [0.0000], Avg: [-527.96 -527.96 -527.96] (1.000)
Step: 47249, Reward: [-412.635 -412.635 -412.635] [0.0000], Avg: [-527.838 -527.838 -527.838] (1.000)
Step: 47299, Reward: [-474.842 -474.842 -474.842] [0.0000], Avg: [-527.782 -527.782 -527.782] (1.000)
Step: 47349, Reward: [-393.094 -393.094 -393.094] [0.0000], Avg: [-527.64 -527.64 -527.64] (1.000)
Step: 47399, Reward: [-410.319 -410.319 -410.319] [0.0000], Avg: [-527.516 -527.516 -527.516] (1.000)
Step: 47449, Reward: [-281.214 -281.214 -281.214] [0.0000], Avg: [-527.257 -527.257 -527.257] (1.000)
Step: 47499, Reward: [-510.2 -510.2 -510.2] [0.0000], Avg: [-527.239 -527.239 -527.239] (1.000)
Step: 47549, Reward: [-375.155 -375.155 -375.155] [0.0000], Avg: [-527.079 -527.079 -527.079] (1.000)
Step: 47599, Reward: [-314.565 -314.565 -314.565] [0.0000], Avg: [-526.856 -526.856 -526.856] (1.000)
Step: 47649, Reward: [-365.57 -365.57 -365.57] [0.0000], Avg: [-526.686 -526.686 -526.686] (1.000)
Step: 47699, Reward: [-328.554 -328.554 -328.554] [0.0000], Avg: [-526.479 -526.479 -526.479] (1.000)
Step: 47749, Reward: [-336.945 -336.945 -336.945] [0.0000], Avg: [-526.28 -526.28 -526.28] (1.000)
Step: 47799, Reward: [-377.788 -377.788 -377.788] [0.0000], Avg: [-526.125 -526.125 -526.125] (1.000)
Step: 47849, Reward: [-382.512 -382.512 -382.512] [0.0000], Avg: [-525.975 -525.975 -525.975] (1.000)
Step: 47899, Reward: [-397.563 -397.563 -397.563] [0.0000], Avg: [-525.841 -525.841 -525.841] (1.000)
Step: 47949, Reward: [-526.123 -526.123 -526.123] [0.0000], Avg: [-525.841 -525.841 -525.841] (1.000)
Step: 47999, Reward: [-423.302 -423.302 -423.302] [0.0000], Avg: [-525.734 -525.734 -525.734] (1.000)
Step: 48049, Reward: [-496.03 -496.03 -496.03] [0.0000], Avg: [-525.703 -525.703 -525.703] (1.000)
Step: 48099, Reward: [-434.036 -434.036 -434.036] [0.0000], Avg: [-525.608 -525.608 -525.608] (1.000)
Step: 48149, Reward: [-474.931 -474.931 -474.931] [0.0000], Avg: [-525.555 -525.555 -525.555] (1.000)
Step: 48199, Reward: [-390.734 -390.734 -390.734] [0.0000], Avg: [-525.415 -525.415 -525.415] (1.000)
Step: 48249, Reward: [-388.034 -388.034 -388.034] [0.0000], Avg: [-525.273 -525.273 -525.273] (1.000)
Step: 48299, Reward: [-600.942 -600.942 -600.942] [0.0000], Avg: [-525.351 -525.351 -525.351] (1.000)
Step: 48349, Reward: [-528.246 -528.246 -528.246] [0.0000], Avg: [-525.354 -525.354 -525.354] (1.000)
Step: 48399, Reward: [-479.629 -479.629 -479.629] [0.0000], Avg: [-525.307 -525.307 -525.307] (1.000)
Step: 48449, Reward: [-381.243 -381.243 -381.243] [0.0000], Avg: [-525.159 -525.159 -525.159] (1.000)
Step: 48499, Reward: [-360.821 -360.821 -360.821] [0.0000], Avg: [-524.989 -524.989 -524.989] (1.000)
Step: 48549, Reward: [-426.404 -426.404 -426.404] [0.0000], Avg: [-524.888 -524.888 -524.888] (1.000)
Step: 48599, Reward: [-436.478 -436.478 -436.478] [0.0000], Avg: [-524.797 -524.797 -524.797] (1.000)
Step: 48649, Reward: [-424.194 -424.194 -424.194] [0.0000], Avg: [-524.693 -524.693 -524.693] (1.000)
Step: 48699, Reward: [-379.294 -379.294 -379.294] [0.0000], Avg: [-524.544 -524.544 -524.544] (1.000)
Step: 48749, Reward: [-445.787 -445.787 -445.787] [0.0000], Avg: [-524.463 -524.463 -524.463] (1.000)
Step: 48799, Reward: [-426.231 -426.231 -426.231] [0.0000], Avg: [-524.363 -524.363 -524.363] (1.000)
Step: 48849, Reward: [-407.806 -407.806 -407.806] [0.0000], Avg: [-524.243 -524.243 -524.243] (1.000)
Step: 48899, Reward: [-457.288 -457.288 -457.288] [0.0000], Avg: [-524.175 -524.175 -524.175] (1.000)
Step: 48949, Reward: [-325.794 -325.794 -325.794] [0.0000], Avg: [-523.972 -523.972 -523.972] (1.000)
Step: 48999, Reward: [-552.217 -552.217 -552.217] [0.0000], Avg: [-524.001 -524.001 -524.001] (1.000)
Step: 49049, Reward: [-453.664 -453.664 -453.664] [0.0000], Avg: [-523.929 -523.929 -523.929] (1.000)
Step: 49099, Reward: [-357.681 -357.681 -357.681] [0.0000], Avg: [-523.76 -523.76 -523.76] (1.000)
Step: 49149, Reward: [-456.615 -456.615 -456.615] [0.0000], Avg: [-523.692 -523.692 -523.692] (1.000)
Step: 49199, Reward: [-468.618 -468.618 -468.618] [0.0000], Avg: [-523.636 -523.636 -523.636] (1.000)
Step: 49249, Reward: [-358.686 -358.686 -358.686] [0.0000], Avg: [-523.468 -523.468 -523.468] (1.000)
Step: 49299, Reward: [-346.654 -346.654 -346.654] [0.0000], Avg: [-523.289 -523.289 -523.289] (1.000)
Step: 49349, Reward: [-402.176 -402.176 -402.176] [0.0000], Avg: [-523.166 -523.166 -523.166] (1.000)
Step: 49399, Reward: [-464.073 -464.073 -464.073] [0.0000], Avg: [-523.106 -523.106 -523.106] (1.000)
Step: 49449, Reward: [-329.073 -329.073 -329.073] [0.0000], Avg: [-522.91 -522.91 -522.91] (1.000)
Step: 49499, Reward: [-286.13 -286.13 -286.13] [0.0000], Avg: [-522.671 -522.671 -522.671] (1.000)
Step: 49549, Reward: [-393.114 -393.114 -393.114] [0.0000], Avg: [-522.54 -522.54 -522.54] (1.000)
Step: 49599, Reward: [-305.212 -305.212 -305.212] [0.0000], Avg: [-522.321 -522.321 -522.321] (1.000)
Step: 49649, Reward: [-448.115 -448.115 -448.115] [0.0000], Avg: [-522.246 -522.246 -522.246] (1.000)
Step: 49699, Reward: [-379.051 -379.051 -379.051] [0.0000], Avg: [-522.102 -522.102 -522.102] (1.000)
Step: 49749, Reward: [-301.023 -301.023 -301.023] [0.0000], Avg: [-521.88 -521.88 -521.88] (1.000)
Step: 49799, Reward: [-464.785 -464.785 -464.785] [0.0000], Avg: [-521.823 -521.823 -521.823] (1.000)
Step: 49849, Reward: [-353.585 -353.585 -353.585] [0.0000], Avg: [-521.654 -521.654 -521.654] (1.000)
Step: 49899, Reward: [-493.261 -493.261 -493.261] [0.0000], Avg: [-521.626 -521.626 -521.626] (1.000)
Step: 49949, Reward: [-500.209 -500.209 -500.209] [0.0000], Avg: [-521.604 -521.604 -521.604] (1.000)
Step: 49999, Reward: [-449.431 -449.431 -449.431] [0.0000], Avg: [-521.532 -521.532 -521.532] (1.000)
Step: 50049, Reward: [-311.139 -311.139 -311.139] [0.0000], Avg: [-521.322 -521.322 -521.322] (1.000)
Step: 50099, Reward: [-409.514 -409.514 -409.514] [0.0000], Avg: [-521.21 -521.21 -521.21] (1.000)
Step: 50149, Reward: [-370.082 -370.082 -370.082] [0.0000], Avg: [-521.06 -521.06 -521.06] (1.000)
Step: 50199, Reward: [-318.485 -318.485 -318.485] [0.0000], Avg: [-520.858 -520.858 -520.858] (1.000)
Step: 50249, Reward: [-468.406 -468.406 -468.406] [0.0000], Avg: [-520.806 -520.806 -520.806] (1.000)
Step: 50299, Reward: [-373.297 -373.297 -373.297] [0.0000], Avg: [-520.659 -520.659 -520.659] (1.000)
Step: 50349, Reward: [-386.668 -386.668 -386.668] [0.0000], Avg: [-520.526 -520.526 -520.526] (1.000)
Step: 50399, Reward: [-312.584 -312.584 -312.584] [0.0000], Avg: [-520.32 -520.32 -520.32] (1.000)
Step: 50449, Reward: [-432.496 -432.496 -432.496] [0.0000], Avg: [-520.233 -520.233 -520.233] (1.000)
Step: 50499, Reward: [-292.767 -292.767 -292.767] [0.0000], Avg: [-520.007 -520.007 -520.007] (1.000)
Step: 50549, Reward: [-451.261 -451.261 -451.261] [0.0000], Avg: [-519.939 -519.939 -519.939] (1.000)
Step: 50599, Reward: [-325.568 -325.568 -325.568] [0.0000], Avg: [-519.747 -519.747 -519.747] (1.000)
Step: 50649, Reward: [-373.108 -373.108 -373.108] [0.0000], Avg: [-519.603 -519.603 -519.603] (1.000)
Step: 50699, Reward: [-321.635 -321.635 -321.635] [0.0000], Avg: [-519.407 -519.407 -519.407] (1.000)
Step: 50749, Reward: [-394.224 -394.224 -394.224] [0.0000], Avg: [-519.284 -519.284 -519.284] (1.000)
Step: 50799, Reward: [-369.377 -369.377 -369.377] [0.0000], Avg: [-519.137 -519.137 -519.137] (1.000)
Step: 50849, Reward: [-301.271 -301.271 -301.271] [0.0000], Avg: [-518.922 -518.922 -518.922] (1.000)
Step: 50899, Reward: [-410.607 -410.607 -410.607] [0.0000], Avg: [-518.816 -518.816 -518.816] (1.000)
Step: 50949, Reward: [-394.364 -394.364 -394.364] [0.0000], Avg: [-518.694 -518.694 -518.694] (1.000)
Step: 50999, Reward: [-307.68 -307.68 -307.68] [0.0000], Avg: [-518.487 -518.487 -518.487] (1.000)
Step: 51049, Reward: [-331.069 -331.069 -331.069] [0.0000], Avg: [-518.303 -518.303 -518.303] (1.000)
Step: 51099, Reward: [-385.532 -385.532 -385.532] [0.0000], Avg: [-518.173 -518.173 -518.173] (1.000)
Step: 51149, Reward: [-499.09 -499.09 -499.09] [0.0000], Avg: [-518.155 -518.155 -518.155] (1.000)
Step: 51199, Reward: [-316.948 -316.948 -316.948] [0.0000], Avg: [-517.958 -517.958 -517.958] (1.000)
Step: 51249, Reward: [-323.398 -323.398 -323.398] [0.0000], Avg: [-517.768 -517.768 -517.768] (1.000)
Step: 51299, Reward: [-428.078 -428.078 -428.078] [0.0000], Avg: [-517.681 -517.681 -517.681] (1.000)
Step: 51349, Reward: [-339.129 -339.129 -339.129] [0.0000], Avg: [-517.507 -517.507 -517.507] (1.000)
Step: 51399, Reward: [-381.112 -381.112 -381.112] [0.0000], Avg: [-517.374 -517.374 -517.374] (1.000)
Step: 51449, Reward: [-329.426 -329.426 -329.426] [0.0000], Avg: [-517.192 -517.192 -517.192] (1.000)
Step: 51499, Reward: [-350.626 -350.626 -350.626] [0.0000], Avg: [-517.03 -517.03 -517.03] (1.000)
Step: 51549, Reward: [-488.932 -488.932 -488.932] [0.0000], Avg: [-517.003 -517.003 -517.003] (1.000)
Step: 51599, Reward: [-423.949 -423.949 -423.949] [0.0000], Avg: [-516.913 -516.913 -516.913] (1.000)
Step: 51649, Reward: [-446.8 -446.8 -446.8] [0.0000], Avg: [-516.845 -516.845 -516.845] (1.000)
Step: 51699, Reward: [-375.964 -375.964 -375.964] [0.0000], Avg: [-516.709 -516.709 -516.709] (1.000)
Step: 51749, Reward: [-384.289 -384.289 -384.289] [0.0000], Avg: [-516.581 -516.581 -516.581] (1.000)
Step: 51799, Reward: [-303.321 -303.321 -303.321] [0.0000], Avg: [-516.375 -516.375 -516.375] (1.000)
Step: 51849, Reward: [-456.257 -456.257 -456.257] [0.0000], Avg: [-516.317 -516.317 -516.317] (1.000)
Step: 51899, Reward: [-339.622 -339.622 -339.622] [0.0000], Avg: [-516.147 -516.147 -516.147] (1.000)
Step: 51949, Reward: [-444.721 -444.721 -444.721] [0.0000], Avg: [-516.078 -516.078 -516.078] (1.000)
Step: 51999, Reward: [-473.403 -473.403 -473.403] [0.0000], Avg: [-516.037 -516.037 -516.037] (1.000)
Step: 52049, Reward: [-411.89 -411.89 -411.89] [0.0000], Avg: [-515.937 -515.937 -515.937] (1.000)
Step: 52099, Reward: [-502.961 -502.961 -502.961] [0.0000], Avg: [-515.924 -515.924 -515.924] (1.000)
Step: 52149, Reward: [-452.476 -452.476 -452.476] [0.0000], Avg: [-515.863 -515.863 -515.863] (1.000)
Step: 52199, Reward: [-451.72 -451.72 -451.72] [0.0000], Avg: [-515.802 -515.802 -515.802] (1.000)
Step: 52249, Reward: [-445.354 -445.354 -445.354] [0.0000], Avg: [-515.735 -515.735 -515.735] (1.000)
Step: 52299, Reward: [-384.106 -384.106 -384.106] [0.0000], Avg: [-515.609 -515.609 -515.609] (1.000)
Step: 52349, Reward: [-326.04 -326.04 -326.04] [0.0000], Avg: [-515.428 -515.428 -515.428] (1.000)
Step: 52399, Reward: [-412.177 -412.177 -412.177] [0.0000], Avg: [-515.329 -515.329 -515.329] (1.000)
Step: 52449, Reward: [-362.571 -362.571 -362.571] [0.0000], Avg: [-515.184 -515.184 -515.184] (1.000)
Step: 52499, Reward: [-459.538 -459.538 -459.538] [0.0000], Avg: [-515.131 -515.131 -515.131] (1.000)
Step: 52549, Reward: [-326.43 -326.43 -326.43] [0.0000], Avg: [-514.951 -514.951 -514.951] (1.000)
Step: 52599, Reward: [-456.278 -456.278 -456.278] [0.0000], Avg: [-514.895 -514.895 -514.895] (1.000)
Step: 52649, Reward: [-434.237 -434.237 -434.237] [0.0000], Avg: [-514.819 -514.819 -514.819] (1.000)
Step: 52699, Reward: [-356.656 -356.656 -356.656] [0.0000], Avg: [-514.669 -514.669 -514.669] (1.000)
Step: 52749, Reward: [-396.75 -396.75 -396.75] [0.0000], Avg: [-514.557 -514.557 -514.557] (1.000)
Step: 52799, Reward: [-363.137 -363.137 -363.137] [0.0000], Avg: [-514.413 -514.413 -514.413] (1.000)
Step: 52849, Reward: [-400.842 -400.842 -400.842] [0.0000], Avg: [-514.306 -514.306 -514.306] (1.000)
Step: 52899, Reward: [-450.272 -450.272 -450.272] [0.0000], Avg: [-514.245 -514.245 -514.245] (1.000)
Step: 52949, Reward: [-387.602 -387.602 -387.602] [0.0000], Avg: [-514.126 -514.126 -514.126] (1.000)
Step: 52999, Reward: [-361.662 -361.662 -361.662] [0.0000], Avg: [-513.982 -513.982 -513.982] (1.000)
Step: 53049, Reward: [-407.221 -407.221 -407.221] [0.0000], Avg: [-513.881 -513.881 -513.881] (1.000)
Step: 53099, Reward: [-313.898 -313.898 -313.898] [0.0000], Avg: [-513.693 -513.693 -513.693] (1.000)
Step: 53149, Reward: [-326.306 -326.306 -326.306] [0.0000], Avg: [-513.517 -513.517 -513.517] (1.000)
Step: 53199, Reward: [-436.912 -436.912 -436.912] [0.0000], Avg: [-513.445 -513.445 -513.445] (1.000)
Step: 53249, Reward: [-415.658 -415.658 -415.658] [0.0000], Avg: [-513.353 -513.353 -513.353] (1.000)
Step: 53299, Reward: [-429.989 -429.989 -429.989] [0.0000], Avg: [-513.275 -513.275 -513.275] (1.000)
Step: 53349, Reward: [-397.461 -397.461 -397.461] [0.0000], Avg: [-513.166 -513.166 -513.166] (1.000)
Step: 53399, Reward: [-279.053 -279.053 -279.053] [0.0000], Avg: [-512.947 -512.947 -512.947] (1.000)
Step: 53449, Reward: [-507.149 -507.149 -507.149] [0.0000], Avg: [-512.942 -512.942 -512.942] (1.000)
Step: 53499, Reward: [-374.04 -374.04 -374.04] [0.0000], Avg: [-512.812 -512.812 -512.812] (1.000)
Step: 53549, Reward: [-449.052 -449.052 -449.052] [0.0000], Avg: [-512.752 -512.752 -512.752] (1.000)
Step: 53599, Reward: [-319.502 -319.502 -319.502] [0.0000], Avg: [-512.572 -512.572 -512.572] (1.000)
Step: 53649, Reward: [-517.658 -517.658 -517.658] [0.0000], Avg: [-512.577 -512.577 -512.577] (1.000)
Step: 53699, Reward: [-449.283 -449.283 -449.283] [0.0000], Avg: [-512.518 -512.518 -512.518] (1.000)
Step: 53749, Reward: [-456.097 -456.097 -456.097] [0.0000], Avg: [-512.465 -512.465 -512.465] (1.000)
Step: 53799, Reward: [-290.809 -290.809 -290.809] [0.0000], Avg: [-512.259 -512.259 -512.259] (1.000)
Step: 53849, Reward: [-386.023 -386.023 -386.023] [0.0000], Avg: [-512.142 -512.142 -512.142] (1.000)
Step: 53899, Reward: [-432.539 -432.539 -432.539] [0.0000], Avg: [-512.068 -512.068 -512.068] (1.000)
Step: 53949, Reward: [-490.055 -490.055 -490.055] [0.0000], Avg: [-512.048 -512.048 -512.048] (1.000)
Step: 53999, Reward: [-443.042 -443.042 -443.042] [0.0000], Avg: [-511.984 -511.984 -511.984] (1.000)
Step: 54049, Reward: [-347.103 -347.103 -347.103] [0.0000], Avg: [-511.831 -511.831 -511.831] (1.000)
Step: 54099, Reward: [-543.772 -543.772 -543.772] [0.0000], Avg: [-511.861 -511.861 -511.861] (1.000)
Step: 54149, Reward: [-448.966 -448.966 -448.966] [0.0000], Avg: [-511.803 -511.803 -511.803] (1.000)
Step: 54199, Reward: [-474.813 -474.813 -474.813] [0.0000], Avg: [-511.769 -511.769 -511.769] (1.000)
Step: 54249, Reward: [-457.445 -457.445 -457.445] [0.0000], Avg: [-511.719 -511.719 -511.719] (1.000)
Step: 54299, Reward: [-421.409 -421.409 -421.409] [0.0000], Avg: [-511.636 -511.636 -511.636] (1.000)
Step: 54349, Reward: [-515.658 -515.658 -515.658] [0.0000], Avg: [-511.639 -511.639 -511.639] (1.000)
Step: 54399, Reward: [-501.484 -501.484 -501.484] [0.0000], Avg: [-511.63 -511.63 -511.63] (1.000)
Step: 54449, Reward: [-355.713 -355.713 -355.713] [0.0000], Avg: [-511.487 -511.487 -511.487] (1.000)
Step: 54499, Reward: [-407.179 -407.179 -407.179] [0.0000], Avg: [-511.391 -511.391 -511.391] (1.000)
Step: 54549, Reward: [-448.863 -448.863 -448.863] [0.0000], Avg: [-511.334 -511.334 -511.334] (1.000)
Step: 54599, Reward: [-446.877 -446.877 -446.877] [0.0000], Avg: [-511.275 -511.275 -511.275] (1.000)
Step: 54649, Reward: [-413.804 -413.804 -413.804] [0.0000], Avg: [-511.186 -511.186 -511.186] (1.000)
Step: 54699, Reward: [-386.338 -386.338 -386.338] [0.0000], Avg: [-511.071 -511.071 -511.071] (1.000)
Step: 54749, Reward: [-452.855 -452.855 -452.855] [0.0000], Avg: [-511.018 -511.018 -511.018] (1.000)
Step: 54799, Reward: [-380.974 -380.974 -380.974] [0.0000], Avg: [-510.9 -510.9 -510.9] (1.000)
Step: 54849, Reward: [-408.208 -408.208 -408.208] [0.0000], Avg: [-510.806 -510.806 -510.806] (1.000)
Step: 54899, Reward: [-261.055 -261.055 -261.055] [0.0000], Avg: [-510.579 -510.579 -510.579] (1.000)
Step: 54949, Reward: [-501.625 -501.625 -501.625] [0.0000], Avg: [-510.57 -510.57 -510.57] (1.000)
Step: 54999, Reward: [-418.23 -418.23 -418.23] [0.0000], Avg: [-510.486 -510.486 -510.486] (1.000)
Step: 55049, Reward: [-444.233 -444.233 -444.233] [0.0000], Avg: [-510.426 -510.426 -510.426] (1.000)
Step: 55099, Reward: [-436.489 -436.489 -436.489] [0.0000], Avg: [-510.359 -510.359 -510.359] (1.000)
Step: 55149, Reward: [-381.691 -381.691 -381.691] [0.0000], Avg: [-510.243 -510.243 -510.243] (1.000)
Step: 55199, Reward: [-480.418 -480.418 -480.418] [0.0000], Avg: [-510.216 -510.216 -510.216] (1.000)
Step: 55249, Reward: [-304.069 -304.069 -304.069] [0.0000], Avg: [-510.029 -510.029 -510.029] (1.000)
Step: 55299, Reward: [-361.019 -361.019 -361.019] [0.0000], Avg: [-509.894 -509.894 -509.894] (1.000)
Step: 55349, Reward: [-389.487 -389.487 -389.487] [0.0000], Avg: [-509.785 -509.785 -509.785] (1.000)
Step: 55399, Reward: [-376.516 -376.516 -376.516] [0.0000], Avg: [-509.665 -509.665 -509.665] (1.000)
Step: 55449, Reward: [-477.641 -477.641 -477.641] [0.0000], Avg: [-509.636 -509.636 -509.636] (1.000)
Step: 55499, Reward: [-434.284 -434.284 -434.284] [0.0000], Avg: [-509.568 -509.568 -509.568] (1.000)
Step: 55549, Reward: [-428.701 -428.701 -428.701] [0.0000], Avg: [-509.496 -509.496 -509.496] (1.000)
Step: 55599, Reward: [-323.911 -323.911 -323.911] [0.0000], Avg: [-509.329 -509.329 -509.329] (1.000)
Step: 55649, Reward: [-433.456 -433.456 -433.456] [0.0000], Avg: [-509.261 -509.261 -509.261] (1.000)
Step: 55699, Reward: [-487.863 -487.863 -487.863] [0.0000], Avg: [-509.241 -509.241 -509.241] (1.000)
Step: 55749, Reward: [-298.657 -298.657 -298.657] [0.0000], Avg: [-509.053 -509.053 -509.053] (1.000)
Step: 55799, Reward: [-365.809 -365.809 -365.809] [0.0000], Avg: [-508.924 -508.924 -508.924] (1.000)
Step: 55849, Reward: [-493.893 -493.893 -493.893] [0.0000], Avg: [-508.911 -508.911 -508.911] (1.000)
Step: 55899, Reward: [-500.71 -500.71 -500.71] [0.0000], Avg: [-508.903 -508.903 -508.903] (1.000)
Step: 55949, Reward: [-454.312 -454.312 -454.312] [0.0000], Avg: [-508.855 -508.855 -508.855] (1.000)
Step: 55999, Reward: [-418.652 -418.652 -418.652] [0.0000], Avg: [-508.774 -508.774 -508.774] (1.000)
Step: 56049, Reward: [-430.055 -430.055 -430.055] [0.0000], Avg: [-508.704 -508.704 -508.704] (1.000)
Step: 56099, Reward: [-386.691 -386.691 -386.691] [0.0000], Avg: [-508.595 -508.595 -508.595] (1.000)
Step: 56149, Reward: [-385.693 -385.693 -385.693] [0.0000], Avg: [-508.486 -508.486 -508.486] (1.000)
Step: 56199, Reward: [-366.904 -366.904 -366.904] [0.0000], Avg: [-508.36 -508.36 -508.36] (1.000)
Step: 56249, Reward: [-413.344 -413.344 -413.344] [0.0000], Avg: [-508.275 -508.275 -508.275] (1.000)
Step: 56299, Reward: [-348.271 -348.271 -348.271] [0.0000], Avg: [-508.133 -508.133 -508.133] (1.000)
Step: 56349, Reward: [-428.901 -428.901 -428.901] [0.0000], Avg: [-508.063 -508.063 -508.063] (1.000)
Step: 56399, Reward: [-389.759 -389.759 -389.759] [0.0000], Avg: [-507.958 -507.958 -507.958] (1.000)
Step: 56449, Reward: [-474.561 -474.561 -474.561] [0.0000], Avg: [-507.928 -507.928 -507.928] (1.000)
Step: 56499, Reward: [-374.962 -374.962 -374.962] [0.0000], Avg: [-507.811 -507.811 -507.811] (1.000)
Step: 56549, Reward: [-325.194 -325.194 -325.194] [0.0000], Avg: [-507.649 -507.649 -507.649] (1.000)
Step: 56599, Reward: [-433.253 -433.253 -433.253] [0.0000], Avg: [-507.583 -507.583 -507.583] (1.000)
Step: 56649, Reward: [-269.045 -269.045 -269.045] [0.0000], Avg: [-507.373 -507.373 -507.373] (1.000)
Step: 56699, Reward: [-379.306 -379.306 -379.306] [0.0000], Avg: [-507.26 -507.26 -507.26] (1.000)
Step: 56749, Reward: [-420.217 -420.217 -420.217] [0.0000], Avg: [-507.183 -507.183 -507.183] (1.000)
Step: 56799, Reward: [-399.854 -399.854 -399.854] [0.0000], Avg: [-507.089 -507.089 -507.089] (1.000)
Step: 56849, Reward: [-345.835 -345.835 -345.835] [0.0000], Avg: [-506.947 -506.947 -506.947] (1.000)
Step: 56899, Reward: [-451.676 -451.676 -451.676] [0.0000], Avg: [-506.898 -506.898 -506.898] (1.000)
Step: 56949, Reward: [-400.724 -400.724 -400.724] [0.0000], Avg: [-506.805 -506.805 -506.805] (1.000)
Step: 56999, Reward: [-304.812 -304.812 -304.812] [0.0000], Avg: [-506.628 -506.628 -506.628] (1.000)
Step: 57049, Reward: [-488.945 -488.945 -488.945] [0.0000], Avg: [-506.613 -506.613 -506.613] (1.000)
Step: 57099, Reward: [-494.188 -494.188 -494.188] [0.0000], Avg: [-506.602 -506.602 -506.602] (1.000)
Step: 57149, Reward: [-314.236 -314.236 -314.236] [0.0000], Avg: [-506.433 -506.433 -506.433] (1.000)
Step: 57199, Reward: [-404.276 -404.276 -404.276] [0.0000], Avg: [-506.344 -506.344 -506.344] (1.000)
Step: 57249, Reward: [-464.973 -464.973 -464.973] [0.0000], Avg: [-506.308 -506.308 -506.308] (1.000)
Step: 57299, Reward: [-461.884 -461.884 -461.884] [0.0000], Avg: [-506.269 -506.269 -506.269] (1.000)
Step: 57349, Reward: [-264.598 -264.598 -264.598] [0.0000], Avg: [-506.058 -506.058 -506.058] (1.000)
Step: 57399, Reward: [-426.832 -426.832 -426.832] [0.0000], Avg: [-505.989 -505.989 -505.989] (1.000)
Step: 57449, Reward: [-401.561 -401.561 -401.561] [0.0000], Avg: [-505.899 -505.899 -505.899] (1.000)
Step: 57499, Reward: [-356.814 -356.814 -356.814] [0.0000], Avg: [-505.769 -505.769 -505.769] (1.000)
Step: 57549, Reward: [-346.13 -346.13 -346.13] [0.0000], Avg: [-505.63 -505.63 -505.63] (1.000)
Step: 57599, Reward: [-322.428 -322.428 -322.428] [0.0000], Avg: [-505.471 -505.471 -505.471] (1.000)
Step: 57649, Reward: [-380.212 -380.212 -380.212] [0.0000], Avg: [-505.363 -505.363 -505.363] (1.000)
Step: 57699, Reward: [-301.681 -301.681 -301.681] [0.0000], Avg: [-505.186 -505.186 -505.186] (1.000)
Step: 57749, Reward: [-419.151 -419.151 -419.151] [0.0000], Avg: [-505.112 -505.112 -505.112] (1.000)
Step: 57799, Reward: [-356.645 -356.645 -356.645] [0.0000], Avg: [-504.983 -504.983 -504.983] (1.000)
Step: 57849, Reward: [-419.938 -419.938 -419.938] [0.0000], Avg: [-504.91 -504.91 -504.91] (1.000)
Step: 57899, Reward: [-302.576 -302.576 -302.576] [0.0000], Avg: [-504.735 -504.735 -504.735] (1.000)
Step: 57949, Reward: [-390.472 -390.472 -390.472] [0.0000], Avg: [-504.636 -504.636 -504.636] (1.000)
Step: 57999, Reward: [-404.287 -404.287 -404.287] [0.0000], Avg: [-504.55 -504.55 -504.55] (1.000)
Step: 58049, Reward: [-412.086 -412.086 -412.086] [0.0000], Avg: [-504.47 -504.47 -504.47] (1.000)
Step: 58099, Reward: [-376.74 -376.74 -376.74] [0.0000], Avg: [-504.36 -504.36 -504.36] (1.000)
Step: 58149, Reward: [-318.899 -318.899 -318.899] [0.0000], Avg: [-504.201 -504.201 -504.201] (1.000)
Step: 58199, Reward: [-414.277 -414.277 -414.277] [0.0000], Avg: [-504.124 -504.124 -504.124] (1.000)
Step: 58249, Reward: [-523.894 -523.894 -523.894] [0.0000], Avg: [-504.141 -504.141 -504.141] (1.000)
Step: 58299, Reward: [-357.317 -357.317 -357.317] [0.0000], Avg: [-504.015 -504.015 -504.015] (1.000)
Step: 58349, Reward: [-292.459 -292.459 -292.459] [0.0000], Avg: [-503.833 -503.833 -503.833] (1.000)
Step: 58399, Reward: [-414.198 -414.198 -414.198] [0.0000], Avg: [-503.757 -503.757 -503.757] (1.000)
Step: 58449, Reward: [-266.911 -266.911 -266.911] [0.0000], Avg: [-503.554 -503.554 -503.554] (1.000)
Step: 58499, Reward: [-422.755 -422.755 -422.755] [0.0000], Avg: [-503.485 -503.485 -503.485] (1.000)
Step: 58549, Reward: [-350.467 -350.467 -350.467] [0.0000], Avg: [-503.354 -503.354 -503.354] (1.000)
Step: 58599, Reward: [-329.953 -329.953 -329.953] [0.0000], Avg: [-503.206 -503.206 -503.206] (1.000)
Step: 58649, Reward: [-408.179 -408.179 -408.179] [0.0000], Avg: [-503.125 -503.125 -503.125] (1.000)
Step: 58699, Reward: [-336.46 -336.46 -336.46] [0.0000], Avg: [-502.983 -502.983 -502.983] (1.000)
Step: 58749, Reward: [-310.61 -310.61 -310.61] [0.0000], Avg: [-502.82 -502.82 -502.82] (1.000)
Step: 58799, Reward: [-312.303 -312.303 -312.303] [0.0000], Avg: [-502.658 -502.658 -502.658] (1.000)
Step: 58849, Reward: [-404.212 -404.212 -404.212] [0.0000], Avg: [-502.574 -502.574 -502.574] (1.000)
Step: 58899, Reward: [-326.319 -326.319 -326.319] [0.0000], Avg: [-502.424 -502.424 -502.424] (1.000)
Step: 58949, Reward: [-412.043 -412.043 -412.043] [0.0000], Avg: [-502.348 -502.348 -502.348] (1.000)
Step: 58999, Reward: [-389.729 -389.729 -389.729] [0.0000], Avg: [-502.252 -502.252 -502.252] (1.000)
Step: 59049, Reward: [-289.632 -289.632 -289.632] [0.0000], Avg: [-502.072 -502.072 -502.072] (1.000)
Step: 59099, Reward: [-419.528 -419.528 -419.528] [0.0000], Avg: [-502.002 -502.002 -502.002] (1.000)
Step: 59149, Reward: [-316.081 -316.081 -316.081] [0.0000], Avg: [-501.845 -501.845 -501.845] (1.000)
Step: 59199, Reward: [-382.496 -382.496 -382.496] [0.0000], Avg: [-501.744 -501.744 -501.744] (1.000)
Step: 59249, Reward: [-424.278 -424.278 -424.278] [0.0000], Avg: [-501.679 -501.679 -501.679] (1.000)
Step: 59299, Reward: [-417.844 -417.844 -417.844] [0.0000], Avg: [-501.608 -501.608 -501.608] (1.000)
Step: 59349, Reward: [-360.108 -360.108 -360.108] [0.0000], Avg: [-501.489 -501.489 -501.489] (1.000)
Step: 59399, Reward: [-451.806 -451.806 -451.806] [0.0000], Avg: [-501.447 -501.447 -501.447] (1.000)
Step: 59449, Reward: [-396.174 -396.174 -396.174] [0.0000], Avg: [-501.359 -501.359 -501.359] (1.000)
Step: 59499, Reward: [-403.82 -403.82 -403.82] [0.0000], Avg: [-501.277 -501.277 -501.277] (1.000)
Step: 59549, Reward: [-450.315 -450.315 -450.315] [0.0000], Avg: [-501.234 -501.234 -501.234] (1.000)
Step: 59599, Reward: [-389.145 -389.145 -389.145] [0.0000], Avg: [-501.14 -501.14 -501.14] (1.000)
Step: 59649, Reward: [-386.892 -386.892 -386.892] [0.0000], Avg: [-501.044 -501.044 -501.044] (1.000)
Step: 59699, Reward: [-313.62 -313.62 -313.62] [0.0000], Avg: [-500.887 -500.887 -500.887] (1.000)
Step: 59749, Reward: [-445.545 -445.545 -445.545] [0.0000], Avg: [-500.841 -500.841 -500.841] (1.000)
Step: 59799, Reward: [-346.919 -346.919 -346.919] [0.0000], Avg: [-500.712 -500.712 -500.712] (1.000)
Step: 59849, Reward: [-404.359 -404.359 -404.359] [0.0000], Avg: [-500.632 -500.632 -500.632] (1.000)
Step: 59899, Reward: [-385.214 -385.214 -385.214] [0.0000], Avg: [-500.535 -500.535 -500.535] (1.000)
Step: 59949, Reward: [-453.813 -453.813 -453.813] [0.0000], Avg: [-500.496 -500.496 -500.496] (1.000)
Step: 59999, Reward: [-362.925 -362.925 -362.925] [0.0000], Avg: [-500.382 -500.382 -500.382] (1.000)
Step: 60049, Reward: [-436.439 -436.439 -436.439] [0.0000], Avg: [-500.329 -500.329 -500.329] (1.000)
Step: 60099, Reward: [-379.254 -379.254 -379.254] [0.0000], Avg: [-500.228 -500.228 -500.228] (1.000)
Step: 60149, Reward: [-376.07 -376.07 -376.07] [0.0000], Avg: [-500.125 -500.125 -500.125] (1.000)
Step: 60199, Reward: [-383.178 -383.178 -383.178] [0.0000], Avg: [-500.027 -500.027 -500.027] (1.000)
Step: 60249, Reward: [-428.197 -428.197 -428.197] [0.0000], Avg: [-499.968 -499.968 -499.968] (1.000)
Step: 60299, Reward: [-345.764 -345.764 -345.764] [0.0000], Avg: [-499.84 -499.84 -499.84] (1.000)
Step: 60349, Reward: [-478.852 -478.852 -478.852] [0.0000], Avg: [-499.823 -499.823 -499.823] (1.000)
Step: 60399, Reward: [-371.286 -371.286 -371.286] [0.0000], Avg: [-499.716 -499.716 -499.716] (1.000)
Step: 60449, Reward: [-364.89 -364.89 -364.89] [0.0000], Avg: [-499.605 -499.605 -499.605] (1.000)
Step: 60499, Reward: [-438.105 -438.105 -438.105] [0.0000], Avg: [-499.554 -499.554 -499.554] (1.000)
Step: 60549, Reward: [-567.187 -567.187 -567.187] [0.0000], Avg: [-499.61 -499.61 -499.61] (1.000)
Step: 60599, Reward: [-475.424 -475.424 -475.424] [0.0000], Avg: [-499.59 -499.59 -499.59] (1.000)
Step: 60649, Reward: [-332.54 -332.54 -332.54] [0.0000], Avg: [-499.452 -499.452 -499.452] (1.000)
Step: 60699, Reward: [-403.615 -403.615 -403.615] [0.0000], Avg: [-499.373 -499.373 -499.373] (1.000)
Step: 60749, Reward: [-450.148 -450.148 -450.148] [0.0000], Avg: [-499.333 -499.333 -499.333] (1.000)
Step: 60799, Reward: [-439.312 -439.312 -439.312] [0.0000], Avg: [-499.283 -499.283 -499.283] (1.000)
Step: 60849, Reward: [-432.978 -432.978 -432.978] [0.0000], Avg: [-499.229 -499.229 -499.229] (1.000)
Step: 60899, Reward: [-438.319 -438.319 -438.319] [0.0000], Avg: [-499.179 -499.179 -499.179] (1.000)
Step: 60949, Reward: [-367.374 -367.374 -367.374] [0.0000], Avg: [-499.071 -499.071 -499.071] (1.000)
Step: 60999, Reward: [-422.252 -422.252 -422.252] [0.0000], Avg: [-499.008 -499.008 -499.008] (1.000)
Step: 61049, Reward: [-372.227 -372.227 -372.227] [0.0000], Avg: [-498.904 -498.904 -498.904] (1.000)
Step: 61099, Reward: [-436.289 -436.289 -436.289] [0.0000], Avg: [-498.853 -498.853 -498.853] (1.000)
Step: 61149, Reward: [-299.845 -299.845 -299.845] [0.0000], Avg: [-498.69 -498.69 -498.69] (1.000)
Step: 61199, Reward: [-370.054 -370.054 -370.054] [0.0000], Avg: [-498.585 -498.585 -498.585] (1.000)
Step: 61249, Reward: [-323.732 -323.732 -323.732] [0.0000], Avg: [-498.442 -498.442 -498.442] (1.000)
Step: 61299, Reward: [-402.831 -402.831 -402.831] [0.0000], Avg: [-498.364 -498.364 -498.364] (1.000)
Step: 61349, Reward: [-344.549 -344.549 -344.549] [0.0000], Avg: [-498.239 -498.239 -498.239] (1.000)
Step: 61399, Reward: [-344.292 -344.292 -344.292] [0.0000], Avg: [-498.113 -498.113 -498.113] (1.000)
Step: 61449, Reward: [-340.571 -340.571 -340.571] [0.0000], Avg: [-497.985 -497.985 -497.985] (1.000)
Step: 61499, Reward: [-374.081 -374.081 -374.081] [0.0000], Avg: [-497.884 -497.884 -497.884] (1.000)
Step: 61549, Reward: [-292.929 -292.929 -292.929] [0.0000], Avg: [-497.718 -497.718 -497.718] (1.000)
Step: 61599, Reward: [-353.134 -353.134 -353.134] [0.0000], Avg: [-497.601 -497.601 -497.601] (1.000)
Step: 61649, Reward: [-363.829 -363.829 -363.829] [0.0000], Avg: [-497.492 -497.492 -497.492] (1.000)
Step: 61699, Reward: [-274.953 -274.953 -274.953] [0.0000], Avg: [-497.312 -497.312 -497.312] (1.000)
Step: 61749, Reward: [-296.681 -296.681 -296.681] [0.0000], Avg: [-497.149 -497.149 -497.149] (1.000)
Step: 61799, Reward: [-354.202 -354.202 -354.202] [0.0000], Avg: [-497.034 -497.034 -497.034] (1.000)
Step: 61849, Reward: [-386.137 -386.137 -386.137] [0.0000], Avg: [-496.944 -496.944 -496.944] (1.000)
Step: 61899, Reward: [-421.304 -421.304 -421.304] [0.0000], Avg: [-496.883 -496.883 -496.883] (1.000)
Step: 61949, Reward: [-332.057 -332.057 -332.057] [0.0000], Avg: [-496.75 -496.75 -496.75] (1.000)
Step: 61999, Reward: [-412.464 -412.464 -412.464] [0.0000], Avg: [-496.682 -496.682 -496.682] (1.000)
Step: 62049, Reward: [-286.923 -286.923 -286.923] [0.0000], Avg: [-496.513 -496.513 -496.513] (1.000)
Step: 62099, Reward: [-442.215 -442.215 -442.215] [0.0000], Avg: [-496.469 -496.469 -496.469] (1.000)
Step: 62149, Reward: [-323.286 -323.286 -323.286] [0.0000], Avg: [-496.33 -496.33 -496.33] (1.000)
Step: 62199, Reward: [-466.283 -466.283 -466.283] [0.0000], Avg: [-496.306 -496.306 -496.306] (1.000)
Step: 62249, Reward: [-280.05 -280.05 -280.05] [0.0000], Avg: [-496.132 -496.132 -496.132] (1.000)
Step: 62299, Reward: [-348.498 -348.498 -348.498] [0.0000], Avg: [-496.013 -496.013 -496.013] (1.000)
Step: 62349, Reward: [-444.987 -444.987 -444.987] [0.0000], Avg: [-495.973 -495.973 -495.973] (1.000)
Step: 62399, Reward: [-406.757 -406.757 -406.757] [0.0000], Avg: [-495.901 -495.901 -495.901] (1.000)
Step: 62449, Reward: [-425.921 -425.921 -425.921] [0.0000], Avg: [-495.845 -495.845 -495.845] (1.000)
Step: 62499, Reward: [-450.691 -450.691 -450.691] [0.0000], Avg: [-495.809 -495.809 -495.809] (1.000)
Step: 62549, Reward: [-435.077 -435.077 -435.077] [0.0000], Avg: [-495.76 -495.76 -495.76] (1.000)
Step: 62599, Reward: [-382.435 -382.435 -382.435] [0.0000], Avg: [-495.67 -495.67 -495.67] (1.000)
Step: 62649, Reward: [-369.096 -369.096 -369.096] [0.0000], Avg: [-495.569 -495.569 -495.569] (1.000)
Step: 62699, Reward: [-307.315 -307.315 -307.315] [0.0000], Avg: [-495.419 -495.419 -495.419] (1.000)
Step: 62749, Reward: [-404.201 -404.201 -404.201] [0.0000], Avg: [-495.346 -495.346 -495.346] (1.000)
Step: 62799, Reward: [-347.147 -347.147 -347.147] [0.0000], Avg: [-495.228 -495.228 -495.228] (1.000)
Step: 62849, Reward: [-412.563 -412.563 -412.563] [0.0000], Avg: [-495.162 -495.162 -495.162] (1.000)
Step: 62899, Reward: [-367.725 -367.725 -367.725] [0.0000], Avg: [-495.061 -495.061 -495.061] (1.000)
Step: 62949, Reward: [-497.472 -497.472 -497.472] [0.0000], Avg: [-495.063 -495.063 -495.063] (1.000)
Step: 62999, Reward: [-373.936 -373.936 -373.936] [0.0000], Avg: [-494.967 -494.967 -494.967] (1.000)
Step: 63049, Reward: [-306.306 -306.306 -306.306] [0.0000], Avg: [-494.817 -494.817 -494.817] (1.000)
Step: 63099, Reward: [-317.576 -317.576 -317.576] [0.0000], Avg: [-494.677 -494.677 -494.677] (1.000)
Step: 63149, Reward: [-340.694 -340.694 -340.694] [0.0000], Avg: [-494.555 -494.555 -494.555] (1.000)
Step: 63199, Reward: [-447.838 -447.838 -447.838] [0.0000], Avg: [-494.518 -494.518 -494.518] (1.000)
Step: 63249, Reward: [-397.272 -397.272 -397.272] [0.0000], Avg: [-494.441 -494.441 -494.441] (1.000)
Step: 63299, Reward: [-294.557 -294.557 -294.557] [0.0000], Avg: [-494.283 -494.283 -494.283] (1.000)
Step: 63349, Reward: [-364.765 -364.765 -364.765] [0.0000], Avg: [-494.181 -494.181 -494.181] (1.000)
Step: 63399, Reward: [-472.472 -472.472 -472.472] [0.0000], Avg: [-494.164 -494.164 -494.164] (1.000)
Step: 63449, Reward: [-403.881 -403.881 -403.881] [0.0000], Avg: [-494.093 -494.093 -494.093] (1.000)
Step: 63499, Reward: [-431.931 -431.931 -431.931] [0.0000], Avg: [-494.044 -494.044 -494.044] (1.000)
Step: 63549, Reward: [-342.931 -342.931 -342.931] [0.0000], Avg: [-493.925 -493.925 -493.925] (1.000)
Step: 63599, Reward: [-448.776 -448.776 -448.776] [0.0000], Avg: [-493.889 -493.889 -493.889] (1.000)
Step: 63649, Reward: [-275.96 -275.96 -275.96] [0.0000], Avg: [-493.718 -493.718 -493.718] (1.000)
Step: 63699, Reward: [-382.662 -382.662 -382.662] [0.0000], Avg: [-493.631 -493.631 -493.631] (1.000)
Step: 63749, Reward: [-406.406 -406.406 -406.406] [0.0000], Avg: [-493.562 -493.562 -493.562] (1.000)
Step: 63799, Reward: [-488.704 -488.704 -488.704] [0.0000], Avg: [-493.559 -493.559 -493.559] (1.000)
Step: 63849, Reward: [-469.76 -469.76 -469.76] [0.0000], Avg: [-493.54 -493.54 -493.54] (1.000)
Step: 63899, Reward: [-310.817 -310.817 -310.817] [0.0000], Avg: [-493.397 -493.397 -493.397] (1.000)
Step: 63949, Reward: [-475.486 -475.486 -475.486] [0.0000], Avg: [-493.383 -493.383 -493.383] (1.000)
Step: 63999, Reward: [-294.553 -294.553 -294.553] [0.0000], Avg: [-493.228 -493.228 -493.228] (1.000)
Step: 64049, Reward: [-314.508 -314.508 -314.508] [0.0000], Avg: [-493.088 -493.088 -493.088] (1.000)
Step: 64099, Reward: [-359.419 -359.419 -359.419] [0.0000], Avg: [-492.984 -492.984 -492.984] (1.000)
Step: 64149, Reward: [-468.676 -468.676 -468.676] [0.0000], Avg: [-492.965 -492.965 -492.965] (1.000)
Step: 64199, Reward: [-378.455 -378.455 -378.455] [0.0000], Avg: [-492.876 -492.876 -492.876] (1.000)
Step: 64249, Reward: [-286.357 -286.357 -286.357] [0.0000], Avg: [-492.715 -492.715 -492.715] (1.000)
Step: 64299, Reward: [-280.902 -280.902 -280.902] [0.0000], Avg: [-492.55 -492.55 -492.55] (1.000)
Step: 64349, Reward: [-405.256 -405.256 -405.256] [0.0000], Avg: [-492.482 -492.482 -492.482] (1.000)
Step: 64399, Reward: [-386.968 -386.968 -386.968] [0.0000], Avg: [-492.401 -492.401 -492.401] (1.000)
Step: 64449, Reward: [-245.962 -245.962 -245.962] [0.0000], Avg: [-492.209 -492.209 -492.209] (1.000)
Step: 64499, Reward: [-345.553 -345.553 -345.553] [0.0000], Avg: [-492.096 -492.096 -492.096] (1.000)
Step: 64549, Reward: [-488.557 -488.557 -488.557] [0.0000], Avg: [-492.093 -492.093 -492.093] (1.000)
Step: 64599, Reward: [-312.979 -312.979 -312.979] [0.0000], Avg: [-491.954 -491.954 -491.954] (1.000)
Step: 64649, Reward: [-381.082 -381.082 -381.082] [0.0000], Avg: [-491.869 -491.869 -491.869] (1.000)
Step: 64699, Reward: [-348.369 -348.369 -348.369] [0.0000], Avg: [-491.758 -491.758 -491.758] (1.000)
Step: 64749, Reward: [-343.267 -343.267 -343.267] [0.0000], Avg: [-491.643 -491.643 -491.643] (1.000)
Step: 64799, Reward: [-327.515 -327.515 -327.515] [0.0000], Avg: [-491.516 -491.516 -491.516] (1.000)
Step: 64849, Reward: [-434.173 -434.173 -434.173] [0.0000], Avg: [-491.472 -491.472 -491.472] (1.000)
Step: 64899, Reward: [-363.757 -363.757 -363.757] [0.0000], Avg: [-491.374 -491.374 -491.374] (1.000)
Step: 64949, Reward: [-442.785 -442.785 -442.785] [0.0000], Avg: [-491.336 -491.336 -491.336] (1.000)
Step: 64999, Reward: [-332.388 -332.388 -332.388] [0.0000], Avg: [-491.214 -491.214 -491.214] (1.000)
Step: 65049, Reward: [-378.611 -378.611 -378.611] [0.0000], Avg: [-491.128 -491.128 -491.128] (1.000)
Step: 65099, Reward: [-329.284 -329.284 -329.284] [0.0000], Avg: [-491.003 -491.003 -491.003] (1.000)
Step: 65149, Reward: [-274.921 -274.921 -274.921] [0.0000], Avg: [-490.837 -490.837 -490.837] (1.000)
Step: 65199, Reward: [-408.561 -408.561 -408.561] [0.0000], Avg: [-490.774 -490.774 -490.774] (1.000)
Step: 65249, Reward: [-367.79 -367.79 -367.79] [0.0000], Avg: [-490.68 -490.68 -490.68] (1.000)
Step: 65299, Reward: [-300.6 -300.6 -300.6] [0.0000], Avg: [-490.535 -490.535 -490.535] (1.000)
Step: 65349, Reward: [-392.157 -392.157 -392.157] [0.0000], Avg: [-490.459 -490.459 -490.459] (1.000)
Step: 65399, Reward: [-323.33 -323.33 -323.33] [0.0000], Avg: [-490.331 -490.331 -490.331] (1.000)
Step: 65449, Reward: [-330.92 -330.92 -330.92] [0.0000], Avg: [-490.21 -490.21 -490.21] (1.000)
Step: 65499, Reward: [-343.882 -343.882 -343.882] [0.0000], Avg: [-490.098 -490.098 -490.098] (1.000)
Step: 65549, Reward: [-325.408 -325.408 -325.408] [0.0000], Avg: [-489.972 -489.972 -489.972] (1.000)
Step: 65599, Reward: [-452.589 -452.589 -452.589] [0.0000], Avg: [-489.944 -489.944 -489.944] (1.000)
Step: 65649, Reward: [-559.723 -559.723 -559.723] [0.0000], Avg: [-489.997 -489.997 -489.997] (1.000)
Step: 65699, Reward: [-331.08 -331.08 -331.08] [0.0000], Avg: [-489.876 -489.876 -489.876] (1.000)
Step: 65749, Reward: [-344.767 -344.767 -344.767] [0.0000], Avg: [-489.766 -489.766 -489.766] (1.000)
Step: 65799, Reward: [-473.583 -473.583 -473.583] [0.0000], Avg: [-489.753 -489.753 -489.753] (1.000)
Step: 65849, Reward: [-422.62 -422.62 -422.62] [0.0000], Avg: [-489.702 -489.702 -489.702] (1.000)
Step: 65899, Reward: [-482.71 -482.71 -482.71] [0.0000], Avg: [-489.697 -489.697 -489.697] (1.000)
Step: 65949, Reward: [-362.666 -362.666 -362.666] [0.0000], Avg: [-489.601 -489.601 -489.601] (1.000)
Step: 65999, Reward: [-290.177 -290.177 -290.177] [0.0000], Avg: [-489.45 -489.45 -489.45] (1.000)
Step: 66049, Reward: [-489.437 -489.437 -489.437] [0.0000], Avg: [-489.45 -489.45 -489.45] (1.000)
Step: 66099, Reward: [-500.791 -500.791 -500.791] [0.0000], Avg: [-489.458 -489.458 -489.458] (1.000)
Step: 66149, Reward: [-504.62 -504.62 -504.62] [0.0000], Avg: [-489.47 -489.47 -489.47] (1.000)
Step: 66199, Reward: [-450.042 -450.042 -450.042] [0.0000], Avg: [-489.44 -489.44 -489.44] (1.000)
Step: 66249, Reward: [-355.249 -355.249 -355.249] [0.0000], Avg: [-489.339 -489.339 -489.339] (1.000)
Step: 66299, Reward: [-342.059 -342.059 -342.059] [0.0000], Avg: [-489.228 -489.228 -489.228] (1.000)
Step: 66349, Reward: [-326.147 -326.147 -326.147] [0.0000], Avg: [-489.105 -489.105 -489.105] (1.000)
Step: 66399, Reward: [-418.885 -418.885 -418.885] [0.0000], Avg: [-489.052 -489.052 -489.052] (1.000)
Step: 66449, Reward: [-420.487 -420.487 -420.487] [0.0000], Avg: [-489. -489. -489.] (1.000)
Step: 66499, Reward: [-363.717 -363.717 -363.717] [0.0000], Avg: [-488.906 -488.906 -488.906] (1.000)
Step: 66549, Reward: [-523.639 -523.639 -523.639] [0.0000], Avg: [-488.932 -488.932 -488.932] (1.000)
Step: 66599, Reward: [-480.205 -480.205 -480.205] [0.0000], Avg: [-488.926 -488.926 -488.926] (1.000)
Step: 66649, Reward: [-333.753 -333.753 -333.753] [0.0000], Avg: [-488.809 -488.809 -488.809] (1.000)
Step: 66699, Reward: [-377.437 -377.437 -377.437] [0.0000], Avg: [-488.726 -488.726 -488.726] (1.000)
Step: 66749, Reward: [-411.556 -411.556 -411.556] [0.0000], Avg: [-488.668 -488.668 -488.668] (1.000)
Step: 66799, Reward: [-364.008 -364.008 -364.008] [0.0000], Avg: [-488.575 -488.575 -488.575] (1.000)
Step: 66849, Reward: [-360.383 -360.383 -360.383] [0.0000], Avg: [-488.479 -488.479 -488.479] (1.000)
Step: 66899, Reward: [-442.982 -442.982 -442.982] [0.0000], Avg: [-488.445 -488.445 -488.445] (1.000)
Step: 66949, Reward: [-297.567 -297.567 -297.567] [0.0000], Avg: [-488.302 -488.302 -488.302] (1.000)
Step: 66999, Reward: [-396.028 -396.028 -396.028] [0.0000], Avg: [-488.233 -488.233 -488.233] (1.000)
Step: 67049, Reward: [-436.369 -436.369 -436.369] [0.0000], Avg: [-488.195 -488.195 -488.195] (1.000)
Step: 67099, Reward: [-499.309 -499.309 -499.309] [0.0000], Avg: [-488.203 -488.203 -488.203] (1.000)
Step: 67149, Reward: [-385.688 -385.688 -385.688] [0.0000], Avg: [-488.127 -488.127 -488.127] (1.000)
Step: 67199, Reward: [-315.483 -315.483 -315.483] [0.0000], Avg: [-487.998 -487.998 -487.998] (1.000)
Step: 67249, Reward: [-445.527 -445.527 -445.527] [0.0000], Avg: [-487.967 -487.967 -487.967] (1.000)
Step: 67299, Reward: [-398.494 -398.494 -398.494] [0.0000], Avg: [-487.9 -487.9 -487.9] (1.000)
Step: 67349, Reward: [-403.19 -403.19 -403.19] [0.0000], Avg: [-487.837 -487.837 -487.837] (1.000)
Step: 67399, Reward: [-249.418 -249.418 -249.418] [0.0000], Avg: [-487.66 -487.66 -487.66] (1.000)
Step: 67449, Reward: [-346.231 -346.231 -346.231] [0.0000], Avg: [-487.556 -487.556 -487.556] (1.000)
Step: 67499, Reward: [-381.695 -381.695 -381.695] [0.0000], Avg: [-487.477 -487.477 -487.477] (1.000)
Step: 67549, Reward: [-401.383 -401.383 -401.383] [0.0000], Avg: [-487.413 -487.413 -487.413] (1.000)
Step: 67599, Reward: [-485.616 -485.616 -485.616] [0.0000], Avg: [-487.412 -487.412 -487.412] (1.000)
Step: 67649, Reward: [-354.724 -354.724 -354.724] [0.0000], Avg: [-487.314 -487.314 -487.314] (1.000)
Step: 67699, Reward: [-386.135 -386.135 -386.135] [0.0000], Avg: [-487.239 -487.239 -487.239] (1.000)
Step: 67749, Reward: [-311.406 -311.406 -311.406] [0.0000], Avg: [-487.109 -487.109 -487.109] (1.000)
Step: 67799, Reward: [-257.264 -257.264 -257.264] [0.0000], Avg: [-486.94 -486.94 -486.94] (1.000)
Step: 67849, Reward: [-318.851 -318.851 -318.851] [0.0000], Avg: [-486.816 -486.816 -486.816] (1.000)
Step: 67899, Reward: [-385.349 -385.349 -385.349] [0.0000], Avg: [-486.741 -486.741 -486.741] (1.000)
Step: 67949, Reward: [-464.396 -464.396 -464.396] [0.0000], Avg: [-486.725 -486.725 -486.725] (1.000)
Step: 67999, Reward: [-369.338 -369.338 -369.338] [0.0000], Avg: [-486.639 -486.639 -486.639] (1.000)
Step: 68049, Reward: [-397.746 -397.746 -397.746] [0.0000], Avg: [-486.573 -486.573 -486.573] (1.000)
Step: 68099, Reward: [-371.791 -371.791 -371.791] [0.0000], Avg: [-486.489 -486.489 -486.489] (1.000)
Step: 68149, Reward: [-455.112 -455.112 -455.112] [0.0000], Avg: [-486.466 -486.466 -486.466] (1.000)
Step: 68199, Reward: [-394.64 -394.64 -394.64] [0.0000], Avg: [-486.399 -486.399 -486.399] (1.000)
Step: 68249, Reward: [-443.668 -443.668 -443.668] [0.0000], Avg: [-486.367 -486.367 -486.367] (1.000)
Step: 68299, Reward: [-394.982 -394.982 -394.982] [0.0000], Avg: [-486.301 -486.301 -486.301] (1.000)
Step: 68349, Reward: [-408.212 -408.212 -408.212] [0.0000], Avg: [-486.243 -486.243 -486.243] (1.000)
Step: 68399, Reward: [-483.212 -483.212 -483.212] [0.0000], Avg: [-486.241 -486.241 -486.241] (1.000)
Step: 68449, Reward: [-300.956 -300.956 -300.956] [0.0000], Avg: [-486.106 -486.106 -486.106] (1.000)
Step: 68499, Reward: [-481.538 -481.538 -481.538] [0.0000], Avg: [-486.102 -486.102 -486.102] (1.000)
Step: 68549, Reward: [-308.379 -308.379 -308.379] [0.0000], Avg: [-485.973 -485.973 -485.973] (1.000)
Step: 68599, Reward: [-388.983 -388.983 -388.983] [0.0000], Avg: [-485.902 -485.902 -485.902] (1.000)
Step: 68649, Reward: [-308.223 -308.223 -308.223] [0.0000], Avg: [-485.773 -485.773 -485.773] (1.000)
Step: 68699, Reward: [-270.584 -270.584 -270.584] [0.0000], Avg: [-485.616 -485.616 -485.616] (1.000)
Step: 68749, Reward: [-393.074 -393.074 -393.074] [0.0000], Avg: [-485.549 -485.549 -485.549] (1.000)
Step: 68799, Reward: [-370.27 -370.27 -370.27] [0.0000], Avg: [-485.465 -485.465 -485.465] (1.000)
Step: 68849, Reward: [-327.988 -327.988 -327.988] [0.0000], Avg: [-485.351 -485.351 -485.351] (1.000)
Step: 68899, Reward: [-253.339 -253.339 -253.339] [0.0000], Avg: [-485.182 -485.182 -485.182] (1.000)
Step: 68949, Reward: [-315.005 -315.005 -315.005] [0.0000], Avg: [-485.059 -485.059 -485.059] (1.000)
Step: 68999, Reward: [-319.967 -319.967 -319.967] [0.0000], Avg: [-484.939 -484.939 -484.939] (1.000)
Step: 69049, Reward: [-411.815 -411.815 -411.815] [0.0000], Avg: [-484.886 -484.886 -484.886] (1.000)
Step: 69099, Reward: [-313.967 -313.967 -313.967] [0.0000], Avg: [-484.763 -484.763 -484.763] (1.000)
Step: 69149, Reward: [-334.964 -334.964 -334.964] [0.0000], Avg: [-484.654 -484.654 -484.654] (1.000)
Step: 69199, Reward: [-380.652 -380.652 -380.652] [0.0000], Avg: [-484.579 -484.579 -484.579] (1.000)
Step: 69249, Reward: [-317.514 -317.514 -317.514] [0.0000], Avg: [-484.459 -484.459 -484.459] (1.000)
Step: 69299, Reward: [-415.05 -415.05 -415.05] [0.0000], Avg: [-484.409 -484.409 -484.409] (1.000)
Step: 69349, Reward: [-306.99 -306.99 -306.99] [0.0000], Avg: [-484.281 -484.281 -484.281] (1.000)
Step: 69399, Reward: [-359.563 -359.563 -359.563] [0.0000], Avg: [-484.191 -484.191 -484.191] (1.000)
Step: 69449, Reward: [-419.681 -419.681 -419.681] [0.0000], Avg: [-484.144 -484.144 -484.144] (1.000)
Step: 69499, Reward: [-349.191 -349.191 -349.191] [0.0000], Avg: [-484.047 -484.047 -484.047] (1.000)
Step: 69549, Reward: [-385.504 -385.504 -385.504] [0.0000], Avg: [-483.976 -483.976 -483.976] (1.000)
Step: 69599, Reward: [-445.742 -445.742 -445.742] [0.0000], Avg: [-483.949 -483.949 -483.949] (1.000)
Step: 69649, Reward: [-418.364 -418.364 -418.364] [0.0000], Avg: [-483.902 -483.902 -483.902] (1.000)
Step: 69699, Reward: [-396.265 -396.265 -396.265] [0.0000], Avg: [-483.839 -483.839 -483.839] (1.000)
Step: 69749, Reward: [-473.368 -473.368 -473.368] [0.0000], Avg: [-483.831 -483.831 -483.831] (1.000)
Step: 69799, Reward: [-320.604 -320.604 -320.604] [0.0000], Avg: [-483.715 -483.715 -483.715] (1.000)
Step: 69849, Reward: [-396.44 -396.44 -396.44] [0.0000], Avg: [-483.652 -483.652 -483.652] (1.000)
Step: 69899, Reward: [-324.908 -324.908 -324.908] [0.0000], Avg: [-483.538 -483.538 -483.538] (1.000)
Step: 69949, Reward: [-367.924 -367.924 -367.924] [0.0000], Avg: [-483.456 -483.456 -483.456] (1.000)
Step: 69999, Reward: [-442.465 -442.465 -442.465] [0.0000], Avg: [-483.427 -483.427 -483.427] (1.000)
Step: 70049, Reward: [-423.344 -423.344 -423.344] [0.0000], Avg: [-483.384 -483.384 -483.384] (1.000)
Step: 70099, Reward: [-342.333 -342.333 -342.333] [0.0000], Avg: [-483.283 -483.283 -483.283] (1.000)
Step: 70149, Reward: [-347.332 -347.332 -347.332] [0.0000], Avg: [-483.186 -483.186 -483.186] (1.000)
Step: 70199, Reward: [-357.742 -357.742 -357.742] [0.0000], Avg: [-483.097 -483.097 -483.097] (1.000)
Step: 70249, Reward: [-375.308 -375.308 -375.308] [0.0000], Avg: [-483.02 -483.02 -483.02] (1.000)
Step: 70299, Reward: [-359.465 -359.465 -359.465] [0.0000], Avg: [-482.932 -482.932 -482.932] (1.000)
Step: 70349, Reward: [-406.999 -406.999 -406.999] [0.0000], Avg: [-482.878 -482.878 -482.878] (1.000)
Step: 70399, Reward: [-485.209 -485.209 -485.209] [0.0000], Avg: [-482.88 -482.88 -482.88] (1.000)
Step: 70449, Reward: [-407.946 -407.946 -407.946] [0.0000], Avg: [-482.827 -482.827 -482.827] (1.000)
Step: 70499, Reward: [-370.598 -370.598 -370.598] [0.0000], Avg: [-482.747 -482.747 -482.747] (1.000)
Step: 70549, Reward: [-426.833 -426.833 -426.833] [0.0000], Avg: [-482.708 -482.708 -482.708] (1.000)
Step: 70599, Reward: [-333.646 -333.646 -333.646] [0.0000], Avg: [-482.602 -482.602 -482.602] (1.000)
Step: 70649, Reward: [-469.913 -469.913 -469.913] [0.0000], Avg: [-482.593 -482.593 -482.593] (1.000)
Step: 70699, Reward: [-421.757 -421.757 -421.757] [0.0000], Avg: [-482.55 -482.55 -482.55] (1.000)
Step: 70749, Reward: [-342.936 -342.936 -342.936] [0.0000], Avg: [-482.451 -482.451 -482.451] (1.000)
Step: 70799, Reward: [-396.973 -396.973 -396.973] [0.0000], Avg: [-482.391 -482.391 -482.391] (1.000)
Step: 70849, Reward: [-292.788 -292.788 -292.788] [0.0000], Avg: [-482.257 -482.257 -482.257] (1.000)
Step: 70899, Reward: [-464.052 -464.052 -464.052] [0.0000], Avg: [-482.244 -482.244 -482.244] (1.000)
Step: 70949, Reward: [-378.77 -378.77 -378.77] [0.0000], Avg: [-482.171 -482.171 -482.171] (1.000)
Step: 70999, Reward: [-394.938 -394.938 -394.938] [0.0000], Avg: [-482.11 -482.11 -482.11] (1.000)
Step: 71049, Reward: [-484.407 -484.407 -484.407] [0.0000], Avg: [-482.112 -482.112 -482.112] (1.000)
Step: 71099, Reward: [-493.644 -493.644 -493.644] [0.0000], Avg: [-482.12 -482.12 -482.12] (1.000)
Step: 71149, Reward: [-425.086 -425.086 -425.086] [0.0000], Avg: [-482.08 -482.08 -482.08] (1.000)
Step: 71199, Reward: [-269.374 -269.374 -269.374] [0.0000], Avg: [-481.93 -481.93 -481.93] (1.000)
Step: 71249, Reward: [-347.404 -347.404 -347.404] [0.0000], Avg: [-481.836 -481.836 -481.836] (1.000)
Step: 71299, Reward: [-416.322 -416.322 -416.322] [0.0000], Avg: [-481.79 -481.79 -481.79] (1.000)
Step: 71349, Reward: [-372.789 -372.789 -372.789] [0.0000], Avg: [-481.713 -481.713 -481.713] (1.000)
Step: 71399, Reward: [-426.189 -426.189 -426.189] [0.0000], Avg: [-481.675 -481.675 -481.675] (1.000)
Step: 71449, Reward: [-298.523 -298.523 -298.523] [0.0000], Avg: [-481.546 -481.546 -481.546] (1.000)
Step: 71499, Reward: [-517.124 -517.124 -517.124] [0.0000], Avg: [-481.571 -481.571 -481.571] (1.000)
Step: 71549, Reward: [-424.537 -424.537 -424.537] [0.0000], Avg: [-481.531 -481.531 -481.531] (1.000)
Step: 71599, Reward: [-412.682 -412.682 -412.682] [0.0000], Avg: [-481.483 -481.483 -481.483] (1.000)
Step: 71649, Reward: [-418.84 -418.84 -418.84] [0.0000], Avg: [-481.44 -481.44 -481.44] (1.000)
Step: 71699, Reward: [-397.77 -397.77 -397.77] [0.0000], Avg: [-481.381 -481.381 -481.381] (1.000)
Step: 71749, Reward: [-443.101 -443.101 -443.101] [0.0000], Avg: [-481.355 -481.355 -481.355] (1.000)
Step: 71799, Reward: [-451.958 -451.958 -451.958] [0.0000], Avg: [-481.334 -481.334 -481.334] (1.000)
Step: 71849, Reward: [-400.525 -400.525 -400.525] [0.0000], Avg: [-481.278 -481.278 -481.278] (1.000)
Step: 71899, Reward: [-433.699 -433.699 -433.699] [0.0000], Avg: [-481.245 -481.245 -481.245] (1.000)
Step: 71949, Reward: [-424.256 -424.256 -424.256] [0.0000], Avg: [-481.205 -481.205 -481.205] (1.000)
Step: 71999, Reward: [-431.273 -431.273 -431.273] [0.0000], Avg: [-481.171 -481.171 -481.171] (1.000)
Step: 72049, Reward: [-419.04 -419.04 -419.04] [0.0000], Avg: [-481.127 -481.127 -481.127] (1.000)
Step: 72099, Reward: [-481.281 -481.281 -481.281] [0.0000], Avg: [-481.128 -481.128 -481.128] (1.000)
Step: 72149, Reward: [-355.745 -355.745 -355.745] [0.0000], Avg: [-481.041 -481.041 -481.041] (1.000)
Step: 72199, Reward: [-443.554 -443.554 -443.554] [0.0000], Avg: [-481.015 -481.015 -481.015] (1.000)
Step: 72249, Reward: [-440.848 -440.848 -440.848] [0.0000], Avg: [-480.987 -480.987 -480.987] (1.000)
Step: 72299, Reward: [-365.633 -365.633 -365.633] [0.0000], Avg: [-480.907 -480.907 -480.907] (1.000)
Step: 72349, Reward: [-468.945 -468.945 -468.945] [0.0000], Avg: [-480.899 -480.899 -480.899] (1.000)
Step: 72399, Reward: [-434.39 -434.39 -434.39] [0.0000], Avg: [-480.867 -480.867 -480.867] (1.000)
Step: 72449, Reward: [-412.858 -412.858 -412.858] [0.0000], Avg: [-480.82 -480.82 -480.82] (1.000)
Step: 72499, Reward: [-306.437 -306.437 -306.437] [0.0000], Avg: [-480.7 -480.7 -480.7] (1.000)
Step: 72549, Reward: [-416.405 -416.405 -416.405] [0.0000], Avg: [-480.655 -480.655 -480.655] (1.000)
Step: 72599, Reward: [-465.689 -465.689 -465.689] [0.0000], Avg: [-480.645 -480.645 -480.645] (1.000)
Step: 72649, Reward: [-540.519 -540.519 -540.519] [0.0000], Avg: [-480.686 -480.686 -480.686] (1.000)
Step: 72699, Reward: [-540.848 -540.848 -540.848] [0.0000], Avg: [-480.727 -480.727 -480.727] (1.000)
Step: 72749, Reward: [-346.794 -346.794 -346.794] [0.0000], Avg: [-480.635 -480.635 -480.635] (1.000)
Step: 72799, Reward: [-370.516 -370.516 -370.516] [0.0000], Avg: [-480.56 -480.56 -480.56] (1.000)
Step: 72849, Reward: [-430.829 -430.829 -430.829] [0.0000], Avg: [-480.526 -480.526 -480.526] (1.000)
Step: 72899, Reward: [-332.974 -332.974 -332.974] [0.0000], Avg: [-480.424 -480.424 -480.424] (1.000)
Step: 72949, Reward: [-309.527 -309.527 -309.527] [0.0000], Avg: [-480.307 -480.307 -480.307] (1.000)
Step: 72999, Reward: [-405.581 -405.581 -405.581] [0.0000], Avg: [-480.256 -480.256 -480.256] (1.000)
Step: 73049, Reward: [-320.749 -320.749 -320.749] [0.0000], Avg: [-480.147 -480.147 -480.147] (1.000)
Step: 73099, Reward: [-357.029 -357.029 -357.029] [0.0000], Avg: [-480.063 -480.063 -480.063] (1.000)
Step: 73149, Reward: [-246.6 -246.6 -246.6] [0.0000], Avg: [-479.903 -479.903 -479.903] (1.000)
Step: 73199, Reward: [-388.087 -388.087 -388.087] [0.0000], Avg: [-479.84 -479.84 -479.84] (1.000)
Step: 73249, Reward: [-365.615 -365.615 -365.615] [0.0000], Avg: [-479.763 -479.763 -479.763] (1.000)
Step: 73299, Reward: [-352.858 -352.858 -352.858] [0.0000], Avg: [-479.676 -479.676 -479.676] (1.000)
Step: 73349, Reward: [-325.01 -325.01 -325.01] [0.0000], Avg: [-479.571 -479.571 -479.571] (1.000)
Step: 73399, Reward: [-441.659 -441.659 -441.659] [0.0000], Avg: [-479.545 -479.545 -479.545] (1.000)
Step: 73449, Reward: [-389.423 -389.423 -389.423] [0.0000], Avg: [-479.483 -479.483 -479.483] (1.000)
Step: 73499, Reward: [-302.535 -302.535 -302.535] [0.0000], Avg: [-479.363 -479.363 -479.363] (1.000)
Step: 73549, Reward: [-425.332 -425.332 -425.332] [0.0000], Avg: [-479.326 -479.326 -479.326] (1.000)
Step: 73599, Reward: [-310.311 -310.311 -310.311] [0.0000], Avg: [-479.211 -479.211 -479.211] (1.000)
Step: 73649, Reward: [-345.692 -345.692 -345.692] [0.0000], Avg: [-479.121 -479.121 -479.121] (1.000)
Step: 73699, Reward: [-347.371 -347.371 -347.371] [0.0000], Avg: [-479.031 -479.031 -479.031] (1.000)
Step: 73749, Reward: [-422.065 -422.065 -422.065] [0.0000], Avg: [-478.993 -478.993 -478.993] (1.000)
Step: 73799, Reward: [-496.913 -496.913 -496.913] [0.0000], Avg: [-479.005 -479.005 -479.005] (1.000)
Step: 73849, Reward: [-320.985 -320.985 -320.985] [0.0000], Avg: [-478.898 -478.898 -478.898] (1.000)
Step: 73899, Reward: [-351.294 -351.294 -351.294] [0.0000], Avg: [-478.812 -478.812 -478.812] (1.000)
Step: 73949, Reward: [-476.639 -476.639 -476.639] [0.0000], Avg: [-478.81 -478.81 -478.81] (1.000)
Step: 73999, Reward: [-336.079 -336.079 -336.079] [0.0000], Avg: [-478.714 -478.714 -478.714] (1.000)
Step: 74049, Reward: [-507.191 -507.191 -507.191] [0.0000], Avg: [-478.733 -478.733 -478.733] (1.000)
Step: 74099, Reward: [-391.058 -391.058 -391.058] [0.0000], Avg: [-478.674 -478.674 -478.674] (1.000)
Step: 74149, Reward: [-367.472 -367.472 -367.472] [0.0000], Avg: [-478.599 -478.599 -478.599] (1.000)
Step: 74199, Reward: [-487.218 -487.218 -487.218] [0.0000], Avg: [-478.605 -478.605 -478.605] (1.000)
Step: 74249, Reward: [-346.224 -346.224 -346.224] [0.0000], Avg: [-478.515 -478.515 -478.515] (1.000)
Step: 74299, Reward: [-376.301 -376.301 -376.301] [0.0000], Avg: [-478.447 -478.447 -478.447] (1.000)
Step: 74349, Reward: [-350.482 -350.482 -350.482] [0.0000], Avg: [-478.361 -478.361 -478.361] (1.000)
Step: 74399, Reward: [-381.706 -381.706 -381.706] [0.0000], Avg: [-478.296 -478.296 -478.296] (1.000)
Step: 74449, Reward: [-427.823 -427.823 -427.823] [0.0000], Avg: [-478.262 -478.262 -478.262] (1.000)
Step: 74499, Reward: [-314.424 -314.424 -314.424] [0.0000], Avg: [-478.152 -478.152 -478.152] (1.000)
Step: 74549, Reward: [-405.009 -405.009 -405.009] [0.0000], Avg: [-478.103 -478.103 -478.103] (1.000)
Step: 74599, Reward: [-410.931 -410.931 -410.931] [0.0000], Avg: [-478.058 -478.058 -478.058] (1.000)
Step: 74649, Reward: [-444.517 -444.517 -444.517] [0.0000], Avg: [-478.035 -478.035 -478.035] (1.000)
Step: 74699, Reward: [-417.006 -417.006 -417.006] [0.0000], Avg: [-477.994 -477.994 -477.994] (1.000)
Step: 74749, Reward: [-373.974 -373.974 -373.974] [0.0000], Avg: [-477.925 -477.925 -477.925] (1.000)
Step: 74799, Reward: [-418.268 -418.268 -418.268] [0.0000], Avg: [-477.885 -477.885 -477.885] (1.000)
Step: 74849, Reward: [-347.21 -347.21 -347.21] [0.0000], Avg: [-477.798 -477.798 -477.798] (1.000)
Step: 74899, Reward: [-511.694 -511.694 -511.694] [0.0000], Avg: [-477.82 -477.82 -477.82] (1.000)
Step: 74949, Reward: [-343.441 -343.441 -343.441] [0.0000], Avg: [-477.731 -477.731 -477.731] (1.000)
Step: 74999, Reward: [-394.333 -394.333 -394.333] [0.0000], Avg: [-477.675 -477.675 -477.675] (1.000)
Step: 75049, Reward: [-359.585 -359.585 -359.585] [0.0000], Avg: [-477.596 -477.596 -477.596] (1.000)
Step: 75099, Reward: [-392.148 -392.148 -392.148] [0.0000], Avg: [-477.539 -477.539 -477.539] (1.000)
Step: 75149, Reward: [-416.022 -416.022 -416.022] [0.0000], Avg: [-477.499 -477.499 -477.499] (1.000)
Step: 75199, Reward: [-378.116 -378.116 -378.116] [0.0000], Avg: [-477.432 -477.432 -477.432] (1.000)
Step: 75249, Reward: [-315.111 -315.111 -315.111] [0.0000], Avg: [-477.325 -477.325 -477.325] (1.000)
Step: 75299, Reward: [-459.282 -459.282 -459.282] [0.0000], Avg: [-477.313 -477.313 -477.313] (1.000)
Step: 75349, Reward: [-357.458 -357.458 -357.458] [0.0000], Avg: [-477.233 -477.233 -477.233] (1.000)
Step: 75399, Reward: [-400.905 -400.905 -400.905] [0.0000], Avg: [-477.182 -477.182 -477.182] (1.000)
Step: 75449, Reward: [-343.087 -343.087 -343.087] [0.0000], Avg: [-477.094 -477.094 -477.094] (1.000)
Step: 75499, Reward: [-385.932 -385.932 -385.932] [0.0000], Avg: [-477.033 -477.033 -477.033] (1.000)
Step: 75549, Reward: [-448.788 -448.788 -448.788] [0.0000], Avg: [-477.015 -477.015 -477.015] (1.000)
Step: 75599, Reward: [-398.475 -398.475 -398.475] [0.0000], Avg: [-476.963 -476.963 -476.963] (1.000)
Step: 75649, Reward: [-404.713 -404.713 -404.713] [0.0000], Avg: [-476.915 -476.915 -476.915] (1.000)
Step: 75699, Reward: [-295.061 -295.061 -295.061] [0.0000], Avg: [-476.795 -476.795 -476.795] (1.000)
Step: 75749, Reward: [-333.343 -333.343 -333.343] [0.0000], Avg: [-476.7 -476.7 -476.7] (1.000)
Step: 75799, Reward: [-458.16 -458.16 -458.16] [0.0000], Avg: [-476.688 -476.688 -476.688] (1.000)
Step: 75849, Reward: [-380.931 -380.931 -380.931] [0.0000], Avg: [-476.625 -476.625 -476.625] (1.000)
Step: 75899, Reward: [-473.336 -473.336 -473.336] [0.0000], Avg: [-476.623 -476.623 -476.623] (1.000)
Step: 75949, Reward: [-422.82 -422.82 -422.82] [0.0000], Avg: [-476.587 -476.587 -476.587] (1.000)
Step: 75999, Reward: [-393.006 -393.006 -393.006] [0.0000], Avg: [-476.532 -476.532 -476.532] (1.000)
Step: 76049, Reward: [-385.417 -385.417 -385.417] [0.0000], Avg: [-476.472 -476.472 -476.472] (1.000)
Step: 76099, Reward: [-324.551 -324.551 -324.551] [0.0000], Avg: [-476.372 -476.372 -476.372] (1.000)
Step: 76149, Reward: [-421.876 -421.876 -421.876] [0.0000], Avg: [-476.337 -476.337 -476.337] (1.000)
Step: 76199, Reward: [-345.869 -345.869 -345.869] [0.0000], Avg: [-476.251 -476.251 -476.251] (1.000)
Step: 76249, Reward: [-417.05 -417.05 -417.05] [0.0000], Avg: [-476.212 -476.212 -476.212] (1.000)
Step: 76299, Reward: [-291.955 -291.955 -291.955] [0.0000], Avg: [-476.091 -476.091 -476.091] (1.000)
Step: 76349, Reward: [-484.767 -484.767 -484.767] [0.0000], Avg: [-476.097 -476.097 -476.097] (1.000)
Step: 76399, Reward: [-410.769 -410.769 -410.769] [0.0000], Avg: [-476.054 -476.054 -476.054] (1.000)
Step: 76449, Reward: [-398.087 -398.087 -398.087] [0.0000], Avg: [-476.003 -476.003 -476.003] (1.000)
Step: 76499, Reward: [-303.033 -303.033 -303.033] [0.0000], Avg: [-475.89 -475.89 -475.89] (1.000)
Step: 76549, Reward: [-481.611 -481.611 -481.611] [0.0000], Avg: [-475.894 -475.894 -475.894] (1.000)
Step: 76599, Reward: [-369.851 -369.851 -369.851] [0.0000], Avg: [-475.825 -475.825 -475.825] (1.000)
Step: 76649, Reward: [-358.333 -358.333 -358.333] [0.0000], Avg: [-475.748 -475.748 -475.748] (1.000)
Step: 76699, Reward: [-338.978 -338.978 -338.978] [0.0000], Avg: [-475.659 -475.659 -475.659] (1.000)
Step: 76749, Reward: [-317.671 -317.671 -317.671] [0.0000], Avg: [-475.556 -475.556 -475.556] (1.000)
Step: 76799, Reward: [-361.286 -361.286 -361.286] [0.0000], Avg: [-475.482 -475.482 -475.482] (1.000)
Step: 76849, Reward: [-381.737 -381.737 -381.737] [0.0000], Avg: [-475.421 -475.421 -475.421] (1.000)
Step: 76899, Reward: [-416.746 -416.746 -416.746] [0.0000], Avg: [-475.383 -475.383 -475.383] (1.000)
Step: 76949, Reward: [-337.615 -337.615 -337.615] [0.0000], Avg: [-475.293 -475.293 -475.293] (1.000)
Step: 76999, Reward: [-519.955 -519.955 -519.955] [0.0000], Avg: [-475.322 -475.322 -475.322] (1.000)
Step: 77049, Reward: [-459.271 -459.271 -459.271] [0.0000], Avg: [-475.312 -475.312 -475.312] (1.000)
Step: 77099, Reward: [-349.278 -349.278 -349.278] [0.0000], Avg: [-475.23 -475.23 -475.23] (1.000)
Step: 77149, Reward: [-337.927 -337.927 -337.927] [0.0000], Avg: [-475.141 -475.141 -475.141] (1.000)
Step: 77199, Reward: [-448.177 -448.177 -448.177] [0.0000], Avg: [-475.123 -475.123 -475.123] (1.000)
Step: 77249, Reward: [-257.958 -257.958 -257.958] [0.0000], Avg: [-474.983 -474.983 -474.983] (1.000)
Step: 77299, Reward: [-404.406 -404.406 -404.406] [0.0000], Avg: [-474.937 -474.937 -474.937] (1.000)
Step: 77349, Reward: [-362.46 -362.46 -362.46] [0.0000], Avg: [-474.865 -474.865 -474.865] (1.000)
Step: 77399, Reward: [-397.118 -397.118 -397.118] [0.0000], Avg: [-474.814 -474.814 -474.814] (1.000)
Step: 77449, Reward: [-401.883 -401.883 -401.883] [0.0000], Avg: [-474.767 -474.767 -474.767] (1.000)
Step: 77499, Reward: [-292.55 -292.55 -292.55] [0.0000], Avg: [-474.65 -474.65 -474.65] (1.000)
Step: 77549, Reward: [-391.183 -391.183 -391.183] [0.0000], Avg: [-474.596 -474.596 -474.596] (1.000)
Step: 77599, Reward: [-492.087 -492.087 -492.087] [0.0000], Avg: [-474.607 -474.607 -474.607] (1.000)
Step: 77649, Reward: [-395.094 -395.094 -395.094] [0.0000], Avg: [-474.556 -474.556 -474.556] (1.000)
Step: 77699, Reward: [-437.804 -437.804 -437.804] [0.0000], Avg: [-474.532 -474.532 -474.532] (1.000)
Step: 77749, Reward: [-400.538 -400.538 -400.538] [0.0000], Avg: [-474.485 -474.485 -474.485] (1.000)
Step: 77799, Reward: [-349.351 -349.351 -349.351] [0.0000], Avg: [-474.404 -474.404 -474.404] (1.000)
Step: 77849, Reward: [-390.829 -390.829 -390.829] [0.0000], Avg: [-474.351 -474.351 -474.351] (1.000)
Step: 77899, Reward: [-286.074 -286.074 -286.074] [0.0000], Avg: [-474.23 -474.23 -474.23] (1.000)
Step: 77949, Reward: [-378.541 -378.541 -378.541] [0.0000], Avg: [-474.168 -474.168 -474.168] (1.000)
Step: 77999, Reward: [-414.187 -414.187 -414.187] [0.0000], Avg: [-474.13 -474.13 -474.13] (1.000)
Step: 78049, Reward: [-609.526 -609.526 -609.526] [0.0000], Avg: [-474.217 -474.217 -474.217] (1.000)
Step: 78099, Reward: [-379.825 -379.825 -379.825] [0.0000], Avg: [-474.156 -474.156 -474.156] (1.000)
Step: 78149, Reward: [-271.678 -271.678 -271.678] [0.0000], Avg: [-474.027 -474.027 -474.027] (1.000)
Step: 78199, Reward: [-323.38 -323.38 -323.38] [0.0000], Avg: [-473.93 -473.93 -473.93] (1.000)
Step: 78249, Reward: [-355.347 -355.347 -355.347] [0.0000], Avg: [-473.855 -473.855 -473.855] (1.000)
Step: 78299, Reward: [-335.815 -335.815 -335.815] [0.0000], Avg: [-473.766 -473.766 -473.766] (1.000)
Step: 78349, Reward: [-419.523 -419.523 -419.523] [0.0000], Avg: [-473.732 -473.732 -473.732] (1.000)
Step: 78399, Reward: [-398.072 -398.072 -398.072] [0.0000], Avg: [-473.684 -473.684 -473.684] (1.000)
Step: 78449, Reward: [-484.682 -484.682 -484.682] [0.0000], Avg: [-473.691 -473.691 -473.691] (1.000)
Step: 78499, Reward: [-382.474 -382.474 -382.474] [0.0000], Avg: [-473.632 -473.632 -473.632] (1.000)
Step: 78549, Reward: [-386.921 -386.921 -386.921] [0.0000], Avg: [-473.577 -473.577 -473.577] (1.000)
Step: 78599, Reward: [-342.009 -342.009 -342.009] [0.0000], Avg: [-473.494 -473.494 -473.494] (1.000)
Step: 78649, Reward: [-482.445 -482.445 -482.445] [0.0000], Avg: [-473.499 -473.499 -473.499] (1.000)
Step: 78699, Reward: [-327.674 -327.674 -327.674] [0.0000], Avg: [-473.407 -473.407 -473.407] (1.000)
Step: 78749, Reward: [-300.485 -300.485 -300.485] [0.0000], Avg: [-473.297 -473.297 -473.297] (1.000)
Step: 78799, Reward: [-444.676 -444.676 -444.676] [0.0000], Avg: [-473.279 -473.279 -473.279] (1.000)
Step: 78849, Reward: [-529.307 -529.307 -529.307] [0.0000], Avg: [-473.314 -473.314 -473.314] (1.000)
Step: 78899, Reward: [-545.477 -545.477 -545.477] [0.0000], Avg: [-473.36 -473.36 -473.36] (1.000)
Step: 78949, Reward: [-420.334 -420.334 -420.334] [0.0000], Avg: [-473.326 -473.326 -473.326] (1.000)
Step: 78999, Reward: [-411.79 -411.79 -411.79] [0.0000], Avg: [-473.287 -473.287 -473.287] (1.000)
Step: 79049, Reward: [-382.476 -382.476 -382.476] [0.0000], Avg: [-473.23 -473.23 -473.23] (1.000)
Step: 79099, Reward: [-425.167 -425.167 -425.167] [0.0000], Avg: [-473.2 -473.2 -473.2] (1.000)
Step: 79149, Reward: [-374.904 -374.904 -374.904] [0.0000], Avg: [-473.137 -473.137 -473.137] (1.000)
Step: 79199, Reward: [-296.4 -296.4 -296.4] [0.0000], Avg: [-473.026 -473.026 -473.026] (1.000)
Step: 79249, Reward: [-338.652 -338.652 -338.652] [0.0000], Avg: [-472.941 -472.941 -472.941] (1.000)
Step: 79299, Reward: [-419.301 -419.301 -419.301] [0.0000], Avg: [-472.907 -472.907 -472.907] (1.000)
Step: 79349, Reward: [-446.003 -446.003 -446.003] [0.0000], Avg: [-472.89 -472.89 -472.89] (1.000)
Step: 79399, Reward: [-475.815 -475.815 -475.815] [0.0000], Avg: [-472.892 -472.892 -472.892] (1.000)
Step: 79449, Reward: [-436.963 -436.963 -436.963] [0.0000], Avg: [-472.87 -472.87 -472.87] (1.000)
Step: 79499, Reward: [-410.221 -410.221 -410.221] [0.0000], Avg: [-472.83 -472.83 -472.83] (1.000)
Step: 79549, Reward: [-388.575 -388.575 -388.575] [0.0000], Avg: [-472.777 -472.777 -472.777] (1.000)
Step: 79599, Reward: [-420.438 -420.438 -420.438] [0.0000], Avg: [-472.744 -472.744 -472.744] (1.000)
Step: 79649, Reward: [-444.697 -444.697 -444.697] [0.0000], Avg: [-472.727 -472.727 -472.727] (1.000)
Step: 79699, Reward: [-267.568 -267.568 -267.568] [0.0000], Avg: [-472.598 -472.598 -472.598] (1.000)
Step: 79749, Reward: [-291.376 -291.376 -291.376] [0.0000], Avg: [-472.484 -472.484 -472.484] (1.000)
Step: 79799, Reward: [-390.742 -390.742 -390.742] [0.0000], Avg: [-472.433 -472.433 -472.433] (1.000)
Step: 79849, Reward: [-304.241 -304.241 -304.241] [0.0000], Avg: [-472.328 -472.328 -472.328] (1.000)
Step: 79899, Reward: [-306.741 -306.741 -306.741] [0.0000], Avg: [-472.224 -472.224 -472.224] (1.000)
Step: 79949, Reward: [-475.92 -475.92 -475.92] [0.0000], Avg: [-472.227 -472.227 -472.227] (1.000)
Step: 79999, Reward: [-453.505 -453.505 -453.505] [0.0000], Avg: [-472.215 -472.215 -472.215] (1.000)
Step: 80049, Reward: [-434.395 -434.395 -434.395] [0.0000], Avg: [-472.191 -472.191 -472.191] (1.000)
Step: 80099, Reward: [-403.355 -403.355 -403.355] [0.0000], Avg: [-472.148 -472.148 -472.148] (1.000)
Step: 80149, Reward: [-327.181 -327.181 -327.181] [0.0000], Avg: [-472.058 -472.058 -472.058] (1.000)
Step: 80199, Reward: [-309.879 -309.879 -309.879] [0.0000], Avg: [-471.957 -471.957 -471.957] (1.000)
Step: 80249, Reward: [-270.87 -270.87 -270.87] [0.0000], Avg: [-471.831 -471.831 -471.831] (1.000)
Step: 80299, Reward: [-380.699 -380.699 -380.699] [0.0000], Avg: [-471.775 -471.775 -471.775] (1.000)
Step: 80349, Reward: [-328.842 -328.842 -328.842] [0.0000], Avg: [-471.686 -471.686 -471.686] (1.000)
Step: 80399, Reward: [-354.313 -354.313 -354.313] [0.0000], Avg: [-471.613 -471.613 -471.613] (1.000)
Step: 80449, Reward: [-471.469 -471.469 -471.469] [0.0000], Avg: [-471.613 -471.613 -471.613] (1.000)
Step: 80499, Reward: [-416.087 -416.087 -416.087] [0.0000], Avg: [-471.578 -471.578 -471.578] (1.000)
Step: 80549, Reward: [-343.589 -343.589 -343.589] [0.0000], Avg: [-471.499 -471.499 -471.499] (1.000)
Step: 80599, Reward: [-452.017 -452.017 -452.017] [0.0000], Avg: [-471.487 -471.487 -471.487] (1.000)
Step: 80649, Reward: [-372.599 -372.599 -372.599] [0.0000], Avg: [-471.425 -471.425 -471.425] (1.000)
Step: 80699, Reward: [-375.576 -375.576 -375.576] [0.0000], Avg: [-471.366 -471.366 -471.366] (1.000)
Step: 80749, Reward: [-408.162 -408.162 -408.162] [0.0000], Avg: [-471.327 -471.327 -471.327] (1.000)
Step: 80799, Reward: [-406.009 -406.009 -406.009] [0.0000], Avg: [-471.286 -471.286 -471.286] (1.000)
Step: 80849, Reward: [-379.544 -379.544 -379.544] [0.0000], Avg: [-471.23 -471.23 -471.23] (1.000)
Step: 80899, Reward: [-405.226 -405.226 -405.226] [0.0000], Avg: [-471.189 -471.189 -471.189] (1.000)
Step: 80949, Reward: [-390.231 -390.231 -390.231] [0.0000], Avg: [-471.139 -471.139 -471.139] (1.000)
Step: 80999, Reward: [-342.557 -342.557 -342.557] [0.0000], Avg: [-471.06 -471.06 -471.06] (1.000)
Step: 81049, Reward: [-365.933 -365.933 -365.933] [0.0000], Avg: [-470.995 -470.995 -470.995] (1.000)
Step: 81099, Reward: [-497.899 -497.899 -497.899] [0.0000], Avg: [-471.011 -471.011 -471.011] (1.000)
Step: 81149, Reward: [-383.348 -383.348 -383.348] [0.0000], Avg: [-470.957 -470.957 -470.957] (1.000)
Step: 81199, Reward: [-421.619 -421.619 -421.619] [0.0000], Avg: [-470.927 -470.927 -470.927] (1.000)
Step: 81249, Reward: [-288.059 -288.059 -288.059] [0.0000], Avg: [-470.814 -470.814 -470.814] (1.000)
Step: 81299, Reward: [-343.322 -343.322 -343.322] [0.0000], Avg: [-470.736 -470.736 -470.736] (1.000)
Step: 81349, Reward: [-375.077 -375.077 -375.077] [0.0000], Avg: [-470.677 -470.677 -470.677] (1.000)
Step: 81399, Reward: [-413.324 -413.324 -413.324] [0.0000], Avg: [-470.642 -470.642 -470.642] (1.000)
Step: 81449, Reward: [-352.343 -352.343 -352.343] [0.0000], Avg: [-470.569 -470.569 -470.569] (1.000)
Step: 81499, Reward: [-324.962 -324.962 -324.962] [0.0000], Avg: [-470.48 -470.48 -470.48] (1.000)
Step: 81549, Reward: [-377.545 -377.545 -377.545] [0.0000], Avg: [-470.423 -470.423 -470.423] (1.000)
Step: 81599, Reward: [-354.028 -354.028 -354.028] [0.0000], Avg: [-470.352 -470.352 -470.352] (1.000)
Step: 81649, Reward: [-339.117 -339.117 -339.117] [0.0000], Avg: [-470.271 -470.271 -470.271] (1.000)
Step: 81699, Reward: [-320.193 -320.193 -320.193] [0.0000], Avg: [-470.179 -470.179 -470.179] (1.000)
Step: 81749, Reward: [-420.282 -420.282 -420.282] [0.0000], Avg: [-470.149 -470.149 -470.149] (1.000)
Step: 81799, Reward: [-406.422 -406.422 -406.422] [0.0000], Avg: [-470.11 -470.11 -470.11] (1.000)
Step: 81849, Reward: [-405.576 -405.576 -405.576] [0.0000], Avg: [-470.071 -470.071 -470.071] (1.000)
Step: 81899, Reward: [-380.63 -380.63 -380.63] [0.0000], Avg: [-470.016 -470.016 -470.016] (1.000)
Step: 81949, Reward: [-305.678 -305.678 -305.678] [0.0000], Avg: [-469.916 -469.916 -469.916] (1.000)
Step: 81999, Reward: [-414.966 -414.966 -414.966] [0.0000], Avg: [-469.882 -469.882 -469.882] (1.000)
Step: 82049, Reward: [-432.588 -432.588 -432.588] [0.0000], Avg: [-469.859 -469.859 -469.859] (1.000)
Step: 82099, Reward: [-385.543 -385.543 -385.543] [0.0000], Avg: [-469.808 -469.808 -469.808] (1.000)
Step: 82149, Reward: [-271.545 -271.545 -271.545] [0.0000], Avg: [-469.687 -469.687 -469.687] (1.000)
Step: 82199, Reward: [-337.92 -337.92 -337.92] [0.0000], Avg: [-469.607 -469.607 -469.607] (1.000)
Step: 82249, Reward: [-405.689 -405.689 -405.689] [0.0000], Avg: [-469.568 -469.568 -469.568] (1.000)
Step: 82299, Reward: [-399.383 -399.383 -399.383] [0.0000], Avg: [-469.526 -469.526 -469.526] (1.000)
Step: 82349, Reward: [-416.54 -416.54 -416.54] [0.0000], Avg: [-469.494 -469.494 -469.494] (1.000)
Step: 82399, Reward: [-381.757 -381.757 -381.757] [0.0000], Avg: [-469.44 -469.44 -469.44] (1.000)
Step: 82449, Reward: [-298.133 -298.133 -298.133] [0.0000], Avg: [-469.336 -469.336 -469.336] (1.000)
Step: 82499, Reward: [-517.433 -517.433 -517.433] [0.0000], Avg: [-469.366 -469.366 -469.366] (1.000)
Step: 82549, Reward: [-404.188 -404.188 -404.188] [0.0000], Avg: [-469.326 -469.326 -469.326] (1.000)
Step: 82599, Reward: [-340.883 -340.883 -340.883] [0.0000], Avg: [-469.248 -469.248 -469.248] (1.000)
Step: 82649, Reward: [-444.004 -444.004 -444.004] [0.0000], Avg: [-469.233 -469.233 -469.233] (1.000)
Step: 82699, Reward: [-381.787 -381.787 -381.787] [0.0000], Avg: [-469.18 -469.18 -469.18] (1.000)
Step: 82749, Reward: [-445.589 -445.589 -445.589] [0.0000], Avg: [-469.166 -469.166 -469.166] (1.000)
Step: 82799, Reward: [-405.58 -405.58 -405.58] [0.0000], Avg: [-469.128 -469.128 -469.128] (1.000)
Step: 82849, Reward: [-359.942 -359.942 -359.942] [0.0000], Avg: [-469.062 -469.062 -469.062] (1.000)
Step: 82899, Reward: [-347.191 -347.191 -347.191] [0.0000], Avg: [-468.988 -468.988 -468.988] (1.000)
Step: 82949, Reward: [-318.116 -318.116 -318.116] [0.0000], Avg: [-468.897 -468.897 -468.897] (1.000)
Step: 82999, Reward: [-378.593 -378.593 -378.593] [0.0000], Avg: [-468.843 -468.843 -468.843] (1.000)
Step: 83049, Reward: [-451.36 -451.36 -451.36] [0.0000], Avg: [-468.832 -468.832 -468.832] (1.000)
Step: 83099, Reward: [-444.934 -444.934 -444.934] [0.0000], Avg: [-468.818 -468.818 -468.818] (1.000)
Step: 83149, Reward: [-403.991 -403.991 -403.991] [0.0000], Avg: [-468.779 -468.779 -468.779] (1.000)
Step: 83199, Reward: [-398.045 -398.045 -398.045] [0.0000], Avg: [-468.736 -468.736 -468.736] (1.000)
Step: 83249, Reward: [-361.948 -361.948 -361.948] [0.0000], Avg: [-468.672 -468.672 -468.672] (1.000)
Step: 83299, Reward: [-520.164 -520.164 -520.164] [0.0000], Avg: [-468.703 -468.703 -468.703] (1.000)
Step: 83349, Reward: [-400.704 -400.704 -400.704] [0.0000], Avg: [-468.662 -468.662 -468.662] (1.000)
Step: 83399, Reward: [-350.206 -350.206 -350.206] [0.0000], Avg: [-468.591 -468.591 -468.591] (1.000)
Step: 83449, Reward: [-507.516 -507.516 -507.516] [0.0000], Avg: [-468.615 -468.615 -468.615] (1.000)
Step: 83499, Reward: [-322.685 -322.685 -322.685] [0.0000], Avg: [-468.527 -468.527 -468.527] (1.000)
Step: 83549, Reward: [-365.574 -365.574 -365.574] [0.0000], Avg: [-468.466 -468.466 -468.466] (1.000)
Step: 83599, Reward: [-321.419 -321.419 -321.419] [0.0000], Avg: [-468.378 -468.378 -468.378] (1.000)
Step: 83649, Reward: [-473.488 -473.488 -473.488] [0.0000], Avg: [-468.381 -468.381 -468.381] (1.000)
Step: 83699, Reward: [-433.73 -433.73 -433.73] [0.0000], Avg: [-468.36 -468.36 -468.36] (1.000)
Step: 83749, Reward: [-406.092 -406.092 -406.092] [0.0000], Avg: [-468.323 -468.323 -468.323] (1.000)
Step: 83799, Reward: [-411.161 -411.161 -411.161] [0.0000], Avg: [-468.289 -468.289 -468.289] (1.000)
Step: 83849, Reward: [-292.084 -292.084 -292.084] [0.0000], Avg: [-468.184 -468.184 -468.184] (1.000)
Step: 83899, Reward: [-364.573 -364.573 -364.573] [0.0000], Avg: [-468.122 -468.122 -468.122] (1.000)
Step: 83949, Reward: [-276.116 -276.116 -276.116] [0.0000], Avg: [-468.008 -468.008 -468.008] (1.000)
Step: 83999, Reward: [-483.389 -483.389 -483.389] [0.0000], Avg: [-468.017 -468.017 -468.017] (1.000)
Step: 84049, Reward: [-404.13 -404.13 -404.13] [0.0000], Avg: [-467.979 -467.979 -467.979] (1.000)
Step: 84099, Reward: [-330.131 -330.131 -330.131] [0.0000], Avg: [-467.897 -467.897 -467.897] (1.000)
Step: 84149, Reward: [-336.35 -336.35 -336.35] [0.0000], Avg: [-467.819 -467.819 -467.819] (1.000)
Step: 84199, Reward: [-419.849 -419.849 -419.849] [0.0000], Avg: [-467.79 -467.79 -467.79] (1.000)
Step: 84249, Reward: [-337.013 -337.013 -337.013] [0.0000], Avg: [-467.713 -467.713 -467.713] (1.000)
Step: 84299, Reward: [-421.243 -421.243 -421.243] [0.0000], Avg: [-467.685 -467.685 -467.685] (1.000)
Step: 84349, Reward: [-429.146 -429.146 -429.146] [0.0000], Avg: [-467.662 -467.662 -467.662] (1.000)
Step: 84399, Reward: [-362.225 -362.225 -362.225] [0.0000], Avg: [-467.6 -467.6 -467.6] (1.000)
Step: 84449, Reward: [-351.411 -351.411 -351.411] [0.0000], Avg: [-467.531 -467.531 -467.531] (1.000)
Step: 84499, Reward: [-480.044 -480.044 -480.044] [0.0000], Avg: [-467.538 -467.538 -467.538] (1.000)
Step: 84549, Reward: [-336.759 -336.759 -336.759] [0.0000], Avg: [-467.461 -467.461 -467.461] (1.000)
Step: 84599, Reward: [-372.143 -372.143 -372.143] [0.0000], Avg: [-467.405 -467.405 -467.405] (1.000)
Step: 84649, Reward: [-413.118 -413.118 -413.118] [0.0000], Avg: [-467.373 -467.373 -467.373] (1.000)
Step: 84699, Reward: [-414.702 -414.702 -414.702] [0.0000], Avg: [-467.342 -467.342 -467.342] (1.000)
Step: 84749, Reward: [-438.611 -438.611 -438.611] [0.0000], Avg: [-467.325 -467.325 -467.325] (1.000)
Step: 84799, Reward: [-444.146 -444.146 -444.146] [0.0000], Avg: [-467.311 -467.311 -467.311] (1.000)
Step: 84849, Reward: [-377.573 -377.573 -377.573] [0.0000], Avg: [-467.258 -467.258 -467.258] (1.000)
Step: 84899, Reward: [-350.694 -350.694 -350.694] [0.0000], Avg: [-467.189 -467.189 -467.189] (1.000)
Step: 84949, Reward: [-292.075 -292.075 -292.075] [0.0000], Avg: [-467.086 -467.086 -467.086] (1.000)
Step: 84999, Reward: [-445.652 -445.652 -445.652] [0.0000], Avg: [-467.074 -467.074 -467.074] (1.000)
Step: 85049, Reward: [-360.059 -360.059 -360.059] [0.0000], Avg: [-467.011 -467.011 -467.011] (1.000)
Step: 85099, Reward: [-389.506 -389.506 -389.506] [0.0000], Avg: [-466.965 -466.965 -466.965] (1.000)
Step: 85149, Reward: [-312.814 -312.814 -312.814] [0.0000], Avg: [-466.875 -466.875 -466.875] (1.000)
Step: 85199, Reward: [-376.091 -376.091 -376.091] [0.0000], Avg: [-466.821 -466.821 -466.821] (1.000)
Step: 85249, Reward: [-286.797 -286.797 -286.797] [0.0000], Avg: [-466.716 -466.716 -466.716] (1.000)
Step: 85299, Reward: [-300.252 -300.252 -300.252] [0.0000], Avg: [-466.618 -466.618 -466.618] (1.000)
Step: 85349, Reward: [-434.599 -434.599 -434.599] [0.0000], Avg: [-466.6 -466.6 -466.6] (1.000)
Step: 85399, Reward: [-445.305 -445.305 -445.305] [0.0000], Avg: [-466.587 -466.587 -466.587] (1.000)
Step: 85449, Reward: [-323.153 -323.153 -323.153] [0.0000], Avg: [-466.503 -466.503 -466.503] (1.000)
Step: 85499, Reward: [-333.115 -333.115 -333.115] [0.0000], Avg: [-466.425 -466.425 -466.425] (1.000)
Step: 85549, Reward: [-537.167 -537.167 -537.167] [0.0000], Avg: [-466.467 -466.467 -466.467] (1.000)
Step: 85599, Reward: [-406.519 -406.519 -406.519] [0.0000], Avg: [-466.431 -466.431 -466.431] (1.000)
Step: 85649, Reward: [-473.064 -473.064 -473.064] [0.0000], Avg: [-466.435 -466.435 -466.435] (1.000)
Step: 85699, Reward: [-505.147 -505.147 -505.147] [0.0000], Avg: [-466.458 -466.458 -466.458] (1.000)
Step: 85749, Reward: [-449.312 -449.312 -449.312] [0.0000], Avg: [-466.448 -466.448 -466.448] (1.000)
Step: 85799, Reward: [-366.32 -366.32 -366.32] [0.0000], Avg: [-466.39 -466.39 -466.39] (1.000)
Step: 85849, Reward: [-346.019 -346.019 -346.019] [0.0000], Avg: [-466.319 -466.319 -466.319] (1.000)
Step: 85899, Reward: [-266.265 -266.265 -266.265] [0.0000], Avg: [-466.203 -466.203 -466.203] (1.000)
Step: 85949, Reward: [-346.286 -346.286 -346.286] [0.0000], Avg: [-466.133 -466.133 -466.133] (1.000)
Step: 85999, Reward: [-397.043 -397.043 -397.043] [0.0000], Avg: [-466.093 -466.093 -466.093] (1.000)
Step: 86049, Reward: [-430.589 -430.589 -430.589] [0.0000], Avg: [-466.072 -466.072 -466.072] (1.000)
Step: 86099, Reward: [-467.564 -467.564 -467.564] [0.0000], Avg: [-466.073 -466.073 -466.073] (1.000)
Step: 86149, Reward: [-253.762 -253.762 -253.762] [0.0000], Avg: [-465.95 -465.95 -465.95] (1.000)
Step: 86199, Reward: [-280.41 -280.41 -280.41] [0.0000], Avg: [-465.843 -465.843 -465.843] (1.000)
Step: 86249, Reward: [-305.078 -305.078 -305.078] [0.0000], Avg: [-465.749 -465.749 -465.749] (1.000)
Step: 86299, Reward: [-311.607 -311.607 -311.607] [0.0000], Avg: [-465.66 -465.66 -465.66] (1.000)
Step: 86349, Reward: [-367.877 -367.877 -367.877] [0.0000], Avg: [-465.603 -465.603 -465.603] (1.000)
Step: 86399, Reward: [-409.054 -409.054 -409.054] [0.0000], Avg: [-465.571 -465.571 -465.571] (1.000)
Step: 86449, Reward: [-458.731 -458.731 -458.731] [0.0000], Avg: [-465.567 -465.567 -465.567] (1.000)
Step: 86499, Reward: [-393.705 -393.705 -393.705] [0.0000], Avg: [-465.525 -465.525 -465.525] (1.000)
Step: 86549, Reward: [-405.43 -405.43 -405.43] [0.0000], Avg: [-465.49 -465.49 -465.49] (1.000)
Step: 86599, Reward: [-251.853 -251.853 -251.853] [0.0000], Avg: [-465.367 -465.367 -465.367] (1.000)
Step: 86649, Reward: [-443.528 -443.528 -443.528] [0.0000], Avg: [-465.355 -465.355 -465.355] (1.000)
Step: 86699, Reward: [-314.167 -314.167 -314.167] [0.0000], Avg: [-465.267 -465.267 -465.267] (1.000)
Step: 86749, Reward: [-416.727 -416.727 -416.727] [0.0000], Avg: [-465.239 -465.239 -465.239] (1.000)
Step: 86799, Reward: [-396.594 -396.594 -396.594] [0.0000], Avg: [-465.2 -465.2 -465.2] (1.000)
Step: 86849, Reward: [-460.159 -460.159 -460.159] [0.0000], Avg: [-465.197 -465.197 -465.197] (1.000)
Step: 86899, Reward: [-434.645 -434.645 -434.645] [0.0000], Avg: [-465.179 -465.179 -465.179] (1.000)
Step: 86949, Reward: [-380.824 -380.824 -380.824] [0.0000], Avg: [-465.131 -465.131 -465.131] (1.000)
Step: 86999, Reward: [-335.644 -335.644 -335.644] [0.0000], Avg: [-465.056 -465.056 -465.056] (1.000)
Step: 87049, Reward: [-369.185 -369.185 -369.185] [0.0000], Avg: [-465.001 -465.001 -465.001] (1.000)
Step: 87099, Reward: [-469.578 -469.578 -469.578] [0.0000], Avg: [-465.004 -465.004 -465.004] (1.000)
Step: 87149, Reward: [-390.396 -390.396 -390.396] [0.0000], Avg: [-464.961 -464.961 -464.961] (1.000)
Step: 87199, Reward: [-420.639 -420.639 -420.639] [0.0000], Avg: [-464.936 -464.936 -464.936] (1.000)
Step: 87249, Reward: [-412.74 -412.74 -412.74] [0.0000], Avg: [-464.906 -464.906 -464.906] (1.000)
Step: 87299, Reward: [-470.502 -470.502 -470.502] [0.0000], Avg: [-464.909 -464.909 -464.909] (1.000)
Step: 87349, Reward: [-490.776 -490.776 -490.776] [0.0000], Avg: [-464.924 -464.924 -464.924] (1.000)
Step: 87399, Reward: [-389.856 -389.856 -389.856] [0.0000], Avg: [-464.881 -464.881 -464.881] (1.000)
Step: 87449, Reward: [-439.768 -439.768 -439.768] [0.0000], Avg: [-464.867 -464.867 -464.867] (1.000)
Step: 87499, Reward: [-415.689 -415.689 -415.689] [0.0000], Avg: [-464.838 -464.838 -464.838] (1.000)
Step: 87549, Reward: [-303.126 -303.126 -303.126] [0.0000], Avg: [-464.746 -464.746 -464.746] (1.000)
Step: 87599, Reward: [-329.576 -329.576 -329.576] [0.0000], Avg: [-464.669 -464.669 -464.669] (1.000)
Step: 87649, Reward: [-343.733 -343.733 -343.733] [0.0000], Avg: [-464.6 -464.6 -464.6] (1.000)
Step: 87699, Reward: [-432.024 -432.024 -432.024] [0.0000], Avg: [-464.581 -464.581 -464.581] (1.000)
Step: 87749, Reward: [-365.259 -365.259 -365.259] [0.0000], Avg: [-464.525 -464.525 -464.525] (1.000)
Step: 87799, Reward: [-335.927 -335.927 -335.927] [0.0000], Avg: [-464.452 -464.452 -464.452] (1.000)
Step: 87849, Reward: [-493.22 -493.22 -493.22] [0.0000], Avg: [-464.468 -464.468 -464.468] (1.000)
Step: 87899, Reward: [-348.809 -348.809 -348.809] [0.0000], Avg: [-464.402 -464.402 -464.402] (1.000)
Step: 87949, Reward: [-362.256 -362.256 -362.256] [0.0000], Avg: [-464.344 -464.344 -464.344] (1.000)
Step: 87999, Reward: [-371.373 -371.373 -371.373] [0.0000], Avg: [-464.291 -464.291 -464.291] (1.000)
Step: 88049, Reward: [-361.286 -361.286 -361.286] [0.0000], Avg: [-464.233 -464.233 -464.233] (1.000)
Step: 88099, Reward: [-304.15 -304.15 -304.15] [0.0000], Avg: [-464.142 -464.142 -464.142] (1.000)
Step: 88149, Reward: [-328.391 -328.391 -328.391] [0.0000], Avg: [-464.065 -464.065 -464.065] (1.000)
Step: 88199, Reward: [-370.269 -370.269 -370.269] [0.0000], Avg: [-464.012 -464.012 -464.012] (1.000)
Step: 88249, Reward: [-384.278 -384.278 -384.278] [0.0000], Avg: [-463.967 -463.967 -463.967] (1.000)
Step: 88299, Reward: [-317.259 -317.259 -317.259] [0.0000], Avg: [-463.883 -463.883 -463.883] (1.000)
Step: 88349, Reward: [-289.575 -289.575 -289.575] [0.0000], Avg: [-463.785 -463.785 -463.785] (1.000)
Step: 88399, Reward: [-352.962 -352.962 -352.962] [0.0000], Avg: [-463.722 -463.722 -463.722] (1.000)
Step: 88449, Reward: [-421.582 -421.582 -421.582] [0.0000], Avg: [-463.698 -463.698 -463.698] (1.000)
Step: 88499, Reward: [-416.244 -416.244 -416.244] [0.0000], Avg: [-463.671 -463.671 -463.671] (1.000)
Step: 88549, Reward: [-325.316 -325.316 -325.316] [0.0000], Avg: [-463.593 -463.593 -463.593] (1.000)
Step: 88599, Reward: [-279.085 -279.085 -279.085] [0.0000], Avg: [-463.489 -463.489 -463.489] (1.000)
Step: 88649, Reward: [-373.173 -373.173 -373.173] [0.0000], Avg: [-463.438 -463.438 -463.438] (1.000)
Step: 88699, Reward: [-333.208 -333.208 -333.208] [0.0000], Avg: [-463.365 -463.365 -463.365] (1.000)
Step: 88749, Reward: [-322.759 -322.759 -322.759] [0.0000], Avg: [-463.286 -463.286 -463.286] (1.000)
Step: 88799, Reward: [-427.104 -427.104 -427.104] [0.0000], Avg: [-463.265 -463.265 -463.265] (1.000)
Step: 88849, Reward: [-365.876 -365.876 -365.876] [0.0000], Avg: [-463.211 -463.211 -463.211] (1.000)
Step: 88899, Reward: [-339.962 -339.962 -339.962] [0.0000], Avg: [-463.141 -463.141 -463.141] (1.000)
Step: 88949, Reward: [-451.283 -451.283 -451.283] [0.0000], Avg: [-463.135 -463.135 -463.135] (1.000)
Step: 88999, Reward: [-395.54 -395.54 -395.54] [0.0000], Avg: [-463.097 -463.097 -463.097] (1.000)
Step: 89049, Reward: [-327.598 -327.598 -327.598] [0.0000], Avg: [-463.02 -463.02 -463.02] (1.000)
Step: 89099, Reward: [-309.339 -309.339 -309.339] [0.0000], Avg: [-462.934 -462.934 -462.934] (1.000)
Step: 89149, Reward: [-350.078 -350.078 -350.078] [0.0000], Avg: [-462.871 -462.871 -462.871] (1.000)
Step: 89199, Reward: [-414.839 -414.839 -414.839] [0.0000], Avg: [-462.844 -462.844 -462.844] (1.000)
Step: 89249, Reward: [-411.523 -411.523 -411.523] [0.0000], Avg: [-462.815 -462.815 -462.815] (1.000)
Step: 89299, Reward: [-355.823 -355.823 -355.823] [0.0000], Avg: [-462.755 -462.755 -462.755] (1.000)
Step: 89349, Reward: [-362.203 -362.203 -362.203] [0.0000], Avg: [-462.699 -462.699 -462.699] (1.000)
Step: 89399, Reward: [-341.013 -341.013 -341.013] [0.0000], Avg: [-462.631 -462.631 -462.631] (1.000)
Step: 89449, Reward: [-515.374 -515.374 -515.374] [0.0000], Avg: [-462.661 -462.661 -462.661] (1.000)
Step: 89499, Reward: [-504.158 -504.158 -504.158] [0.0000], Avg: [-462.684 -462.684 -462.684] (1.000)
Step: 89549, Reward: [-415.725 -415.725 -415.725] [0.0000], Avg: [-462.657 -462.657 -462.657] (1.000)
Step: 89599, Reward: [-383.193 -383.193 -383.193] [0.0000], Avg: [-462.613 -462.613 -462.613] (1.000)
Step: 89649, Reward: [-448.038 -448.038 -448.038] [0.0000], Avg: [-462.605 -462.605 -462.605] (1.000)
Step: 89699, Reward: [-364.472 -364.472 -364.472] [0.0000], Avg: [-462.55 -462.55 -462.55] (1.000)
Step: 89749, Reward: [-467.425 -467.425 -467.425] [0.0000], Avg: [-462.553 -462.553 -462.553] (1.000)
Step: 89799, Reward: [-353.821 -353.821 -353.821] [0.0000], Avg: [-462.492 -462.492 -462.492] (1.000)
Step: 89849, Reward: [-390.555 -390.555 -390.555] [0.0000], Avg: [-462.452 -462.452 -462.452] (1.000)
Step: 89899, Reward: [-400.563 -400.563 -400.563] [0.0000], Avg: [-462.418 -462.418 -462.418] (1.000)
Step: 89949, Reward: [-349.439 -349.439 -349.439] [0.0000], Avg: [-462.355 -462.355 -462.355] (1.000)
Step: 89999, Reward: [-393.337 -393.337 -393.337] [0.0000], Avg: [-462.317 -462.317 -462.317] (1.000)
Step: 90049, Reward: [-317.015 -317.015 -317.015] [0.0000], Avg: [-462.236 -462.236 -462.236] (1.000)
Step: 90099, Reward: [-480.694 -480.694 -480.694] [0.0000], Avg: [-462.246 -462.246 -462.246] (1.000)
Step: 90149, Reward: [-433.568 -433.568 -433.568] [0.0000], Avg: [-462.231 -462.231 -462.231] (1.000)
Step: 90199, Reward: [-379.564 -379.564 -379.564] [0.0000], Avg: [-462.185 -462.185 -462.185] (1.000)
Step: 90249, Reward: [-301.989 -301.989 -301.989] [0.0000], Avg: [-462.096 -462.096 -462.096] (1.000)
Step: 90299, Reward: [-375.972 -375.972 -375.972] [0.0000], Avg: [-462.048 -462.048 -462.048] (1.000)
Step: 90349, Reward: [-432.804 -432.804 -432.804] [0.0000], Avg: [-462.032 -462.032 -462.032] (1.000)
Step: 90399, Reward: [-548.388 -548.388 -548.388] [0.0000], Avg: [-462.08 -462.08 -462.08] (1.000)
Step: 90449, Reward: [-330.452 -330.452 -330.452] [0.0000], Avg: [-462.007 -462.007 -462.007] (1.000)
Step: 90499, Reward: [-438.29 -438.29 -438.29] [0.0000], Avg: [-461.994 -461.994 -461.994] (1.000)
Step: 90549, Reward: [-350.327 -350.327 -350.327] [0.0000], Avg: [-461.932 -461.932 -461.932] (1.000)
Step: 90599, Reward: [-389.477 -389.477 -389.477] [0.0000], Avg: [-461.892 -461.892 -461.892] (1.000)
Step: 90649, Reward: [-346.308 -346.308 -346.308] [0.0000], Avg: [-461.829 -461.829 -461.829] (1.000)
Step: 90699, Reward: [-358.517 -358.517 -358.517] [0.0000], Avg: [-461.772 -461.772 -461.772] (1.000)
Step: 90749, Reward: [-339.415 -339.415 -339.415] [0.0000], Avg: [-461.704 -461.704 -461.704] (1.000)
Step: 90799, Reward: [-428.517 -428.517 -428.517] [0.0000], Avg: [-461.686 -461.686 -461.686] (1.000)
Step: 90849, Reward: [-429.757 -429.757 -429.757] [0.0000], Avg: [-461.668 -461.668 -461.668] (1.000)
Step: 90899, Reward: [-482.734 -482.734 -482.734] [0.0000], Avg: [-461.68 -461.68 -461.68] (1.000)
Step: 90949, Reward: [-518.824 -518.824 -518.824] [0.0000], Avg: [-461.711 -461.711 -461.711] (1.000)
Step: 90999, Reward: [-300.676 -300.676 -300.676] [0.0000], Avg: [-461.623 -461.623 -461.623] (1.000)
Step: 91049, Reward: [-430.611 -430.611 -430.611] [0.0000], Avg: [-461.606 -461.606 -461.606] (1.000)
Step: 91099, Reward: [-313.939 -313.939 -313.939] [0.0000], Avg: [-461.525 -461.525 -461.525] (1.000)
Step: 91149, Reward: [-506.6 -506.6 -506.6] [0.0000], Avg: [-461.55 -461.55 -461.55] (1.000)
Step: 91199, Reward: [-412.74 -412.74 -412.74] [0.0000], Avg: [-461.523 -461.523 -461.523] (1.000)
Step: 91249, Reward: [-355.192 -355.192 -355.192] [0.0000], Avg: [-461.465 -461.465 -461.465] (1.000)
Step: 91299, Reward: [-447.774 -447.774 -447.774] [0.0000], Avg: [-461.457 -461.457 -461.457] (1.000)
Step: 91349, Reward: [-442.688 -442.688 -442.688] [0.0000], Avg: [-461.447 -461.447 -461.447] (1.000)
Step: 91399, Reward: [-473.507 -473.507 -473.507] [0.0000], Avg: [-461.453 -461.453 -461.453] (1.000)
Step: 91449, Reward: [-537.472 -537.472 -537.472] [0.0000], Avg: [-461.495 -461.495 -461.495] (1.000)
Step: 91499, Reward: [-411.72 -411.72 -411.72] [0.0000], Avg: [-461.468 -461.468 -461.468] (1.000)
Step: 91549, Reward: [-388.538 -388.538 -388.538] [0.0000], Avg: [-461.428 -461.428 -461.428] (1.000)
Step: 91599, Reward: [-455.799 -455.799 -455.799] [0.0000], Avg: [-461.425 -461.425 -461.425] (1.000)
Step: 91649, Reward: [-638.086 -638.086 -638.086] [0.0000], Avg: [-461.521 -461.521 -461.521] (1.000)
Step: 91699, Reward: [-449.884 -449.884 -449.884] [0.0000], Avg: [-461.515 -461.515 -461.515] (1.000)
Step: 91749, Reward: [-289.448 -289.448 -289.448] [0.0000], Avg: [-461.421 -461.421 -461.421] (1.000)
Step: 91799, Reward: [-370.493 -370.493 -370.493] [0.0000], Avg: [-461.372 -461.372 -461.372] (1.000)
Step: 91849, Reward: [-350.565 -350.565 -350.565] [0.0000], Avg: [-461.311 -461.311 -461.311] (1.000)
Step: 91899, Reward: [-320.171 -320.171 -320.171] [0.0000], Avg: [-461.234 -461.234 -461.234] (1.000)
Step: 91949, Reward: [-314.387 -314.387 -314.387] [0.0000], Avg: [-461.155 -461.155 -461.155] (1.000)
Step: 91999, Reward: [-473.335 -473.335 -473.335] [0.0000], Avg: [-461.161 -461.161 -461.161] (1.000)
Step: 92049, Reward: [-433.839 -433.839 -433.839] [0.0000], Avg: [-461.146 -461.146 -461.146] (1.000)
Step: 92099, Reward: [-414.453 -414.453 -414.453] [0.0000], Avg: [-461.121 -461.121 -461.121] (1.000)
Step: 92149, Reward: [-378.323 -378.323 -378.323] [0.0000], Avg: [-461.076 -461.076 -461.076] (1.000)
Step: 92199, Reward: [-383.582 -383.582 -383.582] [0.0000], Avg: [-461.034 -461.034 -461.034] (1.000)
Step: 92249, Reward: [-439.78 -439.78 -439.78] [0.0000], Avg: [-461.023 -461.023 -461.023] (1.000)
Step: 92299, Reward: [-377.886 -377.886 -377.886] [0.0000], Avg: [-460.978 -460.978 -460.978] (1.000)
Step: 92349, Reward: [-357.327 -357.327 -357.327] [0.0000], Avg: [-460.921 -460.921 -460.921] (1.000)
Step: 92399, Reward: [-487.168 -487.168 -487.168] [0.0000], Avg: [-460.936 -460.936 -460.936] (1.000)
Step: 92449, Reward: [-334.822 -334.822 -334.822] [0.0000], Avg: [-460.867 -460.867 -460.867] (1.000)
Step: 92499, Reward: [-425.523 -425.523 -425.523] [0.0000], Avg: [-460.848 -460.848 -460.848] (1.000)
Step: 92549, Reward: [-476.339 -476.339 -476.339] [0.0000], Avg: [-460.857 -460.857 -460.857] (1.000)
Step: 92599, Reward: [-302.721 -302.721 -302.721] [0.0000], Avg: [-460.771 -460.771 -460.771] (1.000)
Step: 92649, Reward: [-420.756 -420.756 -420.756] [0.0000], Avg: [-460.75 -460.75 -460.75] (1.000)
Step: 92699, Reward: [-439.933 -439.933 -439.933] [0.0000], Avg: [-460.738 -460.738 -460.738] (1.000)
Step: 92749, Reward: [-365.818 -365.818 -365.818] [0.0000], Avg: [-460.687 -460.687 -460.687] (1.000)
Step: 92799, Reward: [-344.866 -344.866 -344.866] [0.0000], Avg: [-460.625 -460.625 -460.625] (1.000)
Step: 92849, Reward: [-491.176 -491.176 -491.176] [0.0000], Avg: [-460.641 -460.641 -460.641] (1.000)
Step: 92899, Reward: [-340.679 -340.679 -340.679] [0.0000], Avg: [-460.577 -460.577 -460.577] (1.000)
Step: 92949, Reward: [-426.152 -426.152 -426.152] [0.0000], Avg: [-460.558 -460.558 -460.558] (1.000)
Step: 92999, Reward: [-404.871 -404.871 -404.871] [0.0000], Avg: [-460.528 -460.528 -460.528] (1.000)
Step: 93049, Reward: [-512.436 -512.436 -512.436] [0.0000], Avg: [-460.556 -460.556 -460.556] (1.000)
Step: 93099, Reward: [-402.415 -402.415 -402.415] [0.0000], Avg: [-460.525 -460.525 -460.525] (1.000)
Step: 93149, Reward: [-395.755 -395.755 -395.755] [0.0000], Avg: [-460.49 -460.49 -460.49] (1.000)
Step: 93199, Reward: [-303.223 -303.223 -303.223] [0.0000], Avg: [-460.406 -460.406 -460.406] (1.000)
Step: 93249, Reward: [-400.361 -400.361 -400.361] [0.0000], Avg: [-460.374 -460.374 -460.374] (1.000)
Step: 93299, Reward: [-320.864 -320.864 -320.864] [0.0000], Avg: [-460.299 -460.299 -460.299] (1.000)
Step: 93349, Reward: [-482.153 -482.153 -482.153] [0.0000], Avg: [-460.311 -460.311 -460.311] (1.000)
Step: 93399, Reward: [-361.419 -361.419 -361.419] [0.0000], Avg: [-460.258 -460.258 -460.258] (1.000)
Step: 93449, Reward: [-386.912 -386.912 -386.912] [0.0000], Avg: [-460.218 -460.218 -460.218] (1.000)
Step: 93499, Reward: [-396.815 -396.815 -396.815] [0.0000], Avg: [-460.184 -460.184 -460.184] (1.000)
Step: 93549, Reward: [-506.986 -506.986 -506.986] [0.0000], Avg: [-460.209 -460.209 -460.209] (1.000)
Step: 93599, Reward: [-469.758 -469.758 -469.758] [0.0000], Avg: [-460.215 -460.215 -460.215] (1.000)
Step: 93649, Reward: [-486.377 -486.377 -486.377] [0.0000], Avg: [-460.229 -460.229 -460.229] (1.000)
Step: 93699, Reward: [-342.807 -342.807 -342.807] [0.0000], Avg: [-460.166 -460.166 -460.166] (1.000)
Step: 93749, Reward: [-451.85 -451.85 -451.85] [0.0000], Avg: [-460.161 -460.161 -460.161] (1.000)
Step: 93799, Reward: [-444.951 -444.951 -444.951] [0.0000], Avg: [-460.153 -460.153 -460.153] (1.000)
Step: 93849, Reward: [-350.69 -350.69 -350.69] [0.0000], Avg: [-460.095 -460.095 -460.095] (1.000)
Step: 93899, Reward: [-443.909 -443.909 -443.909] [0.0000], Avg: [-460.086 -460.086 -460.086] (1.000)
Step: 93949, Reward: [-440.862 -440.862 -440.862] [0.0000], Avg: [-460.076 -460.076 -460.076] (1.000)
Step: 93999, Reward: [-466.816 -466.816 -466.816] [0.0000], Avg: [-460.08 -460.08 -460.08] (1.000)
Step: 94049, Reward: [-313.612 -313.612 -313.612] [0.0000], Avg: [-460.002 -460.002 -460.002] (1.000)
Step: 94099, Reward: [-381.389 -381.389 -381.389] [0.0000], Avg: [-459.96 -459.96 -459.96] (1.000)
Step: 94149, Reward: [-520.625 -520.625 -520.625] [0.0000], Avg: [-459.992 -459.992 -459.992] (1.000)
Step: 94199, Reward: [-277.591 -277.591 -277.591] [0.0000], Avg: [-459.896 -459.896 -459.896] (1.000)
Step: 94249, Reward: [-388.57 -388.57 -388.57] [0.0000], Avg: [-459.858 -459.858 -459.858] (1.000)
Step: 94299, Reward: [-401.446 -401.446 -401.446] [0.0000], Avg: [-459.827 -459.827 -459.827] (1.000)
Step: 94349, Reward: [-399.846 -399.846 -399.846] [0.0000], Avg: [-459.795 -459.795 -459.795] (1.000)
Step: 94399, Reward: [-471.601 -471.601 -471.601] [0.0000], Avg: [-459.801 -459.801 -459.801] (1.000)
Step: 94449, Reward: [-470.982 -470.982 -470.982] [0.0000], Avg: [-459.807 -459.807 -459.807] (1.000)
Step: 94499, Reward: [-342.926 -342.926 -342.926] [0.0000], Avg: [-459.745 -459.745 -459.745] (1.000)
Step: 94549, Reward: [-445.94 -445.94 -445.94] [0.0000], Avg: [-459.738 -459.738 -459.738] (1.000)
Step: 94599, Reward: [-346.496 -346.496 -346.496] [0.0000], Avg: [-459.678 -459.678 -459.678] (1.000)
Step: 94649, Reward: [-402.843 -402.843 -402.843] [0.0000], Avg: [-459.648 -459.648 -459.648] (1.000)
Step: 94699, Reward: [-436.106 -436.106 -436.106] [0.0000], Avg: [-459.636 -459.636 -459.636] (1.000)
Step: 94749, Reward: [-280.161 -280.161 -280.161] [0.0000], Avg: [-459.541 -459.541 -459.541] (1.000)
Step: 94799, Reward: [-420.768 -420.768 -420.768] [0.0000], Avg: [-459.521 -459.521 -459.521] (1.000)
Step: 94849, Reward: [-485.062 -485.062 -485.062] [0.0000], Avg: [-459.534 -459.534 -459.534] (1.000)
Step: 94899, Reward: [-466.75 -466.75 -466.75] [0.0000], Avg: [-459.538 -459.538 -459.538] (1.000)
Step: 94949, Reward: [-290.901 -290.901 -290.901] [0.0000], Avg: [-459.449 -459.449 -459.449] (1.000)
Step: 94999, Reward: [-402.152 -402.152 -402.152] [0.0000], Avg: [-459.419 -459.419 -459.419] (1.000)
Step: 95049, Reward: [-405.315 -405.315 -405.315] [0.0000], Avg: [-459.39 -459.39 -459.39] (1.000)
Step: 95099, Reward: [-435.968 -435.968 -435.968] [0.0000], Avg: [-459.378 -459.378 -459.378] (1.000)
Step: 95149, Reward: [-461.774 -461.774 -461.774] [0.0000], Avg: [-459.379 -459.379 -459.379] (1.000)
Step: 95199, Reward: [-420.442 -420.442 -420.442] [0.0000], Avg: [-459.359 -459.359 -459.359] (1.000)
Step: 95249, Reward: [-409.636 -409.636 -409.636] [0.0000], Avg: [-459.333 -459.333 -459.333] (1.000)
Step: 95299, Reward: [-345.275 -345.275 -345.275] [0.0000], Avg: [-459.273 -459.273 -459.273] (1.000)
Step: 95349, Reward: [-343.236 -343.236 -343.236] [0.0000], Avg: [-459.212 -459.212 -459.212] (1.000)
Step: 95399, Reward: [-424.441 -424.441 -424.441] [0.0000], Avg: [-459.194 -459.194 -459.194] (1.000)
Step: 95449, Reward: [-391.397 -391.397 -391.397] [0.0000], Avg: [-459.158 -459.158 -459.158] (1.000)
Step: 95499, Reward: [-434.872 -434.872 -434.872] [0.0000], Avg: [-459.146 -459.146 -459.146] (1.000)
Step: 95549, Reward: [-484.043 -484.043 -484.043] [0.0000], Avg: [-459.159 -459.159 -459.159] (1.000)
Step: 95599, Reward: [-398.404 -398.404 -398.404] [0.0000], Avg: [-459.127 -459.127 -459.127] (1.000)
Step: 95649, Reward: [-356.431 -356.431 -356.431] [0.0000], Avg: [-459.073 -459.073 -459.073] (1.000)
Step: 95699, Reward: [-413.923 -413.923 -413.923] [0.0000], Avg: [-459.05 -459.05 -459.05] (1.000)
Step: 95749, Reward: [-371.815 -371.815 -371.815] [0.0000], Avg: [-459.004 -459.004 -459.004] (1.000)
Step: 95799, Reward: [-409.122 -409.122 -409.122] [0.0000], Avg: [-458.978 -458.978 -458.978] (1.000)
Step: 95849, Reward: [-381.935 -381.935 -381.935] [0.0000], Avg: [-458.938 -458.938 -458.938] (1.000)
Step: 95899, Reward: [-488.859 -488.859 -488.859] [0.0000], Avg: [-458.953 -458.953 -458.953] (1.000)
Step: 95949, Reward: [-302.279 -302.279 -302.279] [0.0000], Avg: [-458.872 -458.872 -458.872] (1.000)
Step: 95999, Reward: [-335.83 -335.83 -335.83] [0.0000], Avg: [-458.808 -458.808 -458.808] (1.000)
Step: 96049, Reward: [-437.112 -437.112 -437.112] [0.0000], Avg: [-458.796 -458.796 -458.796] (1.000)
Step: 96099, Reward: [-324.487 -324.487 -324.487] [0.0000], Avg: [-458.727 -458.727 -458.727] (1.000)
Step: 96149, Reward: [-352.12 -352.12 -352.12] [0.0000], Avg: [-458.671 -458.671 -458.671] (1.000)
Step: 96199, Reward: [-359.137 -359.137 -359.137] [0.0000], Avg: [-458.619 -458.619 -458.619] (1.000)
Step: 96249, Reward: [-353.226 -353.226 -353.226] [0.0000], Avg: [-458.565 -458.565 -458.565] (1.000)
Step: 96299, Reward: [-343.715 -343.715 -343.715] [0.0000], Avg: [-458.505 -458.505 -458.505] (1.000)
Step: 96349, Reward: [-477.727 -477.727 -477.727] [0.0000], Avg: [-458.515 -458.515 -458.515] (1.000)
Step: 96399, Reward: [-481.805 -481.805 -481.805] [0.0000], Avg: [-458.527 -458.527 -458.527] (1.000)
Step: 96449, Reward: [-442.912 -442.912 -442.912] [0.0000], Avg: [-458.519 -458.519 -458.519] (1.000)
Step: 96499, Reward: [-372.181 -372.181 -372.181] [0.0000], Avg: [-458.474 -458.474 -458.474] (1.000)
Step: 96549, Reward: [-316.012 -316.012 -316.012] [0.0000], Avg: [-458.4 -458.4 -458.4] (1.000)
Step: 96599, Reward: [-417.451 -417.451 -417.451] [0.0000], Avg: [-458.379 -458.379 -458.379] (1.000)
Step: 96649, Reward: [-433.043 -433.043 -433.043] [0.0000], Avg: [-458.366 -458.366 -458.366] (1.000)
Step: 96699, Reward: [-395.374 -395.374 -395.374] [0.0000], Avg: [-458.334 -458.334 -458.334] (1.000)
Step: 96749, Reward: [-485.574 -485.574 -485.574] [0.0000], Avg: [-458.348 -458.348 -458.348] (1.000)
Step: 96799, Reward: [-350.94 -350.94 -350.94] [0.0000], Avg: [-458.292 -458.292 -458.292] (1.000)
Step: 96849, Reward: [-365.254 -365.254 -365.254] [0.0000], Avg: [-458.244 -458.244 -458.244] (1.000)
Step: 96899, Reward: [-416.299 -416.299 -416.299] [0.0000], Avg: [-458.222 -458.222 -458.222] (1.000)
Step: 96949, Reward: [-457.322 -457.322 -457.322] [0.0000], Avg: [-458.222 -458.222 -458.222] (1.000)
Step: 96999, Reward: [-349.452 -349.452 -349.452] [0.0000], Avg: [-458.166 -458.166 -458.166] (1.000)
Step: 97049, Reward: [-346.357 -346.357 -346.357] [0.0000], Avg: [-458.108 -458.108 -458.108] (1.000)
Step: 97099, Reward: [-347.537 -347.537 -347.537] [0.0000], Avg: [-458.051 -458.051 -458.051] (1.000)
Step: 97149, Reward: [-357.099 -357.099 -357.099] [0.0000], Avg: [-457.999 -457.999 -457.999] (1.000)
Step: 97199, Reward: [-412.544 -412.544 -412.544] [0.0000], Avg: [-457.976 -457.976 -457.976] (1.000)
Step: 97249, Reward: [-507.339 -507.339 -507.339] [0.0000], Avg: [-458.001 -458.001 -458.001] (1.000)
Step: 97299, Reward: [-466.735 -466.735 -466.735] [0.0000], Avg: [-458.006 -458.006 -458.006] (1.000)
Step: 97349, Reward: [-359.667 -359.667 -359.667] [0.0000], Avg: [-457.955 -457.955 -457.955] (1.000)
Step: 97399, Reward: [-329.381 -329.381 -329.381] [0.0000], Avg: [-457.889 -457.889 -457.889] (1.000)
Step: 97449, Reward: [-425.955 -425.955 -425.955] [0.0000], Avg: [-457.873 -457.873 -457.873] (1.000)
Step: 97499, Reward: [-426.059 -426.059 -426.059] [0.0000], Avg: [-457.857 -457.857 -457.857] (1.000)
Step: 97549, Reward: [-468.713 -468.713 -468.713] [0.0000], Avg: [-457.862 -457.862 -457.862] (1.000)
Step: 97599, Reward: [-499.867 -499.867 -499.867] [0.0000], Avg: [-457.884 -457.884 -457.884] (1.000)
Step: 97649, Reward: [-358.014 -358.014 -358.014] [0.0000], Avg: [-457.833 -457.833 -457.833] (1.000)
Step: 97699, Reward: [-325.591 -325.591 -325.591] [0.0000], Avg: [-457.765 -457.765 -457.765] (1.000)
Step: 97749, Reward: [-314.509 -314.509 -314.509] [0.0000], Avg: [-457.692 -457.692 -457.692] (1.000)
Step: 97799, Reward: [-333.444 -333.444 -333.444] [0.0000], Avg: [-457.628 -457.628 -457.628] (1.000)
Step: 97849, Reward: [-434.902 -434.902 -434.902] [0.0000], Avg: [-457.617 -457.617 -457.617] (1.000)
Step: 97899, Reward: [-413.74 -413.74 -413.74] [0.0000], Avg: [-457.594 -457.594 -457.594] (1.000)
Step: 97949, Reward: [-423.154 -423.154 -423.154] [0.0000], Avg: [-457.577 -457.577 -457.577] (1.000)
Step: 97999, Reward: [-351.889 -351.889 -351.889] [0.0000], Avg: [-457.523 -457.523 -457.523] (1.000)
Step: 98049, Reward: [-410.998 -410.998 -410.998] [0.0000], Avg: [-457.499 -457.499 -457.499] (1.000)
Step: 98099, Reward: [-584.017 -584.017 -584.017] [0.0000], Avg: [-457.563 -457.563 -457.563] (1.000)
Step: 98149, Reward: [-363.07 -363.07 -363.07] [0.0000], Avg: [-457.515 -457.515 -457.515] (1.000)
Step: 98199, Reward: [-441.582 -441.582 -441.582] [0.0000], Avg: [-457.507 -457.507 -457.507] (1.000)
Step: 98249, Reward: [-376.247 -376.247 -376.247] [0.0000], Avg: [-457.466 -457.466 -457.466] (1.000)
Step: 98299, Reward: [-469.328 -469.328 -469.328] [0.0000], Avg: [-457.472 -457.472 -457.472] (1.000)
Step: 98349, Reward: [-405.253 -405.253 -405.253] [0.0000], Avg: [-457.445 -457.445 -457.445] (1.000)
Step: 98399, Reward: [-357.178 -357.178 -357.178] [0.0000], Avg: [-457.394 -457.394 -457.394] (1.000)
Step: 98449, Reward: [-395.253 -395.253 -395.253] [0.0000], Avg: [-457.363 -457.363 -457.363] (1.000)
Step: 98499, Reward: [-366.95 -366.95 -366.95] [0.0000], Avg: [-457.317 -457.317 -457.317] (1.000)
Step: 98549, Reward: [-368.724 -368.724 -368.724] [0.0000], Avg: [-457.272 -457.272 -457.272] (1.000)
Step: 98599, Reward: [-382.249 -382.249 -382.249] [0.0000], Avg: [-457.234 -457.234 -457.234] (1.000)
Step: 98649, Reward: [-426.251 -426.251 -426.251] [0.0000], Avg: [-457.218 -457.218 -457.218] (1.000)
Step: 98699, Reward: [-411.399 -411.399 -411.399] [0.0000], Avg: [-457.195 -457.195 -457.195] (1.000)
Step: 98749, Reward: [-446.107 -446.107 -446.107] [0.0000], Avg: [-457.189 -457.189 -457.189] (1.000)
Step: 98799, Reward: [-501.476 -501.476 -501.476] [0.0000], Avg: [-457.212 -457.212 -457.212] (1.000)
Step: 98849, Reward: [-373.103 -373.103 -373.103] [0.0000], Avg: [-457.169 -457.169 -457.169] (1.000)
Step: 98899, Reward: [-404.99 -404.99 -404.99] [0.0000], Avg: [-457.143 -457.143 -457.143] (1.000)
Step: 98949, Reward: [-322.456 -322.456 -322.456] [0.0000], Avg: [-457.075 -457.075 -457.075] (1.000)
Step: 98999, Reward: [-442.255 -442.255 -442.255] [0.0000], Avg: [-457.067 -457.067 -457.067] (1.000)
Step: 99049, Reward: [-403.963 -403.963 -403.963] [0.0000], Avg: [-457.041 -457.041 -457.041] (1.000)
Step: 99099, Reward: [-384.029 -384.029 -384.029] [0.0000], Avg: [-457.004 -457.004 -457.004] (1.000)
Step: 99149, Reward: [-379.73 -379.73 -379.73] [0.0000], Avg: [-456.965 -456.965 -456.965] (1.000)
Step: 99199, Reward: [-449.858 -449.858 -449.858] [0.0000], Avg: [-456.961 -456.961 -456.961] (1.000)
Step: 99249, Reward: [-428.125 -428.125 -428.125] [0.0000], Avg: [-456.947 -456.947 -456.947] (1.000)
Step: 99299, Reward: [-368.6 -368.6 -368.6] [0.0000], Avg: [-456.902 -456.902 -456.902] (1.000)
Step: 99349, Reward: [-372.055 -372.055 -372.055] [0.0000], Avg: [-456.859 -456.859 -456.859] (1.000)
Step: 99399, Reward: [-330.94 -330.94 -330.94] [0.0000], Avg: [-456.796 -456.796 -456.796] (1.000)
Step: 99449, Reward: [-366.505 -366.505 -366.505] [0.0000], Avg: [-456.751 -456.751 -456.751] (1.000)
Step: 99499, Reward: [-461.557 -461.557 -461.557] [0.0000], Avg: [-456.753 -456.753 -456.753] (1.000)
Step: 99549, Reward: [-436.441 -436.441 -436.441] [0.0000], Avg: [-456.743 -456.743 -456.743] (1.000)
Step: 99599, Reward: [-337.749 -337.749 -337.749] [0.0000], Avg: [-456.683 -456.683 -456.683] (1.000)
Step: 99649, Reward: [-472.388 -472.388 -472.388] [0.0000], Avg: [-456.691 -456.691 -456.691] (1.000)
Step: 99699, Reward: [-360.639 -360.639 -360.639] [0.0000], Avg: [-456.643 -456.643 -456.643] (1.000)
Step: 99749, Reward: [-386.481 -386.481 -386.481] [0.0000], Avg: [-456.608 -456.608 -456.608] (1.000)
Step: 99799, Reward: [-341.795 -341.795 -341.795] [0.0000], Avg: [-456.55 -456.55 -456.55] (1.000)
Step: 99849, Reward: [-294.486 -294.486 -294.486] [0.0000], Avg: [-456.469 -456.469 -456.469] (1.000)
Step: 99899, Reward: [-417.354 -417.354 -417.354] [0.0000], Avg: [-456.449 -456.449 -456.449] (1.000)
Step: 99949, Reward: [-298.191 -298.191 -298.191] [0.0000], Avg: [-456.37 -456.37 -456.37] (1.000)
Step: 99999, Reward: [-361.33 -361.33 -361.33] [0.0000], Avg: [-456.323 -456.323 -456.323] (1.000)
