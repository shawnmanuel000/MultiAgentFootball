Model: <class 'multiagent.maddpg.MADDPGAgent'>, Dir: simple_tag
num_envs: 1, state_size: [(1, 16), (1, 16), (1, 16), (1, 14)], action_size: [[1, 5], [1, 5], [1, 5], [1, 5]], action_space: [MultiDiscrete([5]), MultiDiscrete([5]), MultiDiscrete([5]), MultiDiscrete([5])],

import torch
import random
import numpy as np
from models.rand import MultiagentReplayBuffer
from models.ddpg import DDPGActor, DDPGCritic, DDPGNetwork
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACNetwork, PTACAgent, LEARN_RATE, DISCOUNT_RATE, EPS_MIN, EPS_DECAY, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, MAX_BUFFER_SIZE, TARGET_UPDATE_RATE, gsoftmax, one_hot

REPLAY_BATCH_SIZE = 1024
ENTROPY_WEIGHT = 0.001			# The weight for the entropy term of the Actor loss
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
NUM_STEPS = 100					# The number of steps to collect experience in sequence for each GAE calculation
INPUT_LAYER = 64
ACTOR_HIDDEN = 64
CRITIC_HIDDEN = 64
LEARN_RATE = 0.01
TARGET_UPDATE_RATE = 0.01
DISCOUNT_RATE = 0.95

class MADDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		action_mu = self.action_mu(state)
		return action_mu
	
class MADDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1]+action_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.q_value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = torch.cat([state, action], -1)
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		q_value = self.q_value(state)
		return q_value

class MADDPGNetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, tau=TARGET_UPDATE_RATE, gpu=False, load=None):
		super().__init__(tau=tau, gpu=gpu)
		self.state_size = state_size
		self.action_size = action_size
		self.critic = MADDPGCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.models = [DDPGNetwork(s_size, a_size, MADDPGActor, lambda s,a: self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		if load: self.load_model(load)

	def get_action_probs(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action = [gsoftmax(model.get_action(s, use_target, grad, numpy=False), hard=True) for s,model in zip(state, self.models)]
			return [a.cpu().numpy() if numpy else a for a in action]

	def optimize(self, states, actions, next_states, rewards, dones, gamma):
		for i, agent in enumerate(self.models):
			next_actions = [one_hot(model.get_action(nobs, numpy=False)) for model, nobs in zip(self.models, next_states)]
			next_states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(next_states, self.state_size)], dim=-1)
			next_actions_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(next_actions, self.action_size)], dim=-1)
			next_value = agent.get_q_value(next_states_joint, next_actions_joint, use_target=True, numpy=False)
			target_value = (rewards[i].view(-1, 1) + gamma * next_value * (1 - dones[i].view(-1, 1)))

			states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			actions_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(actions, self.action_size)], dim=-1)
			actual_value = agent.get_q_value(states_joint, actions_joint, grad=True, numpy=False)
			critic_loss = (actual_value - target_value.detach()).pow(2).mean()
			agent.step(agent.critic_optimizer, critic_loss, param_norm=agent.critic_local.parameters())
			agent.soft_copy(agent.critic_local, agent.critic_target)

			curr_pol_out = agent.get_action(states[i], grad=True, numpy=False)
			curr_pol_vf_in = gsoftmax(curr_pol_out, hard=True)
			action = [curr_pol_vf_in if j==i else one_hot(model.get_action(ob, numpy=False)) for (j,model), ob in zip(enumerate(self.models), states)]
			action_joint = torch.cat([a.view(*a.size()[:-len(a_size)], np.prod(a_size)) for a,a_size in zip(action, self.action_size)], dim=-1)
			actor_loss = -agent.critic_local(states_joint, action_joint).mean() + 0.001*curr_pol_out.pow(2).mean() 
			agent.step(agent.actor_optimizer, actor_loss, param_norm=agent.actor_local.parameters())
			agent.soft_copy(agent.actor_local, agent.actor_target)

	def save_model(self, dirname="pytorch", name="checkpoint"):
		[PTACNetwork.save_model(model, "maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="checkpoint"):
		[PTACNetwork.load_model(model, "maddpg", dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class MADDPGAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, MADDPGNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.replay_buffer = MultiagentReplayBuffer(MAX_BUFFER_SIZE, state_size, action_size)

	def get_action(self, state, eps=None, sample=True, numpy=True):
		action = self.network.get_action_probs(self.to_tensor(state), sample=sample, numpy=numpy)
		return action

	def train(self, state, action, next_state, reward, done):
		self.step = 0 if not hasattr(self, "step") else self.step + 1
		self.replay_buffer.push(state, action, next_state, reward, done)
		if (self.step % self.update_freq)==0 and len(self.replay_buffer) >= REPLAY_BATCH_SIZE:
			states, actions, next_states, rewards, dones = self.replay_buffer.sample(REPLAY_BATCH_SIZE, to_gpu=False)
			self.network.optimize(states, actions, next_states, rewards, dones, gamma=DISCOUNT_RATE)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 100					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.950             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
# import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return gym.make(env_name)
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":0} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env)

def run(model, steps=10000, ports=16, env_name=env_name, eval_at=1000, checkpoint=True, save_best=False, log=True, render=True):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(lambda: make_env(env_name), ports)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, num_envs=num_envs, gpu=False, agent2=RandomAgent) 
	logger = Logger(model, env_name, num_envs=num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if np.any(dones[0]):
			rollouts = [rollout(envs.env, agent.reset(1), render=render) for _ in range(1)]
			test_reward = np.mean(rollouts, axis=0) - np.std(rollouts, axis=0)
			total_rewards.append(test_reward)
			if checkpoint: agent.save_model(env_name, "checkpoint")
			if save_best and np.all(total_rewards[-1] >= np.max(total_rewards, axis=0)): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts, axis=0)} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")
			agent.reset(num_envs)

def trial(model, env_name, render):
	envs = EnsembleEnv(lambda: make_env(env_name, log=True, render=render), 0)
	agent = ParallelAgent(envs.state_size, envs.action_size, model, gpu=False, load=f"{env_name}")
	print(f"Reward: {rollout(envs.env, agent, eps=0.02, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[1], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="maddpg", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--test", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.test:
		trial(model, env_name=env_name, render=args.render)
	elif args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		run(model, args.steps, args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)

Step: 49, Reward: [ 0.     0.     0.    -7.037] [3.0470], Avg: [ 0.     0.     0.    -7.037] (1.000)
Step: 99, Reward: [  0.      0.      0.    -57.199] [24.7681], Avg: [  0.      0.      0.    -32.118] (1.000)
Step: 149, Reward: [0. 0. 0. 0.] [0.0000], Avg: [  0.      0.      0.    -21.412] (1.000)
Step: 199, Reward: [ 20.     20.     20.    -41.094] [26.4545], Avg: [  5.      5.      5.    -26.333] (1.000)
Step: 249, Reward: [0. 0. 0. 0.] [0.0000], Avg: [  4.      4.      4.    -21.066] (1.000)
Step: 299, Reward: [0. 0. 0. 0.] [0.0000], Avg: [  3.333   3.333   3.333 -17.555] (1.000)
Step: 349, Reward: [ 20.  20.  20. -20.] [17.3205], Avg: [  5.714   5.714   5.714 -17.904] (1.000)
Step: 399, Reward: [0. 0. 0. 0.] [0.0000], Avg: [  5.      5.      5.    -15.666] (1.000)
Step: 449, Reward: [  30.      30.      30.    -121.983] [65.8105], Avg: [  7.778   7.778   7.778 -27.479] (1.000)
Step: 499, Reward: [  0.      0.      0.    -52.045] [22.5359], Avg: [  7.      7.      7.    -29.936] (1.000)
Step: 549, Reward: [  0.      0.      0.    -90.401] [39.1447], Avg: [  6.364   6.364   6.364 -35.433] (1.000)
Step: 599, Reward: [ 10.  10.  10. -10.] [8.6603], Avg: [  6.667   6.667   6.667 -33.313] (1.000)
Step: 649, Reward: [ 10.     10.     10.    -11.707] [9.3992], Avg: [  6.923   6.923   6.923 -31.651] (1.000)
Step: 699, Reward: [ 0.     0.     0.    -0.228] [0.0989], Avg: [  6.429   6.429   6.429 -29.407] (1.000)
Step: 749, Reward: [  0.      0.      0.    -52.053] [22.5397], Avg: [  6.      6.      6.    -30.916] (1.000)
Step: 799, Reward: [ 30.  30.  30. -30.] [25.9808], Avg: [  7.5     7.5     7.5   -30.859] (1.000)
Step: 849, Reward: [0. 0. 0. 0.] [0.0000], Avg: [  7.059   7.059   7.059 -29.044] (1.000)
Step: 899, Reward: [ 0.     0.     0.    -6.931] [3.0013], Avg: [  6.667   6.667   6.667 -27.815] (1.000)
Step: 949, Reward: [ 0.     0.     0.    -4.237] [1.8345], Avg: [  6.316   6.316   6.316 -26.574] (1.000)
Step: 999, Reward: [ 20.  20.  20. -20.] [17.3205], Avg: [  7.      7.      7.    -26.246] (1.000)
Step: 1049, Reward: [ 0.     0.     0.    -0.209] [0.0907], Avg: [  6.667   6.667   6.667 -25.006] (1.000)
Step: 1099, Reward: [  0.      0.      0.    -60.513] [26.2028], Avg: [  6.364   6.364   6.364 -26.62 ] (1.000)
Step: 1149, Reward: [ 0.     0.     0.    -3.702] [1.6030], Avg: [  6.087   6.087   6.087 -25.623] (1.000)
Step: 1199, Reward: [   0.       0.       0.    -240.833] [104.2836], Avg: [  5.833   5.833   5.833 -34.59 ] (1.000)
Step: 1249, Reward: [   0.       0.       0.    -525.114] [227.3809], Avg: [  5.6     5.6     5.6   -54.211] (1.000)
Step: 1299, Reward: [   0.      0.      0.   -269.85] [116.8485], Avg: [  5.385   5.385   5.385 -62.505] (1.000)
Step: 1349, Reward: [   0.      0.      0.   -230.12] [99.6447], Avg: [  5.185   5.185   5.185 -68.713] (1.000)
Step: 1399, Reward: [   0.       0.       0.    -542.893] [235.0798], Avg: [  5.      5.      5.    -85.648] (1.000)
Step: 1449, Reward: [  20.      20.      20.    -479.092] [216.1133], Avg: [  5.517   5.517   5.517 -99.215] (1.000)
Step: 1499, Reward: [   0.       0.       0.    -513.998] [222.5677], Avg: [   5.333    5.333    5.333 -113.041] (1.000)
Step: 1549, Reward: [   0.       0.       0.    -357.832] [154.9459], Avg: [   5.161    5.161    5.161 -120.938] (1.000)
Step: 1599, Reward: [   0.       0.       0.    -368.949] [159.7598], Avg: [   5.       5.       5.    -128.688] (1.000)
Step: 1649, Reward: [   0.       0.       0.    -350.766] [151.8863], Avg: [   4.848    4.848    4.848 -135.418] (1.000)
Step: 1699, Reward: [   0.       0.       0.    -332.555] [144.0006], Avg: [   4.706    4.706    4.706 -141.216] (1.000)
Step: 1749, Reward: [   0.       0.       0.    -394.647] [170.8872], Avg: [   4.571    4.571    4.571 -148.457] (1.000)
Step: 1799, Reward: [   0.       0.       0.    -286.815] [124.1944], Avg: [   4.444    4.444    4.444 -152.3  ] (1.000)
Step: 1849, Reward: [  20.      20.      20.    -534.028] [239.9013], Avg: [   4.865    4.865    4.865 -162.617] (1.000)
Step: 1899, Reward: [   0.       0.       0.    -470.424] [203.6995], Avg: [   4.737    4.737    4.737 -170.717] (1.000)
Step: 1949, Reward: [   0.      0.      0.   -654.91] [283.5842], Avg: [   4.615    4.615    4.615 -183.132] (1.000)
Step: 1999, Reward: [   0.       0.       0.    -512.247] [221.8097], Avg: [   4.5     4.5     4.5  -191.36] (1.000)
Step: 2049, Reward: [  0.      0.      0.    -93.803] [40.6177], Avg: [   4.39     4.39     4.39  -188.981] (1.000)
Step: 2099, Reward: [  20.      20.      20.    -389.587] [177.3564], Avg: [   4.762    4.762    4.762 -193.757] (1.000)
Step: 2149, Reward: [   0.       0.       0.    -450.608] [195.1189], Avg: [   4.651    4.651    4.651 -199.73 ] (1.000)
Step: 2199, Reward: [   0.       0.       0.    -592.556] [256.5841], Avg: [   4.545    4.545    4.545 -208.658] (1.000)
Step: 2249, Reward: [   0.       0.       0.    -440.021] [190.5345], Avg: [   4.444    4.444    4.444 -213.8  ] (1.000)
Step: 2299, Reward: [  20.      20.      20.    -437.013] [197.8923], Avg: [   4.783    4.783    4.783 -218.652] (1.000)
Step: 2349, Reward: [   0.       0.       0.    -459.261] [198.8657], Avg: [   4.681    4.681    4.681 -223.771] (1.000)
Step: 2399, Reward: [   0.       0.       0.    -626.271] [271.1831], Avg: [   4.583    4.583    4.583 -232.157] (1.000)
Step: 2449, Reward: [   0.       0.       0.    -391.518] [169.5325], Avg: [   4.49     4.49     4.49  -235.409] (1.000)
Step: 2499, Reward: [   0.       0.       0.    -257.455] [111.4815], Avg: [   4.4     4.4     4.4  -235.85] (1.000)
Step: 2549, Reward: [   0.       0.       0.    -548.081] [237.3262], Avg: [   4.314    4.314    4.314 -241.972] (1.000)
Step: 2599, Reward: [   0.       0.       0.    -259.879] [112.5310], Avg: [   4.231    4.231    4.231 -242.317] (1.000)
Step: 2649, Reward: [   0.       0.       0.    -305.651] [132.3507], Avg: [   4.151    4.151    4.151 -243.512] (1.000)
Step: 2699, Reward: [   0.       0.       0.    -198.042] [85.7547], Avg: [   4.074    4.074    4.074 -242.67 ] (1.000)
Step: 2749, Reward: [   0.       0.       0.    -485.504] [210.2296], Avg: [   4.       4.       4.    -247.085] (1.000)
Step: 2799, Reward: [   0.       0.       0.    -338.691] [146.6573], Avg: [   3.929    3.929    3.929 -248.721] (1.000)
Step: 2849, Reward: [   0.       0.       0.    -282.938] [122.5156], Avg: [   3.86     3.86     3.86  -249.321] (1.000)
Step: 2899, Reward: [   0.       0.       0.    -357.355] [154.7392], Avg: [   3.793    3.793    3.793 -251.184] (1.000)
Step: 2949, Reward: [   0.       0.       0.    -313.364] [135.6906], Avg: [   3.729    3.729    3.729 -252.237] (1.000)
Step: 2999, Reward: [   0.       0.       0.    -313.596] [135.7910], Avg: [   3.667    3.667    3.667 -253.26 ] (1.000)
Step: 3049, Reward: [   0.    0.    0. -374.] [161.9467], Avg: [   3.607    3.607    3.607 -255.239] (1.000)
Step: 3099, Reward: [   0.       0.       0.    -305.828] [132.4276], Avg: [   3.548    3.548    3.548 -256.055] (1.000)
Step: 3149, Reward: [   0.       0.       0.    -401.686] [173.9350], Avg: [   3.492    3.492    3.492 -258.367] (1.000)
Step: 3199, Reward: [   0.       0.       0.    -328.007] [142.0313], Avg: [   3.438    3.438    3.438 -259.455] (1.000)
Step: 3249, Reward: [   0.       0.       0.    -360.801] [156.2314], Avg: [   3.385    3.385    3.385 -261.014] (1.000)
Step: 3299, Reward: [   0.       0.       0.    -269.706] [116.7862], Avg: [   3.333    3.333    3.333 -261.146] (1.000)
Step: 3349, Reward: [   0.       0.       0.    -415.643] [179.9787], Avg: [   3.284    3.284    3.284 -263.452] (1.000)
Step: 3399, Reward: [  20.      20.      20.    -287.039] [132.9519], Avg: [   3.529    3.529    3.529 -263.799] (1.000)
Step: 3449, Reward: [   0.       0.       0.    -386.152] [167.2089], Avg: [   3.478    3.478    3.478 -265.572] (1.000)
Step: 3499, Reward: [   0.       0.       0.    -345.912] [149.7844], Avg: [   3.429    3.429    3.429 -266.72 ] (1.000)
Step: 3549, Reward: [   0.       0.       0.    -377.018] [163.2537], Avg: [   3.38     3.38     3.38  -268.273] (1.000)
Step: 3599, Reward: [  60.      60.      60.    -345.266] [175.4854], Avg: [   4.167    4.167    4.167 -269.343] (1.000)
Step: 3649, Reward: [  20.    20.    20.  -356.8] [163.1593], Avg: [   4.384    4.384    4.384 -270.541] (1.000)
Step: 3699, Reward: [  30.     30.     30.   -358.03] [168.0221], Avg: [   4.73     4.73     4.73  -271.723] (1.000)
Step: 3749, Reward: [ 20.     20.     20.    -27.332] [20.4952], Avg: [   4.933    4.933    4.933 -268.464] (1.000)
Step: 3799, Reward: [ 20.     20.     20.    -76.605] [41.8314], Avg: [   5.132    5.132    5.132 -265.94 ] (1.000)
Step: 3849, Reward: [ 0.     0.     0.    -5.707] [2.4711], Avg: [   5.065    5.065    5.065 -262.56 ] (1.000)
Step: 3899, Reward: [   0.       0.       0.    -413.859] [179.2061], Avg: [   5.     5.     5.  -264.5] (1.000)
Step: 3949, Reward: [   0.       0.       0.    -307.763] [133.2652], Avg: [   4.937    4.937    4.937 -265.048] (1.000)
Step: 3999, Reward: [  0.      0.      0.    -28.217] [12.2182], Avg: [   4.875    4.875    4.875 -262.087] (1.000)
Step: 4049, Reward: [   0.       0.       0.    -199.576] [86.4190], Avg: [   4.815    4.815    4.815 -261.315] (1.000)
Step: 4099, Reward: [  20.     20.     20.   -112.33] [57.3004], Avg: [   5.       5.       5.    -259.499] (1.000)
Step: 4149, Reward: [   0.       0.       0.    -364.606] [157.8792], Avg: [   4.94     4.94     4.94  -260.765] (1.000)
Step: 4199, Reward: [  0.      0.      0.    -14.779] [6.3995], Avg: [   4.881    4.881    4.881 -257.837] (1.000)
Step: 4249, Reward: [   0.       0.       0.    -186.127] [80.5954], Avg: [   4.824    4.824    4.824 -256.993] (1.000)
Step: 4299, Reward: [   0.       0.       0.    -134.487] [58.2346], Avg: [   4.767    4.767    4.767 -255.568] (1.000)
Step: 4349, Reward: [  0.      0.      0.    -61.322] [26.5531], Avg: [   4.713    4.713    4.713 -253.336] (1.000)
Step: 4399, Reward: [   0.       0.       0.    -169.368] [73.3384], Avg: [   4.659    4.659    4.659 -252.382] (1.000)
Step: 4449, Reward: [  40.      40.      40.    -471.083] [221.3056], Avg: [   5.056    5.056    5.056 -254.839] (1.000)
Step: 4499, Reward: [ 0.     0.     0.    -0.435] [0.1882], Avg: [   5.       5.       5.    -252.012] (1.000)
Step: 4549, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.945    4.945    4.945 -249.243] (1.000)
Step: 4599, Reward: [  0.      0.      0.    -46.006] [19.9211], Avg: [   4.891    4.891    4.891 -247.034] (1.000)
Step: 4649, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.839    4.839    4.839 -244.377] (1.000)
Step: 4699, Reward: [  0.      0.      0.    -30.162] [13.0605], Avg: [   4.787    4.787    4.787 -242.098] (1.000)
Step: 4749, Reward: [  60.      60.      60.    -286.816] [150.1756], Avg: [   5.368    5.368    5.368 -242.569] (1.000)
Step: 4799, Reward: [   0.       0.       0.    -280.775] [121.5792], Avg: [   5.312    5.312    5.312 -242.967] (1.000)
Step: 4849, Reward: [  20.      20.      20.    -349.815] [160.1346], Avg: [   5.464    5.464    5.464 -244.069] (1.000)
Step: 4899, Reward: [ 0.     0.     0.    -5.225] [2.2626], Avg: [   5.408    5.408    5.408 -241.632] (1.000)
Step: 4949, Reward: [   0.       0.       0.    -392.974] [170.1626], Avg: [   5.354    5.354    5.354 -243.16 ] (1.000)
Step: 4999, Reward: [   0.       0.       0.    -195.757] [84.7653], Avg: [   5.3      5.3      5.3   -242.686] (1.000)
Step: 5049, Reward: [   0.       0.       0.    -424.227] [183.6959], Avg: [   5.248    5.248    5.248 -244.484] (1.000)
Step: 5099, Reward: [   0.       0.       0.    -182.756] [79.1356], Avg: [   5.196    5.196    5.196 -243.878] (1.000)
Step: 5149, Reward: [   0.       0.       0.    -232.179] [100.5366], Avg: [   5.146    5.146    5.146 -243.765] (1.000)
Step: 5199, Reward: [  30.      30.      30.    -218.546] [107.6237], Avg: [   5.385    5.385    5.385 -243.522] (1.000)
Step: 5249, Reward: [   0.       0.       0.    -418.873] [181.3772], Avg: [   5.333    5.333    5.333 -245.192] (1.000)
Step: 5299, Reward: [  10.      10.      10.    -182.712] [83.4469], Avg: [   5.377    5.377    5.377 -244.603] (1.000)
Step: 5349, Reward: [   0.       0.       0.    -377.906] [163.6381], Avg: [   5.327    5.327    5.327 -245.849] (1.000)
Step: 5399, Reward: [   0.       0.       0.    -178.409] [77.2534], Avg: [   5.278    5.278    5.278 -245.224] (1.000)
Step: 5449, Reward: [   0.       0.       0.    -416.317] [180.2705], Avg: [   5.229    5.229    5.229 -246.794] (1.000)
Step: 5499, Reward: [   0.       0.       0.    -348.865] [151.0631], Avg: [   5.182    5.182    5.182 -247.722] (1.000)
Step: 5549, Reward: [  10.      10.      10.    -267.757] [120.2725], Avg: [   5.225    5.225    5.225 -247.902] (1.000)
Step: 5599, Reward: [   0.       0.       0.    -401.598] [173.8968], Avg: [   5.179    5.179    5.179 -249.275] (1.000)
Step: 5649, Reward: [   0.       0.       0.    -386.354] [167.2964], Avg: [   5.133    5.133    5.133 -250.488] (1.000)
Step: 5699, Reward: [   0.       0.       0.    -372.067] [161.1099], Avg: [   5.088    5.088    5.088 -251.554] (1.000)
Step: 5749, Reward: [  30.      30.      30.    -270.493] [130.1172], Avg: [   5.304    5.304    5.304 -251.719] (1.000)
Step: 5799, Reward: [   0.       0.       0.    -415.431] [179.8870], Avg: [   5.259    5.259    5.259 -253.13 ] (1.000)
Step: 5849, Reward: [   0.       0.       0.    -308.072] [133.3992], Avg: [   5.214    5.214    5.214 -253.6  ] (1.000)
Step: 5899, Reward: [   0.       0.       0.    -257.474] [111.4893], Avg: [   5.169    5.169    5.169 -253.633] (1.000)
Step: 5949, Reward: [   0.      0.      0.   -324.01] [140.3007], Avg: [   5.126    5.126    5.126 -254.224] (1.000)
Step: 5999, Reward: [  20.      20.      20.    -390.987] [177.9627], Avg: [   5.25     5.25     5.25  -255.364] (1.000)
Step: 6049, Reward: [   0.       0.       0.    -366.109] [158.5297], Avg: [   5.207    5.207    5.207 -256.279] (1.000)
Step: 6099, Reward: [   0.       0.       0.    -283.755] [122.8694], Avg: [   5.164    5.164    5.164 -256.504] (1.000)
Step: 6149, Reward: [  10.      10.      10.    -360.635] [160.4896], Avg: [   5.203    5.203    5.203 -257.351] (1.000)
Step: 6199, Reward: [   0.       0.       0.    -301.026] [130.3479], Avg: [   5.161    5.161    5.161 -257.703] (1.000)
Step: 6249, Reward: [  10.      10.      10.    -340.574] [151.8030], Avg: [   5.2      5.2      5.2   -258.366] (1.000)
Step: 6299, Reward: [   0.       0.       0.    -353.224] [152.9504], Avg: [   5.159    5.159    5.159 -259.119] (1.000)
Step: 6349, Reward: [   0.       0.       0.    -401.686] [173.9350], Avg: [   5.118    5.118    5.118 -260.241] (1.000)
Step: 6399, Reward: [   0.       0.       0.    -382.018] [165.4188], Avg: [   5.078    5.078    5.078 -261.193] (1.000)
Step: 6449, Reward: [   0.      0.      0.   -400.69] [173.5040], Avg: [   5.039    5.039    5.039 -262.274] (1.000)
Step: 6499, Reward: [   0.       0.       0.    -354.344] [153.4356], Avg: [   5.       5.       5.    -262.982] (1.000)
Step: 6549, Reward: [   0.       0.       0.    -381.499] [165.1941], Avg: [   4.962    4.962    4.962 -263.887] (1.000)
Step: 6599, Reward: [   0.       0.       0.    -367.659] [159.2009], Avg: [   4.924    4.924    4.924 -264.673] (1.000)
Step: 6649, Reward: [   0.       0.       0.    -434.002] [187.9284], Avg: [   4.887    4.887    4.887 -265.946] (1.000)
Step: 6699, Reward: [   0.      0.      0.   -346.98] [150.2466], Avg: [   4.851    4.851    4.851 -266.551] (1.000)
Step: 6749, Reward: [   0.       0.       0.    -319.722] [138.4438], Avg: [   4.815    4.815    4.815 -266.945] (1.000)
Step: 6799, Reward: [   0.       0.       0.    -346.029] [149.8349], Avg: [   4.779    4.779    4.779 -267.527] (1.000)
Step: 6849, Reward: [   0.       0.       0.    -388.586] [168.2627], Avg: [   4.745    4.745    4.745 -268.41 ] (1.000)
Step: 6899, Reward: [   0.       0.       0.    -477.746] [206.8703], Avg: [   4.71     4.71     4.71  -269.927] (1.000)
Step: 6949, Reward: [   0.       0.       0.    -340.044] [147.2433], Avg: [   4.676    4.676    4.676 -270.432] (1.000)
Step: 6999, Reward: [   0.       0.       0.    -379.341] [164.2595], Avg: [   4.643    4.643    4.643 -271.209] (1.000)
Step: 7049, Reward: [   0.       0.       0.    -513.154] [222.2022], Avg: [   4.61     4.61     4.61  -272.925] (1.000)
Step: 7099, Reward: [   0.     0.     0.  -395.8] [171.3864], Avg: [   4.577    4.577    4.577 -273.791] (1.000)
Step: 7149, Reward: [   0.       0.       0.    -430.096] [186.2369], Avg: [   4.545    4.545    4.545 -274.884] (1.000)
Step: 7199, Reward: [   0.       0.       0.    -360.714] [156.1937], Avg: [   4.514    4.514    4.514 -275.48 ] (1.000)
Step: 7249, Reward: [  0.      0.      0.    -30.948] [13.4007], Avg: [   4.483    4.483    4.483 -273.793] (1.000)
Step: 7299, Reward: [  10.      10.      10.    -228.183] [103.1364], Avg: [   4.521    4.521    4.521 -273.481] (1.000)
Step: 7349, Reward: [   0.       0.       0.    -114.362] [49.5204], Avg: [   4.49     4.49     4.49  -272.399] (1.000)
Step: 7399, Reward: [   0.       0.       0.    -203.275] [88.0209], Avg: [   4.459    4.459    4.459 -271.931] (1.000)
Step: 7449, Reward: [   0.       0.       0.    -387.196] [167.6609], Avg: [   4.43     4.43     4.43  -272.705] (1.000)
Step: 7499, Reward: [  20.      20.      20.    -268.848] [125.0748], Avg: [   4.533    4.533    4.533 -272.679] (1.000)
Step: 7549, Reward: [   0.       0.       0.    -220.039] [95.2796], Avg: [   4.503    4.503    4.503 -272.331] (1.000)
Step: 7599, Reward: [   0.       0.       0.    -108.215] [46.8584], Avg: [   4.474    4.474    4.474 -271.251] (1.000)
Step: 7649, Reward: [  30.      30.      30.    -125.795] [67.4614], Avg: [   4.641    4.641    4.641 -270.3  ] (1.000)
Step: 7699, Reward: [   0.       0.       0.    -260.944] [112.9923], Avg: [   4.61    4.61    4.61 -270.24] (1.000)
Step: 7749, Reward: [  50.      50.      50.    -157.555] [89.8740], Avg: [   4.903    4.903    4.903 -269.513] (1.000)
Step: 7799, Reward: [   0.       0.       0.    -143.802] [62.2679], Avg: [   4.872    4.872    4.872 -268.707] (1.000)
Step: 7849, Reward: [  0.     0.     0.   -49.64] [21.4949], Avg: [   4.841    4.841    4.841 -267.311] (1.000)
Step: 7899, Reward: [  0.      0.      0.    -63.477] [27.4864], Avg: [   4.81     4.81     4.81  -266.021] (1.000)
Step: 7949, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.78     4.78     4.78  -264.348] (1.000)
Step: 7999, Reward: [  0.      0.      0.    -81.444] [35.2663], Avg: [   4.75     4.75     4.75  -263.205] (1.000)
Step: 8049, Reward: [ 50.     50.     50.    -90.442] [60.8132], Avg: [   5.031    5.031    5.031 -262.132] (1.000)
Step: 8099, Reward: [ 30.  30.  30. -30.] [25.9808], Avg: [   5.185    5.185    5.185 -260.699] (1.000)
Step: 8149, Reward: [   0.       0.       0.    -207.081] [89.6689], Avg: [   5.153    5.153    5.153 -260.37 ] (1.000)
Step: 8199, Reward: [ 20.  20.  20. -20.] [17.3205], Avg: [   5.244    5.244    5.244 -258.904] (1.000)
Step: 8249, Reward: [  0.      0.      0.    -40.896] [17.7084], Avg: [   5.212    5.212    5.212 -257.583] (1.000)
Step: 8299, Reward: [ 20.     20.     20.    -93.383] [49.0962], Avg: [   5.301    5.301    5.301 -256.594] (1.000)
Step: 8349, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   5.269    5.269    5.269 -255.058] (1.000)
Step: 8399, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   5.238    5.238    5.238 -253.539] (1.000)
Step: 8449, Reward: [  0.      0.      0.    -25.077] [10.8585], Avg: [   5.207    5.207    5.207 -252.188] (1.000)
Step: 8499, Reward: [ 0.     0.     0.    -9.023] [3.9071], Avg: [   5.176    5.176    5.176 -250.757] (1.000)
Step: 8549, Reward: [  0.      0.      0.    -53.105] [22.9953], Avg: [   5.146    5.146    5.146 -249.601] (1.000)
Step: 8599, Reward: [  0.      0.      0.    -40.683] [17.6163], Avg: [   5.116    5.116    5.116 -248.387] (1.000)
Step: 8649, Reward: [   0.       0.       0.    -212.044] [91.8178], Avg: [   5.087    5.087    5.087 -248.177] (1.000)
Step: 8699, Reward: [  0.      0.      0.    -10.102] [4.3745], Avg: [   5.057    5.057    5.057 -246.808] (1.000)
Step: 8749, Reward: [ 10.     10.     10.    -23.755] [14.6165], Avg: [   5.086    5.086    5.086 -245.534] (1.000)
Step: 8799, Reward: [ 10.     10.     10.    -18.347] [12.2747], Avg: [   5.114    5.114    5.114 -244.243] (1.000)
Step: 8849, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   5.085    5.085    5.085 -242.863] (1.000)
Step: 8899, Reward: [  0.      0.      0.    -25.182] [10.9042], Avg: [   5.056    5.056    5.056 -241.64 ] (1.000)
Step: 8949, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   5.028    5.028    5.028 -240.29 ] (1.000)
Step: 8999, Reward: [  0.      0.      0.    -11.788] [5.1043], Avg: [   5.       5.       5.    -239.021] (1.000)
Step: 9049, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.972    4.972    4.972 -237.7  ] (1.000)
Step: 9099, Reward: [   0.      0.      0.   -187.16] [81.0425], Avg: [   4.945    4.945    4.945 -237.422] (1.000)
Step: 9149, Reward: [  0.      0.      0.    -13.752] [5.9549], Avg: [   4.918    4.918    4.918 -236.2  ] (1.000)
Step: 9199, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.891    4.891    4.891 -234.916] (1.000)
Step: 9249, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.865    4.865    4.865 -233.647] (1.000)
Step: 9299, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.839    4.839    4.839 -232.39 ] (1.000)
Step: 9349, Reward: [  0.      0.      0.    -30.407] [13.1668], Avg: [   4.813    4.813    4.813 -231.31 ] (1.000)
Step: 9399, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.787    4.787    4.787 -230.08 ] (1.000)
Step: 9449, Reward: [   0.       0.       0.    -250.587] [108.5075], Avg: [   4.762    4.762    4.762 -230.189] (1.000)
Step: 9499, Reward: [ 0.     0.     0.    -2.066] [0.8948], Avg: [   4.737    4.737    4.737 -228.988] (1.000)
Step: 9549, Reward: [   0.       0.       0.    -298.323] [129.1775], Avg: [   4.712    4.712    4.712 -229.351] (1.000)
Step: 9599, Reward: [  10.      10.      10.    -393.755] [174.8310], Avg: [   4.74     4.74     4.74  -230.207] (1.000)
Step: 9649, Reward: [  10.      10.      10.    -369.177] [164.1884], Avg: [   4.767    4.767    4.767 -230.927] (1.000)
Step: 9699, Reward: [   0.       0.       0.    -424.382] [183.7627], Avg: [   4.742    4.742    4.742 -231.924] (1.000)
Step: 9749, Reward: [   0.       0.       0.    -162.048] [70.1688], Avg: [   4.718    4.718    4.718 -231.566] (1.000)
Step: 9799, Reward: [  30.      30.      30.    -148.668] [77.3654], Avg: [   4.847    4.847    4.847 -231.143] (1.000)
Step: 9849, Reward: [   0.       0.       0.    -303.837] [131.5653], Avg: [   4.822    4.822    4.822 -231.512] (1.000)
Step: 9899, Reward: [   0.       0.       0.    -151.967] [65.8036], Avg: [   4.798    4.798    4.798 -231.11 ] (1.000)
Step: 9949, Reward: [   0.       0.       0.    -301.366] [130.4953], Avg: [   4.774    4.774    4.774 -231.463] (1.000)
Step: 9999, Reward: [   0.       0.       0.    -418.004] [181.0011], Avg: [   4.75     4.75     4.75  -232.396] (1.000)
Step: 10049, Reward: [   0.       0.       0.    -329.096] [142.5027], Avg: [   4.726    4.726    4.726 -232.877] (1.000)
Step: 10099, Reward: [  10.     10.     10.   -261.38] [117.5111], Avg: [   4.752    4.752    4.752 -233.018] (1.000)
Step: 10149, Reward: [  20.      20.      20.    -380.089] [173.2434], Avg: [   4.828    4.828    4.828 -233.743] (1.000)
Step: 10199, Reward: [   0.       0.       0.    -408.288] [176.7940], Avg: [   4.804    4.804    4.804 -234.598] (1.000)
Step: 10249, Reward: [   0.       0.       0.    -295.877] [128.1184], Avg: [   4.78     4.78     4.78  -234.897] (1.000)
Step: 10299, Reward: [   0.       0.       0.    -414.635] [179.5424], Avg: [   4.757    4.757    4.757 -235.77 ] (1.000)
Step: 10349, Reward: [   0.       0.       0.    -294.808] [127.6555], Avg: [   4.734    4.734    4.734 -236.055] (1.000)
Step: 10399, Reward: [   0.       0.       0.    -416.111] [180.1815], Avg: [   4.712    4.712    4.712 -236.921] (1.000)
Step: 10449, Reward: [   0.      0.      0.   -302.07] [130.8003], Avg: [   4.689    4.689    4.689 -237.232] (1.000)
Step: 10499, Reward: [  20.      20.      20.    -310.764] [143.2252], Avg: [   4.762    4.762    4.762 -237.583] (1.000)
Step: 10549, Reward: [   0.       0.       0.    -415.433] [179.8878], Avg: [   4.739    4.739    4.739 -238.425] (1.000)
Step: 10599, Reward: [  20.      20.      20.    -399.463] [181.6328], Avg: [   4.811    4.811    4.811 -239.185] (1.000)
Step: 10649, Reward: [   0.      0.      0.   -371.37] [160.8079], Avg: [   4.789    4.789    4.789 -239.806] (1.000)
Step: 10699, Reward: [   0.       0.       0.    -266.552] [115.4204], Avg: [   4.766    4.766    4.766 -239.931] (1.000)
Step: 10749, Reward: [  20.      20.      20.    -291.257] [134.7782], Avg: [   4.837    4.837    4.837 -240.169] (1.000)
Step: 10799, Reward: [   0.       0.       0.    -398.784] [172.6786], Avg: [   4.815    4.815    4.815 -240.904] (1.000)
Step: 10849, Reward: [  10.      10.      10.    -402.827] [178.7592], Avg: [   4.839    4.839    4.839 -241.65 ] (1.000)
Step: 10899, Reward: [   0.       0.       0.    -312.943] [135.5083], Avg: [   4.817    4.817    4.817 -241.977] (1.000)
Step: 10949, Reward: [   0.       0.       0.    -418.864] [181.3735], Avg: [   4.795    4.795    4.795 -242.785] (1.000)
Step: 10999, Reward: [   0.       0.       0.    -407.954] [176.6491], Avg: [   4.773    4.773    4.773 -243.535] (1.000)
Step: 11049, Reward: [   0.       0.       0.    -378.553] [163.9183], Avg: [   4.751    4.751    4.751 -244.146] (1.000)
Step: 11099, Reward: [   0.       0.       0.    -413.916] [179.2307], Avg: [   4.73     4.73     4.73  -244.911] (1.000)
Step: 11149, Reward: [   0.       0.       0.    -326.981] [141.5869], Avg: [   4.709    4.709    4.709 -245.279] (1.000)
Step: 11199, Reward: [   0.       0.       0.    -412.856] [178.7719], Avg: [   4.688    4.688    4.688 -246.027] (1.000)
Step: 11249, Reward: [   0.       0.       0.    -272.362] [117.9362], Avg: [   4.667    4.667    4.667 -246.144] (1.000)
Step: 11299, Reward: [   0.       0.       0.    -303.654] [131.4862], Avg: [   4.646    4.646    4.646 -246.399] (1.000)
Step: 11349, Reward: [   0.       0.       0.    -277.076] [119.9774], Avg: [   4.626    4.626    4.626 -246.534] (1.000)
Step: 11399, Reward: [  20.      20.      20.    -290.788] [134.5751], Avg: [   4.693    4.693    4.693 -246.728] (1.000)
Step: 11449, Reward: [   0.       0.       0.    -272.978] [118.2030], Avg: [   4.672    4.672    4.672 -246.843] (1.000)
Step: 11499, Reward: [   0.       0.       0.    -380.563] [164.7887], Avg: [   4.652    4.652    4.652 -247.424] (1.000)
Step: 11549, Reward: [   0.       0.       0.    -423.888] [183.5487], Avg: [   4.632    4.632    4.632 -248.188] (1.000)
Step: 11599, Reward: [   0.       0.       0.    -359.254] [155.5615], Avg: [   4.612    4.612    4.612 -248.667] (1.000)
Step: 11649, Reward: [   0.      0.      0.   -249.52] [108.0455], Avg: [   4.592    4.592    4.592 -248.67 ] (1.000)
Step: 11699, Reward: [   0.       0.       0.    -322.312] [139.5654], Avg: [   4.573    4.573    4.573 -248.985] (1.000)
Step: 11749, Reward: [   0.      0.      0.   -179.78] [77.8470], Avg: [   4.553    4.553    4.553 -248.69 ] (1.000)
Step: 11799, Reward: [   0.     0.     0.  -375.9] [162.7696], Avg: [   4.534    4.534    4.534 -249.23 ] (1.000)
Step: 11849, Reward: [   0.       0.       0.    -359.447] [155.6452], Avg: [   4.515    4.515    4.515 -249.695] (1.000)
Step: 11899, Reward: [  20.      20.      20.    -307.503] [141.8131], Avg: [   4.58     4.58     4.58  -249.937] (1.000)
Step: 11949, Reward: [   0.       0.       0.    -383.927] [166.2451], Avg: [   4.561    4.561    4.561 -250.498] (1.000)
Step: 11999, Reward: [   0.       0.       0.    -301.172] [130.4113], Avg: [   4.542    4.542    4.542 -250.709] (1.000)
Step: 12049, Reward: [   0.       0.       0.    -410.085] [177.5720], Avg: [   4.523    4.523    4.523 -251.371] (1.000)
Step: 12099, Reward: [ 0.     0.     0.    -8.333] [3.6085], Avg: [   4.504    4.504    4.504 -250.366] (1.000)
Step: 12149, Reward: [  10.      10.      10.    -348.448] [155.2127], Avg: [   4.527    4.527    4.527 -250.77 ] (1.000)
Step: 12199, Reward: [   0.       0.       0.    -346.835] [150.1840], Avg: [   4.508    4.508    4.508 -251.164] (1.000)
Step: 12249, Reward: [   0.      0.      0.   -347.01] [150.2598], Avg: [   4.49     4.49     4.49  -251.555] (1.000)
Step: 12299, Reward: [   0.       0.       0.    -434.822] [188.2836], Avg: [   4.472    4.472    4.472 -252.3  ] (1.000)
Step: 12349, Reward: [   0.       0.       0.    -405.611] [175.6349], Avg: [   4.453    4.453    4.453 -252.92 ] (1.000)
Step: 12399, Reward: [  10.      10.      10.    -360.376] [160.3776], Avg: [   4.476    4.476    4.476 -253.354] (1.000)
Step: 12449, Reward: [   0.       0.       0.    -314.223] [136.0624], Avg: [   4.458    4.458    4.458 -253.598] (1.000)
Step: 12499, Reward: [   0.       0.       0.    -374.673] [162.2382], Avg: [   4.44     4.44     4.44  -254.083] (1.000)
Step: 12549, Reward: [  20.      20.      20.    -282.275] [130.8890], Avg: [   4.502    4.502    4.502 -254.195] (1.000)
Step: 12599, Reward: [   0.       0.       0.    -380.611] [164.8095], Avg: [   4.484    4.484    4.484 -254.697] (1.000)
Step: 12649, Reward: [   0.       0.       0.    -303.644] [131.4815], Avg: [   4.466    4.466    4.466 -254.89 ] (1.000)
Step: 12699, Reward: [   0.       0.       0.    -332.476] [143.9664], Avg: [   4.449    4.449    4.449 -255.195] (1.000)
Step: 12749, Reward: [   0.       0.       0.    -387.683] [167.8715], Avg: [   4.431    4.431    4.431 -255.715] (1.000)
Step: 12799, Reward: [   0.       0.       0.    -369.475] [159.9872], Avg: [   4.414    4.414    4.414 -256.159] (1.000)
Step: 12849, Reward: [   0.       0.       0.    -411.349] [178.1194], Avg: [   4.397    4.397    4.397 -256.763] (1.000)
Step: 12899, Reward: [   0.       0.       0.    -315.645] [136.6785], Avg: [   4.38     4.38     4.38  -256.991] (1.000)
Step: 12949, Reward: [   0.       0.       0.    -368.723] [159.6618], Avg: [   4.363    4.363    4.363 -257.423] (1.000)
Step: 12999, Reward: [   0.       0.       0.    -235.861] [102.1306], Avg: [   4.346    4.346    4.346 -257.34 ] (1.000)
Step: 13049, Reward: [ 20.  20.  20. -20.] [17.3205], Avg: [   4.406    4.406    4.406 -256.431] (1.000)
Step: 13099, Reward: [   0.       0.       0.    -368.872] [159.7263], Avg: [   4.389    4.389    4.389 -256.86 ] (1.000)
Step: 13149, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.373    4.373    4.373 -255.883] (1.000)
Step: 13199, Reward: [   0.       0.       0.    -355.034] [153.7342], Avg: [   4.356    4.356    4.356 -256.259] (1.000)
Step: 13249, Reward: [ 0.     0.     0.    -0.919] [0.3981], Avg: [   4.34     4.34     4.34  -255.295] (1.000)
Step: 13299, Reward: [  0.      0.      0.    -62.354] [27.0001], Avg: [   4.323    4.323    4.323 -254.57 ] (1.000)
Step: 13349, Reward: [  30.      30.      30.    -345.556] [162.6203], Avg: [   4.419    4.419    4.419 -254.911] (1.000)
Step: 13399, Reward: [  0.      0.      0.    -28.212] [12.2162], Avg: [   4.403    4.403    4.403 -254.065] (1.000)
Step: 13449, Reward: [  0.      0.      0.    -19.546] [8.4636], Avg: [   4.387    4.387    4.387 -253.193] (1.000)
Step: 13499, Reward: [   0.      0.      0.   -414.51] [179.4881], Avg: [   4.37    4.37    4.37 -253.79] (1.000)
Step: 13549, Reward: [   0.       0.       0.    -135.027] [58.4682], Avg: [   4.354    4.354    4.354 -253.352] (1.000)
Step: 13599, Reward: [  20.     20.     20.   -267.29] [124.4004], Avg: [   4.412    4.412    4.412 -253.403] (1.000)
Step: 13649, Reward: [   0.       0.       0.    -368.287] [159.4732], Avg: [   4.396    4.396    4.396 -253.824] (1.000)
Step: 13699, Reward: [ 0.     0.     0.    -3.184] [1.3788], Avg: [   4.38     4.38     4.38  -252.909] (1.000)
Step: 13749, Reward: [  0.     0.     0.   -30.11] [13.0381], Avg: [   4.364    4.364    4.364 -252.099] (1.000)
Step: 13799, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.348    4.348    4.348 -251.186] (1.000)
Step: 13849, Reward: [  0.      0.      0.    -27.047] [11.7119], Avg: [   4.332    4.332    4.332 -250.377] (1.000)
Step: 13899, Reward: [  0.      0.      0.    -58.877] [25.4946], Avg: [   4.317    4.317    4.317 -249.688] (1.000)
Step: 13949, Reward: [  0.      0.      0.    -65.043] [28.1645], Avg: [   4.301    4.301    4.301 -249.026] (1.000)
Step: 13999, Reward: [   0.       0.       0.    -168.576] [72.9955], Avg: [   4.286    4.286    4.286 -248.739] (1.000)
Step: 14049, Reward: [  40.      40.      40.    -103.783] [62.2600], Avg: [   4.413    4.413    4.413 -248.223] (1.000)
Step: 14099, Reward: [  10.      10.      10.    -187.577] [85.5532], Avg: [   4.433    4.433    4.433 -248.008] (1.000)
Step: 14149, Reward: [  0.      0.      0.    -14.503] [6.2801], Avg: [   4.417    4.417    4.417 -247.183] (1.000)
Step: 14199, Reward: [ 0.     0.     0.    -6.373] [2.7595], Avg: [   4.401    4.401    4.401 -246.335] (1.000)
Step: 14249, Reward: [   0.       0.       0.    -261.382] [113.1817], Avg: [   4.386    4.386    4.386 -246.388] (1.000)
Step: 14299, Reward: [ 40.     40.     40.    -41.187] [35.1550], Avg: [   4.51    4.51    4.51 -245.67] (1.000)
Step: 14349, Reward: [   0.       0.       0.    -321.248] [139.1046], Avg: [   4.495    4.495    4.495 -245.933] (1.000)
Step: 14399, Reward: [ 0.     0.     0.    -0.188] [0.0815], Avg: [   4.479    4.479    4.479 -245.08 ] (1.000)
Step: 14449, Reward: [ 20.     20.     20.    -31.488] [22.2952], Avg: [   4.533    4.533    4.533 -244.341] (1.000)
Step: 14499, Reward: [ 20.     20.     20.    -47.281] [29.1336], Avg: [   4.586    4.586    4.586 -243.661] (1.000)
Step: 14549, Reward: [  0.      0.      0.    -59.401] [25.7215], Avg: [   4.57     4.57     4.57  -243.028] (1.000)
Step: 14599, Reward: [  0.      0.      0.    -17.727] [7.6762], Avg: [   4.555    4.555    4.555 -242.257] (1.000)
Step: 14649, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.539    4.539    4.539 -241.43 ] (1.000)
Step: 14699, Reward: [ 10.     10.     10.    -18.118] [12.1753], Avg: [   4.558    4.558    4.558 -240.67 ] (1.000)
Step: 14749, Reward: [   0.      0.      0.   -198.73] [86.0527], Avg: [   4.542    4.542    4.542 -240.528] (1.000)
Step: 14799, Reward: [ 20.     20.     20.    -94.291] [49.4896], Avg: [   4.595    4.595    4.595 -240.034] (1.000)
Step: 14849, Reward: [  0.     0.     0.   -53.16] [23.0189], Avg: [   4.579    4.579    4.579 -239.405] (1.000)
Step: 14899, Reward: [ 0.     0.     0.    -2.058] [0.8912], Avg: [   4.564    4.564    4.564 -238.608] (1.000)
Step: 14949, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.548    4.548    4.548 -237.81 ] (1.000)
Step: 14999, Reward: [   0.       0.       0.    -375.749] [162.7040], Avg: [   4.533    4.533    4.533 -238.27 ] (1.000)
Step: 15049, Reward: [  0.      0.      0.    -56.411] [24.4267], Avg: [   4.518    4.518    4.518 -237.666] (1.000)
Step: 15099, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.503    4.503    4.503 -236.879] (1.000)
Step: 15149, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.488    4.488    4.488 -236.097] (1.000)
Step: 15199, Reward: [  90.      90.      90.    -132.789] [96.4704], Avg: [   4.77     4.77     4.77  -235.757] (1.000)
Step: 15249, Reward: [   0.       0.       0.    -137.662] [59.6092], Avg: [   4.754    4.754    4.754 -235.436] (1.000)
Step: 15299, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.739    4.739    4.739 -234.666] (1.000)
Step: 15349, Reward: [ 10.     10.     10.    -23.962] [14.7061], Avg: [   4.756    4.756    4.756 -233.98 ] (1.000)
Step: 15399, Reward: [   0.      0.      0.   -163.17] [70.6545], Avg: [   4.74    4.74    4.74 -233.75] (1.000)
Step: 15449, Reward: [ 10.  10.  10. -10.] [8.6603], Avg: [   4.757    4.757    4.757 -233.026] (1.000)
Step: 15499, Reward: [ 20.  20.  20. -20.] [17.3205], Avg: [   4.806    4.806    4.806 -232.339] (1.000)
Step: 15549, Reward: [   0.      0.      0.   -303.47] [131.4063], Avg: [   4.791    4.791    4.791 -232.568] (1.000)
Step: 15599, Reward: [  0.      0.      0.    -19.051] [8.2493], Avg: [   4.776    4.776    4.776 -231.883] (1.000)
Step: 15649, Reward: [ 20.  20.  20. -31.] [22.0835], Avg: [   4.824    4.824    4.824 -231.241] (1.000)
Step: 15699, Reward: [   0.       0.       0.    -166.793] [72.2234], Avg: [   4.809    4.809    4.809 -231.036] (1.000)
Step: 15749, Reward: [  0.      0.      0.    -65.597] [28.4043], Avg: [   4.794    4.794    4.794 -230.511] (1.000)
Step: 15799, Reward: [ 20.     20.     20.    -53.445] [31.8028], Avg: [   4.842    4.842    4.842 -229.951] (1.000)
Step: 15849, Reward: [  20.      20.      20.    -151.251] [74.1540], Avg: [   4.89     4.89     4.89  -229.702] (1.000)
Step: 15899, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.874    4.874    4.874 -228.98 ] (1.000)
Step: 15949, Reward: [  0.      0.      0.    -56.267] [24.3642], Avg: [   4.859    4.859    4.859 -228.439] (1.000)
Step: 15999, Reward: [   0.       0.       0.    -263.961] [114.2986], Avg: [   4.844    4.844    4.844 -228.55 ] (1.000)
Step: 16049, Reward: [  10.      10.      10.    -321.597] [143.5858], Avg: [   4.86    4.86    4.86 -228.84] (1.000)
Step: 16099, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.845    4.845    4.845 -228.129] (1.000)
Step: 16149, Reward: [ 0.     0.     0.    -0.562] [0.2432], Avg: [   4.83     4.83     4.83  -227.424] (1.000)
Step: 16199, Reward: [  0.      0.      0.    -12.548] [5.4334], Avg: [   4.815    4.815    4.815 -226.761] (1.000)
Step: 16249, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.8      4.8      4.8   -226.063] (1.000)
Step: 16299, Reward: [   0.       0.       0.    -363.438] [157.3732], Avg: [   4.785    4.785    4.785 -226.485] (1.000)
Step: 16349, Reward: [  0.      0.      0.    -65.318] [28.2835], Avg: [   4.771    4.771    4.771 -225.992] (1.000)
Step: 16399, Reward: [   0.       0.       0.    -295.833] [128.0994], Avg: [   4.756    4.756    4.756 -226.205] (1.000)
Step: 16449, Reward: [  0.      0.      0.    -24.024] [10.4026], Avg: [   4.742    4.742    4.742 -225.59 ] (1.000)
Step: 16499, Reward: [   0.       0.       0.    -361.703] [156.6218], Avg: [   4.727    4.727    4.727 -226.003] (1.000)
Step: 16549, Reward: [  0.      0.      0.    -45.126] [19.5401], Avg: [   4.713    4.713    4.713 -225.456] (1.000)
Step: 16599, Reward: [   0.       0.       0.    -199.111] [86.2175], Avg: [   4.699    4.699    4.699 -225.377] (1.000)
Step: 16649, Reward: [   0.       0.       0.    -227.977] [98.7171], Avg: [   4.685    4.685    4.685 -225.385] (1.000)
Step: 16699, Reward: [ 0.     0.     0.    -6.421] [2.7802], Avg: [   4.671    4.671    4.671 -224.729] (1.000)
Step: 16749, Reward: [ 40.     40.     40.    -90.141] [56.3525], Avg: [   4.776    4.776    4.776 -224.327] (1.000)
Step: 16799, Reward: [  0.      0.      0.    -85.054] [36.8296], Avg: [   4.762    4.762    4.762 -223.913] (1.000)
Step: 16849, Reward: [ 20.     20.     20.    -24.986] [19.4794], Avg: [   4.807    4.807    4.807 -223.323] (1.000)
Step: 16899, Reward: [  0.      0.      0.    -40.529] [17.5498], Avg: [   4.793    4.793    4.793 -222.782] (1.000)
Step: 16949, Reward: [ 10.     10.     10.    -15.734] [11.1431], Avg: [   4.808    4.808    4.808 -222.171] (1.000)
Step: 16999, Reward: [  10.      10.      10.    -195.482] [88.9763], Avg: [   4.824    4.824    4.824 -222.093] (1.000)
Step: 17049, Reward: [   0.       0.       0.    -178.776] [77.4122], Avg: [   4.809    4.809    4.809 -221.966] (1.000)
Step: 17099, Reward: [ 0.     0.     0.    -9.147] [3.9606], Avg: [   4.795    4.795    4.795 -221.343] (1.000)
Step: 17149, Reward: [   0.      0.      0.   -500.12] [216.5583], Avg: [   4.781    4.781    4.781 -222.156] (1.000)
Step: 17199, Reward: [  0.      0.      0.    -89.279] [38.6589], Avg: [   4.767    4.767    4.767 -221.77 ] (1.000)
Step: 17249, Reward: [  10.      10.      10.    -321.426] [143.5117], Avg: [   4.783    4.783    4.783 -222.059] (1.000)
Step: 17299, Reward: [   0.       0.       0.    -441.573] [191.2069], Avg: [   4.769    4.769    4.769 -222.693] (1.000)
Step: 17349, Reward: [   0.       0.       0.    -503.313] [217.9411], Avg: [   4.755    4.755    4.755 -223.502] (1.000)
Step: 17399, Reward: [   0.       0.       0.    -396.243] [171.5781], Avg: [   4.741    4.741    4.741 -223.998] (1.000)
Step: 17449, Reward: [  40.      40.      40.    -263.022] [131.2125], Avg: [   4.842    4.842    4.842 -224.11 ] (1.000)
Step: 17499, Reward: [   0.       0.       0.    -546.113] [236.4740], Avg: [   4.829    4.829    4.829 -225.03 ] (1.000)
Step: 17549, Reward: [   0.       0.       0.    -514.431] [222.7550], Avg: [   4.815    4.815    4.815 -225.854] (1.000)
Step: 17599, Reward: [  10.      10.      10.    -667.054] [293.1730], Avg: [   4.83     4.83     4.83  -227.108] (1.000)
Step: 17649, Reward: [   0.       0.       0.    -694.502] [300.7281], Avg: [   4.816    4.816    4.816 -228.432] (1.000)
Step: 17699, Reward: [   0.       0.       0.    -617.019] [267.1771], Avg: [   4.802    4.802    4.802 -229.53 ] (1.000)
Step: 17749, Reward: [  10.      10.      10.    -364.634] [162.2211], Avg: [   4.817    4.817    4.817 -229.91 ] (1.000)
Step: 17799, Reward: [   0.       0.       0.    -697.123] [301.8632], Avg: [   4.803    4.803    4.803 -231.223] (1.000)
Step: 17849, Reward: [   0.       0.       0.    -376.671] [163.1033], Avg: [   4.79    4.79    4.79 -231.63] (1.000)
Step: 17899, Reward: [   0.       0.       0.    -294.948] [127.7161], Avg: [   4.777    4.777    4.777 -231.807] (1.000)
Step: 17949, Reward: [   0.       0.       0.    -594.356] [257.3637], Avg: [   4.763    4.763    4.763 -232.817] (1.000)
Step: 17999, Reward: [   0.       0.       0.    -115.224] [49.8934], Avg: [   4.75    4.75    4.75 -232.49] (1.000)
Step: 18049, Reward: [   0.       0.       0.    -382.178] [165.4878], Avg: [   4.737    4.737    4.737 -232.905] (1.000)
Step: 18099, Reward: [  20.    20.    20.  -281.5] [130.5535], Avg: [   4.779    4.779    4.779 -233.039] (1.000)
Step: 18149, Reward: [   0.      0.      0.   -404.13] [174.9933], Avg: [   4.766    4.766    4.766 -233.51 ] (1.000)
Step: 18199, Reward: [   0.       0.       0.    -307.518] [133.1594], Avg: [   4.753    4.753    4.753 -233.714] (1.000)
Step: 18249, Reward: [   0.      0.      0.   -425.38] [184.1950], Avg: [   4.74     4.74     4.74  -234.239] (1.000)
Step: 18299, Reward: [   0.       0.       0.    -299.498] [129.6866], Avg: [   4.727    4.727    4.727 -234.417] (1.000)
Step: 18349, Reward: [   0.       0.       0.    -333.578] [144.4436], Avg: [   4.714    4.714    4.714 -234.687] (1.000)
Step: 18399, Reward: [  10.      10.      10.    -226.234] [102.2922], Avg: [   4.728    4.728    4.728 -234.664] (1.000)
Step: 18449, Reward: [   0.       0.       0.    -297.945] [129.0139], Avg: [   4.715    4.715    4.715 -234.836] (1.000)
Step: 18499, Reward: [  10.      10.      10.    -290.216] [129.9975], Avg: [   4.73     4.73     4.73  -234.985] (1.000)
Step: 18549, Reward: [   0.       0.       0.    -297.322] [128.7441], Avg: [   4.717    4.717    4.717 -235.154] (1.000)
Step: 18599, Reward: [   0.      0.      0.   -320.86] [138.9366], Avg: [   4.704    4.704    4.704 -235.384] (1.000)
Step: 18649, Reward: [   0.       0.       0.    -357.045] [154.6050], Avg: [   4.692    4.692    4.692 -235.71 ] (1.000)
Step: 18699, Reward: [   0.       0.       0.    -431.192] [186.7116], Avg: [   4.679    4.679    4.679 -236.233] (1.000)
Step: 18749, Reward: [   0.       0.       0.    -293.189] [126.9545], Avg: [   4.667    4.667    4.667 -236.385] (1.000)
Step: 18799, Reward: [   0.       0.       0.    -417.237] [180.6691], Avg: [   4.654    4.654    4.654 -236.866] (1.000)
Step: 18849, Reward: [   0.       0.       0.    -313.849] [135.9004], Avg: [   4.642    4.642    4.642 -237.07 ] (1.000)
Step: 18899, Reward: [   0.       0.       0.    -329.958] [142.8760], Avg: [   4.63     4.63     4.63  -237.316] (1.000)
Step: 18949, Reward: [   0.       0.       0.    -416.002] [180.1340], Avg: [   4.617    4.617    4.617 -237.787] (1.000)
Step: 18999, Reward: [   0.       0.       0.    -410.147] [177.5990], Avg: [   4.605    4.605    4.605 -238.241] (1.000)
Step: 19049, Reward: [   0.       0.       0.    -420.741] [182.1863], Avg: [   4.593    4.593    4.593 -238.72 ] (1.000)
Step: 19099, Reward: [   0.      0.      0.   -367.46] [159.1147], Avg: [   4.581    4.581    4.581 -239.057] (1.000)
Step: 19149, Reward: [   0.       0.       0.    -395.992] [171.4697], Avg: [   4.569    4.569    4.569 -239.466] (1.000)
Step: 19199, Reward: [   0.       0.       0.    -334.366] [144.7847], Avg: [   4.557    4.557    4.557 -239.714] (1.000)
Step: 19249, Reward: [   0.       0.       0.    -327.851] [141.9636], Avg: [   4.545    4.545    4.545 -239.942] (1.000)
Step: 19299, Reward: [   0.       0.       0.    -391.328] [169.4498], Avg: [   4.534    4.534    4.534 -240.335] (1.000)
Step: 19349, Reward: [  20.      20.      20.    -329.923] [151.5212], Avg: [   4.574    4.574    4.574 -240.566] (1.000)
Step: 19399, Reward: [   0.      0.      0.   -408.04] [176.6866], Avg: [   4.562    4.562    4.562 -240.998] (1.000)
Step: 19449, Reward: [   0.      0.      0.   -296.04] [128.1892], Avg: [   4.55     4.55     4.55  -241.139] (1.000)
Step: 19499, Reward: [   0.       0.       0.    -363.331] [157.3268], Avg: [   4.538    4.538    4.538 -241.453] (1.000)
Step: 19549, Reward: [   0.       0.       0.    -375.484] [162.5892], Avg: [   4.527    4.527    4.527 -241.795] (1.000)
Step: 19599, Reward: [   0.       0.       0.    -301.409] [130.5141], Avg: [   4.515    4.515    4.515 -241.947] (1.000)
Step: 19649, Reward: [   0.       0.       0.    -393.365] [170.3320], Avg: [   4.504    4.504    4.504 -242.333] (1.000)
Step: 19699, Reward: [   0.       0.       0.    -408.291] [176.7950], Avg: [   4.492    4.492    4.492 -242.754] (1.000)
Step: 19749, Reward: [   0.       0.       0.    -350.056] [151.5788], Avg: [   4.481    4.481    4.481 -243.026] (1.000)
Step: 19799, Reward: [   0.      0.      0.   -298.97] [129.4577], Avg: [   4.47     4.47     4.47  -243.167] (1.000)
Step: 19849, Reward: [   0.       0.       0.    -284.365] [123.1337], Avg: [   4.458    4.458    4.458 -243.271] (1.000)
Step: 19899, Reward: [   0.       0.       0.    -275.292] [119.2049], Avg: [   4.447    4.447    4.447 -243.351] (1.000)
Step: 19949, Reward: [   0.       0.       0.    -185.172] [80.1816], Avg: [   4.436    4.436    4.436 -243.205] (1.000)
Step: 19999, Reward: [   0.      0.      0.   -186.06] [80.5663], Avg: [   4.425    4.425    4.425 -243.062] (1.000)
Step: 20049, Reward: [  0.     0.     0.   -53.89] [23.3351], Avg: [   4.414    4.414    4.414 -242.591] (1.000)
Step: 20099, Reward: [  10.      10.      10.    -317.211] [141.6864], Avg: [   4.428    4.428    4.428 -242.776] (1.000)
Step: 20149, Reward: [   0.       0.       0.    -360.606] [156.1470], Avg: [   4.417    4.417    4.417 -243.069] (1.000)
Step: 20199, Reward: [   0.       0.       0.    -105.885] [45.8497], Avg: [   4.406    4.406    4.406 -242.729] (1.000)
Step: 20249, Reward: [  0.      0.      0.    -49.112] [21.2659], Avg: [   4.395    4.395    4.395 -242.251] (1.000)
Step: 20299, Reward: [   0.       0.       0.    -165.739] [71.7673], Avg: [   4.384    4.384    4.384 -242.063] (1.000)
Step: 20349, Reward: [  0.      0.      0.    -56.418] [24.4298], Avg: [   4.373    4.373    4.373 -241.606] (1.000)
Step: 20399, Reward: [  0.      0.      0.    -51.083] [22.1196], Avg: [   4.363    4.363    4.363 -241.139] (1.000)
Step: 20449, Reward: [ 20.     20.     20.    -95.307] [49.9292], Avg: [   4.401    4.401    4.401 -240.783] (1.000)
Step: 20499, Reward: [  0.      0.      0.    -92.732] [40.1541], Avg: [   4.39     4.39     4.39  -240.422] (1.000)
Step: 20549, Reward: [ 30.     30.     30.    -78.902] [47.1559], Avg: [   4.453    4.453    4.453 -240.029] (1.000)
Step: 20599, Reward: [  0.      0.      0.    -73.603] [31.8711], Avg: [   4.442    4.442    4.442 -239.625] (1.000)
Step: 20649, Reward: [ 0.     0.     0.    -0.007] [0.0032], Avg: [   4.431    4.431    4.431 -239.045] (1.000)
Step: 20699, Reward: [   0.       0.       0.    -165.967] [71.8660], Avg: [   4.42     4.42     4.42  -238.868] (1.000)
Step: 20749, Reward: [ 0.  0.  0. -5.] [2.1650], Avg: [   4.41     4.41     4.41  -238.305] (1.000)
Step: 20799, Reward: [ 0.    0.    0.   -0.58] [0.2510], Avg: [   4.399    4.399    4.399 -237.733] (1.000)
Step: 20849, Reward: [  0.     0.     0.   -44.11] [19.1002], Avg: [   4.388    4.388    4.388 -237.269] (1.000)
Step: 20899, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.378    4.378    4.378 -236.701] (1.000)
Step: 20949, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.368    4.368    4.368 -236.136] (1.000)
Step: 20999, Reward: [ 40.     40.     40.    -40.839] [35.0045], Avg: [   4.452    4.452    4.452 -235.671] (1.000)
Step: 21049, Reward: [ 20.     20.     20.    -22.192] [18.2695], Avg: [   4.489    4.489    4.489 -235.164] (1.000)
Step: 21099, Reward: [ 0.     0.     0.    -3.351] [1.4510], Avg: [   4.479    4.479    4.479 -234.615] (1.000)
Step: 21149, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.468    4.468    4.468 -234.06 ] (1.000)
Step: 21199, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.458    4.458    4.458 -233.508] (1.000)
Step: 21249, Reward: [   0.       0.       0.    -175.347] [75.9275], Avg: [   4.447    4.447    4.447 -233.371] (1.000)
Step: 21299, Reward: [ 0.     0.     0.    -3.096] [1.3405], Avg: [   4.437    4.437    4.437 -232.831] (1.000)
Step: 21349, Reward: [   0.       0.       0.    -362.787] [157.0914], Avg: [   4.426    4.426    4.426 -233.135] (1.000)
Step: 21399, Reward: [   0.       0.       0.    -313.927] [135.9342], Avg: [   4.416    4.416    4.416 -233.324] (1.000)
Step: 21449, Reward: [   0.       0.       0.    -346.666] [150.1107], Avg: [   4.406    4.406    4.406 -233.588] (1.000)
Step: 21499, Reward: [   0.       0.       0.    -183.983] [79.6670], Avg: [   4.395    4.395    4.395 -233.473] (1.000)
Step: 21549, Reward: [   0.       0.       0.    -385.263] [166.8236], Avg: [   4.385    4.385    4.385 -233.825] (1.000)
Step: 21599, Reward: [  90.      90.      90.    -313.486] [174.7144], Avg: [   4.583    4.583    4.583 -234.009] (1.000)
Step: 21649, Reward: [   0.       0.       0.    -258.005] [111.7195], Avg: [   4.573    4.573    4.573 -234.065] (1.000)
Step: 21699, Reward: [   0.       0.       0.    -308.319] [133.5058], Avg: [   4.562    4.562    4.562 -234.236] (1.000)
Step: 21749, Reward: [   0.       0.       0.    -263.062] [113.9094], Avg: [   4.552    4.552    4.552 -234.302] (1.000)
Step: 21799, Reward: [   0.       0.       0.    -372.955] [161.4941], Avg: [   4.541    4.541    4.541 -234.62 ] (1.000)
Step: 21849, Reward: [   0.      0.      0.   -372.06] [161.1067], Avg: [   4.531    4.531    4.531 -234.935] (1.000)
Step: 21899, Reward: [   0.       0.       0.    -241.549] [104.5936], Avg: [   4.521    4.521    4.521 -234.95 ] (1.000)
Step: 21949, Reward: [   0.       0.       0.    -298.457] [129.2357], Avg: [   4.51     4.51     4.51  -235.094] (1.000)
Step: 21999, Reward: [ 40.     40.     40.    -71.735] [48.3828], Avg: [   4.591    4.591    4.591 -234.723] (1.000)
Step: 22049, Reward: [   0.       0.       0.    -415.548] [179.9374], Avg: [   4.58     4.58     4.58  -235.133] (1.000)
Step: 22099, Reward: [   0.       0.       0.    -266.428] [115.3669], Avg: [   4.57     4.57     4.57  -235.204] (1.000)
Step: 22149, Reward: [   0.       0.       0.    -246.073] [106.5529], Avg: [   4.56     4.56     4.56  -235.229] (1.000)
Step: 22199, Reward: [   0.       0.       0.    -383.452] [166.0397], Avg: [   4.55     4.55     4.55  -235.562] (1.000)
Step: 22249, Reward: [   0.       0.       0.    -222.672] [96.4197], Avg: [   4.539    4.539    4.539 -235.533] (1.000)
Step: 22299, Reward: [   0.       0.       0.    -181.539] [78.6087], Avg: [   4.529    4.529    4.529 -235.412] (1.000)
Step: 22349, Reward: [   0.      0.      0.   -237.63] [102.8970], Avg: [   4.519    4.519    4.519 -235.417] (1.000)
Step: 22399, Reward: [   0.      0.      0.   -336.17] [145.5660], Avg: [   4.509    4.509    4.509 -235.642] (1.000)
Step: 22449, Reward: [   0.       0.       0.    -392.714] [170.0503], Avg: [   4.499    4.499    4.499 -235.992] (1.000)
Step: 22499, Reward: [   0.       0.       0.    -486.372] [210.6053], Avg: [   4.489    4.489    4.489 -236.548] (1.000)
Step: 22549, Reward: [ 20.  20.  20. -20.] [17.3205], Avg: [   4.523    4.523    4.523 -236.068] (1.000)
Step: 22599, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.513    4.513    4.513 -235.546] (1.000)
Step: 22649, Reward: [   0.      0.      0.   -303.31] [131.3372], Avg: [   4.503    4.503    4.503 -235.696] (1.000)
Step: 22699, Reward: [   0.       0.       0.    -162.611] [70.4126], Avg: [   4.493    4.493    4.493 -235.535] (1.000)
Step: 22749, Reward: [   0.       0.       0.    -346.398] [149.9949], Avg: [   4.484    4.484    4.484 -235.778] (1.000)
Step: 22799, Reward: [   0.       0.       0.    -222.821] [96.4842], Avg: [   4.474    4.474    4.474 -235.75 ] (1.000)
Step: 22849, Reward: [  0.      0.      0.    -96.002] [41.5700], Avg: [   4.464    4.464    4.464 -235.444] (1.000)
Step: 22899, Reward: [   0.       0.       0.    -202.645] [87.7480], Avg: [   4.454    4.454    4.454 -235.372] (1.000)
Step: 22949, Reward: [ 10.     10.     10.    -11.801] [9.4403], Avg: [   4.466    4.466    4.466 -234.885] (1.000)
Step: 22999, Reward: [   0.       0.       0.    -574.509] [248.7697], Avg: [   4.457    4.457    4.457 -235.624] (1.000)
Step: 23049, Reward: [  0.      0.      0.    -59.279] [25.6684], Avg: [   4.447    4.447    4.447 -235.241] (1.000)
Step: 23099, Reward: [ 10.  10.  10. -10.] [8.6603], Avg: [   4.459    4.459    4.459 -234.754] (1.000)
Step: 23149, Reward: [ 0.     0.     0.    -0.176] [0.0761], Avg: [   4.449    4.449    4.449 -234.247] (1.000)
Step: 23199, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.44     4.44     4.44  -233.742] (1.000)
Step: 23249, Reward: [ 10.  10.  10. -10.] [8.6603], Avg: [   4.452    4.452    4.452 -233.261] (1.000)
Step: 23299, Reward: [ 20.  20.  20. -20.] [17.3205], Avg: [   4.485    4.485    4.485 -232.803] (1.000)
Step: 23349, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.475    4.475    4.475 -232.305] (1.000)
Step: 23399, Reward: [  0.     0.     0.   -50.65] [21.9322], Avg: [   4.466    4.466    4.466 -231.917] (1.000)
Step: 23449, Reward: [ 10.  10.  10. -10.] [8.6603], Avg: [   4.478    4.478    4.478 -231.443] (1.000)
Step: 23499, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.468    4.468    4.468 -230.951] (1.000)
Step: 23549, Reward: [   0.       0.       0.    -107.903] [46.7233], Avg: [   4.459    4.459    4.459 -230.69 ] (1.000)
Step: 23599, Reward: [ 0.     0.     0.    -4.733] [2.0495], Avg: [   4.449    4.449    4.449 -230.211] (1.000)
Step: 23649, Reward: [ 0.     0.     0.    -5.848] [2.5324], Avg: [   4.44     4.44     4.44  -229.737] (1.000)
Step: 23699, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.43     4.43     4.43  -229.252] (1.000)
Step: 23749, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.421    4.421    4.421 -228.769] (1.000)
Step: 23799, Reward: [ 0.     0.     0.    -0.588] [0.2545], Avg: [   4.412    4.412    4.412 -228.29 ] (1.000)
Step: 23849, Reward: [ 10.  10.  10. -10.] [8.6603], Avg: [   4.423    4.423    4.423 -227.832] (1.000)
Step: 23899, Reward: [ 0.     0.     0.    -2.559] [1.1080], Avg: [   4.414    4.414    4.414 -227.361] (1.000)
Step: 23949, Reward: [ 10.     10.     10.    -61.026] [30.7550], Avg: [   4.426    4.426    4.426 -227.014] (1.000)
Step: 23999, Reward: [   0.       0.       0.    -261.082] [113.0520], Avg: [   4.417    4.417    4.417 -227.085] (1.000)
Step: 24049, Reward: [ 0.     0.     0.    -0.851] [0.3687], Avg: [   4.407    4.407    4.407 -226.615] (1.000)
Step: 24099, Reward: [   0.       0.       0.    -282.056] [122.1340], Avg: [   4.398    4.398    4.398 -226.73 ] (1.000)
Step: 24149, Reward: [   0.       0.       0.    -286.579] [124.0923], Avg: [   4.389    4.389    4.389 -226.853] (1.000)
Step: 24199, Reward: [  0.      0.      0.    -84.861] [36.7459], Avg: [   4.38    4.38    4.38 -226.56] (1.000)
Step: 24249, Reward: [  20.      20.      20.    -130.531] [65.1817], Avg: [   4.412    4.412    4.412 -226.362] (1.000)
Step: 24299, Reward: [ 30.  30.  30. -30.] [25.9808], Avg: [   4.465    4.465    4.465 -225.958] (1.000)
Step: 24349, Reward: [ 20.  20.  20. -20.] [17.3205], Avg: [   4.497    4.497    4.497 -225.535] (1.000)
Step: 24399, Reward: [   0.       0.       0.    -498.372] [215.8013], Avg: [   4.488    4.488    4.488 -226.094] (1.000)
Step: 24449, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.479    4.479    4.479 -225.632] (1.000)
Step: 24499, Reward: [  0.      0.      0.    -42.736] [18.5053], Avg: [   4.469    4.469    4.469 -225.259] (1.000)
Step: 24549, Reward: [ 20.     20.     20.    -20.557] [17.5617], Avg: [   4.501    4.501    4.501 -224.842] (1.000)
Step: 24599, Reward: [ 10.  10.  10. -10.] [8.6603], Avg: [   4.512    4.512    4.512 -224.405] (1.000)
Step: 24649, Reward: [   0.       0.       0.    -434.364] [188.0850], Avg: [   4.503    4.503    4.503 -224.831] (1.000)
Step: 24699, Reward: [ 0.     0.     0.    -6.266] [2.7133], Avg: [   4.494    4.494    4.494 -224.388] (1.000)
Step: 24749, Reward: [   0.       0.       0.    -180.481] [78.1504], Avg: [   4.485    4.485    4.485 -224.3  ] (1.000)
Step: 24799, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.476    4.476    4.476 -223.848] (1.000)
Step: 24849, Reward: [  20.     20.     20.   -387.98] [176.6607], Avg: [   4.507    4.507    4.507 -224.178] (1.000)
Step: 24899, Reward: [0. 0. 0. 0.] [0.0000], Avg: [   4.498    4.498    4.498 -223.728] (1.000)
