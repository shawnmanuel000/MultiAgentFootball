Model: <class 'multiagent.mappo.MAPPOAgent'>, Dir: simple_spread, Date: 13/03/2020 15:11:57
num_envs: 16,
state_size: [(1, 18), (1, 18), (1, 18)],
action_size: [[1, 5], [1, 5], [1, 5]],
action_space: [MultiDiscrete([5]), MultiDiscrete([5]), MultiDiscrete([5])],
envs: <class 'utils.envs.EnsembleEnv'>,
reward_shape: False,
icm: False,

import torch
import numpy as np
from models.ppo import PPONetwork, PPOCritic
from models.rand import MultiagentReplayBuffer2, MultiagentReplayBuffer3
from utils.network import PTNetwork, PTACNetwork, PTACAgent, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, MultiheadAttention, one_hot_from_indices

PPO_EPOCHS = 4					# Number of iterations to sample batches for training
BATCH_SIZE = 10					# Number of samples to train on for each train step
EPISODE_BUFFER = 64  	    	# Sets the maximum length of the replay buffer
CLIP_PARAM = 0.1				# The limit of the ratio of new action probabilities to old probabilities
EPS_MAX = 0.1                 	# The starting weight for the entropy term of the Actor loss
EPS_MIN = 0.001               	# The lower weight for the entropy term of the Actor loss
EPS_DECAY = 0.9             	# The rate at which eps decays from EPS_MAX to EPS_MIN
TIME_BATCHES = 1				# The number of batches of time steps to train critic in reverse time sequence

class MAPPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_probs = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		action_probs = self.action_probs(state).softmax(-1)
		dist = torch.distributions.Categorical(action_probs)
		action_in = dist.sample() if action is None else action.argmax(-1)
		action = one_hot_from_indices(action_in, action_probs.size(-1))
		log_prob = dist.log_prob(action_in)
		entropy = dist.entropy()
		return action, log_prob, entropy

class MAPPONetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(gpu=gpu, name="mappo")
		self.critic = PPOCritic([np.sum([np.prod(s) for s in state_size])], [np.sum([np.prod(a) for a in action_size])])
		self.models = [PPONetwork(s_size, a_size, MAPPOActor, lambda s,a: self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(state_size, action_size)]
		if load: self.load_model(load)

	def get_action_probs(self, state, action_in=None, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action_in = [None] * len(state) if action_in is None else action_in
			action_or_entropy, log_prob = map(list, zip(*[model.get_action_probs(s, a, grad=grad, numpy=numpy, sample=sample) for s,a,model in zip(state, action_in, self.models)]))
			return action_or_entropy, log_prob

	def optimize(self, states, actions, states_joint, old_log_probs, rewards, dones, clip_param=CLIP_PARAM, e_weight=EPS_MIN):
		critic_losses = []
		agent = self.models[0]
		next_value = agent.get_value(states_joint)
		next_value = torch.cat([next_value, torch.zeros_like(next_value[:,-1]).unsqueeze(1)], dim=1)
		targets = PTACAgent.compute_ma_gae(rewards[0].unsqueeze(-1), dones[0].unsqueeze(-1), next_value)
		values = torch.zeros_like(targets)
		t_batch = max(rewards[0].size(1)//TIME_BATCHES, 1)
		for t in reversed(range(0,min(rewards[0].size(1), t_batch*TIME_BATCHES),t_batch)):
			values[:,t:t+t_batch] = agent.get_value(states_joint[:,t:t+t_batch], grad=True, numpy=False)
			critic_loss = (values[:,t:t+t_batch] - targets[:,t:t+t_batch].detach()).pow(2).mean()
			critic_losses.append(critic_loss.detach().cpu().numpy())
			agent.step(agent.critic_optimizer, critic_loss, agent.critic_local.parameters(), retain=t>0)	
		advantage = (targets - values).detach()
		
		actor_losses = []
		for model, state, action, old_log_prob in zip(self.models, states, actions, old_log_probs):		
			entropy, new_log_prob = model.get_action_probs(state, action, grad=True, numpy=False)
			ratio = (new_log_prob - old_log_prob).exp()
			ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
			advantage = advantage.view(*advantage.shape, *[1]*(len(ratio.shape)-len(advantage.shape)))
			actor_loss = -(torch.min(ratio*advantage, ratio_clipped*advantage) + e_weight*entropy).mean()
			model.step(model.actor_optimizer, actor_loss, model.actor_local.parameters())
			actor_losses.append([x.detach().cpu().numpy() for x in [actor_loss, entropy]])
		return [np.mean(critic_losses), *np.mean(actor_losses, axis=0)]

	def save_model(self, dirname="pytorch", name="checkpoint"):
		[PTACNetwork.save_model(model, dirname, f"{name}_{i}", self.name) for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="checkpoint"):
		[PTACNetwork.load_model(model, dirname, f"{name}_{i}", self.name) for i,model in enumerate(self.models)]

class MAPPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, eps=EPS_MAX, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, MAPPONetwork, lr=lr, update_freq=update_freq, eps=eps, decay=decay, gpu=gpu, load=load)
		self.replay_buffer = MultiagentReplayBuffer3(EPISODE_BUFFER, state_size, action_size)
		self.stats = []

	def get_action(self, state, eps=None, sample=True, numpy=True):
		action, self.log_prob = self.network.get_action_probs(self.to_tensor(state), numpy=True, sample=sample)
		return action

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, self.log_prob, reward, done))
		if np.any(done[0]):
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			self.replay_buffer.add([self.to_numpy([t.transpose(0,1) for t in x]) for x in (states, actions, [states_joint], log_probs, rewards, dones)])
			self.buffer.clear()
		if len(self.replay_buffer) >= self.replay_buffer.max_steps:
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				states, actions, states_joint, log_probs, rewards, dones = self.replay_buffer.sample(BATCH_SIZE, lambda x: torch.Tensor(x).to(self.network.device))
				self.stats.append(self.network.optimize(states, actions, states_joint[0], log_probs, rewards, dones, e_weight=self.eps))
			self.eps = max(self.eps * self.decay, EPS_MIN)
			self.replay_buffer.clear()

	def get_stats(self):
		stats = {k:v for k,v in zip(["critic_loss", "actor_loss", "entropy"], np.mean(self.stats, axis=0))} if len(self.stats)>0 else {}
		self.stats = []
		return {**stats, **super().get_stats()}

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0003           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.001   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 256				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 512				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.998			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.001               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 1000000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.sac import SACAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, DoubleAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv, TrainEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, MPI_SIZE, MPI_RANK
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-3]
# env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False, reward_shape=False):
	if env_name in gym_envs: return TrainEnv(gym.make(env_name))
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	ballr = lambda x,y: (np.maximum if x>0 else np.minimum)(x - np.abs(y)*np.sign(x), 0.5*x)
	reward_fn = lambda obs,reward,eps: [0.1*(ballr(o[0,88], o[0,89])) + r for o,r in zip(obs,reward)]
	return FootballTeamEnv(ggym, env_name, reward_fn if reward_shape else None)

def train(model, steps=10000, ports=16, env_name=env_name, trial_at=500, save_at=10, checkpoint=True, save_best=False, log=True, render=False, reward_shape=False, icm=False):
	envs = (EnvManager if type(ports) == list or MPI_SIZE > 1 else EnsembleEnv)(lambda: make_env(env_name, reward_shape=reward_shape), ports)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, envs.num_envs, load="", gpu=True, agent2=RandomAgent, save_dir=env_name, icm=icm) 
	logger = Logger(model, env_name, num_envs=envs.num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space, envs=type(envs), reward_shape=reward_shape, icm=icm)
	states = envs.reset(train=True)
	total_rewards = []
	for s in range(steps+1):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions, train=True)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if s%trial_at == 0:
			rollouts = rollout(envs, agent, render=render)
			total_rewards.append(np.mean(rollouts, axis=-1))
			if save_best and np.all(total_rewards[-1] >= np.max(total_rewards, axis=-1)): agent.save_model(env_name)
			if checkpoint and len(total_rewards) % save_at==0: agent.save_model(env_name, f"checkpoint{'_rs' if reward_shape else ''}{'_icm' if icm else ''}")
			if log: logger.log(f"Step: {s:7d}, Reward: {total_rewards[-1]} [{np.std(rollouts):4.3f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.eps:.4f})", agent.get_stats())

def trial(model, env_name, render):
	envs = EnsembleEnv(lambda: make_env(env_name, log=True, render=render), 0)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, gpu=False, load=f"{env_name}", agent2=RandomAgent, save_dir=env_name)
	print(f"Reward: {np.mean([rollout(envs.env, agent, eps=0.0, render=True) for _ in range(5)], axis=0)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="coma", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=200000, help="Number of steps to train the agent")
	parser.add_argument("--reward_shape", action="store_true", help="Whether to shape rewards for football")
	parser.add_argument("--icm", action="store_true", help="Whether to use intrinsic motivation")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--trial", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "sac":SACAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent, "rand":RandomAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.selfport is not None or MPI_RANK>0:
		EnvWorker(self_port=args.selfport, make_env=make_env).start()
	elif args.trial:
		trial(model=model, env_name=env_name, render=args.render)
	else:
		train(model=model, steps=args.steps, ports=args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render, reward_shape=args.reward_shape, icm=args.icm)


Step:       0, Reward: [-519.964 -519.964 -519.964] [90.133], Avg: [-519.964 -519.964 -519.964] (0.1000) <00:00:00> ({r_i: None, r_t: [-7.756 -7.756 -7.756], eps: 0.1})
Step:     500, Reward: [-486.368 -486.368 -486.368] [105.811], Avg: [-503.166 -503.166 -503.166] (0.0810) <00:00:07> ({r_i: None, r_t: [-4994.958 -4994.958 -4994.958], critic_loss: 18868.046875, actor_loss: 102.2249984741211, entropy: 1.5950000286102295, eps: 0.081})
Step:    1000, Reward: [-506.657 -506.657 -506.657] [92.531], Avg: [-504.330 -504.330 -504.330] (0.0590) <00:00:15> ({r_i: None, r_t: [-4990.131 -4990.131 -4990.131], critic_loss: 26925.07421875, actor_loss: 24.87299919128418, entropy: 1.5859999656677246, eps: 0.059})
Step:    1500, Reward: [-437.630 -437.630 -437.630] [69.092], Avg: [-487.655 -487.655 -487.655] (0.0478) <00:00:23> ({r_i: None, r_t: [-5000.407 -5000.407 -5000.407], critic_loss: 23013.19921875, actor_loss: 15.423999786376953, entropy: 1.5820000171661377, eps: 0.048})
Step:    2000, Reward: [-505.803 -505.803 -505.803] [94.840], Avg: [-491.284 -491.284 -491.284] (0.0349) <00:00:31> ({r_i: None, r_t: [-4805.842 -4805.842 -4805.842], critic_loss: 17472.642578125, actor_loss: 11.01099967956543, entropy: 1.5750000476837158, eps: 0.035})
Step:    2500, Reward: [-477.239 -477.239 -477.239] [84.162], Avg: [-488.943 -488.943 -488.943] (0.0282) <00:00:39> ({r_i: None, r_t: [-4748.711 -4748.711 -4748.711], critic_loss: 13946.2421875, actor_loss: 7.0929999351501465, entropy: 1.562999963760376, eps: 0.028})
Step:    3000, Reward: [-510.149 -510.149 -510.149] [96.170], Avg: [-491.973 -491.973 -491.973] (0.0206) <00:00:47> ({r_i: None, r_t: [-4784.509 -4784.509 -4784.509], critic_loss: 9784.76953125, actor_loss: 2.937000036239624, entropy: 1.5390000343322754, eps: 0.021})
Step:    3500, Reward: [-555.413 -555.413 -555.413] [125.890], Avg: [-499.903 -499.903 -499.903] (0.0167) <00:00:55> ({r_i: None, r_t: [-4972.504 -4972.504 -4972.504], critic_loss: 9717.4189453125, actor_loss: 4.304999828338623, entropy: 1.5169999599456787, eps: 0.017})
Step:    4000, Reward: [-524.802 -524.802 -524.802] [95.991], Avg: [-502.669 -502.669 -502.669] (0.0122) <00:01:03> ({r_i: None, r_t: [-4894.248 -4894.248 -4894.248], critic_loss: 7622.17919921875, actor_loss: 2.6610000133514404, entropy: 1.468999981880188, eps: 0.012})
Step:    4500, Reward: [-505.305 -505.305 -505.305] [76.954], Avg: [-502.933 -502.933 -502.933] (0.0098) <00:01:11> ({r_i: None, r_t: [-4899.357 -4899.357 -4899.357], critic_loss: 6613.72314453125, actor_loss: 1.8799999952316284, entropy: 1.4119999408721924, eps: 0.01})
Step:    5000, Reward: [-478.603 -478.603 -478.603] [90.196], Avg: [-500.721 -500.721 -500.721] (0.0072) <00:01:19> ({r_i: None, r_t: [-5017.671 -5017.671 -5017.671], critic_loss: 6377.65380859375, actor_loss: 3.180999994277954, entropy: 1.4160000085830688, eps: 0.007})
Step:    5500, Reward: [-550.417 -550.417 -550.417] [147.727], Avg: [-504.862 -504.862 -504.862] (0.0058) <00:01:26> ({r_i: None, r_t: [-4841.616 -4841.616 -4841.616], critic_loss: 6761.576171875, actor_loss: -0.8709999918937683, entropy: 1.3980000019073486, eps: 0.006})
Step:    6000, Reward: [-495.189 -495.189 -495.189] [96.214], Avg: [-504.118 -504.118 -504.118] (0.0042) <00:01:35> ({r_i: None, r_t: [-4930.100 -4930.100 -4930.100], critic_loss: 3953.426025390625, actor_loss: 2.5209999084472656, entropy: 1.343999981880188, eps: 0.004})
Step:    6500, Reward: [-488.208 -488.208 -488.208] [99.495], Avg: [-502.982 -502.982 -502.982] (0.0034) <00:01:42> ({r_i: None, r_t: [-4940.815 -4940.815 -4940.815], critic_loss: 5201.89501953125, actor_loss: 2.6670000553131104, entropy: 1.309999942779541, eps: 0.003})
Step:    7000, Reward: [-441.368 -441.368 -441.368] [64.085], Avg: [-498.874 -498.874 -498.874] (0.0025) <00:01:51> ({r_i: None, r_t: [-4759.798 -4759.798 -4759.798], critic_loss: 3552.444091796875, actor_loss: 1.5089999437332153, entropy: 1.3049999475479126, eps: 0.003})
Step:    7500, Reward: [-468.488 -468.488 -468.488] [122.457], Avg: [-496.975 -496.975 -496.975] (0.0020) <00:01:58> ({r_i: None, r_t: [-4849.165 -4849.165 -4849.165], critic_loss: 3218.75390625, actor_loss: 1.8240000009536743, entropy: 1.246999979019165, eps: 0.002})
Step:    8000, Reward: [-464.903 -464.903 -464.903] [83.511], Avg: [-495.089 -495.089 -495.089] (0.0015) <00:02:06> ({r_i: None, r_t: [-4739.566 -4739.566 -4739.566], critic_loss: 2740.422119140625, actor_loss: 1.5199999809265137, entropy: 1.190000057220459, eps: 0.001})
Step:    8500, Reward: [-439.250 -439.250 -439.250] [72.029], Avg: [-491.986 -491.986 -491.986] (0.0012) <00:02:14> ({r_i: None, r_t: [-4593.247 -4593.247 -4593.247], critic_loss: 2338.06591796875, actor_loss: 1.996999979019165, entropy: 1.156999945640564, eps: 0.001})
Step:    9000, Reward: [-427.826 -427.826 -427.826] [35.542], Avg: [-488.610 -488.610 -488.610] (0.0010) <00:02:22> ({r_i: None, r_t: [-4652.713 -4652.713 -4652.713], critic_loss: 1853.6650390625, actor_loss: 0.8389999866485596, entropy: 1.1399999856948853, eps: 0.001})
Step:    9500, Reward: [-443.239 -443.239 -443.239] [53.557], Avg: [-486.341 -486.341 -486.341] (0.0010) <00:02:30> ({r_i: None, r_t: [-4615.442 -4615.442 -4615.442], critic_loss: 1948.009033203125, actor_loss: 1.0449999570846558, entropy: 1.11899995803833, eps: 0.001})
Step:   10000, Reward: [-413.898 -413.898 -413.898] [66.041], Avg: [-482.891 -482.891 -482.891] (0.0010) <00:02:38> ({r_i: None, r_t: [-4390.889 -4390.889 -4390.889], critic_loss: 1204.5550537109375, actor_loss: 0.8870000243186951, entropy: 1.0880000591278076, eps: 0.001})
Step:   10500, Reward: [-417.866 -417.866 -417.866] [67.435], Avg: [-479.936 -479.936 -479.936] (0.0010) <00:02:46> ({r_i: None, r_t: [-4394.953 -4394.953 -4394.953], critic_loss: 2033.905029296875, actor_loss: 2.5320000648498535, entropy: 1.0670000314712524, eps: 0.001})
Step:   11000, Reward: [-437.846 -437.846 -437.846] [49.908], Avg: [-478.106 -478.106 -478.106] (0.0010) <00:02:54> ({r_i: None, r_t: [-4372.879 -4372.879 -4372.879], critic_loss: 1003.239990234375, actor_loss: 0.6570000052452087, entropy: 1.0549999475479126, eps: 0.001})
Step:   11500, Reward: [-443.403 -443.403 -443.403] [72.583], Avg: [-476.660 -476.660 -476.660] (0.0010) <00:03:01> ({r_i: None, r_t: [-4304.861 -4304.861 -4304.861], critic_loss: 798.9229736328125, actor_loss: 0.16300000250339508, entropy: 0.9980000257492065, eps: 0.001})
Step:   12000, Reward: [-421.350 -421.350 -421.350] [48.135], Avg: [-474.447 -474.447 -474.447] (0.0010) <00:03:10> ({r_i: None, r_t: [-4260.061 -4260.061 -4260.061], critic_loss: 681.1400146484375, actor_loss: 0.23100000619888306, entropy: 0.9589999914169312, eps: 0.001})
Step:   12500, Reward: [-407.293 -407.293 -407.293] [66.069], Avg: [-471.865 -471.865 -471.865] (0.0010) <00:03:17> ({r_i: None, r_t: [-4179.744 -4179.744 -4179.744], critic_loss: 814.68798828125, actor_loss: 0.593999981880188, entropy: 0.9359999895095825, eps: 0.001})
Step:   13000, Reward: [-404.184 -404.184 -404.184] [40.789], Avg: [-469.358 -469.358 -469.358] (0.0010) <00:03:26> ({r_i: None, r_t: [-4322.115 -4322.115 -4322.115], critic_loss: 731.427001953125, actor_loss: 0.34200000762939453, entropy: 0.9100000262260437, eps: 0.001})
Step:   13500, Reward: [-431.141 -431.141 -431.141] [70.315], Avg: [-467.993 -467.993 -467.993] (0.0010) <00:03:33> ({r_i: None, r_t: [-4260.052 -4260.052 -4260.052], critic_loss: 578.8909912109375, actor_loss: 0.2329999953508377, entropy: 0.8820000290870667, eps: 0.001})
Step:   14000, Reward: [-440.273 -440.273 -440.273] [52.853], Avg: [-467.037 -467.037 -467.037] (0.0010) <00:03:41> ({r_i: None, r_t: [-4201.583 -4201.583 -4201.583], critic_loss: 718.6209716796875, actor_loss: 0.0430000014603138, entropy: 0.9110000133514404, eps: 0.001})
Step:   14500, Reward: [-444.021 -444.021 -444.021] [56.093], Avg: [-466.270 -466.270 -466.270] (0.0010) <00:03:49> ({r_i: None, r_t: [-4182.657 -4182.657 -4182.657], critic_loss: 674.2349853515625, actor_loss: 1.0399999618530273, entropy: 0.925000011920929, eps: 0.001})
Step:   15000, Reward: [-394.946 -394.946 -394.946] [44.285], Avg: [-463.969 -463.969 -463.969] (0.0010) <00:03:57> ({r_i: None, r_t: [-4174.070 -4174.070 -4174.070], critic_loss: 607.010009765625, actor_loss: -0.41600000858306885, entropy: 0.8799999952316284, eps: 0.001})
Step:   15500, Reward: [-408.128 -408.128 -408.128] [52.115], Avg: [-462.224 -462.224 -462.224] (0.0010) <00:04:05> ({r_i: None, r_t: [-4181.110 -4181.110 -4181.110], critic_loss: 514.5650024414062, actor_loss: 0.12200000137090683, entropy: 0.8090000152587891, eps: 0.001})
Step:   16000, Reward: [-394.817 -394.817 -394.817] [68.412], Avg: [-460.181 -460.181 -460.181] (0.0010) <00:04:13> ({r_i: None, r_t: [-4264.368 -4264.368 -4264.368], critic_loss: 472.0979919433594, actor_loss: -0.31299999356269836, entropy: 0.8119999766349792, eps: 0.001})
Step:   16500, Reward: [-425.471 -425.471 -425.471] [66.312], Avg: [-459.161 -459.161 -459.161] (0.0010) <00:04:20> ({r_i: None, r_t: [-4196.347 -4196.347 -4196.347], critic_loss: 497.40399169921875, actor_loss: -0.35199999809265137, entropy: 0.7699999809265137, eps: 0.001})
Step:   17000, Reward: [-412.039 -412.039 -412.039] [66.476], Avg: [-457.814 -457.814 -457.814] (0.0010) <00:04:29> ({r_i: None, r_t: [-4097.889 -4097.889 -4097.889], critic_loss: 436.35101318359375, actor_loss: 0.3100000023841858, entropy: 0.7440000176429749, eps: 0.001})
Step:   17500, Reward: [-423.699 -423.699 -423.699] [76.934], Avg: [-456.867 -456.867 -456.867] (0.0010) <00:04:36> ({r_i: None, r_t: [-4291.386 -4291.386 -4291.386], critic_loss: 478.34600830078125, actor_loss: 0.039000000804662704, entropy: 0.7490000128746033, eps: 0.001})
Step:   18000, Reward: [-438.133 -438.133 -438.133] [75.841], Avg: [-456.360 -456.360 -456.360] (0.0010) <00:04:44> ({r_i: None, r_t: [-4130.725 -4130.725 -4130.725], critic_loss: 515.8880004882812, actor_loss: -0.12999999523162842, entropy: 0.7580000162124634, eps: 0.001})
Step:   18500, Reward: [-427.535 -427.535 -427.535] [83.104], Avg: [-455.602 -455.602 -455.602] (0.0010) <00:04:52> ({r_i: None, r_t: [-4096.183 -4096.183 -4096.183], critic_loss: 484.5639953613281, actor_loss: 0.722000002861023, entropy: 0.7609999775886536, eps: 0.001})
Step:   19000, Reward: [-409.433 -409.433 -409.433] [74.075], Avg: [-454.418 -454.418 -454.418] (0.0010) <00:05:00> ({r_i: None, r_t: [-4079.280 -4079.280 -4079.280], critic_loss: 451.15399169921875, actor_loss: -0.09700000286102295, entropy: 0.746999979019165, eps: 0.001})
Step:   19500, Reward: [-404.653 -404.653 -404.653] [57.519], Avg: [-453.174 -453.174 -453.174] (0.0010) <00:05:08> ({r_i: None, r_t: [-4080.082 -4080.082 -4080.082], critic_loss: 409.4620056152344, actor_loss: -0.22599999606609344, entropy: 0.75, eps: 0.001})
Step:   20000, Reward: [-406.483 -406.483 -406.483] [60.960], Avg: [-452.035 -452.035 -452.035] (0.0010) <00:05:16> ({r_i: None, r_t: [-4085.530 -4085.530 -4085.530], critic_loss: 465.1809997558594, actor_loss: 0.328000009059906, entropy: 0.7699999809265137, eps: 0.001})
Step:   20500, Reward: [-398.762 -398.762 -398.762] [65.265], Avg: [-450.767 -450.767 -450.767] (0.0010) <00:05:23> ({r_i: None, r_t: [-4023.253 -4023.253 -4023.253], critic_loss: 364.8450012207031, actor_loss: -0.2840000092983246, entropy: 0.7649999856948853, eps: 0.001})
Step:   21000, Reward: [-416.999 -416.999 -416.999] [65.843], Avg: [-449.981 -449.981 -449.981] (0.0010) <00:05:32> ({r_i: None, r_t: [-4036.557 -4036.557 -4036.557], critic_loss: 461.52801513671875, actor_loss: -0.0010000000474974513, entropy: 0.7630000114440918, eps: 0.001})
Step:   21500, Reward: [-409.711 -409.711 -409.711] [69.093], Avg: [-449.066 -449.066 -449.066] (0.0010) <00:05:39> ({r_i: None, r_t: [-3972.411 -3972.411 -3972.411], critic_loss: 462.7019958496094, actor_loss: 0.5490000247955322, entropy: 0.7120000123977661, eps: 0.001})
Step:   22000, Reward: [-394.532 -394.532 -394.532] [52.804], Avg: [-447.854 -447.854 -447.854] (0.0010) <00:05:48> ({r_i: None, r_t: [-4100.856 -4100.856 -4100.856], critic_loss: 393.03900146484375, actor_loss: -0.20600000023841858, entropy: 0.7110000252723694, eps: 0.001})
Step:   22500, Reward: [-404.755 -404.755 -404.755] [56.634], Avg: [-446.917 -446.917 -446.917] (0.0010) <00:05:55> ({r_i: None, r_t: [-4018.177 -4018.177 -4018.177], critic_loss: 397.8190002441406, actor_loss: 0.3070000112056732, entropy: 0.6840000152587891, eps: 0.001})
Step:   23000, Reward: [-392.619 -392.619 -392.619] [63.924], Avg: [-445.762 -445.762 -445.762] (0.0010) <00:06:04> ({r_i: None, r_t: [-3917.473 -3917.473 -3917.473], critic_loss: 418.05499267578125, actor_loss: 0.20900000631809235, entropy: 0.6959999799728394, eps: 0.001})
Step:   23500, Reward: [-398.525 -398.525 -398.525] [60.824], Avg: [-444.778 -444.778 -444.778] (0.0010) <00:06:11> ({r_i: None, r_t: [-4029.636 -4029.636 -4029.636], critic_loss: 533.0770263671875, actor_loss: -0.16300000250339508, entropy: 0.6790000200271606, eps: 0.001})
Step:   24000, Reward: [-442.269 -442.269 -442.269] [69.481], Avg: [-444.727 -444.727 -444.727] (0.0010) <00:06:19> ({r_i: None, r_t: [-3946.163 -3946.163 -3946.163], critic_loss: 383.1510009765625, actor_loss: 0.07800000160932541, entropy: 0.656000018119812, eps: 0.001})
Step:   24500, Reward: [-394.148 -394.148 -394.148] [64.735], Avg: [-443.715 -443.715 -443.715] (0.0010) <00:06:27> ({r_i: None, r_t: [-4060.851 -4060.851 -4060.851], critic_loss: 464.5790100097656, actor_loss: 0.0010000000474974513, entropy: 0.6600000262260437, eps: 0.001})
Step:   25000, Reward: [-405.258 -405.258 -405.258] [62.178], Avg: [-442.961 -442.961 -442.961] (0.0010) <00:06:35> ({r_i: None, r_t: [-4010.037 -4010.037 -4010.037], critic_loss: 345.2690124511719, actor_loss: 0.07400000095367432, entropy: 0.6539999842643738, eps: 0.001})
Step:   25500, Reward: [-381.075 -381.075 -381.075] [68.578], Avg: [-441.771 -441.771 -441.771] (0.0010) <00:06:43> ({r_i: None, r_t: [-3861.279 -3861.279 -3861.279], critic_loss: 379.4909973144531, actor_loss: 0.11500000208616257, entropy: 0.6420000195503235, eps: 0.001})
Step:   26000, Reward: [-408.817 -408.817 -408.817] [57.020], Avg: [-441.149 -441.149 -441.149] (0.0010) <00:06:51> ({r_i: None, r_t: [-3954.460 -3954.460 -3954.460], critic_loss: 398.2279968261719, actor_loss: -0.42800000309944153, entropy: 0.6520000100135803, eps: 0.001})
Step:   26500, Reward: [-400.985 -400.985 -400.985] [71.566], Avg: [-440.405 -440.405 -440.405] (0.0010) <00:06:58> ({r_i: None, r_t: [-4007.550 -4007.550 -4007.550], critic_loss: 358.4309997558594, actor_loss: -0.12399999797344208, entropy: 0.671999990940094, eps: 0.001})
Step:   27000, Reward: [-374.821 -374.821 -374.821] [65.901], Avg: [-439.213 -439.213 -439.213] (0.0010) <00:07:06> ({r_i: None, r_t: [-3995.140 -3995.140 -3995.140], critic_loss: 343.48199462890625, actor_loss: 0.050999999046325684, entropy: 0.652999997138977, eps: 0.001})
Step:   27500, Reward: [-408.558 -408.558 -408.558] [64.028], Avg: [-438.666 -438.666 -438.666] (0.0010) <00:07:14> ({r_i: None, r_t: [-3980.511 -3980.511 -3980.511], critic_loss: 384.51800537109375, actor_loss: -0.12099999934434891, entropy: 0.6430000066757202, eps: 0.001})
Step:   28000, Reward: [-382.791 -382.791 -382.791] [65.690], Avg: [-437.685 -437.685 -437.685] (0.0010) <00:07:22> ({r_i: None, r_t: [-4015.828 -4015.828 -4015.828], critic_loss: 353.5660095214844, actor_loss: 0.23800000548362732, entropy: 0.6620000004768372, eps: 0.001})
Step:   28500, Reward: [-395.264 -395.264 -395.264] [53.208], Avg: [-436.954 -436.954 -436.954] (0.0010) <00:07:30> ({r_i: None, r_t: [-3947.487 -3947.487 -3947.487], critic_loss: 335.0679931640625, actor_loss: -0.8349999785423279, entropy: 0.656000018119812, eps: 0.001})
Step:   29000, Reward: [-357.472 -357.472 -357.472] [64.010], Avg: [-435.607 -435.607 -435.607] (0.0010) <00:07:38> ({r_i: None, r_t: [-3950.027 -3950.027 -3950.027], critic_loss: 373.3710021972656, actor_loss: 0.5189999938011169, entropy: 0.6309999823570251, eps: 0.001})
Step:   29500, Reward: [-401.029 -401.029 -401.029] [88.881], Avg: [-435.030 -435.030 -435.030] (0.0010) <00:07:46> ({r_i: None, r_t: [-3826.770 -3826.770 -3826.770], critic_loss: 283.95599365234375, actor_loss: 0.5600000023841858, entropy: 0.6430000066757202, eps: 0.001})
Step:   30000, Reward: [-390.660 -390.660 -390.660] [70.386], Avg: [-434.303 -434.303 -434.303] (0.0010) <00:07:54> ({r_i: None, r_t: [-3822.207 -3822.207 -3822.207], critic_loss: 290.3420104980469, actor_loss: 0.38499999046325684, entropy: 0.6209999918937683, eps: 0.001})
Step:   30500, Reward: [-381.411 -381.411 -381.411] [70.624], Avg: [-433.450 -433.450 -433.450] (0.0010) <00:08:01> ({r_i: None, r_t: [-3861.624 -3861.624 -3861.624], critic_loss: 297.5429992675781, actor_loss: 0.4300000071525574, entropy: 0.609000027179718, eps: 0.001})
Step:   31000, Reward: [-383.234 -383.234 -383.234] [59.559], Avg: [-432.653 -432.653 -432.653] (0.0010) <00:08:10> ({r_i: None, r_t: [-3752.728 -3752.728 -3752.728], critic_loss: 336.4119873046875, actor_loss: 0.1550000011920929, entropy: 0.625, eps: 0.001})
Step:   31500, Reward: [-374.530 -374.530 -374.530] [49.602], Avg: [-431.745 -431.745 -431.745] (0.0010) <00:08:17> ({r_i: None, r_t: [-3766.493 -3766.493 -3766.493], critic_loss: 392.5870056152344, actor_loss: 0.8029999732971191, entropy: 0.5910000205039978, eps: 0.001})
Step:   32000, Reward: [-370.590 -370.590 -370.590] [52.809], Avg: [-430.804 -430.804 -430.804] (0.0010) <00:08:25> ({r_i: None, r_t: [-3750.367 -3750.367 -3750.367], critic_loss: 294.7640075683594, actor_loss: 0.08900000154972076, entropy: 0.5849999785423279, eps: 0.001})
Step:   32500, Reward: [-367.918 -367.918 -367.918] [53.421], Avg: [-429.851 -429.851 -429.851] (0.0010) <00:08:33> ({r_i: None, r_t: [-3821.564 -3821.564 -3821.564], critic_loss: 331.72601318359375, actor_loss: 0.1120000034570694, entropy: 0.574999988079071, eps: 0.001})
Step:   33000, Reward: [-390.642 -390.642 -390.642] [54.671], Avg: [-429.266 -429.266 -429.266] (0.0010) <00:08:41> ({r_i: None, r_t: [-3806.477 -3806.477 -3806.477], critic_loss: 322.0329895019531, actor_loss: 0.15800000727176666, entropy: 0.5490000247955322, eps: 0.001})
Step:   33500, Reward: [-365.374 -365.374 -365.374] [51.286], Avg: [-428.326 -428.326 -428.326] (0.0010) <00:08:49> ({r_i: None, r_t: [-3720.199 -3720.199 -3720.199], critic_loss: 348.06500244140625, actor_loss: -0.010999999940395355, entropy: 0.5329999923706055, eps: 0.001})
Step:   34000, Reward: [-380.933 -380.933 -380.933] [64.792], Avg: [-427.639 -427.639 -427.639] (0.0010) <00:08:57> ({r_i: None, r_t: [-3728.436 -3728.436 -3728.436], critic_loss: 322.9119873046875, actor_loss: 0.004000000189989805, entropy: 0.531000018119812, eps: 0.001})
Step:   34500, Reward: [-373.502 -373.502 -373.502] [75.891], Avg: [-426.866 -426.866 -426.866] (0.0010) <00:09:04> ({r_i: None, r_t: [-3669.251 -3669.251 -3669.251], critic_loss: 249.61300659179688, actor_loss: -0.21899999678134918, entropy: 0.5299999713897705, eps: 0.001})
Step:   35000, Reward: [-361.687 -361.687 -361.687] [47.796], Avg: [-425.948 -425.948 -425.948] (0.0010) <00:09:13> ({r_i: None, r_t: [-3625.505 -3625.505 -3625.505], critic_loss: 283.5870056152344, actor_loss: 0.12800000607967377, entropy: 0.5009999871253967, eps: 0.001})
Step:   35500, Reward: [-374.797 -374.797 -374.797] [64.817], Avg: [-425.238 -425.238 -425.238] (0.0010) <00:09:20> ({r_i: None, r_t: [-3624.621 -3624.621 -3624.621], critic_loss: 301.8919982910156, actor_loss: -0.7329999804496765, entropy: 0.5109999775886536, eps: 0.001})
Step:   36000, Reward: [-375.511 -375.511 -375.511] [64.523], Avg: [-424.556 -424.556 -424.556] (0.0010) <00:09:28> ({r_i: None, r_t: [-3566.282 -3566.282 -3566.282], critic_loss: 261.63299560546875, actor_loss: 0.6340000033378601, entropy: 0.5210000276565552, eps: 0.001})
Step:   36500, Reward: [-377.930 -377.930 -377.930] [61.860], Avg: [-423.926 -423.926 -423.926] (0.0010) <00:09:36> ({r_i: None, r_t: [-3592.540 -3592.540 -3592.540], critic_loss: 234.13699340820312, actor_loss: -1.059999942779541, entropy: 0.5630000233650208, eps: 0.001})
Step:   37000, Reward: [-358.066 -358.066 -358.066] [62.022], Avg: [-423.048 -423.048 -423.048] (0.0010) <00:09:44> ({r_i: None, r_t: [-3662.416 -3662.416 -3662.416], critic_loss: 212.10000610351562, actor_loss: 0.5540000200271606, entropy: 0.5609999895095825, eps: 0.001})
Step:   37500, Reward: [-352.027 -352.027 -352.027] [55.503], Avg: [-422.114 -422.114 -422.114] (0.0010) <00:09:52> ({r_i: None, r_t: [-3563.719 -3563.719 -3563.719], critic_loss: 305.364990234375, actor_loss: -0.8199999928474426, entropy: 0.5649999976158142, eps: 0.001})
Step:   38000, Reward: [-334.241 -334.241 -334.241] [54.165], Avg: [-420.972 -420.972 -420.972] (0.0010) <00:10:00> ({r_i: None, r_t: [-3441.648 -3441.648 -3441.648], critic_loss: 248.38499450683594, actor_loss: 0.10499999672174454, entropy: 0.5730000138282776, eps: 0.001})
Step:   38500, Reward: [-342.851 -342.851 -342.851] [47.174], Avg: [-419.971 -419.971 -419.971] (0.0010) <00:10:07> ({r_i: None, r_t: [-3362.601 -3362.601 -3362.601], critic_loss: 230.9080047607422, actor_loss: -0.008999999612569809, entropy: 0.5929999947547913, eps: 0.001})
Step:   39000, Reward: [-348.502 -348.502 -348.502] [61.923], Avg: [-419.066 -419.066 -419.066] (0.0010) <00:10:15> ({r_i: None, r_t: [-3441.818 -3441.818 -3441.818], critic_loss: 277.74700927734375, actor_loss: 0.3019999861717224, entropy: 0.6050000190734863, eps: 0.001})
Step:   39500, Reward: [-352.082 -352.082 -352.082] [45.119], Avg: [-418.229 -418.229 -418.229] (0.0010) <00:10:23> ({r_i: None, r_t: [-3551.797 -3551.797 -3551.797], critic_loss: 306.89599609375, actor_loss: 0.7300000190734863, entropy: 0.574999988079071, eps: 0.001})
Step:   40000, Reward: [-359.070 -359.070 -359.070] [62.026], Avg: [-417.499 -417.499 -417.499] (0.0010) <00:10:31> ({r_i: None, r_t: [-3424.720 -3424.720 -3424.720], critic_loss: 256.7019958496094, actor_loss: -0.6420000195503235, entropy: 0.6010000109672546, eps: 0.001})
Step:   40500, Reward: [-334.481 -334.481 -334.481] [35.372], Avg: [-416.486 -416.486 -416.486] (0.0010) <00:10:39> ({r_i: None, r_t: [-3495.458 -3495.458 -3495.458], critic_loss: 380.5899963378906, actor_loss: 0.10400000214576721, entropy: 0.6269999742507935, eps: 0.001})
Step:   41000, Reward: [-354.446 -354.446 -354.446] [41.218], Avg: [-415.739 -415.739 -415.739] (0.0010) <00:10:47> ({r_i: None, r_t: [-3515.785 -3515.785 -3515.785], critic_loss: 241.0260009765625, actor_loss: 0.004999999888241291, entropy: 0.5830000042915344, eps: 0.001})
Step:   41500, Reward: [-331.842 -331.842 -331.842] [60.554], Avg: [-414.740 -414.740 -414.740] (0.0010) <00:10:54> ({r_i: None, r_t: [-3493.608 -3493.608 -3493.608], critic_loss: 250.91600036621094, actor_loss: 0.3330000042915344, entropy: 0.5630000233650208, eps: 0.001})
Step:   42000, Reward: [-345.940 -345.940 -345.940] [43.052], Avg: [-413.931 -413.931 -413.931] (0.0010) <00:11:03> ({r_i: None, r_t: [-3387.910 -3387.910 -3387.910], critic_loss: 304.8710021972656, actor_loss: 0.6710000038146973, entropy: 0.5849999785423279, eps: 0.001})
Step:   42500, Reward: [-340.226 -340.226 -340.226] [73.730], Avg: [-413.073 -413.073 -413.073] (0.0010) <00:11:10> ({r_i: None, r_t: [-3404.289 -3404.289 -3404.289], critic_loss: 251.78199768066406, actor_loss: -0.871999979019165, entropy: 0.5630000233650208, eps: 0.001})
Step:   43000, Reward: [-331.685 -331.685 -331.685] [60.395], Avg: [-412.138 -412.138 -412.138] (0.0010) <00:11:19> ({r_i: None, r_t: [-3417.398 -3417.398 -3417.398], critic_loss: 183.4320068359375, actor_loss: 0.07400000095367432, entropy: 0.5239999890327454, eps: 0.001})
Step:   43500, Reward: [-316.763 -316.763 -316.763] [53.800], Avg: [-411.054 -411.054 -411.054] (0.0010) <00:11:26> ({r_i: None, r_t: [-3462.143 -3462.143 -3462.143], critic_loss: 222.4510040283203, actor_loss: 0.3140000104904175, entropy: 0.5410000085830688, eps: 0.001})
Step:   44000, Reward: [-324.925 -324.925 -324.925] [56.240], Avg: [-410.086 -410.086 -410.086] (0.0010) <00:11:34> ({r_i: None, r_t: [-3459.129 -3459.129 -3459.129], critic_loss: 188.5959930419922, actor_loss: 0.11400000005960464, entropy: 0.5490000247955322, eps: 0.001})
Step:   44500, Reward: [-344.288 -344.288 -344.288] [48.504], Avg: [-409.355 -409.355 -409.355] (0.0010) <00:11:42> ({r_i: None, r_t: [-3429.594 -3429.594 -3429.594], critic_loss: 197.99899291992188, actor_loss: -0.24199999868869781, entropy: 0.5870000123977661, eps: 0.001})
Step:   45000, Reward: [-344.046 -344.046 -344.046] [62.449], Avg: [-408.638 -408.638 -408.638] (0.0010) <00:11:50> ({r_i: None, r_t: [-3463.190 -3463.190 -3463.190], critic_loss: 218.0449981689453, actor_loss: 0.18299999833106995, entropy: 0.5490000247955322, eps: 0.001})
Step:   45500, Reward: [-319.966 -319.966 -319.966] [48.599], Avg: [-407.674 -407.674 -407.674] (0.0010) <00:11:58> ({r_i: None, r_t: [-3420.656 -3420.656 -3420.656], critic_loss: 211.94500732421875, actor_loss: -0.546999990940094, entropy: 0.5460000038146973, eps: 0.001})
Step:   46000, Reward: [-346.443 -346.443 -346.443] [59.175], Avg: [-407.015 -407.015 -407.015] (0.0010) <00:12:06> ({r_i: None, r_t: [-3375.800 -3375.800 -3375.800], critic_loss: 171.3979949951172, actor_loss: 0.24300000071525574, entropy: 0.5529999732971191, eps: 0.001})
Step:   46500, Reward: [-361.808 -361.808 -361.808] [56.180], Avg: [-406.535 -406.535 -406.535] (0.0010) <00:12:14> ({r_i: None, r_t: [-3373.326 -3373.326 -3373.326], critic_loss: 192.35000610351562, actor_loss: 0.5839999914169312, entropy: 0.5809999704360962, eps: 0.001})
Step:   47000, Reward: [-327.835 -327.835 -327.835] [56.990], Avg: [-405.706 -405.706 -405.706] (0.0010) <00:12:22> ({r_i: None, r_t: [-3401.216 -3401.216 -3401.216], critic_loss: 253.13900756835938, actor_loss: -0.050999999046325684, entropy: 0.5870000123977661, eps: 0.001})
Step:   47500, Reward: [-341.035 -341.035 -341.035] [56.538], Avg: [-405.032 -405.032 -405.032] (0.0010) <00:12:30> ({r_i: None, r_t: [-3434.203 -3434.203 -3434.203], critic_loss: 209.85699462890625, actor_loss: -0.07100000232458115, entropy: 0.597000002861023, eps: 0.001})
Step:   48000, Reward: [-365.651 -365.651 -365.651] [60.272], Avg: [-404.626 -404.626 -404.626] (0.0010) <00:12:38> ({r_i: None, r_t: [-3442.826 -3442.826 -3442.826], critic_loss: 217.76100158691406, actor_loss: -0.004999999888241291, entropy: 0.5830000042915344, eps: 0.001})
Step:   48500, Reward: [-359.564 -359.564 -359.564] [53.719], Avg: [-404.167 -404.167 -404.167] (0.0010) <00:12:45> ({r_i: None, r_t: [-3289.471 -3289.471 -3289.471], critic_loss: 181.5709991455078, actor_loss: -0.49000000953674316, entropy: 0.5879999995231628, eps: 0.001})
Step:   49000, Reward: [-320.531 -320.531 -320.531] [47.191], Avg: [-403.322 -403.322 -403.322] (0.0010) <00:12:53> ({r_i: None, r_t: [-3322.343 -3322.343 -3322.343], critic_loss: 230.5449981689453, actor_loss: 0.08399999886751175, entropy: 0.6240000128746033, eps: 0.001})
Step:   49500, Reward: [-326.624 -326.624 -326.624] [73.679], Avg: [-402.555 -402.555 -402.555] (0.0010) <00:13:01> ({r_i: None, r_t: [-3343.673 -3343.673 -3343.673], critic_loss: 180.8990020751953, actor_loss: 0.6909999847412109, entropy: 0.5910000205039978, eps: 0.001})
Step:   50000, Reward: [-319.496 -319.496 -319.496] [65.439], Avg: [-401.732 -401.732 -401.732] (0.0010) <00:13:09> ({r_i: None, r_t: [-3447.115 -3447.115 -3447.115], critic_loss: 222.35400390625, actor_loss: -0.21899999678134918, entropy: 0.5960000157356262, eps: 0.001})
Step:   50500, Reward: [-331.245 -331.245 -331.245] [61.126], Avg: [-401.041 -401.041 -401.041] (0.0010) <00:13:17> ({r_i: None, r_t: [-3378.944 -3378.944 -3378.944], critic_loss: 161.2519989013672, actor_loss: 0.4309999942779541, entropy: 0.6200000047683716, eps: 0.001})
Step:   51000, Reward: [-328.773 -328.773 -328.773] [51.181], Avg: [-400.340 -400.340 -400.340] (0.0010) <00:13:25> ({r_i: None, r_t: [-3356.046 -3356.046 -3356.046], critic_loss: 177.83200073242188, actor_loss: -0.008999999612569809, entropy: 0.5950000286102295, eps: 0.001})
Step:   51500, Reward: [-332.405 -332.405 -332.405] [58.399], Avg: [-399.687 -399.687 -399.687] (0.0010) <00:13:33> ({r_i: None, r_t: [-3363.779 -3363.779 -3363.779], critic_loss: 179.7899932861328, actor_loss: -0.03200000151991844, entropy: 0.621999979019165, eps: 0.001})
Step:   52000, Reward: [-334.874 -334.874 -334.874] [61.594], Avg: [-399.069 -399.069 -399.069] (0.0010) <00:13:41> ({r_i: None, r_t: [-3275.073 -3275.073 -3275.073], critic_loss: 204.9720001220703, actor_loss: -0.27000001072883606, entropy: 0.6200000047683716, eps: 0.001})
Step:   52500, Reward: [-329.367 -329.367 -329.367] [69.422], Avg: [-398.412 -398.412 -398.412] (0.0010) <00:13:49> ({r_i: None, r_t: [-3315.464 -3315.464 -3315.464], critic_loss: 189.59300231933594, actor_loss: -0.5090000033378601, entropy: 0.6079999804496765, eps: 0.001})
Step:   53000, Reward: [-309.035 -309.035 -309.035] [62.626], Avg: [-397.576 -397.576 -397.576] (0.0010) <00:13:57> ({r_i: None, r_t: [-3333.388 -3333.388 -3333.388], critic_loss: 162.25599670410156, actor_loss: -0.08500000089406967, entropy: 0.621999979019165, eps: 0.001})
Step:   53500, Reward: [-342.214 -342.214 -342.214] [61.356], Avg: [-397.064 -397.064 -397.064] (0.0010) <00:14:05> ({r_i: None, r_t: [-3376.138 -3376.138 -3376.138], critic_loss: 255.89300537109375, actor_loss: -0.3199999928474426, entropy: 0.5680000185966492, eps: 0.001})
Step:   54000, Reward: [-325.787 -325.787 -325.787] [61.222], Avg: [-396.410 -396.410 -396.410] (0.0010) <00:14:12> ({r_i: None, r_t: [-3376.094 -3376.094 -3376.094], critic_loss: 185.48800659179688, actor_loss: 0.12200000137090683, entropy: 0.5519999861717224, eps: 0.001})
Step:   54500, Reward: [-311.447 -311.447 -311.447] [44.174], Avg: [-395.638 -395.638 -395.638] (0.0010) <00:14:20> ({r_i: None, r_t: [-3294.975 -3294.975 -3294.975], critic_loss: 186.26699829101562, actor_loss: -0.6940000057220459, entropy: 0.5799999833106995, eps: 0.001})
Step:   55000, Reward: [-328.662 -328.662 -328.662] [49.436], Avg: [-395.034 -395.034 -395.034] (0.0010) <00:14:28> ({r_i: None, r_t: [-3419.836 -3419.836 -3419.836], critic_loss: 282.7699890136719, actor_loss: 0.26600000262260437, entropy: 0.5600000023841858, eps: 0.001})
Step:   55500, Reward: [-312.763 -312.763 -312.763] [63.326], Avg: [-394.300 -394.300 -394.300] (0.0010) <00:14:36> ({r_i: None, r_t: [-3306.349 -3306.349 -3306.349], critic_loss: 221.9530029296875, actor_loss: -0.37599998712539673, entropy: 0.5789999961853027, eps: 0.001})
Step:   56000, Reward: [-333.844 -333.844 -333.844] [61.435], Avg: [-393.765 -393.765 -393.765] (0.0010) <00:14:44> ({r_i: None, r_t: [-3359.116 -3359.116 -3359.116], critic_loss: 276.5320129394531, actor_loss: 0.5260000228881836, entropy: 0.5929999947547913, eps: 0.001})
Step:   56500, Reward: [-355.888 -355.888 -355.888] [64.619], Avg: [-393.432 -393.432 -393.432] (0.0010) <00:14:52> ({r_i: None, r_t: [-3335.317 -3335.317 -3335.317], critic_loss: 234.55999755859375, actor_loss: 0.29899999499320984, entropy: 0.5879999995231628, eps: 0.001})
Step:   57000, Reward: [-341.659 -341.659 -341.659] [55.072], Avg: [-392.982 -392.982 -392.982] (0.0010) <00:15:00> ({r_i: None, r_t: [-3316.208 -3316.208 -3316.208], critic_loss: 177.4080047607422, actor_loss: -0.09200000017881393, entropy: 0.5389999747276306, eps: 0.001})
Step:   57500, Reward: [-341.091 -341.091 -341.091] [59.187], Avg: [-392.535 -392.535 -392.535] (0.0010) <00:15:08> ({r_i: None, r_t: [-3313.737 -3313.737 -3313.737], critic_loss: 197.26199340820312, actor_loss: 0.12700000405311584, entropy: 0.5659999847412109, eps: 0.001})
Step:   58000, Reward: [-329.719 -329.719 -329.719] [51.297], Avg: [-391.998 -391.998 -391.998] (0.0010) <00:15:16> ({r_i: None, r_t: [-3316.605 -3316.605 -3316.605], critic_loss: 236.8560028076172, actor_loss: -0.8489999771118164, entropy: 0.550000011920929, eps: 0.001})
Step:   58500, Reward: [-320.806 -320.806 -320.806] [56.346], Avg: [-391.395 -391.395 -391.395] (0.0010) <00:15:23> ({r_i: None, r_t: [-3299.524 -3299.524 -3299.524], critic_loss: 188.9029998779297, actor_loss: 0.7179999947547913, entropy: 0.5640000104904175, eps: 0.001})
Step:   59000, Reward: [-332.352 -332.352 -332.352] [70.727], Avg: [-390.898 -390.898 -390.898] (0.0010) <00:15:31> ({r_i: None, r_t: [-3345.904 -3345.904 -3345.904], critic_loss: 162.7469940185547, actor_loss: 0.2529999911785126, entropy: 0.5429999828338623, eps: 0.001})
Step:   59500, Reward: [-332.267 -332.267 -332.267] [58.457], Avg: [-390.410 -390.410 -390.410] (0.0010) <00:15:39> ({r_i: None, r_t: [-3357.043 -3357.043 -3357.043], critic_loss: 194.60400390625, actor_loss: -0.041999999433755875, entropy: 0.5450000166893005, eps: 0.001})
Step:   60000, Reward: [-336.601 -336.601 -336.601] [68.246], Avg: [-389.965 -389.965 -389.965] (0.0010) <00:15:47> ({r_i: None, r_t: [-3294.080 -3294.080 -3294.080], critic_loss: 158.27499389648438, actor_loss: -0.24699999392032623, entropy: 0.5360000133514404, eps: 0.001})
Step:   60500, Reward: [-308.671 -308.671 -308.671] [40.101], Avg: [-389.299 -389.299 -389.299] (0.0010) <00:15:55> ({r_i: None, r_t: [-3279.902 -3279.902 -3279.902], critic_loss: 140.78399658203125, actor_loss: 0.09200000017881393, entropy: 0.5170000195503235, eps: 0.001})
Step:   61000, Reward: [-357.037 -357.037 -357.037] [45.201], Avg: [-389.036 -389.036 -389.036] (0.0010) <00:16:03> ({r_i: None, r_t: [-3225.347 -3225.347 -3225.347], critic_loss: 143.98899841308594, actor_loss: 0.06700000166893005, entropy: 0.5210000276565552, eps: 0.001})
Step:   61500, Reward: [-337.833 -337.833 -337.833] [36.596], Avg: [-388.624 -388.624 -388.624] (0.0010) <00:16:10> ({r_i: None, r_t: [-3298.164 -3298.164 -3298.164], critic_loss: 217.6269989013672, actor_loss: -0.32199999690055847, entropy: 0.49799999594688416, eps: 0.001})
Step:   62000, Reward: [-313.965 -313.965 -313.965] [60.935], Avg: [-388.026 -388.026 -388.026] (0.0010) <00:16:19> ({r_i: None, r_t: [-3371.072 -3371.072 -3371.072], critic_loss: 152.46400451660156, actor_loss: -0.3540000021457672, entropy: 0.5199999809265137, eps: 0.001})
Step:   62500, Reward: [-311.385 -311.385 -311.385] [41.207], Avg: [-387.418 -387.418 -387.418] (0.0010) <00:16:26> ({r_i: None, r_t: [-3279.823 -3279.823 -3279.823], critic_loss: 139.34100341796875, actor_loss: -0.3580000102519989, entropy: 0.5049999952316284, eps: 0.001})
Step:   63000, Reward: [-333.998 -333.998 -333.998] [73.342], Avg: [-386.997 -386.997 -386.997] (0.0010) <00:16:34> ({r_i: None, r_t: [-3378.277 -3378.277 -3378.277], critic_loss: 162.0290069580078, actor_loss: 0.22300000488758087, entropy: 0.515999972820282, eps: 0.001})
Step:   63500, Reward: [-293.430 -293.430 -293.430] [42.364], Avg: [-386.266 -386.266 -386.266] (0.0010) <00:16:42> ({r_i: None, r_t: [-3211.582 -3211.582 -3211.582], critic_loss: 138.2949981689453, actor_loss: 0.1770000010728836, entropy: 0.5460000038146973, eps: 0.001})
Step:   64000, Reward: [-304.862 -304.862 -304.862] [42.625], Avg: [-385.635 -385.635 -385.635] (0.0010) <00:16:50> ({r_i: None, r_t: [-3290.738 -3290.738 -3290.738], critic_loss: 185.85899353027344, actor_loss: 0.16200000047683716, entropy: 0.5419999957084656, eps: 0.001})
Step:   64500, Reward: [-322.712 -322.712 -322.712] [40.423], Avg: [-385.151 -385.151 -385.151] (0.0010) <00:16:58> ({r_i: None, r_t: [-3326.282 -3326.282 -3326.282], critic_loss: 190.10800170898438, actor_loss: 0.5600000023841858, entropy: 0.5149999856948853, eps: 0.001})
Step:   65000, Reward: [-324.183 -324.183 -324.183] [57.813], Avg: [-384.686 -384.686 -384.686] (0.0010) <00:17:06> ({r_i: None, r_t: [-3345.864 -3345.864 -3345.864], critic_loss: 154.76499938964844, actor_loss: 0.3720000088214874, entropy: 0.5239999890327454, eps: 0.001})
Step:   65500, Reward: [-328.994 -328.994 -328.994] [42.453], Avg: [-384.264 -384.264 -384.264] (0.0010) <00:17:13> ({r_i: None, r_t: [-3250.700 -3250.700 -3250.700], critic_loss: 134.94500732421875, actor_loss: 0.13899999856948853, entropy: 0.5109999775886536, eps: 0.001})
Step:   66000, Reward: [-324.344 -324.344 -324.344] [33.000], Avg: [-383.814 -383.814 -383.814] (0.0010) <00:17:21> ({r_i: None, r_t: [-3254.459 -3254.459 -3254.459], critic_loss: 143.8719940185547, actor_loss: 0.3269999921321869, entropy: 0.5230000019073486, eps: 0.001})
Step:   66500, Reward: [-313.152 -313.152 -313.152] [57.638], Avg: [-383.286 -383.286 -383.286] (0.0010) <00:17:29> ({r_i: None, r_t: [-3194.101 -3194.101 -3194.101], critic_loss: 162.25799560546875, actor_loss: 0.3930000066757202, entropy: 0.5120000243186951, eps: 0.001})
Step:   67000, Reward: [-325.340 -325.340 -325.340] [41.521], Avg: [-382.857 -382.857 -382.857] (0.0010) <00:17:37> ({r_i: None, r_t: [-3322.493 -3322.493 -3322.493], critic_loss: 176.63800048828125, actor_loss: -0.2329999953508377, entropy: 0.5139999985694885, eps: 0.001})
Step:   67500, Reward: [-330.042 -330.042 -330.042] [59.751], Avg: [-382.469 -382.469 -382.469] (0.0010) <00:17:45> ({r_i: None, r_t: [-3373.015 -3373.015 -3373.015], critic_loss: 196.98699951171875, actor_loss: -0.13099999725818634, entropy: 0.4880000054836273, eps: 0.001})
Step:   68000, Reward: [-350.448 -350.448 -350.448] [54.025], Avg: [-382.235 -382.235 -382.235] (0.0010) <00:17:53> ({r_i: None, r_t: [-3242.939 -3242.939 -3242.939], critic_loss: 174.06199645996094, actor_loss: 0.03500000014901161, entropy: 0.4970000088214874, eps: 0.001})
Step:   68500, Reward: [-339.303 -339.303 -339.303] [50.248], Avg: [-381.924 -381.924 -381.924] (0.0010) <00:18:01> ({r_i: None, r_t: [-3311.604 -3311.604 -3311.604], critic_loss: 155.04100036621094, actor_loss: -0.25600001215934753, entropy: 0.4909999966621399, eps: 0.001})
Step:   69000, Reward: [-327.393 -327.393 -327.393] [55.525], Avg: [-381.531 -381.531 -381.531] (0.0010) <00:18:09> ({r_i: None, r_t: [-3293.074 -3293.074 -3293.074], critic_loss: 190.88299560546875, actor_loss: 0.09099999815225601, entropy: 0.49399998784065247, eps: 0.001})
Step:   69500, Reward: [-318.429 -318.429 -318.429] [44.305], Avg: [-381.081 -381.081 -381.081] (0.0010) <00:18:16> ({r_i: None, r_t: [-3316.878 -3316.878 -3316.878], critic_loss: 139.79800415039062, actor_loss: -0.6430000066757202, entropy: 0.48399999737739563, eps: 0.001})
Step:   70000, Reward: [-314.993 -314.993 -314.993] [61.957], Avg: [-380.612 -380.612 -380.612] (0.0010) <00:18:24> ({r_i: None, r_t: [-3226.538 -3226.538 -3226.538], critic_loss: 140.94400024414062, actor_loss: 0.28700000047683716, entropy: 0.4790000021457672, eps: 0.001})
Step:   70500, Reward: [-328.221 -328.221 -328.221] [75.790], Avg: [-380.243 -380.243 -380.243] (0.0010) <00:18:32> ({r_i: None, r_t: [-3322.170 -3322.170 -3322.170], critic_loss: 168.78799438476562, actor_loss: -0.1599999964237213, entropy: 0.4860000014305115, eps: 0.001})
Step:   71000, Reward: [-308.455 -308.455 -308.455] [55.847], Avg: [-379.741 -379.741 -379.741] (0.0010) <00:18:40> ({r_i: None, r_t: [-3285.661 -3285.661 -3285.661], critic_loss: 170.62399291992188, actor_loss: 0.4000000059604645, entropy: 0.46299999952316284, eps: 0.001})
Step:   71500, Reward: [-315.642 -315.642 -315.642] [66.064], Avg: [-379.296 -379.296 -379.296] (0.0010) <00:18:48> ({r_i: None, r_t: [-3250.009 -3250.009 -3250.009], critic_loss: 144.37100219726562, actor_loss: -0.3070000112056732, entropy: 0.460999995470047, eps: 0.001})
Step:   72000, Reward: [-331.293 -331.293 -331.293] [73.448], Avg: [-378.965 -378.965 -378.965] (0.0010) <00:18:56> ({r_i: None, r_t: [-3272.957 -3272.957 -3272.957], critic_loss: 187.156005859375, actor_loss: -0.27799999713897705, entropy: 0.4860000014305115, eps: 0.001})
Step:   72500, Reward: [-325.391 -325.391 -325.391] [60.283], Avg: [-378.598 -378.598 -378.598] (0.0010) <00:19:03> ({r_i: None, r_t: [-3289.524 -3289.524 -3289.524], critic_loss: 142.98399353027344, actor_loss: 0.6520000100135803, entropy: 0.4749999940395355, eps: 0.001})
Step:   73000, Reward: [-305.663 -305.663 -305.663] [59.471], Avg: [-378.102 -378.102 -378.102] (0.0010) <00:19:11> ({r_i: None, r_t: [-3313.925 -3313.925 -3313.925], critic_loss: 130.1490020751953, actor_loss: 0.19200000166893005, entropy: 0.4580000042915344, eps: 0.001})
Step:   73500, Reward: [-336.324 -336.324 -336.324] [49.466], Avg: [-377.820 -377.820 -377.820] (0.0010) <00:19:19> ({r_i: None, r_t: [-3289.992 -3289.992 -3289.992], critic_loss: 131.28799438476562, actor_loss: -0.6570000052452087, entropy: 0.4909999966621399, eps: 0.001})
Step:   74000, Reward: [-315.356 -315.356 -315.356] [63.660], Avg: [-377.400 -377.400 -377.400] (0.0010) <00:19:27> ({r_i: None, r_t: [-3254.104 -3254.104 -3254.104], critic_loss: 110.90299987792969, actor_loss: 0.21799999475479126, entropy: 0.460999995470047, eps: 0.001})
Step:   74500, Reward: [-322.081 -322.081 -322.081] [50.038], Avg: [-377.031 -377.031 -377.031] (0.0010) <00:19:35> ({r_i: None, r_t: [-3367.260 -3367.260 -3367.260], critic_loss: 148.2689971923828, actor_loss: -0.164000004529953, entropy: 0.48500001430511475, eps: 0.001})
Step:   75000, Reward: [-348.760 -348.760 -348.760] [57.239], Avg: [-376.844 -376.844 -376.844] (0.0010) <00:19:43> ({r_i: None, r_t: [-3365.624 -3365.624 -3365.624], critic_loss: 162.343994140625, actor_loss: -0.06400000303983688, entropy: 0.4440000057220459, eps: 0.001})
Step:   75500, Reward: [-332.054 -332.054 -332.054] [58.350], Avg: [-376.550 -376.550 -376.550] (0.0010) <00:19:50> ({r_i: None, r_t: [-3262.717 -3262.717 -3262.717], critic_loss: 136.83999633789062, actor_loss: -0.43299999833106995, entropy: 0.41999998688697815, eps: 0.001})
Step:   76000, Reward: [-308.402 -308.402 -308.402] [59.728], Avg: [-376.104 -376.104 -376.104] (0.0010) <00:19:58> ({r_i: None, r_t: [-3273.189 -3273.189 -3273.189], critic_loss: 132.7469940185547, actor_loss: -0.07199999690055847, entropy: 0.42399999499320984, eps: 0.001})
Step:   76500, Reward: [-322.449 -322.449 -322.449] [67.697], Avg: [-375.756 -375.756 -375.756] (0.0010) <00:20:06> ({r_i: None, r_t: [-3290.245 -3290.245 -3290.245], critic_loss: 179.28500366210938, actor_loss: -0.004000000189989805, entropy: 0.4490000009536743, eps: 0.001})
Step:   77000, Reward: [-303.732 -303.732 -303.732] [50.375], Avg: [-375.291 -375.291 -375.291] (0.0010) <00:20:14> ({r_i: None, r_t: [-3275.355 -3275.355 -3275.355], critic_loss: 186.86300659179688, actor_loss: 0.2800000011920929, entropy: 0.43299999833106995, eps: 0.001})
Step:   77500, Reward: [-329.430 -329.430 -329.430] [52.017], Avg: [-374.997 -374.997 -374.997] (0.0010) <00:20:22> ({r_i: None, r_t: [-3341.506 -3341.506 -3341.506], critic_loss: 188.76800537109375, actor_loss: 0.3490000069141388, entropy: 0.43700000643730164, eps: 0.001})
Step:   78000, Reward: [-352.914 -352.914 -352.914] [58.933], Avg: [-374.856 -374.856 -374.856] (0.0010) <00:20:30> ({r_i: None, r_t: [-3259.704 -3259.704 -3259.704], critic_loss: 210.91799926757812, actor_loss: -0.7360000014305115, entropy: 0.4259999990463257, eps: 0.001})
Step:   78500, Reward: [-326.906 -326.906 -326.906] [44.991], Avg: [-374.553 -374.553 -374.553] (0.0010) <00:20:38> ({r_i: None, r_t: [-3348.963 -3348.963 -3348.963], critic_loss: 198.75, actor_loss: 0.5540000200271606, entropy: 0.44999998807907104, eps: 0.001})
Step:   79000, Reward: [-312.379 -312.379 -312.379] [72.115], Avg: [-374.162 -374.162 -374.162] (0.0010) <00:20:46> ({r_i: None, r_t: [-3283.506 -3283.506 -3283.506], critic_loss: 185.91000366210938, actor_loss: -0.10899999737739563, entropy: 0.4650000035762787, eps: 0.001})
Step:   79500, Reward: [-333.301 -333.301 -333.301] [60.112], Avg: [-373.907 -373.907 -373.907] (0.0010) <00:20:53> ({r_i: None, r_t: [-3320.733 -3320.733 -3320.733], critic_loss: 140.572998046875, actor_loss: -0.2280000001192093, entropy: 0.45500001311302185, eps: 0.001})
Step:   80000, Reward: [-321.992 -321.992 -321.992] [44.768], Avg: [-373.584 -373.584 -373.584] (0.0010) <00:21:02> ({r_i: None, r_t: [-3281.664 -3281.664 -3281.664], critic_loss: 194.41299438476562, actor_loss: 0.5619999766349792, entropy: 0.47099998593330383, eps: 0.001})
Step:   80500, Reward: [-358.332 -358.332 -358.332] [63.756], Avg: [-373.490 -373.490 -373.490] (0.0010) <00:21:09> ({r_i: None, r_t: [-3305.427 -3305.427 -3305.427], critic_loss: 168.81900024414062, actor_loss: 0.06300000101327896, entropy: 0.4569999873638153, eps: 0.001})
Step:   81000, Reward: [-318.688 -318.688 -318.688] [51.902], Avg: [-373.154 -373.154 -373.154] (0.0010) <00:21:17> ({r_i: None, r_t: [-3291.405 -3291.405 -3291.405], critic_loss: 155.9010009765625, actor_loss: -0.09000000357627869, entropy: 0.46799999475479126, eps: 0.001})
Step:   81500, Reward: [-335.953 -335.953 -335.953] [58.023], Avg: [-372.927 -372.927 -372.927] (0.0010) <00:21:25> ({r_i: None, r_t: [-3285.552 -3285.552 -3285.552], critic_loss: 164.71600341796875, actor_loss: -0.43799999356269836, entropy: 0.4830000102519989, eps: 0.001})
Step:   82000, Reward: [-303.722 -303.722 -303.722] [48.066], Avg: [-372.507 -372.507 -372.507] (0.0010) <00:21:33> ({r_i: None, r_t: [-3296.639 -3296.639 -3296.639], critic_loss: 200.87399291992188, actor_loss: -0.019999999552965164, entropy: 0.46299999952316284, eps: 0.001})
Step:   82500, Reward: [-336.359 -336.359 -336.359] [49.003], Avg: [-372.290 -372.290 -372.290] (0.0010) <00:21:40> ({r_i: None, r_t: [-3289.257 -3289.257 -3289.257], critic_loss: 204.70899963378906, actor_loss: -0.6309999823570251, entropy: 0.4749999940395355, eps: 0.001})
Step:   83000, Reward: [-321.603 -321.603 -321.603] [51.992], Avg: [-371.986 -371.986 -371.986] (0.0010) <00:21:49> ({r_i: None, r_t: [-3330.278 -3330.278 -3330.278], critic_loss: 190.84300231933594, actor_loss: 0.46700000762939453, entropy: 0.48100000619888306, eps: 0.001})
Step:   83500, Reward: [-365.931 -365.931 -365.931] [67.976], Avg: [-371.950 -371.950 -371.950] (0.0010) <00:21:56> ({r_i: None, r_t: [-3286.424 -3286.424 -3286.424], critic_loss: 247.10699462890625, actor_loss: -0.006000000052154064, entropy: 0.5049999952316284, eps: 0.001})
Step:   84000, Reward: [-327.759 -327.759 -327.759] [57.258], Avg: [-371.689 -371.689 -371.689] (0.0010) <00:22:04> ({r_i: None, r_t: [-3256.159 -3256.159 -3256.159], critic_loss: 177.10800170898438, actor_loss: -0.42800000309944153, entropy: 0.47699999809265137, eps: 0.001})
Step:   84500, Reward: [-327.339 -327.339 -327.339] [71.379], Avg: [-371.428 -371.428 -371.428] (0.0010) <00:22:12> ({r_i: None, r_t: [-3228.855 -3228.855 -3228.855], critic_loss: 157.41299438476562, actor_loss: 0.6980000138282776, entropy: 0.4749999940395355, eps: 0.001})
Step:   85000, Reward: [-357.191 -357.191 -357.191] [49.377], Avg: [-371.345 -371.345 -371.345] (0.0010) <00:22:20> ({r_i: None, r_t: [-3245.700 -3245.700 -3245.700], critic_loss: 151.34800720214844, actor_loss: 0.020999999716877937, entropy: 0.4650000035762787, eps: 0.001})
Step:   85500, Reward: [-306.800 -306.800 -306.800] [46.145], Avg: [-370.969 -370.969 -370.969] (0.0010) <00:22:28> ({r_i: None, r_t: [-3244.461 -3244.461 -3244.461], critic_loss: 183.07899475097656, actor_loss: 0.3140000104904175, entropy: 0.4909999966621399, eps: 0.001})
Step:   86000, Reward: [-313.559 -313.559 -313.559] [54.368], Avg: [-370.637 -370.637 -370.637] (0.0010) <00:22:36> ({r_i: None, r_t: [-3258.138 -3258.138 -3258.138], critic_loss: 185.9550018310547, actor_loss: 0.1889999955892563, entropy: 0.4819999933242798, eps: 0.001})
Step:   86500, Reward: [-310.304 -310.304 -310.304] [47.323], Avg: [-370.291 -370.291 -370.291] (0.0010) <00:22:43> ({r_i: None, r_t: [-3335.093 -3335.093 -3335.093], critic_loss: 204.61500549316406, actor_loss: 0.29600000381469727, entropy: 0.47200000286102295, eps: 0.001})
Step:   87000, Reward: [-307.598 -307.598 -307.598] [50.215], Avg: [-369.932 -369.932 -369.932] (0.0010) <00:22:52> ({r_i: None, r_t: [-3341.260 -3341.260 -3341.260], critic_loss: 156.7740020751953, actor_loss: -0.2720000147819519, entropy: 0.4650000035762787, eps: 0.001})
Step:   87500, Reward: [-317.212 -317.212 -317.212] [37.169], Avg: [-369.633 -369.633 -369.633] (0.0010) <00:22:59> ({r_i: None, r_t: [-3292.861 -3292.861 -3292.861], critic_loss: 277.6570129394531, actor_loss: -0.3700000047683716, entropy: 0.5049999952316284, eps: 0.001})
Step:   88000, Reward: [-339.391 -339.391 -339.391] [61.159], Avg: [-369.462 -369.462 -369.462] (0.0010) <00:23:07> ({r_i: None, r_t: [-3243.199 -3243.199 -3243.199], critic_loss: 226.5229949951172, actor_loss: -0.47099998593330383, entropy: 0.4869999885559082, eps: 0.001})
Step:   88500, Reward: [-319.849 -319.849 -319.849] [54.648], Avg: [-369.183 -369.183 -369.183] (0.0010) <00:23:15> ({r_i: None, r_t: [-3242.218 -3242.218 -3242.218], critic_loss: 200.052001953125, actor_loss: -0.22699999809265137, entropy: 0.4779999852180481, eps: 0.001})
Step:   89000, Reward: [-334.998 -334.998 -334.998] [66.694], Avg: [-368.992 -368.992 -368.992] (0.0010) <00:23:23> ({r_i: None, r_t: [-3286.013 -3286.013 -3286.013], critic_loss: 208.7760009765625, actor_loss: -0.05299999937415123, entropy: 0.46700000762939453, eps: 0.001})
Step:   89500, Reward: [-308.578 -308.578 -308.578] [49.674], Avg: [-368.657 -368.657 -368.657] (0.0010) <00:23:31> ({r_i: None, r_t: [-3176.376 -3176.376 -3176.376], critic_loss: 201.11599731445312, actor_loss: 0.3720000088214874, entropy: 0.4580000042915344, eps: 0.001})
Step:   90000, Reward: [-315.567 -315.567 -315.567] [50.710], Avg: [-368.363 -368.363 -368.363] (0.0010) <00:23:39> ({r_i: None, r_t: [-3201.553 -3201.553 -3201.553], critic_loss: 185.86099243164062, actor_loss: 0.023000000044703484, entropy: 0.44200000166893005, eps: 0.001})
Step:   90500, Reward: [-331.506 -331.506 -331.506] [73.956], Avg: [-368.161 -368.161 -368.161] (0.0010) <00:23:46> ({r_i: None, r_t: [-3343.348 -3343.348 -3343.348], critic_loss: 132.74200439453125, actor_loss: -0.13600000739097595, entropy: 0.44699999690055847, eps: 0.001})
Step:   91000, Reward: [-300.227 -300.227 -300.227] [30.877], Avg: [-367.790 -367.790 -367.790] (0.0010) <00:23:54> ({r_i: None, r_t: [-3264.900 -3264.900 -3264.900], critic_loss: 121.60399627685547, actor_loss: 0.4959999918937683, entropy: 0.42500001192092896, eps: 0.001})
Step:   91500, Reward: [-340.812 -340.812 -340.812] [68.427], Avg: [-367.643 -367.643 -367.643] (0.0010) <00:24:02> ({r_i: None, r_t: [-3221.676 -3221.676 -3221.676], critic_loss: 210.39500427246094, actor_loss: 0.5139999985694885, entropy: 0.453000009059906, eps: 0.001})
Step:   92000, Reward: [-322.104 -322.104 -322.104] [57.260], Avg: [-367.397 -367.397 -367.397] (0.0010) <00:24:10> ({r_i: None, r_t: [-3219.667 -3219.667 -3219.667], critic_loss: 159.4040069580078, actor_loss: -0.40400001406669617, entropy: 0.4399999976158142, eps: 0.001})
Step:   92500, Reward: [-349.863 -349.863 -349.863] [65.406], Avg: [-367.303 -367.303 -367.303] (0.0010) <00:24:18> ({r_i: None, r_t: [-3256.334 -3256.334 -3256.334], critic_loss: 166.0679931640625, actor_loss: -0.640999972820282, entropy: 0.44200000166893005, eps: 0.001})
Step:   93000, Reward: [-327.967 -327.967 -327.967] [47.299], Avg: [-367.092 -367.092 -367.092] (0.0010) <00:24:26> ({r_i: None, r_t: [-3281.083 -3281.083 -3281.083], critic_loss: 157.93099975585938, actor_loss: 0.0860000029206276, entropy: 0.42500001192092896, eps: 0.001})
Step:   93500, Reward: [-330.716 -330.716 -330.716] [48.766], Avg: [-366.899 -366.899 -366.899] (0.0010) <00:24:33> ({r_i: None, r_t: [-3270.798 -3270.798 -3270.798], critic_loss: 169.29800415039062, actor_loss: 0.6100000143051147, entropy: 0.42100000381469727, eps: 0.001})
Step:   94000, Reward: [-292.666 -292.666 -292.666] [49.610], Avg: [-366.506 -366.506 -366.506] (0.0010) <00:24:42> ({r_i: None, r_t: [-3221.645 -3221.645 -3221.645], critic_loss: 164.0030059814453, actor_loss: -0.06599999964237213, entropy: 0.4099999964237213, eps: 0.001})
Step:   94500, Reward: [-324.301 -324.301 -324.301] [54.351], Avg: [-366.284 -366.284 -366.284] (0.0010) <00:24:49> ({r_i: None, r_t: [-3298.198 -3298.198 -3298.198], critic_loss: 190.88400268554688, actor_loss: -0.33500000834465027, entropy: 0.43799999356269836, eps: 0.001})
Step:   95000, Reward: [-317.946 -317.946 -317.946] [49.074], Avg: [-366.031 -366.031 -366.031] (0.0010) <00:24:58> ({r_i: None, r_t: [-3228.413 -3228.413 -3228.413], critic_loss: 148.41000366210938, actor_loss: -0.31200000643730164, entropy: 0.4050000011920929, eps: 0.001})
Step:   95500, Reward: [-328.457 -328.457 -328.457] [59.677], Avg: [-365.835 -365.835 -365.835] (0.0010) <00:25:05> ({r_i: None, r_t: [-3239.619 -3239.619 -3239.619], critic_loss: 148.20700073242188, actor_loss: 0.3869999945163727, entropy: 0.41499999165534973, eps: 0.001})
Step:   96000, Reward: [-340.282 -340.282 -340.282] [61.580], Avg: [-365.703 -365.703 -365.703] (0.0010) <00:25:14> ({r_i: None, r_t: [-3237.797 -3237.797 -3237.797], critic_loss: 133.9770050048828, actor_loss: 0.0689999982714653, entropy: 0.4059999883174896, eps: 0.001})
Step:   96500, Reward: [-327.284 -327.284 -327.284] [52.761], Avg: [-365.505 -365.505 -365.505] (0.0010) <00:25:21> ({r_i: None, r_t: [-3236.793 -3236.793 -3236.793], critic_loss: 130.8820037841797, actor_loss: -0.003000000026077032, entropy: 0.40700000524520874, eps: 0.001})
Step:   97000, Reward: [-318.124 -318.124 -318.124] [56.593], Avg: [-365.262 -365.262 -365.262] (0.0010) <00:25:29> ({r_i: None, r_t: [-3300.720 -3300.720 -3300.720], critic_loss: 139.41099548339844, actor_loss: -0.2770000100135803, entropy: 0.4020000100135803, eps: 0.001})
Step:   97500, Reward: [-302.361 -302.361 -302.361] [63.874], Avg: [-364.941 -364.941 -364.941] (0.0010) <00:25:37> ({r_i: None, r_t: [-3240.243 -3240.243 -3240.243], critic_loss: 199.67100524902344, actor_loss: -0.03500000014901161, entropy: 0.4320000112056732, eps: 0.001})
Step:   98000, Reward: [-331.933 -331.933 -331.933] [45.109], Avg: [-364.773 -364.773 -364.773] (0.0010) <00:25:45> ({r_i: None, r_t: [-3178.862 -3178.862 -3178.862], critic_loss: 167.48899841308594, actor_loss: -0.003000000026077032, entropy: 0.4050000011920929, eps: 0.001})
Step:   98500, Reward: [-321.705 -321.705 -321.705] [40.128], Avg: [-364.556 -364.556 -364.556] (0.0010) <00:25:53> ({r_i: None, r_t: [-3302.366 -3302.366 -3302.366], critic_loss: 149.9149932861328, actor_loss: 0.5770000219345093, entropy: 0.375, eps: 0.001})
Step:   99000, Reward: [-328.945 -328.945 -328.945] [57.654], Avg: [-364.377 -364.377 -364.377] (0.0010) <00:26:01> ({r_i: None, r_t: [-3213.631 -3213.631 -3213.631], critic_loss: 95.50800323486328, actor_loss: 0.09099999815225601, entropy: 0.3720000088214874, eps: 0.001})
Step:   99500, Reward: [-316.477 -316.477 -316.477] [44.415], Avg: [-364.137 -364.137 -364.137] (0.0010) <00:26:08> ({r_i: None, r_t: [-3125.011 -3125.011 -3125.011], critic_loss: 118.83200073242188, actor_loss: 0.3140000104904175, entropy: 0.375, eps: 0.001})
Step:  100000, Reward: [-346.420 -346.420 -346.420] [64.665], Avg: [-364.049 -364.049 -364.049] (0.0010) <00:26:17> ({r_i: None, r_t: [-3278.965 -3278.965 -3278.965], critic_loss: 137.95899963378906, actor_loss: -0.8560000061988831, entropy: 0.36800000071525574, eps: 0.001})
Step:  100500, Reward: [-306.164 -306.164 -306.164] [42.224], Avg: [-363.763 -363.763 -363.763] (0.0010) <00:26:24> ({r_i: None, r_t: [-3237.714 -3237.714 -3237.714], critic_loss: 138.28399658203125, actor_loss: -0.026000000536441803, entropy: 0.3610000014305115, eps: 0.001})
Step:  101000, Reward: [-311.550 -311.550 -311.550] [52.432], Avg: [-363.505 -363.505 -363.505] (0.0010) <00:26:32> ({r_i: None, r_t: [-3208.906 -3208.906 -3208.906], critic_loss: 119.84200286865234, actor_loss: 0.057999998331069946, entropy: 0.3709999918937683, eps: 0.001})
Step:  101500, Reward: [-321.897 -321.897 -321.897] [69.353], Avg: [-363.301 -363.301 -363.301] (0.0010) <00:26:40> ({r_i: None, r_t: [-3236.189 -3236.189 -3236.189], critic_loss: 84.84500122070312, actor_loss: 0.38600000739097595, entropy: 0.3659999966621399, eps: 0.001})
Step:  102000, Reward: [-337.907 -337.907 -337.907] [72.460], Avg: [-363.177 -363.177 -363.177] (0.0010) <00:26:48> ({r_i: None, r_t: [-3243.867 -3243.867 -3243.867], critic_loss: 120.41300201416016, actor_loss: -0.01899999938905239, entropy: 0.375, eps: 0.001})
Step:  102500, Reward: [-325.947 -325.947 -325.947] [56.998], Avg: [-362.997 -362.997 -362.997] (0.0010) <00:26:55> ({r_i: None, r_t: [-3219.263 -3219.263 -3219.263], critic_loss: 103.46900177001953, actor_loss: -0.07500000298023224, entropy: 0.35600000619888306, eps: 0.001})
Step:  103000, Reward: [-317.083 -317.083 -317.083] [51.849], Avg: [-362.775 -362.775 -362.775] (0.0010) <00:27:04> ({r_i: None, r_t: [-3224.192 -3224.192 -3224.192], critic_loss: 102.87999725341797, actor_loss: 0.2280000001192093, entropy: 0.36500000953674316, eps: 0.001})
Step:  103500, Reward: [-331.411 -331.411 -331.411] [47.743], Avg: [-362.624 -362.624 -362.624] (0.0010) <00:27:11> ({r_i: None, r_t: [-3221.400 -3221.400 -3221.400], critic_loss: 96.76599884033203, actor_loss: 0.032999999821186066, entropy: 0.36899998784065247, eps: 0.001})
Step:  104000, Reward: [-298.707 -298.707 -298.707] [56.700], Avg: [-362.318 -362.318 -362.318] (0.0010) <00:27:19> ({r_i: None, r_t: [-3139.900 -3139.900 -3139.900], critic_loss: 134.43600463867188, actor_loss: -0.04500000178813934, entropy: 0.3700000047683716, eps: 0.001})
Step:  104500, Reward: [-324.967 -324.967 -324.967] [62.958], Avg: [-362.140 -362.140 -362.140] (0.0010) <00:27:27> ({r_i: None, r_t: [-3171.956 -3171.956 -3171.956], critic_loss: 96.30799865722656, actor_loss: -0.5680000185966492, entropy: 0.37700000405311584, eps: 0.001})
Step:  105000, Reward: [-322.507 -322.507 -322.507] [47.243], Avg: [-361.953 -361.953 -361.953] (0.0010) <00:27:35> ({r_i: None, r_t: [-3191.280 -3191.280 -3191.280], critic_loss: 138.91099548339844, actor_loss: -0.3630000054836273, entropy: 0.3779999911785126, eps: 0.001})
Step:  105500, Reward: [-327.582 -327.582 -327.582] [53.041], Avg: [-361.791 -361.791 -361.791] (0.0010) <00:27:43> ({r_i: None, r_t: [-3233.485 -3233.485 -3233.485], critic_loss: 109.86100006103516, actor_loss: 0.3160000145435333, entropy: 0.3790000081062317, eps: 0.001})
Step:  106000, Reward: [-327.456 -327.456 -327.456] [68.097], Avg: [-361.629 -361.629 -361.629] (0.0010) <00:27:51> ({r_i: None, r_t: [-3237.425 -3237.425 -3237.425], critic_loss: 120.36199951171875, actor_loss: 0.5, entropy: 0.36500000953674316, eps: 0.001})
Step:  106500, Reward: [-320.346 -320.346 -320.346] [44.002], Avg: [-361.436 -361.436 -361.436] (0.0010) <00:27:59> ({r_i: None, r_t: [-3201.924 -3201.924 -3201.924], critic_loss: 101.88500213623047, actor_loss: -0.22200000286102295, entropy: 0.3700000047683716, eps: 0.001})
Step:  107000, Reward: [-317.630 -317.630 -317.630] [57.214], Avg: [-361.233 -361.233 -361.233] (0.0010) <00:28:07> ({r_i: None, r_t: [-3158.203 -3158.203 -3158.203], critic_loss: 99.0770034790039, actor_loss: -0.08399999886751175, entropy: 0.36399999260902405, eps: 0.001})
Step:  107500, Reward: [-324.647 -324.647 -324.647] [44.315], Avg: [-361.063 -361.063 -361.063] (0.0010) <00:28:14> ({r_i: None, r_t: [-3293.319 -3293.319 -3293.319], critic_loss: 90.79900360107422, actor_loss: 0.38100001215934753, entropy: 0.375, eps: 0.001})
Step:  108000, Reward: [-310.243 -310.243 -310.243] [70.329], Avg: [-360.829 -360.829 -360.829] (0.0010) <00:28:22> ({r_i: None, r_t: [-3180.617 -3180.617 -3180.617], critic_loss: 91.59600067138672, actor_loss: 0.1979999989271164, entropy: 0.382999986410141, eps: 0.001})
Step:  108500, Reward: [-307.539 -307.539 -307.539] [55.043], Avg: [-360.585 -360.585 -360.585] (0.0010) <00:28:30> ({r_i: None, r_t: [-3263.277 -3263.277 -3263.277], critic_loss: 147.63699340820312, actor_loss: -0.492000013589859, entropy: 0.3790000081062317, eps: 0.001})
Step:  109000, Reward: [-320.514 -320.514 -320.514] [58.651], Avg: [-360.402 -360.402 -360.402] (0.0010) <00:28:38> ({r_i: None, r_t: [-3266.779 -3266.779 -3266.779], critic_loss: 113.98600006103516, actor_loss: -0.028999999165534973, entropy: 0.38199999928474426, eps: 0.001})
Step:  109500, Reward: [-314.596 -314.596 -314.596] [45.172], Avg: [-360.193 -360.193 -360.193] (0.0010) <00:28:45> ({r_i: None, r_t: [-3223.835 -3223.835 -3223.835], critic_loss: 118.95600128173828, actor_loss: 0.15700000524520874, entropy: 0.38499999046325684, eps: 0.001})
Step:  110000, Reward: [-285.826 -285.826 -285.826] [57.851], Avg: [-359.857 -359.857 -359.857] (0.0010) <00:28:54> ({r_i: None, r_t: [-3137.651 -3137.651 -3137.651], critic_loss: 101.34100341796875, actor_loss: 0.1120000034570694, entropy: 0.3959999978542328, eps: 0.001})
Step:  110500, Reward: [-332.741 -332.741 -332.741] [64.914], Avg: [-359.735 -359.735 -359.735] (0.0010) <00:29:01> ({r_i: None, r_t: [-3254.762 -3254.762 -3254.762], critic_loss: 106.7030029296875, actor_loss: 0.24699999392032623, entropy: 0.39500001072883606, eps: 0.001})
Step:  111000, Reward: [-297.844 -297.844 -297.844] [28.554], Avg: [-359.457 -359.457 -359.457] (0.0010) <00:29:09> ({r_i: None, r_t: [-3160.237 -3160.237 -3160.237], critic_loss: 95.23699951171875, actor_loss: 0.2930000126361847, entropy: 0.38600000739097595, eps: 0.001})
Step:  111500, Reward: [-305.715 -305.715 -305.715] [38.170], Avg: [-359.217 -359.217 -359.217] (0.0010) <00:29:17> ({r_i: None, r_t: [-3198.926 -3198.926 -3198.926], critic_loss: 162.75900268554688, actor_loss: -0.08100000023841858, entropy: 0.3889999985694885, eps: 0.001})
Step:  112000, Reward: [-336.217 -336.217 -336.217] [53.826], Avg: [-359.115 -359.115 -359.115] (0.0010) <00:29:25> ({r_i: None, r_t: [-3218.343 -3218.343 -3218.343], critic_loss: 110.65299987792969, actor_loss: -0.4009999930858612, entropy: 0.3880000114440918, eps: 0.001})
Step:  112500, Reward: [-308.374 -308.374 -308.374] [41.793], Avg: [-358.891 -358.891 -358.891] (0.0010) <00:29:33> ({r_i: None, r_t: [-3244.216 -3244.216 -3244.216], critic_loss: 122.83000183105469, actor_loss: -0.4189999997615814, entropy: 0.3869999945163727, eps: 0.001})
Step:  113000, Reward: [-333.072 -333.072 -333.072] [60.052], Avg: [-358.777 -358.777 -358.777] (0.0010) <00:29:41> ({r_i: None, r_t: [-3181.731 -3181.731 -3181.731], critic_loss: 87.8290023803711, actor_loss: 0.18400000035762787, entropy: 0.38999998569488525, eps: 0.001})
Step:  113500, Reward: [-321.114 -321.114 -321.114] [53.817], Avg: [-358.612 -358.612 -358.612] (0.0010) <00:29:48> ({r_i: None, r_t: [-3215.142 -3215.142 -3215.142], critic_loss: 98.29399871826172, actor_loss: 0.10899999737739563, entropy: 0.37700000405311584, eps: 0.001})
Step:  114000, Reward: [-302.088 -302.088 -302.088] [52.511], Avg: [-358.365 -358.365 -358.365] (0.0010) <00:29:56> ({r_i: None, r_t: [-3147.779 -3147.779 -3147.779], critic_loss: 94.447998046875, actor_loss: 0.13600000739097595, entropy: 0.38199999928474426, eps: 0.001})
Step:  114500, Reward: [-310.725 -310.725 -310.725] [60.841], Avg: [-358.158 -358.158 -358.158] (0.0010) <00:30:04> ({r_i: None, r_t: [-3187.454 -3187.454 -3187.454], critic_loss: 94.19300079345703, actor_loss: -0.05400000140070915, entropy: 0.375, eps: 0.001})
Step:  115000, Reward: [-337.530 -337.530 -337.530] [76.413], Avg: [-358.068 -358.068 -358.068] (0.0010) <00:30:12> ({r_i: None, r_t: [-3137.222 -3137.222 -3137.222], critic_loss: 103.28500366210938, actor_loss: 0.07100000232458115, entropy: 0.37599998712539673, eps: 0.001})
Step:  115500, Reward: [-338.027 -338.027 -338.027] [61.663], Avg: [-357.982 -357.982 -357.982] (0.0010) <00:30:20> ({r_i: None, r_t: [-3205.166 -3205.166 -3205.166], critic_loss: 101.01200103759766, actor_loss: -0.23199999332427979, entropy: 0.36800000071525574, eps: 0.001})
Step:  116000, Reward: [-337.229 -337.229 -337.229] [67.675], Avg: [-357.893 -357.893 -357.893] (0.0010) <00:30:28> ({r_i: None, r_t: [-3127.632 -3127.632 -3127.632], critic_loss: 80.01599884033203, actor_loss: -0.13699999451637268, entropy: 0.3840000033378601, eps: 0.001})
Step:  116500, Reward: [-308.441 -308.441 -308.441] [67.846], Avg: [-357.682 -357.682 -357.682] (0.0010) <00:30:36> ({r_i: None, r_t: [-3158.229 -3158.229 -3158.229], critic_loss: 87.77799987792969, actor_loss: -0.035999998450279236, entropy: 0.37400001287460327, eps: 0.001})
Step:  117000, Reward: [-326.254 -326.254 -326.254] [44.756], Avg: [-357.548 -357.548 -357.548] (0.0010) <00:30:43> ({r_i: None, r_t: [-3234.012 -3234.012 -3234.012], critic_loss: 101.11900329589844, actor_loss: -0.05900000035762787, entropy: 0.3779999911785126, eps: 0.001})
Step:  117500, Reward: [-340.439 -340.439 -340.439] [63.661], Avg: [-357.475 -357.475 -357.475] (0.0010) <00:30:51> ({r_i: None, r_t: [-3172.162 -3172.162 -3172.162], critic_loss: 85.90899658203125, actor_loss: -0.023000000044703484, entropy: 0.37400001287460327, eps: 0.001})
Step:  118000, Reward: [-334.822 -334.822 -334.822] [67.807], Avg: [-357.380 -357.380 -357.380] (0.0010) <00:30:59> ({r_i: None, r_t: [-3185.151 -3185.151 -3185.151], critic_loss: 105.65499877929688, actor_loss: -0.36000001430511475, entropy: 0.3700000047683716, eps: 0.001})
Step:  118500, Reward: [-316.021 -316.021 -316.021] [44.242], Avg: [-357.206 -357.206 -357.206] (0.0010) <00:31:07> ({r_i: None, r_t: [-3175.954 -3175.954 -3175.954], critic_loss: 114.52999877929688, actor_loss: 0.14900000393390656, entropy: 0.3569999933242798, eps: 0.001})
Step:  119000, Reward: [-330.481 -330.481 -330.481] [57.196], Avg: [-357.094 -357.094 -357.094] (0.0010) <00:31:15> ({r_i: None, r_t: [-3185.216 -3185.216 -3185.216], critic_loss: 92.23400115966797, actor_loss: -0.04500000178813934, entropy: 0.34700000286102295, eps: 0.001})
Step:  119500, Reward: [-299.969 -299.969 -299.969] [59.819], Avg: [-356.856 -356.856 -356.856] (0.0010) <00:31:22> ({r_i: None, r_t: [-3229.044 -3229.044 -3229.044], critic_loss: 114.03399658203125, actor_loss: 0.7789999842643738, entropy: 0.3540000021457672, eps: 0.001})
Step:  120000, Reward: [-317.625 -317.625 -317.625] [37.083], Avg: [-356.693 -356.693 -356.693] (0.0010) <00:31:31> ({r_i: None, r_t: [-3205.812 -3205.812 -3205.812], critic_loss: 83.28199768066406, actor_loss: -0.2840000092983246, entropy: 0.375, eps: 0.001})
Step:  120500, Reward: [-324.407 -324.407 -324.407] [67.253], Avg: [-356.560 -356.560 -356.560] (0.0010) <00:31:38> ({r_i: None, r_t: [-3240.540 -3240.540 -3240.540], critic_loss: 99.08100128173828, actor_loss: 0.40700000524520874, entropy: 0.35600000619888306, eps: 0.001})
Step:  121000, Reward: [-306.309 -306.309 -306.309] [60.821], Avg: [-356.353 -356.353 -356.353] (0.0010) <00:31:46> ({r_i: None, r_t: [-3094.937 -3094.937 -3094.937], critic_loss: 79.72599792480469, actor_loss: 0.2150000035762787, entropy: 0.3529999852180481, eps: 0.001})
Step:  121500, Reward: [-308.112 -308.112 -308.112] [56.397], Avg: [-356.156 -356.156 -356.156] (0.0010) <00:31:54> ({r_i: None, r_t: [-3229.400 -3229.400 -3229.400], critic_loss: 102.57499694824219, actor_loss: 0.328000009059906, entropy: 0.3400000035762787, eps: 0.001})
Step:  122000, Reward: [-316.843 -316.843 -316.843] [52.314], Avg: [-355.995 -355.995 -355.995] (0.0010) <00:32:02> ({r_i: None, r_t: [-3257.076 -3257.076 -3257.076], critic_loss: 73.90899658203125, actor_loss: -0.1770000010728836, entropy: 0.3610000014305115, eps: 0.001})
Step:  122500, Reward: [-306.561 -306.561 -306.561] [47.639], Avg: [-355.794 -355.794 -355.794] (0.0010) <00:32:09> ({r_i: None, r_t: [-3181.839 -3181.839 -3181.839], critic_loss: 68.53500366210938, actor_loss: -0.0689999982714653, entropy: 0.3540000021457672, eps: 0.001})
Step:  123000, Reward: [-297.339 -297.339 -297.339] [44.415], Avg: [-355.557 -355.557 -355.557] (0.0010) <00:32:18> ({r_i: None, r_t: [-3190.092 -3190.092 -3190.092], critic_loss: 92.18399810791016, actor_loss: 0.34299999475479126, entropy: 0.3449999988079071, eps: 0.001})
Step:  123500, Reward: [-319.885 -319.885 -319.885] [47.528], Avg: [-355.414 -355.414 -355.414] (0.0010) <00:32:25> ({r_i: None, r_t: [-3262.966 -3262.966 -3262.966], critic_loss: 96.55699920654297, actor_loss: -0.16599999368190765, entropy: 0.335999995470047, eps: 0.001})
Step:  124000, Reward: [-333.860 -333.860 -333.860] [46.226], Avg: [-355.327 -355.327 -355.327] (0.0010) <00:32:33> ({r_i: None, r_t: [-3145.060 -3145.060 -3145.060], critic_loss: 87.66200256347656, actor_loss: 0.2529999911785126, entropy: 0.3440000116825104, eps: 0.001})
Step:  124500, Reward: [-308.102 -308.102 -308.102] [61.695], Avg: [-355.138 -355.138 -355.138] (0.0010) <00:32:41> ({r_i: None, r_t: [-3162.641 -3162.641 -3162.641], critic_loss: 77.91799926757812, actor_loss: -0.18299999833106995, entropy: 0.3400000035762787, eps: 0.001})
Step:  125000, Reward: [-294.239 -294.239 -294.239] [45.352], Avg: [-354.896 -354.896 -354.896] (0.0010) <00:32:49> ({r_i: None, r_t: [-3144.498 -3144.498 -3144.498], critic_loss: 73.0739974975586, actor_loss: 0.10499999672174454, entropy: 0.328000009059906, eps: 0.001})
Step:  125500, Reward: [-326.606 -326.606 -326.606] [54.093], Avg: [-354.783 -354.783 -354.783] (0.0010) <00:32:57> ({r_i: None, r_t: [-3234.226 -3234.226 -3234.226], critic_loss: 103.36900329589844, actor_loss: 0.4230000078678131, entropy: 0.3240000009536743, eps: 0.001})
Step:  126000, Reward: [-317.832 -317.832 -317.832] [54.554], Avg: [-354.637 -354.637 -354.637] (0.0010) <00:33:05> ({r_i: None, r_t: [-3236.300 -3236.300 -3236.300], critic_loss: 86.75700378417969, actor_loss: -0.12600000202655792, entropy: 0.32600000500679016, eps: 0.001})
Step:  126500, Reward: [-333.015 -333.015 -333.015] [64.635], Avg: [-354.552 -354.552 -354.552] (0.0010) <00:33:13> ({r_i: None, r_t: [-3148.818 -3148.818 -3148.818], critic_loss: 82.09600067138672, actor_loss: -0.33799999952316284, entropy: 0.31700000166893005, eps: 0.001})
Step:  127000, Reward: [-323.232 -323.232 -323.232] [74.892], Avg: [-354.429 -354.429 -354.429] (0.0010) <00:33:21> ({r_i: None, r_t: [-3166.387 -3166.387 -3166.387], critic_loss: 113.94200134277344, actor_loss: 0.4359999895095825, entropy: 0.328000009059906, eps: 0.001})
Step:  127500, Reward: [-319.106 -319.106 -319.106] [55.419], Avg: [-354.291 -354.291 -354.291] (0.0010) <00:33:29> ({r_i: None, r_t: [-3155.805 -3155.805 -3155.805], critic_loss: 99.5009994506836, actor_loss: -0.4180000126361847, entropy: 0.33799999952316284, eps: 0.001})
Step:  128000, Reward: [-324.357 -324.357 -324.357] [42.981], Avg: [-354.175 -354.175 -354.175] (0.0010) <00:33:37> ({r_i: None, r_t: [-3201.330 -3201.330 -3201.330], critic_loss: 117.02100372314453, actor_loss: 0.13099999725818634, entropy: 0.3199999928474426, eps: 0.001})
Step:  128500, Reward: [-319.756 -319.756 -319.756] [72.248], Avg: [-354.041 -354.041 -354.041] (0.0010) <00:33:44> ({r_i: None, r_t: [-3197.710 -3197.710 -3197.710], critic_loss: 70.2760009765625, actor_loss: 0.4440000057220459, entropy: 0.3370000123977661, eps: 0.001})
Step:  129000, Reward: [-315.290 -315.290 -315.290] [49.667], Avg: [-353.892 -353.892 -353.892] (0.0010) <00:33:53> ({r_i: None, r_t: [-3134.387 -3134.387 -3134.387], critic_loss: 77.95099639892578, actor_loss: -0.12099999934434891, entropy: 0.3140000104904175, eps: 0.001})
Step:  129500, Reward: [-316.799 -316.799 -316.799] [68.372], Avg: [-353.749 -353.749 -353.749] (0.0010) <00:34:00> ({r_i: None, r_t: [-3217.076 -3217.076 -3217.076], critic_loss: 79.88800048828125, actor_loss: -0.03099999949336052, entropy: 0.32199999690055847, eps: 0.001})
Step:  130000, Reward: [-328.139 -328.139 -328.139] [52.250], Avg: [-353.651 -353.651 -353.651] (0.0010) <00:34:08> ({r_i: None, r_t: [-3235.635 -3235.635 -3235.635], critic_loss: 71.38300323486328, actor_loss: -0.15399999916553497, entropy: 0.32100000977516174, eps: 0.001})
Step:  130500, Reward: [-300.365 -300.365 -300.365] [50.562], Avg: [-353.448 -353.448 -353.448] (0.0010) <00:34:16> ({r_i: None, r_t: [-3218.590 -3218.590 -3218.590], critic_loss: 74.68099975585938, actor_loss: 0.23800000548362732, entropy: 0.31299999356269836, eps: 0.001})
Step:  131000, Reward: [-337.172 -337.172 -337.172] [49.128], Avg: [-353.386 -353.386 -353.386] (0.0010) <00:34:24> ({r_i: None, r_t: [-3180.835 -3180.835 -3180.835], critic_loss: 75.51499938964844, actor_loss: 0.027000000700354576, entropy: 0.3240000009536743, eps: 0.001})
Step:  131500, Reward: [-335.883 -335.883 -335.883] [47.422], Avg: [-353.319 -353.319 -353.319] (0.0010) <00:34:32> ({r_i: None, r_t: [-3086.143 -3086.143 -3086.143], critic_loss: 77.15899658203125, actor_loss: -0.16200000047683716, entropy: 0.3319999873638153, eps: 0.001})
Step:  132000, Reward: [-312.421 -312.421 -312.421] [49.977], Avg: [-353.165 -353.165 -353.165] (0.0010) <00:34:40> ({r_i: None, r_t: [-3167.055 -3167.055 -3167.055], critic_loss: 95.18900299072266, actor_loss: 0.4880000054836273, entropy: 0.31700000166893005, eps: 0.001})
Step:  132500, Reward: [-308.676 -308.676 -308.676] [41.943], Avg: [-352.998 -352.998 -352.998] (0.0010) <00:34:47> ({r_i: None, r_t: [-3232.201 -3232.201 -3232.201], critic_loss: 101.32099914550781, actor_loss: 0.02800000086426735, entropy: 0.3240000009536743, eps: 0.001})
Step:  133000, Reward: [-355.598 -355.598 -355.598] [58.400], Avg: [-353.008 -353.008 -353.008] (0.0010) <00:34:56> ({r_i: None, r_t: [-3195.458 -3195.458 -3195.458], critic_loss: 105.81999969482422, actor_loss: 0.2720000147819519, entropy: 0.335999995470047, eps: 0.001})
Step:  133500, Reward: [-323.316 -323.316 -323.316] [60.412], Avg: [-352.897 -352.897 -352.897] (0.0010) <00:35:03> ({r_i: None, r_t: [-3154.411 -3154.411 -3154.411], critic_loss: 81.20999908447266, actor_loss: -0.4519999921321869, entropy: 0.34700000286102295, eps: 0.001})
Step:  134000, Reward: [-304.877 -304.877 -304.877] [53.113], Avg: [-352.718 -352.718 -352.718] (0.0010) <00:35:11> ({r_i: None, r_t: [-3147.308 -3147.308 -3147.308], critic_loss: 74.06099700927734, actor_loss: 0.15399999916553497, entropy: 0.34299999475479126, eps: 0.001})
Step:  134500, Reward: [-317.111 -317.111 -317.111] [59.776], Avg: [-352.586 -352.586 -352.586] (0.0010) <00:35:19> ({r_i: None, r_t: [-3132.126 -3132.126 -3132.126], critic_loss: 69.91999816894531, actor_loss: -0.07199999690055847, entropy: 0.33399999141693115, eps: 0.001})
Step:  135000, Reward: [-321.174 -321.174 -321.174] [58.296], Avg: [-352.470 -352.470 -352.470] (0.0010) <00:35:27> ({r_i: None, r_t: [-3167.247 -3167.247 -3167.247], critic_loss: 85.86900329589844, actor_loss: 0.3230000138282776, entropy: 0.33000001311302185, eps: 0.001})
Step:  135500, Reward: [-305.173 -305.173 -305.173] [28.081], Avg: [-352.297 -352.297 -352.297] (0.0010) <00:35:35> ({r_i: None, r_t: [-3254.291 -3254.291 -3254.291], critic_loss: 89.50199890136719, actor_loss: 0.14100000262260437, entropy: 0.3319999873638153, eps: 0.001})
Step:  136000, Reward: [-332.233 -332.233 -332.233] [59.256], Avg: [-352.223 -352.223 -352.223] (0.0010) <00:35:43> ({r_i: None, r_t: [-3135.921 -3135.921 -3135.921], critic_loss: 76.75700378417969, actor_loss: 0.11999999731779099, entropy: 0.328000009059906, eps: 0.001})
Step:  136500, Reward: [-316.076 -316.076 -316.076] [58.097], Avg: [-352.091 -352.091 -352.091] (0.0010) <00:35:50> ({r_i: None, r_t: [-3221.045 -3221.045 -3221.045], critic_loss: 73.42900085449219, actor_loss: 0.31200000643730164, entropy: 0.33399999141693115, eps: 0.001})
Step:  137000, Reward: [-313.313 -313.313 -313.313] [73.356], Avg: [-351.950 -351.950 -351.950] (0.0010) <00:35:59> ({r_i: None, r_t: [-3218.925 -3218.925 -3218.925], critic_loss: 109.552001953125, actor_loss: 0.22599999606609344, entropy: 0.3310000002384186, eps: 0.001})
Step:  137500, Reward: [-320.139 -320.139 -320.139] [60.139], Avg: [-351.835 -351.835 -351.835] (0.0010) <00:36:06> ({r_i: None, r_t: [-3219.355 -3219.355 -3219.355], critic_loss: 84.79900360107422, actor_loss: -0.3370000123977661, entropy: 0.3330000042915344, eps: 0.001})
Step:  138000, Reward: [-328.684 -328.684 -328.684] [70.568], Avg: [-351.751 -351.751 -351.751] (0.0010) <00:36:14> ({r_i: None, r_t: [-3215.152 -3215.152 -3215.152], critic_loss: 91.20999908447266, actor_loss: 0.36899998784065247, entropy: 0.33399999141693115, eps: 0.001})
Step:  138500, Reward: [-291.969 -291.969 -291.969] [66.638], Avg: [-351.536 -351.536 -351.536] (0.0010) <00:36:22> ({r_i: None, r_t: [-3190.594 -3190.594 -3190.594], critic_loss: 81.51599884033203, actor_loss: 0.19200000166893005, entropy: 0.33899998664855957, eps: 0.001})
Step:  139000, Reward: [-326.128 -326.128 -326.128] [51.105], Avg: [-351.445 -351.445 -351.445] (0.0010) <00:36:30> ({r_i: None, r_t: [-3186.979 -3186.979 -3186.979], critic_loss: 92.61599731445312, actor_loss: 0.03999999910593033, entropy: 0.33000001311302185, eps: 0.001})
Step:  139500, Reward: [-312.234 -312.234 -312.234] [58.503], Avg: [-351.305 -351.305 -351.305] (0.0010) <00:36:38> ({r_i: None, r_t: [-3111.290 -3111.290 -3111.290], critic_loss: 103.3550033569336, actor_loss: -0.09600000083446503, entropy: 0.328000009059906, eps: 0.001})
Step:  140000, Reward: [-327.170 -327.170 -327.170] [44.755], Avg: [-351.219 -351.219 -351.219] (0.0010) <00:36:46> ({r_i: None, r_t: [-3234.689 -3234.689 -3234.689], critic_loss: 79.39399719238281, actor_loss: 0.33799999952316284, entropy: 0.3319999873638153, eps: 0.001})
Step:  140500, Reward: [-324.858 -324.858 -324.858] [57.085], Avg: [-351.126 -351.126 -351.126] (0.0010) <00:36:53> ({r_i: None, r_t: [-3187.144 -3187.144 -3187.144], critic_loss: 65.11199951171875, actor_loss: -0.1979999989271164, entropy: 0.3370000123977661, eps: 0.001})
Step:  141000, Reward: [-288.397 -288.397 -288.397] [48.274], Avg: [-350.904 -350.904 -350.904] (0.0010) <00:37:01> ({r_i: None, r_t: [-3185.799 -3185.799 -3185.799], critic_loss: 72.3759994506836, actor_loss: 0.32199999690055847, entropy: 0.31200000643730164, eps: 0.001})
Step:  141500, Reward: [-318.114 -318.114 -318.114] [67.876], Avg: [-350.789 -350.789 -350.789] (0.0010) <00:37:09> ({r_i: None, r_t: [-3204.263 -3204.263 -3204.263], critic_loss: 72.66200256347656, actor_loss: -0.25099998712539673, entropy: 0.30000001192092896, eps: 0.001})
Step:  142000, Reward: [-311.812 -311.812 -311.812] [57.252], Avg: [-350.652 -350.652 -350.652] (0.0010) <00:37:17> ({r_i: None, r_t: [-3093.870 -3093.870 -3093.870], critic_loss: 81.66699981689453, actor_loss: -0.05400000140070915, entropy: 0.30300000309944153, eps: 0.001})
Step:  142500, Reward: [-325.225 -325.225 -325.225] [62.625], Avg: [-350.563 -350.563 -350.563] (0.0010) <00:37:25> ({r_i: None, r_t: [-3225.315 -3225.315 -3225.315], critic_loss: 95.88600158691406, actor_loss: 0.14300000667572021, entropy: 0.30300000309944153, eps: 0.001})
Step:  143000, Reward: [-303.143 -303.143 -303.143] [60.136], Avg: [-350.398 -350.398 -350.398] (0.0010) <00:37:33> ({r_i: None, r_t: [-3096.812 -3096.812 -3096.812], critic_loss: 76.89800262451172, actor_loss: -0.08399999886751175, entropy: 0.3019999861717224, eps: 0.001})
Step:  143500, Reward: [-300.898 -300.898 -300.898] [59.125], Avg: [-350.226 -350.226 -350.226] (0.0010) <00:37:41> ({r_i: None, r_t: [-3234.557 -3234.557 -3234.557], critic_loss: 88.81300354003906, actor_loss: 0.12999999523162842, entropy: 0.30300000309944153, eps: 0.001})
Step:  144000, Reward: [-347.427 -347.427 -347.427] [76.260], Avg: [-350.216 -350.216 -350.216] (0.0010) <00:37:49> ({r_i: None, r_t: [-3075.162 -3075.162 -3075.162], critic_loss: 95.68099975585938, actor_loss: -0.3479999899864197, entropy: 0.3019999861717224, eps: 0.001})
Step:  144500, Reward: [-308.673 -308.673 -308.673] [59.294], Avg: [-350.073 -350.073 -350.073] (0.0010) <00:37:56> ({r_i: None, r_t: [-3182.806 -3182.806 -3182.806], critic_loss: 80.11000061035156, actor_loss: -0.18199999630451202, entropy: 0.30300000309944153, eps: 0.001})
Step:  145000, Reward: [-312.655 -312.655 -312.655] [78.584], Avg: [-349.944 -349.944 -349.944] (0.0010) <00:38:05> ({r_i: None, r_t: [-3223.822 -3223.822 -3223.822], critic_loss: 93.02999877929688, actor_loss: 0.013000000268220901, entropy: 0.3019999861717224, eps: 0.001})
Step:  145500, Reward: [-342.722 -342.722 -342.722] [41.021], Avg: [-349.920 -349.920 -349.920] (0.0010) <00:38:12> ({r_i: None, r_t: [-3195.143 -3195.143 -3195.143], critic_loss: 106.6719970703125, actor_loss: 0.6549999713897705, entropy: 0.3109999895095825, eps: 0.001})
Step:  146000, Reward: [-310.217 -310.217 -310.217] [56.054], Avg: [-349.784 -349.784 -349.784] (0.0010) <00:38:21> ({r_i: None, r_t: [-3167.803 -3167.803 -3167.803], critic_loss: 98.23600006103516, actor_loss: -0.07900000363588333, entropy: 0.2939999997615814, eps: 0.001})
Step:  146500, Reward: [-308.230 -308.230 -308.230] [47.102], Avg: [-349.643 -349.643 -349.643] (0.0010) <00:38:28> ({r_i: None, r_t: [-3114.144 -3114.144 -3114.144], critic_loss: 76.70600128173828, actor_loss: 0.3240000009536743, entropy: 0.29499998688697815, eps: 0.001})
Step:  147000, Reward: [-323.491 -323.491 -323.491] [60.815], Avg: [-349.554 -349.554 -349.554] (0.0010) <00:38:37> ({r_i: None, r_t: [-3196.471 -3196.471 -3196.471], critic_loss: 84.68599700927734, actor_loss: -0.008999999612569809, entropy: 0.2879999876022339, eps: 0.001})
Step:  147500, Reward: [-298.133 -298.133 -298.133] [38.133], Avg: [-349.380 -349.380 -349.380] (0.0010) <00:38:44> ({r_i: None, r_t: [-3121.040 -3121.040 -3121.040], critic_loss: 50.733001708984375, actor_loss: -0.1809999942779541, entropy: 0.28700000047683716, eps: 0.001})
Step:  148000, Reward: [-318.600 -318.600 -318.600] [58.833], Avg: [-349.277 -349.277 -349.277] (0.0010) <00:38:52> ({r_i: None, r_t: [-3116.947 -3116.947 -3116.947], critic_loss: 71.0530014038086, actor_loss: -0.004000000189989805, entropy: 0.28999999165534973, eps: 0.001})
Step:  148500, Reward: [-308.538 -308.538 -308.538] [53.012], Avg: [-349.140 -349.140 -349.140] (0.0010) <00:39:00> ({r_i: None, r_t: [-3171.948 -3171.948 -3171.948], critic_loss: 85.38700103759766, actor_loss: 0.20100000500679016, entropy: 0.3059999942779541, eps: 0.001})
Step:  149000, Reward: [-288.768 -288.768 -288.768] [42.116], Avg: [-348.938 -348.938 -348.938] (0.0010) <00:39:08> ({r_i: None, r_t: [-3177.298 -3177.298 -3177.298], critic_loss: 57.51599884033203, actor_loss: 0.16699999570846558, entropy: 0.28600001335144043, eps: 0.001})
Step:  149500, Reward: [-300.607 -300.607 -300.607] [49.751], Avg: [-348.777 -348.777 -348.777] (0.0010) <00:39:16> ({r_i: None, r_t: [-3253.231 -3253.231 -3253.231], critic_loss: 81.56199645996094, actor_loss: -0.4480000138282776, entropy: 0.28700000047683716, eps: 0.001})
Step:  150000, Reward: [-293.930 -293.930 -293.930] [40.904], Avg: [-348.595 -348.595 -348.595] (0.0010) <00:39:24> ({r_i: None, r_t: [-3187.825 -3187.825 -3187.825], critic_loss: 80.0770034790039, actor_loss: -0.2150000035762787, entropy: 0.28999999165534973, eps: 0.001})
Step:  150500, Reward: [-307.959 -307.959 -307.959] [51.458], Avg: [-348.460 -348.460 -348.460] (0.0010) <00:39:31> ({r_i: None, r_t: [-3148.432 -3148.432 -3148.432], critic_loss: 97.1240005493164, actor_loss: 0.19699999690055847, entropy: 0.29100000858306885, eps: 0.001})
Step:  151000, Reward: [-314.343 -314.343 -314.343] [59.392], Avg: [-348.348 -348.348 -348.348] (0.0010) <00:39:39> ({r_i: None, r_t: [-3201.805 -3201.805 -3201.805], critic_loss: 70.26100158691406, actor_loss: -0.007000000216066837, entropy: 0.29100000858306885, eps: 0.001})
Step:  151500, Reward: [-318.434 -318.434 -318.434] [47.849], Avg: [-348.249 -348.249 -348.249] (0.0010) <00:39:47> ({r_i: None, r_t: [-3116.900 -3116.900 -3116.900], critic_loss: 58.32699966430664, actor_loss: 0.335999995470047, entropy: 0.28700000047683716, eps: 0.001})
Step:  152000, Reward: [-305.664 -305.664 -305.664] [55.597], Avg: [-348.110 -348.110 -348.110] (0.0010) <00:39:55> ({r_i: None, r_t: [-3145.034 -3145.034 -3145.034], critic_loss: 80.99099731445312, actor_loss: -0.2529999911785126, entropy: 0.29600000381469727, eps: 0.001})
Step:  152500, Reward: [-339.613 -339.613 -339.613] [56.650], Avg: [-348.082 -348.082 -348.082] (0.0010) <00:40:03> ({r_i: None, r_t: [-3109.803 -3109.803 -3109.803], critic_loss: 79.21299743652344, actor_loss: -0.024000000208616257, entropy: 0.28999999165534973, eps: 0.001})
Step:  153000, Reward: [-325.950 -325.950 -325.950] [65.620], Avg: [-348.010 -348.010 -348.010] (0.0010) <00:40:11> ({r_i: None, r_t: [-3166.042 -3166.042 -3166.042], critic_loss: 81.7770004272461, actor_loss: -0.16599999368190765, entropy: 0.289000004529953, eps: 0.001})
Step:  153500, Reward: [-331.217 -331.217 -331.217] [59.584], Avg: [-347.955 -347.955 -347.955] (0.0010) <00:40:18> ({r_i: None, r_t: [-3191.402 -3191.402 -3191.402], critic_loss: 88.44200134277344, actor_loss: 0.31200000643730164, entropy: 0.2720000147819519, eps: 0.001})
Step:  154000, Reward: [-323.457 -323.457 -323.457] [41.794], Avg: [-347.876 -347.876 -347.876] (0.0010) <00:40:26> ({r_i: None, r_t: [-3113.244 -3113.244 -3113.244], critic_loss: 70.01300048828125, actor_loss: 0.3100000023841858, entropy: 0.27300000190734863, eps: 0.001})
Step:  154500, Reward: [-308.468 -308.468 -308.468] [52.933], Avg: [-347.749 -347.749 -347.749] (0.0010) <00:40:34> ({r_i: None, r_t: [-3153.680 -3153.680 -3153.680], critic_loss: 60.82500076293945, actor_loss: -0.5400000214576721, entropy: 0.28600001335144043, eps: 0.001})
Step:  155000, Reward: [-312.668 -312.668 -312.668] [53.238], Avg: [-347.636 -347.636 -347.636] (0.0010) <00:40:42> ({r_i: None, r_t: [-3194.162 -3194.162 -3194.162], critic_loss: 60.15999984741211, actor_loss: 0.07599999755620956, entropy: 0.2750000059604645, eps: 0.001})
Step:  155500, Reward: [-318.526 -318.526 -318.526] [39.933], Avg: [-347.543 -347.543 -347.543] (0.0010) <00:40:50> ({r_i: None, r_t: [-3074.805 -3074.805 -3074.805], critic_loss: 64.18699645996094, actor_loss: -0.18700000643730164, entropy: 0.28600001335144043, eps: 0.001})
Step:  156000, Reward: [-304.062 -304.062 -304.062] [65.332], Avg: [-347.404 -347.404 -347.404] (0.0010) <00:40:58> ({r_i: None, r_t: [-3156.944 -3156.944 -3156.944], critic_loss: 75.60600280761719, actor_loss: 0.09099999815225601, entropy: 0.2919999957084656, eps: 0.001})
Step:  156500, Reward: [-308.219 -308.219 -308.219] [42.926], Avg: [-347.279 -347.279 -347.279] (0.0010) <00:41:05> ({r_i: None, r_t: [-3257.811 -3257.811 -3257.811], critic_loss: 81.48400115966797, actor_loss: 0.19599999487400055, entropy: 0.296999990940094, eps: 0.001})
Step:  157000, Reward: [-290.384 -290.384 -290.384] [49.201], Avg: [-347.098 -347.098 -347.098] (0.0010) <00:41:13> ({r_i: None, r_t: [-3078.451 -3078.451 -3078.451], critic_loss: 84.1969985961914, actor_loss: -0.18700000643730164, entropy: 0.2849999964237213, eps: 0.001})
Step:  157500, Reward: [-310.583 -310.583 -310.583] [40.079], Avg: [-346.983 -346.983 -346.983] (0.0010) <00:41:21> ({r_i: None, r_t: [-3187.163 -3187.163 -3187.163], critic_loss: 77.54299926757812, actor_loss: 0.5350000262260437, entropy: 0.2809999883174896, eps: 0.001})
Step:  158000, Reward: [-317.770 -317.770 -317.770] [51.932], Avg: [-346.891 -346.891 -346.891] (0.0010) <00:41:29> ({r_i: None, r_t: [-3155.325 -3155.325 -3155.325], critic_loss: 127.3550033569336, actor_loss: -0.08699999749660492, entropy: 0.3160000145435333, eps: 0.001})
Step:  158500, Reward: [-317.363 -317.363 -317.363] [49.436], Avg: [-346.798 -346.798 -346.798] (0.0010) <00:41:37> ({r_i: None, r_t: [-3119.028 -3119.028 -3119.028], critic_loss: 88.97899627685547, actor_loss: -0.47699999809265137, entropy: 0.3149999976158142, eps: 0.001})
Step:  159000, Reward: [-313.587 -313.587 -313.587] [56.523], Avg: [-346.694 -346.694 -346.694] (0.0010) <00:41:45> ({r_i: None, r_t: [-3071.897 -3071.897 -3071.897], critic_loss: 127.94999694824219, actor_loss: 0.13699999451637268, entropy: 0.3580000102519989, eps: 0.001})
Step:  159500, Reward: [-315.748 -315.748 -315.748] [53.500], Avg: [-346.597 -346.597 -346.597] (0.0010) <00:41:53> ({r_i: None, r_t: [-3186.466 -3186.466 -3186.466], critic_loss: 92.30999755859375, actor_loss: -0.296999990940094, entropy: 0.3140000104904175, eps: 0.001})
Step:  160000, Reward: [-323.867 -323.867 -323.867] [79.694], Avg: [-346.526 -346.526 -346.526] (0.0010) <00:42:01> ({r_i: None, r_t: [-3170.691 -3170.691 -3170.691], critic_loss: 168.16700744628906, actor_loss: 0.1459999978542328, entropy: 0.3529999852180481, eps: 0.001})
Step:  160500, Reward: [-324.077 -324.077 -324.077] [53.230], Avg: [-346.457 -346.457 -346.457] (0.0010) <00:42:08> ({r_i: None, r_t: [-3161.087 -3161.087 -3161.087], critic_loss: 205.40699768066406, actor_loss: 0.07599999755620956, entropy: 0.36899998784065247, eps: 0.001})
Step:  161000, Reward: [-310.212 -310.212 -310.212] [47.227], Avg: [-346.344 -346.344 -346.344] (0.0010) <00:42:16> ({r_i: None, r_t: [-3124.058 -3124.058 -3124.058], critic_loss: 236.60299682617188, actor_loss: 0.05900000035762787, entropy: 0.36399999260902405, eps: 0.001})
Step:  161500, Reward: [-337.483 -337.483 -337.483] [66.365], Avg: [-346.317 -346.317 -346.317] (0.0010) <00:42:25> ({r_i: None, r_t: [-3092.620 -3092.620 -3092.620], critic_loss: 202.5659942626953, actor_loss: 0.37299999594688416, entropy: 0.3440000116825104, eps: 0.001})
Step:  162000, Reward: [-292.244 -292.244 -292.244] [54.157], Avg: [-346.151 -346.151 -346.151] (0.0010) <00:42:33> ({r_i: None, r_t: [-3133.509 -3133.509 -3133.509], critic_loss: 259.8739929199219, actor_loss: -0.46399998664855957, entropy: 0.36899998784065247, eps: 0.001})
Step:  162500, Reward: [-303.302 -303.302 -303.302] [51.007], Avg: [-346.019 -346.019 -346.019] (0.0010) <00:42:41> ({r_i: None, r_t: [-3173.268 -3173.268 -3173.268], critic_loss: 225.3979949951172, actor_loss: -0.49399998784065247, entropy: 0.35199999809265137, eps: 0.001})
Step:  163000, Reward: [-311.837 -311.837 -311.837] [65.413], Avg: [-345.915 -345.915 -345.915] (0.0010) <00:42:49> ({r_i: None, r_t: [-3110.818 -3110.818 -3110.818], critic_loss: 248.24899291992188, actor_loss: 0.21400000154972076, entropy: 0.33500000834465027, eps: 0.001})
Step:  163500, Reward: [-308.209 -308.209 -308.209] [64.560], Avg: [-345.800 -345.800 -345.800] (0.0010) <00:42:57> ({r_i: None, r_t: [-3172.825 -3172.825 -3172.825], critic_loss: 190.07699584960938, actor_loss: 0.35100001096725464, entropy: 0.3499999940395355, eps: 0.001})
Step:  164000, Reward: [-321.025 -321.025 -321.025] [48.001], Avg: [-345.724 -345.724 -345.724] (0.0010) <00:43:06> ({r_i: None, r_t: [-3080.754 -3080.754 -3080.754], critic_loss: 128.7310028076172, actor_loss: 0.3179999887943268, entropy: 0.3160000145435333, eps: 0.001})
Step:  164500, Reward: [-292.595 -292.595 -292.595] [50.531], Avg: [-345.563 -345.563 -345.563] (0.0010) <00:43:14> ({r_i: None, r_t: [-3166.031 -3166.031 -3166.031], critic_loss: 207.70700073242188, actor_loss: -0.257999986410141, entropy: 0.3440000116825104, eps: 0.001})
Step:  165000, Reward: [-330.805 -330.805 -330.805] [48.687], Avg: [-345.519 -345.519 -345.519] (0.0010) <00:43:22> ({r_i: None, r_t: [-3140.723 -3140.723 -3140.723], critic_loss: 150.30799865722656, actor_loss: -0.11800000071525574, entropy: 0.3400000035762787, eps: 0.001})
Step:  165500, Reward: [-299.727 -299.727 -299.727] [33.042], Avg: [-345.381 -345.381 -345.381] (0.0010) <00:43:29> ({r_i: None, r_t: [-3134.908 -3134.908 -3134.908], critic_loss: 186.38900756835938, actor_loss: 0.2980000078678131, entropy: 0.33899998664855957, eps: 0.001})
Step:  166000, Reward: [-296.120 -296.120 -296.120] [36.078], Avg: [-345.233 -345.233 -345.233] (0.0010) <00:43:38> ({r_i: None, r_t: [-3098.379 -3098.379 -3098.379], critic_loss: 140.70399475097656, actor_loss: 0.2070000022649765, entropy: 0.32899999618530273, eps: 0.001})
Step:  166500, Reward: [-305.422 -305.422 -305.422] [49.527], Avg: [-345.114 -345.114 -345.114] (0.0010) <00:43:45> ({r_i: None, r_t: [-3188.176 -3188.176 -3188.176], critic_loss: 119.90599822998047, actor_loss: 0.02199999988079071, entropy: 0.3100000023841858, eps: 0.001})
Step:  167000, Reward: [-309.299 -309.299 -309.299] [51.550], Avg: [-345.007 -345.007 -345.007] (0.0010) <00:43:53> ({r_i: None, r_t: [-3063.770 -3063.770 -3063.770], critic_loss: 153.20599365234375, actor_loss: -0.035999998450279236, entropy: 0.32600000500679016, eps: 0.001})
Step:  167500, Reward: [-317.073 -317.073 -317.073] [47.467], Avg: [-344.924 -344.924 -344.924] (0.0010) <00:44:01> ({r_i: None, r_t: [-3182.239 -3182.239 -3182.239], critic_loss: 141.8820037841797, actor_loss: 0.10899999737739563, entropy: 0.31200000643730164, eps: 0.001})
Step:  168000, Reward: [-310.243 -310.243 -310.243] [62.242], Avg: [-344.821 -344.821 -344.821] (0.0010) <00:44:09> ({r_i: None, r_t: [-3162.475 -3162.475 -3162.475], critic_loss: 190.0590057373047, actor_loss: -0.12700000405311584, entropy: 0.31700000166893005, eps: 0.001})
Step:  168500, Reward: [-324.295 -324.295 -324.295] [66.805], Avg: [-344.760 -344.760 -344.760] (0.0010) <00:44:17> ({r_i: None, r_t: [-3122.580 -3122.580 -3122.580], critic_loss: 163.29200744628906, actor_loss: -0.22499999403953552, entropy: 0.32600000500679016, eps: 0.001})
Step:  169000, Reward: [-313.814 -313.814 -313.814] [52.634], Avg: [-344.669 -344.669 -344.669] (0.0010) <00:44:26> ({r_i: None, r_t: [-3121.083 -3121.083 -3121.083], critic_loss: 143.281005859375, actor_loss: -0.07800000160932541, entropy: 0.3190000057220459, eps: 0.001})
Step:  169500, Reward: [-341.847 -341.847 -341.847] [46.975], Avg: [-344.660 -344.660 -344.660] (0.0010) <00:44:34> ({r_i: None, r_t: [-3094.701 -3094.701 -3094.701], critic_loss: 185.7310028076172, actor_loss: 0.48500001430511475, entropy: 0.3009999990463257, eps: 0.001})
Step:  170000, Reward: [-311.555 -311.555 -311.555] [52.583], Avg: [-344.563 -344.563 -344.563] (0.0010) <00:44:42> ({r_i: None, r_t: [-3244.094 -3244.094 -3244.094], critic_loss: 185.85699462890625, actor_loss: 0.11100000143051147, entropy: 0.3140000104904175, eps: 0.001})
Step:  170500, Reward: [-317.763 -317.763 -317.763] [49.999], Avg: [-344.485 -344.485 -344.485] (0.0010) <00:44:50> ({r_i: None, r_t: [-3136.042 -3136.042 -3136.042], critic_loss: 130.16299438476562, actor_loss: 0.1599999964237213, entropy: 0.30799999833106995, eps: 0.001})
Step:  171000, Reward: [-297.089 -297.089 -297.089] [57.630], Avg: [-344.347 -344.347 -344.347] (0.0010) <00:44:58> ({r_i: None, r_t: [-3164.778 -3164.778 -3164.778], critic_loss: 161.34300231933594, actor_loss: -0.5680000185966492, entropy: 0.3089999854564667, eps: 0.001})
Step:  171500, Reward: [-313.355 -313.355 -313.355] [66.192], Avg: [-344.257 -344.257 -344.257] (0.0010) <00:45:06> ({r_i: None, r_t: [-3175.709 -3175.709 -3175.709], critic_loss: 128.3350067138672, actor_loss: -0.18299999833106995, entropy: 0.31299999356269836, eps: 0.001})
Step:  172000, Reward: [-312.571 -312.571 -312.571] [54.482], Avg: [-344.165 -344.165 -344.165] (0.0010) <00:45:13> ({r_i: None, r_t: [-3111.137 -3111.137 -3111.137], critic_loss: 233.4080047607422, actor_loss: -0.27000001072883606, entropy: 0.32199999690055847, eps: 0.001})
Step:  172500, Reward: [-306.261 -306.261 -306.261] [47.711], Avg: [-344.055 -344.055 -344.055] (0.0010) <00:45:21> ({r_i: None, r_t: [-3086.001 -3086.001 -3086.001], critic_loss: 170.26800537109375, actor_loss: 0.5450000166893005, entropy: 0.30799999833106995, eps: 0.001})
Step:  173000, Reward: [-327.709 -327.709 -327.709] [55.939], Avg: [-344.008 -344.008 -344.008] (0.0010) <00:45:30> ({r_i: None, r_t: [-3142.917 -3142.917 -3142.917], critic_loss: 180.60000610351562, actor_loss: 0.08399999886751175, entropy: 0.3199999928474426, eps: 0.001})
Step:  173500, Reward: [-324.770 -324.770 -324.770] [79.275], Avg: [-343.953 -343.953 -343.953] (0.0010) <00:45:37> ({r_i: None, r_t: [-3098.486 -3098.486 -3098.486], critic_loss: 160.06399536132812, actor_loss: -0.3310000002384186, entropy: 0.3149999976158142, eps: 0.001})
Step:  174000, Reward: [-332.311 -332.311 -332.311] [64.578], Avg: [-343.920 -343.920 -343.920] (0.0010) <00:45:46> ({r_i: None, r_t: [-3149.673 -3149.673 -3149.673], critic_loss: 165.677001953125, actor_loss: 0.16899999976158142, entropy: 0.3149999976158142, eps: 0.001})
Step:  174500, Reward: [-313.125 -313.125 -313.125] [53.054], Avg: [-343.832 -343.832 -343.832] (0.0010) <00:45:54> ({r_i: None, r_t: [-3167.861 -3167.861 -3167.861], critic_loss: 155.16600036621094, actor_loss: -0.07199999690055847, entropy: 0.31700000166893005, eps: 0.001})
Step:  175000, Reward: [-325.061 -325.061 -325.061] [42.640], Avg: [-343.778 -343.778 -343.778] (0.0010) <00:46:02> ({r_i: None, r_t: [-3128.218 -3128.218 -3128.218], critic_loss: 158.42999267578125, actor_loss: -0.2409999966621399, entropy: 0.3149999976158142, eps: 0.001})
Step:  175500, Reward: [-312.050 -312.050 -312.050] [65.723], Avg: [-343.688 -343.688 -343.688] (0.0010) <00:46:10> ({r_i: None, r_t: [-3233.839 -3233.839 -3233.839], critic_loss: 173.4530029296875, actor_loss: 0.12399999797344208, entropy: 0.3230000138282776, eps: 0.001})
Step:  176000, Reward: [-310.890 -310.890 -310.890] [58.888], Avg: [-343.595 -343.595 -343.595] (0.0010) <00:46:19> ({r_i: None, r_t: [-3127.717 -3127.717 -3127.717], critic_loss: 157.9219970703125, actor_loss: -0.017000000923871994, entropy: 0.31200000643730164, eps: 0.001})
Step:  176500, Reward: [-316.341 -316.341 -316.341] [60.723], Avg: [-343.518 -343.518 -343.518] (0.0010) <00:46:26> ({r_i: None, r_t: [-3146.489 -3146.489 -3146.489], critic_loss: 192.33099365234375, actor_loss: 0.09399999678134918, entropy: 0.3109999895095825, eps: 0.001})
Step:  177000, Reward: [-338.126 -338.126 -338.126] [62.630], Avg: [-343.503 -343.503 -343.503] (0.0010) <00:46:35> ({r_i: None, r_t: [-3161.943 -3161.943 -3161.943], critic_loss: 244.447998046875, actor_loss: -0.004999999888241291, entropy: 0.335999995470047, eps: 0.001})
Step:  177500, Reward: [-316.421 -316.421 -316.421] [67.399], Avg: [-343.427 -343.427 -343.427] (0.0010) <00:46:43> ({r_i: None, r_t: [-3136.419 -3136.419 -3136.419], critic_loss: 253.6529998779297, actor_loss: -0.07400000095367432, entropy: 0.3569999933242798, eps: 0.001})
Step:  178000, Reward: [-305.637 -305.637 -305.637] [45.879], Avg: [-343.321 -343.321 -343.321] (0.0010) <00:46:51> ({r_i: None, r_t: [-3081.687 -3081.687 -3081.687], critic_loss: 174.6439971923828, actor_loss: -0.03700000047683716, entropy: 0.3179999887943268, eps: 0.001})
Step:  178500, Reward: [-334.702 -334.702 -334.702] [68.863], Avg: [-343.297 -343.297 -343.297] (0.0010) <00:46:59> ({r_i: None, r_t: [-3119.005 -3119.005 -3119.005], critic_loss: 229.68600463867188, actor_loss: -0.18000000715255737, entropy: 0.3319999873638153, eps: 0.001})
Step:  179000, Reward: [-335.114 -335.114 -335.114] [43.801], Avg: [-343.274 -343.274 -343.274] (0.0010) <00:47:08> ({r_i: None, r_t: [-3112.568 -3112.568 -3112.568], critic_loss: 300.9150085449219, actor_loss: -0.38499999046325684, entropy: 0.33799999952316284, eps: 0.001})
Step:  179500, Reward: [-325.192 -325.192 -325.192] [73.834], Avg: [-343.224 -343.224 -343.224] (0.0010) <00:47:15> ({r_i: None, r_t: [-3165.389 -3165.389 -3165.389], critic_loss: 371.260009765625, actor_loss: 0.7459999918937683, entropy: 0.3230000138282776, eps: 0.001})
Step:  180000, Reward: [-314.110 -314.110 -314.110] [45.079], Avg: [-343.143 -343.143 -343.143] (0.0010) <00:47:24> ({r_i: None, r_t: [-3122.708 -3122.708 -3122.708], critic_loss: 244.24400329589844, actor_loss: -0.061000000685453415, entropy: 0.33799999952316284, eps: 0.001})
Step:  180500, Reward: [-315.800 -315.800 -315.800] [48.276], Avg: [-343.068 -343.068 -343.068] (0.0010) <00:47:31> ({r_i: None, r_t: [-3185.010 -3185.010 -3185.010], critic_loss: 297.55999755859375, actor_loss: 0.17599999904632568, entropy: 0.335999995470047, eps: 0.001})
Step:  181000, Reward: [-298.439 -298.439 -298.439] [47.388], Avg: [-342.945 -342.945 -342.945] (0.0010) <00:47:40> ({r_i: None, r_t: [-3067.007 -3067.007 -3067.007], critic_loss: 355.54901123046875, actor_loss: -0.29600000381469727, entropy: 0.328000009059906, eps: 0.001})
Step:  181500, Reward: [-327.293 -327.293 -327.293] [51.549], Avg: [-342.902 -342.902 -342.902] (0.0010) <00:47:47> ({r_i: None, r_t: [-3016.353 -3016.353 -3016.353], critic_loss: 385.3340148925781, actor_loss: -0.33500000834465027, entropy: 0.3409999907016754, eps: 0.001})
Step:  182000, Reward: [-286.200 -286.200 -286.200] [32.424], Avg: [-342.746 -342.746 -342.746] (0.0010) <00:47:56> ({r_i: None, r_t: [-3108.660 -3108.660 -3108.660], critic_loss: 326.3039855957031, actor_loss: 0.07000000029802322, entropy: 0.3479999899864197, eps: 0.001})
Step:  182500, Reward: [-322.410 -322.410 -322.410] [57.680], Avg: [-342.691 -342.691 -342.691] (0.0010) <00:48:03> ({r_i: None, r_t: [-3176.526 -3176.526 -3176.526], critic_loss: 241.0469970703125, actor_loss: -0.4490000009536743, entropy: 0.3269999921321869, eps: 0.001})
Step:  183000, Reward: [-314.504 -314.504 -314.504] [41.056], Avg: [-342.614 -342.614 -342.614] (0.0010) <00:48:12> ({r_i: None, r_t: [-3161.271 -3161.271 -3161.271], critic_loss: 338.33599853515625, actor_loss: 0.22300000488758087, entropy: 0.3149999976158142, eps: 0.001})
Step:  183500, Reward: [-320.034 -320.034 -320.034] [70.855], Avg: [-342.553 -342.553 -342.553] (0.0010) <00:48:19> ({r_i: None, r_t: [-3147.137 -3147.137 -3147.137], critic_loss: 444.6319885253906, actor_loss: 0.024000000208616257, entropy: 0.2980000078678131, eps: 0.001})
Step:  184000, Reward: [-321.749 -321.749 -321.749] [64.315], Avg: [-342.496 -342.496 -342.496] (0.0010) <00:48:27> ({r_i: None, r_t: [-3148.414 -3148.414 -3148.414], critic_loss: 399.14801025390625, actor_loss: 0.20200000703334808, entropy: 0.3009999990463257, eps: 0.001})
Step:  184500, Reward: [-323.310 -323.310 -323.310] [65.377], Avg: [-342.444 -342.444 -342.444] (0.0010) <00:48:35> ({r_i: None, r_t: [-3115.311 -3115.311 -3115.311], critic_loss: 588.2150268554688, actor_loss: -0.5180000066757202, entropy: 0.289000004529953, eps: 0.001})
Step:  185000, Reward: [-296.540 -296.540 -296.540] [48.094], Avg: [-342.321 -342.321 -342.321] (0.0010) <00:48:43> ({r_i: None, r_t: [-3238.641 -3238.641 -3238.641], critic_loss: 726.85400390625, actor_loss: 0.6430000066757202, entropy: 0.30300000309944153, eps: 0.001})
Step:  185500, Reward: [-309.954 -309.954 -309.954] [68.226], Avg: [-342.234 -342.234 -342.234] (0.0010) <00:48:51> ({r_i: None, r_t: [-3122.586 -3122.586 -3122.586], critic_loss: 328.8450012207031, actor_loss: -0.847000002861023, entropy: 0.2919999957084656, eps: 0.001})
Step:  186000, Reward: [-325.851 -325.851 -325.851] [63.208], Avg: [-342.190 -342.190 -342.190] (0.0010) <00:48:59> ({r_i: None, r_t: [-3115.856 -3115.856 -3115.856], critic_loss: 321.3609924316406, actor_loss: 0.16500000655651093, entropy: 0.2809999883174896, eps: 0.001})
Step:  186500, Reward: [-313.263 -313.263 -313.263] [54.974], Avg: [-342.112 -342.112 -342.112] (0.0010) <00:49:06> ({r_i: None, r_t: [-3144.596 -3144.596 -3144.596], critic_loss: 358.5660095214844, actor_loss: -0.24300000071525574, entropy: 0.2770000100135803, eps: 0.001})
Step:  187000, Reward: [-298.667 -298.667 -298.667] [31.197], Avg: [-341.997 -341.997 -341.997] (0.0010) <00:49:14> ({r_i: None, r_t: [-3227.407 -3227.407 -3227.407], critic_loss: 222.0659942626953, actor_loss: 0.4950000047683716, entropy: 0.25999999046325684, eps: 0.001})
Step:  187500, Reward: [-339.851 -339.851 -339.851] [55.093], Avg: [-341.991 -341.991 -341.991] (0.0010) <00:49:22> ({r_i: None, r_t: [-3116.636 -3116.636 -3116.636], critic_loss: 263.7380065917969, actor_loss: 0.18799999356269836, entropy: 0.2529999911785126, eps: 0.001})
Step:  188000, Reward: [-332.054 -332.054 -332.054] [50.008], Avg: [-341.965 -341.965 -341.965] (0.0010) <00:49:30> ({r_i: None, r_t: [-3145.204 -3145.204 -3145.204], critic_loss: 184.47500610351562, actor_loss: -0.15299999713897705, entropy: 0.2540000081062317, eps: 0.001})
Step:  188500, Reward: [-317.829 -317.829 -317.829] [55.098], Avg: [-341.901 -341.901 -341.901] (0.0010) <00:49:38> ({r_i: None, r_t: [-3127.477 -3127.477 -3127.477], critic_loss: 126.83599853515625, actor_loss: 0.24500000476837158, entropy: 0.24500000476837158, eps: 0.001})
Step:  189000, Reward: [-324.934 -324.934 -324.934] [51.684], Avg: [-341.856 -341.856 -341.856] (0.0010) <00:49:46> ({r_i: None, r_t: [-3158.434 -3158.434 -3158.434], critic_loss: 119.64399719238281, actor_loss: 0.16599999368190765, entropy: 0.2639999985694885, eps: 0.001})
Step:  189500, Reward: [-304.010 -304.010 -304.010] [53.591], Avg: [-341.756 -341.756 -341.756] (0.0010) <00:49:54> ({r_i: None, r_t: [-3184.002 -3184.002 -3184.002], critic_loss: 106.00700378417969, actor_loss: 0.39500001072883606, entropy: 0.25999999046325684, eps: 0.001})
Step:  190000, Reward: [-308.496 -308.496 -308.496] [63.715], Avg: [-341.669 -341.669 -341.669] (0.0010) <00:50:02> ({r_i: None, r_t: [-3162.384 -3162.384 -3162.384], critic_loss: 92.74199676513672, actor_loss: -0.4230000078678131, entropy: 0.25999999046325684, eps: 0.001})
Step:  190500, Reward: [-311.664 -311.664 -311.664] [62.168], Avg: [-341.591 -341.591 -341.591] (0.0010) <00:50:09> ({r_i: None, r_t: [-3145.460 -3145.460 -3145.460], critic_loss: 80.27799987792969, actor_loss: -0.4560000002384186, entropy: 0.2590000033378601, eps: 0.001})
Step:  191000, Reward: [-297.648 -297.648 -297.648] [42.691], Avg: [-341.476 -341.476 -341.476] (0.0010) <00:50:18> ({r_i: None, r_t: [-3161.953 -3161.953 -3161.953], critic_loss: 103.74500274658203, actor_loss: 0.09000000357627869, entropy: 0.24500000476837158, eps: 0.001})
Step:  191500, Reward: [-322.991 -322.991 -322.991] [59.998], Avg: [-341.428 -341.428 -341.428] (0.0010) <00:50:25> ({r_i: None, r_t: [-3195.713 -3195.713 -3195.713], critic_loss: 89.59400177001953, actor_loss: 0.27000001072883606, entropy: 0.25099998712539673, eps: 0.001})
Step:  192000, Reward: [-301.998 -301.998 -301.998] [43.855], Avg: [-341.325 -341.325 -341.325] (0.0010) <00:50:33> ({r_i: None, r_t: [-3229.006 -3229.006 -3229.006], critic_loss: 90.63300323486328, actor_loss: -0.0, entropy: 0.2409999966621399, eps: 0.001})
Step:  192500, Reward: [-323.599 -323.599 -323.599] [43.515], Avg: [-341.279 -341.279 -341.279] (0.0010) <00:50:41> ({r_i: None, r_t: [-3237.287 -3237.287 -3237.287], critic_loss: 97.94599914550781, actor_loss: 0.2460000067949295, entropy: 0.24799999594688416, eps: 0.001})
Step:  193000, Reward: [-297.772 -297.772 -297.772] [50.979], Avg: [-341.167 -341.167 -341.167] (0.0010) <00:50:49> ({r_i: None, r_t: [-3152.155 -3152.155 -3152.155], critic_loss: 83.7030029296875, actor_loss: 0.30799999833106995, entropy: 0.24199999868869781, eps: 0.001})
Step:  193500, Reward: [-313.676 -313.676 -313.676] [45.780], Avg: [-341.096 -341.096 -341.096] (0.0010) <00:50:57> ({r_i: None, r_t: [-3162.301 -3162.301 -3162.301], critic_loss: 78.7490005493164, actor_loss: 0.11299999803304672, entropy: 0.2529999911785126, eps: 0.001})
Step:  194000, Reward: [-322.127 -322.127 -322.127] [51.730], Avg: [-341.047 -341.047 -341.047] (0.0010) <00:51:05> ({r_i: None, r_t: [-3120.677 -3120.677 -3120.677], critic_loss: 89.65499877929688, actor_loss: -0.15199999511241913, entropy: 0.25099998712539673, eps: 0.001})
Step:  194500, Reward: [-346.152 -346.152 -346.152] [70.171], Avg: [-341.060 -341.060 -341.060] (0.0010) <00:51:12> ({r_i: None, r_t: [-3045.859 -3045.859 -3045.859], critic_loss: 80.6240005493164, actor_loss: -0.061000000685453415, entropy: 0.25600001215934753, eps: 0.001})
Step:  195000, Reward: [-337.875 -337.875 -337.875] [68.227], Avg: [-341.052 -341.052 -341.052] (0.0010) <00:51:21> ({r_i: None, r_t: [-3126.942 -3126.942 -3126.942], critic_loss: 83.92900085449219, actor_loss: 0.4189999997615814, entropy: 0.24799999594688416, eps: 0.001})
Step:  195500, Reward: [-307.834 -307.834 -307.834] [64.092], Avg: [-340.967 -340.967 -340.967] (0.0010) <00:51:28> ({r_i: None, r_t: [-3125.577 -3125.577 -3125.577], critic_loss: 70.04199981689453, actor_loss: 0.052000001072883606, entropy: 0.24699999392032623, eps: 0.001})
Step:  196000, Reward: [-312.815 -312.815 -312.815] [39.320], Avg: [-340.896 -340.896 -340.896] (0.0010) <00:51:37> ({r_i: None, r_t: [-3129.592 -3129.592 -3129.592], critic_loss: 78.96099853515625, actor_loss: -0.05400000140070915, entropy: 0.24799999594688416, eps: 0.001})
Step:  196500, Reward: [-319.332 -319.332 -319.332] [64.822], Avg: [-340.841 -340.841 -340.841] (0.0010) <00:51:44> ({r_i: None, r_t: [-3093.763 -3093.763 -3093.763], critic_loss: 64.59200286865234, actor_loss: -0.1809999942779541, entropy: 0.25999999046325684, eps: 0.001})
Step:  197000, Reward: [-298.091 -298.091 -298.091] [56.120], Avg: [-340.733 -340.733 -340.733] (0.0010) <00:51:53> ({r_i: None, r_t: [-3157.089 -3157.089 -3157.089], critic_loss: 75.0510025024414, actor_loss: 0.20000000298023224, entropy: 0.2590000033378601, eps: 0.001})
Step:  197500, Reward: [-307.897 -307.897 -307.897] [62.031], Avg: [-340.650 -340.650 -340.650] (0.0010) <00:52:00> ({r_i: None, r_t: [-3184.261 -3184.261 -3184.261], critic_loss: 66.43900299072266, actor_loss: -0.024000000208616257, entropy: 0.2630000114440918, eps: 0.001})
Step:  198000, Reward: [-332.826 -332.826 -332.826] [50.136], Avg: [-340.630 -340.630 -340.630] (0.0010) <00:52:08> ({r_i: None, r_t: [-3117.228 -3117.228 -3117.228], critic_loss: 72.11699676513672, actor_loss: 0.0860000029206276, entropy: 0.26600000262260437, eps: 0.001})
Step:  198500, Reward: [-300.736 -300.736 -300.736] [46.128], Avg: [-340.530 -340.530 -340.530] (0.0010) <00:52:16> ({r_i: None, r_t: [-3231.757 -3231.757 -3231.757], critic_loss: 83.08300018310547, actor_loss: -0.03500000014901161, entropy: 0.26600000262260437, eps: 0.001})
Step:  199000, Reward: [-338.272 -338.272 -338.272] [52.070], Avg: [-340.524 -340.524 -340.524] (0.0010) <00:52:24> ({r_i: None, r_t: [-3109.302 -3109.302 -3109.302], critic_loss: 69.68499755859375, actor_loss: 0.2070000022649765, entropy: 0.2770000100135803, eps: 0.001})
Step:  199500, Reward: [-323.789 -323.789 -323.789] [50.732], Avg: [-340.483 -340.483 -340.483] (0.0010) <00:52:32> ({r_i: None, r_t: [-3135.511 -3135.511 -3135.511], critic_loss: 80.87000274658203, actor_loss: 0.017999999225139618, entropy: 0.2619999945163727, eps: 0.001})
Step:  200000, Reward: [-298.744 -298.744 -298.744] [52.728], Avg: [-340.378 -340.378 -340.378] (0.0010) <00:52:40> ({r_i: None, r_t: [-3232.786 -3232.786 -3232.786], critic_loss: 91.10800170898438, actor_loss: 0.20399999618530273, entropy: 0.2639999985694885, eps: 0.001})
