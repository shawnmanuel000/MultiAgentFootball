Model: <class 'multiagent.mappo.MAPPOAgent'>, Dir: simple_spread, Date: 14/03/2020 14:33:39
num_envs: 16,
state_size: [(1, 18), (1, 18), (1, 18)],
action_size: [[1, 5], [1, 5], [1, 5]],
action_space: [MultiDiscrete([5]), MultiDiscrete([5]), MultiDiscrete([5])],
envs: <class 'utils.envs.EnsembleEnv'>,
reward_shape: False,
icm: False,

import torch
import numpy as np
from models.ppo import PPONetwork, PPOCritic
from models.rand import MultiagentReplayBuffer
from utils.network import PTNetwork, PTACNetwork, PTACAgent, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, MultiheadAttention, one_hot_from_indices

PPO_EPOCHS = 4					# Number of iterations to sample batches for training
BATCH_SIZE = 16					# Number of samples to train on for each train step
EPISODE_BUFFER = 64  	    	# Sets the maximum length of the replay buffer
CLIP_PARAM = 0.2				# The limit of the ratio of new action probabilities to old probabilities
EPS_MAX = 0.1                 	# The starting weight for the entropy term of the Actor loss
EPS_MIN = 0.001               	# The lower weight for the entropy term of the Actor loss
EPS_DECAY = 0.9             	# The rate at which eps decays from EPS_MAX to EPS_MIN
TIME_BATCHES = 10				# The number of batches of time steps to train critic in reverse time sequence

class MAPPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.action_probs = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		action_probs = self.action_probs(state).softmax(-1)
		dist = torch.distributions.Categorical(action_probs)
		action_in = dist.sample() if action is None else action.argmax(-1)
		action = one_hot_from_indices(action_in, action_probs.size(-1))
		log_prob = dist.log_prob(action_in)
		entropy = dist.entropy()
		return action, log_prob, entropy

class MAPPONetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(gpu=gpu, name="mappo")
		self.critic = PPOCritic([np.sum([np.prod(s) for s in state_size])], [np.sum([np.prod(a) for a in action_size])])
		self.models = [PPONetwork(s_size, a_size, MAPPOActor, lambda s,a: self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(state_size, action_size)]
		if load: self.load_model(load)

	def get_action_probs(self, state, action_in=None, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action_in = [None] * len(state) if action_in is None else action_in
			action_or_entropy, log_prob = map(list, zip(*[model.get_action_probs(s, a, grad=grad, numpy=numpy, sample=sample) for s,a,model in zip(state, action_in, self.models)]))
			return action_or_entropy, log_prob

	def optimize(self, states, actions, states_joint, old_log_probs, rewards, dones, clip_param=CLIP_PARAM, e_weight=EPS_MIN):
		critic_losses = []
		agent = self.models[0]
		next_value = agent.get_value(states_joint)
		next_value = torch.cat([next_value, torch.zeros_like(next_value[:,-1]).unsqueeze(1)], dim=1)
		targets = PTACAgent.compute_ma_gae(rewards[0].unsqueeze(-1), dones[0].unsqueeze(-1), next_value)
		values = torch.zeros_like(targets)
		t_batch = max(rewards[0].size(1)//TIME_BATCHES, 1)
		for t in reversed(range(0,min(rewards[0].size(1), t_batch*TIME_BATCHES),t_batch)):
			values[:,t:t+t_batch] = agent.get_value(states_joint[:,t:t+t_batch], grad=True, numpy=False)
			critic_loss = (values[:,t:t+t_batch] - targets[:,t:t+t_batch].detach()).pow(2).mean()
			critic_losses.append(critic_loss.detach().cpu().numpy())
			agent.step(agent.critic_optimizer, critic_loss, agent.critic_local.parameters(), retain=t>0)	
		advantage = (targets - values).detach()
		
		actor_losses = []
		for model, state, action, old_log_prob in zip(self.models, states, actions, old_log_probs):		
			entropy, new_log_prob = model.get_action_probs(state, action, grad=True, numpy=False)
			ratio = (new_log_prob - old_log_prob).exp()
			ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
			advantage = advantage.view(*advantage.shape, *[1]*(len(ratio.shape)-len(advantage.shape)))
			actor_loss = -(torch.min(ratio*advantage, ratio_clipped*advantage) + e_weight*entropy).mean()
			model.step(model.actor_optimizer, actor_loss, model.actor_local.parameters())
			actor_losses.append([x.detach().cpu().numpy() for x in [actor_loss, entropy]])
		return [np.mean(critic_losses), *np.mean(actor_losses, axis=0)]

	def save_model(self, dirname="pytorch", name="checkpoint"):
		[PTACNetwork.save_model(model, dirname, f"{name}_{i}", self.name) for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="checkpoint"):
		[PTACNetwork.load_model(model, dirname, f"{name}_{i}", self.name) for i,model in enumerate(self.models)]

class MAPPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, eps=EPS_MAX, decay=EPS_DECAY, gpu=True, load=None):
		super().__init__(state_size, action_size, MAPPONetwork, lr=lr, update_freq=update_freq, eps=eps, decay=decay, gpu=gpu, load=load)
		self.replay_buffer = MultiagentReplayBuffer(EPISODE_BUFFER)
		self.stats = []

	def get_action(self, state, eps=None, sample=True, numpy=True):
		action, self.log_prob = self.network.get_action_probs(self.to_tensor(state), numpy=True, sample=sample)
		return action

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, self.log_prob, reward, done))
		if np.any(done[0]):
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			self.replay_buffer.add([self.to_numpy([t.transpose(0,1) for t in x]) for x in (states, actions, [states_joint], log_probs, rewards, dones)])
			self.buffer.clear()
		if len(self.replay_buffer) >= self.replay_buffer.max_steps:
			for _ in range((len(self.replay_buffer)*PPO_EPOCHS)//BATCH_SIZE):
				states, actions, states_joint, log_probs, rewards, dones = self.replay_buffer.sample(BATCH_SIZE, lambda x: torch.Tensor(x).to(self.network.device))
				self.stats.append(self.network.optimize(states, actions, states_joint[0], log_probs, rewards, dones, e_weight=self.eps))
			self.eps = max(self.eps * self.decay, EPS_MIN)
			self.replay_buffer.clear()

	def get_stats(self):
		stats = {k:v for k,v in zip(["critic_loss", "actor_loss", "entropy"], np.mean(self.stats, axis=0))} if len(self.stats)>0 else {}
		self.stats = []
		return {**stats, **super().get_stats()}

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0003           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.001   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 256				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 512				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.998			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.001               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 1000000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.sac import SACAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, DoubleAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv, TrainEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, MPI_SIZE, MPI_RANK
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-3]
# env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False, reward_shape=False):
	if env_name in gym_envs: return TrainEnv(gym.make(env_name))
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	ballr = lambda x,y: (np.maximum if x>0 else np.minimum)(x - np.abs(y)*np.sign(x), 0.5*x)
	reward_fn = lambda obs,reward,eps: [0.1*(ballr(o[0,88], o[0,89]) - o[0,96]) + r for o,r in zip(obs,reward)]
	return FootballTeamEnv(ggym, env_name, reward_fn if reward_shape else None)

def train(model, steps=10000, ports=16, env_name=env_name, trial_at=100, save_at=10, checkpoint=True, save_best=False, log=True, render=False, reward_shape=False, icm=False):
	envs = (EnvManager if type(ports) == list or MPI_SIZE > 1 else EnsembleEnv)(lambda: make_env(env_name, reward_shape=reward_shape), ports)
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, envs.num_envs, load="", gpu=True, agent2=RandomAgent, save_dir=env_name, icm=icm) 
	logger = Logger(model, env_name, num_envs=envs.num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space, envs=type(envs), reward_shape=reward_shape, icm=icm)
	states = envs.reset(train=True)
	total_rewards = []
	for s in range(steps+1):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions, train=True)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if s%trial_at == 0:
			rollouts = rollout(envs, agent, render=render)
			total_rewards.append(np.mean(rollouts, axis=-1))
			save_dir = env_name + "/" +  "_".join(["rs"]*int(reward_shape) + ["icm"]*int(icm))
			if checkpoint and len(total_rewards) % save_at==0: agent.save_model(save_dir, "checkpoint")
			if save_best and np.all(total_rewards[-1] >= np.max(total_rewards, axis=-1)): agent.save_model(env_name)
			if log: logger.log(f"Step: {s:7d}, Reward: {total_rewards[-1]} [{np.std(rollouts):4.3f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.eps:.4f})", agent.get_stats())

def trial(model, env_name, render, reward_shape=False, icm=False):
	envs = EnsembleEnv(lambda: make_env(env_name, log=True, render=render), 1)
	load_dir = env_name + "/" +  "_".join(["rs"]*int(reward_shape) + ["icm"]*int(icm))
	agent = (DoubleAgent if envs.env.self_play else ParallelAgent)(envs.state_size, envs.action_size, model, gpu=False, load=load_dir, agent2=RandomAgent, save_dir=env_name)
	print(f"Reward: {rollout(envs, agent, eps=0.0, render=True)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="coma", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=200000, help="Number of steps to train the agent")
	parser.add_argument("--reward_shape", action="store_true", help="Whether to shape rewards for football")
	parser.add_argument("--icm", action="store_true", help="Whether to use intrinsic motivation")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--trial", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "sac":SACAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent, "rand":RandomAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.selfport is not None or MPI_RANK>0:
		EnvWorker(self_port=args.selfport, make_env=make_env).start()
	elif args.trial:
		trial(model=model, env_name=env_name, render=args.render, reward_shape=args.reward_shape, icm=args.icm)
	else:
		train(model=model, steps=args.steps, ports=args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render, reward_shape=args.reward_shape, icm=args.icm)


Step:       0, Reward: [-498.280 -498.280 -498.280] [88.977], Avg: [-498.280 -498.280 -498.280] (0.1000) <00:00:00> ({r_i: None, r_t: [-9.015 -9.015 -9.015], eps: 0.1})
Step:     100, Reward: [-481.350 -481.350 -481.350] [98.684], Avg: [-489.815 -489.815 -489.815] (0.1000) <00:00:02> ({r_i: None, r_t: [-1029.121 -1029.121 -1029.121], eps: 0.1})
Step:     200, Reward: [-508.915 -508.915 -508.915] [113.618], Avg: [-496.182 -496.182 -496.182] (0.0900) <00:00:05> ({r_i: None, r_t: [-937.575 -937.575 -937.575], critic_loss: 33393.59765625, actor_loss: 24.1560001373291, entropy: 1.5770000219345093, eps: 0.09})
Step:     300, Reward: [-545.518 -545.518 -545.518] [107.314], Avg: [-508.516 -508.516 -508.516] (0.0900) <00:00:08> ({r_i: None, r_t: [-992.074 -992.074 -992.074], eps: 0.09})
Step:     400, Reward: [-486.374 -486.374 -486.374] [104.427], Avg: [-504.087 -504.087 -504.087] (0.0810) <00:00:11> ({r_i: None, r_t: [-1000.390 -1000.390 -1000.390], critic_loss: 77226.9453125, actor_loss: -66.33799743652344, entropy: 1.562999963760376, eps: 0.081})
Step:     500, Reward: [-508.124 -508.124 -508.124] [103.169], Avg: [-504.760 -504.760 -504.760] (0.0810) <00:00:13> ({r_i: None, r_t: [-938.692 -938.692 -938.692], eps: 0.081})
Step:     600, Reward: [-490.844 -490.844 -490.844] [79.496], Avg: [-502.772 -502.772 -502.772] (0.0729) <00:00:17> ({r_i: None, r_t: [-1021.795 -1021.795 -1021.795], critic_loss: 63698.7734375, actor_loss: -74.39800262451172, entropy: 1.5570000410079956, eps: 0.073})
Step:     700, Reward: [-480.519 -480.519 -480.519] [83.612], Avg: [-499.991 -499.991 -499.991] (0.0729) <00:00:19> ({r_i: None, r_t: [-941.049 -941.049 -941.049], eps: 0.073})
Step:     800, Reward: [-454.636 -454.636 -454.636] [98.797], Avg: [-494.951 -494.951 -494.951] (0.0656) <00:00:22> ({r_i: None, r_t: [-963.657 -963.657 -963.657], critic_loss: 51692.45703125, actor_loss: -67.97200012207031, entropy: 1.559000015258789, eps: 0.066})
Step:     900, Reward: [-498.384 -498.384 -498.384] [79.741], Avg: [-495.294 -495.294 -495.294] (0.0656) <00:00:25> ({r_i: None, r_t: [-910.673 -910.673 -910.673], eps: 0.066})
Step:    1000, Reward: [-458.856 -458.856 -458.856] [86.573], Avg: [-491.982 -491.982 -491.982] (0.0590) <00:00:29> ({r_i: None, r_t: [-912.107 -912.107 -912.107], critic_loss: 44162.0859375, actor_loss: -73.41600036621094, entropy: 1.531999945640564, eps: 0.059})
Step:    1100, Reward: [-484.612 -484.612 -484.612] [92.142], Avg: [-491.368 -491.368 -491.368] (0.0590) <00:00:31> ({r_i: None, r_t: [-975.488 -975.488 -975.488], eps: 0.059})
Step:    1200, Reward: [-463.158 -463.158 -463.158] [56.649], Avg: [-489.198 -489.198 -489.198] (0.0531) <00:00:34> ({r_i: None, r_t: [-1029.751 -1029.751 -1029.751], critic_loss: 45968.85546875, actor_loss: -75.58799743652344, entropy: 1.496000051498413, eps: 0.053})
Step:    1300, Reward: [-474.787 -474.787 -474.787] [69.090], Avg: [-488.168 -488.168 -488.168] (0.0531) <00:00:37> ({r_i: None, r_t: [-932.799 -932.799 -932.799], eps: 0.053})
Step:    1400, Reward: [-437.800 -437.800 -437.800] [62.862], Avg: [-484.810 -484.810 -484.810] (0.0478) <00:00:40> ({r_i: None, r_t: [-941.598 -941.598 -941.598], critic_loss: 25311.298828125, actor_loss: -56.96799850463867, entropy: 1.4630000591278076, eps: 0.048})
Step:    1500, Reward: [-446.733 -446.733 -446.733] [96.305], Avg: [-482.431 -482.431 -482.431] (0.0478) <00:00:43> ({r_i: None, r_t: [-924.681 -924.681 -924.681], eps: 0.048})
Step:    1600, Reward: [-507.373 -507.373 -507.373] [113.844], Avg: [-483.898 -483.898 -483.898] (0.0430) <00:00:46> ({r_i: None, r_t: [-933.733 -933.733 -933.733], critic_loss: 17097.048828125, actor_loss: -44.39099884033203, entropy: 1.4520000219345093, eps: 0.043})
Step:    1700, Reward: [-491.567 -491.567 -491.567] [99.533], Avg: [-484.324 -484.324 -484.324] (0.0430) <00:00:48> ({r_i: None, r_t: [-922.884 -922.884 -922.884], eps: 0.043})
Step:    1800, Reward: [-520.062 -520.062 -520.062] [102.913], Avg: [-486.205 -486.205 -486.205] (0.0387) <00:00:52> ({r_i: None, r_t: [-984.883 -984.883 -984.883], critic_loss: 11289.9814453125, actor_loss: -36.518001556396484, entropy: 1.3229999542236328, eps: 0.039})
Step:    1900, Reward: [-547.742 -547.742 -547.742] [154.167], Avg: [-489.282 -489.282 -489.282] (0.0387) <00:00:54> ({r_i: None, r_t: [-1084.640 -1084.640 -1084.640], eps: 0.039})
Step:    2000, Reward: [-496.816 -496.816 -496.816] [67.532], Avg: [-489.640 -489.640 -489.640] (0.0349) <00:00:57> ({r_i: None, r_t: [-976.274 -976.274 -976.274], critic_loss: 11920.93359375, actor_loss: -38.50199890136719, entropy: 1.215000033378601, eps: 0.035})
Step:    2100, Reward: [-494.770 -494.770 -494.770] [58.006], Avg: [-489.874 -489.874 -489.874] (0.0349) <00:01:00> ({r_i: None, r_t: [-970.336 -970.336 -970.336], eps: 0.035})
Step:    2200, Reward: [-445.206 -445.206 -445.206] [79.051], Avg: [-487.932 -487.932 -487.932] (0.0314) <00:01:03> ({r_i: None, r_t: [-943.222 -943.222 -943.222], critic_loss: 9007.9384765625, actor_loss: -33.64899826049805, entropy: 1.0750000476837158, eps: 0.031})
Step:    2300, Reward: [-469.490 -469.490 -469.490] [115.559], Avg: [-487.163 -487.163 -487.163] (0.0314) <00:01:05> ({r_i: None, r_t: [-961.334 -961.334 -961.334], eps: 0.031})
Step:    2400, Reward: [-473.380 -473.380 -473.380] [54.353], Avg: [-486.612 -486.612 -486.612] (0.0282) <00:01:09> ({r_i: None, r_t: [-972.607 -972.607 -972.607], critic_loss: 9130.0302734375, actor_loss: -35.63999938964844, entropy: 1.0010000467300415, eps: 0.028})
Step:    2500, Reward: [-475.934 -475.934 -475.934] [92.874], Avg: [-486.201 -486.201 -486.201] (0.0282) <00:01:11> ({r_i: None, r_t: [-947.489 -947.489 -947.489], eps: 0.028})
Step:    2600, Reward: [-481.373 -481.373 -481.373] [81.526], Avg: [-486.022 -486.022 -486.022] (0.0254) <00:01:14> ({r_i: None, r_t: [-941.615 -941.615 -941.615], critic_loss: 6754.6572265625, actor_loss: -31.070999145507812, entropy: 0.7699999809265137, eps: 0.025})
Step:    2700, Reward: [-457.943 -457.943 -457.943] [79.908], Avg: [-485.020 -485.020 -485.020] (0.0254) <00:01:17> ({r_i: None, r_t: [-928.929 -928.929 -928.929], eps: 0.025})
Step:    2800, Reward: [-459.340 -459.340 -459.340] [81.865], Avg: [-484.134 -484.134 -484.134] (0.0229) <00:01:20> ({r_i: None, r_t: [-950.404 -950.404 -950.404], critic_loss: 6097.31494140625, actor_loss: -26.68000030517578, entropy: 0.7319999933242798, eps: 0.023})
Step:    2900, Reward: [-426.838 -426.838 -426.838] [73.891], Avg: [-482.224 -482.224 -482.224] (0.0229) <00:01:22> ({r_i: None, r_t: [-933.503 -933.503 -933.503], eps: 0.023})
Step:    3000, Reward: [-487.815 -487.815 -487.815] [89.085], Avg: [-482.405 -482.405 -482.405] (0.0206) <00:01:26> ({r_i: None, r_t: [-927.463 -927.463 -927.463], critic_loss: 3787.695068359375, actor_loss: -18.14299964904785, entropy: 0.6570000052452087, eps: 0.021})
Step:    3100, Reward: [-457.537 -457.537 -457.537] [64.067], Avg: [-481.627 -481.627 -481.627] (0.0206) <00:01:28> ({r_i: None, r_t: [-872.690 -872.690 -872.690], eps: 0.021})
Step:    3200, Reward: [-466.017 -466.017 -466.017] [81.679], Avg: [-481.154 -481.154 -481.154] (0.0185) <00:01:31> ({r_i: None, r_t: [-886.162 -886.162 -886.162], critic_loss: 3331.2041015625, actor_loss: -17.49799919128418, entropy: 0.6370000243186951, eps: 0.019})
Step:    3300, Reward: [-433.155 -433.155 -433.155] [81.589], Avg: [-479.743 -479.743 -479.743] (0.0185) <00:01:34> ({r_i: None, r_t: [-900.823 -900.823 -900.823], eps: 0.019})
Step:    3400, Reward: [-441.349 -441.349 -441.349] [98.110], Avg: [-478.646 -478.646 -478.646] (0.0167) <00:01:37> ({r_i: None, r_t: [-905.017 -905.017 -905.017], critic_loss: 2525.56201171875, actor_loss: -10.468999862670898, entropy: 0.6100000143051147, eps: 0.017})
Step:    3500, Reward: [-469.874 -469.874 -469.874] [85.862], Avg: [-478.402 -478.402 -478.402] (0.0167) <00:01:40> ({r_i: None, r_t: [-905.751 -905.751 -905.751], eps: 0.017})
Step:    3600, Reward: [-439.187 -439.187 -439.187] [50.804], Avg: [-477.342 -477.342 -477.342] (0.0150) <00:01:43> ({r_i: None, r_t: [-888.175 -888.175 -888.175], critic_loss: 2383.926025390625, actor_loss: -13.409000396728516, entropy: 0.550000011920929, eps: 0.015})
Step:    3700, Reward: [-470.155 -470.155 -470.155] [78.165], Avg: [-477.153 -477.153 -477.153] (0.0150) <00:01:46> ({r_i: None, r_t: [-916.954 -916.954 -916.954], eps: 0.015})
Step:    3800, Reward: [-477.266 -477.266 -477.266] [76.735], Avg: [-477.156 -477.156 -477.156] (0.0135) <00:01:49> ({r_i: None, r_t: [-889.874 -889.874 -889.874], critic_loss: 2294.693115234375, actor_loss: -14.166999816894531, entropy: 0.5669999718666077, eps: 0.014})
Step:    3900, Reward: [-437.832 -437.832 -437.832] [54.258], Avg: [-476.173 -476.173 -476.173] (0.0135) <00:01:51> ({r_i: None, r_t: [-921.149 -921.149 -921.149], eps: 0.014})
Step:    4000, Reward: [-414.385 -414.385 -414.385] [49.682], Avg: [-474.666 -474.666 -474.666] (0.0122) <00:01:55> ({r_i: None, r_t: [-886.758 -886.758 -886.758], critic_loss: 1622.3199462890625, actor_loss: -6.0320000648498535, entropy: 0.5440000295639038, eps: 0.012})
Step:    4100, Reward: [-432.686 -432.686 -432.686] [83.115], Avg: [-473.666 -473.666 -473.666] (0.0122) <00:01:57> ({r_i: None, r_t: [-896.465 -896.465 -896.465], eps: 0.012})
Step:    4200, Reward: [-465.388 -465.388 -465.388] [86.559], Avg: [-473.474 -473.474 -473.474] (0.0109) <00:02:00> ({r_i: None, r_t: [-899.657 -899.657 -899.657], critic_loss: 1297.95703125, actor_loss: -5.9670000076293945, entropy: 0.5659999847412109, eps: 0.011})
Step:    4300, Reward: [-461.916 -461.916 -461.916] [57.976], Avg: [-473.211 -473.211 -473.211] (0.0109) <00:02:02> ({r_i: None, r_t: [-863.008 -863.008 -863.008], eps: 0.011})
Step:    4400, Reward: [-459.838 -459.838 -459.838] [75.801], Avg: [-472.914 -472.914 -472.914] (0.0098) <00:02:06> ({r_i: None, r_t: [-910.170 -910.170 -910.170], critic_loss: 1874.3719482421875, actor_loss: -10.579000473022461, entropy: 0.5289999842643738, eps: 0.01})
Step:    4500, Reward: [-442.153 -442.153 -442.153] [52.960], Avg: [-472.245 -472.245 -472.245] (0.0098) <00:02:08> ({r_i: None, r_t: [-835.240 -835.240 -835.240], eps: 0.01})
Step:    4600, Reward: [-415.678 -415.678 -415.678] [71.465], Avg: [-471.042 -471.042 -471.042] (0.0089) <00:02:12> ({r_i: None, r_t: [-874.799 -874.799 -874.799], critic_loss: 1609.592041015625, actor_loss: -8.850000381469727, entropy: 0.5329999923706055, eps: 0.009})
Step:    4700, Reward: [-420.457 -420.457 -420.457] [58.180], Avg: [-469.988 -469.988 -469.988] (0.0089) <00:02:14> ({r_i: None, r_t: [-921.755 -921.755 -921.755], eps: 0.009})
Step:    4800, Reward: [-395.781 -395.781 -395.781] [75.041], Avg: [-468.473 -468.473 -468.473] (0.0080) <00:02:18> ({r_i: None, r_t: [-847.400 -847.400 -847.400], critic_loss: 1076.5350341796875, actor_loss: -4.26800012588501, entropy: 0.5210000276565552, eps: 0.008})
Step:    4900, Reward: [-378.303 -378.303 -378.303] [60.611], Avg: [-466.670 -466.670 -466.670] (0.0080) <00:02:20> ({r_i: None, r_t: [-884.635 -884.635 -884.635], eps: 0.008})
Step:    5000, Reward: [-415.097 -415.097 -415.097] [45.780], Avg: [-465.659 -465.659 -465.659] (0.0072) <00:02:24> ({r_i: None, r_t: [-845.756 -845.756 -845.756], critic_loss: 1137.0770263671875, actor_loss: -2.5209999084472656, entropy: 0.527999997138977, eps: 0.007})
Step:    5100, Reward: [-410.104 -410.104 -410.104] [61.684], Avg: [-464.590 -464.590 -464.590] (0.0072) <00:02:26> ({r_i: None, r_t: [-894.116 -894.116 -894.116], eps: 0.007})
Step:    5200, Reward: [-419.176 -419.176 -419.176] [64.482], Avg: [-463.733 -463.733 -463.733] (0.0065) <00:02:29> ({r_i: None, r_t: [-880.030 -880.030 -880.030], critic_loss: 1065.041015625, actor_loss: -4.97599983215332, entropy: 0.5379999876022339, eps: 0.006})
Step:    5300, Reward: [-457.966 -457.966 -457.966] [65.214], Avg: [-463.627 -463.627 -463.627] (0.0065) <00:02:32> ({r_i: None, r_t: [-863.692 -863.692 -863.692], eps: 0.006})
Step:    5400, Reward: [-433.827 -433.827 -433.827] [74.180], Avg: [-463.085 -463.085 -463.085] (0.0058) <00:02:35> ({r_i: None, r_t: [-880.345 -880.345 -880.345], critic_loss: 1852.3160400390625, actor_loss: -7.807000160217285, entropy: 0.5389999747276306, eps: 0.006})
Step:    5500, Reward: [-432.167 -432.167 -432.167] [71.736], Avg: [-462.533 -462.533 -462.533] (0.0058) <00:02:37> ({r_i: None, r_t: [-892.070 -892.070 -892.070], eps: 0.006})
Step:    5600, Reward: [-447.215 -447.215 -447.215] [56.734], Avg: [-462.264 -462.264 -462.264] (0.0052) <00:02:41> ({r_i: None, r_t: [-903.470 -903.470 -903.470], critic_loss: 2053.924072265625, actor_loss: -12.25, entropy: 0.5260000228881836, eps: 0.005})
Step:    5700, Reward: [-436.748 -436.748 -436.748] [78.725], Avg: [-461.824 -461.824 -461.824] (0.0052) <00:02:43> ({r_i: None, r_t: [-863.915 -863.915 -863.915], eps: 0.005})
Step:    5800, Reward: [-444.594 -444.594 -444.594] [75.328], Avg: [-461.532 -461.532 -461.532] (0.0047) <00:02:46> ({r_i: None, r_t: [-887.356 -887.356 -887.356], critic_loss: 1103.2230224609375, actor_loss: -6.585999965667725, entropy: 0.5139999985694885, eps: 0.005})
Step:    5900, Reward: [-406.329 -406.329 -406.329] [59.904], Avg: [-460.612 -460.612 -460.612] (0.0047) <00:02:49> ({r_i: None, r_t: [-856.555 -856.555 -856.555], eps: 0.005})
Step:    6000, Reward: [-393.140 -393.140 -393.140] [78.284], Avg: [-459.506 -459.506 -459.506] (0.0042) <00:02:52> ({r_i: None, r_t: [-855.042 -855.042 -855.042], critic_loss: 920.6170043945312, actor_loss: -5.910999774932861, entropy: 0.5099999904632568, eps: 0.004})
Step:    6100, Reward: [-448.764 -448.764 -448.764] [66.263], Avg: [-459.333 -459.333 -459.333] (0.0042) <00:02:55> ({r_i: None, r_t: [-858.258 -858.258 -858.258], eps: 0.004})
Step:    6200, Reward: [-423.796 -423.796 -423.796] [70.278], Avg: [-458.769 -458.769 -458.769] (0.0038) <00:02:58> ({r_i: None, r_t: [-839.701 -839.701 -839.701], critic_loss: 945.89501953125, actor_loss: -1.996999979019165, entropy: 0.4860000014305115, eps: 0.004})
Step:    6300, Reward: [-431.488 -431.488 -431.488] [54.480], Avg: [-458.342 -458.342 -458.342] (0.0038) <00:03:00> ({r_i: None, r_t: [-830.073 -830.073 -830.073], eps: 0.004})
Step:    6400, Reward: [-439.549 -439.549 -439.549] [55.944], Avg: [-458.053 -458.053 -458.053] (0.0034) <00:03:04> ({r_i: None, r_t: [-887.898 -887.898 -887.898], critic_loss: 1191.614990234375, actor_loss: -4.538000106811523, entropy: 0.49000000953674316, eps: 0.003})
Step:    6500, Reward: [-436.318 -436.318 -436.318] [63.605], Avg: [-457.724 -457.724 -457.724] (0.0034) <00:03:06> ({r_i: None, r_t: [-831.434 -831.434 -831.434], eps: 0.003})
Step:    6600, Reward: [-417.543 -417.543 -417.543] [76.604], Avg: [-457.124 -457.124 -457.124] (0.0031) <00:03:09> ({r_i: None, r_t: [-857.462 -857.462 -857.462], critic_loss: 1073.362060546875, actor_loss: -5.74399995803833, entropy: 0.4749999940395355, eps: 0.003})
Step:    6700, Reward: [-404.795 -404.795 -404.795] [63.362], Avg: [-456.355 -456.355 -456.355] (0.0031) <00:03:11> ({r_i: None, r_t: [-848.193 -848.193 -848.193], eps: 0.003})
Step:    6800, Reward: [-426.766 -426.766 -426.766] [40.464], Avg: [-455.926 -455.926 -455.926] (0.0028) <00:03:15> ({r_i: None, r_t: [-824.203 -824.203 -824.203], critic_loss: 1078.7669677734375, actor_loss: -2.319000005722046, entropy: 0.4869999885559082, eps: 0.003})
Step:    6900, Reward: [-430.994 -430.994 -430.994] [81.512], Avg: [-455.570 -455.570 -455.570] (0.0028) <00:03:17> ({r_i: None, r_t: [-851.133 -851.133 -851.133], eps: 0.003})
Step:    7000, Reward: [-416.122 -416.122 -416.122] [54.937], Avg: [-455.014 -455.014 -455.014] (0.0025) <00:03:20> ({r_i: None, r_t: [-865.181 -865.181 -865.181], critic_loss: 967.0369873046875, actor_loss: -1.9220000505447388, entropy: 0.492000013589859, eps: 0.003})
Step:    7100, Reward: [-426.947 -426.947 -426.947] [66.732], Avg: [-454.624 -454.624 -454.624] (0.0025) <00:03:23> ({r_i: None, r_t: [-866.164 -866.164 -866.164], eps: 0.003})
Step:    7200, Reward: [-438.698 -438.698 -438.698] [63.289], Avg: [-454.406 -454.406 -454.406] (0.0023) <00:03:26> ({r_i: None, r_t: [-847.523 -847.523 -847.523], critic_loss: 1322.802978515625, actor_loss: -7.631999969482422, entropy: 0.492000013589859, eps: 0.002})
Step:    7300, Reward: [-414.505 -414.505 -414.505] [61.945], Avg: [-453.867 -453.867 -453.867] (0.0023) <00:03:28> ({r_i: None, r_t: [-852.008 -852.008 -852.008], eps: 0.002})
Step:    7400, Reward: [-435.310 -435.310 -435.310] [72.233], Avg: [-453.619 -453.619 -453.619] (0.0020) <00:03:32> ({r_i: None, r_t: [-837.512 -837.512 -837.512], critic_loss: 830.7869873046875, actor_loss: -2.364000082015991, entropy: 0.4909999966621399, eps: 0.002})
Step:    7500, Reward: [-415.987 -415.987 -415.987] [74.839], Avg: [-453.124 -453.124 -453.124] (0.0020) <00:03:34> ({r_i: None, r_t: [-841.522 -841.522 -841.522], eps: 0.002})
Step:    7600, Reward: [-422.923 -422.923 -422.923] [67.656], Avg: [-452.732 -452.732 -452.732] (0.0018) <00:03:37> ({r_i: None, r_t: [-883.660 -883.660 -883.660], critic_loss: 848.1920166015625, actor_loss: -2.315000057220459, entropy: 0.4819999933242798, eps: 0.002})
Step:    7700, Reward: [-408.604 -408.604 -408.604] [38.458], Avg: [-452.166 -452.166 -452.166] (0.0018) <00:03:40> ({r_i: None, r_t: [-822.682 -822.682 -822.682], eps: 0.002})
Step:    7800, Reward: [-396.532 -396.532 -396.532] [55.104], Avg: [-451.462 -451.462 -451.462] (0.0016) <00:03:43> ({r_i: None, r_t: [-822.480 -822.480 -822.480], critic_loss: 758.301025390625, actor_loss: -0.5299999713897705, entropy: 0.4950000047683716, eps: 0.002})
Step:    7900, Reward: [-404.941 -404.941 -404.941] [53.352], Avg: [-450.881 -450.881 -450.881] (0.0016) <00:03:45> ({r_i: None, r_t: [-838.956 -838.956 -838.956], eps: 0.002})
Step:    8000, Reward: [-423.030 -423.030 -423.030] [53.493], Avg: [-450.537 -450.537 -450.537] (0.0015) <00:03:49> ({r_i: None, r_t: [-815.429 -815.429 -815.429], critic_loss: 620.0180053710938, actor_loss: -0.8510000109672546, entropy: 0.4860000014305115, eps: 0.001})
Step:    8100, Reward: [-436.325 -436.325 -436.325] [63.404], Avg: [-450.363 -450.363 -450.363] (0.0015) <00:03:51> ({r_i: None, r_t: [-841.411 -841.411 -841.411], eps: 0.001})
Step:    8200, Reward: [-403.548 -403.548 -403.548] [55.863], Avg: [-449.799 -449.799 -449.799] (0.0013) <00:03:55> ({r_i: None, r_t: [-817.809 -817.809 -817.809], critic_loss: 1028.7869873046875, actor_loss: -6.551000118255615, entropy: 0.492000013589859, eps: 0.001})
Step:    8300, Reward: [-442.493 -442.493 -442.493] [51.601], Avg: [-449.712 -449.712 -449.712] (0.0013) <00:03:57> ({r_i: None, r_t: [-874.830 -874.830 -874.830], eps: 0.001})
Step:    8400, Reward: [-423.702 -423.702 -423.702] [68.477], Avg: [-449.406 -449.406 -449.406] (0.0012) <00:04:00> ({r_i: None, r_t: [-828.058 -828.058 -828.058], critic_loss: 720.864990234375, actor_loss: -0.8849999904632568, entropy: 0.4950000047683716, eps: 0.001})
Step:    8500, Reward: [-423.871 -423.871 -423.871] [55.777], Avg: [-449.109 -449.109 -449.109] (0.0012) <00:04:03> ({r_i: None, r_t: [-845.994 -845.994 -845.994], eps: 0.001})
Step:    8600, Reward: [-414.630 -414.630 -414.630] [41.936], Avg: [-448.713 -448.713 -448.713] (0.0011) <00:04:06> ({r_i: None, r_t: [-852.856 -852.856 -852.856], critic_loss: 715.8280029296875, actor_loss: -0.5370000004768372, entropy: 0.5019999742507935, eps: 0.001})
Step:    8700, Reward: [-431.472 -431.472 -431.472] [53.499], Avg: [-448.517 -448.517 -448.517] (0.0011) <00:04:08> ({r_i: None, r_t: [-826.521 -826.521 -826.521], eps: 0.001})
Step:    8800, Reward: [-410.481 -410.481 -410.481] [54.250], Avg: [-448.090 -448.090 -448.090] (0.0010) <00:04:12> ({r_i: None, r_t: [-857.775 -857.775 -857.775], critic_loss: 1228.738037109375, actor_loss: -8.24899959564209, entropy: 0.4779999852180481, eps: 0.001})
Step:    8900, Reward: [-434.077 -434.077 -434.077] [54.555], Avg: [-447.934 -447.934 -447.934] (0.0010) <00:04:14> ({r_i: None, r_t: [-859.207 -859.207 -859.207], eps: 0.001})
Step:    9000, Reward: [-433.086 -433.086 -433.086] [58.717], Avg: [-447.771 -447.771 -447.771] (0.0010) <00:04:18> ({r_i: None, r_t: [-857.802 -857.802 -857.802], critic_loss: 811.5830078125, actor_loss: -0.9390000104904175, entropy: 0.45899999141693115, eps: 0.001})
Step:    9100, Reward: [-400.466 -400.466 -400.466] [69.499], Avg: [-447.257 -447.257 -447.257] (0.0010) <00:04:20> ({r_i: None, r_t: [-846.731 -846.731 -846.731], eps: 0.001})
Step:    9200, Reward: [-423.192 -423.192 -423.192] [69.029], Avg: [-446.998 -446.998 -446.998] (0.0010) <00:04:23> ({r_i: None, r_t: [-787.475 -787.475 -787.475], critic_loss: 842.0369873046875, actor_loss: -2.75, entropy: 0.4950000047683716, eps: 0.001})
Step:    9300, Reward: [-407.505 -407.505 -407.505] [63.397], Avg: [-446.578 -446.578 -446.578] (0.0010) <00:04:25> ({r_i: None, r_t: [-821.351 -821.351 -821.351], eps: 0.001})
Step:    9400, Reward: [-438.238 -438.238 -438.238] [74.080], Avg: [-446.490 -446.490 -446.490] (0.0010) <00:04:29> ({r_i: None, r_t: [-840.782 -840.782 -840.782], critic_loss: 857.4140014648438, actor_loss: -7.321000099182129, entropy: 0.4650000035762787, eps: 0.001})
Step:    9500, Reward: [-427.963 -427.963 -427.963] [60.969], Avg: [-446.297 -446.297 -446.297] (0.0010) <00:04:31> ({r_i: None, r_t: [-818.954 -818.954 -818.954], eps: 0.001})
Step:    9600, Reward: [-413.671 -413.671 -413.671] [55.548], Avg: [-445.961 -445.961 -445.961] (0.0010) <00:04:34> ({r_i: None, r_t: [-848.759 -848.759 -848.759], critic_loss: 829.5560302734375, actor_loss: -2.9600000381469727, entropy: 0.49000000953674316, eps: 0.001})
Step:    9700, Reward: [-416.878 -416.878 -416.878] [58.296], Avg: [-445.664 -445.664 -445.664] (0.0010) <00:04:36> ({r_i: None, r_t: [-826.896 -826.896 -826.896], eps: 0.001})
Step:    9800, Reward: [-420.365 -420.365 -420.365] [53.685], Avg: [-445.408 -445.408 -445.408] (0.0010) <00:04:40> ({r_i: None, r_t: [-833.000 -833.000 -833.000], critic_loss: 945.1539916992188, actor_loss: -4.2820000648498535, entropy: 0.46399998664855957, eps: 0.001})
Step:    9900, Reward: [-434.504 -434.504 -434.504] [75.894], Avg: [-445.299 -445.299 -445.299] (0.0010) <00:04:43> ({r_i: None, r_t: [-829.118 -829.118 -829.118], eps: 0.001})
Step:   10000, Reward: [-435.425 -435.425 -435.425] [64.337], Avg: [-445.202 -445.202 -445.202] (0.0010) <00:04:46> ({r_i: None, r_t: [-807.018 -807.018 -807.018], critic_loss: 889.7990112304688, actor_loss: -5.011000156402588, entropy: 0.4740000069141388, eps: 0.001})
Step:   10100, Reward: [-441.086 -441.086 -441.086] [61.233], Avg: [-445.161 -445.161 -445.161] (0.0010) <00:04:48> ({r_i: None, r_t: [-844.010 -844.010 -844.010], eps: 0.001})
Step:   10200, Reward: [-391.044 -391.044 -391.044] [60.002], Avg: [-444.636 -444.636 -444.636] (0.0010) <00:04:52> ({r_i: None, r_t: [-822.280 -822.280 -822.280], critic_loss: 661.4420166015625, actor_loss: -1.6100000143051147, entropy: 0.46799999475479126, eps: 0.001})
Step:   10300, Reward: [-405.883 -405.883 -405.883] [61.109], Avg: [-444.263 -444.263 -444.263] (0.0010) <00:04:54> ({r_i: None, r_t: [-815.847 -815.847 -815.847], eps: 0.001})
Step:   10400, Reward: [-429.411 -429.411 -429.411] [62.863], Avg: [-444.122 -444.122 -444.122] (0.0010) <00:04:57> ({r_i: None, r_t: [-820.919 -820.919 -820.919], critic_loss: 661.781982421875, actor_loss: -5.206999778747559, entropy: 0.46000000834465027, eps: 0.001})
Step:   10500, Reward: [-435.499 -435.499 -435.499] [72.703], Avg: [-444.040 -444.040 -444.040] (0.0010) <00:05:00> ({r_i: None, r_t: [-835.917 -835.917 -835.917], eps: 0.001})
Step:   10600, Reward: [-412.906 -412.906 -412.906] [64.752], Avg: [-443.749 -443.749 -443.749] (0.0010) <00:05:03> ({r_i: None, r_t: [-873.356 -873.356 -873.356], critic_loss: 1169.0849609375, actor_loss: -7.559999942779541, entropy: 0.41999998688697815, eps: 0.001})
Step:   10700, Reward: [-415.362 -415.362 -415.362] [62.365], Avg: [-443.487 -443.487 -443.487] (0.0010) <00:05:05> ({r_i: None, r_t: [-839.380 -839.380 -839.380], eps: 0.001})
Step:   10800, Reward: [-404.307 -404.307 -404.307] [41.503], Avg: [-443.127 -443.127 -443.127] (0.0010) <00:05:09> ({r_i: None, r_t: [-826.699 -826.699 -826.699], critic_loss: 648.844970703125, actor_loss: -0.9789999723434448, entropy: 0.4440000057220459, eps: 0.001})
Step:   10900, Reward: [-408.758 -408.758 -408.758] [53.305], Avg: [-442.815 -442.815 -442.815] (0.0010) <00:05:11> ({r_i: None, r_t: [-861.795 -861.795 -861.795], eps: 0.001})
Step:   11000, Reward: [-411.522 -411.522 -411.522] [67.212], Avg: [-442.533 -442.533 -442.533] (0.0010) <00:05:15> ({r_i: None, r_t: [-843.587 -843.587 -843.587], critic_loss: 925.8930053710938, actor_loss: -5.454999923706055, entropy: 0.42899999022483826, eps: 0.001})
Step:   11100, Reward: [-403.522 -403.522 -403.522] [74.592], Avg: [-442.185 -442.185 -442.185] (0.0010) <00:05:17> ({r_i: None, r_t: [-850.587 -850.587 -850.587], eps: 0.001})
Step:   11200, Reward: [-436.057 -436.057 -436.057] [45.866], Avg: [-442.130 -442.130 -442.130] (0.0010) <00:05:20> ({r_i: None, r_t: [-785.858 -785.858 -785.858], critic_loss: 776.4710083007812, actor_loss: -4.302999973297119, entropy: 0.414000004529953, eps: 0.001})
Step:   11300, Reward: [-398.852 -398.852 -398.852] [58.444], Avg: [-441.751 -441.751 -441.751] (0.0010) <00:05:23> ({r_i: None, r_t: [-823.870 -823.870 -823.870], eps: 0.001})
Step:   11400, Reward: [-396.546 -396.546 -396.546] [70.146], Avg: [-441.358 -441.358 -441.358] (0.0010) <00:05:26> ({r_i: None, r_t: [-854.518 -854.518 -854.518], critic_loss: 718.1669921875, actor_loss: -0.1860000044107437, entropy: 0.41999998688697815, eps: 0.001})
Step:   11500, Reward: [-427.653 -427.653 -427.653] [70.660], Avg: [-441.239 -441.239 -441.239] (0.0010) <00:05:28> ({r_i: None, r_t: [-816.625 -816.625 -816.625], eps: 0.001})
Step:   11600, Reward: [-413.752 -413.752 -413.752] [58.648], Avg: [-441.005 -441.005 -441.005] (0.0010) <00:05:32> ({r_i: None, r_t: [-852.306 -852.306 -852.306], critic_loss: 659.4299926757812, actor_loss: -2.365999937057495, entropy: 0.4269999861717224, eps: 0.001})
Step:   11700, Reward: [-402.747 -402.747 -402.747] [73.441], Avg: [-440.680 -440.680 -440.680] (0.0010) <00:05:34> ({r_i: None, r_t: [-827.222 -827.222 -827.222], eps: 0.001})
Step:   11800, Reward: [-435.259 -435.259 -435.259] [72.820], Avg: [-440.635 -440.635 -440.635] (0.0010) <00:05:37> ({r_i: None, r_t: [-852.777 -852.777 -852.777], critic_loss: 720.7890014648438, actor_loss: -3.1019999980926514, entropy: 0.4189999997615814, eps: 0.001})
Step:   11900, Reward: [-403.155 -403.155 -403.155] [54.904], Avg: [-440.322 -440.322 -440.322] (0.0010) <00:05:40> ({r_i: None, r_t: [-836.317 -836.317 -836.317], eps: 0.001})
Step:   12000, Reward: [-432.665 -432.665 -432.665] [73.301], Avg: [-440.259 -440.259 -440.259] (0.0010) <00:05:43> ({r_i: None, r_t: [-826.474 -826.474 -826.474], critic_loss: 728.9940185546875, actor_loss: -3.992000102996826, entropy: 0.4230000078678131, eps: 0.001})
Step:   12100, Reward: [-425.767 -425.767 -425.767] [59.383], Avg: [-440.140 -440.140 -440.140] (0.0010) <00:05:45> ({r_i: None, r_t: [-864.132 -864.132 -864.132], eps: 0.001})
Step:   12200, Reward: [-416.965 -416.965 -416.965] [52.778], Avg: [-439.952 -439.952 -439.952] (0.0010) <00:05:48> ({r_i: None, r_t: [-826.208 -826.208 -826.208], critic_loss: 1007.1019897460938, actor_loss: -5.51200008392334, entropy: 0.41200000047683716, eps: 0.001})
Step:   12300, Reward: [-414.465 -414.465 -414.465] [54.939], Avg: [-439.746 -439.746 -439.746] (0.0010) <00:05:50> ({r_i: None, r_t: [-825.475 -825.475 -825.475], eps: 0.001})
Step:   12400, Reward: [-404.591 -404.591 -404.591] [55.562], Avg: [-439.465 -439.465 -439.465] (0.0010) <00:05:54> ({r_i: None, r_t: [-823.882 -823.882 -823.882], critic_loss: 771.3300170898438, actor_loss: -4.190999984741211, entropy: 0.41999998688697815, eps: 0.001})
Step:   12500, Reward: [-425.282 -425.282 -425.282] [60.001], Avg: [-439.353 -439.353 -439.353] (0.0010) <00:05:56> ({r_i: None, r_t: [-800.690 -800.690 -800.690], eps: 0.001})
Step:   12600, Reward: [-424.441 -424.441 -424.441] [67.092], Avg: [-439.235 -439.235 -439.235] (0.0010) <00:05:59> ({r_i: None, r_t: [-832.547 -832.547 -832.547], critic_loss: 688.3460083007812, actor_loss: -1.6510000228881836, entropy: 0.414000004529953, eps: 0.001})
Step:   12700, Reward: [-421.636 -421.636 -421.636] [71.879], Avg: [-439.098 -439.098 -439.098] (0.0010) <00:06:02> ({r_i: None, r_t: [-863.375 -863.375 -863.375], eps: 0.001})
Step:   12800, Reward: [-426.062 -426.062 -426.062] [54.999], Avg: [-438.997 -438.997 -438.997] (0.0010) <00:06:05> ({r_i: None, r_t: [-825.629 -825.629 -825.629], critic_loss: 648.2219848632812, actor_loss: -3.484999895095825, entropy: 0.38999998569488525, eps: 0.001})
Step:   12900, Reward: [-381.806 -381.806 -381.806] [60.938], Avg: [-438.557 -438.557 -438.557] (0.0010) <00:06:07> ({r_i: None, r_t: [-853.769 -853.769 -853.769], eps: 0.001})
Step:   13000, Reward: [-390.425 -390.425 -390.425] [71.259], Avg: [-438.189 -438.189 -438.189] (0.0010) <00:06:11> ({r_i: None, r_t: [-793.160 -793.160 -793.160], critic_loss: 522.541015625, actor_loss: -1.559000015258789, entropy: 0.39399999380111694, eps: 0.001})
Step:   13100, Reward: [-404.961 -404.961 -404.961] [62.075], Avg: [-437.938 -437.938 -437.938] (0.0010) <00:06:13> ({r_i: None, r_t: [-836.781 -836.781 -836.781], eps: 0.001})
Step:   13200, Reward: [-436.895 -436.895 -436.895] [62.981], Avg: [-437.930 -437.930 -437.930] (0.0010) <00:06:16> ({r_i: None, r_t: [-871.257 -871.257 -871.257], critic_loss: 800.06201171875, actor_loss: -4.973999977111816, entropy: 0.41100001335144043, eps: 0.001})
Step:   13300, Reward: [-426.532 -426.532 -426.532] [55.726], Avg: [-437.845 -437.845 -437.845] (0.0010) <00:06:19> ({r_i: None, r_t: [-891.502 -891.502 -891.502], eps: 0.001})
Step:   13400, Reward: [-382.808 -382.808 -382.808] [71.253], Avg: [-437.437 -437.437 -437.437] (0.0010) <00:06:22> ({r_i: None, r_t: [-864.751 -864.751 -864.751], critic_loss: 661.5440063476562, actor_loss: -2.5290000438690186, entropy: 0.40400001406669617, eps: 0.001})
Step:   13500, Reward: [-404.105 -404.105 -404.105] [70.909], Avg: [-437.192 -437.192 -437.192] (0.0010) <00:06:25> ({r_i: None, r_t: [-805.264 -805.264 -805.264], eps: 0.001})
Step:   13600, Reward: [-437.407 -437.407 -437.407] [66.582], Avg: [-437.193 -437.193 -437.193] (0.0010) <00:06:28> ({r_i: None, r_t: [-827.970 -827.970 -827.970], critic_loss: 524.2410278320312, actor_loss: -1.8289999961853027, entropy: 0.38999998569488525, eps: 0.001})
Step:   13700, Reward: [-401.136 -401.136 -401.136] [59.497], Avg: [-436.932 -436.932 -436.932] (0.0010) <00:06:30> ({r_i: None, r_t: [-839.092 -839.092 -839.092], eps: 0.001})
Step:   13800, Reward: [-414.774 -414.774 -414.774] [64.946], Avg: [-436.773 -436.773 -436.773] (0.0010) <00:06:34> ({r_i: None, r_t: [-829.551 -829.551 -829.551], critic_loss: 878.9190063476562, actor_loss: -4.885000228881836, entropy: 0.39800000190734863, eps: 0.001})
Step:   13900, Reward: [-407.531 -407.531 -407.531] [42.780], Avg: [-436.564 -436.564 -436.564] (0.0010) <00:06:36> ({r_i: None, r_t: [-860.164 -860.164 -860.164], eps: 0.001})
Step:   14000, Reward: [-407.461 -407.461 -407.461] [46.686], Avg: [-436.357 -436.357 -436.357] (0.0010) <00:06:39> ({r_i: None, r_t: [-894.838 -894.838 -894.838], critic_loss: 662.666015625, actor_loss: -1.4950000047683716, entropy: 0.3840000033378601, eps: 0.001})
Step:   14100, Reward: [-396.369 -396.369 -396.369] [52.859], Avg: [-436.076 -436.076 -436.076] (0.0010) <00:06:42> ({r_i: None, r_t: [-816.740 -816.740 -816.740], eps: 0.001})
Step:   14200, Reward: [-402.289 -402.289 -402.289] [40.237], Avg: [-435.840 -435.840 -435.840] (0.0010) <00:06:45> ({r_i: None, r_t: [-828.977 -828.977 -828.977], critic_loss: 769.6229858398438, actor_loss: -5.36299991607666, entropy: 0.40299999713897705, eps: 0.001})
Step:   14300, Reward: [-393.734 -393.734 -393.734] [63.470], Avg: [-435.547 -435.547 -435.547] (0.0010) <00:06:47> ({r_i: None, r_t: [-810.560 -810.560 -810.560], eps: 0.001})
Step:   14400, Reward: [-424.159 -424.159 -424.159] [50.954], Avg: [-435.469 -435.469 -435.469] (0.0010) <00:06:51> ({r_i: None, r_t: [-823.449 -823.449 -823.449], critic_loss: 664.2780151367188, actor_loss: -4.013000011444092, entropy: 0.4169999957084656, eps: 0.001})
Step:   14500, Reward: [-421.669 -421.669 -421.669] [55.413], Avg: [-435.374 -435.374 -435.374] (0.0010) <00:06:53> ({r_i: None, r_t: [-792.225 -792.225 -792.225], eps: 0.001})
Step:   14600, Reward: [-399.761 -399.761 -399.761] [73.824], Avg: [-435.132 -435.132 -435.132] (0.0010) <00:06:56> ({r_i: None, r_t: [-837.091 -837.091 -837.091], critic_loss: 581.0609741210938, actor_loss: -2.1579999923706055, entropy: 0.3919999897480011, eps: 0.001})
Step:   14700, Reward: [-435.833 -435.833 -435.833] [65.770], Avg: [-435.137 -435.137 -435.137] (0.0010) <00:06:59> ({r_i: None, r_t: [-843.726 -843.726 -843.726], eps: 0.001})
Step:   14800, Reward: [-414.398 -414.398 -414.398] [64.501], Avg: [-434.997 -434.997 -434.997] (0.0010) <00:07:02> ({r_i: None, r_t: [-828.402 -828.402 -828.402], critic_loss: 680.6119995117188, actor_loss: -4.702000141143799, entropy: 0.40400001406669617, eps: 0.001})
Step:   14900, Reward: [-405.760 -405.760 -405.760] [51.314], Avg: [-434.803 -434.803 -434.803] (0.0010) <00:07:04> ({r_i: None, r_t: [-803.266 -803.266 -803.266], eps: 0.001})
Step:   15000, Reward: [-427.238 -427.238 -427.238] [70.078], Avg: [-434.752 -434.752 -434.752] (0.0010) <00:07:08> ({r_i: None, r_t: [-806.682 -806.682 -806.682], critic_loss: 449.89898681640625, actor_loss: -0.9200000166893005, entropy: 0.3930000066757202, eps: 0.001})
Step:   15100, Reward: [-422.151 -422.151 -422.151] [74.928], Avg: [-434.670 -434.670 -434.670] (0.0010) <00:07:10> ({r_i: None, r_t: [-851.088 -851.088 -851.088], eps: 0.001})
Step:   15200, Reward: [-427.299 -427.299 -427.299] [60.021], Avg: [-434.621 -434.621 -434.621] (0.0010) <00:07:13> ({r_i: None, r_t: [-844.862 -844.862 -844.862], critic_loss: 451.6919860839844, actor_loss: -1.6920000314712524, entropy: 0.3790000081062317, eps: 0.001})
Step:   15300, Reward: [-416.666 -416.666 -416.666] [61.427], Avg: [-434.505 -434.505 -434.505] (0.0010) <00:07:16> ({r_i: None, r_t: [-827.379 -827.379 -827.379], eps: 0.001})
Step:   15400, Reward: [-412.350 -412.350 -412.350] [63.145], Avg: [-434.362 -434.362 -434.362] (0.0010) <00:07:19> ({r_i: None, r_t: [-822.519 -822.519 -822.519], critic_loss: 526.166015625, actor_loss: -4.201000213623047, entropy: 0.375, eps: 0.001})
Step:   15500, Reward: [-403.360 -403.360 -403.360] [72.982], Avg: [-434.163 -434.163 -434.163] (0.0010) <00:07:21> ({r_i: None, r_t: [-827.153 -827.153 -827.153], eps: 0.001})
Step:   15600, Reward: [-429.310 -429.310 -429.310] [64.475], Avg: [-434.132 -434.132 -434.132] (0.0010) <00:07:25> ({r_i: None, r_t: [-856.703 -856.703 -856.703], critic_loss: 506.6889953613281, actor_loss: -2.259999990463257, entropy: 0.38499999046325684, eps: 0.001})
Step:   15700, Reward: [-421.387 -421.387 -421.387] [67.036], Avg: [-434.051 -434.051 -434.051] (0.0010) <00:07:27> ({r_i: None, r_t: [-843.340 -843.340 -843.340], eps: 0.001})
Step:   15800, Reward: [-396.225 -396.225 -396.225] [61.927], Avg: [-433.814 -433.814 -433.814] (0.0010) <00:07:30> ({r_i: None, r_t: [-818.402 -818.402 -818.402], critic_loss: 649.5540161132812, actor_loss: -3.878999948501587, entropy: 0.38499999046325684, eps: 0.001})
Step:   15900, Reward: [-423.809 -423.809 -423.809] [87.210], Avg: [-433.751 -433.751 -433.751] (0.0010) <00:07:33> ({r_i: None, r_t: [-833.304 -833.304 -833.304], eps: 0.001})
Step:   16000, Reward: [-435.604 -435.604 -435.604] [70.319], Avg: [-433.763 -433.763 -433.763] (0.0010) <00:07:36> ({r_i: None, r_t: [-827.978 -827.978 -827.978], critic_loss: 565.22900390625, actor_loss: -1.8289999961853027, entropy: 0.40700000524520874, eps: 0.001})
Step:   16100, Reward: [-402.456 -402.456 -402.456] [82.822], Avg: [-433.569 -433.569 -433.569] (0.0010) <00:07:38> ({r_i: None, r_t: [-829.260 -829.260 -829.260], eps: 0.001})
Step:   16200, Reward: [-376.613 -376.613 -376.613] [41.374], Avg: [-433.220 -433.220 -433.220] (0.0010) <00:07:42> ({r_i: None, r_t: [-825.184 -825.184 -825.184], critic_loss: 667.8369750976562, actor_loss: -3.125, entropy: 0.40799999237060547, eps: 0.001})
Step:   16300, Reward: [-420.825 -420.825 -420.825] [63.631], Avg: [-433.144 -433.144 -433.144] (0.0010) <00:07:44> ({r_i: None, r_t: [-850.373 -850.373 -850.373], eps: 0.001})
Step:   16400, Reward: [-414.950 -414.950 -414.950] [51.337], Avg: [-433.034 -433.034 -433.034] (0.0010) <00:07:47> ({r_i: None, r_t: [-844.704 -844.704 -844.704], critic_loss: 780.1909790039062, actor_loss: -4.138999938964844, entropy: 0.40700000524520874, eps: 0.001})
Step:   16500, Reward: [-391.749 -391.749 -391.749] [65.265], Avg: [-432.785 -432.785 -432.785] (0.0010) <00:07:49> ({r_i: None, r_t: [-812.870 -812.870 -812.870], eps: 0.001})
Step:   16600, Reward: [-431.174 -431.174 -431.174] [59.188], Avg: [-432.776 -432.776 -432.776] (0.0010) <00:07:53> ({r_i: None, r_t: [-820.379 -820.379 -820.379], critic_loss: 502.5069885253906, actor_loss: -3.180999994277954, entropy: 0.3970000147819519, eps: 0.001})
Step:   16700, Reward: [-398.946 -398.946 -398.946] [58.942], Avg: [-432.574 -432.574 -432.574] (0.0010) <00:07:55> ({r_i: None, r_t: [-850.900 -850.900 -850.900], eps: 0.001})
Step:   16800, Reward: [-433.806 -433.806 -433.806] [58.781], Avg: [-432.582 -432.582 -432.582] (0.0010) <00:07:59> ({r_i: None, r_t: [-841.284 -841.284 -841.284], critic_loss: 607.9609985351562, actor_loss: -1.225000023841858, entropy: 0.40299999713897705, eps: 0.001})
Step:   16900, Reward: [-412.034 -412.034 -412.034] [48.922], Avg: [-432.461 -432.461 -432.461] (0.0010) <00:08:01> ({r_i: None, r_t: [-815.081 -815.081 -815.081], eps: 0.001})
Step:   17000, Reward: [-427.421 -427.421 -427.421] [58.438], Avg: [-432.431 -432.431 -432.431] (0.0010) <00:08:04> ({r_i: None, r_t: [-840.172 -840.172 -840.172], critic_loss: 645.072998046875, actor_loss: -6.0920000076293945, entropy: 0.367000013589859, eps: 0.001})
Step:   17100, Reward: [-418.816 -418.816 -418.816] [46.830], Avg: [-432.352 -432.352 -432.352] (0.0010) <00:08:07> ({r_i: None, r_t: [-842.603 -842.603 -842.603], eps: 0.001})
Step:   17200, Reward: [-424.889 -424.889 -424.889] [79.337], Avg: [-432.309 -432.309 -432.309] (0.0010) <00:08:10> ({r_i: None, r_t: [-857.294 -857.294 -857.294], critic_loss: 694.7579956054688, actor_loss: -2.890000104904175, entropy: 0.3869999945163727, eps: 0.001})
Step:   17300, Reward: [-408.932 -408.932 -408.932] [66.089], Avg: [-432.175 -432.175 -432.175] (0.0010) <00:08:12> ({r_i: None, r_t: [-813.396 -813.396 -813.396], eps: 0.001})
Step:   17400, Reward: [-426.789 -426.789 -426.789] [83.243], Avg: [-432.144 -432.144 -432.144] (0.0010) <00:08:16> ({r_i: None, r_t: [-887.824 -887.824 -887.824], critic_loss: 769.5850219726562, actor_loss: -4.855000019073486, entropy: 0.3779999911785126, eps: 0.001})
Step:   17500, Reward: [-392.908 -392.908 -392.908] [58.492], Avg: [-431.921 -431.921 -431.921] (0.0010) <00:08:18> ({r_i: None, r_t: [-853.250 -853.250 -853.250], eps: 0.001})
Step:   17600, Reward: [-398.660 -398.660 -398.660] [83.350], Avg: [-431.733 -431.733 -431.733] (0.0010) <00:08:21> ({r_i: None, r_t: [-848.372 -848.372 -848.372], critic_loss: 1029.9649658203125, actor_loss: -7.394999980926514, entropy: 0.3959999978542328, eps: 0.001})
Step:   17700, Reward: [-388.600 -388.600 -388.600] [56.985], Avg: [-431.491 -431.491 -431.491] (0.0010) <00:08:23> ({r_i: None, r_t: [-890.419 -890.419 -890.419], eps: 0.001})
Step:   17800, Reward: [-416.352 -416.352 -416.352] [77.163], Avg: [-431.406 -431.406 -431.406] (0.0010) <00:08:27> ({r_i: None, r_t: [-842.888 -842.888 -842.888], critic_loss: 720.7490234375, actor_loss: -3.4030001163482666, entropy: 0.37299999594688416, eps: 0.001})
Step:   17900, Reward: [-416.495 -416.495 -416.495] [64.511], Avg: [-431.323 -431.323 -431.323] (0.0010) <00:08:29> ({r_i: None, r_t: [-839.717 -839.717 -839.717], eps: 0.001})
Step:   18000, Reward: [-413.003 -413.003 -413.003] [46.421], Avg: [-431.222 -431.222 -431.222] (0.0010) <00:08:33> ({r_i: None, r_t: [-812.154 -812.154 -812.154], critic_loss: 542.3560180664062, actor_loss: -4.232999801635742, entropy: 0.3959999978542328, eps: 0.001})
Step:   18100, Reward: [-418.219 -418.219 -418.219] [57.600], Avg: [-431.151 -431.151 -431.151] (0.0010) <00:08:35> ({r_i: None, r_t: [-845.535 -845.535 -845.535], eps: 0.001})
Step:   18200, Reward: [-412.463 -412.463 -412.463] [38.106], Avg: [-431.048 -431.048 -431.048] (0.0010) <00:08:39> ({r_i: None, r_t: [-872.553 -872.553 -872.553], critic_loss: 594.8889770507812, actor_loss: -1.2000000476837158, entropy: 0.38600000739097595, eps: 0.001})
Step:   18300, Reward: [-390.758 -390.758 -390.758] [55.339], Avg: [-430.830 -430.830 -430.830] (0.0010) <00:08:41> ({r_i: None, r_t: [-848.419 -848.419 -848.419], eps: 0.001})
Step:   18400, Reward: [-442.932 -442.932 -442.932] [80.585], Avg: [-430.895 -430.895 -430.895] (0.0010) <00:08:44> ({r_i: None, r_t: [-838.883 -838.883 -838.883], critic_loss: 640.0180053710938, actor_loss: -2.2290000915527344, entropy: 0.4020000100135803, eps: 0.001})
Step:   18500, Reward: [-427.692 -427.692 -427.692] [73.532], Avg: [-430.878 -430.878 -430.878] (0.0010) <00:08:46> ({r_i: None, r_t: [-798.754 -798.754 -798.754], eps: 0.001})
Step:   18600, Reward: [-429.640 -429.640 -429.640] [41.867], Avg: [-430.871 -430.871 -430.871] (0.0010) <00:08:50> ({r_i: None, r_t: [-838.381 -838.381 -838.381], critic_loss: 682.4520263671875, actor_loss: -4.3420000076293945, entropy: 0.37599998712539673, eps: 0.001})
Step:   18700, Reward: [-417.806 -417.806 -417.806] [48.966], Avg: [-430.802 -430.802 -430.802] (0.0010) <00:08:52> ({r_i: None, r_t: [-829.574 -829.574 -829.574], eps: 0.001})
Step:   18800, Reward: [-415.854 -415.854 -415.854] [57.212], Avg: [-430.723 -430.723 -430.723] (0.0010) <00:08:56> ({r_i: None, r_t: [-846.656 -846.656 -846.656], critic_loss: 457.8900146484375, actor_loss: -1.4490000009536743, entropy: 0.38600000739097595, eps: 0.001})
Step:   18900, Reward: [-424.183 -424.183 -424.183] [38.180], Avg: [-430.688 -430.688 -430.688] (0.0010) <00:08:58> ({r_i: None, r_t: [-864.768 -864.768 -864.768], eps: 0.001})
Step:   19000, Reward: [-422.344 -422.344 -422.344] [49.832], Avg: [-430.644 -430.644 -430.644] (0.0010) <00:09:01> ({r_i: None, r_t: [-814.236 -814.236 -814.236], critic_loss: 708.6240234375, actor_loss: -3.4140000343322754, entropy: 0.40400001406669617, eps: 0.001})
Step:   19100, Reward: [-415.121 -415.121 -415.121] [73.228], Avg: [-430.564 -430.564 -430.564] (0.0010) <00:09:04> ({r_i: None, r_t: [-850.183 -850.183 -850.183], eps: 0.001})
Step:   19200, Reward: [-414.114 -414.114 -414.114] [72.970], Avg: [-430.478 -430.478 -430.478] (0.0010) <00:09:07> ({r_i: None, r_t: [-856.578 -856.578 -856.578], critic_loss: 520.8040161132812, actor_loss: -3.678999900817871, entropy: 0.38999998569488525, eps: 0.001})
Step:   19300, Reward: [-425.621 -425.621 -425.621] [89.619], Avg: [-430.453 -430.453 -430.453] (0.0010) <00:09:09> ({r_i: None, r_t: [-812.238 -812.238 -812.238], eps: 0.001})
Step:   19400, Reward: [-429.275 -429.275 -429.275] [60.007], Avg: [-430.447 -430.447 -430.447] (0.0010) <00:09:13> ({r_i: None, r_t: [-817.121 -817.121 -817.121], critic_loss: 727.1859741210938, actor_loss: -2.8529999256134033, entropy: 0.3799999952316284, eps: 0.001})
Step:   19500, Reward: [-427.463 -427.463 -427.463] [57.396], Avg: [-430.432 -430.432 -430.432] (0.0010) <00:09:15> ({r_i: None, r_t: [-825.423 -825.423 -825.423], eps: 0.001})
Step:   19600, Reward: [-401.897 -401.897 -401.897] [64.511], Avg: [-430.287 -430.287 -430.287] (0.0010) <00:09:19> ({r_i: None, r_t: [-821.705 -821.705 -821.705], critic_loss: 465.1199951171875, actor_loss: -2.924999952316284, entropy: 0.3610000014305115, eps: 0.001})
Step:   19700, Reward: [-430.752 -430.752 -430.752] [68.890], Avg: [-430.290 -430.290 -430.290] (0.0010) <00:09:21> ({r_i: None, r_t: [-837.464 -837.464 -837.464], eps: 0.001})
Step:   19800, Reward: [-411.405 -411.405 -411.405] [67.315], Avg: [-430.195 -430.195 -430.195] (0.0010) <00:09:24> ({r_i: None, r_t: [-817.731 -817.731 -817.731], critic_loss: 562.1090087890625, actor_loss: -4.763999938964844, entropy: 0.3700000047683716, eps: 0.001})
Step:   19900, Reward: [-400.688 -400.688 -400.688] [63.989], Avg: [-430.047 -430.047 -430.047] (0.0010) <00:09:27> ({r_i: None, r_t: [-866.534 -866.534 -866.534], eps: 0.001})
Step:   20000, Reward: [-381.714 -381.714 -381.714] [66.076], Avg: [-429.807 -429.807 -429.807] (0.0010) <00:09:30> ({r_i: None, r_t: [-800.510 -800.510 -800.510], critic_loss: 513.0479736328125, actor_loss: -1.649999976158142, entropy: 0.3540000021457672, eps: 0.001})
Step:   20100, Reward: [-402.275 -402.275 -402.275] [62.297], Avg: [-429.670 -429.670 -429.670] (0.0010) <00:09:32> ({r_i: None, r_t: [-792.529 -792.529 -792.529], eps: 0.001})
Step:   20200, Reward: [-426.780 -426.780 -426.780] [55.129], Avg: [-429.656 -429.656 -429.656] (0.0010) <00:09:36> ({r_i: None, r_t: [-871.195 -871.195 -871.195], critic_loss: 389.81500244140625, actor_loss: -1.6799999475479126, entropy: 0.3659999966621399, eps: 0.001})
Step:   20300, Reward: [-436.246 -436.246 -436.246] [74.322], Avg: [-429.688 -429.688 -429.688] (0.0010) <00:09:38> ({r_i: None, r_t: [-809.851 -809.851 -809.851], eps: 0.001})
Step:   20400, Reward: [-452.110 -452.110 -452.110] [74.233], Avg: [-429.798 -429.798 -429.798] (0.0010) <00:09:42> ({r_i: None, r_t: [-857.899 -857.899 -857.899], critic_loss: 488.1709899902344, actor_loss: -1.9170000553131104, entropy: 0.3540000021457672, eps: 0.001})
Step:   20500, Reward: [-418.995 -418.995 -418.995] [78.024], Avg: [-429.745 -429.745 -429.745] (0.0010) <00:09:44> ({r_i: None, r_t: [-829.580 -829.580 -829.580], eps: 0.001})
Step:   20600, Reward: [-440.415 -440.415 -440.415] [73.241], Avg: [-429.797 -429.797 -429.797] (0.0010) <00:09:47> ({r_i: None, r_t: [-844.361 -844.361 -844.361], critic_loss: 581.3610229492188, actor_loss: -2.4200000762939453, entropy: 0.3529999852180481, eps: 0.001})
Step:   20700, Reward: [-422.088 -422.088 -422.088] [66.307], Avg: [-429.760 -429.760 -429.760] (0.0010) <00:09:49> ({r_i: None, r_t: [-789.299 -789.299 -789.299], eps: 0.001})
Step:   20800, Reward: [-417.652 -417.652 -417.652] [72.251], Avg: [-429.702 -429.702 -429.702] (0.0010) <00:09:53> ({r_i: None, r_t: [-852.725 -852.725 -852.725], critic_loss: 481.635009765625, actor_loss: -2.3519999980926514, entropy: 0.36000001430511475, eps: 0.001})
Step:   20900, Reward: [-428.915 -428.915 -428.915] [72.032], Avg: [-429.698 -429.698 -429.698] (0.0010) <00:09:55> ({r_i: None, r_t: [-819.817 -819.817 -819.817], eps: 0.001})
Step:   21000, Reward: [-447.249 -447.249 -447.249] [53.715], Avg: [-429.781 -429.781 -429.781] (0.0010) <00:09:59> ({r_i: None, r_t: [-805.509 -805.509 -805.509], critic_loss: 369.62799072265625, actor_loss: -2.315000057220459, entropy: 0.3659999966621399, eps: 0.001})
Step:   21100, Reward: [-426.590 -426.590 -426.590] [68.319], Avg: [-429.766 -429.766 -429.766] (0.0010) <00:10:01> ({r_i: None, r_t: [-911.175 -911.175 -911.175], eps: 0.001})
Step:   21200, Reward: [-388.161 -388.161 -388.161] [54.556], Avg: [-429.571 -429.571 -429.571] (0.0010) <00:10:04> ({r_i: None, r_t: [-813.454 -813.454 -813.454], critic_loss: 485.3680114746094, actor_loss: -1.2309999465942383, entropy: 0.36899998784065247, eps: 0.001})
Step:   21300, Reward: [-410.337 -410.337 -410.337] [75.399], Avg: [-429.481 -429.481 -429.481] (0.0010) <00:10:06> ({r_i: None, r_t: [-830.445 -830.445 -830.445], eps: 0.001})
Step:   21400, Reward: [-395.473 -395.473 -395.473] [79.550], Avg: [-429.323 -429.323 -429.323] (0.0010) <00:10:10> ({r_i: None, r_t: [-803.238 -803.238 -803.238], critic_loss: 521.0180053710938, actor_loss: -4.089000225067139, entropy: 0.3610000014305115, eps: 0.001})
Step:   21500, Reward: [-415.307 -415.307 -415.307] [47.983], Avg: [-429.258 -429.258 -429.258] (0.0010) <00:10:12> ({r_i: None, r_t: [-857.268 -857.268 -857.268], eps: 0.001})
Step:   21600, Reward: [-447.638 -447.638 -447.638] [89.452], Avg: [-429.343 -429.343 -429.343] (0.0010) <00:10:16> ({r_i: None, r_t: [-815.189 -815.189 -815.189], critic_loss: 436.2560119628906, actor_loss: -1.7450000047683716, entropy: 0.3630000054836273, eps: 0.001})
Step:   21700, Reward: [-428.125 -428.125 -428.125] [77.748], Avg: [-429.337 -429.337 -429.337] (0.0010) <00:10:18> ({r_i: None, r_t: [-819.416 -819.416 -819.416], eps: 0.001})
Step:   21800, Reward: [-420.304 -420.304 -420.304] [60.964], Avg: [-429.296 -429.296 -429.296] (0.0010) <00:10:21> ({r_i: None, r_t: [-856.418 -856.418 -856.418], critic_loss: 387.0409851074219, actor_loss: -1.6979999542236328, entropy: 0.35100001096725464, eps: 0.001})
Step:   21900, Reward: [-426.721 -426.721 -426.721] [63.832], Avg: [-429.284 -429.284 -429.284] (0.0010) <00:10:24> ({r_i: None, r_t: [-811.532 -811.532 -811.532], eps: 0.001})
Step:   22000, Reward: [-426.886 -426.886 -426.886] [58.254], Avg: [-429.273 -429.273 -429.273] (0.0010) <00:10:27> ({r_i: None, r_t: [-823.006 -823.006 -823.006], critic_loss: 393.81201171875, actor_loss: -1.4600000381469727, entropy: 0.3619999885559082, eps: 0.001})
Step:   22100, Reward: [-428.600 -428.600 -428.600] [65.658], Avg: [-429.270 -429.270 -429.270] (0.0010) <00:10:29> ({r_i: None, r_t: [-848.418 -848.418 -848.418], eps: 0.001})
Step:   22200, Reward: [-409.171 -409.171 -409.171] [60.342], Avg: [-429.180 -429.180 -429.180] (0.0010) <00:10:33> ({r_i: None, r_t: [-821.375 -821.375 -821.375], critic_loss: 418.9339904785156, actor_loss: -1.1360000371932983, entropy: 0.3569999933242798, eps: 0.001})
Step:   22300, Reward: [-433.626 -433.626 -433.626] [52.167], Avg: [-429.200 -429.200 -429.200] (0.0010) <00:10:35> ({r_i: None, r_t: [-841.797 -841.797 -841.797], eps: 0.001})
Step:   22400, Reward: [-389.015 -389.015 -389.015] [77.094], Avg: [-429.021 -429.021 -429.021] (0.0010) <00:10:38> ({r_i: None, r_t: [-865.115 -865.115 -865.115], critic_loss: 478.7959899902344, actor_loss: -3.677000045776367, entropy: 0.3619999885559082, eps: 0.001})
Step:   22500, Reward: [-429.861 -429.861 -429.861] [65.851], Avg: [-429.025 -429.025 -429.025] (0.0010) <00:10:41> ({r_i: None, r_t: [-840.230 -840.230 -840.230], eps: 0.001})
Step:   22600, Reward: [-437.948 -437.948 -437.948] [71.219], Avg: [-429.064 -429.064 -429.064] (0.0010) <00:10:44> ({r_i: None, r_t: [-830.805 -830.805 -830.805], critic_loss: 466.39300537109375, actor_loss: -3.5799999237060547, entropy: 0.3619999885559082, eps: 0.001})
Step:   22700, Reward: [-412.745 -412.745 -412.745] [67.148], Avg: [-428.993 -428.993 -428.993] (0.0010) <00:10:46> ({r_i: None, r_t: [-881.990 -881.990 -881.990], eps: 0.001})
Step:   22800, Reward: [-429.291 -429.291 -429.291] [60.897], Avg: [-428.994 -428.994 -428.994] (0.0010) <00:10:50> ({r_i: None, r_t: [-826.284 -826.284 -826.284], critic_loss: 456.0989990234375, actor_loss: -2.184999942779541, entropy: 0.35100001096725464, eps: 0.001})
Step:   22900, Reward: [-436.728 -436.728 -436.728] [38.622], Avg: [-429.028 -429.028 -429.028] (0.0010) <00:10:52> ({r_i: None, r_t: [-857.675 -857.675 -857.675], eps: 0.001})
Step:   23000, Reward: [-416.828 -416.828 -416.828] [63.569], Avg: [-428.975 -428.975 -428.975] (0.0010) <00:10:56> ({r_i: None, r_t: [-830.487 -830.487 -830.487], critic_loss: 632.989013671875, actor_loss: -3.996000051498413, entropy: 0.34599998593330383, eps: 0.001})
Step:   23100, Reward: [-422.285 -422.285 -422.285] [72.713], Avg: [-428.946 -428.946 -428.946] (0.0010) <00:10:58> ({r_i: None, r_t: [-837.703 -837.703 -837.703], eps: 0.001})
Step:   23200, Reward: [-428.855 -428.855 -428.855] [63.142], Avg: [-428.946 -428.946 -428.946] (0.0010) <00:11:01> ({r_i: None, r_t: [-813.931 -813.931 -813.931], critic_loss: 468.69000244140625, actor_loss: -1.9839999675750732, entropy: 0.35499998927116394, eps: 0.001})
Step:   23300, Reward: [-408.059 -408.059 -408.059] [80.288], Avg: [-428.856 -428.856 -428.856] (0.0010) <00:11:03> ({r_i: None, r_t: [-825.302 -825.302 -825.302], eps: 0.001})
Step:   23400, Reward: [-447.712 -447.712 -447.712] [70.723], Avg: [-428.937 -428.937 -428.937] (0.0010) <00:11:07> ({r_i: None, r_t: [-788.420 -788.420 -788.420], critic_loss: 498.11700439453125, actor_loss: -4.267000198364258, entropy: 0.3490000069141388, eps: 0.001})
Step:   23500, Reward: [-412.746 -412.746 -412.746] [74.624], Avg: [-428.868 -428.868 -428.868] (0.0010) <00:11:09> ({r_i: None, r_t: [-830.758 -830.758 -830.758], eps: 0.001})
Step:   23600, Reward: [-423.037 -423.037 -423.037] [50.195], Avg: [-428.843 -428.843 -428.843] (0.0010) <00:11:13> ({r_i: None, r_t: [-870.771 -870.771 -870.771], critic_loss: 575.3480224609375, actor_loss: -3.302999973297119, entropy: 0.35600000619888306, eps: 0.001})
Step:   23700, Reward: [-406.988 -406.988 -406.988] [68.395], Avg: [-428.752 -428.752 -428.752] (0.0010) <00:11:15> ({r_i: None, r_t: [-896.456 -896.456 -896.456], eps: 0.001})
Step:   23800, Reward: [-427.111 -427.111 -427.111] [39.231], Avg: [-428.745 -428.745 -428.745] (0.0010) <00:11:18> ({r_i: None, r_t: [-844.875 -844.875 -844.875], critic_loss: 498.1340026855469, actor_loss: -3.9760000705718994, entropy: 0.3409999907016754, eps: 0.001})
Step:   23900, Reward: [-437.735 -437.735 -437.735] [58.477], Avg: [-428.782 -428.782 -428.782] (0.0010) <00:11:21> ({r_i: None, r_t: [-872.547 -872.547 -872.547], eps: 0.001})
Step:   24000, Reward: [-438.782 -438.782 -438.782] [54.741], Avg: [-428.824 -428.824 -428.824] (0.0010) <00:11:24> ({r_i: None, r_t: [-818.241 -818.241 -818.241], critic_loss: 432.9360046386719, actor_loss: -3.306999921798706, entropy: 0.3370000123977661, eps: 0.001})
Step:   24100, Reward: [-389.661 -389.661 -389.661] [54.876], Avg: [-428.662 -428.662 -428.662] (0.0010) <00:11:27> ({r_i: None, r_t: [-884.993 -884.993 -884.993], eps: 0.001})
Step:   24200, Reward: [-416.300 -416.300 -416.300] [55.977], Avg: [-428.611 -428.611 -428.611] (0.0010) <00:11:30> ({r_i: None, r_t: [-812.307 -812.307 -812.307], critic_loss: 353.9590148925781, actor_loss: 0.03200000151991844, entropy: 0.3330000042915344, eps: 0.001})
Step:   24300, Reward: [-450.551 -450.551 -450.551] [75.661], Avg: [-428.701 -428.701 -428.701] (0.0010) <00:11:32> ({r_i: None, r_t: [-889.332 -889.332 -889.332], eps: 0.001})
Step:   24400, Reward: [-414.778 -414.778 -414.778] [63.179], Avg: [-428.644 -428.644 -428.644] (0.0010) <00:11:36> ({r_i: None, r_t: [-866.276 -866.276 -866.276], critic_loss: 452.9620056152344, actor_loss: -2.0350000858306885, entropy: 0.3199999928474426, eps: 0.001})
Step:   24500, Reward: [-405.859 -405.859 -405.859] [83.177], Avg: [-428.552 -428.552 -428.552] (0.0010) <00:11:38> ({r_i: None, r_t: [-824.694 -824.694 -824.694], eps: 0.001})
Step:   24600, Reward: [-435.534 -435.534 -435.534] [56.376], Avg: [-428.580 -428.580 -428.580] (0.0010) <00:11:41> ({r_i: None, r_t: [-825.189 -825.189 -825.189], critic_loss: 395.9259948730469, actor_loss: -1.5509999990463257, entropy: 0.32100000977516174, eps: 0.001})
Step:   24700, Reward: [-426.159 -426.159 -426.159] [70.994], Avg: [-428.570 -428.570 -428.570] (0.0010) <00:11:44> ({r_i: None, r_t: [-858.075 -858.075 -858.075], eps: 0.001})
Step:   24800, Reward: [-394.045 -394.045 -394.045] [69.587], Avg: [-428.431 -428.431 -428.431] (0.0010) <00:11:47> ({r_i: None, r_t: [-902.115 -902.115 -902.115], critic_loss: 490.34600830078125, actor_loss: -1.7669999599456787, entropy: 0.32199999690055847, eps: 0.001})
Step:   24900, Reward: [-459.699 -459.699 -459.699] [83.131], Avg: [-428.556 -428.556 -428.556] (0.0010) <00:11:49> ({r_i: None, r_t: [-819.827 -819.827 -819.827], eps: 0.001})
Step:   25000, Reward: [-427.434 -427.434 -427.434] [60.795], Avg: [-428.552 -428.552 -428.552] (0.0010) <00:11:52> ({r_i: None, r_t: [-836.366 -836.366 -836.366], critic_loss: 452.8970031738281, actor_loss: -4.071000099182129, entropy: 0.3190000057220459, eps: 0.001})
Step:   25100, Reward: [-457.243 -457.243 -457.243] [57.360], Avg: [-428.666 -428.666 -428.666] (0.0010) <00:11:55> ({r_i: None, r_t: [-829.191 -829.191 -829.191], eps: 0.001})
Step:   25200, Reward: [-453.671 -453.671 -453.671] [41.763], Avg: [-428.765 -428.765 -428.765] (0.0010) <00:11:58> ({r_i: None, r_t: [-864.840 -864.840 -864.840], critic_loss: 401.31201171875, actor_loss: -2.052999973297119, entropy: 0.32499998807907104, eps: 0.001})
Step:   25300, Reward: [-446.299 -446.299 -446.299] [70.063], Avg: [-428.834 -428.834 -428.834] (0.0010) <00:12:01> ({r_i: None, r_t: [-788.669 -788.669 -788.669], eps: 0.001})
Step:   25400, Reward: [-368.475 -368.475 -368.475] [57.634], Avg: [-428.597 -428.597 -428.597] (0.0010) <00:12:04> ({r_i: None, r_t: [-859.835 -859.835 -859.835], critic_loss: 351.3689880371094, actor_loss: -2.0, entropy: 0.3160000145435333, eps: 0.001})
Step:   25500, Reward: [-386.253 -386.253 -386.253] [67.866], Avg: [-428.432 -428.432 -428.432] (0.0010) <00:12:06> ({r_i: None, r_t: [-863.218 -863.218 -863.218], eps: 0.001})
Step:   25600, Reward: [-429.066 -429.066 -429.066] [69.634], Avg: [-428.434 -428.434 -428.434] (0.0010) <00:12:09> ({r_i: None, r_t: [-843.678 -843.678 -843.678], critic_loss: 447.70599365234375, actor_loss: -1.0980000495910645, entropy: 0.3240000009536743, eps: 0.001})
Step:   25700, Reward: [-441.464 -441.464 -441.464] [71.361], Avg: [-428.485 -428.485 -428.485] (0.0010) <00:12:12> ({r_i: None, r_t: [-825.496 -825.496 -825.496], eps: 0.001})
Step:   25800, Reward: [-434.977 -434.977 -434.977] [52.379], Avg: [-428.510 -428.510 -428.510] (0.0010) <00:12:15> ({r_i: None, r_t: [-889.258 -889.258 -889.258], critic_loss: 477.26800537109375, actor_loss: -4.459000110626221, entropy: 0.3089999854564667, eps: 0.001})
Step:   25900, Reward: [-426.513 -426.513 -426.513] [72.046], Avg: [-428.502 -428.502 -428.502] (0.0010) <00:12:17> ({r_i: None, r_t: [-857.086 -857.086 -857.086], eps: 0.001})
Step:   26000, Reward: [-412.569 -412.569 -412.569] [57.478], Avg: [-428.441 -428.441 -428.441] (0.0010) <00:12:21> ({r_i: None, r_t: [-851.900 -851.900 -851.900], critic_loss: 290.239013671875, actor_loss: 0.597000002861023, entropy: 0.3149999976158142, eps: 0.001})
Step:   26100, Reward: [-404.464 -404.464 -404.464] [57.262], Avg: [-428.349 -428.349 -428.349] (0.0010) <00:12:23> ({r_i: None, r_t: [-865.958 -865.958 -865.958], eps: 0.001})
Step:   26200, Reward: [-438.226 -438.226 -438.226] [52.909], Avg: [-428.387 -428.387 -428.387] (0.0010) <00:12:27> ({r_i: None, r_t: [-851.447 -851.447 -851.447], critic_loss: 497.2130126953125, actor_loss: -3.0850000381469727, entropy: 0.3160000145435333, eps: 0.001})
Step:   26300, Reward: [-417.230 -417.230 -417.230] [76.878], Avg: [-428.345 -428.345 -428.345] (0.0010) <00:12:29> ({r_i: None, r_t: [-880.799 -880.799 -880.799], eps: 0.001})
Step:   26400, Reward: [-444.322 -444.322 -444.322] [81.385], Avg: [-428.405 -428.405 -428.405] (0.0010) <00:12:33> ({r_i: None, r_t: [-836.539 -836.539 -836.539], critic_loss: 417.6260070800781, actor_loss: -2.4739999771118164, entropy: 0.3140000104904175, eps: 0.001})
Step:   26500, Reward: [-419.849 -419.849 -419.849] [92.297], Avg: [-428.373 -428.373 -428.373] (0.0010) <00:12:35> ({r_i: None, r_t: [-905.683 -905.683 -905.683], eps: 0.001})
Step:   26600, Reward: [-420.575 -420.575 -420.575] [76.631], Avg: [-428.344 -428.344 -428.344] (0.0010) <00:12:38> ({r_i: None, r_t: [-888.923 -888.923 -888.923], critic_loss: 419.5260009765625, actor_loss: -2.2160000801086426, entropy: 0.31200000643730164, eps: 0.001})
Step:   26700, Reward: [-438.855 -438.855 -438.855] [51.841], Avg: [-428.383 -428.383 -428.383] (0.0010) <00:12:40> ({r_i: None, r_t: [-894.866 -894.866 -894.866], eps: 0.001})
Step:   26800, Reward: [-434.782 -434.782 -434.782] [60.954], Avg: [-428.407 -428.407 -428.407] (0.0010) <00:12:44> ({r_i: None, r_t: [-859.014 -859.014 -859.014], critic_loss: 390.62799072265625, actor_loss: -2.503000020980835, entropy: 0.3070000112056732, eps: 0.001})
Step:   26900, Reward: [-448.232 -448.232 -448.232] [96.651], Avg: [-428.480 -428.480 -428.480] (0.0010) <00:12:46> ({r_i: None, r_t: [-826.992 -826.992 -826.992], eps: 0.001})
Step:   27000, Reward: [-414.623 -414.623 -414.623] [75.705], Avg: [-428.429 -428.429 -428.429] (0.0010) <00:12:49> ({r_i: None, r_t: [-877.650 -877.650 -877.650], critic_loss: 346.14801025390625, actor_loss: -0.4580000042915344, entropy: 0.3050000071525574, eps: 0.001})
Step:   27100, Reward: [-428.823 -428.823 -428.823] [82.109], Avg: [-428.430 -428.430 -428.430] (0.0010) <00:12:52> ({r_i: None, r_t: [-884.331 -884.331 -884.331], eps: 0.001})
Step:   27200, Reward: [-410.789 -410.789 -410.789] [77.268], Avg: [-428.366 -428.366 -428.366] (0.0010) <00:12:55> ({r_i: None, r_t: [-867.661 -867.661 -867.661], critic_loss: 507.2250061035156, actor_loss: -4.229000091552734, entropy: 0.3109999895095825, eps: 0.001})
Step:   27300, Reward: [-428.947 -428.947 -428.947] [58.416], Avg: [-428.368 -428.368 -428.368] (0.0010) <00:12:57> ({r_i: None, r_t: [-854.747 -854.747 -854.747], eps: 0.001})
Step:   27400, Reward: [-431.358 -431.358 -431.358] [51.578], Avg: [-428.379 -428.379 -428.379] (0.0010) <00:13:01> ({r_i: None, r_t: [-864.454 -864.454 -864.454], critic_loss: 424.5530090332031, actor_loss: -3.3410000801086426, entropy: 0.3089999854564667, eps: 0.001})
Step:   27500, Reward: [-426.996 -426.996 -426.996] [53.047], Avg: [-428.374 -428.374 -428.374] (0.0010) <00:13:03> ({r_i: None, r_t: [-861.266 -861.266 -861.266], eps: 0.001})
Step:   27600, Reward: [-449.836 -449.836 -449.836] [78.879], Avg: [-428.451 -428.451 -428.451] (0.0010) <00:13:07> ({r_i: None, r_t: [-882.268 -882.268 -882.268], critic_loss: 556.9140014648438, actor_loss: -3.119999885559082, entropy: 0.31299999356269836, eps: 0.001})
Step:   27700, Reward: [-428.890 -428.890 -428.890] [56.178], Avg: [-428.453 -428.453 -428.453] (0.0010) <00:13:09> ({r_i: None, r_t: [-844.975 -844.975 -844.975], eps: 0.001})
Step:   27800, Reward: [-432.675 -432.675 -432.675] [51.643], Avg: [-428.468 -428.468 -428.468] (0.0010) <00:13:13> ({r_i: None, r_t: [-869.554 -869.554 -869.554], critic_loss: 469.59600830078125, actor_loss: -4.249000072479248, entropy: 0.3089999854564667, eps: 0.001})
Step:   27900, Reward: [-458.624 -458.624 -458.624] [61.365], Avg: [-428.576 -428.576 -428.576] (0.0010) <00:13:15> ({r_i: None, r_t: [-800.845 -800.845 -800.845], eps: 0.001})
Step:   28000, Reward: [-400.770 -400.770 -400.770] [76.920], Avg: [-428.477 -428.477 -428.477] (0.0010) <00:13:18> ({r_i: None, r_t: [-872.039 -872.039 -872.039], critic_loss: 390.5249938964844, actor_loss: -1.246999979019165, entropy: 0.30300000309944153, eps: 0.001})
Step:   28100, Reward: [-410.799 -410.799 -410.799] [68.242], Avg: [-428.414 -428.414 -428.414] (0.0010) <00:13:20> ({r_i: None, r_t: [-848.156 -848.156 -848.156], eps: 0.001})
Step:   28200, Reward: [-416.396 -416.396 -416.396] [50.253], Avg: [-428.371 -428.371 -428.371] (0.0010) <00:13:24> ({r_i: None, r_t: [-860.026 -860.026 -860.026], critic_loss: 394.0329895019531, actor_loss: -3.446000099182129, entropy: 0.30000001192092896, eps: 0.001})
Step:   28300, Reward: [-416.386 -416.386 -416.386] [82.050], Avg: [-428.329 -428.329 -428.329] (0.0010) <00:13:26> ({r_i: None, r_t: [-859.782 -859.782 -859.782], eps: 0.001})
Step:   28400, Reward: [-414.228 -414.228 -414.228] [58.821], Avg: [-428.280 -428.280 -428.280] (0.0010) <00:13:30> ({r_i: None, r_t: [-817.685 -817.685 -817.685], critic_loss: 401.1629943847656, actor_loss: -1.222000002861023, entropy: 0.2919999957084656, eps: 0.001})
Step:   28500, Reward: [-460.354 -460.354 -460.354] [70.638], Avg: [-428.392 -428.392 -428.392] (0.0010) <00:13:32> ({r_i: None, r_t: [-857.421 -857.421 -857.421], eps: 0.001})
Step:   28600, Reward: [-449.850 -449.850 -449.850] [77.543], Avg: [-428.467 -428.467 -428.467] (0.0010) <00:13:36> ({r_i: None, r_t: [-821.888 -821.888 -821.888], critic_loss: 329.2030029296875, actor_loss: -1.0240000486373901, entropy: 0.30000001192092896, eps: 0.001})
Step:   28700, Reward: [-434.196 -434.196 -434.196] [76.741], Avg: [-428.487 -428.487 -428.487] (0.0010) <00:13:38> ({r_i: None, r_t: [-851.641 -851.641 -851.641], eps: 0.001})
Step:   28800, Reward: [-425.851 -425.851 -425.851] [77.715], Avg: [-428.478 -428.478 -428.478] (0.0010) <00:13:41> ({r_i: None, r_t: [-860.696 -860.696 -860.696], critic_loss: 299.4330139160156, actor_loss: 0.4560000002384186, entropy: 0.29899999499320984, eps: 0.001})
Step:   28900, Reward: [-481.091 -481.091 -481.091] [85.009], Avg: [-428.659 -428.659 -428.659] (0.0010) <00:13:43> ({r_i: None, r_t: [-861.485 -861.485 -861.485], eps: 0.001})
Step:   29000, Reward: [-427.650 -427.650 -427.650] [56.761], Avg: [-428.655 -428.655 -428.655] (0.0010) <00:13:47> ({r_i: None, r_t: [-849.934 -849.934 -849.934], critic_loss: 321.8940124511719, actor_loss: -0.22200000286102295, entropy: 0.2980000078678131, eps: 0.001})
Step:   29100, Reward: [-436.015 -436.015 -436.015] [54.343], Avg: [-428.681 -428.681 -428.681] (0.0010) <00:13:49> ({r_i: None, r_t: [-875.198 -875.198 -875.198], eps: 0.001})
Step:   29200, Reward: [-427.219 -427.219 -427.219] [66.786], Avg: [-428.676 -428.676 -428.676] (0.0010) <00:13:53> ({r_i: None, r_t: [-859.989 -859.989 -859.989], critic_loss: 262.6319885253906, actor_loss: -1.00600004196167, entropy: 0.3019999861717224, eps: 0.001})
Step:   29300, Reward: [-428.695 -428.695 -428.695] [73.458], Avg: [-428.676 -428.676 -428.676] (0.0010) <00:13:55> ({r_i: None, r_t: [-881.358 -881.358 -881.358], eps: 0.001})
Step:   29400, Reward: [-447.715 -447.715 -447.715] [70.484], Avg: [-428.740 -428.740 -428.740] (0.0010) <00:13:58> ({r_i: None, r_t: [-854.683 -854.683 -854.683], critic_loss: 297.7560119628906, actor_loss: -2.7709999084472656, entropy: 0.289000004529953, eps: 0.001})
Step:   29500, Reward: [-444.122 -444.122 -444.122] [73.293], Avg: [-428.792 -428.792 -428.792] (0.0010) <00:14:00> ({r_i: None, r_t: [-871.750 -871.750 -871.750], eps: 0.001})
Step:   29600, Reward: [-447.353 -447.353 -447.353] [73.277], Avg: [-428.855 -428.855 -428.855] (0.0010) <00:14:04> ({r_i: None, r_t: [-822.630 -822.630 -822.630], critic_loss: 454.6390075683594, actor_loss: -3.1730000972747803, entropy: 0.2809999883174896, eps: 0.001})
Step:   29700, Reward: [-389.943 -389.943 -389.943] [70.314], Avg: [-428.724 -428.724 -428.724] (0.0010) <00:14:06> ({r_i: None, r_t: [-878.719 -878.719 -878.719], eps: 0.001})
Step:   29800, Reward: [-417.332 -417.332 -417.332] [66.300], Avg: [-428.686 -428.686 -428.686] (0.0010) <00:14:10> ({r_i: None, r_t: [-816.952 -816.952 -816.952], critic_loss: 431.3659973144531, actor_loss: -0.9620000123977661, entropy: 0.27799999713897705, eps: 0.001})
Step:   29900, Reward: [-419.073 -419.073 -419.073] [62.462], Avg: [-428.654 -428.654 -428.654] (0.0010) <00:14:12> ({r_i: None, r_t: [-786.909 -786.909 -786.909], eps: 0.001})
Step:   30000, Reward: [-445.400 -445.400 -445.400] [68.480], Avg: [-428.710 -428.710 -428.710] (0.0010) <00:14:15> ({r_i: None, r_t: [-833.597 -833.597 -833.597], critic_loss: 282.822998046875, actor_loss: -1.5440000295639038, entropy: 0.28200000524520874, eps: 0.001})
Step:   30100, Reward: [-436.361 -436.361 -436.361] [79.876], Avg: [-428.735 -428.735 -428.735] (0.0010) <00:14:18> ({r_i: None, r_t: [-838.008 -838.008 -838.008], eps: 0.001})
Step:   30200, Reward: [-450.539 -450.539 -450.539] [69.964], Avg: [-428.807 -428.807 -428.807] (0.0010) <00:14:21> ({r_i: None, r_t: [-859.294 -859.294 -859.294], critic_loss: 447.9309997558594, actor_loss: -3.007999897003174, entropy: 0.2770000100135803, eps: 0.001})
Step:   30300, Reward: [-430.174 -430.174 -430.174] [59.409], Avg: [-428.811 -428.811 -428.811] (0.0010) <00:14:23> ({r_i: None, r_t: [-842.492 -842.492 -842.492], eps: 0.001})
Step:   30400, Reward: [-440.540 -440.540 -440.540] [70.585], Avg: [-428.850 -428.850 -428.850] (0.0010) <00:14:27> ({r_i: None, r_t: [-845.769 -845.769 -845.769], critic_loss: 296.2300109863281, actor_loss: 0.2409999966621399, entropy: 0.2849999964237213, eps: 0.001})
Step:   30500, Reward: [-391.851 -391.851 -391.851] [71.482], Avg: [-428.729 -428.729 -428.729] (0.0010) <00:14:29> ({r_i: None, r_t: [-868.329 -868.329 -868.329], eps: 0.001})
Step:   30600, Reward: [-421.387 -421.387 -421.387] [55.717], Avg: [-428.705 -428.705 -428.705] (0.0010) <00:14:33> ({r_i: None, r_t: [-813.329 -813.329 -813.329], critic_loss: 376.6340026855469, actor_loss: -3.007999897003174, entropy: 0.27799999713897705, eps: 0.001})
Step:   30700, Reward: [-441.551 -441.551 -441.551] [76.734], Avg: [-428.747 -428.747 -428.747] (0.0010) <00:14:35> ({r_i: None, r_t: [-846.995 -846.995 -846.995], eps: 0.001})
Step:   30800, Reward: [-431.820 -431.820 -431.820] [91.145], Avg: [-428.757 -428.757 -428.757] (0.0010) <00:14:38> ({r_i: None, r_t: [-808.547 -808.547 -808.547], critic_loss: 340.3380126953125, actor_loss: -1.809999942779541, entropy: 0.2759999930858612, eps: 0.001})
Step:   30900, Reward: [-410.066 -410.066 -410.066] [58.427], Avg: [-428.696 -428.696 -428.696] (0.0010) <00:14:41> ({r_i: None, r_t: [-875.373 -875.373 -875.373], eps: 0.001})
Step:   31000, Reward: [-424.353 -424.353 -424.353] [81.866], Avg: [-428.682 -428.682 -428.682] (0.0010) <00:14:44> ({r_i: None, r_t: [-874.166 -874.166 -874.166], critic_loss: 309.5740051269531, actor_loss: -1.8960000276565552, entropy: 0.28200000524520874, eps: 0.001})
Step:   31100, Reward: [-436.911 -436.911 -436.911] [75.582], Avg: [-428.709 -428.709 -428.709] (0.0010) <00:14:46> ({r_i: None, r_t: [-839.155 -839.155 -839.155], eps: 0.001})
Step:   31200, Reward: [-412.015 -412.015 -412.015] [74.424], Avg: [-428.656 -428.656 -428.656] (0.0010) <00:14:50> ({r_i: None, r_t: [-866.518 -866.518 -866.518], critic_loss: 315.3210144042969, actor_loss: -0.6389999985694885, entropy: 0.28999999165534973, eps: 0.001})
Step:   31300, Reward: [-407.104 -407.104 -407.104] [70.353], Avg: [-428.587 -428.587 -428.587] (0.0010) <00:14:52> ({r_i: None, r_t: [-851.711 -851.711 -851.711], eps: 0.001})
Step:   31400, Reward: [-438.090 -438.090 -438.090] [70.517], Avg: [-428.617 -428.617 -428.617] (0.0010) <00:14:56> ({r_i: None, r_t: [-871.203 -871.203 -871.203], critic_loss: 276.1470031738281, actor_loss: -0.4300000071525574, entropy: 0.2759999930858612, eps: 0.001})
Step:   31500, Reward: [-472.244 -472.244 -472.244] [65.619], Avg: [-428.755 -428.755 -428.755] (0.0010) <00:14:58> ({r_i: None, r_t: [-808.849 -808.849 -808.849], eps: 0.001})
Step:   31600, Reward: [-398.580 -398.580 -398.580] [33.692], Avg: [-428.660 -428.660 -428.660] (0.0010) <00:15:01> ({r_i: None, r_t: [-861.493 -861.493 -861.493], critic_loss: 360.5429992675781, actor_loss: -1.5820000171661377, entropy: 0.2800000011920929, eps: 0.001})
Step:   31700, Reward: [-426.143 -426.143 -426.143] [62.406], Avg: [-428.652 -428.652 -428.652] (0.0010) <00:15:04> ({r_i: None, r_t: [-901.989 -901.989 -901.989], eps: 0.001})
Step:   31800, Reward: [-409.501 -409.501 -409.501] [71.798], Avg: [-428.592 -428.592 -428.592] (0.0010) <00:15:07> ({r_i: None, r_t: [-855.536 -855.536 -855.536], critic_loss: 540.031982421875, actor_loss: -3.822000026702881, entropy: 0.28600001335144043, eps: 0.001})
Step:   31900, Reward: [-415.850 -415.850 -415.850] [82.315], Avg: [-428.552 -428.552 -428.552] (0.0010) <00:15:09> ({r_i: None, r_t: [-868.991 -868.991 -868.991], eps: 0.001})
Step:   32000, Reward: [-402.707 -402.707 -402.707] [69.869], Avg: [-428.472 -428.472 -428.472] (0.0010) <00:15:13> ({r_i: None, r_t: [-828.060 -828.060 -828.060], critic_loss: 407.4700012207031, actor_loss: -3.563999891281128, entropy: 0.2720000147819519, eps: 0.001})
Step:   32100, Reward: [-420.574 -420.574 -420.574] [85.002], Avg: [-428.447 -428.447 -428.447] (0.0010) <00:15:15> ({r_i: None, r_t: [-852.275 -852.275 -852.275], eps: 0.001})
Step:   32200, Reward: [-408.301 -408.301 -408.301] [61.071], Avg: [-428.385 -428.385 -428.385] (0.0010) <00:15:19> ({r_i: None, r_t: [-849.547 -849.547 -849.547], critic_loss: 262.60400390625, actor_loss: -0.15600000321865082, entropy: 0.2759999930858612, eps: 0.001})
Step:   32300, Reward: [-440.754 -440.754 -440.754] [81.771], Avg: [-428.423 -428.423 -428.423] (0.0010) <00:15:21> ({r_i: None, r_t: [-859.825 -859.825 -859.825], eps: 0.001})
Step:   32400, Reward: [-438.262 -438.262 -438.262] [80.261], Avg: [-428.453 -428.453 -428.453] (0.0010) <00:15:25> ({r_i: None, r_t: [-893.566 -893.566 -893.566], critic_loss: 364.0119934082031, actor_loss: -2.2939999103546143, entropy: 0.28200000524520874, eps: 0.001})
Step:   32500, Reward: [-428.891 -428.891 -428.891] [97.395], Avg: [-428.455 -428.455 -428.455] (0.0010) <00:15:27> ({r_i: None, r_t: [-859.061 -859.061 -859.061], eps: 0.001})
Step:   32600, Reward: [-447.120 -447.120 -447.120] [81.627], Avg: [-428.512 -428.512 -428.512] (0.0010) <00:15:30> ({r_i: None, r_t: [-891.702 -891.702 -891.702], critic_loss: 262.0820007324219, actor_loss: -0.18400000035762787, entropy: 0.2709999978542328, eps: 0.001})
Step:   32700, Reward: [-417.529 -417.529 -417.529] [81.323], Avg: [-428.478 -428.478 -428.478] (0.0010) <00:15:33> ({r_i: None, r_t: [-815.716 -815.716 -815.716], eps: 0.001})
Step:   32800, Reward: [-431.519 -431.519 -431.519] [66.230], Avg: [-428.487 -428.487 -428.487] (0.0010) <00:15:36> ({r_i: None, r_t: [-832.755 -832.755 -832.755], critic_loss: 246.906005859375, actor_loss: -0.8299999833106995, entropy: 0.2720000147819519, eps: 0.001})
Step:   32900, Reward: [-441.387 -441.387 -441.387] [64.390], Avg: [-428.526 -428.526 -428.526] (0.0010) <00:15:38> ({r_i: None, r_t: [-849.117 -849.117 -849.117], eps: 0.001})
Step:   33000, Reward: [-423.378 -423.378 -423.378] [79.149], Avg: [-428.511 -428.511 -428.511] (0.0010) <00:15:42> ({r_i: None, r_t: [-881.000 -881.000 -881.000], critic_loss: 344.88299560546875, actor_loss: -1.1069999933242798, entropy: 0.2669999897480011, eps: 0.001})
Step:   33100, Reward: [-445.759 -445.759 -445.759] [68.798], Avg: [-428.563 -428.563 -428.563] (0.0010) <00:15:44> ({r_i: None, r_t: [-891.437 -891.437 -891.437], eps: 0.001})
Step:   33200, Reward: [-412.163 -412.163 -412.163] [50.321], Avg: [-428.514 -428.514 -428.514] (0.0010) <00:15:47> ({r_i: None, r_t: [-842.645 -842.645 -842.645], critic_loss: 348.07598876953125, actor_loss: -1.4019999504089355, entropy: 0.25699999928474426, eps: 0.001})
Step:   33300, Reward: [-434.267 -434.267 -434.267] [71.794], Avg: [-428.531 -428.531 -428.531] (0.0010) <00:15:50> ({r_i: None, r_t: [-854.342 -854.342 -854.342], eps: 0.001})
Step:   33400, Reward: [-427.469 -427.469 -427.469] [78.818], Avg: [-428.528 -428.528 -428.528] (0.0010) <00:15:53> ({r_i: None, r_t: [-855.323 -855.323 -855.323], critic_loss: 438.01800537109375, actor_loss: -2.796999931335449, entropy: 0.2549999952316284, eps: 0.001})
Step:   33500, Reward: [-420.900 -420.900 -420.900] [61.020], Avg: [-428.505 -428.505 -428.505] (0.0010) <00:15:55> ({r_i: None, r_t: [-865.464 -865.464 -865.464], eps: 0.001})
Step:   33600, Reward: [-441.594 -441.594 -441.594] [54.722], Avg: [-428.544 -428.544 -428.544] (0.0010) <00:15:59> ({r_i: None, r_t: [-832.717 -832.717 -832.717], critic_loss: 401.27301025390625, actor_loss: -1.031000018119812, entropy: 0.2639999985694885, eps: 0.001})
Step:   33700, Reward: [-416.861 -416.861 -416.861] [59.671], Avg: [-428.509 -428.509 -428.509] (0.0010) <00:16:01> ({r_i: None, r_t: [-873.633 -873.633 -873.633], eps: 0.001})
Step:   33800, Reward: [-424.705 -424.705 -424.705] [68.129], Avg: [-428.498 -428.498 -428.498] (0.0010) <00:16:05> ({r_i: None, r_t: [-844.953 -844.953 -844.953], critic_loss: 398.89300537109375, actor_loss: -2.7709999084472656, entropy: 0.2619999945163727, eps: 0.001})
Step:   33900, Reward: [-448.412 -448.412 -448.412] [77.560], Avg: [-428.557 -428.557 -428.557] (0.0010) <00:16:07> ({r_i: None, r_t: [-858.549 -858.549 -858.549], eps: 0.001})
Step:   34000, Reward: [-386.693 -386.693 -386.693] [56.198], Avg: [-428.434 -428.434 -428.434] (0.0010) <00:16:10> ({r_i: None, r_t: [-844.952 -844.952 -844.952], critic_loss: 318.14300537109375, actor_loss: -1.909000039100647, entropy: 0.25200000405311584, eps: 0.001})
Step:   34100, Reward: [-450.708 -450.708 -450.708] [75.532], Avg: [-428.499 -428.499 -428.499] (0.0010) <00:16:13> ({r_i: None, r_t: [-842.442 -842.442 -842.442], eps: 0.001})
Step:   34200, Reward: [-430.630 -430.630 -430.630] [69.373], Avg: [-428.505 -428.505 -428.505] (0.0010) <00:16:16> ({r_i: None, r_t: [-797.231 -797.231 -797.231], critic_loss: 362.7200012207031, actor_loss: -1.6050000190734863, entropy: 0.2540000081062317, eps: 0.001})
Step:   34300, Reward: [-415.091 -415.091 -415.091] [65.283], Avg: [-428.466 -428.466 -428.466] (0.0010) <00:16:18> ({r_i: None, r_t: [-822.039 -822.039 -822.039], eps: 0.001})
Step:   34400, Reward: [-412.864 -412.864 -412.864] [57.079], Avg: [-428.421 -428.421 -428.421] (0.0010) <00:16:22> ({r_i: None, r_t: [-869.621 -869.621 -869.621], critic_loss: 295.31201171875, actor_loss: -1.4980000257492065, entropy: 0.26499998569488525, eps: 0.001})
Step:   34500, Reward: [-421.466 -421.466 -421.466] [94.082], Avg: [-428.401 -428.401 -428.401] (0.0010) <00:16:24> ({r_i: None, r_t: [-839.784 -839.784 -839.784], eps: 0.001})
Step:   34600, Reward: [-391.205 -391.205 -391.205] [83.555], Avg: [-428.294 -428.294 -428.294] (0.0010) <00:16:27> ({r_i: None, r_t: [-875.266 -875.266 -875.266], critic_loss: 350.5069885253906, actor_loss: -1.6619999408721924, entropy: 0.26100000739097595, eps: 0.001})
Step:   34700, Reward: [-421.031 -421.031 -421.031] [56.881], Avg: [-428.273 -428.273 -428.273] (0.0010) <00:16:30> ({r_i: None, r_t: [-831.221 -831.221 -831.221], eps: 0.001})
Step:   34800, Reward: [-409.581 -409.581 -409.581] [75.025], Avg: [-428.219 -428.219 -428.219] (0.0010) <00:16:33> ({r_i: None, r_t: [-888.429 -888.429 -888.429], critic_loss: 324.656005859375, actor_loss: -0.20100000500679016, entropy: 0.2590000033378601, eps: 0.001})
Step:   34900, Reward: [-460.699 -460.699 -460.699] [93.782], Avg: [-428.312 -428.312 -428.312] (0.0010) <00:16:35> ({r_i: None, r_t: [-837.363 -837.363 -837.363], eps: 0.001})
Step:   35000, Reward: [-438.511 -438.511 -438.511] [51.099], Avg: [-428.341 -428.341 -428.341] (0.0010) <00:16:39> ({r_i: None, r_t: [-824.055 -824.055 -824.055], critic_loss: 257.47198486328125, actor_loss: -1.069000005722046, entropy: 0.25, eps: 0.001})
Step:   35100, Reward: [-433.853 -433.853 -433.853] [85.398], Avg: [-428.357 -428.357 -428.357] (0.0010) <00:16:41> ({r_i: None, r_t: [-833.094 -833.094 -833.094], eps: 0.001})
Step:   35200, Reward: [-383.131 -383.131 -383.131] [58.812], Avg: [-428.229 -428.229 -428.229] (0.0010) <00:16:45> ({r_i: None, r_t: [-825.621 -825.621 -825.621], critic_loss: 286.1969909667969, actor_loss: -1.3739999532699585, entropy: 0.2540000081062317, eps: 0.001})
Step:   35300, Reward: [-389.741 -389.741 -389.741] [66.658], Avg: [-428.120 -428.120 -428.120] (0.0010) <00:16:47> ({r_i: None, r_t: [-860.313 -860.313 -860.313], eps: 0.001})
Step:   35400, Reward: [-427.774 -427.774 -427.774] [52.899], Avg: [-428.119 -428.119 -428.119] (0.0010) <00:16:50> ({r_i: None, r_t: [-858.969 -858.969 -858.969], critic_loss: 324.239990234375, actor_loss: -1.3459999561309814, entropy: 0.25699999928474426, eps: 0.001})
Step:   35500, Reward: [-417.379 -417.379 -417.379] [59.705], Avg: [-428.089 -428.089 -428.089] (0.0010) <00:16:52> ({r_i: None, r_t: [-840.883 -840.883 -840.883], eps: 0.001})
Step:   35600, Reward: [-420.109 -420.109 -420.109] [67.806], Avg: [-428.066 -428.066 -428.066] (0.0010) <00:16:56> ({r_i: None, r_t: [-848.128 -848.128 -848.128], critic_loss: 307.9049987792969, actor_loss: -1.6549999713897705, entropy: 0.25999999046325684, eps: 0.001})
Step:   35700, Reward: [-417.270 -417.270 -417.270] [80.675], Avg: [-428.036 -428.036 -428.036] (0.0010) <00:16:58> ({r_i: None, r_t: [-845.979 -845.979 -845.979], eps: 0.001})
Step:   35800, Reward: [-389.772 -389.772 -389.772] [56.640], Avg: [-427.930 -427.930 -427.930] (0.0010) <00:17:02> ({r_i: None, r_t: [-882.003 -882.003 -882.003], critic_loss: 355.24200439453125, actor_loss: -2.242000102996826, entropy: 0.2549999952316284, eps: 0.001})
Step:   35900, Reward: [-453.923 -453.923 -453.923] [65.813], Avg: [-428.002 -428.002 -428.002] (0.0010) <00:17:04> ({r_i: None, r_t: [-826.980 -826.980 -826.980], eps: 0.001})
Step:   36000, Reward: [-429.362 -429.362 -429.362] [47.256], Avg: [-428.006 -428.006 -428.006] (0.0010) <00:17:07> ({r_i: None, r_t: [-820.378 -820.378 -820.378], critic_loss: 460.8659973144531, actor_loss: -2.947999954223633, entropy: 0.2590000033378601, eps: 0.001})
Step:   36100, Reward: [-406.540 -406.540 -406.540] [82.418], Avg: [-427.946 -427.946 -427.946] (0.0010) <00:17:10> ({r_i: None, r_t: [-818.086 -818.086 -818.086], eps: 0.001})
Step:   36200, Reward: [-455.124 -455.124 -455.124] [55.644], Avg: [-428.021 -428.021 -428.021] (0.0010) <00:17:13> ({r_i: None, r_t: [-845.193 -845.193 -845.193], critic_loss: 406.1570129394531, actor_loss: -0.9509999752044678, entropy: 0.2630000114440918, eps: 0.001})
Step:   36300, Reward: [-438.357 -438.357 -438.357] [74.424], Avg: [-428.050 -428.050 -428.050] (0.0010) <00:17:16> ({r_i: None, r_t: [-855.624 -855.624 -855.624], eps: 0.001})
Step:   36400, Reward: [-425.145 -425.145 -425.145] [66.984], Avg: [-428.042 -428.042 -428.042] (0.0010) <00:17:19> ({r_i: None, r_t: [-869.159 -869.159 -869.159], critic_loss: 267.6889953613281, actor_loss: -1.9110000133514404, entropy: 0.2720000147819519, eps: 0.001})
Step:   36500, Reward: [-406.920 -406.920 -406.920] [64.347], Avg: [-427.984 -427.984 -427.984] (0.0010) <00:17:21> ({r_i: None, r_t: [-830.793 -830.793 -830.793], eps: 0.001})
Step:   36600, Reward: [-411.509 -411.509 -411.509] [78.302], Avg: [-427.939 -427.939 -427.939] (0.0010) <00:17:25> ({r_i: None, r_t: [-851.864 -851.864 -851.864], critic_loss: 333.9330139160156, actor_loss: -1.628999948501587, entropy: 0.26499998569488525, eps: 0.001})
Step:   36700, Reward: [-432.567 -432.567 -432.567] [66.491], Avg: [-427.952 -427.952 -427.952] (0.0010) <00:17:27> ({r_i: None, r_t: [-827.278 -827.278 -827.278], eps: 0.001})
Step:   36800, Reward: [-421.072 -421.072 -421.072] [67.754], Avg: [-427.933 -427.933 -427.933] (0.0010) <00:17:30> ({r_i: None, r_t: [-804.595 -804.595 -804.595], critic_loss: 238.11199951171875, actor_loss: -1.371999979019165, entropy: 0.2680000066757202, eps: 0.001})
Step:   36900, Reward: [-445.237 -445.237 -445.237] [77.189], Avg: [-427.980 -427.980 -427.980] (0.0010) <00:17:33> ({r_i: None, r_t: [-821.537 -821.537 -821.537], eps: 0.001})
Step:   37000, Reward: [-423.600 -423.600 -423.600] [49.202], Avg: [-427.968 -427.968 -427.968] (0.0010) <00:17:36> ({r_i: None, r_t: [-890.165 -890.165 -890.165], critic_loss: 364.031005859375, actor_loss: -2.2780001163482666, entropy: 0.2619999945163727, eps: 0.001})
Step:   37100, Reward: [-426.013 -426.013 -426.013] [54.810], Avg: [-427.963 -427.963 -427.963] (0.0010) <00:17:38> ({r_i: None, r_t: [-875.679 -875.679 -875.679], eps: 0.001})
Step:   37200, Reward: [-420.795 -420.795 -420.795] [94.987], Avg: [-427.943 -427.943 -427.943] (0.0010) <00:17:42> ({r_i: None, r_t: [-846.023 -846.023 -846.023], critic_loss: 302.5260009765625, actor_loss: -1.9140000343322754, entropy: 0.27399998903274536, eps: 0.001})
Step:   37300, Reward: [-451.608 -451.608 -451.608] [67.171], Avg: [-428.007 -428.007 -428.007] (0.0010) <00:17:44> ({r_i: None, r_t: [-874.218 -874.218 -874.218], eps: 0.001})
Step:   37400, Reward: [-392.198 -392.198 -392.198] [58.476], Avg: [-427.911 -427.911 -427.911] (0.0010) <00:17:48> ({r_i: None, r_t: [-877.722 -877.722 -877.722], critic_loss: 289.48199462890625, actor_loss: -2.38100004196167, entropy: 0.2669999897480011, eps: 0.001})
Step:   37500, Reward: [-438.797 -438.797 -438.797] [63.730], Avg: [-427.940 -427.940 -427.940] (0.0010) <00:17:50> ({r_i: None, r_t: [-843.096 -843.096 -843.096], eps: 0.001})
Step:   37600, Reward: [-415.221 -415.221 -415.221] [79.336], Avg: [-427.906 -427.906 -427.906] (0.0010) <00:17:53> ({r_i: None, r_t: [-864.377 -864.377 -864.377], critic_loss: 285.9280090332031, actor_loss: -0.2849999964237213, entropy: 0.25999999046325684, eps: 0.001})
Step:   37700, Reward: [-418.982 -418.982 -418.982] [72.593], Avg: [-427.883 -427.883 -427.883] (0.0010) <00:17:55> ({r_i: None, r_t: [-845.062 -845.062 -845.062], eps: 0.001})
Step:   37800, Reward: [-420.788 -420.788 -420.788] [57.825], Avg: [-427.864 -427.864 -427.864] (0.0010) <00:17:59> ({r_i: None, r_t: [-861.113 -861.113 -861.113], critic_loss: 275.3429870605469, actor_loss: -1.2259999513626099, entropy: 0.2669999897480011, eps: 0.001})
Step:   37900, Reward: [-383.127 -383.127 -383.127] [75.799], Avg: [-427.746 -427.746 -427.746] (0.0010) <00:18:01> ({r_i: None, r_t: [-819.078 -819.078 -819.078], eps: 0.001})
Step:   38000, Reward: [-410.723 -410.723 -410.723] [70.334], Avg: [-427.702 -427.702 -427.702] (0.0010) <00:18:05> ({r_i: None, r_t: [-908.402 -908.402 -908.402], critic_loss: 322.6340026855469, actor_loss: -0.9100000262260437, entropy: 0.26600000262260437, eps: 0.001})
Step:   38100, Reward: [-427.939 -427.939 -427.939] [58.513], Avg: [-427.702 -427.702 -427.702] (0.0010) <00:18:07> ({r_i: None, r_t: [-875.009 -875.009 -875.009], eps: 0.001})
Step:   38200, Reward: [-424.453 -424.453 -424.453] [63.392], Avg: [-427.694 -427.694 -427.694] (0.0010) <00:18:10> ({r_i: None, r_t: [-863.471 -863.471 -863.471], critic_loss: 275.4209899902344, actor_loss: -0.6880000233650208, entropy: 0.27900001406669617, eps: 0.001})
Step:   38300, Reward: [-416.822 -416.822 -416.822] [49.906], Avg: [-427.666 -427.666 -427.666] (0.0010) <00:18:13> ({r_i: None, r_t: [-865.279 -865.279 -865.279], eps: 0.001})
Step:   38400, Reward: [-423.619 -423.619 -423.619] [66.532], Avg: [-427.655 -427.655 -427.655] (0.0010) <00:18:16> ({r_i: None, r_t: [-818.201 -818.201 -818.201], critic_loss: 367.9100036621094, actor_loss: -2.9830000400543213, entropy: 0.2759999930858612, eps: 0.001})
Step:   38500, Reward: [-421.516 -421.516 -421.516] [75.059], Avg: [-427.639 -427.639 -427.639] (0.0010) <00:18:18> ({r_i: None, r_t: [-845.609 -845.609 -845.609], eps: 0.001})
Step:   38600, Reward: [-415.480 -415.480 -415.480] [97.694], Avg: [-427.608 -427.608 -427.608] (0.0010) <00:18:22> ({r_i: None, r_t: [-871.641 -871.641 -871.641], critic_loss: 373.4230041503906, actor_loss: -2.381999969482422, entropy: 0.26499998569488525, eps: 0.001})
Step:   38700, Reward: [-425.578 -425.578 -425.578] [54.648], Avg: [-427.602 -427.602 -427.602] (0.0010) <00:18:24> ({r_i: None, r_t: [-844.905 -844.905 -844.905], eps: 0.001})
Step:   38800, Reward: [-429.849 -429.849 -429.849] [57.367], Avg: [-427.608 -427.608 -427.608] (0.0010) <00:18:28> ({r_i: None, r_t: [-846.241 -846.241 -846.241], critic_loss: 351.84100341796875, actor_loss: -1.9270000457763672, entropy: 0.26899999380111694, eps: 0.001})
Step:   38900, Reward: [-422.057 -422.057 -422.057] [76.688], Avg: [-427.594 -427.594 -427.594] (0.0010) <00:18:30> ({r_i: None, r_t: [-908.663 -908.663 -908.663], eps: 0.001})
Step:   39000, Reward: [-418.786 -418.786 -418.786] [85.670], Avg: [-427.572 -427.572 -427.572] (0.0010) <00:18:33> ({r_i: None, r_t: [-860.042 -860.042 -860.042], critic_loss: 405.27301025390625, actor_loss: -1.3300000429153442, entropy: 0.2759999930858612, eps: 0.001})
Step:   39100, Reward: [-437.825 -437.825 -437.825] [58.399], Avg: [-427.598 -427.598 -427.598] (0.0010) <00:18:35> ({r_i: None, r_t: [-821.639 -821.639 -821.639], eps: 0.001})
Step:   39200, Reward: [-414.003 -414.003 -414.003] [79.649], Avg: [-427.563 -427.563 -427.563] (0.0010) <00:18:39> ({r_i: None, r_t: [-832.870 -832.870 -832.870], critic_loss: 336.53900146484375, actor_loss: -2.11299991607666, entropy: 0.27300000190734863, eps: 0.001})
Step:   39300, Reward: [-405.643 -405.643 -405.643] [72.737], Avg: [-427.507 -427.507 -427.507] (0.0010) <00:18:41> ({r_i: None, r_t: [-824.747 -824.747 -824.747], eps: 0.001})
Step:   39400, Reward: [-409.297 -409.297 -409.297] [45.463], Avg: [-427.461 -427.461 -427.461] (0.0010) <00:18:45> ({r_i: None, r_t: [-848.886 -848.886 -848.886], critic_loss: 228.51100158691406, actor_loss: -1.0920000076293945, entropy: 0.2800000011920929, eps: 0.001})
Step:   39500, Reward: [-441.374 -441.374 -441.374] [80.165], Avg: [-427.496 -427.496 -427.496] (0.0010) <00:18:47> ({r_i: None, r_t: [-866.587 -866.587 -866.587], eps: 0.001})
Step:   39600, Reward: [-438.747 -438.747 -438.747] [61.295], Avg: [-427.525 -427.525 -427.525] (0.0010) <00:18:50> ({r_i: None, r_t: [-876.743 -876.743 -876.743], critic_loss: 250.68299865722656, actor_loss: -1.4980000257492065, entropy: 0.2930000126361847, eps: 0.001})
Step:   39700, Reward: [-415.747 -415.747 -415.747] [68.123], Avg: [-427.495 -427.495 -427.495] (0.0010) <00:18:53> ({r_i: None, r_t: [-875.386 -875.386 -875.386], eps: 0.001})
Step:   39800, Reward: [-421.706 -421.706 -421.706] [54.039], Avg: [-427.481 -427.481 -427.481] (0.0010) <00:18:56> ({r_i: None, r_t: [-861.720 -861.720 -861.720], critic_loss: 346.927001953125, actor_loss: -1.718000054359436, entropy: 0.27000001072883606, eps: 0.001})
Step:   39900, Reward: [-444.565 -444.565 -444.565] [57.673], Avg: [-427.523 -427.523 -427.523] (0.0010) <00:18:58> ({r_i: None, r_t: [-830.474 -830.474 -830.474], eps: 0.001})
Step:   40000, Reward: [-439.092 -439.092 -439.092] [67.524], Avg: [-427.552 -427.552 -427.552] (0.0010) <00:19:02> ({r_i: None, r_t: [-832.242 -832.242 -832.242], critic_loss: 240.13400268554688, actor_loss: -1.9179999828338623, entropy: 0.26600000262260437, eps: 0.001})
Step:   40100, Reward: [-421.244 -421.244 -421.244] [61.791], Avg: [-427.537 -427.537 -427.537] (0.0010) <00:19:04> ({r_i: None, r_t: [-836.967 -836.967 -836.967], eps: 0.001})
Step:   40200, Reward: [-428.279 -428.279 -428.279] [84.465], Avg: [-427.538 -427.538 -427.538] (0.0010) <00:19:07> ({r_i: None, r_t: [-807.631 -807.631 -807.631], critic_loss: 237.5749969482422, actor_loss: -1.2020000219345093, entropy: 0.2639999985694885, eps: 0.001})
Step:   40300, Reward: [-424.347 -424.347 -424.347] [82.948], Avg: [-427.531 -427.531 -427.531] (0.0010) <00:19:10> ({r_i: None, r_t: [-836.294 -836.294 -836.294], eps: 0.001})
Step:   40400, Reward: [-414.249 -414.249 -414.249] [71.990], Avg: [-427.498 -427.498 -427.498] (0.0010) <00:19:13> ({r_i: None, r_t: [-840.027 -840.027 -840.027], critic_loss: 351.7139892578125, actor_loss: -1.5190000534057617, entropy: 0.2630000114440918, eps: 0.001})
Step:   40500, Reward: [-402.105 -402.105 -402.105] [76.416], Avg: [-427.435 -427.435 -427.435] (0.0010) <00:19:15> ({r_i: None, r_t: [-859.379 -859.379 -859.379], eps: 0.001})
Step:   40600, Reward: [-465.033 -465.033 -465.033] [72.618], Avg: [-427.528 -427.528 -427.528] (0.0010) <00:19:19> ({r_i: None, r_t: [-797.966 -797.966 -797.966], critic_loss: 281.531005859375, actor_loss: -2.2190001010894775, entropy: 0.27900001406669617, eps: 0.001})
Step:   40700, Reward: [-396.953 -396.953 -396.953] [44.170], Avg: [-427.453 -427.453 -427.453] (0.0010) <00:19:21> ({r_i: None, r_t: [-834.889 -834.889 -834.889], eps: 0.001})
Step:   40800, Reward: [-414.613 -414.613 -414.613] [77.577], Avg: [-427.421 -427.421 -427.421] (0.0010) <00:19:25> ({r_i: None, r_t: [-885.976 -885.976 -885.976], critic_loss: 249.3820037841797, actor_loss: -1.218999981880188, entropy: 0.2590000033378601, eps: 0.001})
Step:   40900, Reward: [-426.131 -426.131 -426.131] [83.514], Avg: [-427.418 -427.418 -427.418] (0.0010) <00:19:27> ({r_i: None, r_t: [-880.302 -880.302 -880.302], eps: 0.001})
Step:   41000, Reward: [-418.372 -418.372 -418.372] [68.449], Avg: [-427.396 -427.396 -427.396] (0.0010) <00:19:30> ({r_i: None, r_t: [-808.912 -808.912 -808.912], critic_loss: 462.56298828125, actor_loss: -2.2820000648498535, entropy: 0.27300000190734863, eps: 0.001})
Step:   41100, Reward: [-376.031 -376.031 -376.031] [41.448], Avg: [-427.271 -427.271 -427.271] (0.0010) <00:19:32> ({r_i: None, r_t: [-874.435 -874.435 -874.435], eps: 0.001})
Step:   41200, Reward: [-439.972 -439.972 -439.972] [57.752], Avg: [-427.302 -427.302 -427.302] (0.0010) <00:19:36> ({r_i: None, r_t: [-850.989 -850.989 -850.989], critic_loss: 367.302001953125, actor_loss: -1.2610000371932983, entropy: 0.2800000011920929, eps: 0.001})
Step:   41300, Reward: [-458.400 -458.400 -458.400] [58.072], Avg: [-427.377 -427.377 -427.377] (0.0010) <00:19:38> ({r_i: None, r_t: [-838.095 -838.095 -838.095], eps: 0.001})
Step:   41400, Reward: [-392.276 -392.276 -392.276] [71.326], Avg: [-427.293 -427.293 -427.293] (0.0010) <00:19:42> ({r_i: None, r_t: [-857.243 -857.243 -857.243], critic_loss: 296.0840148925781, actor_loss: -2.4820001125335693, entropy: 0.27300000190734863, eps: 0.001})
Step:   41500, Reward: [-434.625 -434.625 -434.625] [61.763], Avg: [-427.310 -427.310 -427.310] (0.0010) <00:19:44> ({r_i: None, r_t: [-833.035 -833.035 -833.035], eps: 0.001})
Step:   41600, Reward: [-406.424 -406.424 -406.424] [45.253], Avg: [-427.260 -427.260 -427.260] (0.0010) <00:19:47> ({r_i: None, r_t: [-808.894 -808.894 -808.894], critic_loss: 284.3169860839844, actor_loss: -1.3660000562667847, entropy: 0.26499998569488525, eps: 0.001})
Step:   41700, Reward: [-428.757 -428.757 -428.757] [49.624], Avg: [-427.264 -427.264 -427.264] (0.0010) <00:19:50> ({r_i: None, r_t: [-880.044 -880.044 -880.044], eps: 0.001})
Step:   41800, Reward: [-436.873 -436.873 -436.873] [71.157], Avg: [-427.287 -427.287 -427.287] (0.0010) <00:19:53> ({r_i: None, r_t: [-898.452 -898.452 -898.452], critic_loss: 238.69500732421875, actor_loss: -0.8880000114440918, entropy: 0.2680000066757202, eps: 0.001})
Step:   41900, Reward: [-402.031 -402.031 -402.031] [62.438], Avg: [-427.227 -427.227 -427.227] (0.0010) <00:19:55> ({r_i: None, r_t: [-852.274 -852.274 -852.274], eps: 0.001})
Step:   42000, Reward: [-399.917 -399.917 -399.917] [63.532], Avg: [-427.162 -427.162 -427.162] (0.0010) <00:19:59> ({r_i: None, r_t: [-860.193 -860.193 -860.193], critic_loss: 291.0050048828125, actor_loss: -1.0839999914169312, entropy: 0.26499998569488525, eps: 0.001})
Step:   42100, Reward: [-433.082 -433.082 -433.082] [76.901], Avg: [-427.176 -427.176 -427.176] (0.0010) <00:20:01> ({r_i: None, r_t: [-854.578 -854.578 -854.578], eps: 0.001})
Step:   42200, Reward: [-435.618 -435.618 -435.618] [80.539], Avg: [-427.196 -427.196 -427.196] (0.0010) <00:20:05> ({r_i: None, r_t: [-857.740 -857.740 -857.740], critic_loss: 325.91400146484375, actor_loss: -3.4660000801086426, entropy: 0.25699999928474426, eps: 0.001})
Step:   42300, Reward: [-417.760 -417.760 -417.760] [74.197], Avg: [-427.173 -427.173 -427.173] (0.0010) <00:20:07> ({r_i: None, r_t: [-808.841 -808.841 -808.841], eps: 0.001})
Step:   42400, Reward: [-423.731 -423.731 -423.731] [76.103], Avg: [-427.165 -427.165 -427.165] (0.0010) <00:20:10> ({r_i: None, r_t: [-852.123 -852.123 -852.123], critic_loss: 255.63900756835938, actor_loss: -0.703000009059906, entropy: 0.26899999380111694, eps: 0.001})
Step:   42500, Reward: [-417.686 -417.686 -417.686] [73.345], Avg: [-427.143 -427.143 -427.143] (0.0010) <00:20:12> ({r_i: None, r_t: [-855.499 -855.499 -855.499], eps: 0.001})
Step:   42600, Reward: [-445.257 -445.257 -445.257] [92.732], Avg: [-427.186 -427.186 -427.186] (0.0010) <00:20:16> ({r_i: None, r_t: [-874.904 -874.904 -874.904], critic_loss: 400.59698486328125, actor_loss: -2.627000093460083, entropy: 0.2639999985694885, eps: 0.001})
Step:   42700, Reward: [-434.047 -434.047 -434.047] [79.487], Avg: [-427.202 -427.202 -427.202] (0.0010) <00:20:18> ({r_i: None, r_t: [-852.629 -852.629 -852.629], eps: 0.001})
Step:   42800, Reward: [-420.670 -420.670 -420.670] [73.177], Avg: [-427.186 -427.186 -427.186] (0.0010) <00:20:22> ({r_i: None, r_t: [-847.190 -847.190 -847.190], critic_loss: 394.8089904785156, actor_loss: -2.1710000038146973, entropy: 0.2680000066757202, eps: 0.001})
Step:   42900, Reward: [-384.005 -384.005 -384.005] [67.441], Avg: [-427.086 -427.086 -427.086] (0.0010) <00:20:24> ({r_i: None, r_t: [-886.668 -886.668 -886.668], eps: 0.001})
Step:   43000, Reward: [-407.197 -407.197 -407.197] [83.222], Avg: [-427.040 -427.040 -427.040] (0.0010) <00:20:27> ({r_i: None, r_t: [-879.528 -879.528 -879.528], critic_loss: 262.2099914550781, actor_loss: -1.2690000534057617, entropy: 0.26499998569488525, eps: 0.001})
Step:   43100, Reward: [-428.253 -428.253 -428.253] [68.652], Avg: [-427.043 -427.043 -427.043] (0.0010) <00:20:29> ({r_i: None, r_t: [-837.346 -837.346 -837.346], eps: 0.001})
Step:   43200, Reward: [-446.796 -446.796 -446.796] [61.611], Avg: [-427.088 -427.088 -427.088] (0.0010) <00:20:33> ({r_i: None, r_t: [-778.833 -778.833 -778.833], critic_loss: 217.3260040283203, actor_loss: -1.1399999856948853, entropy: 0.2590000033378601, eps: 0.001})
Step:   43300, Reward: [-367.439 -367.439 -367.439] [45.711], Avg: [-426.951 -426.951 -426.951] (0.0010) <00:20:35> ({r_i: None, r_t: [-844.167 -844.167 -844.167], eps: 0.001})
Step:   43400, Reward: [-421.694 -421.694 -421.694] [82.217], Avg: [-426.939 -426.939 -426.939] (0.0010) <00:20:39> ({r_i: None, r_t: [-821.505 -821.505 -821.505], critic_loss: 370.8609924316406, actor_loss: -1.5399999618530273, entropy: 0.2669999897480011, eps: 0.001})
Step:   43500, Reward: [-429.110 -429.110 -429.110] [74.529], Avg: [-426.944 -426.944 -426.944] (0.0010) <00:20:41> ({r_i: None, r_t: [-832.351 -832.351 -832.351], eps: 0.001})
Step:   43600, Reward: [-435.029 -435.029 -435.029] [63.558], Avg: [-426.962 -426.962 -426.962] (0.0010) <00:20:44> ({r_i: None, r_t: [-882.597 -882.597 -882.597], critic_loss: 353.78399658203125, actor_loss: -1.965999960899353, entropy: 0.2590000033378601, eps: 0.001})
Step:   43700, Reward: [-391.146 -391.146 -391.146] [54.264], Avg: [-426.880 -426.880 -426.880] (0.0010) <00:20:47> ({r_i: None, r_t: [-840.905 -840.905 -840.905], eps: 0.001})
Step:   43800, Reward: [-436.139 -436.139 -436.139] [94.955], Avg: [-426.901 -426.901 -426.901] (0.0010) <00:20:50> ({r_i: None, r_t: [-874.080 -874.080 -874.080], critic_loss: 315.4739990234375, actor_loss: -1.9160000085830688, entropy: 0.2540000081062317, eps: 0.001})
Step:   43900, Reward: [-442.554 -442.554 -442.554] [61.575], Avg: [-426.937 -426.937 -426.937] (0.0010) <00:20:53> ({r_i: None, r_t: [-865.476 -865.476 -865.476], eps: 0.001})
Step:   44000, Reward: [-435.965 -435.965 -435.965] [51.474], Avg: [-426.958 -426.958 -426.958] (0.0010) <00:20:56> ({r_i: None, r_t: [-873.339 -873.339 -873.339], critic_loss: 406.4540100097656, actor_loss: -3.671999931335449, entropy: 0.26600000262260437, eps: 0.001})
Step:   44100, Reward: [-460.875 -460.875 -460.875] [67.693], Avg: [-427.034 -427.034 -427.034] (0.0010) <00:20:58> ({r_i: None, r_t: [-814.537 -814.537 -814.537], eps: 0.001})
Step:   44200, Reward: [-423.936 -423.936 -423.936] [72.081], Avg: [-427.027 -427.027 -427.027] (0.0010) <00:21:02> ({r_i: None, r_t: [-857.891 -857.891 -857.891], critic_loss: 334.3009948730469, actor_loss: -1.6549999713897705, entropy: 0.2619999945163727, eps: 0.001})
Step:   44300, Reward: [-467.177 -467.177 -467.177] [47.465], Avg: [-427.118 -427.118 -427.118] (0.0010) <00:21:04> ({r_i: None, r_t: [-846.348 -846.348 -846.348], eps: 0.001})
Step:   44400, Reward: [-435.820 -435.820 -435.820] [69.143], Avg: [-427.137 -427.137 -427.137] (0.0010) <00:21:07> ({r_i: None, r_t: [-853.512 -853.512 -853.512], critic_loss: 339.2300109863281, actor_loss: -2.7149999141693115, entropy: 0.2619999945163727, eps: 0.001})
Step:   44500, Reward: [-421.293 -421.293 -421.293] [81.311], Avg: [-427.124 -427.124 -427.124] (0.0010) <00:21:09> ({r_i: None, r_t: [-883.265 -883.265 -883.265], eps: 0.001})
Step:   44600, Reward: [-464.001 -464.001 -464.001] [48.680], Avg: [-427.207 -427.207 -427.207] (0.0010) <00:21:13> ({r_i: None, r_t: [-841.660 -841.660 -841.660], critic_loss: 439.07000732421875, actor_loss: -3.7139999866485596, entropy: 0.2630000114440918, eps: 0.001})
Step:   44700, Reward: [-417.756 -417.756 -417.756] [59.963], Avg: [-427.186 -427.186 -427.186] (0.0010) <00:21:15> ({r_i: None, r_t: [-837.971 -837.971 -837.971], eps: 0.001})
Step:   44800, Reward: [-428.323 -428.323 -428.323] [73.648], Avg: [-427.188 -427.188 -427.188] (0.0010) <00:21:19> ({r_i: None, r_t: [-844.051 -844.051 -844.051], critic_loss: 263.8940124511719, actor_loss: -1.444000005722046, entropy: 0.25699999928474426, eps: 0.001})
Step:   44900, Reward: [-396.720 -396.720 -396.720] [70.801], Avg: [-427.120 -427.120 -427.120] (0.0010) <00:21:21> ({r_i: None, r_t: [-852.317 -852.317 -852.317], eps: 0.001})
Step:   45000, Reward: [-457.493 -457.493 -457.493] [55.508], Avg: [-427.188 -427.188 -427.188] (0.0010) <00:21:24> ({r_i: None, r_t: [-877.355 -877.355 -877.355], critic_loss: 439.281005859375, actor_loss: -3.562000036239624, entropy: 0.24400000274181366, eps: 0.001})
Step:   45100, Reward: [-405.073 -405.073 -405.073] [66.931], Avg: [-427.139 -427.139 -427.139] (0.0010) <00:21:27> ({r_i: None, r_t: [-865.986 -865.986 -865.986], eps: 0.001})
Step:   45200, Reward: [-426.958 -426.958 -426.958] [92.017], Avg: [-427.138 -427.138 -427.138] (0.0010) <00:21:30> ({r_i: None, r_t: [-868.414 -868.414 -868.414], critic_loss: 307.7030029296875, actor_loss: -1.1109999418258667, entropy: 0.26600000262260437, eps: 0.001})
Step:   45300, Reward: [-411.178 -411.178 -411.178] [100.671], Avg: [-427.103 -427.103 -427.103] (0.0010) <00:21:32> ({r_i: None, r_t: [-878.057 -878.057 -878.057], eps: 0.001})
Step:   45400, Reward: [-460.753 -460.753 -460.753] [56.440], Avg: [-427.177 -427.177 -427.177] (0.0010) <00:21:36> ({r_i: None, r_t: [-893.350 -893.350 -893.350], critic_loss: 278.4729919433594, actor_loss: -0.8740000128746033, entropy: 0.2540000081062317, eps: 0.001})
Step:   45500, Reward: [-420.108 -420.108 -420.108] [68.960], Avg: [-427.162 -427.162 -427.162] (0.0010) <00:21:38> ({r_i: None, r_t: [-849.342 -849.342 -849.342], eps: 0.001})
Step:   45600, Reward: [-417.337 -417.337 -417.337] [85.048], Avg: [-427.140 -427.140 -427.140] (0.0010) <00:21:41> ({r_i: None, r_t: [-861.522 -861.522 -861.522], critic_loss: 288.7090148925781, actor_loss: -1.187000036239624, entropy: 0.24699999392032623, eps: 0.001})
Step:   45700, Reward: [-450.197 -450.197 -450.197] [55.648], Avg: [-427.191 -427.191 -427.191] (0.0010) <00:21:44> ({r_i: None, r_t: [-865.379 -865.379 -865.379], eps: 0.001})
Step:   45800, Reward: [-432.474 -432.474 -432.474] [61.409], Avg: [-427.202 -427.202 -427.202] (0.0010) <00:21:47> ({r_i: None, r_t: [-933.626 -933.626 -933.626], critic_loss: 450.1600036621094, actor_loss: -3.1710000038146973, entropy: 0.2549999952316284, eps: 0.001})
Step:   45900, Reward: [-412.668 -412.668 -412.668] [88.448], Avg: [-427.170 -427.170 -427.170] (0.0010) <00:21:49> ({r_i: None, r_t: [-865.647 -865.647 -865.647], eps: 0.001})
Step:   46000, Reward: [-382.256 -382.256 -382.256] [92.755], Avg: [-427.073 -427.073 -427.073] (0.0010) <00:21:53> ({r_i: None, r_t: [-838.724 -838.724 -838.724], critic_loss: 393.8349914550781, actor_loss: -1.746000051498413, entropy: 0.257999986410141, eps: 0.001})
Step:   46100, Reward: [-442.147 -442.147 -442.147] [87.157], Avg: [-427.106 -427.106 -427.106] (0.0010) <00:21:55> ({r_i: None, r_t: [-849.581 -849.581 -849.581], eps: 0.001})
Step:   46200, Reward: [-456.439 -456.439 -456.439] [86.828], Avg: [-427.169 -427.169 -427.169] (0.0010) <00:21:59> ({r_i: None, r_t: [-868.658 -868.658 -868.658], critic_loss: 307.8330078125, actor_loss: -2.4760000705718994, entropy: 0.24500000476837158, eps: 0.001})
Step:   46300, Reward: [-440.730 -440.730 -440.730] [77.087], Avg: [-427.198 -427.198 -427.198] (0.0010) <00:22:01> ({r_i: None, r_t: [-825.409 -825.409 -825.409], eps: 0.001})
Step:   46400, Reward: [-433.550 -433.550 -433.550] [76.371], Avg: [-427.212 -427.212 -427.212] (0.0010) <00:22:04> ({r_i: None, r_t: [-873.023 -873.023 -873.023], critic_loss: 450.77099609375, actor_loss: -2.694000005722046, entropy: 0.24799999594688416, eps: 0.001})
Step:   46500, Reward: [-435.037 -435.037 -435.037] [75.508], Avg: [-427.229 -427.229 -427.229] (0.0010) <00:22:07> ({r_i: None, r_t: [-879.031 -879.031 -879.031], eps: 0.001})
Step:   46600, Reward: [-413.389 -413.389 -413.389] [83.962], Avg: [-427.199 -427.199 -427.199] (0.0010) <00:22:10> ({r_i: None, r_t: [-826.334 -826.334 -826.334], critic_loss: 300.49700927734375, actor_loss: -1.7139999866485596, entropy: 0.24400000274181366, eps: 0.001})
Step:   46700, Reward: [-407.862 -407.862 -407.862] [68.461], Avg: [-427.158 -427.158 -427.158] (0.0010) <00:22:12> ({r_i: None, r_t: [-812.972 -812.972 -812.972], eps: 0.001})
Step:   46800, Reward: [-413.852 -413.852 -413.852] [77.162], Avg: [-427.129 -427.129 -427.129] (0.0010) <00:22:16> ({r_i: None, r_t: [-851.395 -851.395 -851.395], critic_loss: 256.3370056152344, actor_loss: -2.121000051498413, entropy: 0.25600001215934753, eps: 0.001})
Step:   46900, Reward: [-434.111 -434.111 -434.111] [77.739], Avg: [-427.144 -427.144 -427.144] (0.0010) <00:22:18> ({r_i: None, r_t: [-873.277 -873.277 -873.277], eps: 0.001})
Step:   47000, Reward: [-419.985 -419.985 -419.985] [82.446], Avg: [-427.129 -427.129 -427.129] (0.0010) <00:22:22> ({r_i: None, r_t: [-801.128 -801.128 -801.128], critic_loss: 373.2359924316406, actor_loss: -3.0929999351501465, entropy: 0.2549999952316284, eps: 0.001})
Step:   47100, Reward: [-417.315 -417.315 -417.315] [71.233], Avg: [-427.108 -427.108 -427.108] (0.0010) <00:22:24> ({r_i: None, r_t: [-814.030 -814.030 -814.030], eps: 0.001})
Step:   47200, Reward: [-427.524 -427.524 -427.524] [50.065], Avg: [-427.109 -427.109 -427.109] (0.0010) <00:22:27> ({r_i: None, r_t: [-839.000 -839.000 -839.000], critic_loss: 251.7030029296875, actor_loss: -2.3259999752044678, entropy: 0.23899999260902405, eps: 0.001})
Step:   47300, Reward: [-419.326 -419.326 -419.326] [55.550], Avg: [-427.093 -427.093 -427.093] (0.0010) <00:22:29> ({r_i: None, r_t: [-833.705 -833.705 -833.705], eps: 0.001})
Step:   47400, Reward: [-429.339 -429.339 -429.339] [86.704], Avg: [-427.097 -427.097 -427.097] (0.0010) <00:22:33> ({r_i: None, r_t: [-839.373 -839.373 -839.373], critic_loss: 239.531005859375, actor_loss: -1.61899995803833, entropy: 0.2460000067949295, eps: 0.001})
Step:   47500, Reward: [-413.584 -413.584 -413.584] [62.343], Avg: [-427.069 -427.069 -427.069] (0.0010) <00:22:35> ({r_i: None, r_t: [-857.646 -857.646 -857.646], eps: 0.001})
Step:   47600, Reward: [-426.317 -426.317 -426.317] [39.497], Avg: [-427.067 -427.067 -427.067] (0.0010) <00:22:38> ({r_i: None, r_t: [-859.237 -859.237 -859.237], critic_loss: 326.0450134277344, actor_loss: -1.784000039100647, entropy: 0.25, eps: 0.001})
Step:   47700, Reward: [-414.597 -414.597 -414.597] [57.701], Avg: [-427.041 -427.041 -427.041] (0.0010) <00:22:41> ({r_i: None, r_t: [-861.714 -861.714 -861.714], eps: 0.001})
Step:   47800, Reward: [-412.462 -412.462 -412.462] [79.120], Avg: [-427.011 -427.011 -427.011] (0.0010) <00:22:44> ({r_i: None, r_t: [-866.909 -866.909 -866.909], critic_loss: 379.4410095214844, actor_loss: -1.878000020980835, entropy: 0.2680000066757202, eps: 0.001})
Step:   47900, Reward: [-418.608 -418.608 -418.608] [54.864], Avg: [-426.993 -426.993 -426.993] (0.0010) <00:22:46> ({r_i: None, r_t: [-871.844 -871.844 -871.844], eps: 0.001})
Step:   48000, Reward: [-423.977 -423.977 -423.977] [56.310], Avg: [-426.987 -426.987 -426.987] (0.0010) <00:22:50> ({r_i: None, r_t: [-818.876 -818.876 -818.876], critic_loss: 517.9400024414062, actor_loss: -4.275000095367432, entropy: 0.2590000033378601, eps: 0.001})
Step:   48100, Reward: [-395.876 -395.876 -395.876] [82.289], Avg: [-426.923 -426.923 -426.923] (0.0010) <00:22:52> ({r_i: None, r_t: [-890.629 -890.629 -890.629], eps: 0.001})
Step:   48200, Reward: [-406.981 -406.981 -406.981] [75.192], Avg: [-426.881 -426.881 -426.881] (0.0010) <00:22:56> ({r_i: None, r_t: [-849.676 -849.676 -849.676], critic_loss: 442.2300109863281, actor_loss: -2.7239999771118164, entropy: 0.24699999392032623, eps: 0.001})
Step:   48300, Reward: [-426.913 -426.913 -426.913] [63.856], Avg: [-426.881 -426.881 -426.881] (0.0010) <00:22:58> ({r_i: None, r_t: [-882.343 -882.343 -882.343], eps: 0.001})
Step:   48400, Reward: [-438.174 -438.174 -438.174] [57.833], Avg: [-426.905 -426.905 -426.905] (0.0010) <00:23:01> ({r_i: None, r_t: [-843.889 -843.889 -843.889], critic_loss: 337.7820129394531, actor_loss: -3.1070001125335693, entropy: 0.2460000067949295, eps: 0.001})
Step:   48500, Reward: [-430.296 -430.296 -430.296] [67.771], Avg: [-426.912 -426.912 -426.912] (0.0010) <00:23:03> ({r_i: None, r_t: [-900.210 -900.210 -900.210], eps: 0.001})
Step:   48600, Reward: [-408.090 -408.090 -408.090] [64.815], Avg: [-426.873 -426.873 -426.873] (0.0010) <00:23:07> ({r_i: None, r_t: [-857.546 -857.546 -857.546], critic_loss: 397.43499755859375, actor_loss: -1.9509999752044678, entropy: 0.24799999594688416, eps: 0.001})
Step:   48700, Reward: [-462.634 -462.634 -462.634] [78.276], Avg: [-426.946 -426.946 -426.946] (0.0010) <00:23:09> ({r_i: None, r_t: [-875.481 -875.481 -875.481], eps: 0.001})
Step:   48800, Reward: [-446.526 -446.526 -446.526] [44.567], Avg: [-426.986 -426.986 -426.986] (0.0010) <00:23:12> ({r_i: None, r_t: [-814.305 -814.305 -814.305], critic_loss: 262.0790100097656, actor_loss: -1.3329999446868896, entropy: 0.25099998712539673, eps: 0.001})
Step:   48900, Reward: [-402.238 -402.238 -402.238] [47.687], Avg: [-426.936 -426.936 -426.936] (0.0010) <00:23:15> ({r_i: None, r_t: [-840.841 -840.841 -840.841], eps: 0.001})
Step:   49000, Reward: [-435.110 -435.110 -435.110] [60.781], Avg: [-426.952 -426.952 -426.952] (0.0010) <00:23:18> ({r_i: None, r_t: [-873.181 -873.181 -873.181], critic_loss: 267.1210021972656, actor_loss: -2.0829999446868896, entropy: 0.2460000067949295, eps: 0.001})
Step:   49100, Reward: [-405.370 -405.370 -405.370] [58.517], Avg: [-426.909 -426.909 -426.909] (0.0010) <00:23:20> ({r_i: None, r_t: [-826.619 -826.619 -826.619], eps: 0.001})
Step:   49200, Reward: [-418.267 -418.267 -418.267] [65.268], Avg: [-426.891 -426.891 -426.891] (0.0010) <00:23:24> ({r_i: None, r_t: [-798.612 -798.612 -798.612], critic_loss: 324.0610046386719, actor_loss: -2.4579999446868896, entropy: 0.23899999260902405, eps: 0.001})
Step:   49300, Reward: [-408.915 -408.915 -408.915] [71.451], Avg: [-426.855 -426.855 -426.855] (0.0010) <00:23:26> ({r_i: None, r_t: [-886.306 -886.306 -886.306], eps: 0.001})
Step:   49400, Reward: [-452.268 -452.268 -452.268] [69.533], Avg: [-426.906 -426.906 -426.906] (0.0010) <00:23:30> ({r_i: None, r_t: [-825.642 -825.642 -825.642], critic_loss: 276.9549865722656, actor_loss: -1.152999997138977, entropy: 0.25600001215934753, eps: 0.001})
Step:   49500, Reward: [-429.557 -429.557 -429.557] [75.454], Avg: [-426.911 -426.911 -426.911] (0.0010) <00:23:32> ({r_i: None, r_t: [-849.601 -849.601 -849.601], eps: 0.001})
Step:   49600, Reward: [-412.302 -412.302 -412.302] [76.252], Avg: [-426.882 -426.882 -426.882] (0.0010) <00:23:35> ({r_i: None, r_t: [-819.405 -819.405 -819.405], critic_loss: 381.8940124511719, actor_loss: -3.0439999103546143, entropy: 0.23899999260902405, eps: 0.001})
Step:   49700, Reward: [-452.165 -452.165 -452.165] [65.572], Avg: [-426.933 -426.933 -426.933] (0.0010) <00:23:37> ({r_i: None, r_t: [-828.716 -828.716 -828.716], eps: 0.001})
Step:   49800, Reward: [-431.377 -431.377 -431.377] [84.846], Avg: [-426.942 -426.942 -426.942] (0.0010) <00:23:41> ({r_i: None, r_t: [-823.697 -823.697 -823.697], critic_loss: 492.2650146484375, actor_loss: -3.6389999389648438, entropy: 0.2409999966621399, eps: 0.001})
Step:   49900, Reward: [-437.352 -437.352 -437.352] [54.211], Avg: [-426.962 -426.962 -426.962] (0.0010) <00:23:43> ({r_i: None, r_t: [-903.356 -903.356 -903.356], eps: 0.001})
Step:   50000, Reward: [-432.499 -432.499 -432.499] [72.797], Avg: [-426.974 -426.974 -426.974] (0.0010) <00:23:46> ({r_i: None, r_t: [-826.530 -826.530 -826.530], critic_loss: 394.7690124511719, actor_loss: -2.7890000343322754, entropy: 0.23199999332427979, eps: 0.001})
Step:   50100, Reward: [-416.955 -416.955 -416.955] [71.046], Avg: [-426.954 -426.954 -426.954] (0.0010) <00:23:49> ({r_i: None, r_t: [-889.868 -889.868 -889.868], eps: 0.001})
Step:   50200, Reward: [-416.156 -416.156 -416.156] [54.185], Avg: [-426.932 -426.932 -426.932] (0.0010) <00:23:52> ({r_i: None, r_t: [-861.531 -861.531 -861.531], critic_loss: 343.8399963378906, actor_loss: -3.003000020980835, entropy: 0.24400000274181366, eps: 0.001})
Step:   50300, Reward: [-415.264 -415.264 -415.264] [73.636], Avg: [-426.909 -426.909 -426.909] (0.0010) <00:23:54> ({r_i: None, r_t: [-841.704 -841.704 -841.704], eps: 0.001})
Step:   50400, Reward: [-459.507 -459.507 -459.507] [57.967], Avg: [-426.973 -426.973 -426.973] (0.0010) <00:23:58> ({r_i: None, r_t: [-842.438 -842.438 -842.438], critic_loss: 245.44200134277344, actor_loss: -1.5809999704360962, entropy: 0.23800000548362732, eps: 0.001})
Step:   50500, Reward: [-415.863 -415.863 -415.863] [74.339], Avg: [-426.952 -426.952 -426.952] (0.0010) <00:24:00> ({r_i: None, r_t: [-887.200 -887.200 -887.200], eps: 0.001})
Step:   50600, Reward: [-420.504 -420.504 -420.504] [83.648], Avg: [-426.939 -426.939 -426.939] (0.0010) <00:24:03> ({r_i: None, r_t: [-876.245 -876.245 -876.245], critic_loss: 305.6059875488281, actor_loss: -2.0980000495910645, entropy: 0.2460000067949295, eps: 0.001})
Step:   50700, Reward: [-428.836 -428.836 -428.836] [56.550], Avg: [-426.943 -426.943 -426.943] (0.0010) <00:24:05> ({r_i: None, r_t: [-857.243 -857.243 -857.243], eps: 0.001})
Step:   50800, Reward: [-437.068 -437.068 -437.068] [84.959], Avg: [-426.962 -426.962 -426.962] (0.0010) <00:24:09> ({r_i: None, r_t: [-823.201 -823.201 -823.201], critic_loss: 448.56500244140625, actor_loss: -2.9630000591278076, entropy: 0.25099998712539673, eps: 0.001})
Step:   50900, Reward: [-392.252 -392.252 -392.252] [50.007], Avg: [-426.894 -426.894 -426.894] (0.0010) <00:24:11> ({r_i: None, r_t: [-848.894 -848.894 -848.894], eps: 0.001})
Step:   51000, Reward: [-410.156 -410.156 -410.156] [66.869], Avg: [-426.862 -426.862 -426.862] (0.0010) <00:24:15> ({r_i: None, r_t: [-863.032 -863.032 -863.032], critic_loss: 294.69000244140625, actor_loss: -3.005000114440918, entropy: 0.26600000262260437, eps: 0.001})
Step:   51100, Reward: [-396.187 -396.187 -396.187] [52.339], Avg: [-426.802 -426.802 -426.802] (0.0010) <00:24:17> ({r_i: None, r_t: [-832.434 -832.434 -832.434], eps: 0.001})
Step:   51200, Reward: [-463.757 -463.757 -463.757] [70.382], Avg: [-426.874 -426.874 -426.874] (0.0010) <00:24:21> ({r_i: None, r_t: [-865.140 -865.140 -865.140], critic_loss: 247.4409942626953, actor_loss: -0.37599998712539673, entropy: 0.25, eps: 0.001})
Step:   51300, Reward: [-424.596 -424.596 -424.596] [59.981], Avg: [-426.869 -426.869 -426.869] (0.0010) <00:24:23> ({r_i: None, r_t: [-860.611 -860.611 -860.611], eps: 0.001})
Step:   51400, Reward: [-414.745 -414.745 -414.745] [60.966], Avg: [-426.846 -426.846 -426.846] (0.0010) <00:24:27> ({r_i: None, r_t: [-806.323 -806.323 -806.323], critic_loss: 239.14700317382812, actor_loss: -1.7400000095367432, entropy: 0.2549999952316284, eps: 0.001})
Step:   51500, Reward: [-442.020 -442.020 -442.020] [63.094], Avg: [-426.875 -426.875 -426.875] (0.0010) <00:24:29> ({r_i: None, r_t: [-831.206 -831.206 -831.206], eps: 0.001})
Step:   51600, Reward: [-420.344 -420.344 -420.344] [61.956], Avg: [-426.863 -426.863 -426.863] (0.0010) <00:24:32> ({r_i: None, r_t: [-781.714 -781.714 -781.714], critic_loss: 257.57000732421875, actor_loss: -1.187999963760376, entropy: 0.25099998712539673, eps: 0.001})
Step:   51700, Reward: [-435.610 -435.610 -435.610] [62.259], Avg: [-426.879 -426.879 -426.879] (0.0010) <00:24:34> ({r_i: None, r_t: [-841.540 -841.540 -841.540], eps: 0.001})
Step:   51800, Reward: [-436.016 -436.016 -436.016] [68.724], Avg: [-426.897 -426.897 -426.897] (0.0010) <00:24:37> ({r_i: None, r_t: [-894.488 -894.488 -894.488], critic_loss: 400.9530029296875, actor_loss: -3.200000047683716, entropy: 0.25200000405311584, eps: 0.001})
Step:   51900, Reward: [-409.162 -409.162 -409.162] [69.485], Avg: [-426.863 -426.863 -426.863] (0.0010) <00:24:40> ({r_i: None, r_t: [-859.406 -859.406 -859.406], eps: 0.001})
Step:   52000, Reward: [-449.830 -449.830 -449.830] [85.898], Avg: [-426.907 -426.907 -426.907] (0.0010) <00:24:44> ({r_i: None, r_t: [-828.177 -828.177 -828.177], critic_loss: 377.08599853515625, actor_loss: -2.5239999294281006, entropy: 0.2409999966621399, eps: 0.001})
Step:   52100, Reward: [-416.613 -416.613 -416.613] [87.232], Avg: [-426.887 -426.887 -426.887] (0.0010) <00:24:46> ({r_i: None, r_t: [-866.297 -866.297 -866.297], eps: 0.001})
Step:   52200, Reward: [-436.445 -436.445 -436.445] [67.320], Avg: [-426.906 -426.906 -426.906] (0.0010) <00:24:49> ({r_i: None, r_t: [-857.174 -857.174 -857.174], critic_loss: 217.4459991455078, actor_loss: -0.2840000092983246, entropy: 0.25200000405311584, eps: 0.001})
Step:   52300, Reward: [-420.059 -420.059 -420.059] [72.048], Avg: [-426.893 -426.893 -426.893] (0.0010) <00:24:51> ({r_i: None, r_t: [-841.670 -841.670 -841.670], eps: 0.001})
Step:   52400, Reward: [-426.347 -426.347 -426.347] [74.455], Avg: [-426.891 -426.891 -426.891] (0.0010) <00:24:55> ({r_i: None, r_t: [-890.250 -890.250 -890.250], critic_loss: 330.3999938964844, actor_loss: -2.0880000591278076, entropy: 0.257999986410141, eps: 0.001})
Step:   52500, Reward: [-424.985 -424.985 -424.985] [62.815], Avg: [-426.888 -426.888 -426.888] (0.0010) <00:24:57> ({r_i: None, r_t: [-838.356 -838.356 -838.356], eps: 0.001})
Step:   52600, Reward: [-444.508 -444.508 -444.508] [64.565], Avg: [-426.921 -426.921 -426.921] (0.0010) <00:25:01> ({r_i: None, r_t: [-852.842 -852.842 -852.842], critic_loss: 215.94000244140625, actor_loss: -1.6330000162124634, entropy: 0.24699999392032623, eps: 0.001})
Step:   52700, Reward: [-420.159 -420.159 -420.159] [91.336], Avg: [-426.908 -426.908 -426.908] (0.0010) <00:25:03> ({r_i: None, r_t: [-863.298 -863.298 -863.298], eps: 0.001})
Step:   52800, Reward: [-466.407 -466.407 -466.407] [84.533], Avg: [-426.983 -426.983 -426.983] (0.0010) <00:25:06> ({r_i: None, r_t: [-851.110 -851.110 -851.110], critic_loss: 278.22698974609375, actor_loss: -2.3369998931884766, entropy: 0.2529999911785126, eps: 0.001})
Step:   52900, Reward: [-392.883 -392.883 -392.883] [55.587], Avg: [-426.919 -426.919 -426.919] (0.0010) <00:25:08> ({r_i: None, r_t: [-799.469 -799.469 -799.469], eps: 0.001})
Step:   53000, Reward: [-407.521 -407.521 -407.521] [78.098], Avg: [-426.882 -426.882 -426.882] (0.0010) <00:25:12> ({r_i: None, r_t: [-852.893 -852.893 -852.893], critic_loss: 307.3919982910156, actor_loss: -2.4509999752044678, entropy: 0.23499999940395355, eps: 0.001})
Step:   53100, Reward: [-441.811 -441.811 -441.811] [68.506], Avg: [-426.910 -426.910 -426.910] (0.0010) <00:25:14> ({r_i: None, r_t: [-866.583 -866.583 -866.583], eps: 0.001})
Step:   53200, Reward: [-418.885 -418.885 -418.885] [65.070], Avg: [-426.895 -426.895 -426.895] (0.0010) <00:25:18> ({r_i: None, r_t: [-898.630 -898.630 -898.630], critic_loss: 316.781005859375, actor_loss: -3.121000051498413, entropy: 0.2630000114440918, eps: 0.001})
Step:   53300, Reward: [-418.591 -418.591 -418.591] [48.804], Avg: [-426.880 -426.880 -426.880] (0.0010) <00:25:20> ({r_i: None, r_t: [-801.155 -801.155 -801.155], eps: 0.001})
Step:   53400, Reward: [-416.484 -416.484 -416.484] [80.052], Avg: [-426.860 -426.860 -426.860] (0.0010) <00:25:23> ({r_i: None, r_t: [-816.507 -816.507 -816.507], critic_loss: 198.21400451660156, actor_loss: -0.37299999594688416, entropy: 0.2540000081062317, eps: 0.001})
Step:   53500, Reward: [-417.086 -417.086 -417.086] [54.028], Avg: [-426.842 -426.842 -426.842] (0.0010) <00:25:26> ({r_i: None, r_t: [-861.351 -861.351 -861.351], eps: 0.001})
Step:   53600, Reward: [-424.644 -424.644 -424.644] [80.791], Avg: [-426.838 -426.838 -426.838] (0.0010) <00:25:29> ({r_i: None, r_t: [-848.254 -848.254 -848.254], critic_loss: 316.2040100097656, actor_loss: -1.684000015258789, entropy: 0.2549999952316284, eps: 0.001})
Step:   53700, Reward: [-407.146 -407.146 -407.146] [50.797], Avg: [-426.801 -426.801 -426.801] (0.0010) <00:25:32> ({r_i: None, r_t: [-844.914 -844.914 -844.914], eps: 0.001})
Step:   53800, Reward: [-421.509 -421.509 -421.509] [65.152], Avg: [-426.792 -426.792 -426.792] (0.0010) <00:25:35> ({r_i: None, r_t: [-868.335 -868.335 -868.335], critic_loss: 248.98899841308594, actor_loss: -1.4809999465942383, entropy: 0.25, eps: 0.001})
Step:   53900, Reward: [-448.203 -448.203 -448.203] [64.198], Avg: [-426.831 -426.831 -426.831] (0.0010) <00:25:37> ({r_i: None, r_t: [-864.847 -864.847 -864.847], eps: 0.001})
Step:   54000, Reward: [-451.665 -451.665 -451.665] [67.543], Avg: [-426.877 -426.877 -426.877] (0.0010) <00:25:41> ({r_i: None, r_t: [-866.495 -866.495 -866.495], critic_loss: 175.09300231933594, actor_loss: -0.7039999961853027, entropy: 0.2630000114440918, eps: 0.001})
Step:   54100, Reward: [-451.698 -451.698 -451.698] [71.846], Avg: [-426.923 -426.923 -426.923] (0.0010) <00:25:43> ({r_i: None, r_t: [-856.472 -856.472 -856.472], eps: 0.001})
Step:   54200, Reward: [-467.450 -467.450 -467.450] [63.139], Avg: [-426.998 -426.998 -426.998] (0.0010) <00:25:47> ({r_i: None, r_t: [-834.118 -834.118 -834.118], critic_loss: 277.89300537109375, actor_loss: -1.3029999732971191, entropy: 0.26100000739097595, eps: 0.001})
Step:   54300, Reward: [-441.361 -441.361 -441.361] [85.110], Avg: [-427.024 -427.024 -427.024] (0.0010) <00:25:49> ({r_i: None, r_t: [-846.777 -846.777 -846.777], eps: 0.001})
Step:   54400, Reward: [-448.549 -448.549 -448.549] [76.904], Avg: [-427.063 -427.063 -427.063] (0.0010) <00:25:53> ({r_i: None, r_t: [-849.484 -849.484 -849.484], critic_loss: 291.2659912109375, actor_loss: -2.253000020980835, entropy: 0.24799999594688416, eps: 0.001})
Step:   54500, Reward: [-460.016 -460.016 -460.016] [38.627], Avg: [-427.124 -427.124 -427.124] (0.0010) <00:25:55> ({r_i: None, r_t: [-830.516 -830.516 -830.516], eps: 0.001})
Step:   54600, Reward: [-403.926 -403.926 -403.926] [75.201], Avg: [-427.081 -427.081 -427.081] (0.0010) <00:25:59> ({r_i: None, r_t: [-902.295 -902.295 -902.295], critic_loss: 252.22500610351562, actor_loss: -2.2899999618530273, entropy: 0.25099998712539673, eps: 0.001})
Step:   54700, Reward: [-420.248 -420.248 -420.248] [77.224], Avg: [-427.069 -427.069 -427.069] (0.0010) <00:26:01> ({r_i: None, r_t: [-845.373 -845.373 -845.373], eps: 0.001})
Step:   54800, Reward: [-441.302 -441.302 -441.302] [67.818], Avg: [-427.095 -427.095 -427.095] (0.0010) <00:26:04> ({r_i: None, r_t: [-839.331 -839.331 -839.331], critic_loss: 215.40899658203125, actor_loss: -1.6230000257492065, entropy: 0.24699999392032623, eps: 0.001})
Step:   54900, Reward: [-438.051 -438.051 -438.051] [87.248], Avg: [-427.115 -427.115 -427.115] (0.0010) <00:26:07> ({r_i: None, r_t: [-862.226 -862.226 -862.226], eps: 0.001})
Step:   55000, Reward: [-403.992 -403.992 -403.992] [74.743], Avg: [-427.073 -427.073 -427.073] (0.0010) <00:26:10> ({r_i: None, r_t: [-841.172 -841.172 -841.172], critic_loss: 216.8070068359375, actor_loss: -1.4930000305175781, entropy: 0.24500000476837158, eps: 0.001})
Step:   55100, Reward: [-434.352 -434.352 -434.352] [58.411], Avg: [-427.086 -427.086 -427.086] (0.0010) <00:26:12> ({r_i: None, r_t: [-905.035 -905.035 -905.035], eps: 0.001})
Step:   55200, Reward: [-437.812 -437.812 -437.812] [67.565], Avg: [-427.105 -427.105 -427.105] (0.0010) <00:26:16> ({r_i: None, r_t: [-852.711 -852.711 -852.711], critic_loss: 304.02801513671875, actor_loss: -1.3839999437332153, entropy: 0.24400000274181366, eps: 0.001})
Step:   55300, Reward: [-421.059 -421.059 -421.059] [52.649], Avg: [-427.094 -427.094 -427.094] (0.0010) <00:26:18> ({r_i: None, r_t: [-854.267 -854.267 -854.267], eps: 0.001})
Step:   55400, Reward: [-466.738 -466.738 -466.738] [74.143], Avg: [-427.166 -427.166 -427.166] (0.0010) <00:26:22> ({r_i: None, r_t: [-840.912 -840.912 -840.912], critic_loss: 235.1580047607422, actor_loss: -1.281999945640564, entropy: 0.23499999940395355, eps: 0.001})
Step:   55500, Reward: [-448.244 -448.244 -448.244] [81.481], Avg: [-427.204 -427.204 -427.204] (0.0010) <00:26:24> ({r_i: None, r_t: [-838.472 -838.472 -838.472], eps: 0.001})
Step:   55600, Reward: [-453.931 -453.931 -453.931] [72.381], Avg: [-427.252 -427.252 -427.252] (0.0010) <00:26:27> ({r_i: None, r_t: [-847.513 -847.513 -847.513], critic_loss: 221.35299682617188, actor_loss: -1.3450000286102295, entropy: 0.23600000143051147, eps: 0.001})
Step:   55700, Reward: [-428.341 -428.341 -428.341] [64.155], Avg: [-427.254 -427.254 -427.254] (0.0010) <00:26:29> ({r_i: None, r_t: [-877.814 -877.814 -877.814], eps: 0.001})
Step:   55800, Reward: [-402.204 -402.204 -402.204] [71.556], Avg: [-427.209 -427.209 -427.209] (0.0010) <00:26:33> ({r_i: None, r_t: [-838.250 -838.250 -838.250], critic_loss: 267.94500732421875, actor_loss: -1.2640000581741333, entropy: 0.23899999260902405, eps: 0.001})
Step:   55900, Reward: [-423.511 -423.511 -423.511] [61.299], Avg: [-427.202 -427.202 -427.202] (0.0010) <00:26:35> ({r_i: None, r_t: [-849.570 -849.570 -849.570], eps: 0.001})
Step:   56000, Reward: [-415.500 -415.500 -415.500] [54.091], Avg: [-427.181 -427.181 -427.181] (0.0010) <00:26:39> ({r_i: None, r_t: [-859.475 -859.475 -859.475], critic_loss: 295.1390075683594, actor_loss: -1.9539999961853027, entropy: 0.23499999940395355, eps: 0.001})
Step:   56100, Reward: [-401.323 -401.323 -401.323] [70.485], Avg: [-427.135 -427.135 -427.135] (0.0010) <00:26:41> ({r_i: None, r_t: [-878.552 -878.552 -878.552], eps: 0.001})
Step:   56200, Reward: [-438.098 -438.098 -438.098] [51.096], Avg: [-427.155 -427.155 -427.155] (0.0010) <00:26:45> ({r_i: None, r_t: [-832.348 -832.348 -832.348], critic_loss: 251.25599670410156, actor_loss: -1.9609999656677246, entropy: 0.23199999332427979, eps: 0.001})
Step:   56300, Reward: [-445.489 -445.489 -445.489] [84.273], Avg: [-427.187 -427.187 -427.187] (0.0010) <00:26:47> ({r_i: None, r_t: [-908.319 -908.319 -908.319], eps: 0.001})
Step:   56400, Reward: [-435.681 -435.681 -435.681] [55.538], Avg: [-427.202 -427.202 -427.202] (0.0010) <00:26:51> ({r_i: None, r_t: [-848.782 -848.782 -848.782], critic_loss: 299.010009765625, actor_loss: -2.0209999084472656, entropy: 0.23499999940395355, eps: 0.001})
