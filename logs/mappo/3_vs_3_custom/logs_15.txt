Model: <class 'multiagent.mappo.MAPPOAgent'>, Dir: 3_vs_3_custom
num_envs: 32, state_size: [(1, 115), (1, 115), (1, 115), (1, 115), (1, 115), (1, 115)], action_size: [[1, 19], [1, 19], [1, 19], [1, 19], [1, 19], [1, 19]], action_space: [MultiDiscrete([19]), MultiDiscrete([19]), MultiDiscrete([19]), MultiDiscrete([19]), MultiDiscrete([19]), MultiDiscrete([19])], envs: <class 'utils.envs.EnvManager'>,

import torch
import random
import numpy as np
from models.ppo import PPONetwork
from utils.wrappers import ParallelAgent
from utils.network import PTNetwork, PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS, EPS_MIN, MultiheadAttention, one_hot_from_indices, gsoftmax

ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.05				# The limit of the ratio of new action probabilities to old probabilities

class MAPPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.norm1 = torch.nn.LayerNorm(ACTOR_HIDDEN)
		self.norm2 = torch.nn.LayerNorm(ACTOR_HIDDEN)
		self.layer1 = torch.nn.Linear(state_size[-1], ACTOR_HIDDEN)
		# self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		# self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		# self.attention = MultiheadAttention(ACTOR_HIDDEN, 8, 32)
		# self.attention = torch.nn.modules.MultiheadAttention(ACTOR_HIDDEN, 4)
		self.recurrent = torch.nn.GRUCell(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_probs = torch.nn.Linear(ACTOR_HIDDEN, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.init_hidden()

	def forward(self, state, action=None, sample=True):
		out_dims = state.shape[:-1]
		state = self.norm1(self.layer1(state)).relu()
		# state = self.layer2(state).relu()
		# state = self.layer3(state).relu()
		# state = self.norm2(self.attention(state, state, state)[0])
		# state = self.attention(state)
		state = state.reshape(-1, state.shape[-1])
		if self.hidden.size(0) != state.size(0): self.init_hidden(state.size(0), state.device)
		self.hidden = self.recurrent(state, self.hidden)
		action_probs = self.action_probs(self.hidden)
		action_probs = action_probs.reshape(*out_dims, action_probs.shape[-1])
		dist = torch.distributions.Categorical(action_probs.softmax(-1))
		action = dist.sample() if action is None else action.argmax(-1)
		action_one_hot = one_hot_from_indices(action, action_probs.size(-1))
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action_one_hot, log_prob, entropy

	def init_hidden(self, batch_size=1, device=torch.device("cpu")):
		self.hidden = torch.zeros([batch_size, ACTOR_HIDDEN]).to(device)

class MAPPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		# self.attention = torch.nn.modules.MultiheadAttention(CRITIC_HIDDEN, 8)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		# out_dims = state.shape[:-1]
		# state = state.reshape(-1, state.shape[-1])
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		# state = self.attention(state, state, state)[0]
		value = self.value(state)
		# value = value.reshape(*out_dims, value.shape[-1])
		return value

class MAPPONetwork(PTNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(gpu=gpu, name="mappo")
		self.state_size = state_size
		self.action_size = action_size
		self.actor = lambda s,a: MAPPOActor(state_size[0], action_size[0])
		self.critic = lambda s,a: MAPPOCritic([np.sum([np.prod(s) for s in self.state_size])], [np.sum([np.prod(a) for a in self.action_size])])
		self.models = [PPONetwork(s_size, a_size, self.actor, self.critic, lr=lr, gpu=gpu, load=load) for s_size,a_size in zip(self.state_size, self.action_size)]
		if load: self.load_model(load)

	def get_action_probs(self, state, action_in=None, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action_in = [None] * len(state) if action_in is None else action_in
			action_or_entropy, log_prob = map(list, zip(*[model.get_action_probs(s, a, grad=grad, numpy=numpy, sample=sample) for s,a,model in zip(state, action_in, self.models)]))
			return action_or_entropy, log_prob

	def get_value(self, state, grad=False):
		with torch.enable_grad() if grad else torch.no_grad():
			q_value = [model.get_value(state, grad) for model in self.models]
			return q_value

	def optimize(self, states, actions, old_log_probs, targets, advantages, clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
		for model, state, action, old_log_prob, target, advantage in zip(self.models, states, actions, old_log_probs, targets, advantages):		
			[m.train() for m in [model.actor_local, model.critic_local]]
			values = model.get_value(states_joint, grad=True)
			critic_error = values - target.detach()
			critic_loss = critic_error.pow(2)
			model.step(model.critic_optimizer, critic_loss.mean(), model.critic_local.parameters())

			model.actor_local.init_hidden(state.size(0), state.device)
			entropy, new_log_prob = zip(*[model.get_action_probs(state[:,t], action[:,t], grad=True, numpy=False) for t in range(state.size(1))])
			new_log_prob = torch.stack(new_log_prob, dim=1)
			ratio = (new_log_prob - old_log_prob).exp()
			ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
			advantage = advantage.view(*advantage.shape, *[1]*(len(ratio.shape)-len(advantage.shape)))
			entropy = torch.stack(entropy).view(1, -1, *advantage.shape[2:])
			actor_loss = -(torch.min(ratio*advantage, ratio_clipped*advantage) + e_weight*entropy) * scale
			model.step(model.actor_optimizer, actor_loss.mean(), model.actor_local.parameters())
			[m.eval() for m in [model.actor_local, model.critic_local]]

	def save_model(self, dirname="pytorch", name="checkpoint"):
		[PTACNetwork.save_model(model, self.name, dirname, f"{name}_{i}") for i,model in enumerate(self.models)]
		
	def load_model(self, dirname="pytorch", name="checkpoint"):
		[PTACNetwork.load_model(model, self.name, dirname, f"{name}_{i}") for i,model in enumerate(self.models)]

class MAPPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, MAPPONetwork, lr=lr, update_freq=update_freq, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True, numpy=True):
		action, self.log_prob = self.network.get_action_probs(self.to_tensor(state), numpy=True, sample=sample)
		return action

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, self.log_prob, reward, done))
		if np.any(done[0]):
			states, actions, log_probs, rewards, dones = map(lambda x: self.to_tensor(x), zip(*self.buffer))
			self.buffer.clear()
			states = [torch.cat([s, ns.unsqueeze(0)], dim=0) for s,ns in zip(states, self.to_tensor(next_state))]
			states_joint = torch.cat([s.view(*s.size()[:-len(s_size)], np.prod(s_size)) for s,s_size in zip(states, self.state_size)], dim=-1)
			values = self.network.get_value(states_joint)
			targets, advantages = zip(*[self.compute_gae(value[-1], reward.unsqueeze(-1), done.unsqueeze(-1), value[:-1]) for value,reward,done in zip(values, rewards, dones)])
			time_split = lambda x: list(zip(*[t.view(-1,10,*t.shape[1:]).transpose(0,1).reshape(10,-1,*t.shape[2:]).transpose(0,1) for t in x]))
			states, actions, log_probs, targets, advantages = [time_split(x) for x in [[s[:-1] for s in states], actions, log_probs, targets, advantages]]
			self.replay_buffer.extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
		if len(self.replay_buffer) >= 640:
			for _ in range((len(self.replay_buffer)*5)//640):
				states, actions, log_probs, targets, advantages = self.replay_buffer.next_batch(640, lambda x: [torch.stack(l) for l in list(zip(*x))])
				self.network.optimize(states, actions, log_probs, targets, advantages)
			self.replay_buffer.clear()

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.001   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 256				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 512			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 500					# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.000               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

import gym
import argparse
import numpy as np
import particle_envs.make_env as pgym
import football.gfootball.env as ggym
from models.ppo import PPOAgent
from models.sac import SACAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from multiagent.coma import COMAAgent
from multiagent.maddpg import MADDPGAgent
from multiagent.mappo import MAPPOAgent
from utils.wrappers import ParallelAgent, DoubleAgent, SelfPlayAgent, ParticleTeamEnv, FootballTeamEnv, TrainEnv
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, MPI_SIZE, MPI_RANK
from utils.misc import Logger, rollout
np.set_printoptions(precision=3)

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "BipedalWalkerHardcore-v2", "LunarLander-v2", "LunarLanderContinuous-v2"]
gfb_envs = ["academy_empty_goal_close", "academy_empty_goal", "academy_run_to_score", "academy_run_to_score_with_keeper", "academy_single_goal_versus_lazy", "academy_3_vs_1_with_keeper", "1_vs_1_easy", "3_vs_3_custom", "5_vs_5", "11_vs_11_stochastic", "test_example_multiagent"]
ptc_envs = ["simple_adversary", "simple_speaker_listener", "simple_tag", "simple_spread", "simple_push"]
env_name = gym_envs[0]
env_name = gfb_envs[-4]
# env_name = ptc_envs[-2]

def make_env(env_name=env_name, log=False, render=False):
	if env_name in gym_envs: return TrainEnv(gym.make(env_name))
	if env_name in ptc_envs: return ParticleTeamEnv(pgym.make_env(env_name))
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	multiagent_args = {"number_of_left_players_agent_controls":3, "number_of_right_players_agent_controls":3} if env_name == "3_vs_3_custom" else {}
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=render, **multiagent_args)
	ballr = lambda x,y: (np.maximum if x>0 else np.minimum)(x - np.abs(y)*np.sign(x), 0.5*x)
	reward_fn = lambda obs,reward: [(ballr(o[0,88], o[0,89]) + o[0,95]-o[0,96] + 2*r)/4 for o,r in zip(obs,reward)]
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space}")
	return FootballTeamEnv(env, reward_fn)

def run(model, steps=10000, ports=16, env_name=env_name, trial_at=1000, save_at=100, checkpoint=True, save_best=False, log=True, render=False, load=False):
	envs = (EnvManager if type(ports) == list or MPI_SIZE > 1 else EnsembleEnv)(lambda: make_env(env_name), ports)
	agent = (SelfPlayAgent if env_name=="3_vs_3_custom" else ParallelAgent)(envs.state_size, envs.action_size, model, envs.num_envs, load=f"{env_name}" if load else "", gpu=True, agent2=RandomAgent, save_dir=env_name) 
	logger = Logger(model, env_name, num_envs=envs.num_envs, state_size=agent.state_size, action_size=envs.action_size, action_space=envs.env.action_space, envs=type(envs))
	states = envs.reset(train=True)
	total_rewards = []
	for s in range(steps):
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions, train=True)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if s>0 and s%trial_at == 0:
			rollouts = rollout(envs, agent, render=render)
			total_rewards.append(np.mean(rollouts, axis=-1))
			if checkpoint and len(total_rewards) % save_at==0: agent.save_model(env_name, "checkpoint")
			if save_best and np.all(total_rewards[-1] >= np.max(total_rewards, axis=-1)): agent.save_model(env_name)
			if log: logger.log(f"Step: {s}, Reward: {total_rewards[-1]} [{np.std(rollouts):.4f}], Avg: {np.mean(total_rewards, axis=0)} ({agent.agent.eps:.3f})")

def trial(model, env_name, render):
	envs = EnsembleEnv(lambda: make_env(env_name, log=True, render=render), 0)
	agent = (DoubleAgent if env_name=="3_vs_3_custom" else ParallelAgent)(envs.state_size, envs.action_size, model, gpu=False, load=f"{env_name}", agent2=RandomAgent, save_dir=env_name)
	print(f"Reward: {np.mean([rollout(envs.env, agent, eps=0.0, render=True) for _ in range(5)], axis=0)}")
	envs.close()

def parse_args():
	parser = argparse.ArgumentParser(description="A3C Trainer")
	parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
	parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
	parser.add_argument("--model", type=str, default="mappo", help="Which reinforcement learning algorithm to use")
	parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
	parser.add_argument("--render", action="store_true", help="Whether to render during training")
	parser.add_argument("--trial", action="store_true", help="Whether to show a trial run")
	parser.add_argument("--env", type=str, default="", help="Name of env to use")
	return parser.parse_args()

if __name__ == "__main__":
	args = parse_args()
	env_name = env_name if args.env not in [*gym_envs, *gfb_envs, *ptc_envs] else args.env
	models = {"ddpg":DDPGAgent, "ppo":PPOAgent, "sac":SACAgent, "ddqn":DDQNAgent, "maddpg":MADDPGAgent, "mappo":MAPPOAgent, "coma":COMAAgent, "rand":RandomAgent}
	model = models[args.model] if args.model in models else RandomAgent
	if args.trial:
		trial(model=model, env_name=env_name, render=args.render)
	elif args.selfport is not None or MPI_RANK>0 :
		EnvWorker(self_port=args.selfport, make_env=make_env).start()
	else:
		run(model=model, steps=args.steps, ports=args.workerports[0] if len(args.workerports)==1 else args.workerports, env_name=env_name, render=args.render)


Step: 1000, Reward: [-0.094 -0.094 -0.094  0.094  0.094  0.094] [0.4677], Avg: [-0.094 -0.094 -0.094  0.094  0.094  0.094] (1.000)
Step: 2000, Reward: [-0.125 -0.125 -0.125  0.125  0.125  0.125] [0.5000], Avg: [-0.109 -0.109 -0.109  0.109  0.109  0.109] (1.000)
Step: 3000, Reward: [-0.188 -0.188 -0.188  0.188  0.188  0.188] [0.5590], Avg: [-0.135 -0.135 -0.135  0.135  0.135  0.135] (1.000)
Step: 4000, Reward: [-0.125 -0.125 -0.125  0.125  0.125  0.125] [0.4330], Avg: [-0.133 -0.133 -0.133  0.133  0.133  0.133] (1.000)
Step: 5000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3953], Avg: [-0.1 -0.1 -0.1  0.1  0.1  0.1] (1.000)
Step: 6000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.6124], Avg: [-0.073 -0.073 -0.073  0.073  0.073  0.073] (1.000)
Step: 7000, Reward: [-0.094 -0.094 -0.094  0.094  0.094  0.094] [0.3953], Avg: [-0.076 -0.076 -0.076  0.076  0.076  0.076] (1.000)
Step: 8000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.3536], Avg: [-0.059 -0.059 -0.059  0.059  0.059  0.059] (1.000)
Step: 9000, Reward: [-0.188 -0.188 -0.188  0.188  0.188  0.188] [0.5000], Avg: [-0.073 -0.073 -0.073  0.073  0.073  0.073] (1.000)
Step: 10000, Reward: [-0.125 -0.125 -0.125  0.125  0.125  0.125] [0.4330], Avg: [-0.078 -0.078 -0.078  0.078  0.078  0.078] (1.000)
Step: 11000, Reward: [-0.125 -0.125 -0.125  0.125  0.125  0.125] [0.3536], Avg: [-0.082 -0.082 -0.082  0.082  0.082  0.082] (1.000)
Step: 12000, Reward: [-0.062 -0.062 -0.062  0.062  0.062  0.062] [0.4330], Avg: [-0.081 -0.081 -0.081  0.081  0.081  0.081] (1.000)
Step: 13000, Reward: [-0.094 -0.094 -0.094  0.094  0.094  0.094] [0.4677], Avg: [-0.082 -0.082 -0.082  0.082  0.082  0.082] (1.000)
Step: 14000, Reward: [-0.188 -0.188 -0.188  0.188  0.188  0.188] [0.6124], Avg: [-0.089 -0.089 -0.089  0.089  0.089  0.089] (1.000)
Step: 15000, Reward: [-0.188 -0.188 -0.188  0.188  0.188  0.188] [0.4330], Avg: [-0.096 -0.096 -0.096  0.096  0.096  0.096] (1.000)
Step: 16000, Reward: [-0.062 -0.062 -0.062  0.062  0.062  0.062] [0.4330], Avg: [-0.094 -0.094 -0.094  0.094  0.094  0.094] (1.000)
Step: 17000, Reward: [-0.094 -0.094 -0.094  0.094  0.094  0.094] [0.3062], Avg: [-0.094 -0.094 -0.094  0.094  0.094  0.094] (1.000)
Step: 18000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3953], Avg: [-0.087 -0.087 -0.087  0.087  0.087  0.087] (1.000)
Step: 19000, Reward: [-0.062 -0.062 -0.062  0.062  0.062  0.062] [0.3536], Avg: [-0.086 -0.086 -0.086  0.086  0.086  0.086] (1.000)
Step: 20000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.3953], Avg: [-0.083 -0.083 -0.083  0.083  0.083  0.083] (1.000)
Step: 21000, Reward: [-0.062 -0.062 -0.062  0.062  0.062  0.062] [0.3536], Avg: [-0.082 -0.082 -0.082  0.082  0.082  0.082] (1.000)
Step: 22000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.3953], Avg: [-0.08 -0.08 -0.08  0.08  0.08  0.08] (1.000)
Step: 23000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.3062], Avg: [-0.077 -0.077 -0.077  0.077  0.077  0.077] (1.000)
Step: 24000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.4677], Avg: [-0.076 -0.076 -0.076  0.076  0.076  0.076] (1.000)
Step: 25000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [-0.074 -0.074 -0.074  0.074  0.074  0.074] (1.000)
Step: 26000, Reward: [-0.094 -0.094 -0.094  0.094  0.094  0.094] [0.4677], Avg: [-0.075 -0.075 -0.075  0.075  0.075  0.075] (1.000)
Step: 27000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3953], Avg: [-0.071 -0.071 -0.071  0.071  0.071  0.071] (1.000)
Step: 28000, Reward: [-0.062 -0.062 -0.062  0.062  0.062  0.062] [0.2500], Avg: [-0.07 -0.07 -0.07  0.07  0.07  0.07] (1.000)
Step: 29000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.4677], Avg: [-0.069 -0.069 -0.069  0.069  0.069  0.069] (1.000)
Step: 30000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.3953], Avg: [-0.068 -0.068 -0.068  0.068  0.068  0.068] (1.000)
Step: 31000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3062], Avg: [-0.065 -0.065 -0.065  0.065  0.065  0.065] (1.000)
Step: 32000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.3536], Avg: [-0.061 -0.061 -0.061  0.061  0.061  0.061] (1.000)
Step: 33000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3953], Avg: [-0.058 -0.058 -0.058  0.058  0.058  0.058] (1.000)
Step: 34000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.3536], Avg: [-0.054 -0.054 -0.054  0.054  0.054  0.054] (1.000)
Step: 35000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.5863], Avg: [-0.052 -0.052 -0.052  0.052  0.052  0.052] (1.000)
Step: 36000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3062], Avg: [-0.049 -0.049 -0.049  0.049  0.049  0.049] (1.000)
Step: 37000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.3953], Avg: [-0.049 -0.049 -0.049  0.049  0.049  0.049] (1.000)
Step: 38000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3062], Avg: [-0.047 -0.047 -0.047  0.047  0.047  0.047] (1.000)
Step: 39000, Reward: [-0.094 -0.094 -0.094  0.094  0.094  0.094] [0.4677], Avg: [-0.048 -0.048 -0.048  0.048  0.048  0.048] (1.000)
Step: 40000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [-0.047 -0.047 -0.047  0.047  0.047  0.047] (1.000)
Step: 41000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3062], Avg: [-0.045 -0.045 -0.045  0.045  0.045  0.045] (1.000)
Step: 42000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3953], Avg: [-0.043 -0.043 -0.043  0.043  0.043  0.043] (1.000)
Step: 43000, Reward: [-0.125 -0.125 -0.125  0.125  0.125  0.125] [0.4330], Avg: [-0.045 -0.045 -0.045  0.045  0.045  0.045] (1.000)
Step: 44000, Reward: [0. 0. 0. 0. 0. 0.] [0.3536], Avg: [-0.044 -0.044 -0.044  0.044  0.044  0.044] (1.000)
Step: 45000, Reward: [0. 0. 0. 0. 0. 0.] [0.4330], Avg: [-0.043 -0.043 -0.043  0.043  0.043  0.043] (1.000)
Step: 46000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.5303], Avg: [-0.041 -0.041 -0.041  0.041  0.041  0.041] (1.000)
Step: 47000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.5303], Avg: [-0.04 -0.04 -0.04  0.04  0.04  0.04] (1.000)
Step: 48000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3953], Avg: [-0.038 -0.038 -0.038  0.038  0.038  0.038] (1.000)
Step: 49000, Reward: [ 0.125  0.125  0.125 -0.125 -0.125 -0.125] [0.3536], Avg: [-0.035 -0.035 -0.035  0.035  0.035  0.035] (1.000)
Step: 50000, Reward: [-0.219 -0.219 -0.219  0.219  0.219  0.219] [0.4677], Avg: [-0.039 -0.039 -0.039  0.039  0.039  0.039] (1.000)
Step: 51000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.3536], Avg: [-0.037 -0.037 -0.037  0.037  0.037  0.037] (1.000)
Step: 52000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [-0.036 -0.036 -0.036  0.036  0.036  0.036] (1.000)
Step: 53000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.5000], Avg: [-0.034 -0.034 -0.034  0.034  0.034  0.034] (1.000)
Step: 54000, Reward: [0. 0. 0. 0. 0. 0.] [0.3536], Avg: [-0.034 -0.034 -0.034  0.034  0.034  0.034] (1.000)
Step: 55000, Reward: [ 0.094  0.094  0.094 -0.094 -0.094 -0.094] [0.3953], Avg: [-0.031 -0.031 -0.031  0.031  0.031  0.031] (1.000)
Step: 56000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.3536], Avg: [-0.03 -0.03 -0.03  0.03  0.03  0.03] (1.000)
Step: 57000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.3536], Avg: [-0.028 -0.028 -0.028  0.028  0.028  0.028] (1.000)
Step: 58000, Reward: [-0.062 -0.062 -0.062  0.062  0.062  0.062] [0.3536], Avg: [-0.029 -0.029 -0.029  0.029  0.029  0.029] (1.000)
Step: 59000, Reward: [ 0.094  0.094  0.094 -0.094 -0.094 -0.094] [0.3953], Avg: [-0.026 -0.026 -0.026  0.026  0.026  0.026] (1.000)
Step: 60000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.3062], Avg: [-0.027 -0.027 -0.027  0.027  0.027  0.027] (1.000)
Step: 61000, Reward: [ 0.125  0.125  0.125 -0.125 -0.125 -0.125] [0.4330], Avg: [-0.024 -0.024 -0.024  0.024  0.024  0.024] (1.000)
Step: 62000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.024 -0.024 -0.024  0.024  0.024  0.024] (1.000)
Step: 63000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3062], Avg: [-0.023 -0.023 -0.023  0.023  0.023  0.023] (1.000)
Step: 64000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.3536], Avg: [-0.021 -0.021 -0.021  0.021  0.021  0.021] (1.000)
Step: 65000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.4330], Avg: [-0.02 -0.02 -0.02  0.02  0.02  0.02] (1.000)
Step: 66000, Reward: [ 0.156  0.156  0.156 -0.156 -0.156 -0.156] [0.4677], Avg: [-0.018 -0.018 -0.018  0.018  0.018  0.018] (1.000)
Step: 67000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.4677], Avg: [-0.018 -0.018 -0.018  0.018  0.018  0.018] (1.000)
Step: 68000, Reward: [ 0.094  0.094  0.094 -0.094 -0.094 -0.094] [0.3062], Avg: [-0.016 -0.016 -0.016  0.016  0.016  0.016] (1.000)
Step: 69000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [-0.016 -0.016 -0.016  0.016  0.016  0.016] (1.000)
Step: 70000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.3536], Avg: [-0.015 -0.015 -0.015  0.015  0.015  0.015] (1.000)
Step: 71000, Reward: [ 0.125  0.125  0.125 -0.125 -0.125 -0.125] [0.3536], Avg: [-0.013 -0.013 -0.013  0.013  0.013  0.013] (1.000)
Step: 72000, Reward: [ 0.094  0.094  0.094 -0.094 -0.094 -0.094] [0.3062], Avg: [-0.011 -0.011 -0.011  0.011  0.011  0.011] (1.000)
Step: 73000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3062], Avg: [-0.011 -0.011 -0.011  0.011  0.011  0.011] (1.000)
Step: 74000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.011 -0.011 -0.011  0.011  0.011  0.011] (1.000)
Step: 75000, Reward: [ 0.094  0.094  0.094 -0.094 -0.094 -0.094] [0.3062], Avg: [-0.009 -0.009 -0.009  0.009  0.009  0.009] (1.000)
Step: 76000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.3536], Avg: [-0.008 -0.008 -0.008  0.008  0.008  0.008] (1.000)
Step: 77000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [-0.007 -0.007 -0.007  0.007  0.007  0.007] (1.000)
Step: 78000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [-0.007 -0.007 -0.007  0.007  0.007  0.007] (1.000)
Step: 79000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [-0.008 -0.008 -0.008  0.008  0.008  0.008] (1.000)
Step: 80000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.007 -0.007 -0.007  0.007  0.007  0.007] (1.000)
Step: 81000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.3062], Avg: [-0.007 -0.007 -0.007  0.007  0.007  0.007] (1.000)
Step: 82000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [-0.008 -0.008 -0.008  0.008  0.008  0.008] (1.000)
Step: 83000, Reward: [ 0.094  0.094  0.094 -0.094 -0.094 -0.094] [0.3062], Avg: [-0.006 -0.006 -0.006  0.006  0.006  0.006] (1.000)
Step: 84000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [-0.007 -0.007 -0.007  0.007  0.007  0.007] (1.000)
Step: 85000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.3062], Avg: [-0.007 -0.007 -0.007  0.007  0.007  0.007] (1.000)
Step: 86000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [-0.007 -0.007 -0.007  0.007  0.007  0.007] (1.000)
Step: 87000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [-0.006 -0.006 -0.006  0.006  0.006  0.006] (1.000)
Step: 88000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.006 -0.006 -0.006  0.006  0.006  0.006] (1.000)
Step: 89000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.006 -0.006 -0.006  0.006  0.006  0.006] (1.000)
Step: 90000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [-0.005 -0.005 -0.005  0.005  0.005  0.005] (1.000)
Step: 91000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.005 -0.005 -0.005  0.005  0.005  0.005] (1.000)
Step: 92000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [-0.005 -0.005 -0.005  0.005  0.005  0.005] (1.000)
Step: 93000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.005 -0.005 -0.005  0.005  0.005  0.005] (1.000)
Step: 94000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.004 -0.004 -0.004  0.004  0.004  0.004] (1.000)
Step: 95000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.004 -0.004 -0.004  0.004  0.004  0.004] (1.000)
Step: 96000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.004 -0.004 -0.004  0.004  0.004  0.004] (1.000)
Step: 97000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.004 -0.004 -0.004  0.004  0.004  0.004] (1.000)
Step: 98000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [-0.004 -0.004 -0.004  0.004  0.004  0.004] (1.000)
Step: 99000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.004 -0.004 -0.004  0.004  0.004  0.004] (1.000)
Step: 100000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.004 -0.004 -0.004  0.004  0.004  0.004] (1.000)
Step: 101000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [-0.003 -0.003 -0.003  0.003  0.003  0.003] (1.000)
Step: 102000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.003 -0.003 -0.003  0.003  0.003  0.003] (1.000)
Step: 103000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.003 -0.003 -0.003  0.003  0.003  0.003] (1.000)
Step: 104000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.003 -0.003 -0.003  0.003  0.003  0.003] (1.000)
Step: 105000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.003 -0.003 -0.003  0.003  0.003  0.003] (1.000)
Step: 106000, Reward: [ 0.094  0.094  0.094 -0.094 -0.094 -0.094] [0.3062], Avg: [-0.002 -0.002 -0.002  0.002  0.002  0.002] (1.000)
Step: 107000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 108000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 109000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 110000, Reward: [-0.062 -0.062 -0.062  0.062  0.062  0.062] [0.2500], Avg: [-0.002 -0.002 -0.002  0.002  0.002  0.002] (1.000)
Step: 111000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.002 -0.002 -0.002  0.002  0.002  0.002] (1.000)
Step: 112000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [-0.002 -0.002 -0.002  0.002  0.002  0.002] (1.000)
Step: 113000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [-0.002 -0.002 -0.002  0.002  0.002  0.002] (1.000)
Step: 114000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.002 -0.002 -0.002  0.002  0.002  0.002] (1.000)
Step: 115000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.002 -0.002 -0.002  0.002  0.002  0.002] (1.000)
Step: 116000, Reward: [ 0.094  0.094  0.094 -0.094 -0.094 -0.094] [0.3062], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 117000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 118000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 119000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 120000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 121000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 122000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 123000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 124000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 125000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0.001 -0.001 -0.001  0.001  0.001  0.001] (1.000)
Step: 126000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [-0. -0. -0.  0.  0.  0.] (1.000)
Step: 127000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [-0. -0. -0.  0.  0.  0.] (1.000)
Step: 128000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 129000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 130000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 131000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 132000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 133000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 134000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 135000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 136000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 137000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 138000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [0. 0. 0. 0. 0. 0.] (1.000)
Step: 139000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 140000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 141000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 142000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 143000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 144000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 145000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 146000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 147000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 148000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.  0.  0. -0. -0. -0.] (1.000)
Step: 149000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 150000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 151000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 152000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 153000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 154000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 155000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 156000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 157000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 158000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.3536], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 159000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 160000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 161000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 162000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 163000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 164000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 165000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 166000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 167000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 168000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 169000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 170000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 171000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 172000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 173000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 174000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 175000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 176000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 177000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 178000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 179000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 180000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 181000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 182000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 183000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 184000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 185000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 186000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 187000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 188000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 189000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 190000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 191000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3062], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 192000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 193000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 194000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 195000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 196000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 197000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 198000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 199000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 200000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.001  0.001  0.001 -0.001 -0.001 -0.001] (1.000)
Step: 201000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 202000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 203000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 204000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 205000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 206000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 207000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 208000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 209000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 210000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 211000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 212000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 213000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 214000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 215000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 216000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 217000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 218000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 219000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 220000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 221000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 222000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 223000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 224000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 225000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 226000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.002  0.002  0.002 -0.002 -0.002 -0.002] (1.000)
Step: 227000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 228000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 229000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 230000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 231000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 232000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 233000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 234000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 235000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 236000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 237000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 238000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 239000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 240000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 241000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 242000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 243000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 244000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 245000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 246000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 247000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 248000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 249000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 250000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 251000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 252000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 253000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 254000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 255000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 256000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 257000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 258000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 259000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 260000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 261000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 262000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 263000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 264000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 265000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 266000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 267000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 268000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 269000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 270000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 271000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.3062], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 272000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 273000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 274000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 275000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 276000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 277000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 278000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 279000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 280000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 281000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 282000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 283000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 284000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 285000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 286000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 287000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 288000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 289000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 290000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 291000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 292000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 293000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 294000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 295000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 296000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 297000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 298000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 299000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 300000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 301000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 302000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 303000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 304000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 305000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 306000, Reward: [0. 0. 0. 0. 0. 0.] [0.2500], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 307000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 308000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 309000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 310000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 311000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 312000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 313000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 314000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 315000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 316000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 317000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 318000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 319000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 320000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 321000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 322000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 323000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 324000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 325000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 326000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 327000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 328000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 329000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 330000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 331000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 332000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 333000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 334000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 335000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 336000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 337000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 338000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 339000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 340000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 341000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 342000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 343000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 344000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 345000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 346000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 347000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 348000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 349000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 350000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 351000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 352000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 353000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 354000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 355000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 356000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 357000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 358000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 359000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 360000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 361000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 362000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 363000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 364000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 365000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 366000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 367000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 368000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 369000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 370000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 371000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 372000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 373000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 374000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 375000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 376000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 377000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 378000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 379000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 380000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 381000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 382000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 383000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 384000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 385000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 386000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 387000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 388000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 389000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 390000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 391000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 392000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 393000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 394000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 395000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 396000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 397000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 398000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 399000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 400000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 401000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 402000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 403000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 404000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 405000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 406000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 407000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 408000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 409000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 410000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 411000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 412000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 413000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 414000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 415000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 416000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 417000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 418000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 419000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 420000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 421000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 422000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 423000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 424000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 425000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 426000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 427000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 428000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 429000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 430000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 431000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 432000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 433000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 434000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 435000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 436000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 437000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 438000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.003  0.003  0.003 -0.003 -0.003 -0.003] (1.000)
Step: 439000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 440000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 441000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 442000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 443000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 444000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 445000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 446000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 447000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 448000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 449000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 450000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 451000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 452000, Reward: [-0.031 -0.031 -0.031  0.031  0.031  0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 453000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 454000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 455000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 456000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 457000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 458000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 459000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 460000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 461000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 462000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 463000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 464000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 465000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 466000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 467000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 468000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 469000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 470000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 471000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 472000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 473000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 474000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 475000, Reward: [ 0.094  0.094  0.094 -0.094 -0.094 -0.094] [0.3062], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 476000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 477000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 478000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 479000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 480000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 481000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 482000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 483000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 484000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 485000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 486000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 487000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 488000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 489000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 490000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 491000, Reward: [ 0.062  0.062  0.062 -0.062 -0.062 -0.062] [0.2500], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 492000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 493000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 494000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 495000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 496000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 497000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 498000, Reward: [ 0.031  0.031  0.031 -0.031 -0.031 -0.031] [0.1768], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 499000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
Step: 500000, Reward: [0. 0. 0. 0. 0. 0.] [0.0000], Avg: [ 0.004  0.004  0.004 -0.004 -0.004 -0.004] (1.000)
