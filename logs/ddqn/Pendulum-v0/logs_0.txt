Model: <class 'models.ddqn.DDQNAgent'>, Dir: Pendulum-v0
num_envs: 16,

import os
import math
import torch
import random
import numpy as np
from models.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer
from utils.network import PTQNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS

EPS_MIN = 0.020              	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.99             	# The rate at which eps decays from EPS_MAX to EPS_MIN
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

class DDQNetwork(PTQNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None): 
		super().__init__(state_size, action_size, lr=lr, gpu=gpu, load=load)

	def get_action(self, state, use_target=False, numpy=True, sample=True):
		with torch.no_grad():
			q_values = self.critic_local(state) if not use_target else self.critic_target(state)
			return q_values.cpu().numpy() if numpy else q_values

	def get_q_value(self, state, action, use_target=False, numpy=True):
		with torch.no_grad():
			q_values = self.critic_local(state) if not use_target else self.critic_target(state)
			out_dims = q_values.size()[:-1]
			q_values = q_values.reshape(-1, q_values.size(-1))
			q_indices = action.argmax(-1).reshape(-1)
			q_selected = q_values[np.arange(q_indices.size(0)), q_indices].reshape(*out_dims, 1)
			return q_selected.cpu().numpy() if numpy else q_selected
	
	def optimize(self, states, actions, q_targets, importances=1):
		q_values = self.critic_local(states)[np.arange(actions.size(0)), actions.argmax(-1)].unsqueeze(-1)
		critic_error = q_values - q_targets.detach()
		critic_loss = importances.to(self.device) * critic_error.pow(2)
		self.step(self.critic_optimizer, critic_loss.mean())
		self.soft_copy(self.critic_local, self.critic_target)
		return critic_error.cpu().detach().numpy().squeeze(-1)
	
	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ddqn", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ddqn", dirname, name)

class DDQNAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, DDQNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True, e_greedy=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if e_greedy and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), sample=sample)
		return action_greedy
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if len(self.buffer) >= int(self.update_freq * (1 - self.eps + EPS_MIN)**0.5):
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			next_state = self.to_tensor(next_state)
			next_action = self.network.get_action(next_state, use_target=False, numpy=False)
			values = self.network.get_q_value(states, actions, use_target=True, numpy=False)
			next_value = self.network.get_q_value(next_state, next_action, use_target=True, numpy=False)
			targets, _ = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values)
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states, actions, targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=True)	
		if len(self.replay_buffer) > 0:
			(states, actions, targets), indices, importances = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)
			errors = self.network.optimize(states, actions, targets, importances**(1-self.eps))
			self.replay_buffer.update_priorities(indices, errors)
			if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "Acrobot-v1", "Pendulum-v0"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[2]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class PixelAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	logger = Logger(model, env_name, num_envs=num_envs)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = PixelAgent(envs.state_size, envs.action_size, num_envs, model)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0] or s+1 % envs.env.spec.max_episode_steps == 0:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 199, Reward: -1306.2817 [173.15], Avg: -1479.4309 (0.990)
Step: 399, Reward: -1303.1285 [53.67], Avg: -1418.1126 (0.980)
Step: 599, Reward: -1198.1911 [131.24], Avg: -1388.5521 (0.970)
Step: 799, Reward: -1138.4312 [79.92], Avg: -1346.0030 (0.961)
Step: 999, Reward: -1347.0077 [113.87], Avg: -1368.9774 (0.951)
Step: 1199, Reward: -1264.5913 [201.44], Avg: -1385.1530 (0.941)
Step: 1399, Reward: -1420.5442 [183.60], Avg: -1416.4381 (0.932)
Step: 1599, Reward: -1347.2691 [184.00], Avg: -1430.7921 (0.923)
Step: 1799, Reward: -1278.2275 [185.74], Avg: -1434.4782 (0.914)
Step: 1999, Reward: -1326.0400 [143.27], Avg: -1437.9614 (0.904)
Step: 2199, Reward: -1266.0456 [177.68], Avg: -1438.4850 (0.895)
Step: 2399, Reward: -1385.1102 [183.82], Avg: -1449.3558 (0.886)
Step: 2599, Reward: -1340.1600 [149.27], Avg: -1452.4386 (0.878)
Step: 2799, Reward: -1198.6721 [95.26], Avg: -1441.1165 (0.869)
Step: 2999, Reward: -1409.7327 [208.29], Avg: -1452.9100 (0.860)
Step: 3199, Reward: -1346.7329 [142.37], Avg: -1455.1722 (0.851)
Step: 3399, Reward: -1461.4217 [234.86], Avg: -1469.3549 (0.843)
Step: 3599, Reward: -1363.6670 [193.19], Avg: -1474.2161 (0.835)
Step: 3799, Reward: -1344.1249 [123.89], Avg: -1473.8898 (0.826)
Step: 3999, Reward: -1315.3283 [258.10], Avg: -1478.8668 (0.818)
Step: 4199, Reward: -1133.6779 [170.12], Avg: -1470.5303 (0.810)
Step: 4399, Reward: -1285.2484 [153.76], Avg: -1469.0974 (0.802)
Step: 4599, Reward: -1359.6034 [132.47], Avg: -1470.0964 (0.794)
Step: 4799, Reward: -1368.1358 [183.16], Avg: -1473.4799 (0.786)
Step: 4999, Reward: -1303.6617 [138.47], Avg: -1472.2259 (0.778)
Step: 5199, Reward: -1195.8697 [32.08], Avg: -1462.8306 (0.770)
Step: 5399, Reward: -1375.8262 [131.66], Avg: -1464.4845 (0.762)
Step: 5599, Reward: -1385.9497 [195.97], Avg: -1468.6786 (0.755)
Step: 5799, Reward: -1419.3534 [133.34], Avg: -1471.5755 (0.747)
Step: 5999, Reward: -1319.4277 [298.53], Avg: -1476.4547 (0.740)
Step: 6199, Reward: -1343.3332 [158.27], Avg: -1477.2661 (0.732)
Step: 6399, Reward: -1417.1572 [249.55], Avg: -1483.1861 (0.725)
Step: 6599, Reward: -1363.5218 [177.10], Avg: -1484.9265 (0.718)
Step: 6799, Reward: -1341.4226 [177.69], Avg: -1485.9320 (0.711)
Step: 6999, Reward: -1179.5505 [101.07], Avg: -1480.0661 (0.703)
Step: 7199, Reward: -1373.8673 [208.78], Avg: -1482.9156 (0.696)
Step: 7399, Reward: -1127.5148 [190.24], Avg: -1478.4519 (0.689)
Step: 7599, Reward: -1315.6592 [243.78], Avg: -1480.5831 (0.683)
Step: 7799, Reward: -1415.6948 [218.45], Avg: -1484.5206 (0.676)
Step: 7999, Reward: -1247.3058 [175.16], Avg: -1482.9693 (0.669)
Step: 8199, Reward: -1260.9887 [40.25], Avg: -1478.5368 (0.662)
Step: 8399, Reward: -1223.9306 [91.88], Avg: -1474.6624 (0.656)
Step: 8599, Reward: -1213.5193 [96.30], Avg: -1470.8289 (0.649)
Step: 8799, Reward: -1443.0071 [144.69], Avg: -1473.4850 (0.643)
Step: 8999, Reward: -1452.3457 [65.00], Avg: -1474.4597 (0.636)
Step: 9199, Reward: -1220.5528 [147.14], Avg: -1472.1387 (0.630)
Step: 9399, Reward: -1377.4232 [170.75], Avg: -1473.7565 (0.624)
Step: 9599, Reward: -1281.7881 [142.18], Avg: -1472.7193 (0.617)
Step: 9799, Reward: -1254.3895 [113.21], Avg: -1470.5739 (0.611)
Step: 9999, Reward: -1451.3358 [185.85], Avg: -1473.9061 (0.605)
Step: 10199, Reward: -1465.3215 [206.31], Avg: -1477.7830 (0.599)
Step: 10399, Reward: -1338.7630 [124.22], Avg: -1477.4984 (0.593)
Step: 10599, Reward: -1314.0191 [153.45], Avg: -1477.3091 (0.587)
Step: 10799, Reward: -1196.9171 [109.56], Avg: -1474.1456 (0.581)
Step: 10999, Reward: -1321.8464 [192.97], Avg: -1474.8851 (0.575)
Step: 11199, Reward: -1436.8396 [61.64], Avg: -1475.3064 (0.570)
Step: 11399, Reward: -1391.8776 [171.69], Avg: -1476.8548 (0.564)
Step: 11599, Reward: -1297.5060 [61.09], Avg: -1474.8158 (0.558)
Step: 11799, Reward: -1482.6413 [81.54], Avg: -1476.3305 (0.553)
Step: 11999, Reward: -1173.0948 [135.69], Avg: -1473.5382 (0.547)
Step: 12199, Reward: -1215.9734 [100.06], Avg: -1470.9561 (0.542)
Step: 12399, Reward: -1489.2257 [35.99], Avg: -1471.8312 (0.536)
Step: 12599, Reward: -1314.6578 [182.78], Avg: -1472.2377 (0.531)
Step: 12799, Reward: -1328.0699 [197.44], Avg: -1473.0701 (0.526)
Step: 12999, Reward: -1370.3281 [131.06], Avg: -1473.5057 (0.520)
Step: 13199, Reward: -1357.1736 [124.74], Avg: -1473.6332 (0.515)
Step: 13399, Reward: -1158.6609 [177.37], Avg: -1471.5795 (0.510)
Step: 13599, Reward: -1406.8273 [148.70], Avg: -1472.8140 (0.505)
Step: 13799, Reward: -1443.4997 [127.10], Avg: -1474.2312 (0.500)
Step: 13999, Reward: -1480.4226 [223.92], Avg: -1477.5185 (0.495)
Step: 14199, Reward: -1423.0197 [217.82], Avg: -1479.8188 (0.490)
Step: 14399, Reward: -1436.3048 [121.15], Avg: -1480.8971 (0.485)
Step: 14599, Reward: -1379.8708 [136.29], Avg: -1481.3802 (0.480)
Step: 14799, Reward: -1375.0835 [187.97], Avg: -1482.4839 (0.475)
Step: 14999, Reward: -1223.2884 [149.79], Avg: -1481.0252 (0.471)
Step: 15199, Reward: -1446.5351 [218.12], Avg: -1483.4413 (0.466)
Step: 15399, Reward: -1239.4127 [124.14], Avg: -1481.8843 (0.461)
Step: 15599, Reward: -1485.4107 [106.92], Avg: -1483.3003 (0.457)
Step: 15799, Reward: -1248.8253 [110.63], Avg: -1481.7326 (0.452)
Step: 15999, Reward: -1212.2946 [169.99], Avg: -1480.4895 (0.448)
Step: 16199, Reward: -1426.3600 [153.87], Avg: -1481.7209 (0.443)
Step: 16399, Reward: -1378.6099 [222.60], Avg: -1483.1781 (0.439)
Step: 16599, Reward: -1378.1565 [162.14], Avg: -1483.8662 (0.434)
Step: 16799, Reward: -1373.3095 [147.78], Avg: -1484.3093 (0.430)
Step: 16999, Reward: -1407.6607 [124.55], Avg: -1484.8729 (0.426)
Step: 17199, Reward: -1312.1450 [129.61], Avg: -1484.3716 (0.421)
Step: 17399, Reward: -1431.7108 [205.16], Avg: -1486.1244 (0.417)
Step: 17599, Reward: -1390.1735 [159.63], Avg: -1486.8480 (0.413)
Step: 17799, Reward: -1197.5178 [124.28], Avg: -1484.9935 (0.409)
Step: 17999, Reward: -1352.8090 [145.02], Avg: -1485.1361 (0.405)
Step: 18199, Reward: -1268.9643 [155.68], Avg: -1484.4714 (0.401)
Step: 18399, Reward: -1289.5942 [194.64], Avg: -1484.4688 (0.397)
Step: 18599, Reward: -1331.6301 [230.00], Avg: -1485.2985 (0.393)
Step: 18799, Reward: -1421.4912 [105.46], Avg: -1485.7416 (0.389)
Step: 18999, Reward: -1333.5223 [22.22], Avg: -1484.3732 (0.385)
Step: 19199, Reward: -1390.2153 [79.37], Avg: -1484.2192 (0.381)
Step: 19399, Reward: -1393.4405 [169.47], Avg: -1485.0305 (0.377)
Step: 19599, Reward: -1490.3576 [60.90], Avg: -1485.7062 (0.373)
Step: 19799, Reward: -1330.5859 [88.96], Avg: -1485.0379 (0.370)
Step: 19999, Reward: -1323.2617 [76.41], Avg: -1484.1842 (0.366)
Step: 20199, Reward: -1426.7428 [98.98], Avg: -1484.5955 (0.362)
Step: 20399, Reward: -1343.6085 [194.67], Avg: -1485.1218 (0.359)
Step: 20599, Reward: -1410.0217 [88.65], Avg: -1485.2533 (0.355)
Step: 20799, Reward: -1451.9685 [51.17], Avg: -1485.4253 (0.352)
Step: 20999, Reward: -1316.0176 [120.22], Avg: -1484.9568 (0.348)
Step: 21199, Reward: -1358.6831 [165.08], Avg: -1485.3230 (0.345)
Step: 21399, Reward: -1280.2188 [71.89], Avg: -1484.0780 (0.341)
Step: 21599, Reward: -1380.6463 [144.48], Avg: -1484.4581 (0.338)
Step: 21799, Reward: -1367.9791 [217.04], Avg: -1485.3807 (0.334)
Step: 21999, Reward: -1302.4629 [126.52], Avg: -1484.8680 (0.331)
Step: 22199, Reward: -1390.0446 [163.41], Avg: -1485.4859 (0.328)
Step: 22399, Reward: -1422.3473 [128.34], Avg: -1486.0681 (0.324)
Step: 22599, Reward: -1292.9340 [121.57], Avg: -1485.4347 (0.321)
Step: 22799, Reward: -1457.6546 [121.07], Avg: -1486.2531 (0.318)
Step: 22999, Reward: -1401.9622 [104.07], Avg: -1486.4251 (0.315)
Step: 23199, Reward: -1474.0994 [92.72], Avg: -1487.1181 (0.312)
Step: 23399, Reward: -1317.1834 [155.44], Avg: -1486.9942 (0.309)
Step: 23599, Reward: -1419.1960 [133.87], Avg: -1487.5541 (0.305)
Step: 23799, Reward: -1313.6054 [147.16], Avg: -1487.3290 (0.302)
Step: 23999, Reward: -1458.3156 [114.08], Avg: -1488.0379 (0.299)
Step: 24199, Reward: -1380.5252 [126.12], Avg: -1488.1917 (0.296)
Step: 24399, Reward: -1315.5606 [113.92], Avg: -1487.7104 (0.293)
Step: 24599, Reward: -1290.2236 [253.65], Avg: -1488.1671 (0.290)
Step: 24799, Reward: -1402.2999 [148.49], Avg: -1488.6720 (0.288)
Step: 24999, Reward: -1329.1180 [89.58], Avg: -1488.1122 (0.285)
Step: 25199, Reward: -1441.9691 [136.00], Avg: -1488.8254 (0.282)
Step: 25399, Reward: -1377.5307 [167.10], Avg: -1489.2648 (0.279)
Step: 25599, Reward: -1216.9178 [270.60], Avg: -1489.2512 (0.276)
Step: 25799, Reward: -1413.3599 [138.45], Avg: -1489.7361 (0.273)
Step: 25999, Reward: -1361.8133 [187.18], Avg: -1490.1920 (0.271)
Step: 26199, Reward: -1403.2151 [85.66], Avg: -1490.1819 (0.268)
Step: 26399, Reward: -1395.6348 [130.66], Avg: -1490.4555 (0.265)
Step: 26599, Reward: -1458.9586 [53.67], Avg: -1490.6222 (0.263)
Step: 26799, Reward: -1418.3476 [137.10], Avg: -1491.1060 (0.260)
Step: 26999, Reward: -1452.4873 [174.85], Avg: -1492.1150 (0.257)
Step: 27199, Reward: -1487.8270 [39.46], Avg: -1492.3737 (0.255)
Step: 27399, Reward: -1521.8919 [41.81], Avg: -1492.8944 (0.252)
Step: 27599, Reward: -1329.3603 [135.80], Avg: -1492.6934 (0.250)
Step: 27799, Reward: -1399.1857 [159.96], Avg: -1493.1715 (0.247)
Step: 27999, Reward: -1373.7901 [179.96], Avg: -1493.6042 (0.245)
Step: 28199, Reward: -1428.8767 [91.03], Avg: -1493.7907 (0.242)
Step: 28399, Reward: -1435.7525 [129.82], Avg: -1494.2962 (0.240)
Step: 28599, Reward: -1460.5394 [124.04], Avg: -1494.9276 (0.238)
Step: 28799, Reward: -1449.3258 [141.81], Avg: -1495.5957 (0.235)
Step: 28999, Reward: -1454.8204 [91.37], Avg: -1495.9447 (0.233)
Step: 29199, Reward: -1406.8380 [169.41], Avg: -1496.4947 (0.231)
Step: 29399, Reward: -1407.8018 [87.49], Avg: -1496.4865 (0.228)
Step: 29599, Reward: -1514.2181 [71.93], Avg: -1497.0923 (0.226)
Step: 29799, Reward: -1303.8575 [198.21], Avg: -1497.1257 (0.224)
Step: 29999, Reward: -1452.1571 [171.32], Avg: -1497.9681 (0.221)
Step: 30199, Reward: -1393.6357 [114.75], Avg: -1498.0371 (0.219)
Step: 30399, Reward: -1338.5031 [223.83], Avg: -1498.4601 (0.217)
Step: 30599, Reward: -1373.7811 [162.75], Avg: -1498.7090 (0.215)
Step: 30799, Reward: -1438.5795 [139.66], Avg: -1499.2254 (0.213)
Step: 30999, Reward: -1445.5630 [114.84], Avg: -1499.6201 (0.211)
Step: 31199, Reward: -1407.0604 [189.05], Avg: -1500.2386 (0.208)
Step: 31399, Reward: -1267.5888 [223.24], Avg: -1500.1787 (0.206)
Step: 31599, Reward: -1411.4325 [187.59], Avg: -1500.8043 (0.204)
Step: 31799, Reward: -1386.8044 [174.91], Avg: -1501.1874 (0.202)
Step: 31999, Reward: -1389.6467 [271.84], Avg: -1502.1893 (0.200)
Step: 32199, Reward: -1260.6734 [225.78], Avg: -1502.0915 (0.198)
Step: 32399, Reward: -1245.4945 [138.79], Avg: -1501.3643 (0.196)
Step: 32599, Reward: -1449.8861 [90.93], Avg: -1501.6063 (0.194)
Step: 32799, Reward: -1515.0522 [86.49], Avg: -1502.2157 (0.192)
Step: 32999, Reward: -1403.6036 [108.52], Avg: -1502.2757 (0.190)
Step: 33199, Reward: -1356.3668 [123.78], Avg: -1502.1424 (0.189)
Step: 33399, Reward: -1433.4180 [158.08], Avg: -1502.6775 (0.187)
Step: 33599, Reward: -1450.2814 [72.66], Avg: -1502.7981 (0.185)
Step: 33799, Reward: -1448.1160 [87.87], Avg: -1502.9945 (0.183)
Step: 33999, Reward: -1410.3546 [102.73], Avg: -1503.0538 (0.181)
Step: 34199, Reward: -1541.7883 [122.34], Avg: -1503.9958 (0.179)
Step: 34399, Reward: -1377.4771 [149.59], Avg: -1504.1299 (0.178)
Step: 34599, Reward: -1516.5583 [101.28], Avg: -1504.7872 (0.176)
Step: 34799, Reward: -1457.2558 [93.62], Avg: -1505.0520 (0.174)
Step: 34999, Reward: -1357.1316 [184.18], Avg: -1505.2592 (0.172)
Step: 35199, Reward: -1533.5645 [17.22], Avg: -1505.5179 (0.171)
Step: 35399, Reward: -1383.8045 [153.43], Avg: -1505.6971 (0.169)
Step: 35599, Reward: -1443.4569 [135.86], Avg: -1506.1107 (0.167)
Step: 35799, Reward: -1458.7272 [83.20], Avg: -1506.3108 (0.165)
Step: 35999, Reward: -1254.2503 [177.58], Avg: -1505.8971 (0.164)
Step: 36199, Reward: -1473.0488 [70.75], Avg: -1506.1065 (0.162)
Step: 36399, Reward: -1388.8923 [135.70], Avg: -1506.2081 (0.161)
Step: 36599, Reward: -1466.8269 [101.66], Avg: -1506.5484 (0.159)
Step: 36799, Reward: -1425.0469 [193.53], Avg: -1507.1573 (0.157)
Step: 36999, Reward: -1384.4326 [228.46], Avg: -1507.7288 (0.156)
Step: 37199, Reward: -1304.3759 [139.50], Avg: -1507.3855 (0.154)
Step: 37399, Reward: -1461.4895 [126.47], Avg: -1507.8164 (0.153)
Step: 37599, Reward: -1202.5982 [223.24], Avg: -1507.3803 (0.151)
Step: 37799, Reward: -1406.7855 [157.67], Avg: -1507.6823 (0.150)
Step: 37999, Reward: -1280.8846 [177.91], Avg: -1507.4250 (0.148)
Step: 38199, Reward: -1482.1072 [133.23], Avg: -1507.9900 (0.147)
Step: 38399, Reward: -1493.2188 [103.56], Avg: -1508.4524 (0.145)
Step: 38599, Reward: -1480.7201 [75.10], Avg: -1508.6979 (0.144)
Step: 38799, Reward: -1490.9732 [163.12], Avg: -1509.4473 (0.142)
Step: 38999, Reward: -1518.3683 [45.34], Avg: -1509.7256 (0.141)
Step: 39199, Reward: -1495.7341 [45.52], Avg: -1509.8865 (0.139)
Step: 39399, Reward: -1329.5353 [170.44], Avg: -1509.8362 (0.138)
Step: 39599, Reward: -1406.1219 [94.67], Avg: -1509.7905 (0.137)
Step: 39799, Reward: -1442.6792 [100.92], Avg: -1509.9604 (0.135)
Step: 39999, Reward: -1450.9286 [126.27], Avg: -1510.2965 (0.134)
Step: 40199, Reward: -1314.3974 [206.12], Avg: -1510.3474 (0.133)
Step: 40399, Reward: -1150.4315 [170.37], Avg: -1509.4091 (0.131)
Step: 40599, Reward: -1326.1890 [122.46], Avg: -1509.1098 (0.130)
Step: 40799, Reward: -1357.2521 [186.44], Avg: -1509.2793 (0.129)
Step: 40999, Reward: -1484.4952 [100.10], Avg: -1509.6467 (0.127)
Step: 41199, Reward: -1307.7557 [129.49], Avg: -1509.2952 (0.126)
Step: 41399, Reward: -1454.8054 [105.29], Avg: -1509.5407 (0.125)
Step: 41599, Reward: -1384.9296 [161.01], Avg: -1509.7156 (0.124)
Step: 41799, Reward: -1302.4459 [217.09], Avg: -1509.7626 (0.122)
Step: 41999, Reward: -1361.0854 [154.64], Avg: -1509.7910 (0.121)
Step: 42199, Reward: -1480.9703 [69.42], Avg: -1509.9835 (0.120)
Step: 42399, Reward: -1505.5815 [113.70], Avg: -1510.4990 (0.119)
Step: 42599, Reward: -1399.8622 [110.37], Avg: -1510.4978 (0.118)
Step: 42799, Reward: -1524.7558 [55.64], Avg: -1510.8244 (0.116)
Step: 42999, Reward: -1532.9420 [88.50], Avg: -1511.3389 (0.115)
Step: 43199, Reward: -1381.3693 [163.18], Avg: -1511.4927 (0.114)
Step: 43399, Reward: -1391.4671 [147.42], Avg: -1511.6189 (0.113)
Step: 43599, Reward: -1244.4259 [241.39], Avg: -1511.5006 (0.112)
Step: 43799, Reward: -1473.6507 [202.42], Avg: -1512.2520 (0.111)
Step: 43999, Reward: -1444.1672 [225.01], Avg: -1512.9654 (0.110)
Step: 44199, Reward: -1513.5735 [111.52], Avg: -1513.4727 (0.108)
Step: 44399, Reward: -1558.6487 [76.39], Avg: -1514.0203 (0.107)
Step: 44599, Reward: -1421.5567 [227.51], Avg: -1514.6259 (0.106)
Step: 44799, Reward: -1404.4098 [159.72], Avg: -1514.8469 (0.105)
Step: 44999, Reward: -1267.7470 [186.45], Avg: -1514.5773 (0.104)
Step: 45199, Reward: -1411.4404 [230.22], Avg: -1515.1397 (0.103)
Step: 45399, Reward: -1555.6077 [44.84], Avg: -1515.5155 (0.102)
Step: 45599, Reward: -1430.5150 [174.60], Avg: -1515.9085 (0.101)
Step: 45799, Reward: -1354.4767 [145.16], Avg: -1515.8374 (0.100)
Step: 45999, Reward: -1265.6343 [186.64], Avg: -1515.5611 (0.099)
Step: 46199, Reward: -1518.6790 [141.11], Avg: -1516.1854 (0.098)
Step: 46399, Reward: -1353.0094 [102.93], Avg: -1515.9257 (0.097)
Step: 46599, Reward: -1488.9692 [80.20], Avg: -1516.1542 (0.096)
Step: 46799, Reward: -1458.9748 [92.01], Avg: -1516.3031 (0.095)
Step: 46999, Reward: -1319.5256 [194.32], Avg: -1516.2926 (0.094)
Step: 47199, Reward: -1528.2690 [53.37], Avg: -1516.5695 (0.093)
Step: 47399, Reward: -1481.3031 [106.47], Avg: -1516.8699 (0.092)
Step: 47599, Reward: -1601.7827 [30.70], Avg: -1517.3557 (0.091)
Step: 47799, Reward: -1371.3026 [177.98], Avg: -1517.4893 (0.091)
Step: 47999, Reward: -1357.7271 [231.18], Avg: -1517.7869 (0.090)
Step: 48199, Reward: -1426.7750 [203.03], Avg: -1518.2516 (0.089)
Step: 48399, Reward: -1418.8813 [110.90], Avg: -1518.2993 (0.088)
Step: 48599, Reward: -1381.5372 [175.96], Avg: -1518.4606 (0.087)
Step: 48799, Reward: -1438.3260 [139.75], Avg: -1518.7049 (0.086)
Step: 48999, Reward: -1424.3829 [184.23], Avg: -1519.0719 (0.085)
Step: 49199, Reward: -1281.9629 [153.24], Avg: -1518.7310 (0.084)
Step: 49399, Reward: -1456.0038 [103.77], Avg: -1518.8971 (0.084)
Step: 49599, Reward: -1492.8633 [109.60], Avg: -1519.2341 (0.083)
Step: 49799, Reward: -1431.3827 [190.37], Avg: -1519.6458 (0.082)
Step: 49999, Reward: -1454.7727 [161.26], Avg: -1520.0313 (0.081)
Step: 50199, Reward: -1383.4249 [166.80], Avg: -1520.1516 (0.080)
Step: 50399, Reward: -1400.2449 [152.55], Avg: -1520.2811 (0.079)
Step: 50599, Reward: -1248.6301 [118.55], Avg: -1519.6760 (0.079)
Step: 50799, Reward: -1552.9986 [93.64], Avg: -1520.1759 (0.078)
Step: 50999, Reward: -1447.8308 [79.19], Avg: -1520.2027 (0.077)
Step: 51199, Reward: -1325.6419 [240.26], Avg: -1520.3812 (0.076)
Step: 51399, Reward: -1124.5962 [91.39], Avg: -1519.1968 (0.076)
Step: 51599, Reward: -1279.0044 [269.00], Avg: -1519.3084 (0.075)
Step: 51799, Reward: -1305.6066 [62.89], Avg: -1518.7261 (0.074)
Step: 51999, Reward: -1443.0324 [135.35], Avg: -1518.9556 (0.073)
Step: 52199, Reward: -1427.2312 [210.08], Avg: -1519.4090 (0.073)
Step: 52399, Reward: -1544.6344 [105.09], Avg: -1519.9064 (0.072)
Step: 52599, Reward: -1291.8989 [203.18], Avg: -1519.8120 (0.071)
Step: 52799, Reward: -1406.1824 [223.55], Avg: -1520.2284 (0.070)
Step: 52999, Reward: -1473.4778 [232.39], Avg: -1520.9289 (0.070)
Step: 53199, Reward: -1483.0755 [77.81], Avg: -1521.0791 (0.069)
Step: 53399, Reward: -1456.1874 [95.33], Avg: -1521.1931 (0.068)
Step: 53599, Reward: -1343.8642 [147.08], Avg: -1521.0803 (0.068)
Step: 53799, Reward: -1409.9369 [138.56], Avg: -1521.1822 (0.067)
Step: 53999, Reward: -1568.4280 [84.11], Avg: -1521.6687 (0.066)
Step: 54199, Reward: -1486.5334 [139.17], Avg: -1522.0526 (0.066)
Step: 54399, Reward: -1518.0754 [110.39], Avg: -1522.4438 (0.065)
Step: 54599, Reward: -1306.4453 [242.99], Avg: -1522.5427 (0.064)
Step: 54799, Reward: -1381.3774 [226.80], Avg: -1522.8552 (0.064)
Step: 54999, Reward: -1450.7015 [174.77], Avg: -1523.2284 (0.063)
Step: 55199, Reward: -1470.8687 [121.13], Avg: -1523.4776 (0.062)
Step: 55399, Reward: -1392.0846 [230.96], Avg: -1523.8370 (0.062)
Step: 55599, Reward: -1470.6743 [140.34], Avg: -1524.1506 (0.061)
Step: 55799, Reward: -1311.3751 [339.78], Avg: -1524.6058 (0.061)
Step: 55999, Reward: -1434.3968 [245.70], Avg: -1525.1611 (0.060)
Step: 56199, Reward: -1545.9124 [91.20], Avg: -1525.5596 (0.059)
Step: 56399, Reward: -1467.7743 [104.34], Avg: -1525.7246 (0.059)
Step: 56599, Reward: -1485.2289 [182.84], Avg: -1526.2276 (0.058)
Step: 56799, Reward: -1455.5162 [168.67], Avg: -1526.5726 (0.058)
Step: 56999, Reward: -1506.6743 [128.12], Avg: -1526.9523 (0.057)
Step: 57199, Reward: -1287.9568 [250.68], Avg: -1526.9932 (0.056)
Step: 57399, Reward: -1386.7671 [160.83], Avg: -1527.0649 (0.056)
Step: 57599, Reward: -1347.9040 [187.15], Avg: -1527.0927 (0.055)
Step: 57799, Reward: -1578.8834 [60.38], Avg: -1527.4808 (0.055)
Step: 57999, Reward: -1418.4248 [182.04], Avg: -1527.7325 (0.054)
Step: 58199, Reward: -1545.2642 [162.18], Avg: -1528.3501 (0.054)
Step: 58399, Reward: -1554.0864 [52.09], Avg: -1528.6166 (0.053)
Step: 58599, Reward: -1294.2066 [139.48], Avg: -1528.2926 (0.053)
Step: 58799, Reward: -1358.3045 [131.53], Avg: -1528.1618 (0.052)
Step: 58999, Reward: -1604.4869 [31.53], Avg: -1528.5274 (0.052)
Step: 59199, Reward: -1432.8192 [162.56], Avg: -1528.7532 (0.051)
Step: 59399, Reward: -1547.4971 [66.24], Avg: -1529.0394 (0.051)
Step: 59599, Reward: -1484.0766 [105.28], Avg: -1529.2418 (0.050)
Step: 59799, Reward: -1352.6680 [225.98], Avg: -1529.4070 (0.050)
Step: 59999, Reward: -1461.0252 [72.64], Avg: -1529.4212 (0.049)
Step: 60199, Reward: -1464.3245 [167.66], Avg: -1529.7619 (0.049)
Step: 60399, Reward: -1420.2019 [121.86], Avg: -1529.8027 (0.048)
Step: 60599, Reward: -1407.0431 [145.63], Avg: -1529.8782 (0.048)
Step: 60799, Reward: -1447.9832 [203.84], Avg: -1530.2793 (0.047)
Step: 60999, Reward: -1496.6183 [151.96], Avg: -1530.6671 (0.047)
Step: 61199, Reward: -1405.7482 [172.16], Avg: -1530.8215 (0.046)
Step: 61399, Reward: -1375.5853 [238.96], Avg: -1531.0942 (0.046)
Step: 61599, Reward: -1262.9175 [202.20], Avg: -1530.8800 (0.045)
Step: 61799, Reward: -1504.4285 [147.06], Avg: -1531.2704 (0.045)
Step: 61999, Reward: -1369.6228 [159.00], Avg: -1531.2618 (0.044)
Step: 62199, Reward: -1426.5075 [202.29], Avg: -1531.5754 (0.044)
Step: 62399, Reward: -1540.3076 [87.09], Avg: -1531.8826 (0.043)
Step: 62599, Reward: -1545.7258 [81.04], Avg: -1532.1857 (0.043)
Step: 62799, Reward: -1524.9906 [76.10], Avg: -1532.4052 (0.043)
Step: 62999, Reward: -1367.3775 [151.53], Avg: -1532.3623 (0.042)
Step: 63199, Reward: -1356.2279 [123.43], Avg: -1532.1956 (0.042)
Step: 63399, Reward: -1336.4322 [244.26], Avg: -1532.3486 (0.041)
Step: 63599, Reward: -1325.7244 [33.65], Avg: -1531.8046 (0.041)
Step: 63799, Reward: -1512.2270 [133.09], Avg: -1532.1604 (0.041)
Step: 63999, Reward: -1542.9978 [97.59], Avg: -1532.4993 (0.040)
Step: 64199, Reward: -1451.6151 [143.40], Avg: -1532.6940 (0.040)
Step: 64399, Reward: -1457.2546 [65.50], Avg: -1532.6632 (0.039)
Step: 64599, Reward: -1254.6089 [194.24], Avg: -1532.4037 (0.039)
Step: 64799, Reward: -1442.3200 [148.71], Avg: -1532.5846 (0.039)
Step: 64999, Reward: -1515.6807 [101.42], Avg: -1532.8447 (0.038)
Step: 65199, Reward: -1532.0988 [154.09], Avg: -1533.3151 (0.038)
Step: 65399, Reward: -1318.1792 [240.46], Avg: -1533.3925 (0.037)
Step: 65599, Reward: -1339.5192 [222.27], Avg: -1533.4791 (0.037)
Step: 65799, Reward: -1498.9541 [92.16], Avg: -1533.6543 (0.037)
Step: 65999, Reward: -1287.6066 [237.38], Avg: -1533.6280 (0.036)
Step: 66199, Reward: -1385.3289 [226.43], Avg: -1533.8641 (0.036)
Step: 66399, Reward: -1395.5751 [244.00], Avg: -1534.1825 (0.036)
Step: 66599, Reward: -1463.2338 [209.72], Avg: -1534.5992 (0.035)
Step: 66799, Reward: -1422.5919 [182.96], Avg: -1534.8116 (0.035)
Step: 66999, Reward: -1365.6982 [188.72], Avg: -1534.8701 (0.034)
Step: 67199, Reward: -1357.1020 [254.13], Avg: -1535.0974 (0.034)
Step: 67399, Reward: -1437.7543 [122.71], Avg: -1535.1727 (0.034)
Step: 67599, Reward: -1489.0677 [196.13], Avg: -1535.6166 (0.033)
Step: 67799, Reward: -1493.4729 [107.40], Avg: -1535.8091 (0.033)
Step: 67999, Reward: -1405.5101 [135.54], Avg: -1535.8245 (0.033)
Step: 68199, Reward: -1490.9244 [106.21], Avg: -1536.0043 (0.032)
Step: 68399, Reward: -1273.4711 [211.15], Avg: -1535.8540 (0.032)
Step: 68599, Reward: -1378.3240 [217.43], Avg: -1536.0286 (0.032)
Step: 68799, Reward: -1513.3073 [159.93], Avg: -1536.4275 (0.032)
Step: 68999, Reward: -1453.0741 [94.83], Avg: -1536.4608 (0.031)
Step: 69199, Reward: -1445.5589 [148.30], Avg: -1536.6266 (0.031)
Step: 69399, Reward: -1357.9738 [179.14], Avg: -1536.6280 (0.031)
Step: 69599, Reward: -1436.8896 [220.19], Avg: -1536.9742 (0.030)
Step: 69799, Reward: -1448.5988 [166.41], Avg: -1537.1978 (0.030)
Step: 69999, Reward: -1502.7857 [165.31], Avg: -1537.5718 (0.030)
Step: 70199, Reward: -1426.8798 [185.02], Avg: -1537.7835 (0.029)
Step: 70399, Reward: -1382.4989 [296.50], Avg: -1538.1847 (0.029)
Step: 70599, Reward: -1610.5689 [34.44], Avg: -1538.4873 (0.029)
Step: 70799, Reward: -1524.0663 [108.97], Avg: -1538.7544 (0.029)
Step: 70999, Reward: -1473.5556 [210.81], Avg: -1539.1646 (0.028)
Step: 71199, Reward: -1492.8792 [194.79], Avg: -1539.5817 (0.028)
Step: 71399, Reward: -1490.3653 [165.31], Avg: -1539.9069 (0.028)
Step: 71599, Reward: -1444.1511 [238.19], Avg: -1540.3048 (0.027)
Step: 71799, Reward: -1426.8711 [149.79], Avg: -1540.4061 (0.027)
Step: 71999, Reward: -1552.7298 [87.46], Avg: -1540.6833 (0.027)
Step: 72199, Reward: -1418.7859 [105.02], Avg: -1540.6365 (0.027)
Step: 72399, Reward: -1398.8643 [287.94], Avg: -1541.0403 (0.026)
Step: 72599, Reward: -1325.8264 [264.19], Avg: -1541.1752 (0.026)
Step: 72799, Reward: -1418.5651 [277.95], Avg: -1541.6020 (0.026)
Step: 72999, Reward: -1413.5401 [142.65], Avg: -1541.6419 (0.026)
Step: 73199, Reward: -1399.6023 [112.44], Avg: -1541.5611 (0.025)
Step: 73399, Reward: -1375.2364 [183.84], Avg: -1541.6088 (0.025)
Step: 73599, Reward: -1343.2950 [197.05], Avg: -1541.6054 (0.025)
Step: 73799, Reward: -1571.0740 [68.37], Avg: -1541.8705 (0.025)
Step: 73999, Reward: -1489.8839 [103.95], Avg: -1542.0109 (0.024)
Step: 74199, Reward: -1437.4896 [124.27], Avg: -1542.0642 (0.024)
Step: 74399, Reward: -1424.0735 [255.94], Avg: -1542.4350 (0.024)
Step: 74599, Reward: -1455.4276 [228.26], Avg: -1542.8137 (0.024)
Step: 74799, Reward: -1522.0073 [106.31], Avg: -1543.0423 (0.023)
Step: 74999, Reward: -1370.6313 [275.83], Avg: -1543.3181 (0.023)
Step: 75199, Reward: -1568.3919 [105.70], Avg: -1543.6659 (0.023)
Step: 75399, Reward: -1470.4673 [178.49], Avg: -1543.9452 (0.023)
Step: 75599, Reward: -1491.9361 [223.36], Avg: -1544.3985 (0.022)
Step: 75799, Reward: -1455.7238 [259.50], Avg: -1544.8492 (0.022)
Step: 75999, Reward: -1335.7894 [239.49], Avg: -1544.9293 (0.022)
Step: 76199, Reward: -1407.0141 [219.94], Avg: -1545.1446 (0.022)
Step: 76399, Reward: -1503.5765 [238.01], Avg: -1545.6588 (0.022)
Step: 76599, Reward: -1434.7310 [141.10], Avg: -1545.7376 (0.021)
Step: 76799, Reward: -1395.8129 [228.11], Avg: -1545.9412 (0.021)
Step: 76999, Reward: -1538.3766 [92.60], Avg: -1546.1621 (0.021)
Step: 77199, Reward: -1547.0486 [65.40], Avg: -1546.3338 (0.021)
Step: 77399, Reward: -1341.6890 [236.34], Avg: -1546.4158 (0.020)
Step: 77599, Reward: -1320.0936 [234.57], Avg: -1546.4370 (0.020)
Step: 77799, Reward: -1605.7470 [60.25], Avg: -1546.7444 (0.020)
Step: 77999, Reward: -1418.4543 [150.82], Avg: -1546.8021 (0.020)
Step: 78199, Reward: -1318.3286 [149.83], Avg: -1546.6010 (0.020)
Step: 78399, Reward: -1503.9157 [74.34], Avg: -1546.6818 (0.020)
Step: 78599, Reward: -1459.6453 [137.60], Avg: -1546.8104 (0.020)
Step: 78799, Reward: -1473.7725 [145.83], Avg: -1546.9952 (0.020)
Step: 78999, Reward: -1461.8851 [250.07], Avg: -1547.4128 (0.020)
Step: 79199, Reward: -1577.1587 [60.80], Avg: -1547.6415 (0.020)
Step: 79399, Reward: -1432.1566 [227.92], Avg: -1547.9247 (0.020)
Step: 79599, Reward: -1421.4135 [244.30], Avg: -1548.2206 (0.020)
Step: 79799, Reward: -1547.8636 [80.51], Avg: -1548.4215 (0.020)
Step: 79999, Reward: -1346.2956 [164.17], Avg: -1548.3266 (0.020)
Step: 80199, Reward: -1451.7530 [145.98], Avg: -1548.4498 (0.020)
Step: 80399, Reward: -1396.8940 [184.32], Avg: -1548.5313 (0.020)
Step: 80599, Reward: -1477.8305 [103.67], Avg: -1548.6131 (0.020)
Step: 80799, Reward: -1578.6846 [67.13], Avg: -1548.8537 (0.020)
Step: 80999, Reward: -1568.8993 [58.95], Avg: -1549.0488 (0.020)
Step: 81199, Reward: -1462.0396 [81.93], Avg: -1549.0363 (0.020)
Step: 81399, Reward: -1391.0474 [188.31], Avg: -1549.1108 (0.020)
Step: 81599, Reward: -1457.8501 [157.01], Avg: -1549.2719 (0.020)
Step: 81799, Reward: -1370.8319 [196.84], Avg: -1549.3169 (0.020)
Step: 81999, Reward: -1487.7442 [125.58], Avg: -1549.4730 (0.020)
Step: 82199, Reward: -1446.7044 [228.97], Avg: -1549.7801 (0.020)
Step: 82399, Reward: -1493.5007 [103.04], Avg: -1549.8936 (0.020)
Step: 82599, Reward: -1422.5641 [133.65], Avg: -1549.9089 (0.020)
Step: 82799, Reward: -1306.5010 [238.09], Avg: -1549.8960 (0.020)
Step: 82999, Reward: -1494.7190 [173.59], Avg: -1550.1814 (0.020)
Step: 83199, Reward: -1336.0132 [291.84], Avg: -1550.3681 (0.020)
Step: 83399, Reward: -1537.5736 [66.41], Avg: -1550.4967 (0.020)
Step: 83599, Reward: -1439.1625 [86.14], Avg: -1550.4364 (0.020)
Step: 83799, Reward: -1354.1267 [285.56], Avg: -1550.6494 (0.020)
Step: 83999, Reward: -1439.2110 [143.67], Avg: -1550.7262 (0.020)
Step: 84199, Reward: -1251.8811 [314.18], Avg: -1550.7626 (0.020)
Step: 84399, Reward: -1356.0534 [293.79], Avg: -1550.9974 (0.020)
Step: 84599, Reward: -1447.9092 [256.74], Avg: -1551.3606 (0.020)
Step: 84799, Reward: -1434.9211 [154.46], Avg: -1551.4503 (0.020)
Step: 84999, Reward: -1328.2646 [212.29], Avg: -1551.4246 (0.020)
Step: 85199, Reward: -1494.8044 [204.50], Avg: -1551.7718 (0.020)
Step: 85399, Reward: -1466.1965 [317.01], Avg: -1552.3138 (0.020)
Step: 85599, Reward: -1530.6871 [143.51], Avg: -1552.5985 (0.020)
Step: 85799, Reward: -1366.4461 [244.60], Avg: -1552.7348 (0.020)
Step: 85999, Reward: -1416.4185 [204.94], Avg: -1552.8944 (0.020)
Step: 86199, Reward: -1575.9267 [36.60], Avg: -1553.0328 (0.020)
Step: 86399, Reward: -1462.7221 [173.42], Avg: -1553.2251 (0.020)
Step: 86599, Reward: -1477.7191 [129.16], Avg: -1553.3491 (0.020)
Step: 86799, Reward: -1492.6869 [221.03], Avg: -1553.7186 (0.020)
Step: 86999, Reward: -1512.5449 [96.04], Avg: -1553.8447 (0.020)
Step: 87199, Reward: -1529.3527 [133.11], Avg: -1554.0938 (0.020)
Step: 87399, Reward: -1246.7055 [280.63], Avg: -1554.0326 (0.020)
Step: 87599, Reward: -1589.9386 [103.47], Avg: -1554.3508 (0.020)
Step: 87799, Reward: -1362.2211 [168.50], Avg: -1554.2970 (0.020)
Step: 87999, Reward: -1344.3467 [224.73], Avg: -1554.3306 (0.020)
Step: 88199, Reward: -1465.2549 [174.93], Avg: -1554.5252 (0.020)
Step: 88399, Reward: -1384.2146 [202.90], Avg: -1554.5990 (0.020)
Step: 88599, Reward: -1362.3203 [323.34], Avg: -1554.8948 (0.020)
Step: 88799, Reward: -1184.5776 [205.49], Avg: -1554.5236 (0.020)
Step: 88999, Reward: -1423.8184 [190.41], Avg: -1554.6577 (0.020)
Step: 89199, Reward: -1471.7662 [245.10], Avg: -1555.0215 (0.020)
Step: 89399, Reward: -1547.8432 [53.12], Avg: -1555.1242 (0.020)
Step: 89599, Reward: -1606.7506 [45.80], Avg: -1555.3417 (0.020)
Step: 89799, Reward: -1276.6727 [149.46], Avg: -1555.0539 (0.020)
Step: 89999, Reward: -1383.6935 [174.62], Avg: -1555.0612 (0.020)
Step: 90199, Reward: -1302.7036 [249.16], Avg: -1555.0541 (0.020)
Step: 90399, Reward: -1454.1412 [113.30], Avg: -1555.0815 (0.020)
Step: 90599, Reward: -1527.7498 [108.52], Avg: -1555.2607 (0.020)
Step: 90799, Reward: -1402.0202 [139.75], Avg: -1555.2310 (0.020)
Step: 90999, Reward: -1354.1696 [212.21], Avg: -1555.2555 (0.020)
Step: 91199, Reward: -1299.5653 [300.87], Avg: -1555.3546 (0.020)
Step: 91399, Reward: -1473.6096 [161.08], Avg: -1555.5282 (0.020)
Step: 91599, Reward: -1412.5034 [230.53], Avg: -1555.7193 (0.020)
Step: 91799, Reward: -1272.3024 [180.81], Avg: -1555.4957 (0.020)
Step: 91999, Reward: -1461.4949 [166.33], Avg: -1555.6529 (0.020)
Step: 92199, Reward: -1610.1603 [63.64], Avg: -1555.9092 (0.020)
Step: 92399, Reward: -1439.8062 [177.54], Avg: -1556.0422 (0.020)
Step: 92599, Reward: -1287.8179 [134.21], Avg: -1555.7528 (0.020)
Step: 92799, Reward: -1514.1640 [154.84], Avg: -1555.9968 (0.020)
Step: 92999, Reward: -1372.7833 [239.51], Avg: -1556.1179 (0.020)
Step: 93199, Reward: -1439.1824 [169.08], Avg: -1556.2298 (0.020)
Step: 93399, Reward: -1351.4954 [107.11], Avg: -1556.0207 (0.020)
Step: 93599, Reward: -1357.5742 [171.96], Avg: -1555.9642 (0.020)
Step: 93799, Reward: -1321.5599 [317.99], Avg: -1556.1424 (0.020)
Step: 93999, Reward: -1614.1543 [49.06], Avg: -1556.3702 (0.020)
Step: 94199, Reward: -1441.4549 [250.06], Avg: -1556.6571 (0.020)
Step: 94399, Reward: -1617.5813 [48.07], Avg: -1556.8880 (0.020)
Step: 94599, Reward: -1495.2534 [113.07], Avg: -1556.9968 (0.020)
Step: 94799, Reward: -1404.0747 [225.80], Avg: -1557.1505 (0.020)
Step: 94999, Reward: -1312.0092 [150.17], Avg: -1556.9506 (0.020)
Step: 95199, Reward: -1414.7201 [232.98], Avg: -1557.1413 (0.020)
Step: 95399, Reward: -1498.6405 [135.12], Avg: -1557.3019 (0.020)
Step: 95599, Reward: -1447.2280 [120.31], Avg: -1557.3233 (0.020)
Step: 95799, Reward: -1457.5258 [217.66], Avg: -1557.5694 (0.020)
Step: 95999, Reward: -1468.0456 [152.24], Avg: -1557.7000 (0.020)
Step: 96199, Reward: -1525.4558 [80.21], Avg: -1557.7997 (0.020)
Step: 96399, Reward: -1454.0539 [183.76], Avg: -1557.9657 (0.020)
Step: 96599, Reward: -1519.6685 [176.86], Avg: -1558.2526 (0.020)
Step: 96799, Reward: -1474.0636 [155.39], Avg: -1558.3997 (0.020)
Step: 96999, Reward: -1435.5743 [150.18], Avg: -1558.4561 (0.020)
Step: 97199, Reward: -1318.2916 [194.31], Avg: -1558.3618 (0.020)
Step: 97399, Reward: -1398.6351 [162.36], Avg: -1558.3672 (0.020)
Step: 97599, Reward: -1558.9479 [62.67], Avg: -1558.4968 (0.020)
Step: 97799, Reward: -1468.3019 [264.84], Avg: -1558.8539 (0.020)
Step: 97999, Reward: -1401.4621 [278.80], Avg: -1559.1017 (0.020)
Step: 98199, Reward: -1364.4673 [287.09], Avg: -1559.2900 (0.020)
Step: 98399, Reward: -1334.4604 [224.87], Avg: -1559.2901 (0.020)
Step: 98599, Reward: -1532.5008 [192.26], Avg: -1559.6257 (0.020)
Step: 98799, Reward: -1476.8713 [133.74], Avg: -1559.7289 (0.020)
Step: 98999, Reward: -1467.0998 [141.12], Avg: -1559.8269 (0.020)
Step: 99199, Reward: -1506.1352 [150.28], Avg: -1560.0216 (0.020)
Step: 99399, Reward: -1446.2981 [268.37], Avg: -1560.3328 (0.020)
Step: 99599, Reward: -1247.4907 [239.67], Avg: -1560.1858 (0.020)
Step: 99799, Reward: -1365.2704 [189.17], Avg: -1560.1743 (0.020)
Step: 99999, Reward: -1434.7777 [234.35], Avg: -1560.3922 (0.020)
