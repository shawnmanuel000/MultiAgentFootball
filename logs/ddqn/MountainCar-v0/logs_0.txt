Model: <class 'models.ddqn.DDQNAgent'>, Dir: MountainCar-v0
num_envs: 16,

import os
import math
import torch
import random
import numpy as np
from models.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer
from utils.network import PTQNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, NUM_STEPS

EPS_MIN = 0.020              	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.99             	# The rate at which eps decays from EPS_MAX to EPS_MIN
REPLAY_BATCH_SIZE = 32        	# How many experience tuples to sample from the buffer for each train step

class DDQNetwork(PTQNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None): 
		super().__init__(state_size, action_size, lr=lr, gpu=gpu, load=load)

	def get_action(self, state, use_target=False, numpy=True, sample=True):
		with torch.no_grad():
			q_values = self.critic_local(state) if not use_target else self.critic_target(state)
			return q_values.cpu().numpy() if numpy else q_values

	def get_q_value(self, state, action, use_target=False, numpy=True):
		with torch.no_grad():
			q_values = self.critic_local(state) if not use_target else self.critic_target(state)
			out_dims = q_values.size()[:-1]
			q_values = q_values.reshape(-1, q_values.size(-1))
			q_indices = action.argmax(-1).reshape(-1)
			q_selected = q_values[np.arange(q_indices.size(0)), q_indices].reshape(*out_dims, 1)
			return q_selected.cpu().numpy() if numpy else q_selected
	
	def optimize(self, states, actions, q_targets, importances=1):
		q_values = self.critic_local(states)[np.arange(actions.size(0)), actions.argmax(-1)].unsqueeze(-1)
		critic_error = q_values - q_targets.detach()
		critic_loss = importances.to(self.device) * critic_error.pow(2)
		self.step(self.critic_optimizer, critic_loss.mean())
		self.soft_copy(self.critic_local, self.critic_target)
		return critic_error.cpu().detach().numpy().squeeze(-1)
	
	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ddqn", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ddqn", dirname, name)

class DDQNAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, DDQNetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True, e_greedy=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if e_greedy and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), sample=sample)
		return action_greedy
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if len(self.buffer) >= int(self.update_freq * (1 - self.eps + EPS_MIN)**0.5):
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			next_state = self.to_tensor(next_state)
			next_action = self.network.get_action(next_state, use_target=False, numpy=False)
			values = self.network.get_q_value(states, actions, use_target=True, numpy=False)
			next_value = self.network.get_q_value(next_state, next_action, use_target=True, numpy=False)
			targets, _ = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values)
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states, actions, targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=True)	
		if len(self.replay_buffer) > 0:
			(states, actions, targets), indices, importances = self.replay_buffer.sample(REPLAY_BATCH_SIZE, dtype=self.to_tensor)
			errors = self.network.optimize(states, actions, targets, importances**(1-self.eps))
			self.replay_buffer.update_priorities(indices, errors)
			if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000 				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.980             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import gym
import argparse
import numpy as np
# import gfootball.env as ggym
from collections import deque
from models.ppo import PPOAgent
from models.ddqn import DDQNAgent
from models.ddpg import DDPGAgent
from models.rand import RandomAgent
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, ImgStack, RawStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--model", type=str, default="ddqn", choices=["ddqn", "ddpg", "ppo", "rand"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--steps", type=int, default=100000, help="Number of steps to train the agent")
args = parser.parse_args()

gym_envs = ["CartPole-v0", "MountainCar-v0", "Acrobot-v1", "Pendulum-v0", "MountainCarContinuous-v0", "CarRacing-v0", "BipedalWalker-v2", "LunarLander-v2"]
gfb_envs = ["11_vs_11_stochastic", "academy_empty_goal_close"]
env_name = gym_envs[1]

def make_env(env_name=env_name, log=False):
	if env_name in gym_envs: return gym.make(env_name)
	reps = ["pixels", "pixels_gray", "extracted", "simple115"]
	env = ggym.create_environment(env_name=env_name, representation=reps[3], logdir='/football/logs/', render=False)
	env.spec = gym.envs.registration.EnvSpec(env_name + "-v0", max_episode_steps=env.unwrapped._config._scenario_cfg.game_duration)
	if log: print(f"State space: {env.observation_space.shape} \nAction space: {env.action_space.n}")
	return env

class PixelAgent(RandomAgent):
	def __init__(self, state_size, action_size, num_envs, agent, load="", gpu=True, train=True):
		super().__init__(state_size, action_size)
		statemodel = RawStack if len(state_size) == 1 else ImgStack
		self.stack = statemodel(state_size, num_envs, load=load, gpu=gpu)
		self.agent = agent(self.stack.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state = self.stack.get_state(state)
		env_action, action = self.agent.get_env_action(env, state, eps, sample)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.stack.get_state(next_state)
		self.agent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.stack.num_envs if num_envs is None else num_envs
		self.stack.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		if hasattr(self.agent, "network"): self.agent.network.save_model(dirname, name)

def run(model, steps=10000, ports=16, eval_at=1000):
	num_envs = len(ports) if type(ports) == list else min(ports, 64)
	logger = Logger(model, env_name, num_envs=num_envs)
	envs = EnvManager(make_env, ports) if type(ports) == list else EnsembleEnv(make_env, ports)
	agent = PixelAgent(envs.state_size, envs.action_size, num_envs, model)
	states = envs.reset()
	total_rewards = []
	for s in range(steps):
		agent.reset(num_envs)
		env_actions, actions, states = agent.get_env_action(envs.env, states)
		next_states, rewards, dones, _ = envs.step(env_actions)
		agent.train(states, actions, next_states, rewards, dones)
		states = next_states
		if dones[0] or s+1 % envs.env.spec.max_episode_steps == 0:
			rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(5)]
			test_reward = np.mean(rollouts) - np.std(rollouts)
			total_rewards.append(test_reward)
			agent.save_model(env_name, "checkpoint")
			if env_name in gfb_envs and total_rewards[-1] >= max(total_rewards): agent.save_model(env_name)
			logger.log(f"Step: {s}, Reward: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.agent.eps:.3f})")

if __name__ == "__main__":
	model = DDPGAgent if args.model == "ddpg" else PPOAgent if args.model == "ppo" else DDQNAgent if args.model == "ddqn" else RandomAgent
	if args.selfport is not None:
		EnvWorker(args.selfport, make_env).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, args.steps, args.workerports)
	print(f"Training finished")

Step: 199, Reward: -200.0000 [0.00], Avg: -200.0000 (0.990)
Step: 399, Reward: -200.0000 [0.00], Avg: -200.0000 (0.980)
Step: 599, Reward: -200.0000 [0.00], Avg: -200.0000 (0.970)
Step: 799, Reward: -200.0000 [0.00], Avg: -200.0000 (0.961)
Step: 999, Reward: -200.0000 [0.00], Avg: -200.0000 (0.951)
Step: 1199, Reward: -200.0000 [0.00], Avg: -200.0000 (0.941)
Step: 1399, Reward: -200.0000 [0.00], Avg: -200.0000 (0.932)
Step: 1599, Reward: -200.0000 [0.00], Avg: -200.0000 (0.923)
Step: 1799, Reward: -200.0000 [0.00], Avg: -200.0000 (0.914)
Step: 1999, Reward: -200.0000 [0.00], Avg: -200.0000 (0.904)
Step: 2199, Reward: -200.0000 [0.00], Avg: -200.0000 (0.895)
Step: 2399, Reward: -200.0000 [0.00], Avg: -200.0000 (0.886)
Step: 2599, Reward: -200.0000 [0.00], Avg: -200.0000 (0.878)
Step: 2799, Reward: -200.0000 [0.00], Avg: -200.0000 (0.869)
Step: 2999, Reward: -200.0000 [0.00], Avg: -200.0000 (0.860)
Step: 3199, Reward: -200.0000 [0.00], Avg: -200.0000 (0.851)
Step: 3399, Reward: -200.0000 [0.00], Avg: -200.0000 (0.843)
Step: 3599, Reward: -200.0000 [0.00], Avg: -200.0000 (0.835)
Step: 3799, Reward: -200.0000 [0.00], Avg: -200.0000 (0.826)
Step: 3999, Reward: -200.0000 [0.00], Avg: -200.0000 (0.818)
Step: 4199, Reward: -200.0000 [0.00], Avg: -200.0000 (0.810)
Step: 4399, Reward: -200.0000 [0.00], Avg: -200.0000 (0.802)
Step: 4599, Reward: -200.0000 [0.00], Avg: -200.0000 (0.794)
Step: 4799, Reward: -200.0000 [0.00], Avg: -200.0000 (0.786)
Step: 4999, Reward: -200.0000 [0.00], Avg: -200.0000 (0.778)
Step: 5199, Reward: -200.0000 [0.00], Avg: -200.0000 (0.770)
Step: 5341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.762)
Step: 5541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.755)
Step: 5741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.747)
Step: 5941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.740)
Step: 6141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.732)
Step: 6341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.725)
Step: 6541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.718)
Step: 6741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.711)
Step: 6941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.703)
Step: 7141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.696)
Step: 7341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.689)
Step: 7541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.683)
Step: 7741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.676)
Step: 7941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.669)
Step: 8141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.662)
Step: 8341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.656)
Step: 8541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.649)
Step: 8741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.643)
Step: 8941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.636)
Step: 9141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.630)
Step: 9341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.624)
Step: 9541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.617)
Step: 9741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.611)
Step: 9941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.605)
Step: 10141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.599)
Step: 10341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.593)
Step: 10541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.587)
Step: 10741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.581)
Step: 10941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.575)
Step: 11141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.570)
Step: 11341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.564)
Step: 11541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.558)
Step: 11741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.553)
Step: 11941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.547)
Step: 12141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.542)
Step: 12341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.536)
Step: 12541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.531)
Step: 12741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.526)
Step: 12941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.520)
Step: 13141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.515)
Step: 13341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.510)
Step: 13541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.505)
Step: 13741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.500)
Step: 13941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.495)
Step: 14141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.490)
Step: 14341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.485)
Step: 14541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.480)
Step: 14741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.475)
Step: 14941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.471)
Step: 15141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.466)
Step: 15341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.461)
Step: 15541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.457)
Step: 15741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.452)
Step: 15941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.448)
Step: 16141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.443)
Step: 16341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.439)
Step: 16541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.434)
Step: 16741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.430)
Step: 16941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.426)
Step: 17141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.421)
Step: 17341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.417)
Step: 17541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.413)
Step: 17741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.409)
Step: 17941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.405)
Step: 18141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.401)
Step: 18341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.397)
Step: 18541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.393)
Step: 18741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.389)
Step: 18941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.385)
Step: 19141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.381)
Step: 19341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.377)
Step: 19541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.373)
Step: 19741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.370)
Step: 19941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.366)
Step: 20141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.362)
Step: 20341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.359)
Step: 20541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.355)
Step: 20741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.352)
Step: 20941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.348)
Step: 21141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.345)
Step: 21341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.341)
Step: 21541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.338)
Step: 21741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.334)
Step: 21941, Reward: -200.0000 [0.00], Avg: -200.0000 (0.331)
Step: 22141, Reward: -200.0000 [0.00], Avg: -200.0000 (0.328)
Step: 22341, Reward: -200.0000 [0.00], Avg: -200.0000 (0.324)
Step: 22541, Reward: -200.0000 [0.00], Avg: -200.0000 (0.321)
Step: 22741, Reward: -200.0000 [0.00], Avg: -200.0000 (0.318)
Step: 22931, Reward: -200.0000 [0.00], Avg: -200.0000 (0.315)
Step: 23131, Reward: -200.0000 [0.00], Avg: -200.0000 (0.312)
Step: 23331, Reward: -200.0000 [0.00], Avg: -200.0000 (0.309)
Step: 23531, Reward: -200.0000 [0.00], Avg: -200.0000 (0.305)
Step: 23731, Reward: -200.0000 [0.00], Avg: -200.0000 (0.302)
Step: 23931, Reward: -200.0000 [0.00], Avg: -200.0000 (0.299)
Step: 24131, Reward: -200.0000 [0.00], Avg: -200.0000 (0.296)
Step: 24331, Reward: -200.0000 [0.00], Avg: -200.0000 (0.293)
Step: 24531, Reward: -200.0000 [0.00], Avg: -200.0000 (0.290)
Step: 24731, Reward: -200.0000 [0.00], Avg: -200.0000 (0.288)
Step: 24931, Reward: -200.0000 [0.00], Avg: -200.0000 (0.285)
Step: 25131, Reward: -200.0000 [0.00], Avg: -200.0000 (0.282)
Step: 25331, Reward: -200.0000 [0.00], Avg: -200.0000 (0.279)
Step: 25531, Reward: -200.0000 [0.00], Avg: -200.0000 (0.276)
Step: 25731, Reward: -200.0000 [0.00], Avg: -200.0000 (0.273)
Step: 25931, Reward: -200.0000 [0.00], Avg: -200.0000 (0.271)
Step: 26131, Reward: -200.0000 [0.00], Avg: -200.0000 (0.268)
Step: 26331, Reward: -200.0000 [0.00], Avg: -200.0000 (0.265)
Step: 26531, Reward: -200.0000 [0.00], Avg: -200.0000 (0.263)
Step: 26731, Reward: -200.0000 [0.00], Avg: -200.0000 (0.260)
Step: 26931, Reward: -200.0000 [0.00], Avg: -200.0000 (0.257)
Step: 27131, Reward: -200.0000 [0.00], Avg: -200.0000 (0.255)
Step: 27331, Reward: -200.0000 [0.00], Avg: -200.0000 (0.252)
Step: 27531, Reward: -200.0000 [0.00], Avg: -200.0000 (0.250)
Step: 27731, Reward: -200.0000 [0.00], Avg: -200.0000 (0.247)
Step: 27931, Reward: -200.0000 [0.00], Avg: -200.0000 (0.245)
Step: 28131, Reward: -200.0000 [0.00], Avg: -200.0000 (0.242)
Step: 28331, Reward: -200.0000 [0.00], Avg: -200.0000 (0.240)
Step: 28531, Reward: -200.0000 [0.00], Avg: -200.0000 (0.238)
Step: 28731, Reward: -200.0000 [0.00], Avg: -200.0000 (0.235)
Step: 28931, Reward: -200.0000 [0.00], Avg: -200.0000 (0.233)
Step: 29131, Reward: -200.0000 [0.00], Avg: -200.0000 (0.231)
Step: 29331, Reward: -200.0000 [0.00], Avg: -200.0000 (0.228)
Step: 29531, Reward: -200.0000 [0.00], Avg: -200.0000 (0.226)
Step: 29731, Reward: -200.0000 [0.00], Avg: -200.0000 (0.224)
Step: 29931, Reward: -200.0000 [0.00], Avg: -200.0000 (0.221)
Step: 30131, Reward: -200.0000 [0.00], Avg: -200.0000 (0.219)
Step: 30331, Reward: -200.0000 [0.00], Avg: -200.0000 (0.217)
Step: 30531, Reward: -200.0000 [0.00], Avg: -200.0000 (0.215)
Step: 30731, Reward: -200.0000 [0.00], Avg: -200.0000 (0.213)
Step: 30918, Reward: -200.0000 [0.00], Avg: -200.0000 (0.211)
Step: 31118, Reward: -183.6000 [20.13], Avg: -200.0239 (0.208)
Step: 31318, Reward: -200.0000 [0.00], Avg: -200.0237 (0.206)
Step: 31518, Reward: -200.0000 [0.00], Avg: -200.0236 (0.204)
Step: 31718, Reward: -200.0000 [0.00], Avg: -200.0234 (0.202)
Step: 31918, Reward: -200.0000 [0.00], Avg: -200.0233 (0.200)
Step: 32118, Reward: -200.0000 [0.00], Avg: -200.0231 (0.198)
Step: 32318, Reward: -200.0000 [0.00], Avg: -200.0230 (0.196)
Step: 32518, Reward: -200.0000 [0.00], Avg: -200.0229 (0.194)
Step: 32718, Reward: -200.0000 [0.00], Avg: -200.0227 (0.192)
Step: 32918, Reward: -200.0000 [0.00], Avg: -200.0226 (0.190)
Step: 33118, Reward: -200.0000 [0.00], Avg: -200.0224 (0.189)
Step: 33318, Reward: -200.0000 [0.00], Avg: -200.0223 (0.187)
Step: 33497, Reward: -200.0000 [0.00], Avg: -200.0222 (0.185)
Step: 33697, Reward: -200.0000 [0.00], Avg: -200.0220 (0.183)
Step: 33897, Reward: -200.0000 [0.00], Avg: -200.0219 (0.181)
Step: 34097, Reward: -200.0000 [0.00], Avg: -200.0218 (0.179)
Step: 34297, Reward: -200.0000 [0.00], Avg: -200.0217 (0.178)
Step: 34497, Reward: -200.0000 [0.00], Avg: -200.0215 (0.176)
Step: 34697, Reward: -200.0000 [0.00], Avg: -200.0214 (0.174)
Step: 34897, Reward: -200.0000 [0.00], Avg: -200.0213 (0.172)
Step: 35097, Reward: -200.0000 [0.00], Avg: -200.0212 (0.171)
Step: 35297, Reward: -200.0000 [0.00], Avg: -200.0210 (0.169)
Step: 35497, Reward: -200.0000 [0.00], Avg: -200.0209 (0.167)
Step: 35697, Reward: -200.0000 [0.00], Avg: -200.0208 (0.165)
Step: 35897, Reward: -200.0000 [0.00], Avg: -200.0207 (0.164)
Step: 36097, Reward: -200.0000 [0.00], Avg: -200.0206 (0.162)
Step: 36297, Reward: -195.8000 [8.40], Avg: -200.0435 (0.161)
Step: 36497, Reward: -200.0000 [0.00], Avg: -200.0433 (0.159)
Step: 36697, Reward: -200.0000 [0.00], Avg: -200.0431 (0.157)
Step: 36897, Reward: -200.0000 [0.00], Avg: -200.0428 (0.156)
Step: 37097, Reward: -200.0000 [0.00], Avg: -200.0426 (0.154)
Step: 37297, Reward: -200.0000 [0.00], Avg: -200.0424 (0.153)
Step: 37497, Reward: -200.0000 [0.00], Avg: -200.0422 (0.151)
Step: 37697, Reward: -189.8000 [20.40], Avg: -200.0959 (0.150)
Step: 37897, Reward: -200.0000 [0.00], Avg: -200.0954 (0.148)
Step: 38097, Reward: -200.0000 [0.00], Avg: -200.0949 (0.147)
Step: 38297, Reward: -198.6000 [2.80], Avg: -200.1017 (0.145)
Step: 38497, Reward: -200.0000 [0.00], Avg: -200.1012 (0.144)
Step: 38697, Reward: -200.0000 [0.00], Avg: -200.1006 (0.142)
Step: 38897, Reward: -200.0000 [0.00], Avg: -200.1001 (0.141)
Step: 39097, Reward: -200.0000 [0.00], Avg: -200.0996 (0.139)
Step: 39297, Reward: -200.0000 [0.00], Avg: -200.0991 (0.138)
Step: 39447, Reward: -200.0000 [0.00], Avg: -200.0986 (0.137)
Step: 39647, Reward: -200.0000 [0.00], Avg: -200.0981 (0.135)
Step: 39808, Reward: -200.0000 [0.00], Avg: -200.0976 (0.134)
Step: 40008, Reward: -200.0000 [0.00], Avg: -200.0971 (0.133)
Step: 40208, Reward: -200.0000 [0.00], Avg: -200.0967 (0.131)
Step: 40408, Reward: -200.0000 [0.00], Avg: -200.0962 (0.130)
Step: 40608, Reward: -200.0000 [0.00], Avg: -200.0957 (0.129)
Step: 40808, Reward: -200.0000 [0.00], Avg: -200.0952 (0.127)
Step: 41008, Reward: -200.0000 [0.00], Avg: -200.0948 (0.126)
Step: 41208, Reward: -195.6000 [8.80], Avg: -200.1156 (0.125)
Step: 41408, Reward: -200.0000 [0.00], Avg: -200.1150 (0.124)
Step: 41608, Reward: -200.0000 [0.00], Avg: -200.1145 (0.122)
Step: 41808, Reward: -200.0000 [0.00], Avg: -200.1139 (0.121)
Step: 42008, Reward: -200.0000 [0.00], Avg: -200.1134 (0.120)
Step: 42208, Reward: -200.0000 [0.00], Avg: -200.1129 (0.119)
Step: 42408, Reward: -200.0000 [0.00], Avg: -200.1123 (0.118)
Step: 42608, Reward: -200.0000 [0.00], Avg: -200.1118 (0.116)
Step: 42808, Reward: -200.0000 [0.00], Avg: -200.1113 (0.115)
Step: 43008, Reward: -200.0000 [0.00], Avg: -200.1108 (0.114)
Step: 43208, Reward: -200.0000 [0.00], Avg: -200.1103 (0.113)
Step: 43408, Reward: -200.0000 [0.00], Avg: -200.1098 (0.112)
Step: 43608, Reward: -200.0000 [0.00], Avg: -200.1092 (0.111)
Step: 43808, Reward: -200.0000 [0.00], Avg: -200.1088 (0.110)
Step: 44008, Reward: -200.0000 [0.00], Avg: -200.1083 (0.108)
Step: 44203, Reward: -197.8000 [4.40], Avg: -200.1177 (0.107)
Step: 44403, Reward: -200.0000 [0.00], Avg: -200.1172 (0.106)
Step: 44603, Reward: -200.0000 [0.00], Avg: -200.1166 (0.105)
Step: 44803, Reward: -200.0000 [0.00], Avg: -200.1161 (0.104)
Step: 45003, Reward: -191.2000 [7.25], Avg: -200.1087 (0.103)
Step: 45198, Reward: -200.0000 [0.00], Avg: -200.1083 (0.102)
Step: 45398, Reward: -200.0000 [0.00], Avg: -200.1078 (0.101)
Step: 45598, Reward: -200.0000 [0.00], Avg: -200.1073 (0.100)
Step: 45798, Reward: -200.0000 [0.00], Avg: -200.1068 (0.099)
Step: 45998, Reward: -200.0000 [0.00], Avg: -200.1064 (0.098)
Step: 46198, Reward: -197.6000 [4.80], Avg: -200.1163 (0.097)
Step: 46398, Reward: -199.4000 [1.20], Avg: -200.1183 (0.096)
Step: 46598, Reward: -200.0000 [0.00], Avg: -200.1178 (0.095)
Step: 46788, Reward: -200.0000 [0.00], Avg: -200.1173 (0.094)
Step: 46988, Reward: -193.6000 [5.39], Avg: -200.1126 (0.093)
Step: 47166, Reward: -191.6000 [16.80], Avg: -200.1475 (0.092)
Step: 47366, Reward: -200.0000 [0.00], Avg: -200.1469 (0.091)
Step: 47566, Reward: -200.0000 [0.00], Avg: -200.1463 (0.091)
Step: 47766, Reward: -191.6000 [16.80], Avg: -200.1807 (0.090)
Step: 47966, Reward: -200.0000 [0.00], Avg: -200.1799 (0.089)
Step: 48166, Reward: -200.0000 [0.00], Avg: -200.1792 (0.088)
Step: 48366, Reward: -197.2000 [5.60], Avg: -200.1900 (0.087)
Step: 48566, Reward: -179.2000 [25.48], Avg: -200.2084 (0.086)
Step: 48766, Reward: -200.0000 [0.00], Avg: -200.2075 (0.085)
Step: 48966, Reward: -185.0000 [7.97], Avg: -200.1781 (0.084)
Step: 49166, Reward: -190.4000 [19.20], Avg: -200.2163 (0.084)
Step: 49366, Reward: -200.0000 [0.00], Avg: -200.2154 (0.083)
Step: 49566, Reward: -153.4000 [12.27], Avg: -200.0767 (0.082)
Step: 49766, Reward: -181.8000 [22.29], Avg: -200.0928 (0.081)
Step: 49966, Reward: -200.0000 [0.00], Avg: -200.0924 (0.080)
Step: 50118, Reward: -190.6000 [5.00], Avg: -200.0746 (0.079)
Step: 50287, Reward: -157.6000 [21.25], Avg: -199.9907 (0.079)
Step: 50487, Reward: -174.4000 [3.67], Avg: -199.9044 (0.078)
Step: 50687, Reward: -161.8000 [17.10], Avg: -199.8220 (0.077)
Step: 50884, Reward: -159.0000 [20.52], Avg: -199.7427 (0.076)
Step: 51084, Reward: -161.6000 [21.45], Avg: -199.6778 (0.076)
Step: 51262, Reward: -166.8000 [27.23], Avg: -199.6559 (0.075)
Step: 51462, Reward: -176.0000 [6.29], Avg: -199.5888 (0.074)
Step: 51651, Reward: -180.4000 [20.26], Avg: -199.5930 (0.073)
Step: 51851, Reward: -186.6000 [8.57], Avg: -199.5760 (0.073)
Step: 52016, Reward: -178.2000 [19.33], Avg: -199.5682 (0.072)
Step: 52216, Reward: -198.0000 [4.00], Avg: -199.5775 (0.071)
Step: 52377, Reward: -174.2000 [18.87], Avg: -199.5528 (0.070)
Step: 52532, Reward: -160.0000 [16.77], Avg: -199.4668 (0.070)
Step: 52678, Reward: -181.0000 [18.83], Avg: -199.4682 (0.069)
Step: 52830, Reward: -178.0000 [18.42], Avg: -199.4568 (0.068)
Step: 52982, Reward: -161.6000 [23.28], Avg: -199.4024 (0.068)
Step: 53136, Reward: -173.0000 [22.61], Avg: -199.3883 (0.067)
Step: 53320, Reward: -164.2000 [15.61], Avg: -199.3158 (0.066)
Step: 53480, Reward: -156.0000 [20.60], Avg: -199.2320 (0.066)
Step: 53636, Reward: -155.6000 [3.50], Avg: -199.0844 (0.065)
Step: 53783, Reward: -194.4000 [5.75], Avg: -199.0883 (0.064)
Step: 53956, Reward: -200.0000 [0.00], Avg: -199.0916 (0.064)
Step: 54105, Reward: -148.0000 [3.90], Avg: -198.9200 (0.063)
Step: 54305, Reward: -149.2000 [3.31], Avg: -198.7519 (0.062)
Step: 54454, Reward: -191.2000 [17.60], Avg: -198.7881 (0.062)
Step: 54607, Reward: -148.2000 [1.94], Avg: -198.6131 (0.061)
Step: 54754, Reward: -179.0000 [17.16], Avg: -198.6043 (0.061)
Step: 54904, Reward: -154.8000 [3.31], Avg: -198.4597 (0.060)
Step: 55025, Reward: -193.4000 [13.20], Avg: -198.4887 (0.059)
Step: 55179, Reward: -200.0000 [0.00], Avg: -198.4941 (0.059)
Step: 55379, Reward: -148.8000 [2.71], Avg: -198.3280 (0.058)
Step: 55520, Reward: -145.0000 [3.41], Avg: -198.1523 (0.058)
Step: 55660, Reward: -147.6000 [0.49], Avg: -197.9766 (0.057)
Step: 55787, Reward: -145.6000 [4.32], Avg: -197.8086 (0.056)
Step: 55937, Reward: -151.4000 [2.42], Avg: -197.6553 (0.056)
Step: 56079, Reward: -151.6000 [1.85], Avg: -197.5018 (0.055)
Step: 56236, Reward: -149.0000 [4.05], Avg: -197.3480 (0.055)
Step: 56384, Reward: -159.6000 [20.36], Avg: -197.2880 (0.054)
Step: 56533, Reward: -147.6000 [28.29], Avg: -197.2145 (0.054)
Step: 56688, Reward: -149.2000 [2.40], Avg: -197.0583 (0.053)
Step: 56824, Reward: -146.6000 [5.08], Avg: -196.9034 (0.053)
Step: 56985, Reward: -144.0000 [1.79], Avg: -196.7296 (0.052)
Step: 57185, Reward: -145.4000 [2.87], Avg: -196.5653 (0.052)
Step: 57320, Reward: -139.6000 [17.30], Avg: -196.4313 (0.051)
Step: 57472, Reward: -162.4000 [18.81], Avg: -196.3801 (0.051)
Step: 57613, Reward: -171.8000 [23.05], Avg: -196.3749 (0.050)
Step: 57767, Reward: -149.2000 [0.98], Avg: -196.2204 (0.050)
Step: 57924, Reward: -153.6000 [1.85], Avg: -196.0845 (0.049)
Step: 58059, Reward: -154.2000 [1.72], Avg: -195.9511 (0.049)
Step: 58211, Reward: -140.6000 [13.60], Avg: -195.8129 (0.048)
Step: 58411, Reward: -182.6000 [21.33], Avg: -195.8397 (0.048)
Step: 58556, Reward: -180.0000 [40.00], Avg: -195.9191 (0.047)
Step: 58713, Reward: -145.6000 [5.20], Avg: -195.7712 (0.047)
Step: 58864, Reward: -154.4000 [4.08], Avg: -195.6493 (0.046)
Step: 59010, Reward: -123.6000 [12.22], Avg: -195.4545 (0.046)
Step: 59166, Reward: -150.0000 [26.77], Avg: -195.3938 (0.045)
Step: 59344, Reward: -147.2000 [1.60], Avg: -195.2430 (0.045)
Step: 59481, Reward: -145.6000 [5.24], Avg: -195.0998 (0.044)
Step: 59634, Reward: -152.4000 [7.14], Avg: -194.9855 (0.044)
Step: 59808, Reward: -160.2000 [20.01], Avg: -194.9381 (0.043)
Step: 59947, Reward: -146.6000 [2.58], Avg: -194.7919 (0.043)
Step: 60082, Reward: -148.0000 [1.26], Avg: -194.6469 (0.043)
Step: 60226, Reward: -142.6000 [3.67], Avg: -194.4933 (0.042)
Step: 60380, Reward: -138.8000 [9.30], Avg: -194.3465 (0.042)
Step: 60490, Reward: -148.4000 [8.04], Avg: -194.2270 (0.041)
Step: 60630, Reward: -178.2000 [33.57], Avg: -194.2821 (0.041)
Step: 60788, Reward: -161.6000 [15.86], Avg: -194.2294 (0.041)
Step: 60929, Reward: -158.4000 [20.92], Avg: -194.1828 (0.040)
Step: 61086, Reward: -146.4000 [6.37], Avg: -194.0538 (0.040)
Step: 61224, Reward: -146.2000 [1.60], Avg: -193.9102 (0.039)
Step: 61370, Reward: -142.0000 [2.19], Avg: -193.7562 (0.039)
Step: 61504, Reward: -138.6000 [2.87], Avg: -193.5949 (0.039)
Step: 61642, Reward: -138.6000 [3.01], Avg: -193.4349 (0.038)
Step: 61781, Reward: -140.6000 [31.56], Avg: -193.3696 (0.038)
Step: 61894, Reward: -140.6000 [32.52], Avg: -193.3077 (0.037)
Step: 62070, Reward: -140.8000 [5.49], Avg: -193.1644 (0.037)
Step: 62267, Reward: -142.2000 [2.79], Avg: -193.0179 (0.037)
Step: 62404, Reward: -157.6000 [22.06], Avg: -192.9774 (0.036)
Step: 62545, Reward: -137.2000 [10.91], Avg: -192.8419 (0.036)
Step: 62688, Reward: -146.0000 [2.61], Avg: -192.7087 (0.036)
Step: 62825, Reward: -152.2000 [24.08], Avg: -192.6593 (0.035)
Step: 62968, Reward: -141.6000 [3.83], Avg: -192.5179 (0.035)
Step: 63105, Reward: -144.8000 [4.79], Avg: -192.3898 (0.034)
Step: 63247, Reward: -139.6000 [1.36], Avg: -192.2367 (0.034)
Step: 63359, Reward: -152.2000 [23.92], Avg: -192.1889 (0.034)
Step: 63502, Reward: -140.0000 [1.79], Avg: -192.0397 (0.033)
Step: 63643, Reward: -155.0000 [22.85], Avg: -191.9979 (0.033)
Step: 63770, Reward: -184.0000 [32.00], Avg: -192.0685 (0.033)
Step: 63882, Reward: -138.6000 [2.65], Avg: -191.9195 (0.032)
Step: 64019, Reward: -123.2000 [11.05], Avg: -191.7508 (0.032)
Step: 64163, Reward: -146.6000 [28.81], Avg: -191.7032 (0.032)
Step: 64285, Reward: -139.6000 [2.33], Avg: -191.5585 (0.032)
Step: 64430, Reward: -138.0000 [2.61], Avg: -191.4108 (0.031)
Step: 64577, Reward: -155.6000 [22.82], Avg: -191.3733 (0.031)
Step: 64761, Reward: -124.2000 [10.76], Avg: -191.2107 (0.031)
Step: 64922, Reward: -139.8000 [1.60], Avg: -191.0676 (0.030)
Step: 65063, Reward: -133.0000 [9.59], Avg: -190.9287 (0.030)
Step: 65200, Reward: -123.6000 [5.85], Avg: -190.7530 (0.030)
Step: 65311, Reward: -138.8000 [13.76], Avg: -190.6442 (0.029)
Step: 65511, Reward: -150.0000 [41.14], Avg: -190.6456 (0.029)
Step: 65651, Reward: -174.6000 [27.05], Avg: -190.6768 (0.029)
Step: 65792, Reward: -140.6000 [2.94], Avg: -190.5436 (0.029)
Step: 65948, Reward: -115.0000 [18.19], Avg: -190.3821 (0.028)
Step: 66076, Reward: -118.0000 [10.06], Avg: -190.2070 (0.028)
Step: 66232, Reward: -115.4000 [3.01], Avg: -190.0059 (0.028)
Step: 66366, Reward: -135.8000 [18.44], Avg: -189.9060 (0.027)
Step: 66523, Reward: -121.0000 [11.97], Avg: -189.7474 (0.027)
Step: 66636, Reward: -138.8000 [4.26], Avg: -189.6177 (0.027)
Step: 66771, Reward: -137.8000 [12.89], Avg: -189.5099 (0.027)
Step: 66912, Reward: -200.0000 [0.00], Avg: -189.5389 (0.026)
Step: 67027, Reward: -117.2000 [12.42], Avg: -189.3738 (0.026)
Step: 67163, Reward: -133.4000 [33.48], Avg: -189.3120 (0.026)
Step: 67274, Reward: -125.2000 [19.50], Avg: -189.1897 (0.026)
Step: 67402, Reward: -113.6000 [2.15], Avg: -188.9891 (0.025)
Step: 67520, Reward: -114.2000 [2.48], Avg: -188.7921 (0.025)
Step: 67640, Reward: -118.8000 [3.66], Avg: -188.6118 (0.025)
Step: 67753, Reward: -108.6000 [4.84], Avg: -188.4081 (0.025)
Step: 67879, Reward: -119.6000 [19.02], Avg: -188.2735 (0.024)
Step: 67989, Reward: -165.8000 [28.20], Avg: -188.2890 (0.024)
Step: 68101, Reward: -117.6000 [2.58], Avg: -188.1059 (0.024)
Step: 68270, Reward: -114.8000 [2.48], Avg: -187.9160 (0.024)
Step: 68381, Reward: -141.8000 [31.04], Avg: -187.8757 (0.023)
Step: 68530, Reward: -137.8000 [31.22], Avg: -187.8254 (0.023)
Step: 68640, Reward: -111.8000 [3.71], Avg: -187.6331 (0.023)
Step: 68751, Reward: -103.0000 [9.57], Avg: -187.4340 (0.023)
Step: 68881, Reward: -111.0000 [0.89], Avg: -187.2342 (0.022)
Step: 68992, Reward: -112.4000 [1.74], Avg: -187.0413 (0.022)
Step: 69088, Reward: -117.0000 [2.00], Avg: -186.8622 (0.022)
Step: 69201, Reward: -113.0000 [1.90], Avg: -186.6734 (0.022)
Step: 69318, Reward: -126.8000 [21.23], Avg: -186.5722 (0.022)
Step: 69463, Reward: -113.4000 [3.01], Avg: -186.3890 (0.021)
Step: 69573, Reward: -109.6000 [4.50], Avg: -186.2007 (0.021)
Step: 69682, Reward: -109.8000 [0.40], Avg: -186.0033 (0.021)
Step: 69792, Reward: -111.8000 [1.83], Avg: -185.8158 (0.021)
Step: 69902, Reward: -116.0000 [12.02], Avg: -185.6665 (0.020)
Step: 70040, Reward: -113.4000 [2.42], Avg: -185.4865 (0.020)
Step: 70131, Reward: -116.2000 [2.71], Avg: -185.3153 (0.020)
Step: 70300, Reward: -104.6000 [6.83], Avg: -185.1259 (0.020)
Step: 70409, Reward: -110.0000 [1.10], Avg: -184.9365 (0.020)
Step: 70502, Reward: -112.6000 [21.53], Avg: -184.8069 (0.020)
Step: 70611, Reward: -110.4000 [1.74], Avg: -184.6220 (0.020)
Step: 70720, Reward: -104.4000 [7.74], Avg: -184.4381 (0.020)
Step: 70914, Reward: -123.2000 [20.45], Avg: -184.3348 (0.020)
Step: 71022, Reward: -107.6000 [3.14], Avg: -184.1489 (0.020)
Step: 71134, Reward: -106.0000 [5.02], Avg: -183.9647 (0.020)
Step: 71256, Reward: -109.6000 [1.20], Avg: -183.7809 (0.020)
Step: 71365, Reward: -108.4000 [1.50], Avg: -183.5957 (0.020)
Step: 71459, Reward: -118.4000 [21.44], Avg: -183.4863 (0.020)
Step: 71562, Reward: -102.6000 [8.66], Avg: -183.3062 (0.020)
Step: 71655, Reward: -105.4000 [5.78], Avg: -183.1268 (0.020)
Step: 71767, Reward: -116.0000 [14.52], Avg: -182.9963 (0.020)
Step: 71875, Reward: -103.8000 [7.03], Avg: -182.8176 (0.020)
Step: 71983, Reward: -108.2000 [1.47], Avg: -182.6370 (0.020)
Step: 72093, Reward: -116.0000 [15.53], Avg: -182.5112 (0.020)
Step: 72195, Reward: -116.6000 [17.27], Avg: -182.3916 (0.020)
Step: 72290, Reward: -112.0000 [24.92], Avg: -182.2802 (0.020)
Step: 72401, Reward: -106.8000 [0.40], Avg: -182.0966 (0.020)
Step: 72493, Reward: -99.8000 [8.13], Avg: -181.9157 (0.020)
Step: 72604, Reward: -103.8000 [7.05], Avg: -181.7428 (0.020)
Step: 72692, Reward: -107.8000 [0.98], Avg: -181.5658 (0.020)
Step: 72802, Reward: -104.0000 [6.60], Avg: -181.3939 (0.020)
Step: 72909, Reward: -104.4000 [6.89], Avg: -181.2246 (0.020)
Step: 73014, Reward: -112.8000 [16.64], Avg: -181.0998 (0.020)
Step: 73154, Reward: -129.6000 [16.91], Avg: -181.0167 (0.020)
Step: 73261, Reward: -103.6000 [7.91], Avg: -180.8500 (0.020)
Step: 73368, Reward: -176.6000 [31.72], Avg: -180.9157 (0.020)
Step: 73514, Reward: -104.8000 [6.49], Avg: -180.7495 (0.020)
Step: 73620, Reward: -106.6000 [0.49], Avg: -180.5742 (0.020)
Step: 73728, Reward: -125.2000 [16.52], Avg: -180.4819 (0.020)
Step: 73845, Reward: -146.2000 [32.43], Avg: -180.4775 (0.020)
Step: 73967, Reward: -98.0000 [7.07], Avg: -180.2992 (0.020)
Step: 74074, Reward: -103.4000 [6.28], Avg: -180.1327 (0.020)
Step: 74186, Reward: -106.4000 [1.02], Avg: -179.9616 (0.020)
Step: 74295, Reward: -104.4000 [5.24], Avg: -179.7965 (0.020)
Step: 74391, Reward: -107.6000 [4.22], Avg: -179.6373 (0.020)
Step: 74497, Reward: -103.2000 [2.99], Avg: -179.4657 (0.020)
Step: 74605, Reward: -107.2000 [0.40], Avg: -179.2982 (0.020)
Step: 74712, Reward: -105.0000 [1.26], Avg: -179.1284 (0.020)
Step: 74820, Reward: -103.2000 [6.62], Avg: -178.9675 (0.020)
Step: 74928, Reward: -114.2000 [18.97], Avg: -178.8615 (0.020)
Step: 75037, Reward: -96.0000 [8.51], Avg: -178.6898 (0.020)
Step: 75147, Reward: -96.8000 [7.36], Avg: -178.5181 (0.020)
Step: 75245, Reward: -102.4000 [7.74], Avg: -178.3609 (0.020)
Step: 75353, Reward: -103.4000 [7.20], Avg: -178.2055 (0.020)
Step: 75462, Reward: -103.2000 [6.85], Avg: -178.0495 (0.020)
Step: 75568, Reward: -106.2000 [0.75], Avg: -177.8872 (0.020)
Step: 75676, Reward: -99.0000 [8.65], Avg: -177.7272 (0.020)
Step: 75783, Reward: -99.0000 [9.84], Avg: -177.5706 (0.020)
Step: 75891, Reward: -106.2000 [1.17], Avg: -177.4114 (0.020)
Step: 75997, Reward: -102.4000 [7.71], Avg: -177.2591 (0.020)
Step: 76083, Reward: -102.8000 [7.03], Avg: -177.1069 (0.020)
Step: 76188, Reward: -104.8000 [3.76], Avg: -176.9525 (0.020)
Step: 76295, Reward: -104.2000 [1.47], Avg: -176.7924 (0.020)
Step: 76402, Reward: -105.4000 [2.80], Avg: -176.6386 (0.020)
Step: 76510, Reward: -103.2000 [6.73], Avg: -176.4893 (0.020)
Step: 76617, Reward: -99.2000 [8.33], Avg: -176.3354 (0.020)
Step: 76723, Reward: -100.2000 [7.55], Avg: -176.1827 (0.020)
Step: 76828, Reward: -102.0000 [8.51], Avg: -176.0367 (0.020)
Step: 76935, Reward: -105.8000 [1.94], Avg: -175.8853 (0.020)
Step: 77025, Reward: -106.6000 [1.85], Avg: -175.7361 (0.020)
Step: 77132, Reward: -99.0000 [9.06], Avg: -175.5867 (0.020)
Step: 77218, Reward: -115.8000 [15.69], Avg: -175.4896 (0.020)
Step: 77324, Reward: -105.0000 [2.28], Avg: -175.3396 (0.020)
Step: 77429, Reward: -103.2000 [9.62], Avg: -175.2025 (0.020)
Step: 77536, Reward: -114.0000 [17.50], Avg: -175.1069 (0.020)
Step: 77621, Reward: -105.6000 [1.50], Avg: -174.9584 (0.020)
Step: 77727, Reward: -93.4000 [3.88], Avg: -174.7892 (0.020)
Step: 77833, Reward: -102.4000 [8.73], Avg: -174.6508 (0.020)
Step: 77940, Reward: -103.2000 [8.70], Avg: -174.5147 (0.020)
Step: 78046, Reward: -99.4000 [7.28], Avg: -174.3679 (0.020)
Step: 78152, Reward: -105.2000 [1.33], Avg: -174.2213 (0.020)
Step: 78259, Reward: -104.6000 [1.50], Avg: -174.0745 (0.020)
Step: 78367, Reward: -106.4000 [1.96], Avg: -173.9332 (0.020)
Step: 78472, Reward: -102.0000 [6.10], Avg: -173.7919 (0.020)
Step: 78579, Reward: -111.8000 [9.68], Avg: -173.6799 (0.020)
Step: 78728, Reward: -104.6000 [8.14], Avg: -173.5497 (0.020)
Step: 78814, Reward: -111.4000 [18.35], Avg: -173.4563 (0.020)
Step: 78901, Reward: -104.8000 [3.31], Avg: -173.3173 (0.020)
Step: 79027, Reward: -101.4000 [7.20], Avg: -173.1799 (0.020)
Step: 79135, Reward: -104.4000 [2.42], Avg: -173.0393 (0.020)
Step: 79243, Reward: -104.6000 [7.17], Avg: -172.9097 (0.020)
Step: 79349, Reward: -103.0000 [6.78], Avg: -172.7766 (0.020)
Step: 79454, Reward: -105.0000 [0.63], Avg: -172.6352 (0.020)
Step: 79559, Reward: -98.0000 [7.46], Avg: -172.4941 (0.020)
Step: 79666, Reward: -99.2000 [4.58], Avg: -172.3500 (0.020)
Step: 79772, Reward: -105.4000 [1.36], Avg: -172.2128 (0.020)
Step: 79877, Reward: -99.0000 [8.39], Avg: -172.0775 (0.020)
Step: 79983, Reward: -103.2000 [6.37], Avg: -171.9472 (0.020)
Step: 80069, Reward: -97.2000 [8.45], Avg: -171.8094 (0.020)
Step: 80168, Reward: -100.6000 [5.31], Avg: -171.6727 (0.020)
Step: 80261, Reward: -105.2000 [1.47], Avg: -171.5381 (0.020)
Step: 80365, Reward: -102.8000 [9.79], Avg: -171.4163 (0.020)
Step: 80471, Reward: -104.8000 [2.04], Avg: -171.2832 (0.020)
Step: 80577, Reward: -104.8000 [0.98], Avg: -171.1484 (0.020)
Step: 80682, Reward: -106.4000 [2.24], Avg: -171.0200 (0.020)
Step: 80787, Reward: -105.0000 [1.41], Avg: -170.8876 (0.020)
Step: 80873, Reward: -98.4000 [7.34], Avg: -170.7544 (0.020)
Step: 80977, Reward: -104.8000 [1.17], Avg: -170.6222 (0.020)
Step: 81081, Reward: -98.2000 [9.17], Avg: -170.4934 (0.020)
Step: 81185, Reward: -98.8000 [7.19], Avg: -170.3623 (0.020)
Step: 81290, Reward: -112.8000 [19.79], Avg: -170.2857 (0.020)
Step: 81377, Reward: -104.0000 [7.46], Avg: -170.1666 (0.020)
Step: 81481, Reward: -100.8000 [8.42], Avg: -170.0435 (0.020)
Step: 81587, Reward: -101.0000 [6.10], Avg: -169.9166 (0.020)
Step: 81676, Reward: -98.6000 [8.09], Avg: -169.7893 (0.020)
Step: 81783, Reward: -119.8000 [19.45], Avg: -169.7280 (0.020)
Step: 81889, Reward: -97.6000 [6.83], Avg: -169.5972 (0.020)
Step: 81999, Reward: -104.0000 [3.90], Avg: -169.4738 (0.020)
Step: 82085, Reward: -100.8000 [7.91], Avg: -169.3525 (0.020)
Step: 82193, Reward: -115.8000 [22.22], Avg: -169.2901 (0.020)
Step: 82299, Reward: -103.8000 [2.56], Avg: -169.1649 (0.020)
Step: 82387, Reward: -104.6000 [1.20], Avg: -169.0392 (0.020)
Step: 82489, Reward: -105.2000 [1.60], Avg: -168.9160 (0.020)
Step: 82587, Reward: -103.8000 [2.04], Avg: -168.7913 (0.020)
Step: 82692, Reward: -96.0000 [6.99], Avg: -168.6615 (0.020)
Step: 82798, Reward: -98.8000 [8.11], Avg: -168.5400 (0.020)
Step: 82944, Reward: -105.2000 [0.75], Avg: -168.4170 (0.020)
Step: 83049, Reward: -106.4000 [0.80], Avg: -168.2970 (0.020)
Step: 83154, Reward: -105.2000 [1.94], Avg: -168.1773 (0.020)
Step: 83259, Reward: -105.4000 [1.85], Avg: -168.0583 (0.020)
Step: 83365, Reward: -121.4000 [20.24], Avg: -168.0068 (0.020)
Step: 83469, Reward: -102.8000 [5.78], Avg: -167.8912 (0.020)
Step: 83559, Reward: -122.4000 [17.76], Avg: -167.8373 (0.020)
Step: 83703, Reward: -102.6000 [8.16], Avg: -167.7267 (0.020)
Step: 83801, Reward: -104.6000 [1.02], Avg: -167.6066 (0.020)
Step: 83895, Reward: -107.0000 [5.83], Avg: -167.5009 (0.020)
Step: 83990, Reward: -100.0000 [8.07], Avg: -167.3864 (0.020)
Step: 84075, Reward: -105.6000 [1.62], Avg: -167.2707 (0.020)
Step: 84181, Reward: -103.0000 [7.40], Avg: -167.1615 (0.020)
Step: 84269, Reward: -109.2000 [4.92], Avg: -167.0599 (0.020)
Step: 84373, Reward: -106.8000 [1.17], Avg: -166.9469 (0.020)
Step: 84478, Reward: -98.6000 [7.71], Avg: -166.8312 (0.020)
Step: 84582, Reward: -106.8000 [5.60], Avg: -166.7275 (0.020)
Step: 84688, Reward: -102.4000 [9.31], Avg: -166.6229 (0.020)
Step: 84788, Reward: -101.8000 [5.56], Avg: -166.5104 (0.020)
Step: 84892, Reward: -98.0000 [8.37], Avg: -166.3965 (0.020)
Step: 84997, Reward: -97.2000 [8.89], Avg: -166.2825 (0.020)
Step: 85086, Reward: -106.0000 [0.89], Avg: -166.1705 (0.020)
Step: 85190, Reward: -99.6000 [7.86], Avg: -166.0599 (0.020)
Step: 85295, Reward: -121.0000 [27.88], Avg: -166.0276 (0.020)
Step: 85386, Reward: -106.4000 [3.50], Avg: -165.9223 (0.020)
Step: 85472, Reward: -97.2000 [9.58], Avg: -165.8116 (0.020)
Step: 85569, Reward: -114.8000 [20.92], Avg: -165.7553 (0.020)
Step: 85662, Reward: -106.2000 [3.49], Avg: -165.6507 (0.020)
Step: 85767, Reward: -104.8000 [2.48], Avg: -165.5420 (0.020)
Step: 85859, Reward: -103.2000 [5.38], Avg: -165.4361 (0.020)
Step: 85947, Reward: -105.2000 [0.98], Avg: -165.3262 (0.020)
Step: 86053, Reward: -104.8000 [1.47], Avg: -165.2168 (0.020)
Step: 86158, Reward: -102.6000 [8.71], Avg: -165.1172 (0.020)
Step: 86262, Reward: -102.8000 [5.46], Avg: -165.0123 (0.020)
Step: 86372, Reward: -99.6000 [6.22], Avg: -164.9033 (0.020)
Step: 86477, Reward: -105.2000 [0.98], Avg: -164.7953 (0.020)
Step: 86585, Reward: -100.8000 [6.08], Avg: -164.6891 (0.020)
Step: 86690, Reward: -106.8000 [30.30], Avg: -164.6385 (0.020)
Step: 86796, Reward: -103.2000 [5.67], Avg: -164.5366 (0.020)
Step: 86900, Reward: -112.6000 [26.09], Avg: -164.4894 (0.020)
Step: 86991, Reward: -91.4000 [7.45], Avg: -164.3698 (0.020)
Step: 87099, Reward: -97.8000 [9.28], Avg: -164.2657 (0.020)
Step: 87190, Reward: -102.6000 [6.59], Avg: -164.1657 (0.020)
Step: 87294, Reward: -106.6000 [2.58], Avg: -164.0661 (0.020)
Step: 87413, Reward: -98.6000 [5.82], Avg: -163.9582 (0.020)
Step: 87521, Reward: -124.0000 [28.76], Avg: -163.9380 (0.020)
Step: 87627, Reward: -101.4000 [8.40], Avg: -163.8405 (0.020)
Step: 87733, Reward: -107.6000 [0.80], Avg: -163.7408 (0.020)
Step: 87823, Reward: -102.2000 [6.14], Avg: -163.6413 (0.020)
Step: 87930, Reward: -113.0000 [14.07], Avg: -163.5758 (0.020)
Step: 88036, Reward: -104.8000 [4.75], Avg: -163.4791 (0.020)
Step: 88142, Reward: -106.0000 [1.41], Avg: -163.3790 (0.020)
Step: 88248, Reward: -96.6000 [7.58], Avg: -163.2735 (0.020)
Step: 88359, Reward: -104.2000 [1.17], Avg: -163.1705 (0.020)
Step: 88444, Reward: -102.8000 [6.76], Avg: -163.0752 (0.020)
Step: 88560, Reward: -101.6000 [5.82], Avg: -162.9766 (0.020)
Step: 88668, Reward: -113.2000 [20.55], Avg: -162.9248 (0.020)
Step: 88772, Reward: -105.0000 [1.41], Avg: -162.8250 (0.020)
Step: 88878, Reward: -103.0000 [1.90], Avg: -162.7228 (0.020)
Step: 89003, Reward: -106.0000 [4.05], Avg: -162.6301 (0.020)
Step: 89116, Reward: -98.8000 [7.63], Avg: -162.5313 (0.020)
Step: 89221, Reward: -104.6000 [0.80], Avg: -162.4311 (0.020)
Step: 89325, Reward: -105.2000 [1.47], Avg: -162.3334 (0.020)
Step: 89430, Reward: -110.6000 [11.22], Avg: -162.2626 (0.020)
Step: 89521, Reward: -117.4000 [15.60], Avg: -162.2115 (0.020)
Step: 89614, Reward: -104.4000 [1.62], Avg: -162.1136 (0.020)
Step: 89712, Reward: -107.4000 [4.08], Avg: -162.0256 (0.020)
Step: 89818, Reward: -104.0000 [1.10], Avg: -161.9267 (0.020)
Step: 89904, Reward: -102.2000 [5.46], Avg: -161.8327 (0.020)
Step: 90010, Reward: -100.4000 [6.18], Avg: -161.7371 (0.020)
Step: 90117, Reward: -106.0000 [1.10], Avg: -161.6427 (0.020)
Step: 90203, Reward: -104.0000 [1.10], Avg: -161.5452 (0.020)
Step: 90309, Reward: -98.4000 [9.29], Avg: -161.4525 (0.020)
Step: 90397, Reward: -107.2000 [26.19], Avg: -161.4043 (0.020)
Step: 90503, Reward: -114.2000 [19.93], Avg: -161.3575 (0.020)
Step: 90605, Reward: -104.6000 [1.20], Avg: -161.2624 (0.020)
Step: 90772, Reward: -102.0000 [4.05], Avg: -161.1680 (0.020)
Step: 90876, Reward: -129.6000 [40.34], Avg: -161.1830 (0.020)
Step: 91028, Reward: -107.8000 [2.32], Avg: -161.0960 (0.020)
Step: 91134, Reward: -103.6000 [6.95], Avg: -161.0100 (0.020)
Step: 91239, Reward: -122.2000 [17.59], Avg: -160.9740 (0.020)
Step: 91397, Reward: -99.8000 [5.23], Avg: -160.8792 (0.020)
Step: 91500, Reward: -107.2000 [4.35], Avg: -160.7957 (0.020)
Step: 91599, Reward: -104.4000 [2.58], Avg: -160.7048 (0.020)
Step: 91704, Reward: -102.8000 [6.11], Avg: -160.6175 (0.020)
Step: 91808, Reward: -137.2000 [34.00], Avg: -160.6353 (0.020)
Step: 91945, Reward: -127.2000 [14.30], Avg: -160.6031 (0.020)
Step: 92030, Reward: -110.0000 [17.99], Avg: -160.5484 (0.020)
Step: 92194, Reward: -102.2000 [6.40], Avg: -160.4614 (0.020)
Step: 92304, Reward: -102.2000 [9.17], Avg: -160.3793 (0.020)
Step: 92410, Reward: -99.0000 [9.84], Avg: -160.2933 (0.020)
Step: 92509, Reward: -97.0000 [9.10], Avg: -160.2029 (0.020)
Step: 92674, Reward: -119.2000 [24.54], Avg: -160.1755 (0.020)
Step: 92760, Reward: -104.8000 [0.75], Avg: -160.0848 (0.020)
Step: 92865, Reward: -105.4000 [1.02], Avg: -159.9958 (0.020)
Step: 92975, Reward: -103.2000 [8.57], Avg: -159.9159 (0.020)
Step: 93079, Reward: -105.8000 [1.17], Avg: -159.8284 (0.020)
Step: 93237, Reward: -98.0000 [8.41], Avg: -159.7403 (0.020)
Step: 93323, Reward: -114.6000 [24.92], Avg: -159.7070 (0.020)
Step: 93431, Reward: -97.8000 [8.18], Avg: -159.6186 (0.020)
Step: 93545, Reward: -99.4000 [10.17], Avg: -159.5364 (0.020)
Step: 93649, Reward: -106.4000 [3.07], Avg: -159.4544 (0.020)
Step: 93753, Reward: -101.6000 [5.16], Avg: -159.3681 (0.020)
Step: 93856, Reward: -101.4000 [6.71], Avg: -159.2844 (0.020)
Step: 94009, Reward: -103.2000 [2.64], Avg: -159.1972 (0.020)
Step: 94115, Reward: -97.4000 [9.75], Avg: -159.1124 (0.020)
Step: 94204, Reward: -98.0000 [6.29], Avg: -159.0233 (0.020)
Step: 94308, Reward: -121.8000 [21.01], Avg: -158.9969 (0.020)
Step: 94415, Reward: -99.8000 [7.44], Avg: -158.9131 (0.020)
Step: 94519, Reward: -102.4000 [4.76], Avg: -158.8293 (0.020)
Step: 94627, Reward: -101.6000 [7.94], Avg: -158.7497 (0.020)
Step: 94714, Reward: -102.6000 [5.75], Avg: -158.6684 (0.020)
Step: 94820, Reward: -98.0000 [10.41], Avg: -158.5875 (0.020)
Step: 94923, Reward: -105.6000 [1.50], Avg: -158.5047 (0.020)
Step: 95029, Reward: -105.6000 [3.61], Avg: -158.4256 (0.020)
Step: 95134, Reward: -105.2000 [1.47], Avg: -158.3426 (0.020)
Step: 95239, Reward: -101.0000 [7.64], Avg: -158.2631 (0.020)
Step: 95342, Reward: -96.0000 [8.67], Avg: -158.1775 (0.020)
Step: 95448, Reward: -102.2000 [7.68], Avg: -158.1005 (0.020)
Step: 95553, Reward: -99.8000 [7.08], Avg: -158.0189 (0.020)
Step: 95659, Reward: -118.0000 [32.26], Avg: -158.0066 (0.020)
Step: 95761, Reward: -102.0000 [8.22], Avg: -157.9307 (0.020)
Step: 95864, Reward: -103.2000 [8.03], Avg: -157.8567 (0.020)
Step: 95969, Reward: -120.6000 [16.68], Avg: -157.8241 (0.020)
Step: 96074, Reward: -101.6000 [6.95], Avg: -157.7463 (0.020)
Step: 96180, Reward: -101.2000 [8.28], Avg: -157.6702 (0.020)
Step: 96265, Reward: -102.6000 [1.85], Avg: -157.5864 (0.020)
Step: 96380, Reward: -118.0000 [31.39], Avg: -157.5735 (0.020)
Step: 96466, Reward: -101.0000 [7.51], Avg: -157.4965 (0.020)
Step: 96620, Reward: -100.4000 [7.23], Avg: -157.4183 (0.020)
Step: 96725, Reward: -101.2000 [6.62], Avg: -157.3407 (0.020)
Step: 96832, Reward: -112.0000 [31.70], Avg: -157.3194 (0.020)
Step: 96940, Reward: -104.8000 [1.60], Avg: -157.2399 (0.020)
Step: 97038, Reward: -108.2000 [21.57], Avg: -157.1971 (0.020)
Step: 97143, Reward: -111.6000 [21.92], Avg: -157.1603 (0.020)
Step: 97237, Reward: -105.2000 [0.98], Avg: -157.0812 (0.020)
Step: 97323, Reward: -107.6000 [9.81], Avg: -157.0196 (0.020)
Step: 97428, Reward: -99.6000 [9.67], Avg: -156.9457 (0.020)
Step: 97516, Reward: -101.6000 [7.91], Avg: -156.8724 (0.020)
Step: 97625, Reward: -103.2000 [7.39], Avg: -156.8010 (0.020)
Step: 97730, Reward: -105.2000 [2.32], Avg: -156.7250 (0.020)
Step: 97833, Reward: -111.2000 [23.24], Avg: -156.6908 (0.020)
Step: 97927, Reward: -105.2000 [2.14], Avg: -156.6149 (0.020)
Step: 98032, Reward: -106.8000 [6.11], Avg: -156.5479 (0.020)
Step: 98136, Reward: -100.8000 [5.46], Avg: -156.4709 (0.020)
Step: 98241, Reward: -100.0000 [6.87], Avg: -156.3951 (0.020)
Step: 98347, Reward: -112.4000 [9.89], Avg: -156.3430 (0.020)
Step: 98442, Reward: -103.0000 [5.76], Avg: -156.2705 (0.020)
Step: 98539, Reward: -98.2000 [7.93], Avg: -156.1942 (0.020)
Step: 98634, Reward: -102.6000 [8.48], Avg: -156.1256 (0.020)
Step: 98736, Reward: -94.6000 [8.98], Avg: -156.0458 (0.020)
Step: 98841, Reward: -104.0000 [2.61], Avg: -155.9709 (0.020)
Step: 98944, Reward: -105.8000 [1.83], Avg: -155.8978 (0.020)
Step: 99048, Reward: -102.2000 [4.66], Avg: -155.8237 (0.020)
Step: 99151, Reward: -105.0000 [1.41], Avg: -155.7492 (0.020)
Step: 99255, Reward: -104.4000 [1.85], Avg: -155.6747 (0.020)
Step: 99358, Reward: -99.6000 [8.09], Avg: -155.6025 (0.020)
Step: 99463, Reward: -100.6000 [8.40], Avg: -155.5326 (0.020)
Step: 99569, Reward: -109.4000 [10.82], Avg: -155.4796 (0.020)
Step: 99673, Reward: -100.2000 [8.49], Avg: -155.4096 (0.020)
Step: 99778, Reward: -113.2000 [25.76], Avg: -155.3850 (0.020)
Step: 99877, Reward: -98.4000 [9.89], Avg: -155.3147 (0.020)
Step: 99982, Reward: -103.2000 [1.83], Avg: -155.2398 (0.020)
